searchNodes=[{"ref":"AWS.html","title":"AWS","type":"module","doc":""},{"ref":"AWS.ACM.html","title":"AWS.ACM","type":"module","doc":"AWS Certificate Manager Welcome to the AWS Certificate Manager (ACM) API documentation. You can use ACM to manage SSL/TLS certificates for your AWS-based websites and applications. For general information about using ACM, see the AWS Certificate Manager User Guide ."},{"ref":"AWS.ACM.html#add_tags_to_certificate/3","title":"AWS.ACM.add_tags_to_certificate/3","type":"function","doc":"Adds one or more tags to an ACM certificate. Tags are labels that you can use to identify and organize your AWS resources. Each tag consists of a key and an optional value. You specify the certificate on input by its Amazon Resource Name (ARN). You specify the tag by using a key-value pair. You can apply a tag to just one certificate if you want to identify a specific characteristic of that certificate, or you can apply the same tag to multiple certificates if you want to filter for a common relationship among those certificates. Similarly, you can apply the same tag to multiple resources if you want to specify a relationship among those resources. For example, you can add the same tag to an ACM certificate and an Elastic Load Balancing load balancer to indicate that they are both used by the same website. For more information, see Tagging ACM certificates. To remove one or more tags, use the RemoveTagsFromCertificate action. To view all of the tags that have been applied to the certificate, use the ListTagsForCertificate action."},{"ref":"AWS.ACM.html#delete_certificate/3","title":"AWS.ACM.delete_certificate/3","type":"function","doc":"Deletes a certificate and its associated private key. If this action succeeds, the certificate no longer appears in the list that can be displayed by calling the ListCertificates action or be retrieved by calling the GetCertificate action. The certificate will not be available for use by AWS services integrated with ACM. You cannot delete an ACM certificate that is being used by another AWS service. To delete a certificate that is in use, the certificate association must first be removed."},{"ref":"AWS.ACM.html#describe_certificate/3","title":"AWS.ACM.describe_certificate/3","type":"function","doc":"Returns detailed metadata about the specified ACM certificate."},{"ref":"AWS.ACM.html#export_certificate/3","title":"AWS.ACM.export_certificate/3","type":"function","doc":"Exports a private certificate issued by a private certificate authority (CA) for use anywhere. The exported file contains the certificate, the certificate chain, and the encrypted private 2048-bit RSA key associated with the public key that is embedded in the certificate. For security, you must assign a passphrase for the private key when exporting it. For information about exporting and formatting a certificate using the ACM console or CLI, see Export a Private Certificate."},{"ref":"AWS.ACM.html#get_certificate/3","title":"AWS.ACM.get_certificate/3","type":"function","doc":"Retrieves an Amazon-issued certificate and its certificate chain. The chain consists of the certificate of the issuing CA and the intermediate certificates of any other subordinate CAs. All of the certificates are base64 encoded. You can use OpenSSL to decode the certificates and inspect individual fields."},{"ref":"AWS.ACM.html#import_certificate/3","title":"AWS.ACM.import_certificate/3","type":"function","doc":"Imports a certificate into AWS Certificate Manager (ACM) to use with services that are integrated with ACM. Note that integrated services allow only certificate types and keys they support to be associated with their resources. Further, their support differs depending on whether the certificate is imported into IAM or into ACM. For more information, see the documentation for each service. For more information about importing certificates into ACM, see Importing Certificates in the AWS Certificate Manager User Guide. ACM does not provide managed renewal for certificates that you import. Note the following guidelines when importing third party certificates: You must enter the private key that matches the certificate you are importing. The private key must be unencrypted. You cannot import a private key that is protected by a password or a passphrase. If the certificate you are importing is not self-signed, you must enter its certificate chain. If a certificate chain is included, the issuer must be the subject of one of the certificates in the chain. The certificate, private key, and certificate chain must be PEM-encoded. The current time must be between the Not Before and Not After certificate fields. The Issuer field must not be empty. The OCSP authority URL, if present, must not exceed 1000 characters. To import a new certificate, omit the CertificateArn argument. Include this argument only when you want to replace a previously imported certifica When you import a certificate by using the CLI, you must specify the certificate, the certificate chain, and the private key by their file names preceded by file://. For example, you can specify a certificate saved in the C: emp folder as file://C: empcertificate_to_import.pem. If you are making an HTTP or HTTPS Query request, include these arguments as BLOBs. When you import a certificate by using an SDK, you must specify the certificate, the certificate chain, and the private key files in the manner required by the programming language you&#39;re using. The cryptographic algorithm of an imported certificate must match the algorithm of the signing CA. For example, if the signing CA key type is RSA, then the certificate key type must also be RSA. This operation returns the Amazon Resource Name (ARN) of the imported certificate."},{"ref":"AWS.ACM.html#list_certificates/3","title":"AWS.ACM.list_certificates/3","type":"function","doc":"Retrieves a list of certificate ARNs and domain names. You can request that only certificates that match a specific status be listed. You can also filter by specific attributes of the certificate. Default filtering returns only RSA_2048 certificates. For more information, see Filters."},{"ref":"AWS.ACM.html#list_tags_for_certificate/3","title":"AWS.ACM.list_tags_for_certificate/3","type":"function","doc":"Lists the tags that have been applied to the ACM certificate. Use the certificate&#39;s Amazon Resource Name (ARN) to specify the certificate. To add a tag to an ACM certificate, use the AddTagsToCertificate action. To delete a tag, use the RemoveTagsFromCertificate action."},{"ref":"AWS.ACM.html#remove_tags_from_certificate/3","title":"AWS.ACM.remove_tags_from_certificate/3","type":"function","doc":"Remove one or more tags from an ACM certificate. A tag consists of a key-value pair. If you do not specify the value portion of the tag when calling this function, the tag will be removed regardless of value. If you specify a value, the tag is removed only if it is associated with the specified value. To add tags to a certificate, use the AddTagsToCertificate action. To view all of the tags that have been applied to a specific ACM certificate, use the ListTagsForCertificate action."},{"ref":"AWS.ACM.html#renew_certificate/3","title":"AWS.ACM.renew_certificate/3","type":"function","doc":"Renews an eligable ACM certificate. At this time, only exported private certificates can be renewed with this operation. In order to renew your ACM PCA certificates with ACM, you must first grant the ACM service principal permission to do so. For more information, see Testing Managed Renewal in the ACM User Guide."},{"ref":"AWS.ACM.html#request_certificate/3","title":"AWS.ACM.request_certificate/3","type":"function","doc":"Requests an ACM certificate for use with other AWS services. To request an ACM certificate, you must specify a fully qualified domain name (FQDN) in the DomainName parameter. You can also specify additional FQDNs in the SubjectAlternativeNames parameter. If you are requesting a private certificate, domain validation is not required. If you are requesting a public certificate, each domain name that you specify must be validated to verify that you own or control the domain. You can use DNS validation or email validation. We recommend that you use DNS validation. ACM issues public certificates after receiving approval from the domain owner."},{"ref":"AWS.ACM.html#resend_validation_email/3","title":"AWS.ACM.resend_validation_email/3","type":"function","doc":"Resends the email that requests domain ownership validation. The domain owner or an authorized representative must approve the ACM certificate before it can be issued. The certificate can be approved by clicking a link in the mail to navigate to the Amazon certificate approval website and then clicking I Approve. However, the validation email can be blocked by spam filters. Therefore, if you do not receive the original mail, you can request that the mail be resent within 72 hours of requesting the ACM certificate. If more than 72 hours have elapsed since your original request or since your last attempt to resend validation mail, you must request a new certificate. For more information about setting up your contact email addresses, see Configure Email for your Domain."},{"ref":"AWS.ACM.html#update_certificate_options/3","title":"AWS.ACM.update_certificate_options/3","type":"function","doc":"Updates a certificate. Currently, you can use this function to specify whether to opt in to or out of recording your certificate in a certificate transparency log. For more information, see Opting Out of Certificate Transparency Logging."},{"ref":"AWS.ACMPCA.html","title":"AWS.ACMPCA","type":"module","doc":"This is the ACM Private CA API Reference. It provides descriptions, syntax, and usage examples for each of the actions and data types involved in creating and managing private certificate authorities (CA) for your organization. The documentation for each action shows the Query API request parameters and the XML response. Alternatively, you can use one of the AWS SDKs to access an API that&#39;s tailored to the programming language or platform that you&#39;re using. For more information, see AWS SDKs. Each ACM Private CA API action has a quota that determines the number of times the action can be called per second. For more information, see API Rate Quotas in ACM Private CA in the ACM Private CA user guide."},{"ref":"AWS.ACMPCA.html#create_certificate_authority/3","title":"AWS.ACMPCA.create_certificate_authority/3","type":"function","doc":"Creates a root or subordinate private certificate authority (CA). You must specify the CA configuration, the certificate revocation list (CRL) configuration, the CA type, and an optional idempotency token to avoid accidental creation of multiple CAs. The CA configuration specifies the name of the algorithm and key size to be used to create the CA private key, the type of signing algorithm that the CA uses, and X.500 subject information. The CRL configuration specifies the CRL expiration period in days (the validity period of the CRL), the Amazon S3 bucket that will contain the CRL, and a CNAME alias for the S3 bucket that is included in certificates issued by the CA. If successful, this action returns the Amazon Resource Name (ARN) of the CA. ACM Private CAA assets that are stored in Amazon S3 can be protected with encryption. For more information, see Encrypting Your CRLs. Both PCA and the IAM principal must have permission to write to the S3 bucket that you specify. If the IAM principal making the call does not have permission to write to the bucket, then an exception is thrown. For more information, see Configure Access to ACM Private CA."},{"ref":"AWS.ACMPCA.html#create_certificate_authority_audit_report/3","title":"AWS.ACMPCA.create_certificate_authority_audit_report/3","type":"function","doc":"Creates an audit report that lists every time that your CA private key is used. The report is saved in the Amazon S3 bucket that you specify on input. The IssueCertificate and RevokeCertificate actions use the private key. Both PCA and the IAM principal must have permission to write to the S3 bucket that you specify. If the IAM principal making the call does not have permission to write to the bucket, then an exception is thrown. For more information, see Configure Access to ACM Private CA. ACM Private CAA assets that are stored in Amazon S3 can be protected with encryption. For more information, see Encrypting Your Audit Reports."},{"ref":"AWS.ACMPCA.html#create_permission/3","title":"AWS.ACMPCA.create_permission/3","type":"function","doc":"Grants one or more permissions on a private CA to the AWS Certificate Manager (ACM) service principal (acm.amazonaws.com). These permissions allow ACM to issue and renew ACM certificates that reside in the same AWS account as the CA. You can list current permissions with the ListPermissions action and revoke them with the DeletePermission action. About Permissions If the private CA and the certificates it issues reside in the same account, you can use CreatePermission to grant permissions for ACM to carry out automatic certificate renewals. For automatic certificate renewal to succeed, the ACM service principal needs permissions to create, retrieve, and list certificates. If the private CA and the ACM certificates reside in different accounts, then permissions cannot be used to enable automatic renewals. Instead, the ACM certificate owner must set up a resource-based policy to enable cross-account issuance and renewals. For more information, see Using a Resource Based Policy with ACM Private CA."},{"ref":"AWS.ACMPCA.html#delete_certificate_authority/3","title":"AWS.ACMPCA.delete_certificate_authority/3","type":"function","doc":"Deletes a private certificate authority (CA). You must provide the Amazon Resource Name (ARN) of the private CA that you want to delete. You can find the ARN by calling the ListCertificateAuthorities action. Deleting a CA will invalidate other CAs and certificates below it in your CA hierarchy. Before you can delete a CA that you have created and activated, you must disable it. To do this, call the UpdateCertificateAuthority action and set the CertificateAuthorityStatus parameter to DISABLED. Additionally, you can delete a CA if you are waiting for it to be created (that is, the status of the CA is CREATING). You can also delete it if the CA has been created but you haven&#39;t yet imported the signed certificate into ACM Private CA (that is, the status of the CA is PENDING_CERTIFICATE). When you successfully call DeleteCertificateAuthority, the CA&#39;s status changes to DELETED. However, the CA won&#39;t be permanently deleted until the restoration period has passed. By default, if you do not set the PermanentDeletionTimeInDays parameter, the CA remains restorable for 30 days. You can set the parameter from 7 to 30 days. The DescribeCertificateAuthority action returns the time remaining in the restoration window of a private CA in the DELETED state. To restore an eligible CA, call the RestoreCertificateAuthority action."},{"ref":"AWS.ACMPCA.html#delete_permission/3","title":"AWS.ACMPCA.delete_permission/3","type":"function","doc":"Revokes permissions on a private CA granted to the AWS Certificate Manager (ACM) service principal (acm.amazonaws.com). These permissions allow ACM to issue and renew ACM certificates that reside in the same AWS account as the CA. If you revoke these permissions, ACM will no longer renew the affected certificates automatically. Permissions can be granted with the CreatePermission action and listed with the ListPermissions action. About Permissions If the private CA and the certificates it issues reside in the same account, you can use CreatePermission to grant permissions for ACM to carry out automatic certificate renewals. For automatic certificate renewal to succeed, the ACM service principal needs permissions to create, retrieve, and list certificates. If the private CA and the ACM certificates reside in different accounts, then permissions cannot be used to enable automatic renewals. Instead, the ACM certificate owner must set up a resource-based policy to enable cross-account issuance and renewals. For more information, see Using a Resource Based Policy with ACM Private CA."},{"ref":"AWS.ACMPCA.html#delete_policy/3","title":"AWS.ACMPCA.delete_policy/3","type":"function","doc":"Deletes the resource-based policy attached to a private CA. Deletion will remove any access that the policy has granted. If there is no policy attached to the private CA, this action will return successful. If you delete a policy that was applied through AWS Resource Access Manager (RAM), the CA will be removed from all shares in which it was included. The AWS Certificate Manager Service Linked Role that the policy supports is not affected when you delete the policy. The current policy can be shown with GetPolicy and updated with PutPolicy. About Policies A policy grants access on a private CA to an AWS customer account, to AWS Organizations, or to an AWS Organizations unit. Policies are under the control of a CA administrator. For more information, see Using a Resource Based Policy with ACM Private CA. A policy permits a user of AWS Certificate Manager (ACM) to issue ACM certificates signed by a CA in another account. For ACM to manage automatic renewal of these certificates, the ACM user must configure a Service Linked Role (SLR). The SLR allows the ACM service to assume the identity of the user, subject to confirmation against the ACM Private CA policy. For more information, see Using a Service Linked Role with ACM. Updates made in AWS Resource Manager (RAM) are reflected in policies. For more information, see Using AWS Resource Access Manager (RAM) with ACM Private CA."},{"ref":"AWS.ACMPCA.html#describe_certificate_authority/3","title":"AWS.ACMPCA.describe_certificate_authority/3","type":"function","doc":"Lists information about your private certificate authority (CA) or one that has been shared with you. You specify the private CA on input by its ARN (Amazon Resource Name). The output contains the status of your CA. This can be any of the following: CREATING - ACM Private CA is creating your private certificate authority. PENDING_CERTIFICATE - The certificate is pending. You must use your ACM Private CA-hosted or on-premises root or subordinate CA to sign your private CA CSR and then import it into PCA. ACTIVE - Your private CA is active. DISABLED - Your private CA has been disabled. EXPIRED - Your private CA certificate has expired. FAILED - Your private CA has failed. Your CA can fail because of problems such a network outage or backend AWS failure or other errors. A failed CA can never return to the pending state. You must create a new CA. DELETED - Your private CA is within the restoration period, after which it is permanently deleted. The length of time remaining in the CA&#39;s restoration period is also included in this action&#39;s output."},{"ref":"AWS.ACMPCA.html#describe_certificate_authority_audit_report/3","title":"AWS.ACMPCA.describe_certificate_authority_audit_report/3","type":"function","doc":"Lists information about a specific audit report created by calling the CreateCertificateAuthorityAuditReport action. Audit information is created every time the certificate authority (CA) private key is used. The private key is used when you call the IssueCertificate action or the RevokeCertificate action."},{"ref":"AWS.ACMPCA.html#get_certificate/3","title":"AWS.ACMPCA.get_certificate/3","type":"function","doc":"Retrieves a certificate from your private CA or one that has been shared with you. The ARN of the certificate is returned when you call the IssueCertificate action. You must specify both the ARN of your private CA and the ARN of the issued certificate when calling the GetCertificate action. You can retrieve the certificate if it is in the ISSUED state. You can call the CreateCertificateAuthorityAuditReport action to create a report that contains information about all of the certificates issued and revoked by your private CA."},{"ref":"AWS.ACMPCA.html#get_certificate_authority_certificate/3","title":"AWS.ACMPCA.get_certificate_authority_certificate/3","type":"function","doc":"Retrieves the certificate and certificate chain for your private certificate authority (CA) or one that has been shared with you. Both the certificate and the chain are base64 PEM-encoded. The chain does not include the CA certificate. Each certificate in the chain signs the one before it."},{"ref":"AWS.ACMPCA.html#get_certificate_authority_csr/3","title":"AWS.ACMPCA.get_certificate_authority_csr/3","type":"function","doc":"Retrieves the certificate signing request (CSR) for your private certificate authority (CA). The CSR is created when you call the CreateCertificateAuthority action. Sign the CSR with your ACM Private CA-hosted or on-premises root or subordinate CA. Then import the signed certificate back into ACM Private CA by calling the ImportCertificateAuthorityCertificate action. The CSR is returned as a base64 PEM-encoded string."},{"ref":"AWS.ACMPCA.html#get_policy/3","title":"AWS.ACMPCA.get_policy/3","type":"function","doc":"Retrieves the resource-based policy attached to a private CA. If either the private CA resource or the policy cannot be found, this action returns a ResourceNotFoundException. The policy can be attached or updated with PutPolicy and removed with DeletePolicy. About Policies A policy grants access on a private CA to an AWS customer account, to AWS Organizations, or to an AWS Organizations unit. Policies are under the control of a CA administrator. For more information, see Using a Resource Based Policy with ACM Private CA. A policy permits a user of AWS Certificate Manager (ACM) to issue ACM certificates signed by a CA in another account. For ACM to manage automatic renewal of these certificates, the ACM user must configure a Service Linked Role (SLR). The SLR allows the ACM service to assume the identity of the user, subject to confirmation against the ACM Private CA policy. For more information, see Using a Service Linked Role with ACM. Updates made in AWS Resource Manager (RAM) are reflected in policies. For more information, see Using AWS Resource Access Manager (RAM) with ACM Private CA."},{"ref":"AWS.ACMPCA.html#import_certificate_authority_certificate/3","title":"AWS.ACMPCA.import_certificate_authority_certificate/3","type":"function","doc":"Imports a signed private CA certificate into ACM Private CA. This action is used when you are using a chain of trust whose root is located outside ACM Private CA. Before you can call this action, the following preparations must in place: In ACM Private CA, call the CreateCertificateAuthority action to create the private CA that that you plan to back with the imported certificate. Call the GetCertificateAuthorityCsr action to generate a certificate signing request (CSR). Sign the CSR using a root or intermediate CA hosted by either an on-premises PKI hierarchy or by a commercial CA. Create a certificate chain and copy the signed certificate and the certificate chain to your working directory. The following requirements apply when you import a CA certificate. You cannot import a non-self-signed certificate for use as a root CA. You cannot import a self-signed certificate for use as a subordinate CA. Your certificate chain must not include the private CA certificate that you are importing. Your ACM Private CA-hosted or on-premises CA certificate must be the last certificate in your chain. The subordinate certificate, if any, that your root CA signed must be next to last. The subordinate certificate signed by the preceding subordinate CA must come next, and so on until your chain is built. The chain must be PEM-encoded. The maximum allowed size of a certificate is 32 KB. The maximum allowed size of a certificate chain is 2 MB. Enforcement of Critical Constraints ACM Private CA allows the following extensions to be marked critical in the imported CA certificate or chain. Basic constraints (must be marked critical) Subject alternative names Key usage Extended key usage Authority key identifier Subject key identifier Issuer alternative name Subject directory attributes Subject information access Certificate policies Policy mappings Inhibit anyPolicy ACM Private CA rejects the following extensions when they are marked critical in an imported CA certificate or chain. Name constraints Policy constraints CRL distribution points Authority information access Freshest CRL Any other extension"},{"ref":"AWS.ACMPCA.html#issue_certificate/3","title":"AWS.ACMPCA.issue_certificate/3","type":"function","doc":"Uses your private certificate authority (CA), or one that has been shared with you, to issue a client certificate. This action returns the Amazon Resource Name (ARN) of the certificate. You can retrieve the certificate by calling the GetCertificate action and specifying the ARN. You cannot use the ACM ListCertificateAuthorities action to retrieve the ARNs of the certificates that you issue by using ACM Private CA."},{"ref":"AWS.ACMPCA.html#list_certificate_authorities/3","title":"AWS.ACMPCA.list_certificate_authorities/3","type":"function","doc":"Lists the private certificate authorities that you created by using the CreateCertificateAuthority action."},{"ref":"AWS.ACMPCA.html#list_permissions/3","title":"AWS.ACMPCA.list_permissions/3","type":"function","doc":"List all permissions on a private CA, if any, granted to the AWS Certificate Manager (ACM) service principal (acm.amazonaws.com). These permissions allow ACM to issue and renew ACM certificates that reside in the same AWS account as the CA. Permissions can be granted with the CreatePermission action and revoked with the DeletePermission action. About Permissions If the private CA and the certificates it issues reside in the same account, you can use CreatePermission to grant permissions for ACM to carry out automatic certificate renewals. For automatic certificate renewal to succeed, the ACM service principal needs permissions to create, retrieve, and list certificates. If the private CA and the ACM certificates reside in different accounts, then permissions cannot be used to enable automatic renewals. Instead, the ACM certificate owner must set up a resource-based policy to enable cross-account issuance and renewals. For more information, see Using a Resource Based Policy with ACM Private CA."},{"ref":"AWS.ACMPCA.html#list_tags/3","title":"AWS.ACMPCA.list_tags/3","type":"function","doc":"Lists the tags, if any, that are associated with your private CA or one that has been shared with you. Tags are labels that you can use to identify and organize your CAs. Each tag consists of a key and an optional value. Call the TagCertificateAuthority action to add one or more tags to your CA. Call the UntagCertificateAuthority action to remove tags."},{"ref":"AWS.ACMPCA.html#put_policy/3","title":"AWS.ACMPCA.put_policy/3","type":"function","doc":"Attaches a resource-based policy to a private CA. A policy can also be applied by sharing a private CA through AWS Resource Access Manager (RAM). The policy can be displayed with GetPolicy and removed with DeletePolicy. About Policies A policy grants access on a private CA to an AWS customer account, to AWS Organizations, or to an AWS Organizations unit. Policies are under the control of a CA administrator. For more information, see Using a Resource Based Policy with ACM Private CA. A policy permits a user of AWS Certificate Manager (ACM) to issue ACM certificates signed by a CA in another account. For ACM to manage automatic renewal of these certificates, the ACM user must configure a Service Linked Role (SLR). The SLR allows the ACM service to assume the identity of the user, subject to confirmation against the ACM Private CA policy. For more information, see Using a Service Linked Role with ACM. Updates made in AWS Resource Manager (RAM) are reflected in policies. For more information, see Using AWS Resource Access Manager (RAM) with ACM Private CA."},{"ref":"AWS.ACMPCA.html#restore_certificate_authority/3","title":"AWS.ACMPCA.restore_certificate_authority/3","type":"function","doc":"Restores a certificate authority (CA) that is in the DELETED state. You can restore a CA during the period that you defined in the PermanentDeletionTimeInDays parameter of the DeleteCertificateAuthority action. Currently, you can specify 7 to 30 days. If you did not specify a PermanentDeletionTimeInDays value, by default you can restore the CA at any time in a 30 day period. You can check the time remaining in the restoration period of a private CA in the DELETED state by calling the DescribeCertificateAuthority or ListCertificateAuthorities actions. The status of a restored CA is set to its pre-deletion status when the RestoreCertificateAuthority action returns. To change its status to ACTIVE, call the UpdateCertificateAuthority action. If the private CA was in the PENDING_CERTIFICATE state at deletion, you must use the ImportCertificateAuthorityCertificate action to import a certificate authority into the private CA before it can be activated. You cannot restore a CA after the restoration period has ended."},{"ref":"AWS.ACMPCA.html#revoke_certificate/3","title":"AWS.ACMPCA.revoke_certificate/3","type":"function","doc":"Revokes a certificate that was issued inside ACM Private CA. If you enable a certificate revocation list (CRL) when you create or update your private CA, information about the revoked certificates will be included in the CRL. ACM Private CA writes the CRL to an S3 bucket that you specify. A CRL is typically updated approximately 30 minutes after a certificate is revoked. If for any reason the CRL update fails, ACM Private CA attempts makes further attempts every 15 minutes. With Amazon CloudWatch, you can create alarms for the metrics CRLGenerated and MisconfiguredCRLBucket. For more information, see Supported CloudWatch Metrics. Both PCA and the IAM principal must have permission to write to the S3 bucket that you specify. If the IAM principal making the call does not have permission to write to the bucket, then an exception is thrown. For more information, see Configure Access to ACM Private CA. ACM Private CA also writes revocation information to the audit report. For more information, see CreateCertificateAuthorityAuditReport. You cannot revoke a root CA self-signed certificate."},{"ref":"AWS.ACMPCA.html#tag_certificate_authority/3","title":"AWS.ACMPCA.tag_certificate_authority/3","type":"function","doc":"Adds one or more tags to your private CA. Tags are labels that you can use to identify and organize your AWS resources. Each tag consists of a key and an optional value. You specify the private CA on input by its Amazon Resource Name (ARN). You specify the tag by using a key-value pair. You can apply a tag to just one private CA if you want to identify a specific characteristic of that CA, or you can apply the same tag to multiple private CAs if you want to filter for a common relationship among those CAs. To remove one or more tags, use the UntagCertificateAuthority action. Call the ListTags action to see what tags are associated with your CA."},{"ref":"AWS.ACMPCA.html#untag_certificate_authority/3","title":"AWS.ACMPCA.untag_certificate_authority/3","type":"function","doc":"Remove one or more tags from your private CA. A tag consists of a key-value pair. If you do not specify the value portion of the tag when calling this action, the tag will be removed regardless of value. If you specify a value, the tag is removed only if it is associated with the specified value. To add tags to a private CA, use the TagCertificateAuthority. Call the ListTags action to see what tags are associated with your CA."},{"ref":"AWS.ACMPCA.html#update_certificate_authority/3","title":"AWS.ACMPCA.update_certificate_authority/3","type":"function","doc":"Updates the status or configuration of a private certificate authority (CA). Your private CA must be in the ACTIVE or DISABLED state before you can update it. You can disable a private CA that is in the ACTIVE state or make a CA that is in the DISABLED state active again. Both PCA and the IAM principal must have permission to write to the S3 bucket that you specify. If the IAM principal making the call does not have permission to write to the bucket, then an exception is thrown. For more information, see Configure Access to ACM Private CA."},{"ref":"AWS.API.Pricing.html","title":"AWS.API.Pricing","type":"module","doc":"AWS Price List Service API (AWS Price List Service) is a centralized and convenient way to programmatically query Amazon Web Services for services, products, and pricing information. The AWS Price List Service uses standardized product attributes such as Location, Storage Class, and Operating System, and provides prices at the SKU level. You can use the AWS Price List Service to build cost control and scenario planning tools, reconcile billing data, forecast future spend for budgeting purposes, and provide cost benefit analysis that compare your internal workloads with AWS. Use GetServices without a service code to retrieve the service codes for all AWS services, then GetServices with a service code to retreive the attribute names for that service. After you have the service code and attribute names, you can use GetAttributeValues to see what values are available for an attribute. With the service code and an attribute name and value, you can use GetProducts to find specific products that you&#39;re interested in, such as an AmazonEC2 instance, with a Provisioned IOPS volumeType. Service Endpoint AWS Price List Service API provides the following two endpoints: https://api.pricing.us-east-1.amazonaws.com https://api.pricing.ap-south-1.amazonaws.com"},{"ref":"AWS.API.Pricing.html#describe_services/3","title":"AWS.API.Pricing.describe_services/3","type":"function","doc":"Returns the metadata for one service or a list of the metadata for all services. Use this without a service code to get the service codes for all services. Use it with a service code, such as AmazonEC2, to get information specific to that service, such as the attribute names available for that service. For example, some of the attribute names available for EC2 are volumeType, maxIopsVolume, operation, locationType, and instanceCapacity10xlarge."},{"ref":"AWS.API.Pricing.html#get_attribute_values/3","title":"AWS.API.Pricing.get_attribute_values/3","type":"function","doc":"Returns a list of attribute values. Attibutes are similar to the details in a Price List API offer file. For a list of available attributes, see Offer File Definitions in the AWS Billing and Cost Management User Guide."},{"ref":"AWS.API.Pricing.html#get_products/3","title":"AWS.API.Pricing.get_products/3","type":"function","doc":"Returns a list of all products that match the filter criteria."},{"ref":"AWS.APIGateway.html","title":"AWS.APIGateway","type":"module","doc":"Amazon API Gateway Amazon API Gateway helps developers deliver robust, secure, and scalable mobile and web application back ends. API Gateway allows developers to securely connect mobile and web applications to APIs that run on AWS Lambda, Amazon EC2, or other publicly addressable web services that are hosted outside of AWS."},{"ref":"AWS.APIGateway.html#create_api_key/3","title":"AWS.APIGateway.create_api_key/3","type":"function","doc":"Create an ApiKey resource. See also: AWS CLI"},{"ref":"AWS.APIGateway.html#create_authorizer/4","title":"AWS.APIGateway.create_authorizer/4","type":"function","doc":"Adds a new Authorizer resource to an existing RestApi resource. See also: AWS CLI"},{"ref":"AWS.APIGateway.html#create_base_path_mapping/4","title":"AWS.APIGateway.create_base_path_mapping/4","type":"function","doc":"Creates a new BasePathMapping resource."},{"ref":"AWS.APIGateway.html#create_deployment/4","title":"AWS.APIGateway.create_deployment/4","type":"function","doc":"Creates a Deployment resource, which makes a specified RestApi callable over the internet."},{"ref":"AWS.APIGateway.html#create_documentation_part/4","title":"AWS.APIGateway.create_documentation_part/4","type":"function","doc":""},{"ref":"AWS.APIGateway.html#create_documentation_version/4","title":"AWS.APIGateway.create_documentation_version/4","type":"function","doc":""},{"ref":"AWS.APIGateway.html#create_domain_name/3","title":"AWS.APIGateway.create_domain_name/3","type":"function","doc":"Creates a new domain name."},{"ref":"AWS.APIGateway.html#create_model/4","title":"AWS.APIGateway.create_model/4","type":"function","doc":"Adds a new Model resource to an existing RestApi resource."},{"ref":"AWS.APIGateway.html#create_request_validator/4","title":"AWS.APIGateway.create_request_validator/4","type":"function","doc":"Creates a ReqeustValidator of a given RestApi."},{"ref":"AWS.APIGateway.html#create_resource/5","title":"AWS.APIGateway.create_resource/5","type":"function","doc":"Creates a Resource resource."},{"ref":"AWS.APIGateway.html#create_rest_api/3","title":"AWS.APIGateway.create_rest_api/3","type":"function","doc":"Creates a new RestApi resource."},{"ref":"AWS.APIGateway.html#create_stage/4","title":"AWS.APIGateway.create_stage/4","type":"function","doc":"Creates a new Stage resource that references a pre-existing Deployment for the API."},{"ref":"AWS.APIGateway.html#create_usage_plan/3","title":"AWS.APIGateway.create_usage_plan/3","type":"function","doc":"Creates a usage plan with the throttle and quota limits, as well as the associated API stages, specified in the payload."},{"ref":"AWS.APIGateway.html#create_usage_plan_key/4","title":"AWS.APIGateway.create_usage_plan_key/4","type":"function","doc":"Creates a usage plan key for adding an existing API key to a usage plan."},{"ref":"AWS.APIGateway.html#create_vpc_link/3","title":"AWS.APIGateway.create_vpc_link/3","type":"function","doc":"Creates a VPC link, under the caller&#39;s account in a selected region, in an asynchronous operation that typically takes 2-4 minutes to complete and become operational. The caller must have permissions to create and update VPC Endpoint services."},{"ref":"AWS.APIGateway.html#delete_api_key/4","title":"AWS.APIGateway.delete_api_key/4","type":"function","doc":"Deletes the ApiKey resource."},{"ref":"AWS.APIGateway.html#delete_authorizer/5","title":"AWS.APIGateway.delete_authorizer/5","type":"function","doc":"Deletes an existing Authorizer resource. See also: AWS CLI"},{"ref":"AWS.APIGateway.html#delete_base_path_mapping/5","title":"AWS.APIGateway.delete_base_path_mapping/5","type":"function","doc":"Deletes the BasePathMapping resource."},{"ref":"AWS.APIGateway.html#delete_client_certificate/4","title":"AWS.APIGateway.delete_client_certificate/4","type":"function","doc":"Deletes the ClientCertificate resource."},{"ref":"AWS.APIGateway.html#delete_deployment/5","title":"AWS.APIGateway.delete_deployment/5","type":"function","doc":"Deletes a Deployment resource. Deleting a deployment will only succeed if there are no Stage resources associated with it."},{"ref":"AWS.APIGateway.html#delete_documentation_part/5","title":"AWS.APIGateway.delete_documentation_part/5","type":"function","doc":""},{"ref":"AWS.APIGateway.html#delete_documentation_version/5","title":"AWS.APIGateway.delete_documentation_version/5","type":"function","doc":""},{"ref":"AWS.APIGateway.html#delete_domain_name/4","title":"AWS.APIGateway.delete_domain_name/4","type":"function","doc":"Deletes the DomainName resource."},{"ref":"AWS.APIGateway.html#delete_gateway_response/5","title":"AWS.APIGateway.delete_gateway_response/5","type":"function","doc":"Clears any customization of a GatewayResponse of a specified response type on the given RestApi and resets it with the default settings."},{"ref":"AWS.APIGateway.html#delete_integration/6","title":"AWS.APIGateway.delete_integration/6","type":"function","doc":"Represents a delete integration."},{"ref":"AWS.APIGateway.html#delete_integration_response/7","title":"AWS.APIGateway.delete_integration_response/7","type":"function","doc":"Represents a delete integration response."},{"ref":"AWS.APIGateway.html#delete_method/6","title":"AWS.APIGateway.delete_method/6","type":"function","doc":"Deletes an existing Method resource."},{"ref":"AWS.APIGateway.html#delete_method_response/7","title":"AWS.APIGateway.delete_method_response/7","type":"function","doc":"Deletes an existing MethodResponse resource."},{"ref":"AWS.APIGateway.html#delete_model/5","title":"AWS.APIGateway.delete_model/5","type":"function","doc":"Deletes a model."},{"ref":"AWS.APIGateway.html#delete_request_validator/5","title":"AWS.APIGateway.delete_request_validator/5","type":"function","doc":"Deletes a RequestValidator of a given RestApi."},{"ref":"AWS.APIGateway.html#delete_resource/5","title":"AWS.APIGateway.delete_resource/5","type":"function","doc":"Deletes a Resource resource."},{"ref":"AWS.APIGateway.html#delete_rest_api/4","title":"AWS.APIGateway.delete_rest_api/4","type":"function","doc":"Deletes the specified API."},{"ref":"AWS.APIGateway.html#delete_stage/5","title":"AWS.APIGateway.delete_stage/5","type":"function","doc":"Deletes a Stage resource."},{"ref":"AWS.APIGateway.html#delete_usage_plan/4","title":"AWS.APIGateway.delete_usage_plan/4","type":"function","doc":"Deletes a usage plan of a given plan Id."},{"ref":"AWS.APIGateway.html#delete_usage_plan_key/5","title":"AWS.APIGateway.delete_usage_plan_key/5","type":"function","doc":"Deletes a usage plan key and remove the underlying API key from the associated usage plan."},{"ref":"AWS.APIGateway.html#delete_vpc_link/4","title":"AWS.APIGateway.delete_vpc_link/4","type":"function","doc":"Deletes an existing VpcLink of a specified identifier."},{"ref":"AWS.APIGateway.html#flush_stage_authorizers_cache/5","title":"AWS.APIGateway.flush_stage_authorizers_cache/5","type":"function","doc":"Flushes all authorizer cache entries on a stage."},{"ref":"AWS.APIGateway.html#flush_stage_cache/5","title":"AWS.APIGateway.flush_stage_cache/5","type":"function","doc":"Flushes a stage&#39;s cache."},{"ref":"AWS.APIGateway.html#generate_client_certificate/3","title":"AWS.APIGateway.generate_client_certificate/3","type":"function","doc":"Generates a ClientCertificate resource."},{"ref":"AWS.APIGateway.html#get_account/2","title":"AWS.APIGateway.get_account/2","type":"function","doc":"Gets information about the current Account resource."},{"ref":"AWS.APIGateway.html#get_api_key/4","title":"AWS.APIGateway.get_api_key/4","type":"function","doc":"Gets information about the current ApiKey resource."},{"ref":"AWS.APIGateway.html#get_api_keys/7","title":"AWS.APIGateway.get_api_keys/7","type":"function","doc":"Gets information about the current ApiKeys resource."},{"ref":"AWS.APIGateway.html#get_authorizer/4","title":"AWS.APIGateway.get_authorizer/4","type":"function","doc":"Describe an existing Authorizer resource. See also: AWS CLI"},{"ref":"AWS.APIGateway.html#get_authorizers/5","title":"AWS.APIGateway.get_authorizers/5","type":"function","doc":"Describe an existing Authorizers resource. See also: AWS CLI"},{"ref":"AWS.APIGateway.html#get_base_path_mapping/4","title":"AWS.APIGateway.get_base_path_mapping/4","type":"function","doc":"Describe a BasePathMapping resource."},{"ref":"AWS.APIGateway.html#get_base_path_mappings/5","title":"AWS.APIGateway.get_base_path_mappings/5","type":"function","doc":"Represents a collection of BasePathMapping resources."},{"ref":"AWS.APIGateway.html#get_client_certificate/3","title":"AWS.APIGateway.get_client_certificate/3","type":"function","doc":"Gets information about the current ClientCertificate resource."},{"ref":"AWS.APIGateway.html#get_client_certificates/4","title":"AWS.APIGateway.get_client_certificates/4","type":"function","doc":"Gets a collection of ClientCertificate resources."},{"ref":"AWS.APIGateway.html#get_deployment/5","title":"AWS.APIGateway.get_deployment/5","type":"function","doc":"Gets information about a Deployment resource."},{"ref":"AWS.APIGateway.html#get_deployments/5","title":"AWS.APIGateway.get_deployments/5","type":"function","doc":"Gets information about a Deployments collection."},{"ref":"AWS.APIGateway.html#get_documentation_part/4","title":"AWS.APIGateway.get_documentation_part/4","type":"function","doc":""},{"ref":"AWS.APIGateway.html#get_documentation_parts/9","title":"AWS.APIGateway.get_documentation_parts/9","type":"function","doc":""},{"ref":"AWS.APIGateway.html#get_documentation_version/4","title":"AWS.APIGateway.get_documentation_version/4","type":"function","doc":""},{"ref":"AWS.APIGateway.html#get_documentation_versions/5","title":"AWS.APIGateway.get_documentation_versions/5","type":"function","doc":""},{"ref":"AWS.APIGateway.html#get_domain_name/3","title":"AWS.APIGateway.get_domain_name/3","type":"function","doc":"Represents a domain name that is contained in a simpler, more intuitive URL that can be called."},{"ref":"AWS.APIGateway.html#get_domain_names/4","title":"AWS.APIGateway.get_domain_names/4","type":"function","doc":"Represents a collection of DomainName resources."},{"ref":"AWS.APIGateway.html#get_export/7","title":"AWS.APIGateway.get_export/7","type":"function","doc":"Exports a deployed version of a RestApi in a specified format."},{"ref":"AWS.APIGateway.html#get_gateway_response/4","title":"AWS.APIGateway.get_gateway_response/4","type":"function","doc":"Gets a GatewayResponse of a specified response type on the given RestApi."},{"ref":"AWS.APIGateway.html#get_gateway_responses/5","title":"AWS.APIGateway.get_gateway_responses/5","type":"function","doc":"Gets the GatewayResponses collection on the given RestApi. If an API developer has not added any definitions for gateway responses, the result will be the API Gateway-generated default GatewayResponses collection for the supported response types."},{"ref":"AWS.APIGateway.html#get_integration/5","title":"AWS.APIGateway.get_integration/5","type":"function","doc":"Get the integration settings."},{"ref":"AWS.APIGateway.html#get_integration_response/6","title":"AWS.APIGateway.get_integration_response/6","type":"function","doc":"Represents a get integration response."},{"ref":"AWS.APIGateway.html#get_method/5","title":"AWS.APIGateway.get_method/5","type":"function","doc":"Describe an existing Method resource."},{"ref":"AWS.APIGateway.html#get_method_response/6","title":"AWS.APIGateway.get_method_response/6","type":"function","doc":"Describes a MethodResponse resource."},{"ref":"AWS.APIGateway.html#get_model/5","title":"AWS.APIGateway.get_model/5","type":"function","doc":"Describes an existing model defined for a RestApi resource."},{"ref":"AWS.APIGateway.html#get_model_template/4","title":"AWS.APIGateway.get_model_template/4","type":"function","doc":"Generates a sample mapping template that can be used to transform a payload into the structure of a model."},{"ref":"AWS.APIGateway.html#get_models/5","title":"AWS.APIGateway.get_models/5","type":"function","doc":"Describes existing Models defined for a RestApi resource."},{"ref":"AWS.APIGateway.html#get_request_validator/4","title":"AWS.APIGateway.get_request_validator/4","type":"function","doc":"Gets a RequestValidator of a given RestApi."},{"ref":"AWS.APIGateway.html#get_request_validators/5","title":"AWS.APIGateway.get_request_validators/5","type":"function","doc":"Gets the RequestValidators collection of a given RestApi."},{"ref":"AWS.APIGateway.html#get_resource/5","title":"AWS.APIGateway.get_resource/5","type":"function","doc":"Lists information about a resource."},{"ref":"AWS.APIGateway.html#get_resources/6","title":"AWS.APIGateway.get_resources/6","type":"function","doc":"Lists information about a collection of Resource resources."},{"ref":"AWS.APIGateway.html#get_rest_api/3","title":"AWS.APIGateway.get_rest_api/3","type":"function","doc":"Lists the RestApi resource in the collection."},{"ref":"AWS.APIGateway.html#get_rest_apis/4","title":"AWS.APIGateway.get_rest_apis/4","type":"function","doc":"Lists the RestApis resources for your collection."},{"ref":"AWS.APIGateway.html#get_sdk/6","title":"AWS.APIGateway.get_sdk/6","type":"function","doc":"Generates a client SDK for a RestApi and Stage."},{"ref":"AWS.APIGateway.html#get_sdk_type/3","title":"AWS.APIGateway.get_sdk_type/3","type":"function","doc":""},{"ref":"AWS.APIGateway.html#get_sdk_types/4","title":"AWS.APIGateway.get_sdk_types/4","type":"function","doc":""},{"ref":"AWS.APIGateway.html#get_stage/4","title":"AWS.APIGateway.get_stage/4","type":"function","doc":"Gets information about a Stage resource."},{"ref":"AWS.APIGateway.html#get_stages/4","title":"AWS.APIGateway.get_stages/4","type":"function","doc":"Gets information about one or more Stage resources."},{"ref":"AWS.APIGateway.html#get_tags/5","title":"AWS.APIGateway.get_tags/5","type":"function","doc":"Gets the Tags collection for a given resource."},{"ref":"AWS.APIGateway.html#get_usage/8","title":"AWS.APIGateway.get_usage/8","type":"function","doc":"Gets the usage data of a usage plan in a specified time interval."},{"ref":"AWS.APIGateway.html#get_usage_plan/3","title":"AWS.APIGateway.get_usage_plan/3","type":"function","doc":"Gets a usage plan of a given plan identifier."},{"ref":"AWS.APIGateway.html#get_usage_plan_key/4","title":"AWS.APIGateway.get_usage_plan_key/4","type":"function","doc":"Gets a usage plan key of a given key identifier."},{"ref":"AWS.APIGateway.html#get_usage_plan_keys/6","title":"AWS.APIGateway.get_usage_plan_keys/6","type":"function","doc":"Gets all the usage plan keys representing the API keys added to a specified usage plan."},{"ref":"AWS.APIGateway.html#get_usage_plans/5","title":"AWS.APIGateway.get_usage_plans/5","type":"function","doc":"Gets all the usage plans of the caller&#39;s account."},{"ref":"AWS.APIGateway.html#get_vpc_link/3","title":"AWS.APIGateway.get_vpc_link/3","type":"function","doc":"Gets a specified VPC link under the caller&#39;s account in a region."},{"ref":"AWS.APIGateway.html#get_vpc_links/4","title":"AWS.APIGateway.get_vpc_links/4","type":"function","doc":"Gets the VpcLinks collection under the caller&#39;s account in a selected region."},{"ref":"AWS.APIGateway.html#import_api_keys/3","title":"AWS.APIGateway.import_api_keys/3","type":"function","doc":"Import API keys from an external source, such as a CSV-formatted file."},{"ref":"AWS.APIGateway.html#import_documentation_parts/4","title":"AWS.APIGateway.import_documentation_parts/4","type":"function","doc":""},{"ref":"AWS.APIGateway.html#import_rest_api/3","title":"AWS.APIGateway.import_rest_api/3","type":"function","doc":"A feature of the API Gateway control service for creating a new API from an external API definition file."},{"ref":"AWS.APIGateway.html#put_gateway_response/5","title":"AWS.APIGateway.put_gateway_response/5","type":"function","doc":"Creates a customization of a GatewayResponse of a specified response type and status code on the given RestApi."},{"ref":"AWS.APIGateway.html#put_integration/6","title":"AWS.APIGateway.put_integration/6","type":"function","doc":"Sets up a method&#39;s integration."},{"ref":"AWS.APIGateway.html#put_integration_response/7","title":"AWS.APIGateway.put_integration_response/7","type":"function","doc":"Represents a put integration."},{"ref":"AWS.APIGateway.html#put_method/6","title":"AWS.APIGateway.put_method/6","type":"function","doc":"Add a method to an existing Resource resource."},{"ref":"AWS.APIGateway.html#put_method_response/7","title":"AWS.APIGateway.put_method_response/7","type":"function","doc":"Adds a MethodResponse to an existing Method resource."},{"ref":"AWS.APIGateway.html#put_rest_api/4","title":"AWS.APIGateway.put_rest_api/4","type":"function","doc":"A feature of the API Gateway control service for updating an existing API with an input of external API definitions. The update can take the form of merging the supplied definition into the existing API or overwriting the existing API."},{"ref":"AWS.APIGateway.html#tag_resource/4","title":"AWS.APIGateway.tag_resource/4","type":"function","doc":"Adds or updates a tag on a given resource."},{"ref":"AWS.APIGateway.html#test_invoke_authorizer/5","title":"AWS.APIGateway.test_invoke_authorizer/5","type":"function","doc":"Simulate the execution of an Authorizer in your RestApi with headers, parameters, and an incoming request body. See also: Use Lambda Function as Authorizer Use Cognito User Pool as Authorizer"},{"ref":"AWS.APIGateway.html#test_invoke_method/6","title":"AWS.APIGateway.test_invoke_method/6","type":"function","doc":"Simulate the execution of a Method in your RestApi with headers, parameters, and an incoming request body."},{"ref":"AWS.APIGateway.html#untag_resource/4","title":"AWS.APIGateway.untag_resource/4","type":"function","doc":"Removes a tag from a given resource."},{"ref":"AWS.APIGateway.html#update_account/3","title":"AWS.APIGateway.update_account/3","type":"function","doc":"Changes information about the current Account resource."},{"ref":"AWS.APIGateway.html#update_api_key/4","title":"AWS.APIGateway.update_api_key/4","type":"function","doc":"Changes information about an ApiKey resource."},{"ref":"AWS.APIGateway.html#update_authorizer/5","title":"AWS.APIGateway.update_authorizer/5","type":"function","doc":"Updates an existing Authorizer resource. See also: AWS CLI"},{"ref":"AWS.APIGateway.html#update_base_path_mapping/5","title":"AWS.APIGateway.update_base_path_mapping/5","type":"function","doc":"Changes information about the BasePathMapping resource."},{"ref":"AWS.APIGateway.html#update_client_certificate/4","title":"AWS.APIGateway.update_client_certificate/4","type":"function","doc":"Changes information about an ClientCertificate resource."},{"ref":"AWS.APIGateway.html#update_deployment/5","title":"AWS.APIGateway.update_deployment/5","type":"function","doc":"Changes information about a Deployment resource."},{"ref":"AWS.APIGateway.html#update_documentation_part/5","title":"AWS.APIGateway.update_documentation_part/5","type":"function","doc":""},{"ref":"AWS.APIGateway.html#update_documentation_version/5","title":"AWS.APIGateway.update_documentation_version/5","type":"function","doc":""},{"ref":"AWS.APIGateway.html#update_domain_name/4","title":"AWS.APIGateway.update_domain_name/4","type":"function","doc":"Changes information about the DomainName resource."},{"ref":"AWS.APIGateway.html#update_gateway_response/5","title":"AWS.APIGateway.update_gateway_response/5","type":"function","doc":"Updates a GatewayResponse of a specified response type on the given RestApi."},{"ref":"AWS.APIGateway.html#update_integration/6","title":"AWS.APIGateway.update_integration/6","type":"function","doc":"Represents an update integration."},{"ref":"AWS.APIGateway.html#update_integration_response/7","title":"AWS.APIGateway.update_integration_response/7","type":"function","doc":"Represents an update integration response."},{"ref":"AWS.APIGateway.html#update_method/6","title":"AWS.APIGateway.update_method/6","type":"function","doc":"Updates an existing Method resource."},{"ref":"AWS.APIGateway.html#update_method_response/7","title":"AWS.APIGateway.update_method_response/7","type":"function","doc":"Updates an existing MethodResponse resource."},{"ref":"AWS.APIGateway.html#update_model/5","title":"AWS.APIGateway.update_model/5","type":"function","doc":"Changes information about a model."},{"ref":"AWS.APIGateway.html#update_request_validator/5","title":"AWS.APIGateway.update_request_validator/5","type":"function","doc":"Updates a RequestValidator of a given RestApi."},{"ref":"AWS.APIGateway.html#update_resource/5","title":"AWS.APIGateway.update_resource/5","type":"function","doc":"Changes information about a Resource resource."},{"ref":"AWS.APIGateway.html#update_rest_api/4","title":"AWS.APIGateway.update_rest_api/4","type":"function","doc":"Changes information about the specified API."},{"ref":"AWS.APIGateway.html#update_stage/5","title":"AWS.APIGateway.update_stage/5","type":"function","doc":"Changes information about a Stage resource."},{"ref":"AWS.APIGateway.html#update_usage/5","title":"AWS.APIGateway.update_usage/5","type":"function","doc":"Grants a temporary extension to the remaining quota of a usage plan associated with a specified API key."},{"ref":"AWS.APIGateway.html#update_usage_plan/4","title":"AWS.APIGateway.update_usage_plan/4","type":"function","doc":"Updates a usage plan of a given plan Id."},{"ref":"AWS.APIGateway.html#update_vpc_link/4","title":"AWS.APIGateway.update_vpc_link/4","type":"function","doc":"Updates an existing VpcLink of a specified identifier."},{"ref":"AWS.AccessAnalyzer.html","title":"AWS.AccessAnalyzer","type":"module","doc":"AWS IAM Access Analyzer helps identify potential resource-access risks by enabling you to identify any policies that grant access to an external principal. It does this by using logic-based reasoning to analyze resource-based policies in your AWS environment. An external principal can be another AWS account, a root user, an IAM user or role, a federated user, an AWS service, or an anonymous user. This guide describes the AWS IAM Access Analyzer operations that you can call programmatically. For general information about Access Analyzer, see the AWS IAM Access Analyzer section of the IAM User Guide. To start using Access Analyzer, you first need to create an analyzer."},{"ref":"AWS.AccessAnalyzer.html#create_analyzer/3","title":"AWS.AccessAnalyzer.create_analyzer/3","type":"function","doc":"Creates an analyzer for your account."},{"ref":"AWS.AccessAnalyzer.html#create_archive_rule/4","title":"AWS.AccessAnalyzer.create_archive_rule/4","type":"function","doc":"Creates an archive rule for the specified analyzer. Archive rules automatically archive findings that meet the criteria you define when you create the rule."},{"ref":"AWS.AccessAnalyzer.html#delete_analyzer/4","title":"AWS.AccessAnalyzer.delete_analyzer/4","type":"function","doc":"Deletes the specified analyzer. When you delete an analyzer, Access Analyzer is disabled for the account in the current or specific Region. All findings that were generated by the analyzer are deleted. You cannot undo this action."},{"ref":"AWS.AccessAnalyzer.html#delete_archive_rule/5","title":"AWS.AccessAnalyzer.delete_archive_rule/5","type":"function","doc":"Deletes the specified archive rule."},{"ref":"AWS.AccessAnalyzer.html#get_analyzed_resource/4","title":"AWS.AccessAnalyzer.get_analyzed_resource/4","type":"function","doc":"Retrieves information about a resource that was analyzed."},{"ref":"AWS.AccessAnalyzer.html#get_analyzer/3","title":"AWS.AccessAnalyzer.get_analyzer/3","type":"function","doc":"Retrieves information about the specified analyzer."},{"ref":"AWS.AccessAnalyzer.html#get_archive_rule/4","title":"AWS.AccessAnalyzer.get_archive_rule/4","type":"function","doc":"Retrieves information about an archive rule."},{"ref":"AWS.AccessAnalyzer.html#get_finding/4","title":"AWS.AccessAnalyzer.get_finding/4","type":"function","doc":"Retrieves information about the specified finding."},{"ref":"AWS.AccessAnalyzer.html#list_analyzed_resources/3","title":"AWS.AccessAnalyzer.list_analyzed_resources/3","type":"function","doc":"Retrieves a list of resources of the specified type that have been analyzed by the specified analyzer.."},{"ref":"AWS.AccessAnalyzer.html#list_analyzers/5","title":"AWS.AccessAnalyzer.list_analyzers/5","type":"function","doc":"Retrieves a list of analyzers."},{"ref":"AWS.AccessAnalyzer.html#list_archive_rules/5","title":"AWS.AccessAnalyzer.list_archive_rules/5","type":"function","doc":"Retrieves a list of archive rules created for the specified analyzer."},{"ref":"AWS.AccessAnalyzer.html#list_findings/3","title":"AWS.AccessAnalyzer.list_findings/3","type":"function","doc":"Retrieves a list of findings generated by the specified analyzer."},{"ref":"AWS.AccessAnalyzer.html#list_tags_for_resource/3","title":"AWS.AccessAnalyzer.list_tags_for_resource/3","type":"function","doc":"Retrieves a list of tags applied to the specified resource."},{"ref":"AWS.AccessAnalyzer.html#start_resource_scan/3","title":"AWS.AccessAnalyzer.start_resource_scan/3","type":"function","doc":"Immediately starts a scan of the policies applied to the specified resource."},{"ref":"AWS.AccessAnalyzer.html#tag_resource/4","title":"AWS.AccessAnalyzer.tag_resource/4","type":"function","doc":"Adds a tag to the specified resource."},{"ref":"AWS.AccessAnalyzer.html#untag_resource/4","title":"AWS.AccessAnalyzer.untag_resource/4","type":"function","doc":"Removes a tag from the specified resource."},{"ref":"AWS.AccessAnalyzer.html#update_archive_rule/5","title":"AWS.AccessAnalyzer.update_archive_rule/5","type":"function","doc":"Updates the criteria and values for the specified archive rule."},{"ref":"AWS.AccessAnalyzer.html#update_findings/3","title":"AWS.AccessAnalyzer.update_findings/3","type":"function","doc":"Updates the status for the specified findings."},{"ref":"AWS.AlexaForBusiness.html","title":"AWS.AlexaForBusiness","type":"module","doc":"Alexa for Business helps you use Alexa in your organization. Alexa for Business provides you with the tools to manage Alexa devices, enroll your users, and assign skills, at scale. You can build your own context-aware voice skills using the Alexa Skills Kit and the Alexa for Business API operations. You can also make these available as private skills for your organization. Alexa for Business makes it efficient to voice-enable your products and services, thus providing context-aware voice experiences for your customers. Device makers building with the Alexa Voice Service (AVS) can create fully integrated solutions, register their products with Alexa for Business, and manage them as shared devices in their organization."},{"ref":"AWS.AlexaForBusiness.html#approve_skill/3","title":"AWS.AlexaForBusiness.approve_skill/3","type":"function","doc":"Associates a skill with the organization under the customer&#39;s AWS account. If a skill is private, the user implicitly accepts access to this skill during enablement."},{"ref":"AWS.AlexaForBusiness.html#associate_contact_with_address_book/3","title":"AWS.AlexaForBusiness.associate_contact_with_address_book/3","type":"function","doc":"Associates a contact with a given address book."},{"ref":"AWS.AlexaForBusiness.html#associate_device_with_network_profile/3","title":"AWS.AlexaForBusiness.associate_device_with_network_profile/3","type":"function","doc":"Associates a device with the specified network profile."},{"ref":"AWS.AlexaForBusiness.html#associate_device_with_room/3","title":"AWS.AlexaForBusiness.associate_device_with_room/3","type":"function","doc":"Associates a device with a given room. This applies all the settings from the room profile to the device, and all the skills in any skill groups added to that room. This operation requires the device to be online, or else a manual sync is required."},{"ref":"AWS.AlexaForBusiness.html#associate_skill_group_with_room/3","title":"AWS.AlexaForBusiness.associate_skill_group_with_room/3","type":"function","doc":"Associates a skill group with a given room. This enables all skills in the associated skill group on all devices in the room."},{"ref":"AWS.AlexaForBusiness.html#associate_skill_with_skill_group/3","title":"AWS.AlexaForBusiness.associate_skill_with_skill_group/3","type":"function","doc":"Associates a skill with a skill group."},{"ref":"AWS.AlexaForBusiness.html#associate_skill_with_users/3","title":"AWS.AlexaForBusiness.associate_skill_with_users/3","type":"function","doc":"Makes a private skill available for enrolled users to enable on their devices."},{"ref":"AWS.AlexaForBusiness.html#create_address_book/3","title":"AWS.AlexaForBusiness.create_address_book/3","type":"function","doc":"Creates an address book with the specified details."},{"ref":"AWS.AlexaForBusiness.html#create_business_report_schedule/3","title":"AWS.AlexaForBusiness.create_business_report_schedule/3","type":"function","doc":"Creates a recurring schedule for usage reports to deliver to the specified S3 location with a specified daily or weekly interval."},{"ref":"AWS.AlexaForBusiness.html#create_conference_provider/3","title":"AWS.AlexaForBusiness.create_conference_provider/3","type":"function","doc":"Adds a new conference provider under the user&#39;s AWS account."},{"ref":"AWS.AlexaForBusiness.html#create_contact/3","title":"AWS.AlexaForBusiness.create_contact/3","type":"function","doc":"Creates a contact with the specified details."},{"ref":"AWS.AlexaForBusiness.html#create_gateway_group/3","title":"AWS.AlexaForBusiness.create_gateway_group/3","type":"function","doc":"Creates a gateway group with the specified details."},{"ref":"AWS.AlexaForBusiness.html#create_network_profile/3","title":"AWS.AlexaForBusiness.create_network_profile/3","type":"function","doc":"Creates a network profile with the specified details."},{"ref":"AWS.AlexaForBusiness.html#create_profile/3","title":"AWS.AlexaForBusiness.create_profile/3","type":"function","doc":"Creates a new room profile with the specified details."},{"ref":"AWS.AlexaForBusiness.html#create_room/3","title":"AWS.AlexaForBusiness.create_room/3","type":"function","doc":"Creates a room with the specified details."},{"ref":"AWS.AlexaForBusiness.html#create_skill_group/3","title":"AWS.AlexaForBusiness.create_skill_group/3","type":"function","doc":"Creates a skill group with a specified name and description."},{"ref":"AWS.AlexaForBusiness.html#create_user/3","title":"AWS.AlexaForBusiness.create_user/3","type":"function","doc":"Creates a user."},{"ref":"AWS.AlexaForBusiness.html#delete_address_book/3","title":"AWS.AlexaForBusiness.delete_address_book/3","type":"function","doc":"Deletes an address book by the address book ARN."},{"ref":"AWS.AlexaForBusiness.html#delete_business_report_schedule/3","title":"AWS.AlexaForBusiness.delete_business_report_schedule/3","type":"function","doc":"Deletes the recurring report delivery schedule with the specified schedule ARN."},{"ref":"AWS.AlexaForBusiness.html#delete_conference_provider/3","title":"AWS.AlexaForBusiness.delete_conference_provider/3","type":"function","doc":"Deletes a conference provider."},{"ref":"AWS.AlexaForBusiness.html#delete_contact/3","title":"AWS.AlexaForBusiness.delete_contact/3","type":"function","doc":"Deletes a contact by the contact ARN."},{"ref":"AWS.AlexaForBusiness.html#delete_device/3","title":"AWS.AlexaForBusiness.delete_device/3","type":"function","doc":"Removes a device from Alexa For Business."},{"ref":"AWS.AlexaForBusiness.html#delete_device_usage_data/3","title":"AWS.AlexaForBusiness.delete_device_usage_data/3","type":"function","doc":"When this action is called for a specified shared device, it allows authorized users to delete the device&#39;s entire previous history of voice input data and associated response data. This action can be called once every 24 hours for a specific shared device."},{"ref":"AWS.AlexaForBusiness.html#delete_gateway_group/3","title":"AWS.AlexaForBusiness.delete_gateway_group/3","type":"function","doc":"Deletes a gateway group."},{"ref":"AWS.AlexaForBusiness.html#delete_network_profile/3","title":"AWS.AlexaForBusiness.delete_network_profile/3","type":"function","doc":"Deletes a network profile by the network profile ARN."},{"ref":"AWS.AlexaForBusiness.html#delete_profile/3","title":"AWS.AlexaForBusiness.delete_profile/3","type":"function","doc":"Deletes a room profile by the profile ARN."},{"ref":"AWS.AlexaForBusiness.html#delete_room/3","title":"AWS.AlexaForBusiness.delete_room/3","type":"function","doc":"Deletes a room by the room ARN."},{"ref":"AWS.AlexaForBusiness.html#delete_room_skill_parameter/3","title":"AWS.AlexaForBusiness.delete_room_skill_parameter/3","type":"function","doc":"Deletes room skill parameter details by room, skill, and parameter key ID."},{"ref":"AWS.AlexaForBusiness.html#delete_skill_authorization/3","title":"AWS.AlexaForBusiness.delete_skill_authorization/3","type":"function","doc":"Unlinks a third-party account from a skill."},{"ref":"AWS.AlexaForBusiness.html#delete_skill_group/3","title":"AWS.AlexaForBusiness.delete_skill_group/3","type":"function","doc":"Deletes a skill group by skill group ARN."},{"ref":"AWS.AlexaForBusiness.html#delete_user/3","title":"AWS.AlexaForBusiness.delete_user/3","type":"function","doc":"Deletes a specified user by user ARN and enrollment ARN."},{"ref":"AWS.AlexaForBusiness.html#disassociate_contact_from_address_book/3","title":"AWS.AlexaForBusiness.disassociate_contact_from_address_book/3","type":"function","doc":"Disassociates a contact from a given address book."},{"ref":"AWS.AlexaForBusiness.html#disassociate_device_from_room/3","title":"AWS.AlexaForBusiness.disassociate_device_from_room/3","type":"function","doc":"Disassociates a device from its current room. The device continues to be connected to the Wi-Fi network and is still registered to the account. The device settings and skills are removed from the room."},{"ref":"AWS.AlexaForBusiness.html#disassociate_skill_from_skill_group/3","title":"AWS.AlexaForBusiness.disassociate_skill_from_skill_group/3","type":"function","doc":"Disassociates a skill from a skill group."},{"ref":"AWS.AlexaForBusiness.html#disassociate_skill_from_users/3","title":"AWS.AlexaForBusiness.disassociate_skill_from_users/3","type":"function","doc":"Makes a private skill unavailable for enrolled users and prevents them from enabling it on their devices."},{"ref":"AWS.AlexaForBusiness.html#disassociate_skill_group_from_room/3","title":"AWS.AlexaForBusiness.disassociate_skill_group_from_room/3","type":"function","doc":"Disassociates a skill group from a specified room. This disables all skills in the skill group on all devices in the room."},{"ref":"AWS.AlexaForBusiness.html#forget_smart_home_appliances/3","title":"AWS.AlexaForBusiness.forget_smart_home_appliances/3","type":"function","doc":"Forgets smart home appliances associated to a room."},{"ref":"AWS.AlexaForBusiness.html#get_address_book/3","title":"AWS.AlexaForBusiness.get_address_book/3","type":"function","doc":"Gets address the book details by the address book ARN."},{"ref":"AWS.AlexaForBusiness.html#get_conference_preference/3","title":"AWS.AlexaForBusiness.get_conference_preference/3","type":"function","doc":"Retrieves the existing conference preferences."},{"ref":"AWS.AlexaForBusiness.html#get_conference_provider/3","title":"AWS.AlexaForBusiness.get_conference_provider/3","type":"function","doc":"Gets details about a specific conference provider."},{"ref":"AWS.AlexaForBusiness.html#get_contact/3","title":"AWS.AlexaForBusiness.get_contact/3","type":"function","doc":"Gets the contact details by the contact ARN."},{"ref":"AWS.AlexaForBusiness.html#get_device/3","title":"AWS.AlexaForBusiness.get_device/3","type":"function","doc":"Gets the details of a device by device ARN."},{"ref":"AWS.AlexaForBusiness.html#get_gateway/3","title":"AWS.AlexaForBusiness.get_gateway/3","type":"function","doc":"Retrieves the details of a gateway."},{"ref":"AWS.AlexaForBusiness.html#get_gateway_group/3","title":"AWS.AlexaForBusiness.get_gateway_group/3","type":"function","doc":"Retrieves the details of a gateway group."},{"ref":"AWS.AlexaForBusiness.html#get_invitation_configuration/3","title":"AWS.AlexaForBusiness.get_invitation_configuration/3","type":"function","doc":"Retrieves the configured values for the user enrollment invitation email template."},{"ref":"AWS.AlexaForBusiness.html#get_network_profile/3","title":"AWS.AlexaForBusiness.get_network_profile/3","type":"function","doc":"Gets the network profile details by the network profile ARN."},{"ref":"AWS.AlexaForBusiness.html#get_profile/3","title":"AWS.AlexaForBusiness.get_profile/3","type":"function","doc":"Gets the details of a room profile by profile ARN."},{"ref":"AWS.AlexaForBusiness.html#get_room/3","title":"AWS.AlexaForBusiness.get_room/3","type":"function","doc":"Gets room details by room ARN."},{"ref":"AWS.AlexaForBusiness.html#get_room_skill_parameter/3","title":"AWS.AlexaForBusiness.get_room_skill_parameter/3","type":"function","doc":"Gets room skill parameter details by room, skill, and parameter key ARN."},{"ref":"AWS.AlexaForBusiness.html#get_skill_group/3","title":"AWS.AlexaForBusiness.get_skill_group/3","type":"function","doc":"Gets skill group details by skill group ARN."},{"ref":"AWS.AlexaForBusiness.html#list_business_report_schedules/3","title":"AWS.AlexaForBusiness.list_business_report_schedules/3","type":"function","doc":"Lists the details of the schedules that a user configured. A download URL of the report associated with each schedule is returned every time this action is called. A new download URL is returned each time, and is valid for 24 hours."},{"ref":"AWS.AlexaForBusiness.html#list_conference_providers/3","title":"AWS.AlexaForBusiness.list_conference_providers/3","type":"function","doc":"Lists conference providers under a specific AWS account."},{"ref":"AWS.AlexaForBusiness.html#list_device_events/3","title":"AWS.AlexaForBusiness.list_device_events/3","type":"function","doc":"Lists the device event history, including device connection status, for up to 30 days."},{"ref":"AWS.AlexaForBusiness.html#list_gateway_groups/3","title":"AWS.AlexaForBusiness.list_gateway_groups/3","type":"function","doc":"Retrieves a list of gateway group summaries. Use GetGatewayGroup to retrieve details of a specific gateway group."},{"ref":"AWS.AlexaForBusiness.html#list_gateways/3","title":"AWS.AlexaForBusiness.list_gateways/3","type":"function","doc":"Retrieves a list of gateway summaries. Use GetGateway to retrieve details of a specific gateway. An optional gateway group ARN can be provided to only retrieve gateway summaries of gateways that are associated with that gateway group ARN."},{"ref":"AWS.AlexaForBusiness.html#list_skills/3","title":"AWS.AlexaForBusiness.list_skills/3","type":"function","doc":"Lists all enabled skills in a specific skill group."},{"ref":"AWS.AlexaForBusiness.html#list_skills_store_categories/3","title":"AWS.AlexaForBusiness.list_skills_store_categories/3","type":"function","doc":"Lists all categories in the Alexa skill store."},{"ref":"AWS.AlexaForBusiness.html#list_skills_store_skills_by_category/3","title":"AWS.AlexaForBusiness.list_skills_store_skills_by_category/3","type":"function","doc":"Lists all skills in the Alexa skill store by category."},{"ref":"AWS.AlexaForBusiness.html#list_smart_home_appliances/3","title":"AWS.AlexaForBusiness.list_smart_home_appliances/3","type":"function","doc":"Lists all of the smart home appliances associated with a room."},{"ref":"AWS.AlexaForBusiness.html#list_tags/3","title":"AWS.AlexaForBusiness.list_tags/3","type":"function","doc":"Lists all tags for the specified resource."},{"ref":"AWS.AlexaForBusiness.html#put_conference_preference/3","title":"AWS.AlexaForBusiness.put_conference_preference/3","type":"function","doc":"Sets the conference preferences on a specific conference provider at the account level."},{"ref":"AWS.AlexaForBusiness.html#put_invitation_configuration/3","title":"AWS.AlexaForBusiness.put_invitation_configuration/3","type":"function","doc":"Configures the email template for the user enrollment invitation with the specified attributes."},{"ref":"AWS.AlexaForBusiness.html#put_room_skill_parameter/3","title":"AWS.AlexaForBusiness.put_room_skill_parameter/3","type":"function","doc":"Updates room skill parameter details by room, skill, and parameter key ID. Not all skills have a room skill parameter."},{"ref":"AWS.AlexaForBusiness.html#put_skill_authorization/3","title":"AWS.AlexaForBusiness.put_skill_authorization/3","type":"function","doc":"Links a user&#39;s account to a third-party skill provider. If this API operation is called by an assumed IAM role, the skill being linked must be a private skill. Also, the skill must be owned by the AWS account that assumed the IAM role."},{"ref":"AWS.AlexaForBusiness.html#register_a_v_s_device/3","title":"AWS.AlexaForBusiness.register_a_v_s_device/3","type":"function","doc":"Registers an Alexa-enabled device built by an Original Equipment Manufacturer (OEM) using Alexa Voice Service (AVS)."},{"ref":"AWS.AlexaForBusiness.html#reject_skill/3","title":"AWS.AlexaForBusiness.reject_skill/3","type":"function","doc":"Disassociates a skill from the organization under a user&#39;s AWS account. If the skill is a private skill, it moves to an AcceptStatus of PENDING. Any private or public skill that is rejected can be added later by calling the ApproveSkill API."},{"ref":"AWS.AlexaForBusiness.html#resolve_room/3","title":"AWS.AlexaForBusiness.resolve_room/3","type":"function","doc":"Determines the details for the room from which a skill request was invoked. This operation is used by skill developers."},{"ref":"AWS.AlexaForBusiness.html#revoke_invitation/3","title":"AWS.AlexaForBusiness.revoke_invitation/3","type":"function","doc":"Revokes an invitation and invalidates the enrollment URL."},{"ref":"AWS.AlexaForBusiness.html#search_address_books/3","title":"AWS.AlexaForBusiness.search_address_books/3","type":"function","doc":"Searches address books and lists the ones that meet a set of filter and sort criteria."},{"ref":"AWS.AlexaForBusiness.html#search_contacts/3","title":"AWS.AlexaForBusiness.search_contacts/3","type":"function","doc":"Searches contacts and lists the ones that meet a set of filter and sort criteria."},{"ref":"AWS.AlexaForBusiness.html#search_devices/3","title":"AWS.AlexaForBusiness.search_devices/3","type":"function","doc":"Searches devices and lists the ones that meet a set of filter criteria."},{"ref":"AWS.AlexaForBusiness.html#search_network_profiles/3","title":"AWS.AlexaForBusiness.search_network_profiles/3","type":"function","doc":"Searches network profiles and lists the ones that meet a set of filter and sort criteria."},{"ref":"AWS.AlexaForBusiness.html#search_profiles/3","title":"AWS.AlexaForBusiness.search_profiles/3","type":"function","doc":"Searches room profiles and lists the ones that meet a set of filter criteria."},{"ref":"AWS.AlexaForBusiness.html#search_rooms/3","title":"AWS.AlexaForBusiness.search_rooms/3","type":"function","doc":"Searches rooms and lists the ones that meet a set of filter and sort criteria."},{"ref":"AWS.AlexaForBusiness.html#search_skill_groups/3","title":"AWS.AlexaForBusiness.search_skill_groups/3","type":"function","doc":"Searches skill groups and lists the ones that meet a set of filter and sort criteria."},{"ref":"AWS.AlexaForBusiness.html#search_users/3","title":"AWS.AlexaForBusiness.search_users/3","type":"function","doc":"Searches users and lists the ones that meet a set of filter and sort criteria."},{"ref":"AWS.AlexaForBusiness.html#send_announcement/3","title":"AWS.AlexaForBusiness.send_announcement/3","type":"function","doc":"Triggers an asynchronous flow to send text, SSML, or audio announcements to rooms that are identified by a search or filter."},{"ref":"AWS.AlexaForBusiness.html#send_invitation/3","title":"AWS.AlexaForBusiness.send_invitation/3","type":"function","doc":"Sends an enrollment invitation email with a URL to a user. The URL is valid for 30 days or until you call this operation again, whichever comes first."},{"ref":"AWS.AlexaForBusiness.html#start_device_sync/3","title":"AWS.AlexaForBusiness.start_device_sync/3","type":"function","doc":"Resets a device and its account to the known default settings. This clears all information and settings set by previous users in the following ways: Bluetooth - This unpairs all bluetooth devices paired with your echo device. Volume - This resets the echo device&#39;s volume to the default value. Notifications - This clears all notifications from your echo device. Lists - This clears all to-do items from your echo device. Settings - This internally syncs the room&#39;s profile (if the device is assigned to a room), contacts, address books, delegation access for account linking, and communications (if enabled on the room profile)."},{"ref":"AWS.AlexaForBusiness.html#start_smart_home_appliance_discovery/3","title":"AWS.AlexaForBusiness.start_smart_home_appliance_discovery/3","type":"function","doc":"Initiates the discovery of any smart home appliances associated with the room."},{"ref":"AWS.AlexaForBusiness.html#tag_resource/3","title":"AWS.AlexaForBusiness.tag_resource/3","type":"function","doc":"Adds metadata tags to a specified resource."},{"ref":"AWS.AlexaForBusiness.html#untag_resource/3","title":"AWS.AlexaForBusiness.untag_resource/3","type":"function","doc":"Removes metadata tags from a specified resource."},{"ref":"AWS.AlexaForBusiness.html#update_address_book/3","title":"AWS.AlexaForBusiness.update_address_book/3","type":"function","doc":"Updates address book details by the address book ARN."},{"ref":"AWS.AlexaForBusiness.html#update_business_report_schedule/3","title":"AWS.AlexaForBusiness.update_business_report_schedule/3","type":"function","doc":"Updates the configuration of the report delivery schedule with the specified schedule ARN."},{"ref":"AWS.AlexaForBusiness.html#update_conference_provider/3","title":"AWS.AlexaForBusiness.update_conference_provider/3","type":"function","doc":"Updates an existing conference provider&#39;s settings."},{"ref":"AWS.AlexaForBusiness.html#update_contact/3","title":"AWS.AlexaForBusiness.update_contact/3","type":"function","doc":"Updates the contact details by the contact ARN."},{"ref":"AWS.AlexaForBusiness.html#update_device/3","title":"AWS.AlexaForBusiness.update_device/3","type":"function","doc":"Updates the device name by device ARN."},{"ref":"AWS.AlexaForBusiness.html#update_gateway/3","title":"AWS.AlexaForBusiness.update_gateway/3","type":"function","doc":"Updates the details of a gateway. If any optional field is not provided, the existing corresponding value is left unmodified."},{"ref":"AWS.AlexaForBusiness.html#update_gateway_group/3","title":"AWS.AlexaForBusiness.update_gateway_group/3","type":"function","doc":"Updates the details of a gateway group. If any optional field is not provided, the existing corresponding value is left unmodified."},{"ref":"AWS.AlexaForBusiness.html#update_network_profile/3","title":"AWS.AlexaForBusiness.update_network_profile/3","type":"function","doc":"Updates a network profile by the network profile ARN."},{"ref":"AWS.AlexaForBusiness.html#update_profile/3","title":"AWS.AlexaForBusiness.update_profile/3","type":"function","doc":"Updates an existing room profile by room profile ARN."},{"ref":"AWS.AlexaForBusiness.html#update_room/3","title":"AWS.AlexaForBusiness.update_room/3","type":"function","doc":"Updates room details by room ARN."},{"ref":"AWS.AlexaForBusiness.html#update_skill_group/3","title":"AWS.AlexaForBusiness.update_skill_group/3","type":"function","doc":"Updates skill group details by skill group ARN."},{"ref":"AWS.Amplify.html","title":"AWS.Amplify","type":"module","doc":"Amplify enables developers to develop and deploy cloud-powered mobile and web apps. The Amplify Console provides a continuous delivery and hosting service for web applications. For more information, see the Amplify Console User Guide. The Amplify Framework is a comprehensive set of SDKs, libraries, tools, and documentation for client app development. For more information, see the Amplify Framework."},{"ref":"AWS.Amplify.html#create_app/3","title":"AWS.Amplify.create_app/3","type":"function","doc":"Creates a new Amplify app."},{"ref":"AWS.Amplify.html#create_backend_environment/4","title":"AWS.Amplify.create_backend_environment/4","type":"function","doc":"Creates a new backend environment for an Amplify app."},{"ref":"AWS.Amplify.html#create_branch/4","title":"AWS.Amplify.create_branch/4","type":"function","doc":"Creates a new branch for an Amplify app."},{"ref":"AWS.Amplify.html#create_deployment/5","title":"AWS.Amplify.create_deployment/5","type":"function","doc":"Creates a deployment for a manually deployed Amplify app. Manually deployed apps are not connected to a repository."},{"ref":"AWS.Amplify.html#create_domain_association/4","title":"AWS.Amplify.create_domain_association/4","type":"function","doc":"Creates a new domain association for an Amplify app. This action associates a custom domain with the Amplify app"},{"ref":"AWS.Amplify.html#create_webhook/4","title":"AWS.Amplify.create_webhook/4","type":"function","doc":"Creates a new webhook on an Amplify app."},{"ref":"AWS.Amplify.html#delete_app/4","title":"AWS.Amplify.delete_app/4","type":"function","doc":"Deletes an existing Amplify app specified by an app ID."},{"ref":"AWS.Amplify.html#delete_backend_environment/5","title":"AWS.Amplify.delete_backend_environment/5","type":"function","doc":"Deletes a backend environment for an Amplify app."},{"ref":"AWS.Amplify.html#delete_branch/5","title":"AWS.Amplify.delete_branch/5","type":"function","doc":"Deletes a branch for an Amplify app."},{"ref":"AWS.Amplify.html#delete_domain_association/5","title":"AWS.Amplify.delete_domain_association/5","type":"function","doc":"Deletes a domain association for an Amplify app."},{"ref":"AWS.Amplify.html#delete_job/6","title":"AWS.Amplify.delete_job/6","type":"function","doc":"Deletes a job for a branch of an Amplify app."},{"ref":"AWS.Amplify.html#delete_webhook/4","title":"AWS.Amplify.delete_webhook/4","type":"function","doc":"Deletes a webhook."},{"ref":"AWS.Amplify.html#generate_access_logs/4","title":"AWS.Amplify.generate_access_logs/4","type":"function","doc":"Returns the website access logs for a specific time range using a presigned URL."},{"ref":"AWS.Amplify.html#get_app/3","title":"AWS.Amplify.get_app/3","type":"function","doc":"Returns an existing Amplify app by appID."},{"ref":"AWS.Amplify.html#get_artifact_url/3","title":"AWS.Amplify.get_artifact_url/3","type":"function","doc":"Returns the artifact info that corresponds to an artifact id."},{"ref":"AWS.Amplify.html#get_backend_environment/4","title":"AWS.Amplify.get_backend_environment/4","type":"function","doc":"Returns a backend environment for an Amplify app."},{"ref":"AWS.Amplify.html#get_branch/4","title":"AWS.Amplify.get_branch/4","type":"function","doc":"Returns a branch for an Amplify app."},{"ref":"AWS.Amplify.html#get_domain_association/4","title":"AWS.Amplify.get_domain_association/4","type":"function","doc":"Returns the domain information for an Amplify app."},{"ref":"AWS.Amplify.html#get_job/5","title":"AWS.Amplify.get_job/5","type":"function","doc":"Returns a job for a branch of an Amplify app."},{"ref":"AWS.Amplify.html#get_webhook/3","title":"AWS.Amplify.get_webhook/3","type":"function","doc":"Returns the webhook information that corresponds to a specified webhook ID."},{"ref":"AWS.Amplify.html#list_apps/4","title":"AWS.Amplify.list_apps/4","type":"function","doc":"Returns a list of the existing Amplify apps."},{"ref":"AWS.Amplify.html#list_artifacts/7","title":"AWS.Amplify.list_artifacts/7","type":"function","doc":"Returns a list of artifacts for a specified app, branch, and job."},{"ref":"AWS.Amplify.html#list_backend_environments/6","title":"AWS.Amplify.list_backend_environments/6","type":"function","doc":"Lists the backend environments for an Amplify app."},{"ref":"AWS.Amplify.html#list_branches/5","title":"AWS.Amplify.list_branches/5","type":"function","doc":"Lists the branches of an Amplify app."},{"ref":"AWS.Amplify.html#list_domain_associations/5","title":"AWS.Amplify.list_domain_associations/5","type":"function","doc":"Returns the domain associations for an Amplify app."},{"ref":"AWS.Amplify.html#list_jobs/6","title":"AWS.Amplify.list_jobs/6","type":"function","doc":"Lists the jobs for a branch of an Amplify app."},{"ref":"AWS.Amplify.html#list_tags_for_resource/3","title":"AWS.Amplify.list_tags_for_resource/3","type":"function","doc":"Returns a list of tags for a specified Amazon Resource Name (ARN)."},{"ref":"AWS.Amplify.html#list_webhooks/5","title":"AWS.Amplify.list_webhooks/5","type":"function","doc":"Returns a list of webhooks for an Amplify app."},{"ref":"AWS.Amplify.html#start_deployment/5","title":"AWS.Amplify.start_deployment/5","type":"function","doc":"Starts a deployment for a manually deployed app. Manually deployed apps are not connected to a repository."},{"ref":"AWS.Amplify.html#start_job/5","title":"AWS.Amplify.start_job/5","type":"function","doc":"Starts a new job for a branch of an Amplify app."},{"ref":"AWS.Amplify.html#stop_job/6","title":"AWS.Amplify.stop_job/6","type":"function","doc":"Stops a job that is in progress for a branch of an Amplify app."},{"ref":"AWS.Amplify.html#tag_resource/4","title":"AWS.Amplify.tag_resource/4","type":"function","doc":"Tags the resource with a tag key and value."},{"ref":"AWS.Amplify.html#untag_resource/4","title":"AWS.Amplify.untag_resource/4","type":"function","doc":"Untags a resource with a specified Amazon Resource Name (ARN)."},{"ref":"AWS.Amplify.html#update_app/4","title":"AWS.Amplify.update_app/4","type":"function","doc":"Updates an existing Amplify app."},{"ref":"AWS.Amplify.html#update_branch/5","title":"AWS.Amplify.update_branch/5","type":"function","doc":"Updates a branch for an Amplify app."},{"ref":"AWS.Amplify.html#update_domain_association/5","title":"AWS.Amplify.update_domain_association/5","type":"function","doc":"Creates a new domain association for an Amplify app."},{"ref":"AWS.Amplify.html#update_webhook/4","title":"AWS.Amplify.update_webhook/4","type":"function","doc":"Updates a webhook."},{"ref":"AWS.ApiGatewayManagementApi.html","title":"AWS.ApiGatewayManagementApi","type":"module","doc":"The Amazon API Gateway Management API allows you to directly manage runtime aspects of your deployed APIs. To use it, you must explicitly set the SDK&#39;s endpoint to point to the endpoint of your deployed API. The endpoint will be of the form https://{api-id}.execute-api.{region}.amazonaws.com/{stage}, or will be the endpoint corresponding to your API&#39;s custom domain and base path, if applicable."},{"ref":"AWS.ApiGatewayManagementApi.html#delete_connection/4","title":"AWS.ApiGatewayManagementApi.delete_connection/4","type":"function","doc":"Delete the connection with the provided id."},{"ref":"AWS.ApiGatewayManagementApi.html#get_connection/3","title":"AWS.ApiGatewayManagementApi.get_connection/3","type":"function","doc":"Get information about the connection with the provided id."},{"ref":"AWS.ApiGatewayManagementApi.html#post_to_connection/4","title":"AWS.ApiGatewayManagementApi.post_to_connection/4","type":"function","doc":"Sends the provided data to the specified connection."},{"ref":"AWS.ApiGatewayV2.html","title":"AWS.ApiGatewayV2","type":"module","doc":"Amazon API Gateway V2"},{"ref":"AWS.ApiGatewayV2.html#create_api/3","title":"AWS.ApiGatewayV2.create_api/3","type":"function","doc":"Creates an Api resource."},{"ref":"AWS.ApiGatewayV2.html#create_api_mapping/4","title":"AWS.ApiGatewayV2.create_api_mapping/4","type":"function","doc":"Creates an API mapping."},{"ref":"AWS.ApiGatewayV2.html#create_authorizer/4","title":"AWS.ApiGatewayV2.create_authorizer/4","type":"function","doc":"Creates an Authorizer for an API."},{"ref":"AWS.ApiGatewayV2.html#create_deployment/4","title":"AWS.ApiGatewayV2.create_deployment/4","type":"function","doc":"Creates a Deployment for an API."},{"ref":"AWS.ApiGatewayV2.html#create_domain_name/3","title":"AWS.ApiGatewayV2.create_domain_name/3","type":"function","doc":"Creates a domain name."},{"ref":"AWS.ApiGatewayV2.html#create_integration/4","title":"AWS.ApiGatewayV2.create_integration/4","type":"function","doc":"Creates an Integration."},{"ref":"AWS.ApiGatewayV2.html#create_integration_response/5","title":"AWS.ApiGatewayV2.create_integration_response/5","type":"function","doc":"Creates an IntegrationResponses."},{"ref":"AWS.ApiGatewayV2.html#create_model/4","title":"AWS.ApiGatewayV2.create_model/4","type":"function","doc":"Creates a Model for an API."},{"ref":"AWS.ApiGatewayV2.html#create_route/4","title":"AWS.ApiGatewayV2.create_route/4","type":"function","doc":"Creates a Route for an API."},{"ref":"AWS.ApiGatewayV2.html#create_route_response/5","title":"AWS.ApiGatewayV2.create_route_response/5","type":"function","doc":"Creates a RouteResponse for a Route."},{"ref":"AWS.ApiGatewayV2.html#create_stage/4","title":"AWS.ApiGatewayV2.create_stage/4","type":"function","doc":"Creates a Stage for an API."},{"ref":"AWS.ApiGatewayV2.html#create_vpc_link/3","title":"AWS.ApiGatewayV2.create_vpc_link/3","type":"function","doc":"Creates a VPC link."},{"ref":"AWS.ApiGatewayV2.html#delete_access_log_settings/5","title":"AWS.ApiGatewayV2.delete_access_log_settings/5","type":"function","doc":"Deletes the AccessLogSettings for a Stage. To disable access logging for a Stage, delete its AccessLogSettings."},{"ref":"AWS.ApiGatewayV2.html#delete_api/4","title":"AWS.ApiGatewayV2.delete_api/4","type":"function","doc":"Deletes an Api resource."},{"ref":"AWS.ApiGatewayV2.html#delete_api_mapping/5","title":"AWS.ApiGatewayV2.delete_api_mapping/5","type":"function","doc":"Deletes an API mapping."},{"ref":"AWS.ApiGatewayV2.html#delete_authorizer/5","title":"AWS.ApiGatewayV2.delete_authorizer/5","type":"function","doc":"Deletes an Authorizer."},{"ref":"AWS.ApiGatewayV2.html#delete_cors_configuration/4","title":"AWS.ApiGatewayV2.delete_cors_configuration/4","type":"function","doc":"Deletes a CORS configuration."},{"ref":"AWS.ApiGatewayV2.html#delete_deployment/5","title":"AWS.ApiGatewayV2.delete_deployment/5","type":"function","doc":"Deletes a Deployment."},{"ref":"AWS.ApiGatewayV2.html#delete_domain_name/4","title":"AWS.ApiGatewayV2.delete_domain_name/4","type":"function","doc":"Deletes a domain name."},{"ref":"AWS.ApiGatewayV2.html#delete_integration/5","title":"AWS.ApiGatewayV2.delete_integration/5","type":"function","doc":"Deletes an Integration."},{"ref":"AWS.ApiGatewayV2.html#delete_integration_response/6","title":"AWS.ApiGatewayV2.delete_integration_response/6","type":"function","doc":"Deletes an IntegrationResponses."},{"ref":"AWS.ApiGatewayV2.html#delete_model/5","title":"AWS.ApiGatewayV2.delete_model/5","type":"function","doc":"Deletes a Model."},{"ref":"AWS.ApiGatewayV2.html#delete_route/5","title":"AWS.ApiGatewayV2.delete_route/5","type":"function","doc":"Deletes a Route."},{"ref":"AWS.ApiGatewayV2.html#delete_route_request_parameter/6","title":"AWS.ApiGatewayV2.delete_route_request_parameter/6","type":"function","doc":"Deletes a route request parameter."},{"ref":"AWS.ApiGatewayV2.html#delete_route_response/6","title":"AWS.ApiGatewayV2.delete_route_response/6","type":"function","doc":"Deletes a RouteResponse."},{"ref":"AWS.ApiGatewayV2.html#delete_route_settings/6","title":"AWS.ApiGatewayV2.delete_route_settings/6","type":"function","doc":"Deletes the RouteSettings for a stage."},{"ref":"AWS.ApiGatewayV2.html#delete_stage/5","title":"AWS.ApiGatewayV2.delete_stage/5","type":"function","doc":"Deletes a Stage."},{"ref":"AWS.ApiGatewayV2.html#delete_vpc_link/4","title":"AWS.ApiGatewayV2.delete_vpc_link/4","type":"function","doc":"Deletes a VPC link."},{"ref":"AWS.ApiGatewayV2.html#export_api/8","title":"AWS.ApiGatewayV2.export_api/8","type":"function","doc":"Exports a definition of an API in a particular output format and specification."},{"ref":"AWS.ApiGatewayV2.html#get_api/3","title":"AWS.ApiGatewayV2.get_api/3","type":"function","doc":"Gets an Api resource."},{"ref":"AWS.ApiGatewayV2.html#get_api_mapping/4","title":"AWS.ApiGatewayV2.get_api_mapping/4","type":"function","doc":"Gets an API mapping."},{"ref":"AWS.ApiGatewayV2.html#get_api_mappings/5","title":"AWS.ApiGatewayV2.get_api_mappings/5","type":"function","doc":"Gets API mappings."},{"ref":"AWS.ApiGatewayV2.html#get_apis/4","title":"AWS.ApiGatewayV2.get_apis/4","type":"function","doc":"Gets a collection of Api resources."},{"ref":"AWS.ApiGatewayV2.html#get_authorizer/4","title":"AWS.ApiGatewayV2.get_authorizer/4","type":"function","doc":"Gets an Authorizer."},{"ref":"AWS.ApiGatewayV2.html#get_authorizers/5","title":"AWS.ApiGatewayV2.get_authorizers/5","type":"function","doc":"Gets the Authorizers for an API."},{"ref":"AWS.ApiGatewayV2.html#get_deployment/4","title":"AWS.ApiGatewayV2.get_deployment/4","type":"function","doc":"Gets a Deployment."},{"ref":"AWS.ApiGatewayV2.html#get_deployments/5","title":"AWS.ApiGatewayV2.get_deployments/5","type":"function","doc":"Gets the Deployments for an API."},{"ref":"AWS.ApiGatewayV2.html#get_domain_name/3","title":"AWS.ApiGatewayV2.get_domain_name/3","type":"function","doc":"Gets a domain name."},{"ref":"AWS.ApiGatewayV2.html#get_domain_names/4","title":"AWS.ApiGatewayV2.get_domain_names/4","type":"function","doc":"Gets the domain names for an AWS account."},{"ref":"AWS.ApiGatewayV2.html#get_integration/4","title":"AWS.ApiGatewayV2.get_integration/4","type":"function","doc":"Gets an Integration."},{"ref":"AWS.ApiGatewayV2.html#get_integration_response/5","title":"AWS.ApiGatewayV2.get_integration_response/5","type":"function","doc":"Gets an IntegrationResponses."},{"ref":"AWS.ApiGatewayV2.html#get_integration_responses/6","title":"AWS.ApiGatewayV2.get_integration_responses/6","type":"function","doc":"Gets the IntegrationResponses for an Integration."},{"ref":"AWS.ApiGatewayV2.html#get_integrations/5","title":"AWS.ApiGatewayV2.get_integrations/5","type":"function","doc":"Gets the Integrations for an API."},{"ref":"AWS.ApiGatewayV2.html#get_model/4","title":"AWS.ApiGatewayV2.get_model/4","type":"function","doc":"Gets a Model."},{"ref":"AWS.ApiGatewayV2.html#get_model_template/4","title":"AWS.ApiGatewayV2.get_model_template/4","type":"function","doc":"Gets a model template."},{"ref":"AWS.ApiGatewayV2.html#get_models/5","title":"AWS.ApiGatewayV2.get_models/5","type":"function","doc":"Gets the Models for an API."},{"ref":"AWS.ApiGatewayV2.html#get_route/4","title":"AWS.ApiGatewayV2.get_route/4","type":"function","doc":"Gets a Route."},{"ref":"AWS.ApiGatewayV2.html#get_route_response/5","title":"AWS.ApiGatewayV2.get_route_response/5","type":"function","doc":"Gets a RouteResponse."},{"ref":"AWS.ApiGatewayV2.html#get_route_responses/6","title":"AWS.ApiGatewayV2.get_route_responses/6","type":"function","doc":"Gets the RouteResponses for a Route."},{"ref":"AWS.ApiGatewayV2.html#get_routes/5","title":"AWS.ApiGatewayV2.get_routes/5","type":"function","doc":"Gets the Routes for an API."},{"ref":"AWS.ApiGatewayV2.html#get_stage/4","title":"AWS.ApiGatewayV2.get_stage/4","type":"function","doc":"Gets a Stage."},{"ref":"AWS.ApiGatewayV2.html#get_stages/5","title":"AWS.ApiGatewayV2.get_stages/5","type":"function","doc":"Gets the Stages for an API."},{"ref":"AWS.ApiGatewayV2.html#get_tags/3","title":"AWS.ApiGatewayV2.get_tags/3","type":"function","doc":"Gets a collection of Tag resources."},{"ref":"AWS.ApiGatewayV2.html#get_vpc_link/3","title":"AWS.ApiGatewayV2.get_vpc_link/3","type":"function","doc":"Gets a VPC link."},{"ref":"AWS.ApiGatewayV2.html#get_vpc_links/4","title":"AWS.ApiGatewayV2.get_vpc_links/4","type":"function","doc":"Gets a collection of VPC links."},{"ref":"AWS.ApiGatewayV2.html#import_api/3","title":"AWS.ApiGatewayV2.import_api/3","type":"function","doc":"Imports an API."},{"ref":"AWS.ApiGatewayV2.html#reimport_api/4","title":"AWS.ApiGatewayV2.reimport_api/4","type":"function","doc":"Puts an Api resource."},{"ref":"AWS.ApiGatewayV2.html#reset_authorizers_cache/5","title":"AWS.ApiGatewayV2.reset_authorizers_cache/5","type":"function","doc":"Resets all authorizer cache entries for the specified stage. Supported only for HTTP API Lambda authorizers."},{"ref":"AWS.ApiGatewayV2.html#tag_resource/4","title":"AWS.ApiGatewayV2.tag_resource/4","type":"function","doc":"Creates a new Tag resource to represent a tag."},{"ref":"AWS.ApiGatewayV2.html#untag_resource/4","title":"AWS.ApiGatewayV2.untag_resource/4","type":"function","doc":"Deletes a Tag."},{"ref":"AWS.ApiGatewayV2.html#update_api/4","title":"AWS.ApiGatewayV2.update_api/4","type":"function","doc":"Updates an Api resource."},{"ref":"AWS.ApiGatewayV2.html#update_api_mapping/5","title":"AWS.ApiGatewayV2.update_api_mapping/5","type":"function","doc":"The API mapping."},{"ref":"AWS.ApiGatewayV2.html#update_authorizer/5","title":"AWS.ApiGatewayV2.update_authorizer/5","type":"function","doc":"Updates an Authorizer."},{"ref":"AWS.ApiGatewayV2.html#update_deployment/5","title":"AWS.ApiGatewayV2.update_deployment/5","type":"function","doc":"Updates a Deployment."},{"ref":"AWS.ApiGatewayV2.html#update_domain_name/4","title":"AWS.ApiGatewayV2.update_domain_name/4","type":"function","doc":"Updates a domain name."},{"ref":"AWS.ApiGatewayV2.html#update_integration/5","title":"AWS.ApiGatewayV2.update_integration/5","type":"function","doc":"Updates an Integration."},{"ref":"AWS.ApiGatewayV2.html#update_integration_response/6","title":"AWS.ApiGatewayV2.update_integration_response/6","type":"function","doc":"Updates an IntegrationResponses."},{"ref":"AWS.ApiGatewayV2.html#update_model/5","title":"AWS.ApiGatewayV2.update_model/5","type":"function","doc":"Updates a Model."},{"ref":"AWS.ApiGatewayV2.html#update_route/5","title":"AWS.ApiGatewayV2.update_route/5","type":"function","doc":"Updates a Route."},{"ref":"AWS.ApiGatewayV2.html#update_route_response/6","title":"AWS.ApiGatewayV2.update_route_response/6","type":"function","doc":"Updates a RouteResponse."},{"ref":"AWS.ApiGatewayV2.html#update_stage/5","title":"AWS.ApiGatewayV2.update_stage/5","type":"function","doc":"Updates a Stage."},{"ref":"AWS.ApiGatewayV2.html#update_vpc_link/4","title":"AWS.ApiGatewayV2.update_vpc_link/4","type":"function","doc":"Updates a VPC link."},{"ref":"AWS.AppConfig.html","title":"AWS.AppConfig","type":"module","doc":"AWS AppConfig Use AWS AppConfig, a capability of AWS Systems Manager, to create, manage, and quickly deploy application configurations. AppConfig supports controlled deployments to applications of any size and includes built-in validation checks and monitoring. You can use AppConfig with applications hosted on Amazon EC2 instances, AWS Lambda, containers, mobile applications, or IoT devices. To prevent errors when deploying application configurations, especially for production systems where a simple typo could cause an unexpected outage, AppConfig includes validators. A validator provides a syntactic or semantic check to ensure that the configuration you want to deploy works as intended. To validate your application configuration data, you provide a schema or a Lambda function that runs against the configuration. The configuration deployment or update can only proceed when the configuration data is valid. During a configuration deployment, AppConfig monitors the application to ensure that the deployment is successful. If the system encounters an error, AppConfig rolls back the change to minimize impact for your application users. You can configure a deployment strategy for each application or environment that includes deployment criteria, including velocity, bake time, and alarms to monitor. Similar to error monitoring, if a deployment triggers an alarm, AppConfig automatically rolls back to the previous version. AppConfig supports multiple use cases. Here are some examples. Application tuning: Use AppConfig to carefully introduce changes to your application that can only be tested with production traffic. Feature toggle: Use AppConfig to turn on new features that require a timely deployment, such as a product launch or announcement. Allow list: Use AppConfig to allow premium subscribers to access paid content. Operational issues: Use AppConfig to reduce stress on your application when a dependency or other external factor impacts the system. This reference is intended to be used with the AWS AppConfig User Guide."},{"ref":"AWS.AppConfig.html#create_application/3","title":"AWS.AppConfig.create_application/3","type":"function","doc":"An application in AppConfig is a logical unit of code that provides capabilities for your customers. For example, an application can be a microservice that runs on Amazon EC2 instances, a mobile application installed by your users, a serverless application using Amazon API Gateway and AWS Lambda, or any system you run on behalf of others."},{"ref":"AWS.AppConfig.html#create_configuration_profile/4","title":"AWS.AppConfig.create_configuration_profile/4","type":"function","doc":"Information that enables AppConfig to access the configuration source. Valid configuration sources include Systems Manager (SSM) documents, SSM Parameter Store parameters, and Amazon S3 objects. A configuration profile includes the following information. The Uri location of the configuration data. The AWS Identity and Access Management (IAM) role that provides access to the configuration data. A validator for the configuration data. Available validators include either a JSON Schema or an AWS Lambda function. For more information, see Create a Configuration and a Configuration Profile in the AWS AppConfig User Guide."},{"ref":"AWS.AppConfig.html#create_deployment_strategy/3","title":"AWS.AppConfig.create_deployment_strategy/3","type":"function","doc":"A deployment strategy defines important criteria for rolling out your configuration to the designated targets. A deployment strategy includes: the overall duration required, a percentage of targets to receive the deployment during each interval, an algorithm that defines how percentage grows, and bake time."},{"ref":"AWS.AppConfig.html#create_environment/4","title":"AWS.AppConfig.create_environment/4","type":"function","doc":"For each application, you define one or more environments. An environment is a logical deployment group of AppConfig targets, such as applications in a Beta or Production environment. You can also define environments for application subcomponents such as the Web, Mobile and Back-end components for your application. You can configure Amazon CloudWatch alarms for each environment. The system monitors alarms during a configuration deployment. If an alarm is triggered, the system rolls back the configuration."},{"ref":"AWS.AppConfig.html#create_hosted_configuration_version/5","title":"AWS.AppConfig.create_hosted_configuration_version/5","type":"function","doc":"Create a new configuration in the AppConfig configuration store."},{"ref":"AWS.AppConfig.html#delete_application/4","title":"AWS.AppConfig.delete_application/4","type":"function","doc":"Delete an application. Deleting an application does not delete a configuration from a host."},{"ref":"AWS.AppConfig.html#delete_configuration_profile/5","title":"AWS.AppConfig.delete_configuration_profile/5","type":"function","doc":"Delete a configuration profile. Deleting a configuration profile does not delete a configuration from a host."},{"ref":"AWS.AppConfig.html#delete_deployment_strategy/4","title":"AWS.AppConfig.delete_deployment_strategy/4","type":"function","doc":"Delete a deployment strategy. Deleting a deployment strategy does not delete a configuration from a host."},{"ref":"AWS.AppConfig.html#delete_environment/5","title":"AWS.AppConfig.delete_environment/5","type":"function","doc":"Delete an environment. Deleting an environment does not delete a configuration from a host."},{"ref":"AWS.AppConfig.html#delete_hosted_configuration_version/6","title":"AWS.AppConfig.delete_hosted_configuration_version/6","type":"function","doc":"Delete a version of a configuration from the AppConfig configuration store."},{"ref":"AWS.AppConfig.html#get_application/3","title":"AWS.AppConfig.get_application/3","type":"function","doc":"Retrieve information about an application."},{"ref":"AWS.AppConfig.html#get_configuration/7","title":"AWS.AppConfig.get_configuration/7","type":"function","doc":"Receive information about a configuration. AWS AppConfig uses the value of the ClientConfigurationVersion parameter to identify the configuration version on your clients. If you dont send ClientConfigurationVersion with each call to GetConfiguration, your clients receive the current configuration. You are charged each time your clients receive a configuration. To avoid excess charges, we recommend that you include the ClientConfigurationVersion value with every call to GetConfiguration. This value must be saved on your client. Subsequent calls to GetConfiguration must pass this value by using the ClientConfigurationVersion parameter."},{"ref":"AWS.AppConfig.html#get_configuration_profile/4","title":"AWS.AppConfig.get_configuration_profile/4","type":"function","doc":"Retrieve information about a configuration profile."},{"ref":"AWS.AppConfig.html#get_deployment/5","title":"AWS.AppConfig.get_deployment/5","type":"function","doc":"Retrieve information about a configuration deployment."},{"ref":"AWS.AppConfig.html#get_deployment_strategy/3","title":"AWS.AppConfig.get_deployment_strategy/3","type":"function","doc":"Retrieve information about a deployment strategy. A deployment strategy defines important criteria for rolling out your configuration to the designated targets. A deployment strategy includes: the overall duration required, a percentage of targets to receive the deployment during each interval, an algorithm that defines how percentage grows, and bake time."},{"ref":"AWS.AppConfig.html#get_environment/4","title":"AWS.AppConfig.get_environment/4","type":"function","doc":"Retrieve information about an environment. An environment is a logical deployment group of AppConfig applications, such as applications in a Production environment or in an EU_Region environment. Each configuration deployment targets an environment. You can enable one or more Amazon CloudWatch alarms for an environment. If an alarm is triggered during a deployment, AppConfig roles back the configuration."},{"ref":"AWS.AppConfig.html#get_hosted_configuration_version/5","title":"AWS.AppConfig.get_hosted_configuration_version/5","type":"function","doc":"Get information about a specific configuration version."},{"ref":"AWS.AppConfig.html#list_applications/4","title":"AWS.AppConfig.list_applications/4","type":"function","doc":"List all applications in your AWS account."},{"ref":"AWS.AppConfig.html#list_configuration_profiles/5","title":"AWS.AppConfig.list_configuration_profiles/5","type":"function","doc":"Lists the configuration profiles for an application."},{"ref":"AWS.AppConfig.html#list_deployment_strategies/4","title":"AWS.AppConfig.list_deployment_strategies/4","type":"function","doc":"List deployment strategies."},{"ref":"AWS.AppConfig.html#list_deployments/6","title":"AWS.AppConfig.list_deployments/6","type":"function","doc":"Lists the deployments for an environment."},{"ref":"AWS.AppConfig.html#list_environments/5","title":"AWS.AppConfig.list_environments/5","type":"function","doc":"List the environments for an application."},{"ref":"AWS.AppConfig.html#list_hosted_configuration_versions/6","title":"AWS.AppConfig.list_hosted_configuration_versions/6","type":"function","doc":"View a list of configurations stored in the AppConfig configuration store by version."},{"ref":"AWS.AppConfig.html#list_tags_for_resource/3","title":"AWS.AppConfig.list_tags_for_resource/3","type":"function","doc":"Retrieves the list of key-value tags assigned to the resource."},{"ref":"AWS.AppConfig.html#start_deployment/5","title":"AWS.AppConfig.start_deployment/5","type":"function","doc":"Starts a deployment."},{"ref":"AWS.AppConfig.html#stop_deployment/6","title":"AWS.AppConfig.stop_deployment/6","type":"function","doc":"Stops a deployment. This API action works only on deployments that have a status of DEPLOYING. This action moves the deployment to a status of ROLLED_BACK."},{"ref":"AWS.AppConfig.html#tag_resource/4","title":"AWS.AppConfig.tag_resource/4","type":"function","doc":"Metadata to assign to an AppConfig resource. Tags help organize and categorize your AppConfig resources. Each tag consists of a key and an optional value, both of which you define. You can specify a maximum of 50 tags for a resource."},{"ref":"AWS.AppConfig.html#untag_resource/4","title":"AWS.AppConfig.untag_resource/4","type":"function","doc":"Deletes a tag key and value from an AppConfig resource."},{"ref":"AWS.AppConfig.html#update_application/4","title":"AWS.AppConfig.update_application/4","type":"function","doc":"Updates an application."},{"ref":"AWS.AppConfig.html#update_configuration_profile/5","title":"AWS.AppConfig.update_configuration_profile/5","type":"function","doc":"Updates a configuration profile."},{"ref":"AWS.AppConfig.html#update_deployment_strategy/4","title":"AWS.AppConfig.update_deployment_strategy/4","type":"function","doc":"Updates a deployment strategy."},{"ref":"AWS.AppConfig.html#update_environment/5","title":"AWS.AppConfig.update_environment/5","type":"function","doc":"Updates an environment."},{"ref":"AWS.AppConfig.html#validate_configuration/5","title":"AWS.AppConfig.validate_configuration/5","type":"function","doc":"Uses the validators in a configuration profile to validate a configuration."},{"ref":"AWS.AppMesh.html","title":"AWS.AppMesh","type":"module","doc":"AWS App Mesh is a service mesh based on the Envoy proxy that makes it easy to monitor and control microservices. App Mesh standardizes how your microservices communicate, giving you end-to-end visibility and helping to ensure high availability for your applications. App Mesh gives you consistent visibility and network traffic controls for every microservice in an application. You can use App Mesh with AWS Fargate, Amazon ECS, Amazon EKS, Kubernetes on AWS, and Amazon EC2. App Mesh supports microservice applications that use service discovery naming for their components. For more information about service discovery on Amazon ECS, see Service Discovery in the Amazon Elastic Container Service Developer Guide. Kubernetes kube-dns and coredns are supported. For more information, see DNS for Services and Pods in the Kubernetes documentation."},{"ref":"AWS.AppMesh.html#create_gateway_route/5","title":"AWS.AppMesh.create_gateway_route/5","type":"function","doc":"Creates a gateway route. A gateway route is attached to a virtual gateway and routes traffic to an existing virtual service. If a route matches a request, it can distribute traffic to a target virtual service. For more information about gateway routes, see Gateway routes."},{"ref":"AWS.AppMesh.html#create_mesh/3","title":"AWS.AppMesh.create_mesh/3","type":"function","doc":"Creates a service mesh. A service mesh is a logical boundary for network traffic between services that are represented by resources within the mesh. After you create your service mesh, you can create virtual services, virtual nodes, virtual routers, and routes to distribute traffic between the applications in your mesh. For more information about service meshes, see Service meshes."},{"ref":"AWS.AppMesh.html#create_route/5","title":"AWS.AppMesh.create_route/5","type":"function","doc":"Creates a route that is associated with a virtual router. You can route several different protocols and define a retry policy for a route. Traffic can be routed to one or more virtual nodes. For more information about routes, see Routes."},{"ref":"AWS.AppMesh.html#create_virtual_gateway/4","title":"AWS.AppMesh.create_virtual_gateway/4","type":"function","doc":"Creates a virtual gateway. A virtual gateway allows resources outside your mesh to communicate to resources that are inside your mesh. The virtual gateway represents an Envoy proxy running in an Amazon ECS task, in a Kubernetes service, or on an Amazon EC2 instance. Unlike a virtual node, which represents an Envoy running with an application, a virtual gateway represents Envoy deployed by itself. For more information about virtual gateways, see Virtual gateways."},{"ref":"AWS.AppMesh.html#create_virtual_node/4","title":"AWS.AppMesh.create_virtual_node/4","type":"function","doc":"Creates a virtual node within a service mesh. A virtual node acts as a logical pointer to a particular task group, such as an Amazon ECS service or a Kubernetes deployment. When you create a virtual node, you can specify the service discovery information for your task group, and whether the proxy running in a task group will communicate with other proxies using Transport Layer Security (TLS). You define a listener for any inbound traffic that your virtual node expects. Any virtual service that your virtual node expects to communicate to is specified as a backend. The response metadata for your new virtual node contains the arn that is associated with the virtual node. Set this value (either the full ARN or the truncated resource name: for example, mesh/default/virtualNode/simpleapp) as the APPMESH_VIRTUAL_NODE_NAME environment variable for your task group&#39;s Envoy proxy container in your task definition or pod spec. This is then mapped to the node.id and node.cluster Envoy parameters. If you require your Envoy stats or tracing to use a different name, you can override the node.cluster value that is set by APPMESH_VIRTUAL_NODE_NAME with the APPMESH_VIRTUAL_NODE_CLUSTER environment variable. For more information about virtual nodes, see Virtual nodes."},{"ref":"AWS.AppMesh.html#create_virtual_router/4","title":"AWS.AppMesh.create_virtual_router/4","type":"function","doc":"Creates a virtual router within a service mesh. Specify a listener for any inbound traffic that your virtual router receives. Create a virtual router for each protocol and port that you need to route. Virtual routers handle traffic for one or more virtual services within your mesh. After you create your virtual router, create and associate routes for your virtual router that direct incoming requests to different virtual nodes. For more information about virtual routers, see Virtual routers."},{"ref":"AWS.AppMesh.html#create_virtual_service/4","title":"AWS.AppMesh.create_virtual_service/4","type":"function","doc":"Creates a virtual service within a service mesh. A virtual service is an abstraction of a real service that is provided by a virtual node directly or indirectly by means of a virtual router. Dependent services call your virtual service by its virtualServiceName, and those requests are routed to the virtual node or virtual router that is specified as the provider for the virtual service. For more information about virtual services, see Virtual services."},{"ref":"AWS.AppMesh.html#delete_gateway_route/6","title":"AWS.AppMesh.delete_gateway_route/6","type":"function","doc":"Deletes an existing gateway route."},{"ref":"AWS.AppMesh.html#delete_mesh/4","title":"AWS.AppMesh.delete_mesh/4","type":"function","doc":"Deletes an existing service mesh. You must delete all resources (virtual services, routes, virtual routers, and virtual nodes) in the service mesh before you can delete the mesh itself."},{"ref":"AWS.AppMesh.html#delete_route/6","title":"AWS.AppMesh.delete_route/6","type":"function","doc":"Deletes an existing route."},{"ref":"AWS.AppMesh.html#delete_virtual_gateway/5","title":"AWS.AppMesh.delete_virtual_gateway/5","type":"function","doc":"Deletes an existing virtual gateway. You cannot delete a virtual gateway if any gateway routes are associated to it."},{"ref":"AWS.AppMesh.html#delete_virtual_node/5","title":"AWS.AppMesh.delete_virtual_node/5","type":"function","doc":"Deletes an existing virtual node. You must delete any virtual services that list a virtual node as a service provider before you can delete the virtual node itself."},{"ref":"AWS.AppMesh.html#delete_virtual_router/5","title":"AWS.AppMesh.delete_virtual_router/5","type":"function","doc":"Deletes an existing virtual router. You must delete any routes associated with the virtual router before you can delete the router itself."},{"ref":"AWS.AppMesh.html#delete_virtual_service/5","title":"AWS.AppMesh.delete_virtual_service/5","type":"function","doc":"Deletes an existing virtual service."},{"ref":"AWS.AppMesh.html#describe_gateway_route/6","title":"AWS.AppMesh.describe_gateway_route/6","type":"function","doc":"Describes an existing gateway route."},{"ref":"AWS.AppMesh.html#describe_mesh/4","title":"AWS.AppMesh.describe_mesh/4","type":"function","doc":"Describes an existing service mesh."},{"ref":"AWS.AppMesh.html#describe_route/6","title":"AWS.AppMesh.describe_route/6","type":"function","doc":"Describes an existing route."},{"ref":"AWS.AppMesh.html#describe_virtual_gateway/5","title":"AWS.AppMesh.describe_virtual_gateway/5","type":"function","doc":"Describes an existing virtual gateway."},{"ref":"AWS.AppMesh.html#describe_virtual_node/5","title":"AWS.AppMesh.describe_virtual_node/5","type":"function","doc":"Describes an existing virtual node."},{"ref":"AWS.AppMesh.html#describe_virtual_router/5","title":"AWS.AppMesh.describe_virtual_router/5","type":"function","doc":"Describes an existing virtual router."},{"ref":"AWS.AppMesh.html#describe_virtual_service/5","title":"AWS.AppMesh.describe_virtual_service/5","type":"function","doc":"Describes an existing virtual service."},{"ref":"AWS.AppMesh.html#list_gateway_routes/7","title":"AWS.AppMesh.list_gateway_routes/7","type":"function","doc":"Returns a list of existing gateway routes that are associated to a virtual gateway."},{"ref":"AWS.AppMesh.html#list_meshes/4","title":"AWS.AppMesh.list_meshes/4","type":"function","doc":"Returns a list of existing service meshes."},{"ref":"AWS.AppMesh.html#list_routes/7","title":"AWS.AppMesh.list_routes/7","type":"function","doc":"Returns a list of existing routes in a service mesh."},{"ref":"AWS.AppMesh.html#list_tags_for_resource/5","title":"AWS.AppMesh.list_tags_for_resource/5","type":"function","doc":"List the tags for an App Mesh resource."},{"ref":"AWS.AppMesh.html#list_virtual_gateways/6","title":"AWS.AppMesh.list_virtual_gateways/6","type":"function","doc":"Returns a list of existing virtual gateways in a service mesh."},{"ref":"AWS.AppMesh.html#list_virtual_nodes/6","title":"AWS.AppMesh.list_virtual_nodes/6","type":"function","doc":"Returns a list of existing virtual nodes."},{"ref":"AWS.AppMesh.html#list_virtual_routers/6","title":"AWS.AppMesh.list_virtual_routers/6","type":"function","doc":"Returns a list of existing virtual routers in a service mesh."},{"ref":"AWS.AppMesh.html#list_virtual_services/6","title":"AWS.AppMesh.list_virtual_services/6","type":"function","doc":"Returns a list of existing virtual services in a service mesh."},{"ref":"AWS.AppMesh.html#tag_resource/3","title":"AWS.AppMesh.tag_resource/3","type":"function","doc":"Associates the specified tags to a resource with the specified resourceArn. If existing tags on a resource aren&#39;t specified in the request parameters, they aren&#39;t changed. When a resource is deleted, the tags associated with that resource are also deleted."},{"ref":"AWS.AppMesh.html#untag_resource/3","title":"AWS.AppMesh.untag_resource/3","type":"function","doc":"Deletes specified tags from a resource."},{"ref":"AWS.AppMesh.html#update_gateway_route/6","title":"AWS.AppMesh.update_gateway_route/6","type":"function","doc":"Updates an existing gateway route that is associated to a specified virtual gateway in a service mesh."},{"ref":"AWS.AppMesh.html#update_mesh/4","title":"AWS.AppMesh.update_mesh/4","type":"function","doc":"Updates an existing service mesh."},{"ref":"AWS.AppMesh.html#update_route/6","title":"AWS.AppMesh.update_route/6","type":"function","doc":"Updates an existing route for a specified service mesh and virtual router."},{"ref":"AWS.AppMesh.html#update_virtual_gateway/5","title":"AWS.AppMesh.update_virtual_gateway/5","type":"function","doc":"Updates an existing virtual gateway in a specified service mesh."},{"ref":"AWS.AppMesh.html#update_virtual_node/5","title":"AWS.AppMesh.update_virtual_node/5","type":"function","doc":"Updates an existing virtual node in a specified service mesh."},{"ref":"AWS.AppMesh.html#update_virtual_router/5","title":"AWS.AppMesh.update_virtual_router/5","type":"function","doc":"Updates an existing virtual router in a specified service mesh."},{"ref":"AWS.AppMesh.html#update_virtual_service/5","title":"AWS.AppMesh.update_virtual_service/5","type":"function","doc":"Updates an existing virtual service in a specified service mesh."},{"ref":"AWS.AppStream.html","title":"AWS.AppStream","type":"module","doc":"Amazon AppStream 2.0 This is the Amazon AppStream 2.0 API Reference. This documentation provides descriptions and syntax for each of the actions and data types in AppStream 2.0. AppStream 2.0 is a fully managed, secure application streaming service that lets you stream desktop applications to users without rewriting applications. AppStream 2.0 manages the AWS resources that are required to host and run your applications, scales automatically, and provides access to your users on demand. You can call the AppStream 2.0 API operations by using an interface VPC endpoint (interface endpoint). For more information, see Access AppStream 2.0 API Operations and CLI Commands Through an Interface VPC Endpoint in the Amazon AppStream 2.0 Administration Guide. To learn more about AppStream 2.0, see the following resources: Amazon AppStream 2.0 product page * Amazon AppStream 2.0 documentation"},{"ref":"AWS.AppStream.html#associate_fleet/3","title":"AWS.AppStream.associate_fleet/3","type":"function","doc":"Associates the specified fleet with the specified stack."},{"ref":"AWS.AppStream.html#batch_associate_user_stack/3","title":"AWS.AppStream.batch_associate_user_stack/3","type":"function","doc":"Associates the specified users with the specified stacks. Users in a user pool cannot be assigned to stacks with fleets that are joined to an Active Directory domain."},{"ref":"AWS.AppStream.html#batch_disassociate_user_stack/3","title":"AWS.AppStream.batch_disassociate_user_stack/3","type":"function","doc":"Disassociates the specified users from the specified stacks."},{"ref":"AWS.AppStream.html#copy_image/3","title":"AWS.AppStream.copy_image/3","type":"function","doc":"Copies the image within the same region or to a new region within the same AWS account. Note that any tags you added to the image will not be copied."},{"ref":"AWS.AppStream.html#create_directory_config/3","title":"AWS.AppStream.create_directory_config/3","type":"function","doc":"Creates a Directory Config object in AppStream 2.0. This object includes the configuration information required to join fleets and image builders to Microsoft Active Directory domains."},{"ref":"AWS.AppStream.html#create_fleet/3","title":"AWS.AppStream.create_fleet/3","type":"function","doc":"Creates a fleet. A fleet consists of streaming instances that run a specified image."},{"ref":"AWS.AppStream.html#create_image_builder/3","title":"AWS.AppStream.create_image_builder/3","type":"function","doc":"Creates an image builder. An image builder is a virtual machine that is used to create an image. The initial state of the builder is PENDING. When it is ready, the state is RUNNING."},{"ref":"AWS.AppStream.html#create_image_builder_streaming_u_r_l/3","title":"AWS.AppStream.create_image_builder_streaming_u_r_l/3","type":"function","doc":"Creates a URL to start an image builder streaming session."},{"ref":"AWS.AppStream.html#create_stack/3","title":"AWS.AppStream.create_stack/3","type":"function","doc":"Creates a stack to start streaming applications to users. A stack consists of an associated fleet, user access policies, and storage configurations."},{"ref":"AWS.AppStream.html#create_streaming_u_r_l/3","title":"AWS.AppStream.create_streaming_u_r_l/3","type":"function","doc":"Creates a temporary URL to start an AppStream 2.0 streaming session for the specified user. A streaming URL enables application streaming to be tested without user setup."},{"ref":"AWS.AppStream.html#create_usage_report_subscription/3","title":"AWS.AppStream.create_usage_report_subscription/3","type":"function","doc":"Creates a usage report subscription. Usage reports are generated daily."},{"ref":"AWS.AppStream.html#create_user/3","title":"AWS.AppStream.create_user/3","type":"function","doc":"Creates a new user in the user pool."},{"ref":"AWS.AppStream.html#delete_directory_config/3","title":"AWS.AppStream.delete_directory_config/3","type":"function","doc":"Deletes the specified Directory Config object from AppStream 2.0. This object includes the information required to join streaming instances to an Active Directory domain."},{"ref":"AWS.AppStream.html#delete_fleet/3","title":"AWS.AppStream.delete_fleet/3","type":"function","doc":"Deletes the specified fleet."},{"ref":"AWS.AppStream.html#delete_image/3","title":"AWS.AppStream.delete_image/3","type":"function","doc":"Deletes the specified image. You cannot delete an image when it is in use. After you delete an image, you cannot provision new capacity using the image."},{"ref":"AWS.AppStream.html#delete_image_builder/3","title":"AWS.AppStream.delete_image_builder/3","type":"function","doc":"Deletes the specified image builder and releases the capacity."},{"ref":"AWS.AppStream.html#delete_image_permissions/3","title":"AWS.AppStream.delete_image_permissions/3","type":"function","doc":"Deletes permissions for the specified private image. After you delete permissions for an image, AWS accounts to which you previously granted these permissions can no longer use the image."},{"ref":"AWS.AppStream.html#delete_stack/3","title":"AWS.AppStream.delete_stack/3","type":"function","doc":"Deletes the specified stack. After the stack is deleted, the application streaming environment provided by the stack is no longer available to users. Also, any reservations made for application streaming sessions for the stack are released."},{"ref":"AWS.AppStream.html#delete_usage_report_subscription/3","title":"AWS.AppStream.delete_usage_report_subscription/3","type":"function","doc":"Disables usage report generation."},{"ref":"AWS.AppStream.html#delete_user/3","title":"AWS.AppStream.delete_user/3","type":"function","doc":"Deletes a user from the user pool."},{"ref":"AWS.AppStream.html#describe_directory_configs/3","title":"AWS.AppStream.describe_directory_configs/3","type":"function","doc":"Retrieves a list that describes one or more specified Directory Config objects for AppStream 2.0, if the names for these objects are provided. Otherwise, all Directory Config objects in the account are described. These objects include the configuration information required to join fleets and image builders to Microsoft Active Directory domains. Although the response syntax in this topic includes the account password, this password is not returned in the actual response."},{"ref":"AWS.AppStream.html#describe_fleets/3","title":"AWS.AppStream.describe_fleets/3","type":"function","doc":"Retrieves a list that describes one or more specified fleets, if the fleet names are provided. Otherwise, all fleets in the account are described."},{"ref":"AWS.AppStream.html#describe_image_builders/3","title":"AWS.AppStream.describe_image_builders/3","type":"function","doc":"Retrieves a list that describes one or more specified image builders, if the image builder names are provided. Otherwise, all image builders in the account are described."},{"ref":"AWS.AppStream.html#describe_image_permissions/3","title":"AWS.AppStream.describe_image_permissions/3","type":"function","doc":"Retrieves a list that describes the permissions for shared AWS account IDs on a private image that you own."},{"ref":"AWS.AppStream.html#describe_images/3","title":"AWS.AppStream.describe_images/3","type":"function","doc":"Retrieves a list that describes one or more specified images, if the image names or image ARNs are provided. Otherwise, all images in the account are described."},{"ref":"AWS.AppStream.html#describe_sessions/3","title":"AWS.AppStream.describe_sessions/3","type":"function","doc":"Retrieves a list that describes the streaming sessions for a specified stack and fleet. If a UserId is provided for the stack and fleet, only streaming sessions for that user are described. If an authentication type is not provided, the default is to authenticate users using a streaming URL."},{"ref":"AWS.AppStream.html#describe_stacks/3","title":"AWS.AppStream.describe_stacks/3","type":"function","doc":"Retrieves a list that describes one or more specified stacks, if the stack names are provided. Otherwise, all stacks in the account are described."},{"ref":"AWS.AppStream.html#describe_usage_report_subscriptions/3","title":"AWS.AppStream.describe_usage_report_subscriptions/3","type":"function","doc":"Retrieves a list that describes one or more usage report subscriptions."},{"ref":"AWS.AppStream.html#describe_user_stack_associations/3","title":"AWS.AppStream.describe_user_stack_associations/3","type":"function","doc":"Retrieves a list that describes the UserStackAssociation objects. You must specify either or both of the following: The stack name The user name (email address of the user associated with the stack) and the authentication type for the user"},{"ref":"AWS.AppStream.html#describe_users/3","title":"AWS.AppStream.describe_users/3","type":"function","doc":"Retrieves a list that describes one or more specified users in the user pool."},{"ref":"AWS.AppStream.html#disable_user/3","title":"AWS.AppStream.disable_user/3","type":"function","doc":"Disables the specified user in the user pool. Users can&#39;t sign in to AppStream 2.0 until they are re-enabled. This action does not delete the user."},{"ref":"AWS.AppStream.html#disassociate_fleet/3","title":"AWS.AppStream.disassociate_fleet/3","type":"function","doc":"Disassociates the specified fleet from the specified stack."},{"ref":"AWS.AppStream.html#enable_user/3","title":"AWS.AppStream.enable_user/3","type":"function","doc":"Enables a user in the user pool. After being enabled, users can sign in to AppStream 2.0 and open applications from the stacks to which they are assigned."},{"ref":"AWS.AppStream.html#expire_session/3","title":"AWS.AppStream.expire_session/3","type":"function","doc":"Immediately stops the specified streaming session."},{"ref":"AWS.AppStream.html#list_associated_fleets/3","title":"AWS.AppStream.list_associated_fleets/3","type":"function","doc":"Retrieves the name of the fleet that is associated with the specified stack."},{"ref":"AWS.AppStream.html#list_associated_stacks/3","title":"AWS.AppStream.list_associated_stacks/3","type":"function","doc":"Retrieves the name of the stack with which the specified fleet is associated."},{"ref":"AWS.AppStream.html#list_tags_for_resource/3","title":"AWS.AppStream.list_tags_for_resource/3","type":"function","doc":"Retrieves a list of all tags for the specified AppStream 2.0 resource. You can tag AppStream 2.0 image builders, images, fleets, and stacks. For more information about tags, see Tagging Your Resources in the Amazon AppStream 2.0 Administration Guide."},{"ref":"AWS.AppStream.html#start_fleet/3","title":"AWS.AppStream.start_fleet/3","type":"function","doc":"Starts the specified fleet."},{"ref":"AWS.AppStream.html#start_image_builder/3","title":"AWS.AppStream.start_image_builder/3","type":"function","doc":"Starts the specified image builder."},{"ref":"AWS.AppStream.html#stop_fleet/3","title":"AWS.AppStream.stop_fleet/3","type":"function","doc":"Stops the specified fleet."},{"ref":"AWS.AppStream.html#stop_image_builder/3","title":"AWS.AppStream.stop_image_builder/3","type":"function","doc":"Stops the specified image builder."},{"ref":"AWS.AppStream.html#tag_resource/3","title":"AWS.AppStream.tag_resource/3","type":"function","doc":"Adds or overwrites one or more tags for the specified AppStream 2.0 resource. You can tag AppStream 2.0 image builders, images, fleets, and stacks. Each tag consists of a key and an optional value. If a resource already has a tag with the same key, this operation updates its value. To list the current tags for your resources, use ListTagsForResource. To disassociate tags from your resources, use UntagResource. For more information about tags, see Tagging Your Resources in the Amazon AppStream 2.0 Administration Guide."},{"ref":"AWS.AppStream.html#untag_resource/3","title":"AWS.AppStream.untag_resource/3","type":"function","doc":"Disassociates one or more specified tags from the specified AppStream 2.0 resource. To list the current tags for your resources, use ListTagsForResource. For more information about tags, see Tagging Your Resources in the Amazon AppStream 2.0 Administration Guide."},{"ref":"AWS.AppStream.html#update_directory_config/3","title":"AWS.AppStream.update_directory_config/3","type":"function","doc":"Updates the specified Directory Config object in AppStream 2.0. This object includes the configuration information required to join fleets and image builders to Microsoft Active Directory domains."},{"ref":"AWS.AppStream.html#update_fleet/3","title":"AWS.AppStream.update_fleet/3","type":"function","doc":"Updates the specified fleet. If the fleet is in the STOPPED state, you can update any attribute except the fleet name. If the fleet is in the RUNNING state, you can update the DisplayName, ComputeCapacity, ImageARN, ImageName, IdleDisconnectTimeoutInSeconds, and DisconnectTimeoutInSeconds attributes. If the fleet is in the STARTING or STOPPING state, you can&#39;t update it."},{"ref":"AWS.AppStream.html#update_image_permissions/3","title":"AWS.AppStream.update_image_permissions/3","type":"function","doc":"Adds or updates permissions for the specified private image."},{"ref":"AWS.AppStream.html#update_stack/3","title":"AWS.AppStream.update_stack/3","type":"function","doc":"Updates the specified fields for the specified stack."},{"ref":"AWS.AppSync.html","title":"AWS.AppSync","type":"module","doc":"AWS AppSync provides API actions for creating and interacting with data sources using GraphQL from your application."},{"ref":"AWS.AppSync.html#create_api_cache/4","title":"AWS.AppSync.create_api_cache/4","type":"function","doc":"Creates a cache for the GraphQL API."},{"ref":"AWS.AppSync.html#create_api_key/4","title":"AWS.AppSync.create_api_key/4","type":"function","doc":"Creates a unique key that you can distribute to clients who are executing your API."},{"ref":"AWS.AppSync.html#create_data_source/4","title":"AWS.AppSync.create_data_source/4","type":"function","doc":"Creates a DataSource object."},{"ref":"AWS.AppSync.html#create_function/4","title":"AWS.AppSync.create_function/4","type":"function","doc":"Creates a Function object. A function is a reusable entity. Multiple functions can be used to compose the resolver logic."},{"ref":"AWS.AppSync.html#create_graphql_api/3","title":"AWS.AppSync.create_graphql_api/3","type":"function","doc":"Creates a GraphqlApi object."},{"ref":"AWS.AppSync.html#create_resolver/5","title":"AWS.AppSync.create_resolver/5","type":"function","doc":"Creates a Resolver object. A resolver converts incoming requests into a format that a data source can understand and converts the data source&#39;s responses into GraphQL."},{"ref":"AWS.AppSync.html#create_type/4","title":"AWS.AppSync.create_type/4","type":"function","doc":"Creates a Type object."},{"ref":"AWS.AppSync.html#delete_api_cache/4","title":"AWS.AppSync.delete_api_cache/4","type":"function","doc":"Deletes an ApiCache object."},{"ref":"AWS.AppSync.html#delete_api_key/5","title":"AWS.AppSync.delete_api_key/5","type":"function","doc":"Deletes an API key."},{"ref":"AWS.AppSync.html#delete_data_source/5","title":"AWS.AppSync.delete_data_source/5","type":"function","doc":"Deletes a DataSource object."},{"ref":"AWS.AppSync.html#delete_function/5","title":"AWS.AppSync.delete_function/5","type":"function","doc":"Deletes a Function."},{"ref":"AWS.AppSync.html#delete_graphql_api/4","title":"AWS.AppSync.delete_graphql_api/4","type":"function","doc":"Deletes a GraphqlApi object."},{"ref":"AWS.AppSync.html#delete_resolver/6","title":"AWS.AppSync.delete_resolver/6","type":"function","doc":"Deletes a Resolver object."},{"ref":"AWS.AppSync.html#delete_type/5","title":"AWS.AppSync.delete_type/5","type":"function","doc":"Deletes a Type object."},{"ref":"AWS.AppSync.html#flush_api_cache/4","title":"AWS.AppSync.flush_api_cache/4","type":"function","doc":"Flushes an ApiCache object."},{"ref":"AWS.AppSync.html#get_api_cache/3","title":"AWS.AppSync.get_api_cache/3","type":"function","doc":"Retrieves an ApiCache object."},{"ref":"AWS.AppSync.html#get_data_source/4","title":"AWS.AppSync.get_data_source/4","type":"function","doc":"Retrieves a DataSource object."},{"ref":"AWS.AppSync.html#get_function/4","title":"AWS.AppSync.get_function/4","type":"function","doc":"Get a Function."},{"ref":"AWS.AppSync.html#get_graphql_api/3","title":"AWS.AppSync.get_graphql_api/3","type":"function","doc":"Retrieves a GraphqlApi object."},{"ref":"AWS.AppSync.html#get_introspection_schema/5","title":"AWS.AppSync.get_introspection_schema/5","type":"function","doc":"Retrieves the introspection schema for a GraphQL API."},{"ref":"AWS.AppSync.html#get_resolver/5","title":"AWS.AppSync.get_resolver/5","type":"function","doc":"Retrieves a Resolver object."},{"ref":"AWS.AppSync.html#get_schema_creation_status/3","title":"AWS.AppSync.get_schema_creation_status/3","type":"function","doc":"Retrieves the current status of a schema creation operation."},{"ref":"AWS.AppSync.html#get_type/5","title":"AWS.AppSync.get_type/5","type":"function","doc":"Retrieves a Type object."},{"ref":"AWS.AppSync.html#list_api_keys/5","title":"AWS.AppSync.list_api_keys/5","type":"function","doc":"Lists the API keys for a given API. API keys are deleted automatically 60 days after they expire. However, they may still be included in the response until they have actually been deleted. You can safely call DeleteApiKey to manually delete a key before it&#39;s automatically deleted."},{"ref":"AWS.AppSync.html#list_data_sources/5","title":"AWS.AppSync.list_data_sources/5","type":"function","doc":"Lists the data sources for a given API."},{"ref":"AWS.AppSync.html#list_functions/5","title":"AWS.AppSync.list_functions/5","type":"function","doc":"List multiple functions."},{"ref":"AWS.AppSync.html#list_graphql_apis/4","title":"AWS.AppSync.list_graphql_apis/4","type":"function","doc":"Lists your GraphQL APIs."},{"ref":"AWS.AppSync.html#list_resolvers/6","title":"AWS.AppSync.list_resolvers/6","type":"function","doc":"Lists the resolvers for a given API and type."},{"ref":"AWS.AppSync.html#list_resolvers_by_function/6","title":"AWS.AppSync.list_resolvers_by_function/6","type":"function","doc":"List the resolvers that are associated with a specific function."},{"ref":"AWS.AppSync.html#list_tags_for_resource/3","title":"AWS.AppSync.list_tags_for_resource/3","type":"function","doc":"Lists the tags for a resource."},{"ref":"AWS.AppSync.html#list_types/6","title":"AWS.AppSync.list_types/6","type":"function","doc":"Lists the types for a given API."},{"ref":"AWS.AppSync.html#start_schema_creation/4","title":"AWS.AppSync.start_schema_creation/4","type":"function","doc":"Adds a new schema to your GraphQL API. This operation is asynchronous. Use to determine when it has completed."},{"ref":"AWS.AppSync.html#tag_resource/4","title":"AWS.AppSync.tag_resource/4","type":"function","doc":"Tags a resource with user-supplied tags."},{"ref":"AWS.AppSync.html#untag_resource/4","title":"AWS.AppSync.untag_resource/4","type":"function","doc":"Untags a resource."},{"ref":"AWS.AppSync.html#update_api_cache/4","title":"AWS.AppSync.update_api_cache/4","type":"function","doc":"Updates the cache for the GraphQL API."},{"ref":"AWS.AppSync.html#update_api_key/5","title":"AWS.AppSync.update_api_key/5","type":"function","doc":"Updates an API key. The key can be updated while it is not deleted."},{"ref":"AWS.AppSync.html#update_data_source/5","title":"AWS.AppSync.update_data_source/5","type":"function","doc":"Updates a DataSource object."},{"ref":"AWS.AppSync.html#update_function/5","title":"AWS.AppSync.update_function/5","type":"function","doc":"Updates a Function object."},{"ref":"AWS.AppSync.html#update_graphql_api/4","title":"AWS.AppSync.update_graphql_api/4","type":"function","doc":"Updates a GraphqlApi object."},{"ref":"AWS.AppSync.html#update_resolver/6","title":"AWS.AppSync.update_resolver/6","type":"function","doc":"Updates a Resolver object."},{"ref":"AWS.AppSync.html#update_type/5","title":"AWS.AppSync.update_type/5","type":"function","doc":"Updates a Type object."},{"ref":"AWS.Appflow.html","title":"AWS.Appflow","type":"module","doc":"Welcome to the Amazon AppFlow API reference. This guide is for developers who need detailed information about the Amazon AppFlow API operations, data types, and errors. Amazon AppFlow is a fully managed integration service that enables you to securely transfer data between software as a service (SaaS) applications like Salesforce, Marketo, Slack, and ServiceNow, and AWS services like Amazon S3 and Amazon Redshift. Use the following links to get started on the Amazon AppFlow API: Actions: An alphabetical list of all Amazon AppFlow API operations. Data types: An alphabetical list of all Amazon AppFlow data types. Common parameters: Parameters that all Query operations can use. Common errors: Client and server errors that all operations can return. If you&#39;re new to Amazon AppFlow, we recommend that you review the Amazon AppFlow User Guide. Amazon AppFlow API users can use vendor-specific mechanisms for OAuth, and include applicable OAuth attributes (such as auth-code and redirecturi) with the connector-specific ConnectorProfileProperties when creating a new connector profile using Amazon AppFlow API operations. For example, Salesforce users can refer to the Authorize Apps with OAuth documentation."},{"ref":"AWS.Appflow.html#create_connector_profile/3","title":"AWS.Appflow.create_connector_profile/3","type":"function","doc":"Creates a new connector profile associated with your AWS account. There is a soft quota of 100 connector profiles per AWS account. If you need more connector profiles than this quota allows, you can submit a request to the Amazon AppFlow team through the Amazon AppFlow support channel."},{"ref":"AWS.Appflow.html#create_flow/3","title":"AWS.Appflow.create_flow/3","type":"function","doc":"Enables your application to create a new flow using Amazon AppFlow. You must create a connector profile before calling this API. Please note that the Request Syntax below shows syntax for multiple destinations, however, you can only transfer data to one item in this list at a time. Amazon AppFlow does not currently support flows to multiple destinations at once."},{"ref":"AWS.Appflow.html#delete_connector_profile/3","title":"AWS.Appflow.delete_connector_profile/3","type":"function","doc":"Enables you to delete an existing connector profile."},{"ref":"AWS.Appflow.html#delete_flow/3","title":"AWS.Appflow.delete_flow/3","type":"function","doc":"Enables your application to delete an existing flow. Before deleting the flow, Amazon AppFlow validates the request by checking the flow configuration and status. You can delete flows one at a time."},{"ref":"AWS.Appflow.html#describe_connector_entity/3","title":"AWS.Appflow.describe_connector_entity/3","type":"function","doc":"Provides details regarding the entity used with the connector, with a description of the data model for each entity."},{"ref":"AWS.Appflow.html#describe_connector_profiles/3","title":"AWS.Appflow.describe_connector_profiles/3","type":"function","doc":"Returns a list of connector-profile details matching the provided connector-profile names and connector-types. Both input lists are optional, and you can use them to filter the result. If no names or connector-types are provided, returns all connector profiles in a paginated form. If there is no match, this operation returns an empty list."},{"ref":"AWS.Appflow.html#describe_connectors/3","title":"AWS.Appflow.describe_connectors/3","type":"function","doc":"Describes the connectors vended by Amazon AppFlow for specified connector types. If you don&#39;t specify a connector type, this operation describes all connectors vended by Amazon AppFlow. If there are more connectors than can be returned in one page, the response contains a nextToken object, which can be be passed in to the next call to the DescribeConnectors API operation to retrieve the next page."},{"ref":"AWS.Appflow.html#describe_flow/3","title":"AWS.Appflow.describe_flow/3","type":"function","doc":"Provides a description of the specified flow."},{"ref":"AWS.Appflow.html#describe_flow_execution_records/3","title":"AWS.Appflow.describe_flow_execution_records/3","type":"function","doc":"Fetches the execution history of the flow."},{"ref":"AWS.Appflow.html#list_connector_entities/3","title":"AWS.Appflow.list_connector_entities/3","type":"function","doc":"Returns the list of available connector entities supported by Amazon AppFlow. For example, you can query Salesforce for Account and Opportunity entities, or query ServiceNow for the Incident entity."},{"ref":"AWS.Appflow.html#list_flows/3","title":"AWS.Appflow.list_flows/3","type":"function","doc":"Lists all of the flows associated with your account."},{"ref":"AWS.Appflow.html#list_tags_for_resource/3","title":"AWS.Appflow.list_tags_for_resource/3","type":"function","doc":"Retrieves the tags that are associated with a specified flow."},{"ref":"AWS.Appflow.html#start_flow/3","title":"AWS.Appflow.start_flow/3","type":"function","doc":"Activates an existing flow. For on-demand flows, this operation runs the flow immediately. For schedule and event-triggered flows, this operation activates the flow."},{"ref":"AWS.Appflow.html#stop_flow/3","title":"AWS.Appflow.stop_flow/3","type":"function","doc":"Deactivates the existing flow. For on-demand flows, this operation returns an unsupportedOperationException error message. For schedule and event-triggered flows, this operation deactivates the flow."},{"ref":"AWS.Appflow.html#tag_resource/4","title":"AWS.Appflow.tag_resource/4","type":"function","doc":"Applies a tag to the specified flow."},{"ref":"AWS.Appflow.html#untag_resource/4","title":"AWS.Appflow.untag_resource/4","type":"function","doc":"Removes a tag from the specified flow."},{"ref":"AWS.Appflow.html#update_connector_profile/3","title":"AWS.Appflow.update_connector_profile/3","type":"function","doc":"Updates a given connector profile associated with your account."},{"ref":"AWS.Appflow.html#update_flow/3","title":"AWS.Appflow.update_flow/3","type":"function","doc":"Updates an existing flow."},{"ref":"AWS.ApplicationAutoScaling.html","title":"AWS.ApplicationAutoScaling","type":"module","doc":"With Application Auto Scaling, you can configure automatic scaling for the following resources: Amazon ECS services Amazon EC2 Spot Fleet requests Amazon EMR clusters Amazon AppStream 2.0 fleets Amazon DynamoDB tables and global secondary indexes throughput capacity Amazon Aurora Replicas Amazon SageMaker endpoint variants Custom resources provided by your own applications or services Amazon Comprehend document classification and entity recognizer endpoints AWS Lambda function provisioned concurrency Amazon Keyspaces (for Apache Cassandra) tables Amazon Managed Streaming for Apache Kafka cluster storage API Summary The Application Auto Scaling service API includes three key sets of actions: Register and manage scalable targets - Register AWS or custom resources as scalable targets (a resource that Application Auto Scaling can scale), set minimum and maximum capacity limits, and retrieve information on existing scalable targets. Configure and manage automatic scaling - Define scaling policies to dynamically scale your resources in response to CloudWatch alarms, schedule one-time or recurring scaling actions, and retrieve your recent scaling activity history. Suspend and resume scaling - Temporarily suspend and later resume automatic scaling by calling the RegisterScalableTarget API action for any Application Auto Scaling scalable target. You can suspend and resume (individually or in combination) scale-out activities that are triggered by a scaling policy, scale-in activities that are triggered by a scaling policy, and scheduled scaling. To learn more about Application Auto Scaling, including information about granting IAM users required permissions for Application Auto Scaling actions, see the Application Auto Scaling User Guide."},{"ref":"AWS.ApplicationAutoScaling.html#delete_scaling_policy/3","title":"AWS.ApplicationAutoScaling.delete_scaling_policy/3","type":"function","doc":"Deletes the specified scaling policy for an Application Auto Scaling scalable target. Deleting a step scaling policy deletes the underlying alarm action, but does not delete the CloudWatch alarm associated with the scaling policy, even if it no longer has an associated action. For more information, see Delete a Step Scaling Policy and Delete a Target Tracking Scaling Policy in the Application Auto Scaling User Guide."},{"ref":"AWS.ApplicationAutoScaling.html#delete_scheduled_action/3","title":"AWS.ApplicationAutoScaling.delete_scheduled_action/3","type":"function","doc":"Deletes the specified scheduled action for an Application Auto Scaling scalable target. For more information, see Delete a Scheduled Action in the Application Auto Scaling User Guide."},{"ref":"AWS.ApplicationAutoScaling.html#deregister_scalable_target/3","title":"AWS.ApplicationAutoScaling.deregister_scalable_target/3","type":"function","doc":"Deregisters an Application Auto Scaling scalable target when you have finished using it. To see which resources have been registered, use DescribeScalableTargets. Deregistering a scalable target deletes the scaling policies and the scheduled actions that are associated with it."},{"ref":"AWS.ApplicationAutoScaling.html#describe_scalable_targets/3","title":"AWS.ApplicationAutoScaling.describe_scalable_targets/3","type":"function","doc":"Gets information about the scalable targets in the specified namespace. You can filter the results using ResourceIds and ScalableDimension."},{"ref":"AWS.ApplicationAutoScaling.html#describe_scaling_activities/3","title":"AWS.ApplicationAutoScaling.describe_scaling_activities/3","type":"function","doc":"Provides descriptive information about the scaling activities in the specified namespace from the previous six weeks. You can filter the results using ResourceId and ScalableDimension."},{"ref":"AWS.ApplicationAutoScaling.html#describe_scaling_policies/3","title":"AWS.ApplicationAutoScaling.describe_scaling_policies/3","type":"function","doc":"Describes the Application Auto Scaling scaling policies for the specified service namespace. You can filter the results using ResourceId, ScalableDimension, and PolicyNames. For more information, see Target Tracking Scaling Policies and Step Scaling Policies in the Application Auto Scaling User Guide."},{"ref":"AWS.ApplicationAutoScaling.html#describe_scheduled_actions/3","title":"AWS.ApplicationAutoScaling.describe_scheduled_actions/3","type":"function","doc":"Describes the Application Auto Scaling scheduled actions for the specified service namespace. You can filter the results using the ResourceId, ScalableDimension, and ScheduledActionNames parameters. For more information, see Scheduled Scaling in the Application Auto Scaling User Guide."},{"ref":"AWS.ApplicationAutoScaling.html#put_scaling_policy/3","title":"AWS.ApplicationAutoScaling.put_scaling_policy/3","type":"function","doc":"Creates or updates a scaling policy for an Application Auto Scaling scalable target. Each scalable target is identified by a service namespace, resource ID, and scalable dimension. A scaling policy applies to the scalable target identified by those three attributes. You cannot create a scaling policy until you have registered the resource as a scalable target. Multiple scaling policies can be in force at the same time for the same scalable target. You can have one or more target tracking scaling policies, one or more step scaling policies, or both. However, there is a chance that multiple policies could conflict, instructing the scalable target to scale out or in at the same time. Application Auto Scaling gives precedence to the policy that provides the largest capacity for both scale out and scale in. For example, if one policy increases capacity by 3, another policy increases capacity by 200 percent, and the current capacity is 10, Application Auto Scaling uses the policy with the highest calculated capacity (200% of 10 = 20) and scales out to 30. We recommend caution, however, when using target tracking scaling policies with step scaling policies because conflicts between these policies can cause undesirable behavior. For example, if the step scaling policy initiates a scale-in activity before the target tracking policy is ready to scale in, the scale-in activity will not be blocked. After the scale-in activity completes, the target tracking policy could instruct the scalable target to scale out again. For more information, see Target Tracking Scaling Policies and Step Scaling Policies in the Application Auto Scaling User Guide. If a scalable target is deregistered, the scalable target is no longer available to execute scaling policies. Any scaling policies that were specified for the scalable target are deleted."},{"ref":"AWS.ApplicationAutoScaling.html#put_scheduled_action/3","title":"AWS.ApplicationAutoScaling.put_scheduled_action/3","type":"function","doc":"Creates or updates a scheduled action for an Application Auto Scaling scalable target. Each scalable target is identified by a service namespace, resource ID, and scalable dimension. A scheduled action applies to the scalable target identified by those three attributes. You cannot create a scheduled action until you have registered the resource as a scalable target. When start and end times are specified with a recurring schedule using a cron expression or rates, they form the boundaries of when the recurring action starts and stops. To update a scheduled action, specify the parameters that you want to change. If you don&#39;t specify start and end times, the old values are deleted. For more information, see Scheduled Scaling in the Application Auto Scaling User Guide. If a scalable target is deregistered, the scalable target is no longer available to run scheduled actions. Any scheduled actions that were specified for the scalable target are deleted."},{"ref":"AWS.ApplicationAutoScaling.html#register_scalable_target/3","title":"AWS.ApplicationAutoScaling.register_scalable_target/3","type":"function","doc":"Registers or updates a scalable target. A scalable target is a resource that Application Auto Scaling can scale out and scale in. Scalable targets are uniquely identified by the combination of resource ID, scalable dimension, and namespace. When you register a new scalable target, you must specify values for minimum and maximum capacity. Current capacity will be adjusted within the specified range when scaling starts. Application Auto Scaling scaling policies will not scale capacity to values that are outside of this range. After you register a scalable target, you do not need to register it again to use other Application Auto Scaling operations. To see which resources have been registered, use DescribeScalableTargets. You can also view the scaling policies for a service namespace by using DescribeScalableTargets. If you no longer need a scalable target, you can deregister it by using DeregisterScalableTarget. To update a scalable target, specify the parameters that you want to change. Include the parameters that identify the scalable target: resource ID, scalable dimension, and namespace. Any parameters that you don&#39;t specify are not changed by this update request."},{"ref":"AWS.ApplicationDiscovery.html","title":"AWS.ApplicationDiscovery","type":"module","doc":"AWS Application Discovery Service AWS Application Discovery Service helps you plan application migration projects. It automatically identifies servers, virtual machines (VMs), and network dependencies in your on-premises data centers. For more information, see the AWS Application Discovery Service FAQ. Application Discovery Service offers three ways of performing discovery and collecting data about your on-premises servers: Agentless discovery is recommended for environments that use VMware vCenter Server. This mode doesn&#39;t require you to install an agent on each host. It does not work in non-VMware environments. Agentless discovery gathers server information regardless of the operating systems, which minimizes the time required for initial on-premises infrastructure assessment. Agentless discovery doesn&#39;t collect information about network dependencies, only agent-based discovery collects that information. Agent-based discovery collects a richer set of data than agentless discovery by using the AWS Application Discovery Agent, which you install on one or more hosts in your data center. The agent captures infrastructure and application information, including an inventory of running processes, system performance information, resource utilization, and network dependencies. The information collected by agents is secured at rest and in transit to the Application Discovery Service database in the cloud. AWS Partner Network (APN) solutions integrate with Application Discovery Service, enabling you to import details of your on-premises environment directly into Migration Hub without using the discovery connector or discovery agent. Third-party application discovery tools can query AWS Application Discovery Service, and they can write to the Application Discovery Service database using the public API. In this way, you can import data into Migration Hub and view it, so that you can associate applications with servers and track migrations. Recommendations We recommend that you use agent-based discovery for non-VMware environments, and whenever you want to collect information about network dependencies. You can run agent-based and agentless discovery simultaneously. Use agentless discovery to complete the initial infrastructure assessment quickly, and then install agents on select hosts to collect additional information. Working With This Guide This API reference provides descriptions, syntax, and usage examples for each of the actions and data types for Application Discovery Service. The topic for each action shows the API request parameters and the response. Alternatively, you can use one of the AWS SDKs to access an API that is tailored to the programming language or platform that you&#39;re using. For more information, see AWS SDKs. Remember that you must set your Migration Hub home region before you call any of these APIs. You must make API calls for write actions (create, notify, associate, disassociate, import, or put) while in your home region, or a HomeRegionNotSetException error is returned. API calls for read actions (list, describe, stop, and delete) are permitted outside of your home region. Although it is unlikely, the Migration Hub home region could change. If you call APIs outside the home region, an InvalidInputException is returned. You must call GetHomeRegion to obtain the latest Migration Hub home region. This guide is intended for use with the AWS Application Discovery Service User Guide. All data is handled according to the AWS Privacy Policy. You can operate Application Discovery Service offline to inspect collected data before it is shared with the service."},{"ref":"AWS.ApplicationDiscovery.html#associate_configuration_items_to_application/3","title":"AWS.ApplicationDiscovery.associate_configuration_items_to_application/3","type":"function","doc":"Associates one or more configuration items with an application."},{"ref":"AWS.ApplicationDiscovery.html#batch_delete_import_data/3","title":"AWS.ApplicationDiscovery.batch_delete_import_data/3","type":"function","doc":"Deletes one or more import tasks, each identified by their import ID. Each import task has a number of records that can identify servers or applications. AWS Application Discovery Service has built-in matching logic that will identify when discovered servers match existing entries that you&#39;ve previously discovered, the information for the already-existing discovered server is updated. When you delete an import task that contains records that were used to match, the information in those matched records that comes from the deleted records will also be deleted."},{"ref":"AWS.ApplicationDiscovery.html#create_application/3","title":"AWS.ApplicationDiscovery.create_application/3","type":"function","doc":"Creates an application with the given name and description."},{"ref":"AWS.ApplicationDiscovery.html#create_tags/3","title":"AWS.ApplicationDiscovery.create_tags/3","type":"function","doc":"Creates one or more tags for configuration items. Tags are metadata that help you categorize IT assets. This API accepts a list of multiple configuration items."},{"ref":"AWS.ApplicationDiscovery.html#delete_applications/3","title":"AWS.ApplicationDiscovery.delete_applications/3","type":"function","doc":"Deletes a list of applications and their associations with configuration items."},{"ref":"AWS.ApplicationDiscovery.html#delete_tags/3","title":"AWS.ApplicationDiscovery.delete_tags/3","type":"function","doc":"Deletes the association between configuration items and one or more tags. This API accepts a list of multiple configuration items."},{"ref":"AWS.ApplicationDiscovery.html#describe_agents/3","title":"AWS.ApplicationDiscovery.describe_agents/3","type":"function","doc":"Lists agents or connectors as specified by ID or other filters. All agents/connectors associated with your user account can be listed if you call DescribeAgents as is without passing any parameters."},{"ref":"AWS.ApplicationDiscovery.html#describe_configurations/3","title":"AWS.ApplicationDiscovery.describe_configurations/3","type":"function","doc":"Retrieves attributes for a list of configuration item IDs. All of the supplied IDs must be for the same asset type from one of the following: server application process connection Output fields are specific to the asset type specified. For example, the output for a server configuration item includes a list of attributes about the server, such as host name, operating system, number of network cards, etc. For a complete list of outputs for each asset type, see Using the DescribeConfigurations Action in the AWS Application Discovery Service User Guide."},{"ref":"AWS.ApplicationDiscovery.html#describe_continuous_exports/3","title":"AWS.ApplicationDiscovery.describe_continuous_exports/3","type":"function","doc":"Lists exports as specified by ID. All continuous exports associated with your user account can be listed if you call DescribeContinuousExports as is without passing any parameters."},{"ref":"AWS.ApplicationDiscovery.html#describe_export_configurations/3","title":"AWS.ApplicationDiscovery.describe_export_configurations/3","type":"function","doc":"DescribeExportConfigurations is deprecated. Use DescribeImportTasks, instead."},{"ref":"AWS.ApplicationDiscovery.html#describe_export_tasks/3","title":"AWS.ApplicationDiscovery.describe_export_tasks/3","type":"function","doc":"Retrieve status of one or more export tasks. You can retrieve the status of up to 100 export tasks."},{"ref":"AWS.ApplicationDiscovery.html#describe_import_tasks/3","title":"AWS.ApplicationDiscovery.describe_import_tasks/3","type":"function","doc":"Returns an array of import tasks for your account, including status information, times, IDs, the Amazon S3 Object URL for the import file, and more."},{"ref":"AWS.ApplicationDiscovery.html#describe_tags/3","title":"AWS.ApplicationDiscovery.describe_tags/3","type":"function","doc":"Retrieves a list of configuration items that have tags as specified by the key-value pairs, name and value, passed to the optional parameter filters. There are three valid tag filter names: tagKey tagValue configurationId Also, all configuration items associated with your user account that have tags can be listed if you call DescribeTags as is without passing any parameters."},{"ref":"AWS.ApplicationDiscovery.html#disassociate_configuration_items_from_application/3","title":"AWS.ApplicationDiscovery.disassociate_configuration_items_from_application/3","type":"function","doc":"Disassociates one or more configuration items from an application."},{"ref":"AWS.ApplicationDiscovery.html#export_configurations/3","title":"AWS.ApplicationDiscovery.export_configurations/3","type":"function","doc":"Deprecated. Use StartExportTask instead. Exports all discovered configuration data to an Amazon S3 bucket or an application that enables you to view and evaluate the data. Data includes tags and tag associations, processes, connections, servers, and system performance. This API returns an export ID that you can query using the DescribeExportConfigurations API. The system imposes a limit of two configuration exports in six hours."},{"ref":"AWS.ApplicationDiscovery.html#get_discovery_summary/3","title":"AWS.ApplicationDiscovery.get_discovery_summary/3","type":"function","doc":"Retrieves a short summary of discovered assets. This API operation takes no request parameters and is called as is at the command prompt as shown in the example."},{"ref":"AWS.ApplicationDiscovery.html#list_configurations/3","title":"AWS.ApplicationDiscovery.list_configurations/3","type":"function","doc":"Retrieves a list of configuration items as specified by the value passed to the required parameter configurationType. Optional filtering may be applied to refine search results."},{"ref":"AWS.ApplicationDiscovery.html#list_server_neighbors/3","title":"AWS.ApplicationDiscovery.list_server_neighbors/3","type":"function","doc":"Retrieves a list of servers that are one network hop away from a specified server."},{"ref":"AWS.ApplicationDiscovery.html#start_continuous_export/3","title":"AWS.ApplicationDiscovery.start_continuous_export/3","type":"function","doc":"Start the continuous flow of agent&#39;s discovered data into Amazon Athena."},{"ref":"AWS.ApplicationDiscovery.html#start_data_collection_by_agent_ids/3","title":"AWS.ApplicationDiscovery.start_data_collection_by_agent_ids/3","type":"function","doc":"Instructs the specified agents or connectors to start collecting data."},{"ref":"AWS.ApplicationDiscovery.html#start_export_task/3","title":"AWS.ApplicationDiscovery.start_export_task/3","type":"function","doc":"Begins the export of discovered data to an S3 bucket. If you specify agentIds in a filter, the task exports up to 72 hours of detailed data collected by the identified Application Discovery Agent, including network, process, and performance details. A time range for exported agent data may be set by using startTime and endTime. Export of detailed agent data is limited to five concurrently running exports. If you do not include an agentIds filter, summary data is exported that includes both AWS Agentless Discovery Connector data and summary data from AWS Discovery Agents. Export of summary data is limited to two exports per day."},{"ref":"AWS.ApplicationDiscovery.html#start_import_task/3","title":"AWS.ApplicationDiscovery.start_import_task/3","type":"function","doc":"Starts an import task, which allows you to import details of your on-premises environment directly into AWS Migration Hub without having to use the Application Discovery Service (ADS) tools such as the Discovery Connector or Discovery Agent. This gives you the option to perform migration assessment and planning directly from your imported data, including the ability to group your devices as applications and track their migration status. To start an import request, do this: Download the specially formatted comma separated value (CSV) import template, which you can find here: https://s3-us-west-2.amazonaws.com/templates-7cffcf56-bd96-4b1c-b45b-a5b42f282e46/import_template.csv. 2. Fill out the template with your server and application data. Upload your import file to an Amazon S3 bucket, and make a note of it&#39;s Object URL. Your import file must be in the CSV format. Use the console or the StartImportTask command with the AWS CLI or one of the AWS SDKs to import the records from your file. For more information, including step-by-step procedures, see Migration Hub Import in the AWS Application Discovery Service User Guide. There are limits to the number of import tasks you can create (and delete) in an AWS account. For more information, see AWS Application Discovery Service Limits in the AWS Application Discovery Service User Guide."},{"ref":"AWS.ApplicationDiscovery.html#stop_continuous_export/3","title":"AWS.ApplicationDiscovery.stop_continuous_export/3","type":"function","doc":"Stop the continuous flow of agent&#39;s discovered data into Amazon Athena."},{"ref":"AWS.ApplicationDiscovery.html#stop_data_collection_by_agent_ids/3","title":"AWS.ApplicationDiscovery.stop_data_collection_by_agent_ids/3","type":"function","doc":"Instructs the specified agents or connectors to stop collecting data."},{"ref":"AWS.ApplicationDiscovery.html#update_application/3","title":"AWS.ApplicationDiscovery.update_application/3","type":"function","doc":"Updates metadata about an application."},{"ref":"AWS.ApplicationInsights.html","title":"AWS.ApplicationInsights","type":"module","doc":"Amazon CloudWatch Application Insights for .NET and SQL Server Amazon CloudWatch Application Insights for .NET and SQL Server is a service that helps you detect common problems with your .NET and SQL Server-based applications. It enables you to pinpoint the source of issues in your applications (built with technologies such as Microsoft IIS, .NET, and Microsoft SQL Server), by providing key insights into detected problems. After you onboard your application, CloudWatch Application Insights for .NET and SQL Server identifies, recommends, and sets up metrics and logs. It continuously analyzes and correlates your metrics and logs for unusual behavior to surface actionable problems with your application. For example, if your application is slow and unresponsive and leading to HTTP 500 errors in your Application Load Balancer (ALB), Application Insights informs you that a memory pressure problem with your SQL Server database is occurring. It bases this analysis on impactful metrics and log errors."},{"ref":"AWS.ApplicationInsights.html#create_application/3","title":"AWS.ApplicationInsights.create_application/3","type":"function","doc":"Adds an application that is created from a resource group."},{"ref":"AWS.ApplicationInsights.html#create_component/3","title":"AWS.ApplicationInsights.create_component/3","type":"function","doc":"Creates a custom component by grouping similar standalone instances to monitor."},{"ref":"AWS.ApplicationInsights.html#create_log_pattern/3","title":"AWS.ApplicationInsights.create_log_pattern/3","type":"function","doc":"Adds an log pattern to a LogPatternSet."},{"ref":"AWS.ApplicationInsights.html#delete_application/3","title":"AWS.ApplicationInsights.delete_application/3","type":"function","doc":"Removes the specified application from monitoring. Does not delete the application."},{"ref":"AWS.ApplicationInsights.html#delete_component/3","title":"AWS.ApplicationInsights.delete_component/3","type":"function","doc":"Ungroups a custom component. When you ungroup custom components, all applicable monitors that are set up for the component are removed and the instances revert to their standalone status."},{"ref":"AWS.ApplicationInsights.html#delete_log_pattern/3","title":"AWS.ApplicationInsights.delete_log_pattern/3","type":"function","doc":"Removes the specified log pattern from a LogPatternSet."},{"ref":"AWS.ApplicationInsights.html#describe_application/3","title":"AWS.ApplicationInsights.describe_application/3","type":"function","doc":"Describes the application."},{"ref":"AWS.ApplicationInsights.html#describe_component/3","title":"AWS.ApplicationInsights.describe_component/3","type":"function","doc":"Describes a component and lists the resources that are grouped together in a component."},{"ref":"AWS.ApplicationInsights.html#describe_component_configuration/3","title":"AWS.ApplicationInsights.describe_component_configuration/3","type":"function","doc":"Describes the monitoring configuration of the component."},{"ref":"AWS.ApplicationInsights.html#describe_component_configuration_recommendation/3","title":"AWS.ApplicationInsights.describe_component_configuration_recommendation/3","type":"function","doc":"Describes the recommended monitoring configuration of the component."},{"ref":"AWS.ApplicationInsights.html#describe_log_pattern/3","title":"AWS.ApplicationInsights.describe_log_pattern/3","type":"function","doc":"Describe a specific log pattern from a LogPatternSet."},{"ref":"AWS.ApplicationInsights.html#describe_observation/3","title":"AWS.ApplicationInsights.describe_observation/3","type":"function","doc":"Describes an anomaly or error with the application."},{"ref":"AWS.ApplicationInsights.html#describe_problem/3","title":"AWS.ApplicationInsights.describe_problem/3","type":"function","doc":"Describes an application problem."},{"ref":"AWS.ApplicationInsights.html#describe_problem_observations/3","title":"AWS.ApplicationInsights.describe_problem_observations/3","type":"function","doc":"Describes the anomalies or errors associated with the problem."},{"ref":"AWS.ApplicationInsights.html#list_applications/3","title":"AWS.ApplicationInsights.list_applications/3","type":"function","doc":"Lists the IDs of the applications that you are monitoring."},{"ref":"AWS.ApplicationInsights.html#list_components/3","title":"AWS.ApplicationInsights.list_components/3","type":"function","doc":"Lists the auto-grouped, standalone, and custom components of the application."},{"ref":"AWS.ApplicationInsights.html#list_configuration_history/3","title":"AWS.ApplicationInsights.list_configuration_history/3","type":"function","doc":"Lists the INFO, WARN, and ERROR events for periodic configuration updates performed by Application Insights. Examples of events represented are: INFO: creating a new alarm or updating an alarm threshold. WARN: alarm not created due to insufficient data points used to predict thresholds. ERROR: alarm not created due to permission errors or exceeding quotas."},{"ref":"AWS.ApplicationInsights.html#list_log_pattern_sets/3","title":"AWS.ApplicationInsights.list_log_pattern_sets/3","type":"function","doc":"Lists the log pattern sets in the specific application."},{"ref":"AWS.ApplicationInsights.html#list_log_patterns/3","title":"AWS.ApplicationInsights.list_log_patterns/3","type":"function","doc":"Lists the log patterns in the specific log LogPatternSet."},{"ref":"AWS.ApplicationInsights.html#list_problems/3","title":"AWS.ApplicationInsights.list_problems/3","type":"function","doc":"Lists the problems with your application."},{"ref":"AWS.ApplicationInsights.html#list_tags_for_resource/3","title":"AWS.ApplicationInsights.list_tags_for_resource/3","type":"function","doc":"Retrieve a list of the tags (keys and values) that are associated with a specified application. A tag is a label that you optionally define and associate with an application. Each tag consists of a required tag key and an optional associated tag value. A tag key is a general label that acts as a category for more specific tag values. A tag value acts as a descriptor within a tag key."},{"ref":"AWS.ApplicationInsights.html#tag_resource/3","title":"AWS.ApplicationInsights.tag_resource/3","type":"function","doc":"Add one or more tags (keys and values) to a specified application. A tag is a label that you optionally define and associate with an application. Tags can help you categorize and manage application in different ways, such as by purpose, owner, environment, or other criteria. Each tag consists of a required tag key and an associated tag value, both of which you define. A tag key is a general label that acts as a category for more specific tag values. A tag value acts as a descriptor within a tag key."},{"ref":"AWS.ApplicationInsights.html#untag_resource/3","title":"AWS.ApplicationInsights.untag_resource/3","type":"function","doc":"Remove one or more tags (keys and values) from a specified application."},{"ref":"AWS.ApplicationInsights.html#update_application/3","title":"AWS.ApplicationInsights.update_application/3","type":"function","doc":"Updates the application."},{"ref":"AWS.ApplicationInsights.html#update_component/3","title":"AWS.ApplicationInsights.update_component/3","type":"function","doc":"Updates the custom component name and/or the list of resources that make up the component."},{"ref":"AWS.ApplicationInsights.html#update_component_configuration/3","title":"AWS.ApplicationInsights.update_component_configuration/3","type":"function","doc":"Updates the monitoring configurations for the component. The configuration input parameter is an escaped JSON of the configuration and should match the schema of what is returned by DescribeComponentConfigurationRecommendation."},{"ref":"AWS.ApplicationInsights.html#update_log_pattern/3","title":"AWS.ApplicationInsights.update_log_pattern/3","type":"function","doc":"Adds a log pattern to a LogPatternSet."},{"ref":"AWS.Athena.html","title":"AWS.Athena","type":"module","doc":"Amazon Athena is an interactive query service that lets you use standard SQL to analyze data directly in Amazon S3. You can point Athena at your data in Amazon S3 and run ad-hoc queries and get results in seconds. Athena is serverless, so there is no infrastructure to set up or manage. You pay only for the queries you run. Athena scales automaticallyexecuting queries in parallelso results are fast, even with large datasets and complex queries. For more information, see What is Amazon Athena in the Amazon Athena User Guide. If you connect to Athena using the JDBC driver, use version 1.1.0 of the driver or later with the Amazon Athena API. Earlier version drivers do not support the API. For more information and to download the driver, see Accessing Amazon Athena with JDBC. For code samples using the AWS SDK for Java, see Examples and Code Samples in the Amazon Athena User Guide."},{"ref":"AWS.Athena.html#batch_get_named_query/3","title":"AWS.Athena.batch_get_named_query/3","type":"function","doc":"Returns the details of a single named query or a list of up to 50 queries, which you provide as an array of query ID strings. Requires you to have access to the workgroup in which the queries were saved. Use ListNamedQueriesInput to get the list of named query IDs in the specified workgroup. If information could not be retrieved for a submitted query ID, information about the query ID submitted is listed under UnprocessedNamedQueryId. Named queries differ from executed queries. Use BatchGetQueryExecutionInput to get details about each unique query execution, and ListQueryExecutionsInput to get a list of query execution IDs."},{"ref":"AWS.Athena.html#batch_get_query_execution/3","title":"AWS.Athena.batch_get_query_execution/3","type":"function","doc":"Returns the details of a single query execution or a list of up to 50 query executions, which you provide as an array of query execution ID strings. Requires you to have access to the workgroup in which the queries ran. To get a list of query execution IDs, use ListQueryExecutionsInput$WorkGroup. Query executions differ from named (saved) queries. Use BatchGetNamedQueryInput to get details about named queries."},{"ref":"AWS.Athena.html#create_data_catalog/3","title":"AWS.Athena.create_data_catalog/3","type":"function","doc":"Creates (registers) a data catalog with the specified name and properties. Catalogs created are visible to all users of the same AWS account."},{"ref":"AWS.Athena.html#create_named_query/3","title":"AWS.Athena.create_named_query/3","type":"function","doc":"Creates a named query in the specified workgroup. Requires that you have access to the workgroup. For code samples using the AWS SDK for Java, see Examples and Code Samples in the Amazon Athena User Guide."},{"ref":"AWS.Athena.html#create_work_group/3","title":"AWS.Athena.create_work_group/3","type":"function","doc":"Creates a workgroup with the specified name."},{"ref":"AWS.Athena.html#delete_data_catalog/3","title":"AWS.Athena.delete_data_catalog/3","type":"function","doc":"Deletes a data catalog."},{"ref":"AWS.Athena.html#delete_named_query/3","title":"AWS.Athena.delete_named_query/3","type":"function","doc":"Deletes the named query if you have access to the workgroup in which the query was saved. For code samples using the AWS SDK for Java, see Examples and Code Samples in the Amazon Athena User Guide."},{"ref":"AWS.Athena.html#delete_work_group/3","title":"AWS.Athena.delete_work_group/3","type":"function","doc":"Deletes the workgroup with the specified name. The primary workgroup cannot be deleted."},{"ref":"AWS.Athena.html#get_data_catalog/3","title":"AWS.Athena.get_data_catalog/3","type":"function","doc":"Returns the specified data catalog."},{"ref":"AWS.Athena.html#get_database/3","title":"AWS.Athena.get_database/3","type":"function","doc":"Returns a database object for the specfied database and data catalog."},{"ref":"AWS.Athena.html#get_named_query/3","title":"AWS.Athena.get_named_query/3","type":"function","doc":"Returns information about a single query. Requires that you have access to the workgroup in which the query was saved."},{"ref":"AWS.Athena.html#get_query_execution/3","title":"AWS.Athena.get_query_execution/3","type":"function","doc":"Returns information about a single execution of a query if you have access to the workgroup in which the query ran. Each time a query executes, information about the query execution is saved with a unique ID."},{"ref":"AWS.Athena.html#get_query_results/3","title":"AWS.Athena.get_query_results/3","type":"function","doc":"Streams the results of a single query execution specified by QueryExecutionId from the Athena query results location in Amazon S3. For more information, see Query Results in the Amazon Athena User Guide. This request does not execute the query but returns results. Use StartQueryExecution to run a query. To stream query results successfully, the IAM principal with permission to call GetQueryResults also must have permissions to the Amazon S3 GetObject action for the Athena query results location. IAM principals with permission to the Amazon S3 GetObject action for the query results location are able to retrieve query results from Amazon S3 even if permission to the GetQueryResults action is denied. To restrict user or role access, ensure that Amazon S3 permissions to the Athena query location are denied."},{"ref":"AWS.Athena.html#get_table_metadata/3","title":"AWS.Athena.get_table_metadata/3","type":"function","doc":"Returns table metadata for the specified catalog, database, and table."},{"ref":"AWS.Athena.html#get_work_group/3","title":"AWS.Athena.get_work_group/3","type":"function","doc":"Returns information about the workgroup with the specified name."},{"ref":"AWS.Athena.html#list_data_catalogs/3","title":"AWS.Athena.list_data_catalogs/3","type":"function","doc":"Lists the data catalogs in the current AWS account."},{"ref":"AWS.Athena.html#list_databases/3","title":"AWS.Athena.list_databases/3","type":"function","doc":"Lists the databases in the specified data catalog."},{"ref":"AWS.Athena.html#list_named_queries/3","title":"AWS.Athena.list_named_queries/3","type":"function","doc":"Provides a list of available query IDs only for queries saved in the specified workgroup. Requires that you have access to the specified workgroup. If a workgroup is not specified, lists the saved queries for the primary workgroup. For code samples using the AWS SDK for Java, see Examples and Code Samples in the Amazon Athena User Guide."},{"ref":"AWS.Athena.html#list_query_executions/3","title":"AWS.Athena.list_query_executions/3","type":"function","doc":"Provides a list of available query execution IDs for the queries in the specified workgroup. If a workgroup is not specified, returns a list of query execution IDs for the primary workgroup. Requires you to have access to the workgroup in which the queries ran. For code samples using the AWS SDK for Java, see Examples and Code Samples in the Amazon Athena User Guide."},{"ref":"AWS.Athena.html#list_table_metadata/3","title":"AWS.Athena.list_table_metadata/3","type":"function","doc":"Lists the metadata for the tables in the specified data catalog database."},{"ref":"AWS.Athena.html#list_tags_for_resource/3","title":"AWS.Athena.list_tags_for_resource/3","type":"function","doc":"Lists the tags associated with an Athena workgroup or data catalog resource."},{"ref":"AWS.Athena.html#list_work_groups/3","title":"AWS.Athena.list_work_groups/3","type":"function","doc":"Lists available workgroups for the account."},{"ref":"AWS.Athena.html#start_query_execution/3","title":"AWS.Athena.start_query_execution/3","type":"function","doc":"Runs the SQL query statements contained in the Query. Requires you to have access to the workgroup in which the query ran. Running queries against an external catalog requires GetDataCatalog permission to the catalog. For code samples using the AWS SDK for Java, see Examples and Code Samples in the Amazon Athena User Guide."},{"ref":"AWS.Athena.html#stop_query_execution/3","title":"AWS.Athena.stop_query_execution/3","type":"function","doc":"Stops a query execution. Requires you to have access to the workgroup in which the query ran. For code samples using the AWS SDK for Java, see Examples and Code Samples in the Amazon Athena User Guide."},{"ref":"AWS.Athena.html#tag_resource/3","title":"AWS.Athena.tag_resource/3","type":"function","doc":"Adds one or more tags to an Athena resource. A tag is a label that you assign to a resource. In Athena, a resource can be a workgroup or data catalog. Each tag consists of a key and an optional value, both of which you define. For example, you can use tags to categorize Athena workgroups or data catalogs by purpose, owner, or environment. Use a consistent set of tag keys to make it easier to search and filter workgroups or data catalogs in your account. For best practices, see Tagging Best Practices. Tag keys can be from 1 to 128 UTF-8 Unicode characters, and tag values can be from 0 to 256 UTF-8 Unicode characters. Tags can use letters and numbers representable in UTF-8, and the following characters: = . _ : / @. Tag keys and values are case-sensitive. Tag keys must be unique per resource. If you specify more than one tag, separate them by commas."},{"ref":"AWS.Athena.html#untag_resource/3","title":"AWS.Athena.untag_resource/3","type":"function","doc":"Removes one or more tags from a data catalog or workgroup resource."},{"ref":"AWS.Athena.html#update_data_catalog/3","title":"AWS.Athena.update_data_catalog/3","type":"function","doc":"Updates the data catalog that has the specified name."},{"ref":"AWS.Athena.html#update_work_group/3","title":"AWS.Athena.update_work_group/3","type":"function","doc":"Updates the workgroup with the specified name. The workgroup&#39;s name cannot be changed."},{"ref":"AWS.AutoScaling.html","title":"AWS.AutoScaling","type":"module","doc":"Amazon EC2 Auto Scaling Amazon EC2 Auto Scaling is designed to automatically launch or terminate EC2 instances based on user-defined scaling policies, scheduled actions, and health checks. Use this service with AWS Auto Scaling, Amazon CloudWatch, and Elastic Load Balancing. For more information, including information about granting IAM users required permissions for Amazon EC2 Auto Scaling actions, see the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#attach_instances/3","title":"AWS.AutoScaling.attach_instances/3","type":"function","doc":"Attaches one or more EC2 instances to the specified Auto Scaling group. When you attach instances, Amazon EC2 Auto Scaling increases the desired capacity of the group by the number of instances being attached. If the number of instances being attached plus the desired capacity of the group exceeds the maximum size of the group, the operation fails. If there is a Classic Load Balancer attached to your Auto Scaling group, the instances are also registered with the load balancer. If there are target groups attached to your Auto Scaling group, the instances are also registered with the target groups. For more information, see Attach EC2 Instances to Your Auto Scaling Group in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#attach_load_balancer_target_groups/3","title":"AWS.AutoScaling.attach_load_balancer_target_groups/3","type":"function","doc":"Attaches one or more target groups to the specified Auto Scaling group. To describe the target groups for an Auto Scaling group, call the DescribeLoadBalancerTargetGroups API. To detach the target group from the Auto Scaling group, call the DetachLoadBalancerTargetGroups API. With Application Load Balancers and Network Load Balancers, instances are registered as targets with a target group. With Classic Load Balancers, instances are registered with the load balancer. For more information, see Attaching a Load Balancer to Your Auto Scaling Group in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#attach_load_balancers/3","title":"AWS.AutoScaling.attach_load_balancers/3","type":"function","doc":"To attach an Application Load Balancer or a Network Load Balancer, use the AttachLoadBalancerTargetGroups API operation instead. Attaches one or more Classic Load Balancers to the specified Auto Scaling group. Amazon EC2 Auto Scaling registers the running instances with these Classic Load Balancers. To describe the load balancers for an Auto Scaling group, call the DescribeLoadBalancers API. To detach the load balancer from the Auto Scaling group, call the DetachLoadBalancers API. For more information, see Attaching a Load Balancer to Your Auto Scaling Group in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#batch_delete_scheduled_action/3","title":"AWS.AutoScaling.batch_delete_scheduled_action/3","type":"function","doc":"Deletes one or more scheduled actions for the specified Auto Scaling group."},{"ref":"AWS.AutoScaling.html#batch_put_scheduled_update_group_action/3","title":"AWS.AutoScaling.batch_put_scheduled_update_group_action/3","type":"function","doc":"Creates or updates one or more scheduled scaling actions for an Auto Scaling group. If you leave a parameter unspecified when updating a scheduled scaling action, the corresponding value remains unchanged."},{"ref":"AWS.AutoScaling.html#cancel_instance_refresh/3","title":"AWS.AutoScaling.cancel_instance_refresh/3","type":"function","doc":"Cancels an instance refresh operation in progress. Cancellation does not roll back any replacements that have already been completed, but it prevents new replacements from being started. For more information, see Replacing Auto Scaling Instances Based on an Instance Refresh."},{"ref":"AWS.AutoScaling.html#complete_lifecycle_action/3","title":"AWS.AutoScaling.complete_lifecycle_action/3","type":"function","doc":"Completes the lifecycle action for the specified token or instance with the specified result. This step is a part of the procedure for adding a lifecycle hook to an Auto Scaling group: (Optional) Create a Lambda function and a rule that allows CloudWatch Events to invoke your Lambda function when Amazon EC2 Auto Scaling launches or terminates instances. (Optional) Create a notification target and an IAM role. The target can be either an Amazon SQS queue or an Amazon SNS topic. The role allows Amazon EC2 Auto Scaling to publish lifecycle notifications to the target. Create the lifecycle hook. Specify whether the hook is used when the instances launch or terminate. If you need more time, record the lifecycle action heartbeat to keep the instance in a pending state. If you finish before the timeout period ends, complete the lifecycle action. For more information, see Amazon EC2 Auto Scaling Lifecycle Hooks in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#create_auto_scaling_group/3","title":"AWS.AutoScaling.create_auto_scaling_group/3","type":"function","doc":"Creates an Auto Scaling group with the specified name and attributes. If you exceed your maximum limit of Auto Scaling groups, the call fails. To query this limit, call the DescribeAccountLimits API. For information about updating this limit, see Amazon EC2 Auto Scaling Service Quotas in the Amazon EC2 Auto Scaling User Guide. For introductory exercises for creating an Auto Scaling group, see Getting Started with Amazon EC2 Auto Scaling and Tutorial: Set Up a Scaled and Load-Balanced Application in the Amazon EC2 Auto Scaling User Guide. For more information, see Auto Scaling Groups in the Amazon EC2 Auto Scaling User Guide. Every Auto Scaling group has three size parameters (DesiredCapacity, MaxSize, and MinSize). Usually, you set these sizes based on a specific number of instances. However, if you configure a mixed instances policy that defines weights for the instance types, you must specify these sizes with the same units that you use for weighting instances."},{"ref":"AWS.AutoScaling.html#create_launch_configuration/3","title":"AWS.AutoScaling.create_launch_configuration/3","type":"function","doc":"Creates a launch configuration. If you exceed your maximum limit of launch configurations, the call fails. To query this limit, call the DescribeAccountLimits API. For information about updating this limit, see Amazon EC2 Auto Scaling Service Quotas in the Amazon EC2 Auto Scaling User Guide. For more information, see Launch Configurations in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#create_or_update_tags/3","title":"AWS.AutoScaling.create_or_update_tags/3","type":"function","doc":"Creates or updates tags for the specified Auto Scaling group. When you specify a tag with a key that already exists, the operation overwrites the previous tag definition, and you do not get an error message. For more information, see Tagging Auto Scaling Groups and Instances in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#delete_auto_scaling_group/3","title":"AWS.AutoScaling.delete_auto_scaling_group/3","type":"function","doc":"Deletes the specified Auto Scaling group. If the group has instances or scaling activities in progress, you must specify the option to force the deletion in order for it to succeed. If the group has policies, deleting the group deletes the policies, the underlying alarm actions, and any alarm that no longer has an associated action. To remove instances from the Auto Scaling group before deleting it, call the DetachInstances API with the list of instances and the option to decrement the desired capacity. This ensures that Amazon EC2 Auto Scaling does not launch replacement instances. To terminate all instances before deleting the Auto Scaling group, call the UpdateAutoScalingGroup API and set the minimum size and desired capacity of the Auto Scaling group to zero."},{"ref":"AWS.AutoScaling.html#delete_launch_configuration/3","title":"AWS.AutoScaling.delete_launch_configuration/3","type":"function","doc":"Deletes the specified launch configuration. The launch configuration must not be attached to an Auto Scaling group. When this call completes, the launch configuration is no longer available for use."},{"ref":"AWS.AutoScaling.html#delete_lifecycle_hook/3","title":"AWS.AutoScaling.delete_lifecycle_hook/3","type":"function","doc":"Deletes the specified lifecycle hook. If there are any outstanding lifecycle actions, they are completed first (ABANDON for launching instances, CONTINUE for terminating instances)."},{"ref":"AWS.AutoScaling.html#delete_notification_configuration/3","title":"AWS.AutoScaling.delete_notification_configuration/3","type":"function","doc":"Deletes the specified notification."},{"ref":"AWS.AutoScaling.html#delete_policy/3","title":"AWS.AutoScaling.delete_policy/3","type":"function","doc":"Deletes the specified scaling policy. Deleting either a step scaling policy or a simple scaling policy deletes the underlying alarm action, but does not delete the alarm, even if it no longer has an associated action. For more information, see Deleting a Scaling Policy in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#delete_scheduled_action/3","title":"AWS.AutoScaling.delete_scheduled_action/3","type":"function","doc":"Deletes the specified scheduled action."},{"ref":"AWS.AutoScaling.html#delete_tags/3","title":"AWS.AutoScaling.delete_tags/3","type":"function","doc":"Deletes the specified tags."},{"ref":"AWS.AutoScaling.html#describe_account_limits/3","title":"AWS.AutoScaling.describe_account_limits/3","type":"function","doc":"Describes the current Amazon EC2 Auto Scaling resource quotas for your AWS account. For information about requesting an increase, see Amazon EC2 Auto Scaling Service Quotas in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#describe_adjustment_types/3","title":"AWS.AutoScaling.describe_adjustment_types/3","type":"function","doc":"Describes the available adjustment types for Amazon EC2 Auto Scaling scaling policies. These settings apply to step scaling policies and simple scaling policies; they do not apply to target tracking scaling policies. The following adjustment types are supported: ChangeInCapacity ExactCapacity PercentChangeInCapacity"},{"ref":"AWS.AutoScaling.html#describe_auto_scaling_groups/3","title":"AWS.AutoScaling.describe_auto_scaling_groups/3","type":"function","doc":"Describes one or more Auto Scaling groups."},{"ref":"AWS.AutoScaling.html#describe_auto_scaling_instances/3","title":"AWS.AutoScaling.describe_auto_scaling_instances/3","type":"function","doc":"Describes one or more Auto Scaling instances."},{"ref":"AWS.AutoScaling.html#describe_auto_scaling_notification_types/3","title":"AWS.AutoScaling.describe_auto_scaling_notification_types/3","type":"function","doc":"Describes the notification types that are supported by Amazon EC2 Auto Scaling."},{"ref":"AWS.AutoScaling.html#describe_instance_refreshes/3","title":"AWS.AutoScaling.describe_instance_refreshes/3","type":"function","doc":"Describes one or more instance refreshes. You can determine the status of a request by looking at the Status parameter. The following are the possible statuses: Pending - The request was created, but the operation has not started. InProgress - The operation is in progress. Successful - The operation completed successfully. Failed - The operation failed to complete. You can troubleshoot using the status reason and the scaling activities. Cancelling - An ongoing operation is being cancelled. Cancellation does not roll back any replacements that have already been completed, but it prevents new replacements from being started. Cancelled - The operation is cancelled. For more information, see Replacing Auto Scaling Instances Based on an Instance Refresh."},{"ref":"AWS.AutoScaling.html#describe_launch_configurations/3","title":"AWS.AutoScaling.describe_launch_configurations/3","type":"function","doc":"Describes one or more launch configurations."},{"ref":"AWS.AutoScaling.html#describe_lifecycle_hook_types/3","title":"AWS.AutoScaling.describe_lifecycle_hook_types/3","type":"function","doc":"Describes the available types of lifecycle hooks. The following hook types are supported: autoscaling:EC2_INSTANCE_LAUNCHING autoscaling:EC2_INSTANCE_TERMINATING"},{"ref":"AWS.AutoScaling.html#describe_lifecycle_hooks/3","title":"AWS.AutoScaling.describe_lifecycle_hooks/3","type":"function","doc":"Describes the lifecycle hooks for the specified Auto Scaling group."},{"ref":"AWS.AutoScaling.html#describe_load_balancer_target_groups/3","title":"AWS.AutoScaling.describe_load_balancer_target_groups/3","type":"function","doc":"Describes the target groups for the specified Auto Scaling group."},{"ref":"AWS.AutoScaling.html#describe_load_balancers/3","title":"AWS.AutoScaling.describe_load_balancers/3","type":"function","doc":"Describes the load balancers for the specified Auto Scaling group. This operation describes only Classic Load Balancers. If you have Application Load Balancers or Network Load Balancers, use the DescribeLoadBalancerTargetGroups API instead."},{"ref":"AWS.AutoScaling.html#describe_metric_collection_types/3","title":"AWS.AutoScaling.describe_metric_collection_types/3","type":"function","doc":"Describes the available CloudWatch metrics for Amazon EC2 Auto Scaling. The GroupStandbyInstances metric is not returned by default. You must explicitly request this metric when calling the EnableMetricsCollection API."},{"ref":"AWS.AutoScaling.html#describe_notification_configurations/3","title":"AWS.AutoScaling.describe_notification_configurations/3","type":"function","doc":"Describes the notification actions associated with the specified Auto Scaling group."},{"ref":"AWS.AutoScaling.html#describe_policies/3","title":"AWS.AutoScaling.describe_policies/3","type":"function","doc":"Describes the policies for the specified Auto Scaling group."},{"ref":"AWS.AutoScaling.html#describe_scaling_activities/3","title":"AWS.AutoScaling.describe_scaling_activities/3","type":"function","doc":"Describes one or more scaling activities for the specified Auto Scaling group."},{"ref":"AWS.AutoScaling.html#describe_scaling_process_types/3","title":"AWS.AutoScaling.describe_scaling_process_types/3","type":"function","doc":"Describes the scaling process types for use with the ResumeProcesses and SuspendProcesses APIs."},{"ref":"AWS.AutoScaling.html#describe_scheduled_actions/3","title":"AWS.AutoScaling.describe_scheduled_actions/3","type":"function","doc":"Describes the actions scheduled for your Auto Scaling group that haven&#39;t run or that have not reached their end time. To describe the actions that have already run, call the DescribeScalingActivities API."},{"ref":"AWS.AutoScaling.html#describe_tags/3","title":"AWS.AutoScaling.describe_tags/3","type":"function","doc":"Describes the specified tags. You can use filters to limit the results. For example, you can query for the tags for a specific Auto Scaling group. You can specify multiple values for a filter. A tag must match at least one of the specified values for it to be included in the results. You can also specify multiple filters. The result includes information for a particular tag only if it matches all the filters. If there&#39;s no match, no special message is returned. For more information, see Tagging Auto Scaling Groups and Instances in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#describe_termination_policy_types/3","title":"AWS.AutoScaling.describe_termination_policy_types/3","type":"function","doc":"Describes the termination policies supported by Amazon EC2 Auto Scaling. For more information, see Controlling Which Auto Scaling Instances Terminate During Scale In in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#detach_instances/3","title":"AWS.AutoScaling.detach_instances/3","type":"function","doc":"Removes one or more instances from the specified Auto Scaling group. After the instances are detached, you can manage them independent of the Auto Scaling group. If you do not specify the option to decrement the desired capacity, Amazon EC2 Auto Scaling launches instances to replace the ones that are detached. If there is a Classic Load Balancer attached to the Auto Scaling group, the instances are deregistered from the load balancer. If there are target groups attached to the Auto Scaling group, the instances are deregistered from the target groups. For more information, see Detach EC2 Instances from Your Auto Scaling Group in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#detach_load_balancer_target_groups/3","title":"AWS.AutoScaling.detach_load_balancer_target_groups/3","type":"function","doc":"Detaches one or more target groups from the specified Auto Scaling group."},{"ref":"AWS.AutoScaling.html#detach_load_balancers/3","title":"AWS.AutoScaling.detach_load_balancers/3","type":"function","doc":"Detaches one or more Classic Load Balancers from the specified Auto Scaling group. This operation detaches only Classic Load Balancers. If you have Application Load Balancers or Network Load Balancers, use the DetachLoadBalancerTargetGroups API instead. When you detach a load balancer, it enters the Removing state while deregistering the instances in the group. When all instances are deregistered, then you can no longer describe the load balancer using the DescribeLoadBalancers API call. The instances remain running."},{"ref":"AWS.AutoScaling.html#disable_metrics_collection/3","title":"AWS.AutoScaling.disable_metrics_collection/3","type":"function","doc":"Disables group metrics for the specified Auto Scaling group."},{"ref":"AWS.AutoScaling.html#enable_metrics_collection/3","title":"AWS.AutoScaling.enable_metrics_collection/3","type":"function","doc":"Enables group metrics for the specified Auto Scaling group. For more information, see Monitoring Your Auto Scaling Groups and Instances in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#enter_standby/3","title":"AWS.AutoScaling.enter_standby/3","type":"function","doc":"Moves the specified instances into the standby state. If you choose to decrement the desired capacity of the Auto Scaling group, the instances can enter standby as long as the desired capacity of the Auto Scaling group after the instances are placed into standby is equal to or greater than the minimum capacity of the group. If you choose not to decrement the desired capacity of the Auto Scaling group, the Auto Scaling group launches new instances to replace the instances on standby. For more information, see Temporarily Removing Instances from Your Auto Scaling Group in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#execute_policy/3","title":"AWS.AutoScaling.execute_policy/3","type":"function","doc":"Executes the specified policy. This can be useful for testing the design of your scaling policy."},{"ref":"AWS.AutoScaling.html#exit_standby/3","title":"AWS.AutoScaling.exit_standby/3","type":"function","doc":"Moves the specified instances out of the standby state. After you put the instances back in service, the desired capacity is incremented. For more information, see Temporarily Removing Instances from Your Auto Scaling Group in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#put_lifecycle_hook/3","title":"AWS.AutoScaling.put_lifecycle_hook/3","type":"function","doc":"Creates or updates a lifecycle hook for the specified Auto Scaling group. A lifecycle hook tells Amazon EC2 Auto Scaling to perform an action on an instance when the instance launches (before it is put into service) or as the instance terminates (before it is fully terminated). This step is a part of the procedure for adding a lifecycle hook to an Auto Scaling group: (Optional) Create a Lambda function and a rule that allows CloudWatch Events to invoke your Lambda function when Amazon EC2 Auto Scaling launches or terminates instances. (Optional) Create a notification target and an IAM role. The target can be either an Amazon SQS queue or an Amazon SNS topic. The role allows Amazon EC2 Auto Scaling to publish lifecycle notifications to the target. Create the lifecycle hook. Specify whether the hook is used when the instances launch or terminate. If you need more time, record the lifecycle action heartbeat to keep the instance in a pending state using the RecordLifecycleActionHeartbeat API call. If you finish before the timeout period ends, complete the lifecycle action using the CompleteLifecycleAction API call. For more information, see Amazon EC2 Auto Scaling Lifecycle Hooks in the Amazon EC2 Auto Scaling User Guide. If you exceed your maximum limit of lifecycle hooks, which by default is 50 per Auto Scaling group, the call fails. You can view the lifecycle hooks for an Auto Scaling group using the DescribeLifecycleHooks API call. If you are no longer using a lifecycle hook, you can delete it by calling the DeleteLifecycleHook API."},{"ref":"AWS.AutoScaling.html#put_notification_configuration/3","title":"AWS.AutoScaling.put_notification_configuration/3","type":"function","doc":"Configures an Auto Scaling group to send notifications when specified events take place. Subscribers to the specified topic can have messages delivered to an endpoint such as a web server or an email address. This configuration overwrites any existing configuration. For more information, see Getting Amazon SNS Notifications When Your Auto Scaling Group Scales in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#put_scaling_policy/3","title":"AWS.AutoScaling.put_scaling_policy/3","type":"function","doc":"Creates or updates a scaling policy for an Auto Scaling group. For more information about using scaling policies to scale your Auto Scaling group, see Target Tracking Scaling Policies and Step and Simple Scaling Policies in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#put_scheduled_update_group_action/3","title":"AWS.AutoScaling.put_scheduled_update_group_action/3","type":"function","doc":"Creates or updates a scheduled scaling action for an Auto Scaling group. If you leave a parameter unspecified when updating a scheduled scaling action, the corresponding value remains unchanged. For more information, see Scheduled Scaling in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#record_lifecycle_action_heartbeat/3","title":"AWS.AutoScaling.record_lifecycle_action_heartbeat/3","type":"function","doc":"Records a heartbeat for the lifecycle action associated with the specified token or instance. This extends the timeout by the length of time defined using the PutLifecycleHook API call. This step is a part of the procedure for adding a lifecycle hook to an Auto Scaling group: (Optional) Create a Lambda function and a rule that allows CloudWatch Events to invoke your Lambda function when Amazon EC2 Auto Scaling launches or terminates instances. (Optional) Create a notification target and an IAM role. The target can be either an Amazon SQS queue or an Amazon SNS topic. The role allows Amazon EC2 Auto Scaling to publish lifecycle notifications to the target. Create the lifecycle hook. Specify whether the hook is used when the instances launch or terminate. If you need more time, record the lifecycle action heartbeat to keep the instance in a pending state. If you finish before the timeout period ends, complete the lifecycle action. For more information, see Auto Scaling Lifecycle in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#resume_processes/3","title":"AWS.AutoScaling.resume_processes/3","type":"function","doc":"Resumes the specified suspended automatic scaling processes, or all suspended process, for the specified Auto Scaling group. For more information, see Suspending and Resuming Scaling Processes in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#set_desired_capacity/3","title":"AWS.AutoScaling.set_desired_capacity/3","type":"function","doc":"Sets the size of the specified Auto Scaling group. If a scale-in activity occurs as a result of a new DesiredCapacity value that is lower than the current size of the group, the Auto Scaling group uses its termination policy to determine which instances to terminate. For more information, see Manual Scaling in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#set_instance_health/3","title":"AWS.AutoScaling.set_instance_health/3","type":"function","doc":"Sets the health status of the specified instance. For more information, see Health Checks for Auto Scaling Instances in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#set_instance_protection/3","title":"AWS.AutoScaling.set_instance_protection/3","type":"function","doc":"Updates the instance protection settings of the specified instances. For more information about preventing instances that are part of an Auto Scaling group from terminating on scale in, see Instance Protection in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#start_instance_refresh/3","title":"AWS.AutoScaling.start_instance_refresh/3","type":"function","doc":"Starts a new instance refresh operation, which triggers a rolling replacement of all previously launched instances in the Auto Scaling group with a new group of instances. If successful, this call creates a new instance refresh request with a unique ID that you can use to track its progress. To query its status, call the DescribeInstanceRefreshes API. To describe the instance refreshes that have already run, call the DescribeInstanceRefreshes API. To cancel an instance refresh operation in progress, use the CancelInstanceRefresh API. For more information, see Replacing Auto Scaling Instances Based on an Instance Refresh."},{"ref":"AWS.AutoScaling.html#suspend_processes/3","title":"AWS.AutoScaling.suspend_processes/3","type":"function","doc":"Suspends the specified automatic scaling processes, or all processes, for the specified Auto Scaling group. If you suspend either the Launch or Terminate process types, it can prevent other process types from functioning properly. For more information, see Suspending and Resuming Scaling Processes in the Amazon EC2 Auto Scaling User Guide. To resume processes that have been suspended, call the ResumeProcesses API."},{"ref":"AWS.AutoScaling.html#terminate_instance_in_auto_scaling_group/3","title":"AWS.AutoScaling.terminate_instance_in_auto_scaling_group/3","type":"function","doc":"Terminates the specified instance and optionally adjusts the desired group size. This call simply makes a termination request. The instance is not terminated immediately. When an instance is terminated, the instance status changes to terminated. You can&#39;t connect to or start an instance after you&#39;ve terminated it. If you do not specify the option to decrement the desired capacity, Amazon EC2 Auto Scaling launches instances to replace the ones that are terminated. By default, Amazon EC2 Auto Scaling balances instances across all Availability Zones. If you decrement the desired capacity, your Auto Scaling group can become unbalanced between Availability Zones. Amazon EC2 Auto Scaling tries to rebalance the group, and rebalancing might terminate instances in other zones. For more information, see Rebalancing Activities in the Amazon EC2 Auto Scaling User Guide."},{"ref":"AWS.AutoScaling.html#update_auto_scaling_group/3","title":"AWS.AutoScaling.update_auto_scaling_group/3","type":"function","doc":"Updates the configuration for the specified Auto Scaling group. To update an Auto Scaling group, specify the name of the group and the parameter that you want to change. Any parameters that you don&#39;t specify are not changed by this update request. The new settings take effect on any scaling activities after this call returns. If you associate a new launch configuration or template with an Auto Scaling group, all new instances will get the updated configuration. Existing instances continue to run with the configuration that they were originally launched with. When you update a group to specify a mixed instances policy instead of a launch configuration or template, existing instances may be replaced to match the new purchasing options that you specified in the policy. For example, if the group currently has 100% On-Demand capacity and the policy specifies 50% Spot capacity, this means that half of your instances will be gradually terminated and relaunched as Spot Instances. When replacing instances, Amazon EC2 Auto Scaling launches new instances before terminating the old ones, so that updating your group does not compromise the performance or availability of your application. Note the following about changing DesiredCapacity, MaxSize, or MinSize: If a scale-in activity occurs as a result of a new DesiredCapacity value that is lower than the current size of the group, the Auto Scaling group uses its termination policy to determine which instances to terminate. If you specify a new value for MinSize without specifying a value for DesiredCapacity, and the new MinSize is larger than the current size of the group, this sets the group&#39;s DesiredCapacity to the new MinSize value. If you specify a new value for MaxSize without specifying a value for DesiredCapacity, and the new MaxSize is smaller than the current size of the group, this sets the group&#39;s DesiredCapacity to the new MaxSize value. To see which parameters have been set, call the DescribeAutoScalingGroups API. To view the scaling policies for an Auto Scaling group, call the DescribePolicies API. If the group has scaling policies, you can update them by calling the PutScalingPolicy API."},{"ref":"AWS.AutoScalingPlans.html","title":"AWS.AutoScalingPlans","type":"module","doc":"AWS Auto Scaling Use AWS Auto Scaling to quickly discover all the scalable AWS resources for your application and configure dynamic scaling and predictive scaling for your resources using scaling plans. Use this service in conjunction with the Amazon EC2 Auto Scaling, Application Auto Scaling, Amazon CloudWatch, and AWS CloudFormation services. Currently, predictive scaling is only available for Amazon EC2 Auto Scaling groups. For more information about AWS Auto Scaling, including information about granting IAM users required permissions for AWS Auto Scaling actions, see the AWS Auto Scaling User Guide."},{"ref":"AWS.AutoScalingPlans.html#create_scaling_plan/3","title":"AWS.AutoScalingPlans.create_scaling_plan/3","type":"function","doc":"Creates a scaling plan."},{"ref":"AWS.AutoScalingPlans.html#delete_scaling_plan/3","title":"AWS.AutoScalingPlans.delete_scaling_plan/3","type":"function","doc":"Deletes the specified scaling plan. Deleting a scaling plan deletes the underlying ScalingInstruction for all of the scalable resources that are covered by the plan. If the plan has launched resources or has scaling activities in progress, you must delete those resources separately."},{"ref":"AWS.AutoScalingPlans.html#describe_scaling_plan_resources/3","title":"AWS.AutoScalingPlans.describe_scaling_plan_resources/3","type":"function","doc":"Describes the scalable resources in the specified scaling plan."},{"ref":"AWS.AutoScalingPlans.html#describe_scaling_plans/3","title":"AWS.AutoScalingPlans.describe_scaling_plans/3","type":"function","doc":"Describes one or more of your scaling plans."},{"ref":"AWS.AutoScalingPlans.html#get_scaling_plan_resource_forecast_data/3","title":"AWS.AutoScalingPlans.get_scaling_plan_resource_forecast_data/3","type":"function","doc":"Retrieves the forecast data for a scalable resource. Capacity forecasts are represented as predicted values, or data points, that are calculated using historical data points from a specified CloudWatch load metric. Data points are available for up to 56 days."},{"ref":"AWS.AutoScalingPlans.html#update_scaling_plan/3","title":"AWS.AutoScalingPlans.update_scaling_plan/3","type":"function","doc":"Updates the specified scaling plan. You cannot update a scaling plan if it is in the process of being created, updated, or deleted."},{"ref":"AWS.Backup.html","title":"AWS.Backup","type":"module","doc":"AWS Backup AWS Backup is a unified backup service designed to protect AWS services and their associated data. AWS Backup simplifies the creation, migration, restoration, and deletion of backups, while also providing reporting and auditing."},{"ref":"AWS.Backup.html#create_backup_plan/3","title":"AWS.Backup.create_backup_plan/3","type":"function","doc":"Creates a backup plan using a backup plan name and backup rules. A backup plan is a document that contains information that AWS Backup uses to schedule tasks that create recovery points for resources. If you call CreateBackupPlan with a plan that already exists, an AlreadyExistsException is returned."},{"ref":"AWS.Backup.html#create_backup_selection/4","title":"AWS.Backup.create_backup_selection/4","type":"function","doc":"Creates a JSON document that specifies a set of resources to assign to a backup plan. Resources can be included by specifying patterns for a ListOfTags and selected Resources. For example, consider the following patterns: Resources: &quot;arn:aws:ec2:region:account-id:volume/volume-id&quot; ConditionKey:&quot;department&quot; ConditionValue:&quot;finance&quot; ConditionType:&quot;StringEquals&quot; ConditionKey:&quot;importance&quot; ConditionValue:&quot;critical&quot; ConditionType:&quot;StringEquals&quot; Using these patterns would back up all Amazon Elastic Block Store (Amazon EBS) volumes that are tagged as &quot;department=finance&quot;, &quot;importance=critical&quot;, in addition to an EBS volume with the specified volume ID. Resources and conditions are additive in that all resources that match the pattern are selected. This shouldn&#39;t be confused with a logical AND, where all conditions must match. The matching patterns are logically put together using the OR operator. In other words, all patterns that match are selected for backup."},{"ref":"AWS.Backup.html#create_backup_vault/4","title":"AWS.Backup.create_backup_vault/4","type":"function","doc":"Creates a logical container where backups are stored. A CreateBackupVault request includes a name, optionally one or more resource tags, an encryption key, and a request ID. Sensitive data, such as passport numbers, should not be included the name of a backup vault."},{"ref":"AWS.Backup.html#delete_backup_plan/4","title":"AWS.Backup.delete_backup_plan/4","type":"function","doc":"Deletes a backup plan. A backup plan can only be deleted after all associated selections of resources have been deleted. Deleting a backup plan deletes the current version of a backup plan. Previous versions, if any, will still exist."},{"ref":"AWS.Backup.html#delete_backup_selection/5","title":"AWS.Backup.delete_backup_selection/5","type":"function","doc":"Deletes the resource selection associated with a backup plan that is specified by the SelectionId."},{"ref":"AWS.Backup.html#delete_backup_vault/4","title":"AWS.Backup.delete_backup_vault/4","type":"function","doc":"Deletes the backup vault identified by its name. A vault can be deleted only if it is empty."},{"ref":"AWS.Backup.html#delete_backup_vault_access_policy/4","title":"AWS.Backup.delete_backup_vault_access_policy/4","type":"function","doc":"Deletes the policy document that manages permissions on a backup vault."},{"ref":"AWS.Backup.html#delete_backup_vault_notifications/4","title":"AWS.Backup.delete_backup_vault_notifications/4","type":"function","doc":"Deletes event notifications for the specified backup vault."},{"ref":"AWS.Backup.html#delete_recovery_point/5","title":"AWS.Backup.delete_recovery_point/5","type":"function","doc":"Deletes the recovery point specified by a recovery point ID."},{"ref":"AWS.Backup.html#describe_backup_job/3","title":"AWS.Backup.describe_backup_job/3","type":"function","doc":"Returns backup job details for the specified BackupJobId."},{"ref":"AWS.Backup.html#describe_backup_vault/3","title":"AWS.Backup.describe_backup_vault/3","type":"function","doc":"Returns metadata about a backup vault specified by its name."},{"ref":"AWS.Backup.html#describe_copy_job/3","title":"AWS.Backup.describe_copy_job/3","type":"function","doc":"Returns metadata associated with creating a copy of a resource."},{"ref":"AWS.Backup.html#describe_protected_resource/3","title":"AWS.Backup.describe_protected_resource/3","type":"function","doc":"Returns information about a saved resource, including the last time it was backed up, its Amazon Resource Name (ARN), and the AWS service type of the saved resource."},{"ref":"AWS.Backup.html#describe_recovery_point/4","title":"AWS.Backup.describe_recovery_point/4","type":"function","doc":"Returns metadata associated with a recovery point, including ID, status, encryption, and lifecycle."},{"ref":"AWS.Backup.html#describe_region_settings/2","title":"AWS.Backup.describe_region_settings/2","type":"function","doc":"Returns the current service opt-in settings for the Region. If the service has a value set to true, AWS Backup tries to protect that service&#39;s resources in this Region, when included in an on-demand backup or scheduled backup plan. If the value is set to false for a service, AWS Backup does not try to protect that service&#39;s resources in this Region."},{"ref":"AWS.Backup.html#describe_restore_job/3","title":"AWS.Backup.describe_restore_job/3","type":"function","doc":"Returns metadata associated with a restore job that is specified by a job ID."},{"ref":"AWS.Backup.html#export_backup_plan_template/3","title":"AWS.Backup.export_backup_plan_template/3","type":"function","doc":"Returns the backup plan that is specified by the plan ID as a backup template."},{"ref":"AWS.Backup.html#get_backup_plan/4","title":"AWS.Backup.get_backup_plan/4","type":"function","doc":"Returns BackupPlan details for the specified BackupPlanId. Returns the body of a backup plan in JSON format, in addition to plan metadata."},{"ref":"AWS.Backup.html#get_backup_plan_from_j_s_o_n/3","title":"AWS.Backup.get_backup_plan_from_j_s_o_n/3","type":"function","doc":"Returns a valid JSON document specifying a backup plan or an error."},{"ref":"AWS.Backup.html#get_backup_plan_from_template/3","title":"AWS.Backup.get_backup_plan_from_template/3","type":"function","doc":"Returns the template specified by its templateId as a backup plan."},{"ref":"AWS.Backup.html#get_backup_selection/4","title":"AWS.Backup.get_backup_selection/4","type":"function","doc":"Returns selection metadata and a document in JSON format that specifies a list of resources that are associated with a backup plan."},{"ref":"AWS.Backup.html#get_backup_vault_access_policy/3","title":"AWS.Backup.get_backup_vault_access_policy/3","type":"function","doc":"Returns the access policy document that is associated with the named backup vault."},{"ref":"AWS.Backup.html#get_backup_vault_notifications/3","title":"AWS.Backup.get_backup_vault_notifications/3","type":"function","doc":"Returns event notifications for the specified backup vault."},{"ref":"AWS.Backup.html#get_recovery_point_restore_metadata/4","title":"AWS.Backup.get_recovery_point_restore_metadata/4","type":"function","doc":"Returns a set of metadata key-value pairs that were used to create the backup."},{"ref":"AWS.Backup.html#get_supported_resource_types/2","title":"AWS.Backup.get_supported_resource_types/2","type":"function","doc":"Returns the AWS resource types supported by AWS Backup."},{"ref":"AWS.Backup.html#list_backup_jobs/11","title":"AWS.Backup.list_backup_jobs/11","type":"function","doc":"Returns a list of existing backup jobs for an authenticated account."},{"ref":"AWS.Backup.html#list_backup_plan_templates/4","title":"AWS.Backup.list_backup_plan_templates/4","type":"function","doc":"Returns metadata of your saved backup plan templates, including the template ID, name, and the creation and deletion dates."},{"ref":"AWS.Backup.html#list_backup_plan_versions/5","title":"AWS.Backup.list_backup_plan_versions/5","type":"function","doc":"Returns version metadata of your backup plans, including Amazon Resource Names (ARNs), backup plan IDs, creation and deletion dates, plan names, and version IDs."},{"ref":"AWS.Backup.html#list_backup_plans/5","title":"AWS.Backup.list_backup_plans/5","type":"function","doc":"Returns a list of existing backup plans for an authenticated account. The list is populated only if the advanced option is set for the backup plan. The list contains information such as Amazon Resource Names (ARNs), plan IDs, creation and deletion dates, version IDs, plan names, and creator request IDs."},{"ref":"AWS.Backup.html#list_backup_selections/5","title":"AWS.Backup.list_backup_selections/5","type":"function","doc":"Returns an array containing metadata of the resources associated with the target backup plan."},{"ref":"AWS.Backup.html#list_backup_vaults/4","title":"AWS.Backup.list_backup_vaults/4","type":"function","doc":"Returns a list of recovery point storage containers along with information about them."},{"ref":"AWS.Backup.html#list_copy_jobs/11","title":"AWS.Backup.list_copy_jobs/11","type":"function","doc":"Returns metadata about your copy jobs."},{"ref":"AWS.Backup.html#list_protected_resources/4","title":"AWS.Backup.list_protected_resources/4","type":"function","doc":"Returns an array of resources successfully backed up by AWS Backup, including the time the resource was saved, an Amazon Resource Name (ARN) of the resource, and a resource type."},{"ref":"AWS.Backup.html#list_recovery_points_by_backup_vault/10","title":"AWS.Backup.list_recovery_points_by_backup_vault/10","type":"function","doc":"Returns detailed information about the recovery points stored in a backup vault."},{"ref":"AWS.Backup.html#list_recovery_points_by_resource/5","title":"AWS.Backup.list_recovery_points_by_resource/5","type":"function","doc":"Returns detailed information about recovery points of the type specified by a resource Amazon Resource Name (ARN)."},{"ref":"AWS.Backup.html#list_restore_jobs/8","title":"AWS.Backup.list_restore_jobs/8","type":"function","doc":"Returns a list of jobs that AWS Backup initiated to restore a saved resource, including metadata about the recovery process."},{"ref":"AWS.Backup.html#list_tags/5","title":"AWS.Backup.list_tags/5","type":"function","doc":"Returns a list of key-value pairs assigned to a target recovery point, backup plan, or backup vault. ListTags are currently only supported with Amazon EFS backups."},{"ref":"AWS.Backup.html#put_backup_vault_access_policy/4","title":"AWS.Backup.put_backup_vault_access_policy/4","type":"function","doc":"Sets a resource-based policy that is used to manage access permissions on the target backup vault. Requires a backup vault name and an access policy document in JSON format."},{"ref":"AWS.Backup.html#put_backup_vault_notifications/4","title":"AWS.Backup.put_backup_vault_notifications/4","type":"function","doc":"Turns on notifications on a backup vault for the specified topic and events."},{"ref":"AWS.Backup.html#start_backup_job/3","title":"AWS.Backup.start_backup_job/3","type":"function","doc":"Starts an on-demand backup job for the specified resource."},{"ref":"AWS.Backup.html#start_copy_job/3","title":"AWS.Backup.start_copy_job/3","type":"function","doc":"Starts a job to create a one-time copy of the specified resource."},{"ref":"AWS.Backup.html#start_restore_job/3","title":"AWS.Backup.start_restore_job/3","type":"function","doc":"Recovers the saved resource identified by an Amazon Resource Name (ARN). If the resource ARN is included in the request, then the last complete backup of that resource is recovered. If the ARN of a recovery point is supplied, then that recovery point is restored."},{"ref":"AWS.Backup.html#stop_backup_job/4","title":"AWS.Backup.stop_backup_job/4","type":"function","doc":"Attempts to cancel a job to create a one-time backup of a resource."},{"ref":"AWS.Backup.html#tag_resource/4","title":"AWS.Backup.tag_resource/4","type":"function","doc":"Assigns a set of key-value pairs to a recovery point, backup plan, or backup vault identified by an Amazon Resource Name (ARN)."},{"ref":"AWS.Backup.html#untag_resource/4","title":"AWS.Backup.untag_resource/4","type":"function","doc":"Removes a set of key-value pairs from a recovery point, backup plan, or backup vault identified by an Amazon Resource Name (ARN)"},{"ref":"AWS.Backup.html#update_backup_plan/4","title":"AWS.Backup.update_backup_plan/4","type":"function","doc":"Updates an existing backup plan identified by its backupPlanId with the input document in JSON format. The new version is uniquely identified by a VersionId."},{"ref":"AWS.Backup.html#update_recovery_point_lifecycle/5","title":"AWS.Backup.update_recovery_point_lifecycle/5","type":"function","doc":"Sets the transition lifecycle of a recovery point. The lifecycle defines when a protected resource is transitioned to cold storage and when it expires. AWS Backup transitions and expires backups automatically according to the lifecycle that you define. Backups transitioned to cold storage must be stored in cold storage for a minimum of 90 days. Therefore, the expire after days setting must be 90 days greater than the transition to cold after days setting. The transition to cold after days setting cannot be changed after a backup has been transitioned to cold."},{"ref":"AWS.Backup.html#update_region_settings/3","title":"AWS.Backup.update_region_settings/3","type":"function","doc":"Updates the current service opt-in settings for the Region. If the service has a value set to true, AWS Backup tries to protect that service&#39;s resources in this Region, when included in an on-demand backup or scheduled backup plan. If the value is set to false for a service, AWS Backup does not try to protect that service&#39;s resources in this Region."},{"ref":"AWS.Batch.html","title":"AWS.Batch","type":"module","doc":"AWS Batch enables you to run batch computing workloads on the AWS Cloud. Batch computing is a common way for developers, scientists, and engineers to access large amounts of compute resources, and AWS Batch removes the undifferentiated heavy lifting of configuring and managing the required infrastructure. AWS Batch will be familiar to users of traditional batch computing software. This service can efficiently provision resources in response to jobs submitted in order to eliminate capacity constraints, reduce compute costs, and deliver results quickly. As a fully managed service, AWS Batch enables developers, scientists, and engineers to run batch computing workloads of any scale. AWS Batch automatically provisions compute resources and optimizes the workload distribution based on the quantity and scale of the workloads. With AWS Batch, there is no need to install or manage batch computing software, which allows you to focus on analyzing results and solving problems. AWS Batch reduces operational complexities, saves time, and reduces costs, which makes it easy for developers, scientists, and engineers to run their batch jobs in the AWS Cloud."},{"ref":"AWS.Batch.html#cancel_job/3","title":"AWS.Batch.cancel_job/3","type":"function","doc":"Cancels a job in an AWS Batch job queue. Jobs that are in the SUBMITTED, PENDING, or RUNNABLE state are cancelled. Jobs that have progressed to STARTING or RUNNING are not cancelled (but the API operation still succeeds, even if no job is cancelled); these jobs must be terminated with the TerminateJob operation."},{"ref":"AWS.Batch.html#create_compute_environment/3","title":"AWS.Batch.create_compute_environment/3","type":"function","doc":"Creates an AWS Batch compute environment. You can create MANAGED or UNMANAGED compute environments. In a managed compute environment, AWS Batch manages the capacity and instance types of the compute resources within the environment. This is based on the compute resource specification that you define or the launch template that you specify when you create the compute environment. You can choose to use Amazon EC2 On-Demand Instances or Spot Instances in your managed compute environment. You can optionally set a maximum price so that Spot Instances only launch when the Spot Instance price is below a specified percentage of the On-Demand price. Multi-node parallel jobs are not supported on Spot Instances. In an unmanaged compute environment, you can manage your own compute resources. This provides more compute resource configuration options, such as using a custom AMI, but you must ensure that your AMI meets the Amazon ECS container instance AMI specification. For more information, see Container Instance AMIs in the Amazon Elastic Container Service Developer Guide. After you have created your unmanaged compute environment, you can use the DescribeComputeEnvironments operation to find the Amazon ECS cluster that is associated with it. Then, manually launch your container instances into that Amazon ECS cluster. For more information, see Launching an Amazon ECS Container Instance in the Amazon Elastic Container Service Developer Guide. AWS Batch does not upgrade the AMIs in a compute environment after it is created (for example, when a newer version of the Amazon ECS-optimized AMI is available). You are responsible for the management of the guest operating system (including updates and security patches) and any additional application software or utilities that you install on the compute resources. To use a new AMI for your AWS Batch jobs: Create a new compute environment with the new AMI. Add the compute environment to an existing job queue. Remove the old compute environment from your job queue. Delete the old compute environment."},{"ref":"AWS.Batch.html#create_job_queue/3","title":"AWS.Batch.create_job_queue/3","type":"function","doc":"Creates an AWS Batch job queue. When you create a job queue, you associate one or more compute environments to the queue and assign an order of preference for the compute environments. You also set a priority to the job queue that determines the order in which the AWS Batch scheduler places jobs onto its associated compute environments. For example, if a compute environment is associated with more than one job queue, the job queue with a higher priority is given preference for scheduling jobs to that compute environment."},{"ref":"AWS.Batch.html#delete_compute_environment/3","title":"AWS.Batch.delete_compute_environment/3","type":"function","doc":"Deletes an AWS Batch compute environment. Before you can delete a compute environment, you must set its state to DISABLED with the UpdateComputeEnvironment API operation and disassociate it from any job queues with the UpdateJobQueue API operation."},{"ref":"AWS.Batch.html#delete_job_queue/3","title":"AWS.Batch.delete_job_queue/3","type":"function","doc":"Deletes the specified job queue. You must first disable submissions for a queue with the UpdateJobQueue operation. All jobs in the queue are terminated when you delete a job queue. It is not necessary to disassociate compute environments from a queue before submitting a DeleteJobQueue request."},{"ref":"AWS.Batch.html#deregister_job_definition/3","title":"AWS.Batch.deregister_job_definition/3","type":"function","doc":"Deregisters an AWS Batch job definition. Job definitions will be permanently deleted after 180 days."},{"ref":"AWS.Batch.html#describe_compute_environments/3","title":"AWS.Batch.describe_compute_environments/3","type":"function","doc":"Describes one or more of your compute environments. If you are using an unmanaged compute environment, you can use the DescribeComputeEnvironment operation to determine the ecsClusterArn that you should launch your Amazon ECS container instances into."},{"ref":"AWS.Batch.html#describe_job_definitions/3","title":"AWS.Batch.describe_job_definitions/3","type":"function","doc":"Describes a list of job definitions. You can specify a status (such as ACTIVE) to only return job definitions that match that status."},{"ref":"AWS.Batch.html#describe_job_queues/3","title":"AWS.Batch.describe_job_queues/3","type":"function","doc":"Describes one or more of your job queues."},{"ref":"AWS.Batch.html#describe_jobs/3","title":"AWS.Batch.describe_jobs/3","type":"function","doc":"Describes a list of AWS Batch jobs."},{"ref":"AWS.Batch.html#list_jobs/3","title":"AWS.Batch.list_jobs/3","type":"function","doc":"Returns a list of AWS Batch jobs. You must specify only one of the following: a job queue ID to return a list of jobs in that job queue a multi-node parallel job ID to return a list of that job&#39;s nodes an array job ID to return a list of that job&#39;s children You can filter the results by job status with the jobStatus parameter. If you do not specify a status, only RUNNING jobs are returned."},{"ref":"AWS.Batch.html#list_tags_for_resource/3","title":"AWS.Batch.list_tags_for_resource/3","type":"function","doc":"List the tags for an AWS Batch resource. AWS Batch resources that support tags are compute environments, jobs, job definitions, and job queues. ARNs for child jobs of array and multi-node parallel (MNP) jobs are not supported."},{"ref":"AWS.Batch.html#register_job_definition/3","title":"AWS.Batch.register_job_definition/3","type":"function","doc":"Registers an AWS Batch job definition."},{"ref":"AWS.Batch.html#submit_job/3","title":"AWS.Batch.submit_job/3","type":"function","doc":"Submits an AWS Batch job from a job definition. Parameters specified during SubmitJob override parameters defined in the job definition."},{"ref":"AWS.Batch.html#tag_resource/4","title":"AWS.Batch.tag_resource/4","type":"function","doc":"Associates the specified tags to a resource with the specified resourceArn. If existing tags on a resource are not specified in the request parameters, they are not changed. When a resource is deleted, the tags associated with that resource are deleted as well. AWS Batch resources that support tags are compute environments, jobs, job definitions, and job queues. ARNs for child jobs of array and multi-node parallel (MNP) jobs are not supported."},{"ref":"AWS.Batch.html#terminate_job/3","title":"AWS.Batch.terminate_job/3","type":"function","doc":"Terminates a job in a job queue. Jobs that are in the STARTING or RUNNING state are terminated, which causes them to transition to FAILED. Jobs that have not progressed to the STARTING state are cancelled."},{"ref":"AWS.Batch.html#untag_resource/4","title":"AWS.Batch.untag_resource/4","type":"function","doc":"Deletes specified tags from an AWS Batch resource."},{"ref":"AWS.Batch.html#update_compute_environment/3","title":"AWS.Batch.update_compute_environment/3","type":"function","doc":"Updates an AWS Batch compute environment."},{"ref":"AWS.Batch.html#update_job_queue/3","title":"AWS.Batch.update_job_queue/3","type":"function","doc":"Updates a job queue."},{"ref":"AWS.Braket.html","title":"AWS.Braket","type":"module","doc":"The Amazon Braket API Reference provides information about the operations and structures supported in Amazon Braket."},{"ref":"AWS.Braket.html#cancel_quantum_task/4","title":"AWS.Braket.cancel_quantum_task/4","type":"function","doc":"Cancels the specified task."},{"ref":"AWS.Braket.html#create_quantum_task/3","title":"AWS.Braket.create_quantum_task/3","type":"function","doc":"Creates a quantum task."},{"ref":"AWS.Braket.html#get_device/3","title":"AWS.Braket.get_device/3","type":"function","doc":"Retrieves the devices available in Amazon Braket."},{"ref":"AWS.Braket.html#get_quantum_task/3","title":"AWS.Braket.get_quantum_task/3","type":"function","doc":"Retrieves the specified quantum task."},{"ref":"AWS.Braket.html#search_devices/3","title":"AWS.Braket.search_devices/3","type":"function","doc":"Searches for devices using the specified filters."},{"ref":"AWS.Braket.html#search_quantum_tasks/3","title":"AWS.Braket.search_quantum_tasks/3","type":"function","doc":"Searches for tasks that match the specified filter values."},{"ref":"AWS.Budgets.html","title":"AWS.Budgets","type":"module","doc":"The AWS Budgets API enables you to use AWS Budgets to plan your service usage, service costs, and instance reservations. The API reference provides descriptions, syntax, and usage examples for each of the actions and data types for AWS Budgets. Budgets provide you with a way to see the following information: How close your plan is to your budgeted amount or to the free tier limits Your usage-to-date, including how much you&#39;ve used of your Reserved Instances (RIs) Your current estimated charges from AWS, and how much your predicted usage will accrue in charges by the end of the month How much of your budget has been used AWS updates your budget status several times a day. Budgets track your unblended costs, subscriptions, refunds, and RIs. You can create the following types of budgets: Cost budgets - Plan how much you want to spend on a service. Usage budgets - Plan how much you want to use one or more services. RI utilization budgets - Define a utilization threshold, and receive alerts when your RI usage falls below that threshold. This lets you see if your RIs are unused or under-utilized. RI coverage budgets - Define a coverage threshold, and receive alerts when the number of your instance hours that are covered by RIs fall below that threshold. This lets you see how much of your instance usage is covered by a reservation. Service Endpoint The AWS Budgets API provides the following endpoint: https://budgets.amazonaws.com For information about costs that are associated with the AWS Budgets API, see AWS Cost Management Pricing."},{"ref":"AWS.Budgets.html#create_budget/3","title":"AWS.Budgets.create_budget/3","type":"function","doc":"Creates a budget and, if included, notifications and subscribers. Only one of BudgetLimit or PlannedBudgetLimits can be present in the syntax at one time. Use the syntax that matches your case. The Request Syntax section shows the BudgetLimit syntax. For PlannedBudgetLimits, see the Examples section."},{"ref":"AWS.Budgets.html#create_notification/3","title":"AWS.Budgets.create_notification/3","type":"function","doc":"Creates a notification. You must create the budget before you create the associated notification."},{"ref":"AWS.Budgets.html#create_subscriber/3","title":"AWS.Budgets.create_subscriber/3","type":"function","doc":"Creates a subscriber. You must create the associated budget and notification before you create the subscriber."},{"ref":"AWS.Budgets.html#delete_budget/3","title":"AWS.Budgets.delete_budget/3","type":"function","doc":"Deletes a budget. You can delete your budget at any time. Deleting a budget also deletes the notifications and subscribers that are associated with that budget."},{"ref":"AWS.Budgets.html#delete_notification/3","title":"AWS.Budgets.delete_notification/3","type":"function","doc":"Deletes a notification. Deleting a notification also deletes the subscribers that are associated with the notification."},{"ref":"AWS.Budgets.html#delete_subscriber/3","title":"AWS.Budgets.delete_subscriber/3","type":"function","doc":"Deletes a subscriber. Deleting the last subscriber to a notification also deletes the notification."},{"ref":"AWS.Budgets.html#describe_budget/3","title":"AWS.Budgets.describe_budget/3","type":"function","doc":"Describes a budget. The Request Syntax section shows the BudgetLimit syntax. For PlannedBudgetLimits, see the Examples section."},{"ref":"AWS.Budgets.html#describe_budget_performance_history/3","title":"AWS.Budgets.describe_budget_performance_history/3","type":"function","doc":"Describes the history for DAILY, MONTHLY, and QUARTERLY budgets. Budget history isn&#39;t available for ANNUAL budgets."},{"ref":"AWS.Budgets.html#describe_budgets/3","title":"AWS.Budgets.describe_budgets/3","type":"function","doc":"Lists the budgets that are associated with an account. The Request Syntax section shows the BudgetLimit syntax. For PlannedBudgetLimits, see the Examples section."},{"ref":"AWS.Budgets.html#describe_notifications_for_budget/3","title":"AWS.Budgets.describe_notifications_for_budget/3","type":"function","doc":"Lists the notifications that are associated with a budget."},{"ref":"AWS.Budgets.html#describe_subscribers_for_notification/3","title":"AWS.Budgets.describe_subscribers_for_notification/3","type":"function","doc":"Lists the subscribers that are associated with a notification."},{"ref":"AWS.Budgets.html#update_budget/3","title":"AWS.Budgets.update_budget/3","type":"function","doc":"Updates a budget. You can change every part of a budget except for the budgetName and the calculatedSpend. When you modify a budget, the calculatedSpend drops to zero until AWS has new usage data to use for forecasting. Only one of BudgetLimit or PlannedBudgetLimits can be present in the syntax at one time. Use the syntax that matches your case. The Request Syntax section shows the BudgetLimit syntax. For PlannedBudgetLimits, see the Examples section."},{"ref":"AWS.Budgets.html#update_notification/3","title":"AWS.Budgets.update_notification/3","type":"function","doc":"Updates a notification."},{"ref":"AWS.Budgets.html#update_subscriber/3","title":"AWS.Budgets.update_subscriber/3","type":"function","doc":"Updates a subscriber."},{"ref":"AWS.Chime.html","title":"AWS.Chime","type":"module","doc":"The Amazon Chime API (application programming interface) is designed for developers to perform key tasks, such as creating and managing Amazon Chime accounts, users, and Voice Connectors. This guide provides detailed information about the Amazon Chime API, including operations, types, inputs and outputs, and error codes. It also includes some server-side API actions to use with the Amazon Chime SDK. For more information about the Amazon Chime SDK, see Using the Amazon Chime SDK in the Amazon Chime Developer Guide. You can use an AWS SDK, the AWS Command Line Interface (AWS CLI), or the REST API to make API calls. We recommend using an AWS SDK or the AWS CLI. Each API operation includes links to information about using it with a language-specific AWS SDK or the AWS CLI. Definitions Using an AWS SDK You don&#39;t need to write code to calculate a signature for request authentication. The SDK clients authenticate your requests by using access keys that you provide. For more information about AWS SDKs, see the AWS Developer Center. Using the AWS CLI Use your access keys with the AWS CLI to make API calls. For information about setting up the AWS CLI, see Installing the AWS Command Line Interface in the AWS Command Line Interface User Guide. For a list of available Amazon Chime commands, see the Amazon Chime commands in the AWS CLI Command Reference. Using REST API If you use REST to make API calls, you must authenticate your request by providing a signature. Amazon Chime supports signature version 4. For more information, see Signature Version 4 Signing Process in the Amazon Web Services General Reference. When making REST API calls, use the service name chime and REST endpoint https://service.chime.aws.amazon.com. Administrative permissions are controlled using AWS Identity and Access Management (IAM). For more information, see Identity and Access Management for Amazon Chime in the Amazon Chime Administration Guide."},{"ref":"AWS.Chime.html#associate_phone_number_with_user/5","title":"AWS.Chime.associate_phone_number_with_user/5","type":"function","doc":"Associates a phone number with the specified Amazon Chime user."},{"ref":"AWS.Chime.html#associate_phone_numbers_with_voice_connector/4","title":"AWS.Chime.associate_phone_numbers_with_voice_connector/4","type":"function","doc":"Associates phone numbers with the specified Amazon Chime Voice Connector."},{"ref":"AWS.Chime.html#associate_phone_numbers_with_voice_connector_group/4","title":"AWS.Chime.associate_phone_numbers_with_voice_connector_group/4","type":"function","doc":"Associates phone numbers with the specified Amazon Chime Voice Connector group."},{"ref":"AWS.Chime.html#associate_signin_delegate_groups_with_account/4","title":"AWS.Chime.associate_signin_delegate_groups_with_account/4","type":"function","doc":"Associates the specified sign-in delegate groups with the specified Amazon Chime account."},{"ref":"AWS.Chime.html#batch_create_attendee/4","title":"AWS.Chime.batch_create_attendee/4","type":"function","doc":"Creates up to 100 new attendees for an active Amazon Chime SDK meeting. For more information about the Amazon Chime SDK, see Using the Amazon Chime SDK in the Amazon Chime Developer Guide."},{"ref":"AWS.Chime.html#batch_create_room_membership/5","title":"AWS.Chime.batch_create_room_membership/5","type":"function","doc":"Adds up to 50 members to a chat room in an Amazon Chime Enterprise account. Members can be either users or bots. The member role designates whether the member is a chat room administrator or a general chat room member."},{"ref":"AWS.Chime.html#batch_delete_phone_number/3","title":"AWS.Chime.batch_delete_phone_number/3","type":"function","doc":"Moves phone numbers into the Deletion queue. Phone numbers must be disassociated from any users or Amazon Chime Voice Connectors before they can be deleted. Phone numbers remain in the Deletion queue for 7 days before they are deleted permanently."},{"ref":"AWS.Chime.html#batch_suspend_user/4","title":"AWS.Chime.batch_suspend_user/4","type":"function","doc":"Suspends up to 50 users from a Team or EnterpriseLWA Amazon Chime account. For more information about different account types, see Managing Your Amazon Chime Accounts in the Amazon Chime Administration Guide. Users suspended from a Team account are disassociated from the account, but they can continue to use Amazon Chime as free users. To remove the suspension from suspended Team account users, invite them to the Team account again. You can use the InviteUsers action to do so. Users suspended from an EnterpriseLWA account are immediately signed out of Amazon Chime and can no longer sign in. To remove the suspension from suspended EnterpriseLWA account users, use the BatchUnsuspendUser action. To sign out users without suspending them, use the LogoutUser action."},{"ref":"AWS.Chime.html#batch_unsuspend_user/4","title":"AWS.Chime.batch_unsuspend_user/4","type":"function","doc":"Removes the suspension from up to 50 previously suspended users for the specified Amazon Chime EnterpriseLWA account. Only users on EnterpriseLWA accounts can be unsuspended using this action. For more information about different account types, see Managing Your Amazon Chime Accounts in the Amazon Chime Administration Guide. Previously suspended users who are unsuspended using this action are returned to Registered status. Users who are not previously suspended are ignored."},{"ref":"AWS.Chime.html#batch_update_phone_number/3","title":"AWS.Chime.batch_update_phone_number/3","type":"function","doc":"Updates phone number product types or calling names. You can update one attribute at a time for each UpdatePhoneNumberRequestItem. For example, you can update either the product type or the calling name. For product types, choose from Amazon Chime Business Calling and Amazon Chime Voice Connector. For toll-free numbers, you must use the Amazon Chime Voice Connector product type. Updates to outbound calling names can take up to 72 hours to complete. Pending updates to outbound calling names must be complete before you can request another update."},{"ref":"AWS.Chime.html#batch_update_user/4","title":"AWS.Chime.batch_update_user/4","type":"function","doc":"Updates user details within the UpdateUserRequestItem object for up to 20 users for the specified Amazon Chime account. Currently, only LicenseType updates are supported for this action."},{"ref":"AWS.Chime.html#create_account/3","title":"AWS.Chime.create_account/3","type":"function","doc":"Creates an Amazon Chime account under the administrator&#39;s AWS account. Only Team account types are currently supported for this action. For more information about different account types, see Managing Your Amazon Chime Accounts in the Amazon Chime Administration Guide."},{"ref":"AWS.Chime.html#create_attendee/4","title":"AWS.Chime.create_attendee/4","type":"function","doc":"Creates a new attendee for an active Amazon Chime SDK meeting. For more information about the Amazon Chime SDK, see Using the Amazon Chime SDK in the Amazon Chime Developer Guide."},{"ref":"AWS.Chime.html#create_bot/4","title":"AWS.Chime.create_bot/4","type":"function","doc":"Creates a bot for an Amazon Chime Enterprise account."},{"ref":"AWS.Chime.html#create_meeting/3","title":"AWS.Chime.create_meeting/3","type":"function","doc":"Creates a new Amazon Chime SDK meeting in the specified media Region with no initial attendees. For more information about specifying media Regions, see Amazon Chime SDK Media Regions in the Amazon Chime Developer Guide. For more information about the Amazon Chime SDK, see Using the Amazon Chime SDK in the Amazon Chime Developer Guide."},{"ref":"AWS.Chime.html#create_meeting_with_attendees/3","title":"AWS.Chime.create_meeting_with_attendees/3","type":"function","doc":"Creates a new Amazon Chime SDK meeting in the specified media Region, with attendees. For more information about specifying media Regions, see Amazon Chime SDK Media Regions in the Amazon Chime Developer Guide. For more information about the Amazon Chime SDK, see Using the Amazon Chime SDK in the Amazon Chime Developer Guide."},{"ref":"AWS.Chime.html#create_phone_number_order/3","title":"AWS.Chime.create_phone_number_order/3","type":"function","doc":"Creates an order for phone numbers to be provisioned. Choose from Amazon Chime Business Calling and Amazon Chime Voice Connector product types. For toll-free numbers, you must use the Amazon Chime Voice Connector product type."},{"ref":"AWS.Chime.html#create_proxy_session/4","title":"AWS.Chime.create_proxy_session/4","type":"function","doc":"Creates a proxy session on the specified Amazon Chime Voice Connector for the specified participant phone numbers."},{"ref":"AWS.Chime.html#create_room/4","title":"AWS.Chime.create_room/4","type":"function","doc":"Creates a chat room for the specified Amazon Chime Enterprise account."},{"ref":"AWS.Chime.html#create_room_membership/5","title":"AWS.Chime.create_room_membership/5","type":"function","doc":"Adds a member to a chat room in an Amazon Chime Enterprise account. A member can be either a user or a bot. The member role designates whether the member is a chat room administrator or a general chat room member."},{"ref":"AWS.Chime.html#create_user/4","title":"AWS.Chime.create_user/4","type":"function","doc":"Creates a user under the specified Amazon Chime account."},{"ref":"AWS.Chime.html#create_voice_connector/3","title":"AWS.Chime.create_voice_connector/3","type":"function","doc":"Creates an Amazon Chime Voice Connector under the administrator&#39;s AWS account. You can choose to create an Amazon Chime Voice Connector in a specific AWS Region. Enabling CreateVoiceConnectorRequest$RequireEncryption configures your Amazon Chime Voice Connector to use TLS transport for SIP signaling and Secure RTP (SRTP) for media. Inbound calls use TLS transport, and unencrypted outbound calls are blocked."},{"ref":"AWS.Chime.html#create_voice_connector_group/3","title":"AWS.Chime.create_voice_connector_group/3","type":"function","doc":"Creates an Amazon Chime Voice Connector group under the administrator&#39;s AWS account. You can associate Amazon Chime Voice Connectors with the Amazon Chime Voice Connector group by including VoiceConnectorItems in the request. You can include Amazon Chime Voice Connectors from different AWS Regions in your group. This creates a fault tolerant mechanism for fallback in case of availability events."},{"ref":"AWS.Chime.html#delete_account/4","title":"AWS.Chime.delete_account/4","type":"function","doc":"Deletes the specified Amazon Chime account. You must suspend all users before deleting a Team account. You can use the BatchSuspendUser action to do so. For EnterpriseLWA and EnterpriseAD accounts, you must release the claimed domains for your Amazon Chime account before deletion. As soon as you release the domain, all users under that account are suspended. Deleted accounts appear in your Disabled accounts list for 90 days. To restore a deleted account from your Disabled accounts list, you must contact AWS Support. After 90 days, deleted accounts are permanently removed from your Disabled accounts list."},{"ref":"AWS.Chime.html#delete_attendee/5","title":"AWS.Chime.delete_attendee/5","type":"function","doc":"Deletes an attendee from the specified Amazon Chime SDK meeting and deletes their JoinToken. Attendees are automatically deleted when a Amazon Chime SDK meeting is deleted. For more information about the Amazon Chime SDK, see Using the Amazon Chime SDK in the Amazon Chime Developer Guide."},{"ref":"AWS.Chime.html#delete_events_configuration/5","title":"AWS.Chime.delete_events_configuration/5","type":"function","doc":"Deletes the events configuration that allows a bot to receive outgoing events."},{"ref":"AWS.Chime.html#delete_meeting/4","title":"AWS.Chime.delete_meeting/4","type":"function","doc":"Deletes the specified Amazon Chime SDK meeting. When a meeting is deleted, its attendees are also deleted and clients can no longer join it. For more information about the Amazon Chime SDK, see Using the Amazon Chime SDK in the Amazon Chime Developer Guide."},{"ref":"AWS.Chime.html#delete_phone_number/4","title":"AWS.Chime.delete_phone_number/4","type":"function","doc":"Moves the specified phone number into the Deletion queue. A phone number must be disassociated from any users or Amazon Chime Voice Connectors before it can be deleted. Deleted phone numbers remain in the Deletion queue for 7 days before they are deleted permanently."},{"ref":"AWS.Chime.html#delete_proxy_session/5","title":"AWS.Chime.delete_proxy_session/5","type":"function","doc":"Deletes the specified proxy session from the specified Amazon Chime Voice Connector."},{"ref":"AWS.Chime.html#delete_room/5","title":"AWS.Chime.delete_room/5","type":"function","doc":"Deletes a chat room in an Amazon Chime Enterprise account."},{"ref":"AWS.Chime.html#delete_room_membership/6","title":"AWS.Chime.delete_room_membership/6","type":"function","doc":"Removes a member from a chat room in an Amazon Chime Enterprise account."},{"ref":"AWS.Chime.html#delete_voice_connector/4","title":"AWS.Chime.delete_voice_connector/4","type":"function","doc":"Deletes the specified Amazon Chime Voice Connector. Any phone numbers associated with the Amazon Chime Voice Connector must be disassociated from it before it can be deleted."},{"ref":"AWS.Chime.html#delete_voice_connector_emergency_calling_configuration/4","title":"AWS.Chime.delete_voice_connector_emergency_calling_configuration/4","type":"function","doc":"Deletes the emergency calling configuration details from the specified Amazon Chime Voice Connector."},{"ref":"AWS.Chime.html#delete_voice_connector_group/4","title":"AWS.Chime.delete_voice_connector_group/4","type":"function","doc":"Deletes the specified Amazon Chime Voice Connector group. Any VoiceConnectorItems and phone numbers associated with the group must be removed before it can be deleted."},{"ref":"AWS.Chime.html#delete_voice_connector_origination/4","title":"AWS.Chime.delete_voice_connector_origination/4","type":"function","doc":"Deletes the origination settings for the specified Amazon Chime Voice Connector. If emergency calling is configured for the Amazon Chime Voice Connector, it must be deleted prior to deleting the origination settings."},{"ref":"AWS.Chime.html#delete_voice_connector_proxy/4","title":"AWS.Chime.delete_voice_connector_proxy/4","type":"function","doc":"Deletes the proxy configuration from the specified Amazon Chime Voice Connector."},{"ref":"AWS.Chime.html#delete_voice_connector_streaming_configuration/4","title":"AWS.Chime.delete_voice_connector_streaming_configuration/4","type":"function","doc":"Deletes the streaming configuration for the specified Amazon Chime Voice Connector."},{"ref":"AWS.Chime.html#delete_voice_connector_termination/4","title":"AWS.Chime.delete_voice_connector_termination/4","type":"function","doc":"Deletes the termination settings for the specified Amazon Chime Voice Connector. If emergency calling is configured for the Amazon Chime Voice Connector, it must be deleted prior to deleting the termination settings."},{"ref":"AWS.Chime.html#delete_voice_connector_termination_credentials/4","title":"AWS.Chime.delete_voice_connector_termination_credentials/4","type":"function","doc":"Deletes the specified SIP credentials used by your equipment to authenticate during call termination."},{"ref":"AWS.Chime.html#disassociate_phone_number_from_user/5","title":"AWS.Chime.disassociate_phone_number_from_user/5","type":"function","doc":"Disassociates the primary provisioned phone number from the specified Amazon Chime user."},{"ref":"AWS.Chime.html#disassociate_phone_numbers_from_voice_connector/4","title":"AWS.Chime.disassociate_phone_numbers_from_voice_connector/4","type":"function","doc":"Disassociates the specified phone numbers from the specified Amazon Chime Voice Connector."},{"ref":"AWS.Chime.html#disassociate_phone_numbers_from_voice_connector_group/4","title":"AWS.Chime.disassociate_phone_numbers_from_voice_connector_group/4","type":"function","doc":"Disassociates the specified phone numbers from the specified Amazon Chime Voice Connector group."},{"ref":"AWS.Chime.html#disassociate_signin_delegate_groups_from_account/4","title":"AWS.Chime.disassociate_signin_delegate_groups_from_account/4","type":"function","doc":"Disassociates the specified sign-in delegate groups from the specified Amazon Chime account."},{"ref":"AWS.Chime.html#get_account/3","title":"AWS.Chime.get_account/3","type":"function","doc":"Retrieves details for the specified Amazon Chime account, such as account type and supported licenses."},{"ref":"AWS.Chime.html#get_account_settings/3","title":"AWS.Chime.get_account_settings/3","type":"function","doc":"Retrieves account settings for the specified Amazon Chime account ID, such as remote control and dial out settings. For more information about these settings, see Use the Policies Page in the Amazon Chime Administration Guide."},{"ref":"AWS.Chime.html#get_attendee/4","title":"AWS.Chime.get_attendee/4","type":"function","doc":"Gets the Amazon Chime SDK attendee details for a specified meeting ID and attendee ID. For more information about the Amazon Chime SDK, see Using the Amazon Chime SDK in the Amazon Chime Developer Guide."},{"ref":"AWS.Chime.html#get_bot/4","title":"AWS.Chime.get_bot/4","type":"function","doc":"Retrieves details for the specified bot, such as bot email address, bot type, status, and display name."},{"ref":"AWS.Chime.html#get_events_configuration/4","title":"AWS.Chime.get_events_configuration/4","type":"function","doc":"Gets details for an events configuration that allows a bot to receive outgoing events, such as an HTTPS endpoint or Lambda function ARN."},{"ref":"AWS.Chime.html#get_global_settings/2","title":"AWS.Chime.get_global_settings/2","type":"function","doc":"Retrieves global settings for the administrator&#39;s AWS account, such as Amazon Chime Business Calling and Amazon Chime Voice Connector settings."},{"ref":"AWS.Chime.html#get_meeting/3","title":"AWS.Chime.get_meeting/3","type":"function","doc":"Gets the Amazon Chime SDK meeting details for the specified meeting ID. For more information about the Amazon Chime SDK, see Using the Amazon Chime SDK in the Amazon Chime Developer Guide."},{"ref":"AWS.Chime.html#get_phone_number/3","title":"AWS.Chime.get_phone_number/3","type":"function","doc":"Retrieves details for the specified phone number ID, such as associations, capabilities, and product type."},{"ref":"AWS.Chime.html#get_phone_number_order/3","title":"AWS.Chime.get_phone_number_order/3","type":"function","doc":"Retrieves details for the specified phone number order, such as order creation timestamp, phone numbers in E.164 format, product type, and order status."},{"ref":"AWS.Chime.html#get_phone_number_settings/2","title":"AWS.Chime.get_phone_number_settings/2","type":"function","doc":"Retrieves the phone number settings for the administrator&#39;s AWS account, such as the default outbound calling name."},{"ref":"AWS.Chime.html#get_proxy_session/4","title":"AWS.Chime.get_proxy_session/4","type":"function","doc":"Gets the specified proxy session details for the specified Amazon Chime Voice Connector."},{"ref":"AWS.Chime.html#get_retention_settings/3","title":"AWS.Chime.get_retention_settings/3","type":"function","doc":"Gets the retention settings for the specified Amazon Chime Enterprise account. For more information about retention settings, see Managing Chat Retention Policies in the Amazon Chime Administration Guide."},{"ref":"AWS.Chime.html#get_room/4","title":"AWS.Chime.get_room/4","type":"function","doc":"Retrieves room details, such as the room name, for a room in an Amazon Chime Enterprise account."},{"ref":"AWS.Chime.html#get_user/4","title":"AWS.Chime.get_user/4","type":"function","doc":"Retrieves details for the specified user ID, such as primary email address, license type, and personal meeting PIN. To retrieve user details with an email address instead of a user ID, use the ListUsers action, and then filter by email address."},{"ref":"AWS.Chime.html#get_user_settings/4","title":"AWS.Chime.get_user_settings/4","type":"function","doc":"Retrieves settings for the specified user ID, such as any associated phone number settings."},{"ref":"AWS.Chime.html#get_voice_connector/3","title":"AWS.Chime.get_voice_connector/3","type":"function","doc":"Retrieves details for the specified Amazon Chime Voice Connector, such as timestamps, name, outbound host, and encryption requirements."},{"ref":"AWS.Chime.html#get_voice_connector_emergency_calling_configuration/3","title":"AWS.Chime.get_voice_connector_emergency_calling_configuration/3","type":"function","doc":"Gets the emergency calling configuration details for the specified Amazon Chime Voice Connector."},{"ref":"AWS.Chime.html#get_voice_connector_group/3","title":"AWS.Chime.get_voice_connector_group/3","type":"function","doc":"Retrieves details for the specified Amazon Chime Voice Connector group, such as timestamps, name, and associated VoiceConnectorItems."},{"ref":"AWS.Chime.html#get_voice_connector_logging_configuration/3","title":"AWS.Chime.get_voice_connector_logging_configuration/3","type":"function","doc":"Retrieves the logging configuration details for the specified Amazon Chime Voice Connector. Shows whether SIP message logs are enabled for sending to Amazon CloudWatch Logs."},{"ref":"AWS.Chime.html#get_voice_connector_origination/3","title":"AWS.Chime.get_voice_connector_origination/3","type":"function","doc":"Retrieves origination setting details for the specified Amazon Chime Voice Connector."},{"ref":"AWS.Chime.html#get_voice_connector_proxy/3","title":"AWS.Chime.get_voice_connector_proxy/3","type":"function","doc":"Gets the proxy configuration details for the specified Amazon Chime Voice Connector."},{"ref":"AWS.Chime.html#get_voice_connector_streaming_configuration/3","title":"AWS.Chime.get_voice_connector_streaming_configuration/3","type":"function","doc":"Retrieves the streaming configuration details for the specified Amazon Chime Voice Connector. Shows whether media streaming is enabled for sending to Amazon Kinesis. It also shows the retention period, in hours, for the Amazon Kinesis data."},{"ref":"AWS.Chime.html#get_voice_connector_termination/3","title":"AWS.Chime.get_voice_connector_termination/3","type":"function","doc":"Retrieves termination setting details for the specified Amazon Chime Voice Connector."},{"ref":"AWS.Chime.html#get_voice_connector_termination_health/3","title":"AWS.Chime.get_voice_connector_termination_health/3","type":"function","doc":"Retrieves information about the last time a SIP OPTIONS ping was received from your SIP infrastructure for the specified Amazon Chime Voice Connector."},{"ref":"AWS.Chime.html#invite_users/4","title":"AWS.Chime.invite_users/4","type":"function","doc":"Sends email to a maximum of 50 users, inviting them to the specified Amazon Chime Team account. Only Team account types are currently supported for this action."},{"ref":"AWS.Chime.html#list_accounts/6","title":"AWS.Chime.list_accounts/6","type":"function","doc":"Lists the Amazon Chime accounts under the administrator&#39;s AWS account. You can filter accounts by account name prefix. To find out which Amazon Chime account a user belongs to, you can filter by the user&#39;s email address, which returns one account result."},{"ref":"AWS.Chime.html#list_attendee_tags/4","title":"AWS.Chime.list_attendee_tags/4","type":"function","doc":"Lists the tags applied to an Amazon Chime SDK attendee resource."},{"ref":"AWS.Chime.html#list_attendees/5","title":"AWS.Chime.list_attendees/5","type":"function","doc":"Lists the attendees for the specified Amazon Chime SDK meeting. For more information about the Amazon Chime SDK, see Using the Amazon Chime SDK in the Amazon Chime Developer Guide."},{"ref":"AWS.Chime.html#list_bots/5","title":"AWS.Chime.list_bots/5","type":"function","doc":"Lists the bots associated with the administrator&#39;s Amazon Chime Enterprise account ID."},{"ref":"AWS.Chime.html#list_meeting_tags/3","title":"AWS.Chime.list_meeting_tags/3","type":"function","doc":"Lists the tags applied to an Amazon Chime SDK meeting resource."},{"ref":"AWS.Chime.html#list_meetings/4","title":"AWS.Chime.list_meetings/4","type":"function","doc":"Lists up to 100 active Amazon Chime SDK meetings. For more information about the Amazon Chime SDK, see Using the Amazon Chime SDK in the Amazon Chime Developer Guide."},{"ref":"AWS.Chime.html#list_phone_number_orders/4","title":"AWS.Chime.list_phone_number_orders/4","type":"function","doc":"Lists the phone number orders for the administrator&#39;s Amazon Chime account."},{"ref":"AWS.Chime.html#list_phone_numbers/8","title":"AWS.Chime.list_phone_numbers/8","type":"function","doc":"Lists the phone numbers for the specified Amazon Chime account, Amazon Chime user, Amazon Chime Voice Connector, or Amazon Chime Voice Connector group."},{"ref":"AWS.Chime.html#list_proxy_sessions/6","title":"AWS.Chime.list_proxy_sessions/6","type":"function","doc":"Lists the proxy sessions for the specified Amazon Chime Voice Connector."},{"ref":"AWS.Chime.html#list_room_memberships/6","title":"AWS.Chime.list_room_memberships/6","type":"function","doc":"Lists the membership details for the specified room in an Amazon Chime Enterprise account, such as the members&#39; IDs, email addresses, and names."},{"ref":"AWS.Chime.html#list_rooms/6","title":"AWS.Chime.list_rooms/6","type":"function","doc":"Lists the room details for the specified Amazon Chime Enterprise account. Optionally, filter the results by a member ID (user ID or bot ID) to see a list of rooms that the member belongs to."},{"ref":"AWS.Chime.html#list_tags_for_resource/3","title":"AWS.Chime.list_tags_for_resource/3","type":"function","doc":"Lists the tags applied to an Amazon Chime SDK meeting resource."},{"ref":"AWS.Chime.html#list_users/7","title":"AWS.Chime.list_users/7","type":"function","doc":"Lists the users that belong to the specified Amazon Chime account. You can specify an email address to list only the user that the email address belongs to."},{"ref":"AWS.Chime.html#list_voice_connector_groups/4","title":"AWS.Chime.list_voice_connector_groups/4","type":"function","doc":"Lists the Amazon Chime Voice Connector groups for the administrator&#39;s AWS account."},{"ref":"AWS.Chime.html#list_voice_connector_termination_credentials/3","title":"AWS.Chime.list_voice_connector_termination_credentials/3","type":"function","doc":"Lists the SIP credentials for the specified Amazon Chime Voice Connector."},{"ref":"AWS.Chime.html#list_voice_connectors/4","title":"AWS.Chime.list_voice_connectors/4","type":"function","doc":"Lists the Amazon Chime Voice Connectors for the administrator&#39;s AWS account."},{"ref":"AWS.Chime.html#logout_user/5","title":"AWS.Chime.logout_user/5","type":"function","doc":"Logs out the specified user from all of the devices they are currently logged into."},{"ref":"AWS.Chime.html#put_events_configuration/5","title":"AWS.Chime.put_events_configuration/5","type":"function","doc":"Creates an events configuration that allows a bot to receive outgoing events sent by Amazon Chime. Choose either an HTTPS endpoint or a Lambda function ARN. For more information, see Bot."},{"ref":"AWS.Chime.html#put_retention_settings/4","title":"AWS.Chime.put_retention_settings/4","type":"function","doc":"Puts retention settings for the specified Amazon Chime Enterprise account. We recommend using AWS CloudTrail to monitor usage of this API for your account. For more information, see Logging Amazon Chime API Calls with AWS CloudTrail in the Amazon Chime Administration Guide. To turn off existing retention settings, remove the number of days from the corresponding RetentionDays field in the RetentionSettings object. For more information about retention settings, see Managing Chat Retention Policies in the Amazon Chime Administration Guide."},{"ref":"AWS.Chime.html#put_voice_connector_emergency_calling_configuration/4","title":"AWS.Chime.put_voice_connector_emergency_calling_configuration/4","type":"function","doc":"Puts emergency calling configuration details to the specified Amazon Chime Voice Connector, such as emergency phone numbers and calling countries. Origination and termination settings must be enabled for the Amazon Chime Voice Connector before emergency calling can be configured."},{"ref":"AWS.Chime.html#put_voice_connector_logging_configuration/4","title":"AWS.Chime.put_voice_connector_logging_configuration/4","type":"function","doc":"Adds a logging configuration for the specified Amazon Chime Voice Connector. The logging configuration specifies whether SIP message logs are enabled for sending to Amazon CloudWatch Logs."},{"ref":"AWS.Chime.html#put_voice_connector_origination/4","title":"AWS.Chime.put_voice_connector_origination/4","type":"function","doc":"Adds origination settings for the specified Amazon Chime Voice Connector. If emergency calling is configured for the Amazon Chime Voice Connector, it must be deleted prior to turning off origination settings."},{"ref":"AWS.Chime.html#put_voice_connector_proxy/4","title":"AWS.Chime.put_voice_connector_proxy/4","type":"function","doc":"Puts the specified proxy configuration to the specified Amazon Chime Voice Connector."},{"ref":"AWS.Chime.html#put_voice_connector_streaming_configuration/4","title":"AWS.Chime.put_voice_connector_streaming_configuration/4","type":"function","doc":"Adds a streaming configuration for the specified Amazon Chime Voice Connector. The streaming configuration specifies whether media streaming is enabled for sending to Amazon Kinesis. It also sets the retention period, in hours, for the Amazon Kinesis data."},{"ref":"AWS.Chime.html#put_voice_connector_termination/4","title":"AWS.Chime.put_voice_connector_termination/4","type":"function","doc":"Adds termination settings for the specified Amazon Chime Voice Connector. If emergency calling is configured for the Amazon Chime Voice Connector, it must be deleted prior to turning off termination settings."},{"ref":"AWS.Chime.html#put_voice_connector_termination_credentials/4","title":"AWS.Chime.put_voice_connector_termination_credentials/4","type":"function","doc":"Adds termination SIP credentials for the specified Amazon Chime Voice Connector."},{"ref":"AWS.Chime.html#redact_conversation_message/6","title":"AWS.Chime.redact_conversation_message/6","type":"function","doc":"Redacts the specified message from the specified Amazon Chime conversation."},{"ref":"AWS.Chime.html#redact_room_message/6","title":"AWS.Chime.redact_room_message/6","type":"function","doc":"Redacts the specified message from the specified Amazon Chime chat room."},{"ref":"AWS.Chime.html#regenerate_security_token/5","title":"AWS.Chime.regenerate_security_token/5","type":"function","doc":"Regenerates the security token for a bot."},{"ref":"AWS.Chime.html#reset_personal_p_i_n/5","title":"AWS.Chime.reset_personal_p_i_n/5","type":"function","doc":"Resets the personal meeting PIN for the specified user on an Amazon Chime account. Returns the User object with the updated personal meeting PIN."},{"ref":"AWS.Chime.html#restore_phone_number/4","title":"AWS.Chime.restore_phone_number/4","type":"function","doc":"Moves a phone number from the Deletion queue back into the phone number Inventory."},{"ref":"AWS.Chime.html#search_available_phone_numbers/9","title":"AWS.Chime.search_available_phone_numbers/9","type":"function","doc":"Searches phone numbers that can be ordered."},{"ref":"AWS.Chime.html#tag_attendee/5","title":"AWS.Chime.tag_attendee/5","type":"function","doc":"Applies the specified tags to the specified Amazon Chime SDK attendee."},{"ref":"AWS.Chime.html#tag_meeting/4","title":"AWS.Chime.tag_meeting/4","type":"function","doc":"Applies the specified tags to the specified Amazon Chime SDK meeting."},{"ref":"AWS.Chime.html#tag_resource/3","title":"AWS.Chime.tag_resource/3","type":"function","doc":"Applies the specified tags to the specified Amazon Chime SDK meeting resource."},{"ref":"AWS.Chime.html#untag_attendee/5","title":"AWS.Chime.untag_attendee/5","type":"function","doc":"Untags the specified tags from the specified Amazon Chime SDK attendee."},{"ref":"AWS.Chime.html#untag_meeting/4","title":"AWS.Chime.untag_meeting/4","type":"function","doc":"Untags the specified tags from the specified Amazon Chime SDK meeting."},{"ref":"AWS.Chime.html#untag_resource/3","title":"AWS.Chime.untag_resource/3","type":"function","doc":"Untags the specified tags from the specified Amazon Chime SDK meeting resource."},{"ref":"AWS.Chime.html#update_account/4","title":"AWS.Chime.update_account/4","type":"function","doc":"Updates account details for the specified Amazon Chime account. Currently, only account name updates are supported for this action."},{"ref":"AWS.Chime.html#update_account_settings/4","title":"AWS.Chime.update_account_settings/4","type":"function","doc":"Updates the settings for the specified Amazon Chime account. You can update settings for remote control of shared screens, or for the dial-out option. For more information about these settings, see Use the Policies Page in the Amazon Chime Administration Guide."},{"ref":"AWS.Chime.html#update_bot/5","title":"AWS.Chime.update_bot/5","type":"function","doc":"Updates the status of the specified bot, such as starting or stopping the bot from running in your Amazon Chime Enterprise account."},{"ref":"AWS.Chime.html#update_global_settings/3","title":"AWS.Chime.update_global_settings/3","type":"function","doc":"Updates global settings for the administrator&#39;s AWS account, such as Amazon Chime Business Calling and Amazon Chime Voice Connector settings."},{"ref":"AWS.Chime.html#update_phone_number/4","title":"AWS.Chime.update_phone_number/4","type":"function","doc":"Updates phone number details, such as product type or calling name, for the specified phone number ID. You can update one phone number detail at a time. For example, you can update either the product type or the calling name in one action. For toll-free numbers, you must use the Amazon Chime Voice Connector product type. Updates to outbound calling names can take up to 72 hours to complete. Pending updates to outbound calling names must be complete before you can request another update."},{"ref":"AWS.Chime.html#update_phone_number_settings/3","title":"AWS.Chime.update_phone_number_settings/3","type":"function","doc":"Updates the phone number settings for the administrator&#39;s AWS account, such as the default outbound calling name. You can update the default outbound calling name once every seven days. Outbound calling names can take up to 72 hours to update."},{"ref":"AWS.Chime.html#update_proxy_session/5","title":"AWS.Chime.update_proxy_session/5","type":"function","doc":"Updates the specified proxy session details, such as voice or SMS capabilities."},{"ref":"AWS.Chime.html#update_room/5","title":"AWS.Chime.update_room/5","type":"function","doc":"Updates room details, such as the room name, for a room in an Amazon Chime Enterprise account."},{"ref":"AWS.Chime.html#update_room_membership/6","title":"AWS.Chime.update_room_membership/6","type":"function","doc":"Updates room membership details, such as the member role, for a room in an Amazon Chime Enterprise account. The member role designates whether the member is a chat room administrator or a general chat room member. The member role can be updated only for user IDs."},{"ref":"AWS.Chime.html#update_user/5","title":"AWS.Chime.update_user/5","type":"function","doc":"Updates user details for a specified user ID. Currently, only LicenseType updates are supported for this action."},{"ref":"AWS.Chime.html#update_user_settings/5","title":"AWS.Chime.update_user_settings/5","type":"function","doc":"Updates the settings for the specified user, such as phone number settings."},{"ref":"AWS.Chime.html#update_voice_connector/4","title":"AWS.Chime.update_voice_connector/4","type":"function","doc":"Updates details for the specified Amazon Chime Voice Connector."},{"ref":"AWS.Chime.html#update_voice_connector_group/4","title":"AWS.Chime.update_voice_connector_group/4","type":"function","doc":"Updates details for the specified Amazon Chime Voice Connector group, such as the name and Amazon Chime Voice Connector priority ranking."},{"ref":"AWS.Client.html","title":"AWS.Client","type":"module","doc":"Access and connections details needed when making requests to AWS services."},{"ref":"AWS.Client.html#create/0","title":"AWS.Client.create/0","type":"function","doc":""},{"ref":"AWS.Client.html#create/1","title":"AWS.Client.create/1","type":"function","doc":""},{"ref":"AWS.Client.html#create/3","title":"AWS.Client.create/3","type":"function","doc":""},{"ref":"AWS.Client.html#create/4","title":"AWS.Client.create/4","type":"function","doc":""},{"ref":"AWS.Client.html#decode!/3","title":"AWS.Client.decode!/3","type":"function","doc":""},{"ref":"AWS.Client.html#encode!/3","title":"AWS.Client.encode!/3","type":"function","doc":""},{"ref":"AWS.Client.html#request/6","title":"AWS.Client.request/6","type":"function","doc":""},{"ref":"AWS.Client.html#t:t/0","title":"AWS.Client.t/0","type":"type","doc":""},{"ref":"AWS.Cloud9.html","title":"AWS.Cloud9","type":"module","doc":"AWS Cloud9 AWS Cloud9 is a collection of tools that you can use to code, build, run, test, debug, and release software in the cloud. For more information about AWS Cloud9, see the AWS Cloud9 User Guide. AWS Cloud9 supports these operations: CreateEnvironmentEC2: Creates an AWS Cloud9 development environment, launches an Amazon EC2 instance, and then connects from the instance to the environment. CreateEnvironmentMembership: Adds an environment member to an environment. DeleteEnvironment: Deletes an environment. If an Amazon EC2 instance is connected to the environment, also terminates the instance. DeleteEnvironmentMembership: Deletes an environment member from an environment. DescribeEnvironmentMemberships: Gets information about environment members for an environment. DescribeEnvironments: Gets information about environments. DescribeEnvironmentStatus: Gets status information for an environment. ListEnvironments: Gets a list of environment identifiers. ListTagsForResource: Gets the tags for an environment. TagResource: Adds tags to an environment. UntagResource: Removes tags from an environment. UpdateEnvironment: Changes the settings of an existing environment. UpdateEnvironmentMembership: Changes the settings of an existing environment member for an environment."},{"ref":"AWS.Cloud9.html#create_environment_e_c2/3","title":"AWS.Cloud9.create_environment_e_c2/3","type":"function","doc":"Creates an AWS Cloud9 development environment, launches an Amazon Elastic Compute Cloud (Amazon EC2) instance, and then connects from the instance to the environment."},{"ref":"AWS.Cloud9.html#create_environment_membership/3","title":"AWS.Cloud9.create_environment_membership/3","type":"function","doc":"Adds an environment member to an AWS Cloud9 development environment."},{"ref":"AWS.Cloud9.html#delete_environment/3","title":"AWS.Cloud9.delete_environment/3","type":"function","doc":"Deletes an AWS Cloud9 development environment. If an Amazon EC2 instance is connected to the environment, also terminates the instance."},{"ref":"AWS.Cloud9.html#delete_environment_membership/3","title":"AWS.Cloud9.delete_environment_membership/3","type":"function","doc":"Deletes an environment member from an AWS Cloud9 development environment."},{"ref":"AWS.Cloud9.html#describe_environment_memberships/3","title":"AWS.Cloud9.describe_environment_memberships/3","type":"function","doc":"Gets information about environment members for an AWS Cloud9 development environment."},{"ref":"AWS.Cloud9.html#describe_environment_status/3","title":"AWS.Cloud9.describe_environment_status/3","type":"function","doc":"Gets status information for an AWS Cloud9 development environment."},{"ref":"AWS.Cloud9.html#describe_environments/3","title":"AWS.Cloud9.describe_environments/3","type":"function","doc":"Gets information about AWS Cloud9 development environments."},{"ref":"AWS.Cloud9.html#list_environments/3","title":"AWS.Cloud9.list_environments/3","type":"function","doc":"Gets a list of AWS Cloud9 development environment identifiers."},{"ref":"AWS.Cloud9.html#list_tags_for_resource/3","title":"AWS.Cloud9.list_tags_for_resource/3","type":"function","doc":"Gets a list of the tags associated with an AWS Cloud9 development environment."},{"ref":"AWS.Cloud9.html#tag_resource/3","title":"AWS.Cloud9.tag_resource/3","type":"function","doc":"Adds tags to an AWS Cloud9 development environment. Tags that you add to an AWS Cloud9 environment by using this method will NOT be automatically propagated to underlying resources."},{"ref":"AWS.Cloud9.html#untag_resource/3","title":"AWS.Cloud9.untag_resource/3","type":"function","doc":"Removes tags from an AWS Cloud9 development environment."},{"ref":"AWS.Cloud9.html#update_environment/3","title":"AWS.Cloud9.update_environment/3","type":"function","doc":"Changes the settings of an existing AWS Cloud9 development environment."},{"ref":"AWS.Cloud9.html#update_environment_membership/3","title":"AWS.Cloud9.update_environment_membership/3","type":"function","doc":"Changes the settings of an existing environment member for an AWS Cloud9 development environment."},{"ref":"AWS.CloudDirectory.html","title":"AWS.CloudDirectory","type":"module","doc":"Amazon Cloud Directory Amazon Cloud Directory is a component of the AWS Directory Service that simplifies the development and management of cloud-scale web, mobile, and IoT applications. This guide describes the Cloud Directory operations that you can call programmatically and includes detailed information on data types and errors. For information about Cloud Directory features, see AWS Directory Service and the Amazon Cloud Directory Developer Guide."},{"ref":"AWS.CloudDirectory.html#add_facet_to_object/3","title":"AWS.CloudDirectory.add_facet_to_object/3","type":"function","doc":"Adds a new Facet to an object. An object can have more than one facet applied on it."},{"ref":"AWS.CloudDirectory.html#apply_schema/3","title":"AWS.CloudDirectory.apply_schema/3","type":"function","doc":"Copies the input published schema, at the specified version, into the Directory with the same name and version as that of the published schema."},{"ref":"AWS.CloudDirectory.html#attach_object/3","title":"AWS.CloudDirectory.attach_object/3","type":"function","doc":"Attaches an existing object to another object. An object can be accessed in two ways: Using the path Using ObjectIdentifier"},{"ref":"AWS.CloudDirectory.html#attach_policy/3","title":"AWS.CloudDirectory.attach_policy/3","type":"function","doc":"Attaches a policy object to a regular object. An object can have a limited number of attached policies."},{"ref":"AWS.CloudDirectory.html#attach_to_index/3","title":"AWS.CloudDirectory.attach_to_index/3","type":"function","doc":"Attaches the specified object to the specified index."},{"ref":"AWS.CloudDirectory.html#attach_typed_link/3","title":"AWS.CloudDirectory.attach_typed_link/3","type":"function","doc":"Attaches a typed link to a specified source and target object. For more information, see Typed Links."},{"ref":"AWS.CloudDirectory.html#batch_read/3","title":"AWS.CloudDirectory.batch_read/3","type":"function","doc":"Performs all the read operations in a batch."},{"ref":"AWS.CloudDirectory.html#batch_write/3","title":"AWS.CloudDirectory.batch_write/3","type":"function","doc":"Performs all the write operations in a batch. Either all the operations succeed or none."},{"ref":"AWS.CloudDirectory.html#create_directory/3","title":"AWS.CloudDirectory.create_directory/3","type":"function","doc":"Creates a Directory by copying the published schema into the directory. A directory cannot be created without a schema. You can also quickly create a directory using a managed schema, called the QuickStartSchema. For more information, see Managed Schema in the Amazon Cloud Directory Developer Guide."},{"ref":"AWS.CloudDirectory.html#create_facet/3","title":"AWS.CloudDirectory.create_facet/3","type":"function","doc":"Creates a new Facet in a schema. Facet creation is allowed only in development or applied schemas."},{"ref":"AWS.CloudDirectory.html#create_index/3","title":"AWS.CloudDirectory.create_index/3","type":"function","doc":"Creates an index object. See Indexing and search for more information."},{"ref":"AWS.CloudDirectory.html#create_object/3","title":"AWS.CloudDirectory.create_object/3","type":"function","doc":"Creates an object in a Directory. Additionally attaches the object to a parent, if a parent reference and LinkName is specified. An object is simply a collection of Facet attributes. You can also use this API call to create a policy object, if the facet from which you create the object is a policy facet."},{"ref":"AWS.CloudDirectory.html#create_schema/3","title":"AWS.CloudDirectory.create_schema/3","type":"function","doc":"Creates a new schema in a development state. A schema can exist in three phases: Development: This is a mutable phase of the schema. All new schemas are in the development phase. Once the schema is finalized, it can be published. Published: Published schemas are immutable and have a version associated with them. Applied: Applied schemas are mutable in a way that allows you to add new schema facets. You can also add new, nonrequired attributes to existing schema facets. You can apply only published schemas to directories."},{"ref":"AWS.CloudDirectory.html#create_typed_link_facet/3","title":"AWS.CloudDirectory.create_typed_link_facet/3","type":"function","doc":"Creates a TypedLinkFacet. For more information, see Typed Links."},{"ref":"AWS.CloudDirectory.html#delete_directory/3","title":"AWS.CloudDirectory.delete_directory/3","type":"function","doc":"Deletes a directory. Only disabled directories can be deleted. A deleted directory cannot be undone. Exercise extreme caution when deleting directories."},{"ref":"AWS.CloudDirectory.html#delete_facet/3","title":"AWS.CloudDirectory.delete_facet/3","type":"function","doc":"Deletes a given Facet. All attributes and Rules that are associated with the facet will be deleted. Only development schema facets are allowed deletion."},{"ref":"AWS.CloudDirectory.html#delete_object/3","title":"AWS.CloudDirectory.delete_object/3","type":"function","doc":"Deletes an object and its associated attributes. Only objects with no children and no parents can be deleted. The maximum number of attributes that can be deleted during an object deletion is 30. For more information, see Amazon Cloud Directory Limits."},{"ref":"AWS.CloudDirectory.html#delete_schema/3","title":"AWS.CloudDirectory.delete_schema/3","type":"function","doc":"Deletes a given schema. Schemas in a development and published state can only be deleted."},{"ref":"AWS.CloudDirectory.html#delete_typed_link_facet/3","title":"AWS.CloudDirectory.delete_typed_link_facet/3","type":"function","doc":"Deletes a TypedLinkFacet. For more information, see Typed Links."},{"ref":"AWS.CloudDirectory.html#detach_from_index/3","title":"AWS.CloudDirectory.detach_from_index/3","type":"function","doc":"Detaches the specified object from the specified index."},{"ref":"AWS.CloudDirectory.html#detach_object/3","title":"AWS.CloudDirectory.detach_object/3","type":"function","doc":"Detaches a given object from the parent object. The object that is to be detached from the parent is specified by the link name."},{"ref":"AWS.CloudDirectory.html#detach_policy/3","title":"AWS.CloudDirectory.detach_policy/3","type":"function","doc":"Detaches a policy from an object."},{"ref":"AWS.CloudDirectory.html#detach_typed_link/3","title":"AWS.CloudDirectory.detach_typed_link/3","type":"function","doc":"Detaches a typed link from a specified source and target object. For more information, see Typed Links."},{"ref":"AWS.CloudDirectory.html#disable_directory/3","title":"AWS.CloudDirectory.disable_directory/3","type":"function","doc":"Disables the specified directory. Disabled directories cannot be read or written to. Only enabled directories can be disabled. Disabled directories may be reenabled."},{"ref":"AWS.CloudDirectory.html#enable_directory/3","title":"AWS.CloudDirectory.enable_directory/3","type":"function","doc":"Enables the specified directory. Only disabled directories can be enabled. Once enabled, the directory can then be read and written to."},{"ref":"AWS.CloudDirectory.html#get_applied_schema_version/3","title":"AWS.CloudDirectory.get_applied_schema_version/3","type":"function","doc":"Returns current applied schema version ARN, including the minor version in use."},{"ref":"AWS.CloudDirectory.html#get_directory/3","title":"AWS.CloudDirectory.get_directory/3","type":"function","doc":"Retrieves metadata about a directory."},{"ref":"AWS.CloudDirectory.html#get_facet/3","title":"AWS.CloudDirectory.get_facet/3","type":"function","doc":"Gets details of the Facet, such as facet name, attributes, Rules, or ObjectType. You can call this on all kinds of schema facets -- published, development, or applied."},{"ref":"AWS.CloudDirectory.html#get_link_attributes/3","title":"AWS.CloudDirectory.get_link_attributes/3","type":"function","doc":"Retrieves attributes that are associated with a typed link."},{"ref":"AWS.CloudDirectory.html#get_object_attributes/3","title":"AWS.CloudDirectory.get_object_attributes/3","type":"function","doc":"Retrieves attributes within a facet that are associated with an object."},{"ref":"AWS.CloudDirectory.html#get_object_information/3","title":"AWS.CloudDirectory.get_object_information/3","type":"function","doc":"Retrieves metadata about an object."},{"ref":"AWS.CloudDirectory.html#get_schema_as_json/3","title":"AWS.CloudDirectory.get_schema_as_json/3","type":"function","doc":"Retrieves a JSON representation of the schema. See JSON Schema Format for more information."},{"ref":"AWS.CloudDirectory.html#get_typed_link_facet_information/3","title":"AWS.CloudDirectory.get_typed_link_facet_information/3","type":"function","doc":"Returns the identity attribute order for a specific TypedLinkFacet. For more information, see Typed Links."},{"ref":"AWS.CloudDirectory.html#list_applied_schema_arns/3","title":"AWS.CloudDirectory.list_applied_schema_arns/3","type":"function","doc":"Lists schema major versions applied to a directory. If SchemaArn is provided, lists the minor version."},{"ref":"AWS.CloudDirectory.html#list_attached_indices/3","title":"AWS.CloudDirectory.list_attached_indices/3","type":"function","doc":"Lists indices attached to the specified object."},{"ref":"AWS.CloudDirectory.html#list_development_schema_arns/3","title":"AWS.CloudDirectory.list_development_schema_arns/3","type":"function","doc":"Retrieves each Amazon Resource Name (ARN) of schemas in the development state."},{"ref":"AWS.CloudDirectory.html#list_directories/3","title":"AWS.CloudDirectory.list_directories/3","type":"function","doc":"Lists directories created within an account."},{"ref":"AWS.CloudDirectory.html#list_facet_attributes/3","title":"AWS.CloudDirectory.list_facet_attributes/3","type":"function","doc":"Retrieves attributes attached to the facet."},{"ref":"AWS.CloudDirectory.html#list_facet_names/3","title":"AWS.CloudDirectory.list_facet_names/3","type":"function","doc":"Retrieves the names of facets that exist in a schema."},{"ref":"AWS.CloudDirectory.html#list_incoming_typed_links/3","title":"AWS.CloudDirectory.list_incoming_typed_links/3","type":"function","doc":"Returns a paginated list of all the incoming TypedLinkSpecifier information for an object. It also supports filtering by typed link facet and identity attributes. For more information, see Typed Links."},{"ref":"AWS.CloudDirectory.html#list_index/3","title":"AWS.CloudDirectory.list_index/3","type":"function","doc":"Lists objects attached to the specified index."},{"ref":"AWS.CloudDirectory.html#list_managed_schema_arns/3","title":"AWS.CloudDirectory.list_managed_schema_arns/3","type":"function","doc":"Lists the major version families of each managed schema. If a major version ARN is provided as SchemaArn, the minor version revisions in that family are listed instead."},{"ref":"AWS.CloudDirectory.html#list_object_attributes/3","title":"AWS.CloudDirectory.list_object_attributes/3","type":"function","doc":"Lists all attributes that are associated with an object."},{"ref":"AWS.CloudDirectory.html#list_object_children/3","title":"AWS.CloudDirectory.list_object_children/3","type":"function","doc":"Returns a paginated list of child objects that are associated with a given object."},{"ref":"AWS.CloudDirectory.html#list_object_parent_paths/3","title":"AWS.CloudDirectory.list_object_parent_paths/3","type":"function","doc":"Retrieves all available parent paths for any object type such as node, leaf node, policy node, and index node objects. For more information about objects, see Directory Structure. Use this API to evaluate all parents for an object. The call returns all objects from the root of the directory up to the requested object. The API returns the number of paths based on user-defined MaxResults, in case there are multiple paths to the parent. The order of the paths and nodes returned is consistent among multiple API calls unless the objects are deleted or moved. Paths not leading to the directory root are ignored from the target object."},{"ref":"AWS.CloudDirectory.html#list_object_parents/3","title":"AWS.CloudDirectory.list_object_parents/3","type":"function","doc":"Lists parent objects that are associated with a given object in pagination fashion."},{"ref":"AWS.CloudDirectory.html#list_object_policies/3","title":"AWS.CloudDirectory.list_object_policies/3","type":"function","doc":"Returns policies attached to an object in pagination fashion."},{"ref":"AWS.CloudDirectory.html#list_outgoing_typed_links/3","title":"AWS.CloudDirectory.list_outgoing_typed_links/3","type":"function","doc":"Returns a paginated list of all the outgoing TypedLinkSpecifier information for an object. It also supports filtering by typed link facet and identity attributes. For more information, see Typed Links."},{"ref":"AWS.CloudDirectory.html#list_policy_attachments/3","title":"AWS.CloudDirectory.list_policy_attachments/3","type":"function","doc":"Returns all of the ObjectIdentifiers to which a given policy is attached."},{"ref":"AWS.CloudDirectory.html#list_published_schema_arns/3","title":"AWS.CloudDirectory.list_published_schema_arns/3","type":"function","doc":"Lists the major version families of each published schema. If a major version ARN is provided as SchemaArn, the minor version revisions in that family are listed instead."},{"ref":"AWS.CloudDirectory.html#list_tags_for_resource/3","title":"AWS.CloudDirectory.list_tags_for_resource/3","type":"function","doc":"Returns tags for a resource. Tagging is currently supported only for directories with a limit of 50 tags per directory. All 50 tags are returned for a given directory with this API call."},{"ref":"AWS.CloudDirectory.html#list_typed_link_facet_attributes/3","title":"AWS.CloudDirectory.list_typed_link_facet_attributes/3","type":"function","doc":"Returns a paginated list of all attribute definitions for a particular TypedLinkFacet. For more information, see Typed Links."},{"ref":"AWS.CloudDirectory.html#list_typed_link_facet_names/3","title":"AWS.CloudDirectory.list_typed_link_facet_names/3","type":"function","doc":"Returns a paginated list of TypedLink facet names for a particular schema. For more information, see Typed Links."},{"ref":"AWS.CloudDirectory.html#lookup_policy/3","title":"AWS.CloudDirectory.lookup_policy/3","type":"function","doc":"Lists all policies from the root of the Directory to the object specified. If there are no policies present, an empty list is returned. If policies are present, and if some objects don&#39;t have the policies attached, it returns the ObjectIdentifier for such objects. If policies are present, it returns ObjectIdentifier, policyId, and policyType. Paths that don&#39;t lead to the root from the target object are ignored. For more information, see Policies."},{"ref":"AWS.CloudDirectory.html#publish_schema/3","title":"AWS.CloudDirectory.publish_schema/3","type":"function","doc":"Publishes a development schema with a major version and a recommended minor version."},{"ref":"AWS.CloudDirectory.html#put_schema_from_json/3","title":"AWS.CloudDirectory.put_schema_from_json/3","type":"function","doc":"Allows a schema to be updated using JSON upload. Only available for development schemas. See JSON Schema Format for more information."},{"ref":"AWS.CloudDirectory.html#remove_facet_from_object/3","title":"AWS.CloudDirectory.remove_facet_from_object/3","type":"function","doc":"Removes the specified facet from the specified object."},{"ref":"AWS.CloudDirectory.html#tag_resource/3","title":"AWS.CloudDirectory.tag_resource/3","type":"function","doc":"An API operation for adding tags to a resource."},{"ref":"AWS.CloudDirectory.html#untag_resource/3","title":"AWS.CloudDirectory.untag_resource/3","type":"function","doc":"An API operation for removing tags from a resource."},{"ref":"AWS.CloudDirectory.html#update_facet/3","title":"AWS.CloudDirectory.update_facet/3","type":"function","doc":"Does the following: 1. Adds new Attributes, Rules, or ObjectTypes. Updates existing Attributes, Rules, or ObjectTypes. Deletes existing Attributes, Rules, or ObjectTypes."},{"ref":"AWS.CloudDirectory.html#update_link_attributes/3","title":"AWS.CloudDirectory.update_link_attributes/3","type":"function","doc":"Updates a given typed links attributes. Attributes to be updated must not contribute to the typed links identity, as defined by its IdentityAttributeOrder."},{"ref":"AWS.CloudDirectory.html#update_object_attributes/3","title":"AWS.CloudDirectory.update_object_attributes/3","type":"function","doc":"Updates a given object&#39;s attributes."},{"ref":"AWS.CloudDirectory.html#update_schema/3","title":"AWS.CloudDirectory.update_schema/3","type":"function","doc":"Updates the schema name with a new name. Only development schema names can be updated."},{"ref":"AWS.CloudDirectory.html#update_typed_link_facet/3","title":"AWS.CloudDirectory.update_typed_link_facet/3","type":"function","doc":"Updates a TypedLinkFacet. For more information, see Typed Links."},{"ref":"AWS.CloudDirectory.html#upgrade_applied_schema/3","title":"AWS.CloudDirectory.upgrade_applied_schema/3","type":"function","doc":"Upgrades a single directory in-place using the PublishedSchemaArn with schema updates found in MinorVersion. Backwards-compatible minor version upgrades are instantaneously available for readers on all objects in the directory. Note: This is a synchronous API call and upgrades only one schema on a given directory per call. To upgrade multiple directories from one schema, you would need to call this API on each directory."},{"ref":"AWS.CloudDirectory.html#upgrade_published_schema/3","title":"AWS.CloudDirectory.upgrade_published_schema/3","type":"function","doc":"Upgrades a published schema under a new minor version revision using the current contents of DevelopmentSchemaArn."},{"ref":"AWS.CloudFormation.html","title":"AWS.CloudFormation","type":"module","doc":"AWS CloudFormation AWS CloudFormation allows you to create and manage AWS infrastructure deployments predictably and repeatedly. You can use AWS CloudFormation to leverage AWS products, such as Amazon Elastic Compute Cloud, Amazon Elastic Block Store, Amazon Simple Notification Service, Elastic Load Balancing, and Auto Scaling to build highly-reliable, highly scalable, cost-effective applications without creating or configuring the underlying AWS infrastructure. With AWS CloudFormation, you declare all of your resources and dependencies in a template file. The template defines a collection of resources as a single unit called a stack. AWS CloudFormation creates and deletes all member resources of the stack together and manages all dependencies between the resources for you. For more information about AWS CloudFormation, see the AWS CloudFormation Product Page. Amazon CloudFormation makes use of other AWS products. If you need additional technical information about a specific AWS product, you can find the product&#39;s technical documentation at docs.aws.amazon.com."},{"ref":"AWS.CloudFormation.html#cancel_update_stack/3","title":"AWS.CloudFormation.cancel_update_stack/3","type":"function","doc":"Cancels an update on the specified stack. If the call completes successfully, the stack rolls back the update and reverts to the previous stack configuration. You can cancel only stacks that are in the UPDATE_IN_PROGRESS state."},{"ref":"AWS.CloudFormation.html#continue_update_rollback/3","title":"AWS.CloudFormation.continue_update_rollback/3","type":"function","doc":"For a specified stack that is in the UPDATE_ROLLBACK_FAILED state, continues rolling it back to the UPDATE_ROLLBACK_COMPLETE state. Depending on the cause of the failure, you can manually fix the error and continue the rollback. By continuing the rollback, you can return your stack to a working state (the UPDATE_ROLLBACK_COMPLETE state), and then try to update the stack again. A stack goes into the UPDATE_ROLLBACK_FAILED state when AWS CloudFormation cannot roll back all changes after a failed stack update. For example, you might have a stack that is rolling back to an old database instance that was deleted outside of AWS CloudFormation. Because AWS CloudFormation doesn&#39;t know the database was deleted, it assumes that the database instance still exists and attempts to roll back to it, causing the update rollback to fail."},{"ref":"AWS.CloudFormation.html#create_change_set/3","title":"AWS.CloudFormation.create_change_set/3","type":"function","doc":"Creates a list of changes that will be applied to a stack so that you can review the changes before executing them. You can create a change set for a stack that doesn&#39;t exist or an existing stack. If you create a change set for a stack that doesn&#39;t exist, the change set shows all of the resources that AWS CloudFormation will create. If you create a change set for an existing stack, AWS CloudFormation compares the stack&#39;s information with the information that you submit in the change set and lists the differences. Use change sets to understand which resources AWS CloudFormation will create or change, and how it will change resources in an existing stack, before you create or update a stack. To create a change set for a stack that doesn&#39;t exist, for the ChangeSetType parameter, specify CREATE. To create a change set for an existing stack, specify UPDATE for the ChangeSetType parameter. To create a change set for an import operation, specify IMPORT for the ChangeSetType parameter. After the CreateChangeSet call successfully completes, AWS CloudFormation starts creating the change set. To check the status of the change set or to review it, use the DescribeChangeSet action. When you are satisfied with the changes the change set will make, execute the change set by using the ExecuteChangeSet action. AWS CloudFormation doesn&#39;t make changes until you execute the change set."},{"ref":"AWS.CloudFormation.html#create_stack/3","title":"AWS.CloudFormation.create_stack/3","type":"function","doc":"Creates a stack as specified in the template. After the call completes successfully, the stack creation starts. You can check the status of the stack via the DescribeStacks API."},{"ref":"AWS.CloudFormation.html#create_stack_instances/3","title":"AWS.CloudFormation.create_stack_instances/3","type":"function","doc":"Creates stack instances for the specified accounts, within the specified Regions. A stack instance refers to a stack in a specific account and Region. You must specify at least one value for either Accounts or DeploymentTargets, and you must specify at least one value for Regions."},{"ref":"AWS.CloudFormation.html#create_stack_set/3","title":"AWS.CloudFormation.create_stack_set/3","type":"function","doc":"Creates a stack set."},{"ref":"AWS.CloudFormation.html#delete_change_set/3","title":"AWS.CloudFormation.delete_change_set/3","type":"function","doc":"Deletes the specified change set. Deleting change sets ensures that no one executes the wrong change set. If the call successfully completes, AWS CloudFormation successfully deleted the change set."},{"ref":"AWS.CloudFormation.html#delete_stack/3","title":"AWS.CloudFormation.delete_stack/3","type":"function","doc":"Deletes a specified stack. Once the call completes successfully, stack deletion starts. Deleted stacks do not show up in the DescribeStacks API if the deletion has been completed successfully."},{"ref":"AWS.CloudFormation.html#delete_stack_instances/3","title":"AWS.CloudFormation.delete_stack_instances/3","type":"function","doc":"Deletes stack instances for the specified accounts, in the specified Regions."},{"ref":"AWS.CloudFormation.html#delete_stack_set/3","title":"AWS.CloudFormation.delete_stack_set/3","type":"function","doc":"Deletes a stack set. Before you can delete a stack set, all of its member stack instances must be deleted. For more information about how to do this, see DeleteStackInstances."},{"ref":"AWS.CloudFormation.html#deregister_type/3","title":"AWS.CloudFormation.deregister_type/3","type":"function","doc":"Removes a type or type version from active use in the CloudFormation registry. If a type or type version is deregistered, it cannot be used in CloudFormation operations. To deregister a type, you must individually deregister all registered versions of that type. If a type has only a single registered version, deregistering that version results in the type itself being deregistered. You cannot deregister the default version of a type, unless it is the only registered version of that type, in which case the type itself is deregistered as well."},{"ref":"AWS.CloudFormation.html#describe_account_limits/3","title":"AWS.CloudFormation.describe_account_limits/3","type":"function","doc":"Retrieves your account&#39;s AWS CloudFormation limits, such as the maximum number of stacks that you can create in your account. For more information about account limits, see AWS CloudFormation Limits in the AWS CloudFormation User Guide."},{"ref":"AWS.CloudFormation.html#describe_change_set/3","title":"AWS.CloudFormation.describe_change_set/3","type":"function","doc":"Returns the inputs for the change set and a list of changes that AWS CloudFormation will make if you execute the change set. For more information, see Updating Stacks Using Change Sets in the AWS CloudFormation User Guide."},{"ref":"AWS.CloudFormation.html#describe_stack_drift_detection_status/3","title":"AWS.CloudFormation.describe_stack_drift_detection_status/3","type":"function","doc":"Returns information about a stack drift detection operation. A stack drift detection operation detects whether a stack&#39;s actual configuration differs, or has drifted, from it&#39;s expected configuration, as defined in the stack template and any values specified as template parameters. A stack is considered to have drifted if one or more of its resources have drifted. For more information on stack and resource drift, see Detecting Unregulated Configuration Changes to Stacks and Resources. Use DetectStackDrift to initiate a stack drift detection operation. DetectStackDrift returns a StackDriftDetectionId you can use to monitor the progress of the operation using DescribeStackDriftDetectionStatus. Once the drift detection operation has completed, use DescribeStackResourceDrifts to return drift information about the stack and its resources."},{"ref":"AWS.CloudFormation.html#describe_stack_events/3","title":"AWS.CloudFormation.describe_stack_events/3","type":"function","doc":"Returns all stack related events for a specified stack in reverse chronological order. For more information about a stack&#39;s event history, go to Stacks in the AWS CloudFormation User Guide. You can list events for stacks that have failed to create or have been deleted by specifying the unique stack identifier (stack ID)."},{"ref":"AWS.CloudFormation.html#describe_stack_instance/3","title":"AWS.CloudFormation.describe_stack_instance/3","type":"function","doc":"Returns the stack instance that&#39;s associated with the specified stack set, AWS account, and Region. For a list of stack instances that are associated with a specific stack set, use ListStackInstances."},{"ref":"AWS.CloudFormation.html#describe_stack_resource/3","title":"AWS.CloudFormation.describe_stack_resource/3","type":"function","doc":"Returns a description of the specified resource in the specified stack. For deleted stacks, DescribeStackResource returns resource information for up to 90 days after the stack has been deleted."},{"ref":"AWS.CloudFormation.html#describe_stack_resource_drifts/3","title":"AWS.CloudFormation.describe_stack_resource_drifts/3","type":"function","doc":"Returns drift information for the resources that have been checked for drift in the specified stack. This includes actual and expected configuration values for resources where AWS CloudFormation detects configuration drift. For a given stack, there will be one StackResourceDrift for each stack resource that has been checked for drift. Resources that have not yet been checked for drift are not included. Resources that do not currently support drift detection are not checked, and so not included. For a list of resources that support drift detection, see Resources that Support Drift Detection. Use DetectStackResourceDrift to detect drift on individual resources, or DetectStackDrift to detect drift on all supported resources for a given stack."},{"ref":"AWS.CloudFormation.html#describe_stack_resources/3","title":"AWS.CloudFormation.describe_stack_resources/3","type":"function","doc":"Returns AWS resource descriptions for running and deleted stacks. If StackName is specified, all the associated resources that are part of the stack are returned. If PhysicalResourceId is specified, the associated resources of the stack that the resource belongs to are returned. Only the first 100 resources will be returned. If your stack has more resources than this, you should use ListStackResources instead. For deleted stacks, DescribeStackResources returns resource information for up to 90 days after the stack has been deleted. You must specify either StackName or PhysicalResourceId, but not both. In addition, you can specify LogicalResourceId to filter the returned result. For more information about resources, the LogicalResourceId and PhysicalResourceId, go to the AWS CloudFormation User Guide. A ValidationError is returned if you specify both StackName and PhysicalResourceId in the same request."},{"ref":"AWS.CloudFormation.html#describe_stack_set/3","title":"AWS.CloudFormation.describe_stack_set/3","type":"function","doc":"Returns the description of the specified stack set."},{"ref":"AWS.CloudFormation.html#describe_stack_set_operation/3","title":"AWS.CloudFormation.describe_stack_set_operation/3","type":"function","doc":"Returns the description of the specified stack set operation."},{"ref":"AWS.CloudFormation.html#describe_stacks/3","title":"AWS.CloudFormation.describe_stacks/3","type":"function","doc":"Returns the description for the specified stack; if no stack name was specified, then it returns the description for all the stacks created. If the stack does not exist, an AmazonCloudFormationException is returned."},{"ref":"AWS.CloudFormation.html#describe_type/3","title":"AWS.CloudFormation.describe_type/3","type":"function","doc":"Returns detailed information about a type that has been registered. If you specify a VersionId, DescribeType returns information about that specific type version. Otherwise, it returns information about the default type version."},{"ref":"AWS.CloudFormation.html#describe_type_registration/3","title":"AWS.CloudFormation.describe_type_registration/3","type":"function","doc":"Returns information about a type&#39;s registration, including its current status and type and version identifiers. When you initiate a registration request using RegisterType, you can then use DescribeTypeRegistration to monitor the progress of that registration request. Once the registration request has completed, use DescribeType to return detailed informaiton about a type."},{"ref":"AWS.CloudFormation.html#detect_stack_drift/3","title":"AWS.CloudFormation.detect_stack_drift/3","type":"function","doc":"Detects whether a stack&#39;s actual configuration differs, or has drifted, from it&#39;s expected configuration, as defined in the stack template and any values specified as template parameters. For each resource in the stack that supports drift detection, AWS CloudFormation compares the actual configuration of the resource with its expected template configuration. Only resource properties explicitly defined in the stack template are checked for drift. A stack is considered to have drifted if one or more of its resources differ from their expected template configurations. For more information, see Detecting Unregulated Configuration Changes to Stacks and Resources. Use DetectStackDrift to detect drift on all supported resources for a given stack, or DetectStackResourceDrift to detect drift on individual resources. For a list of stack resources that currently support drift detection, see Resources that Support Drift Detection. DetectStackDrift can take up to several minutes, depending on the number of resources contained within the stack. Use DescribeStackDriftDetectionStatus to monitor the progress of a detect stack drift operation. Once the drift detection operation has completed, use DescribeStackResourceDrifts to return drift information about the stack and its resources. When detecting drift on a stack, AWS CloudFormation does not detect drift on any nested stacks belonging to that stack. Perform DetectStackDrift directly on the nested stack itself."},{"ref":"AWS.CloudFormation.html#detect_stack_resource_drift/3","title":"AWS.CloudFormation.detect_stack_resource_drift/3","type":"function","doc":"Returns information about whether a resource&#39;s actual configuration differs, or has drifted, from it&#39;s expected configuration, as defined in the stack template and any values specified as template parameters. This information includes actual and expected property values for resources in which AWS CloudFormation detects drift. Only resource properties explicitly defined in the stack template are checked for drift. For more information about stack and resource drift, see Detecting Unregulated Configuration Changes to Stacks and Resources. Use DetectStackResourceDrift to detect drift on individual resources, or DetectStackDrift to detect drift on all resources in a given stack that support drift detection. Resources that do not currently support drift detection cannot be checked. For a list of resources that support drift detection, see Resources that Support Drift Detection."},{"ref":"AWS.CloudFormation.html#detect_stack_set_drift/3","title":"AWS.CloudFormation.detect_stack_set_drift/3","type":"function","doc":"Detect drift on a stack set. When CloudFormation performs drift detection on a stack set, it performs drift detection on the stack associated with each stack instance in the stack set. For more information, see How CloudFormation Performs Drift Detection on a Stack Set. DetectStackSetDrift returns the OperationId of the stack set drift detection operation. Use this operation id with DescribeStackSetOperation to monitor the progress of the drift detection operation. The drift detection operation may take some time, depending on the number of stack instances included in the stack set, as well as the number of resources included in each stack. Once the operation has completed, use the following actions to return drift information: Use DescribeStackSet to return detailed informaiton about the stack set, including detailed information about the last completed drift operation performed on the stack set. (Information about drift operations that are in progress is not included.) Use ListStackInstances to return a list of stack instances belonging to the stack set, including the drift status and last drift time checked of each instance. Use DescribeStackInstance to return detailed information about a specific stack instance, including its drift status and last drift time checked. For more information on performing a drift detection operation on a stack set, see Detecting Unmanaged Changes in Stack Sets. You can only run a single drift detection operation on a given stack set at one time. To stop a drift detection stack set operation, use StopStackSetOperation."},{"ref":"AWS.CloudFormation.html#estimate_template_cost/3","title":"AWS.CloudFormation.estimate_template_cost/3","type":"function","doc":"Returns the estimated monthly cost of a template. The return value is an AWS Simple Monthly Calculator URL with a query string that describes the resources required to run the template."},{"ref":"AWS.CloudFormation.html#execute_change_set/3","title":"AWS.CloudFormation.execute_change_set/3","type":"function","doc":"Updates a stack using the input information that was provided when the specified change set was created. After the call successfully completes, AWS CloudFormation starts updating the stack. Use the DescribeStacks action to view the status of the update. When you execute a change set, AWS CloudFormation deletes all other change sets associated with the stack because they aren&#39;t valid for the updated stack. If a stack policy is associated with the stack, AWS CloudFormation enforces the policy during the update. You can&#39;t specify a temporary stack policy that overrides the current policy."},{"ref":"AWS.CloudFormation.html#get_stack_policy/3","title":"AWS.CloudFormation.get_stack_policy/3","type":"function","doc":"Returns the stack policy for a specified stack. If a stack doesn&#39;t have a policy, a null value is returned."},{"ref":"AWS.CloudFormation.html#get_template/3","title":"AWS.CloudFormation.get_template/3","type":"function","doc":"Returns the template body for a specified stack. You can get the template for running or deleted stacks. For deleted stacks, GetTemplate returns the template for up to 90 days after the stack has been deleted. If the template does not exist, a ValidationError is returned."},{"ref":"AWS.CloudFormation.html#get_template_summary/3","title":"AWS.CloudFormation.get_template_summary/3","type":"function","doc":"Returns information about a new or existing template. The GetTemplateSummary action is useful for viewing parameter information, such as default parameter values and parameter types, before you create or update a stack or stack set. You can use the GetTemplateSummary action when you submit a template, or you can get template information for a stack set, or a running or deleted stack. For deleted stacks, GetTemplateSummary returns the template information for up to 90 days after the stack has been deleted. If the template does not exist, a ValidationError is returned."},{"ref":"AWS.CloudFormation.html#list_change_sets/3","title":"AWS.CloudFormation.list_change_sets/3","type":"function","doc":"Returns the ID and status of each active change set for a stack. For example, AWS CloudFormation lists change sets that are in the CREATE_IN_PROGRESS or CREATE_PENDING state."},{"ref":"AWS.CloudFormation.html#list_exports/3","title":"AWS.CloudFormation.list_exports/3","type":"function","doc":"Lists all exported output values in the account and Region in which you call this action. Use this action to see the exported output values that you can import into other stacks. To import values, use the Fn::ImportValue function. For more information, see AWS CloudFormation Export Stack Output Values."},{"ref":"AWS.CloudFormation.html#list_imports/3","title":"AWS.CloudFormation.list_imports/3","type":"function","doc":"Lists all stacks that are importing an exported output value. To modify or remove an exported output value, first use this action to see which stacks are using it. To see the exported output values in your account, see ListExports. For more information about importing an exported output value, see the Fn::ImportValue function."},{"ref":"AWS.CloudFormation.html#list_stack_instances/3","title":"AWS.CloudFormation.list_stack_instances/3","type":"function","doc":"Returns summary information about stack instances that are associated with the specified stack set. You can filter for stack instances that are associated with a specific AWS account name or Region, or that have a specific status."},{"ref":"AWS.CloudFormation.html#list_stack_resources/3","title":"AWS.CloudFormation.list_stack_resources/3","type":"function","doc":"Returns descriptions of all resources of the specified stack. For deleted stacks, ListStackResources returns resource information for up to 90 days after the stack has been deleted."},{"ref":"AWS.CloudFormation.html#list_stack_set_operation_results/3","title":"AWS.CloudFormation.list_stack_set_operation_results/3","type":"function","doc":"Returns summary information about the results of a stack set operation."},{"ref":"AWS.CloudFormation.html#list_stack_set_operations/3","title":"AWS.CloudFormation.list_stack_set_operations/3","type":"function","doc":"Returns summary information about operations performed on a stack set."},{"ref":"AWS.CloudFormation.html#list_stack_sets/3","title":"AWS.CloudFormation.list_stack_sets/3","type":"function","doc":"Returns summary information about stack sets that are associated with the user."},{"ref":"AWS.CloudFormation.html#list_stacks/3","title":"AWS.CloudFormation.list_stacks/3","type":"function","doc":"Returns the summary information for stacks whose status matches the specified StackStatusFilter. Summary information for stacks that have been deleted is kept for 90 days after the stack is deleted. If no StackStatusFilter is specified, summary information for all stacks is returned (including existing stacks and stacks that have been deleted)."},{"ref":"AWS.CloudFormation.html#list_type_registrations/3","title":"AWS.CloudFormation.list_type_registrations/3","type":"function","doc":"Returns a list of registration tokens for the specified type(s)."},{"ref":"AWS.CloudFormation.html#list_type_versions/3","title":"AWS.CloudFormation.list_type_versions/3","type":"function","doc":"Returns summary information about the versions of a type."},{"ref":"AWS.CloudFormation.html#list_types/3","title":"AWS.CloudFormation.list_types/3","type":"function","doc":"Returns summary information about types that have been registered with CloudFormation."},{"ref":"AWS.CloudFormation.html#record_handler_progress/3","title":"AWS.CloudFormation.record_handler_progress/3","type":"function","doc":"Reports progress of a resource handler to CloudFormation. Reserved for use by the CloudFormation CLI. Do not use this API in your code."},{"ref":"AWS.CloudFormation.html#register_type/3","title":"AWS.CloudFormation.register_type/3","type":"function","doc":"Registers a type with the CloudFormation service. Registering a type makes it available for use in CloudFormation templates in your AWS account, and includes: Validating the resource schema Determining which handlers have been specified for the resource Making the resource type available for use in your account For more information on how to develop types and ready them for registeration, see Creating Resource Providers in the CloudFormation CLI User Guide. You can have a maximum of 50 resource type versions registered at a time. This maximum is per account and per region. Use DeregisterType to deregister specific resource type versions if necessary. Once you have initiated a registration request using RegisterType, you can use DescribeTypeRegistration to monitor the progress of the registration request."},{"ref":"AWS.CloudFormation.html#set_stack_policy/3","title":"AWS.CloudFormation.set_stack_policy/3","type":"function","doc":"Sets a stack policy for a specified stack."},{"ref":"AWS.CloudFormation.html#set_type_default_version/3","title":"AWS.CloudFormation.set_type_default_version/3","type":"function","doc":"Specify the default version of a type. The default version of a type will be used in CloudFormation operations."},{"ref":"AWS.CloudFormation.html#signal_resource/3","title":"AWS.CloudFormation.signal_resource/3","type":"function","doc":"Sends a signal to the specified resource with a success or failure status. You can use the SignalResource API in conjunction with a creation policy or update policy. AWS CloudFormation doesn&#39;t proceed with a stack creation or update until resources receive the required number of signals or the timeout period is exceeded. The SignalResource API is useful in cases where you want to send signals from anywhere other than an Amazon EC2 instance."},{"ref":"AWS.CloudFormation.html#stop_stack_set_operation/3","title":"AWS.CloudFormation.stop_stack_set_operation/3","type":"function","doc":"Stops an in-progress operation on a stack set and its associated stack instances."},{"ref":"AWS.CloudFormation.html#update_stack/3","title":"AWS.CloudFormation.update_stack/3","type":"function","doc":"Updates a stack as specified in the template. After the call completes successfully, the stack update starts. You can check the status of the stack via the DescribeStacks action. To get a copy of the template for an existing stack, you can use the GetTemplate action. For more information about creating an update template, updating a stack, and monitoring the progress of the update, see Updating a Stack."},{"ref":"AWS.CloudFormation.html#update_stack_instances/3","title":"AWS.CloudFormation.update_stack_instances/3","type":"function","doc":"Updates the parameter values for stack instances for the specified accounts, within the specified Regions. A stack instance refers to a stack in a specific account and Region. You can only update stack instances in Regions and accounts where they already exist; to create additional stack instances, use CreateStackInstances. During stack set updates, any parameters overridden for a stack instance are not updated, but retain their overridden value. You can only update the parameter values that are specified in the stack set; to add or delete a parameter itself, use UpdateStackSet to update the stack set template. If you add a parameter to a template, before you can override the parameter value specified in the stack set you must first use UpdateStackSet to update all stack instances with the updated template and parameter value specified in the stack set. Once a stack instance has been updated with the new parameter, you can then override the parameter value using UpdateStackInstances."},{"ref":"AWS.CloudFormation.html#update_stack_set/3","title":"AWS.CloudFormation.update_stack_set/3","type":"function","doc":"Updates the stack set, and associated stack instances in the specified accounts and Regions. Even if the stack set operation created by updating the stack set fails (completely or partially, below or above a specified failure tolerance), the stack set is updated with your changes. Subsequent CreateStackInstances calls on the specified stack set use the updated stack set."},{"ref":"AWS.CloudFormation.html#update_termination_protection/3","title":"AWS.CloudFormation.update_termination_protection/3","type":"function","doc":"Updates termination protection for the specified stack. If a user attempts to delete a stack with termination protection enabled, the operation fails and the stack remains unchanged. For more information, see Protecting a Stack From Being Deleted in the AWS CloudFormation User Guide. For nested stacks, termination protection is set on the root stack and cannot be changed directly on the nested stack."},{"ref":"AWS.CloudFormation.html#validate_template/3","title":"AWS.CloudFormation.validate_template/3","type":"function","doc":"Validates a specified template. AWS CloudFormation first checks if the template is valid JSON. If it isn&#39;t, AWS CloudFormation checks if the template is valid YAML. If both these checks fail, AWS CloudFormation returns a template validation error."},{"ref":"AWS.CloudFront.html","title":"AWS.CloudFront","type":"module","doc":"Amazon CloudFront This is the Amazon CloudFront API Reference. This guide is for developers who need detailed information about CloudFront API actions, data types, and errors. For detailed information about CloudFront features, see the Amazon CloudFront Developer Guide."},{"ref":"AWS.CloudFront.html#create_cache_policy/3","title":"AWS.CloudFront.create_cache_policy/3","type":"function","doc":"Creates a cache policy. After you create a cache policy, you can attach it to one or more cache behaviors. When its attached to a cache behavior, the cache policy determines the following: The values that CloudFront includes in the cache key. These values can include HTTP headers, cookies, and URL query strings. CloudFront uses the cache key to find an object in its cache that it can return to the viewer. The default, minimum, and maximum time to live (TTL) values that you want objects to stay in the CloudFront cache. The headers, cookies, and query strings that are included in the cache key are automatically included in requests that CloudFront sends to the origin. CloudFront sends a request when it cant find an object in its cache that matches the requests cache key. If you want to send values to the origin but not include them in the cache key, use OriginRequestPolicy. For more information about cache policies, see Controlling the cache key in the Amazon CloudFront Developer Guide."},{"ref":"AWS.CloudFront.html#create_cloud_front_origin_access_identity/3","title":"AWS.CloudFront.create_cloud_front_origin_access_identity/3","type":"function","doc":"Creates a new origin access identity. If you&#39;re using Amazon S3 for your origin, you can use an origin access identity to require users to access your content using a CloudFront URL instead of the Amazon S3 URL. For more information about how to use origin access identities, see Serving Private Content through CloudFront in the Amazon CloudFront Developer Guide."},{"ref":"AWS.CloudFront.html#create_distribution/3","title":"AWS.CloudFront.create_distribution/3","type":"function","doc":"Creates a new web distribution. You create a CloudFront distribution to tell CloudFront where you want content to be delivered from, and the details about how to track and manage content delivery. Send a POST request to the /*CloudFront API version*/distribution/distribution ID resource. When you update a distribution, there are more required fields than when you create a distribution. When you update your distribution by using UpdateDistribution, follow the steps included in the documentation to get the current configuration and then make your updates. This helps to make sure that you include all of the required fields. To view a summary, see Required Fields for Create Distribution and Update Distribution in the Amazon CloudFront Developer Guide."},{"ref":"AWS.CloudFront.html#create_distribution_with_tags/3","title":"AWS.CloudFront.create_distribution_with_tags/3","type":"function","doc":"Create a new distribution with tags."},{"ref":"AWS.CloudFront.html#create_field_level_encryption_config/3","title":"AWS.CloudFront.create_field_level_encryption_config/3","type":"function","doc":"Create a new field-level encryption configuration."},{"ref":"AWS.CloudFront.html#create_field_level_encryption_profile/3","title":"AWS.CloudFront.create_field_level_encryption_profile/3","type":"function","doc":"Create a field-level encryption profile."},{"ref":"AWS.CloudFront.html#create_invalidation/4","title":"AWS.CloudFront.create_invalidation/4","type":"function","doc":"Create a new invalidation."},{"ref":"AWS.CloudFront.html#create_monitoring_subscription/4","title":"AWS.CloudFront.create_monitoring_subscription/4","type":"function","doc":"Enables additional CloudWatch metrics for the specified CloudFront distribution. The additional metrics incur an additional cost. For more information, see Viewing additional CloudFront distribution metrics in the Amazon CloudFront Developer Guide."},{"ref":"AWS.CloudFront.html#create_origin_request_policy/3","title":"AWS.CloudFront.create_origin_request_policy/3","type":"function","doc":"Creates an origin request policy. After you create an origin request policy, you can attach it to one or more cache behaviors. When its attached to a cache behavior, the origin request policy determines the values that CloudFront includes in requests that it sends to the origin. Each request that CloudFront sends to the origin includes the following: The request body and the URL path (without the domain name) from the viewer request. The headers that CloudFront automatically includes in every origin request, including Host, User-Agent, and X-Amz-Cf-Id. All HTTP headers, cookies, and URL query strings that are specified in the cache policy or the origin request policy. These can include items from the viewer request and, in the case of headers, additional ones that are added by CloudFront. CloudFront sends a request when it cant find a valid object in its cache that matches the request. If you want to send values to the origin and also include them in the cache key, use CachePolicy. For more information about origin request policies, see Controlling origin requests in the Amazon CloudFront Developer Guide."},{"ref":"AWS.CloudFront.html#create_public_key/3","title":"AWS.CloudFront.create_public_key/3","type":"function","doc":"Add a new public key to CloudFront to use, for example, for field-level encryption. You can add a maximum of 10 public keys with one AWS account."},{"ref":"AWS.CloudFront.html#create_realtime_log_config/3","title":"AWS.CloudFront.create_realtime_log_config/3","type":"function","doc":"Creates a real-time log configuration. After you create a real-time log configuration, you can attach it to one or more cache behaviors to send real-time log data to the specified Amazon Kinesis data stream. For more information about real-time log configurations, see Real-time logs in the Amazon CloudFront Developer Guide."},{"ref":"AWS.CloudFront.html#create_streaming_distribution/3","title":"AWS.CloudFront.create_streaming_distribution/3","type":"function","doc":"Creates a new RTMP distribution. An RTMP distribution is similar to a web distribution, but an RTMP distribution streams media files using the Adobe Real-Time Messaging Protocol (RTMP) instead of serving files using HTTP. To create a new distribution, submit a POST request to the CloudFront API version/distribution resource. The request body must include a document with a StreamingDistributionConfig element. The response echoes the StreamingDistributionConfig element and returns other information about the RTMP distribution. To get the status of your request, use the GET StreamingDistribution API action. When the value of Enabled is true and the value of Status is Deployed, your distribution is ready. A distribution usually deploys in less than 15 minutes. For more information about web distributions, see Working with RTMP Distributions in the Amazon CloudFront Developer Guide. Beginning with the 2012-05-05 version of the CloudFront API, we made substantial changes to the format of the XML document that you include in the request body when you create or update a web distribution or an RTMP distribution, and when you invalidate objects. With previous versions of the API, we discovered that it was too easy to accidentally delete one or more values for an element that accepts multiple values, for example, CNAMEs and trusted signers. Our changes for the 2012-05-05 release are intended to prevent these accidental deletions and to notify you when there&#39;s a mismatch between the number of values you say you&#39;re specifying in the Quantity element and the number of values specified."},{"ref":"AWS.CloudFront.html#create_streaming_distribution_with_tags/3","title":"AWS.CloudFront.create_streaming_distribution_with_tags/3","type":"function","doc":"Create a new streaming distribution with tags."},{"ref":"AWS.CloudFront.html#delete_cache_policy/4","title":"AWS.CloudFront.delete_cache_policy/4","type":"function","doc":"Deletes a cache policy. You cannot delete a cache policy if its attached to a cache behavior. First update your distributions to remove the cache policy from all cache behaviors, then delete the cache policy. To delete a cache policy, you must provide the policys identifier and version. To get these values, you can use ListCachePolicies or GetCachePolicy."},{"ref":"AWS.CloudFront.html#delete_cloud_front_origin_access_identity/4","title":"AWS.CloudFront.delete_cloud_front_origin_access_identity/4","type":"function","doc":"Delete an origin access identity."},{"ref":"AWS.CloudFront.html#delete_distribution/4","title":"AWS.CloudFront.delete_distribution/4","type":"function","doc":"Delete a distribution."},{"ref":"AWS.CloudFront.html#delete_field_level_encryption_config/4","title":"AWS.CloudFront.delete_field_level_encryption_config/4","type":"function","doc":"Remove a field-level encryption configuration."},{"ref":"AWS.CloudFront.html#delete_field_level_encryption_profile/4","title":"AWS.CloudFront.delete_field_level_encryption_profile/4","type":"function","doc":"Remove a field-level encryption profile."},{"ref":"AWS.CloudFront.html#delete_monitoring_subscription/4","title":"AWS.CloudFront.delete_monitoring_subscription/4","type":"function","doc":"Disables additional CloudWatch metrics for the specified CloudFront distribution."},{"ref":"AWS.CloudFront.html#delete_origin_request_policy/4","title":"AWS.CloudFront.delete_origin_request_policy/4","type":"function","doc":"Deletes an origin request policy. You cannot delete an origin request policy if its attached to any cache behaviors. First update your distributions to remove the origin request policy from all cache behaviors, then delete the origin request policy. To delete an origin request policy, you must provide the policys identifier and version. To get the identifier, you can use ListOriginRequestPolicies or GetOriginRequestPolicy."},{"ref":"AWS.CloudFront.html#delete_public_key/4","title":"AWS.CloudFront.delete_public_key/4","type":"function","doc":"Remove a public key you previously added to CloudFront."},{"ref":"AWS.CloudFront.html#delete_realtime_log_config/3","title":"AWS.CloudFront.delete_realtime_log_config/3","type":"function","doc":"Deletes a real-time log configuration. You cannot delete a real-time log configuration if its attached to a cache behavior. First update your distributions to remove the real-time log configuration from all cache behaviors, then delete the real-time log configuration. To delete a real-time log configuration, you can provide the configurations name or its Amazon Resource Name (ARN). You must provide at least one. If you provide both, CloudFront uses the name to identify the real-time log configuration to delete."},{"ref":"AWS.CloudFront.html#delete_streaming_distribution/4","title":"AWS.CloudFront.delete_streaming_distribution/4","type":"function","doc":"Delete a streaming distribution. To delete an RTMP distribution using the CloudFront API, perform the following steps. To delete an RTMP distribution using the CloudFront API: Disable the RTMP distribution. Submit a GET Streaming Distribution Config request to get the current configuration and the Etag header for the distribution. Update the XML document that was returned in the response to your GET Streaming Distribution Config request to change the value of Enabled to false. Submit a PUT Streaming Distribution Config request to update the configuration for your distribution. In the request body, include the XML document that you updated in Step 3. Then set the value of the HTTP If-Match header to the value of the ETag header that CloudFront returned when you submitted the GET Streaming Distribution Config request in Step 2. Review the response to the PUT Streaming Distribution Config request to confirm that the distribution was successfully disabled. Submit a GET Streaming Distribution Config request to confirm that your changes have propagated. When propagation is complete, the value of Status is Deployed. Submit a DELETE Streaming Distribution request. Set the value of the HTTP If-Match header to the value of the ETag header that CloudFront returned when you submitted the GET Streaming Distribution Config request in Step 2. Review the response to your DELETE Streaming Distribution request to confirm that the distribution was successfully deleted. For information about deleting a distribution using the CloudFront console, see Deleting a Distribution in the Amazon CloudFront Developer Guide."},{"ref":"AWS.CloudFront.html#get_cache_policy/3","title":"AWS.CloudFront.get_cache_policy/3","type":"function","doc":"Gets a cache policy, including the following metadata: The policys identifier. The date and time when the policy was last modified. To get a cache policy, you must provide the policys identifier. If the cache policy is attached to a distributions cache behavior, you can get the policys identifier using ListDistributions or GetDistribution. If the cache policy is not attached to a cache behavior, you can get the identifier using ListCachePolicies."},{"ref":"AWS.CloudFront.html#get_cache_policy_config/3","title":"AWS.CloudFront.get_cache_policy_config/3","type":"function","doc":"Gets a cache policy configuration. To get a cache policy configuration, you must provide the policys identifier. If the cache policy is attached to a distributions cache behavior, you can get the policys identifier using ListDistributions or GetDistribution. If the cache policy is not attached to a cache behavior, you can get the identifier using ListCachePolicies."},{"ref":"AWS.CloudFront.html#get_cloud_front_origin_access_identity/3","title":"AWS.CloudFront.get_cloud_front_origin_access_identity/3","type":"function","doc":"Get the information about an origin access identity."},{"ref":"AWS.CloudFront.html#get_cloud_front_origin_access_identity_config/3","title":"AWS.CloudFront.get_cloud_front_origin_access_identity_config/3","type":"function","doc":"Get the configuration information about an origin access identity."},{"ref":"AWS.CloudFront.html#get_distribution/3","title":"AWS.CloudFront.get_distribution/3","type":"function","doc":"Get the information about a distribution."},{"ref":"AWS.CloudFront.html#get_distribution_config/3","title":"AWS.CloudFront.get_distribution_config/3","type":"function","doc":"Get the configuration information about a distribution."},{"ref":"AWS.CloudFront.html#get_field_level_encryption/3","title":"AWS.CloudFront.get_field_level_encryption/3","type":"function","doc":"Get the field-level encryption configuration information."},{"ref":"AWS.CloudFront.html#get_field_level_encryption_config/3","title":"AWS.CloudFront.get_field_level_encryption_config/3","type":"function","doc":"Get the field-level encryption configuration information."},{"ref":"AWS.CloudFront.html#get_field_level_encryption_profile/3","title":"AWS.CloudFront.get_field_level_encryption_profile/3","type":"function","doc":"Get the field-level encryption profile information."},{"ref":"AWS.CloudFront.html#get_field_level_encryption_profile_config/3","title":"AWS.CloudFront.get_field_level_encryption_profile_config/3","type":"function","doc":"Get the field-level encryption profile configuration information."},{"ref":"AWS.CloudFront.html#get_invalidation/4","title":"AWS.CloudFront.get_invalidation/4","type":"function","doc":"Get the information about an invalidation."},{"ref":"AWS.CloudFront.html#get_monitoring_subscription/3","title":"AWS.CloudFront.get_monitoring_subscription/3","type":"function","doc":"Gets information about whether additional CloudWatch metrics are enabled for the specified CloudFront distribution."},{"ref":"AWS.CloudFront.html#get_origin_request_policy/3","title":"AWS.CloudFront.get_origin_request_policy/3","type":"function","doc":"Gets an origin request policy, including the following metadata: The policys identifier. The date and time when the policy was last modified. To get an origin request policy, you must provide the policys identifier. If the origin request policy is attached to a distributions cache behavior, you can get the policys identifier using ListDistributions or GetDistribution. If the origin request policy is not attached to a cache behavior, you can get the identifier using ListOriginRequestPolicies."},{"ref":"AWS.CloudFront.html#get_origin_request_policy_config/3","title":"AWS.CloudFront.get_origin_request_policy_config/3","type":"function","doc":"Gets an origin request policy configuration. To get an origin request policy configuration, you must provide the policys identifier. If the origin request policy is attached to a distributions cache behavior, you can get the policys identifier using ListDistributions or GetDistribution. If the origin request policy is not attached to a cache behavior, you can get the identifier using ListOriginRequestPolicies."},{"ref":"AWS.CloudFront.html#get_public_key/3","title":"AWS.CloudFront.get_public_key/3","type":"function","doc":"Get the public key information."},{"ref":"AWS.CloudFront.html#get_public_key_config/3","title":"AWS.CloudFront.get_public_key_config/3","type":"function","doc":"Return public key configuration informaation"},{"ref":"AWS.CloudFront.html#get_realtime_log_config/3","title":"AWS.CloudFront.get_realtime_log_config/3","type":"function","doc":"Gets a real-time log configuration. To get a real-time log configuration, you can provide the configurations name or its Amazon Resource Name (ARN). You must provide at least one. If you provide both, CloudFront uses the name to identify the real-time log configuration to get."},{"ref":"AWS.CloudFront.html#get_streaming_distribution/3","title":"AWS.CloudFront.get_streaming_distribution/3","type":"function","doc":"Gets information about a specified RTMP distribution, including the distribution configuration."},{"ref":"AWS.CloudFront.html#get_streaming_distribution_config/3","title":"AWS.CloudFront.get_streaming_distribution_config/3","type":"function","doc":"Get the configuration information about a streaming distribution."},{"ref":"AWS.CloudFront.html#list_cache_policies/5","title":"AWS.CloudFront.list_cache_policies/5","type":"function","doc":"Gets a list of cache policies. You can optionally apply a filter to return only the managed policies created by AWS, or only the custom policies created in your AWS account. You can optionally specify the maximum number of items to receive in the response. If the total number of items in the list exceeds the maximum that you specify, or the default maximum, the response is paginated. To get the next page of items, send a subsequent request that specifies the NextMarker value from the current response as the Marker value in the subsequent request."},{"ref":"AWS.CloudFront.html#list_cloud_front_origin_access_identities/4","title":"AWS.CloudFront.list_cloud_front_origin_access_identities/4","type":"function","doc":"Lists origin access identities."},{"ref":"AWS.CloudFront.html#list_distributions/4","title":"AWS.CloudFront.list_distributions/4","type":"function","doc":"List CloudFront distributions."},{"ref":"AWS.CloudFront.html#list_distributions_by_cache_policy_id/5","title":"AWS.CloudFront.list_distributions_by_cache_policy_id/5","type":"function","doc":"Gets a list of distribution IDs for distributions that have a cache behavior thats associated with the specified cache policy. You can optionally specify the maximum number of items to receive in the response. If the total number of items in the list exceeds the maximum that you specify, or the default maximum, the response is paginated. To get the next page of items, send a subsequent request that specifies the NextMarker value from the current response as the Marker value in the subsequent request."},{"ref":"AWS.CloudFront.html#list_distributions_by_origin_request_policy_id/5","title":"AWS.CloudFront.list_distributions_by_origin_request_policy_id/5","type":"function","doc":"Gets a list of distribution IDs for distributions that have a cache behavior thats associated with the specified origin request policy. You can optionally specify the maximum number of items to receive in the response. If the total number of items in the list exceeds the maximum that you specify, or the default maximum, the response is paginated. To get the next page of items, send a subsequent request that specifies the NextMarker value from the current response as the Marker value in the subsequent request."},{"ref":"AWS.CloudFront.html#list_distributions_by_realtime_log_config/3","title":"AWS.CloudFront.list_distributions_by_realtime_log_config/3","type":"function","doc":"Gets a list of distributions that have a cache behavior thats associated with the specified real-time log configuration. You can specify the real-time log configuration by its name or its Amazon Resource Name (ARN). You must provide at least one. If you provide both, CloudFront uses the name to identify the real-time log configuration to list distributions for. You can optionally specify the maximum number of items to receive in the response. If the total number of items in the list exceeds the maximum that you specify, or the default maximum, the response is paginated. To get the next page of items, send a subsequent request that specifies the NextMarker value from the current response as the Marker value in the subsequent request."},{"ref":"AWS.CloudFront.html#list_distributions_by_web_a_c_l_id/5","title":"AWS.CloudFront.list_distributions_by_web_a_c_l_id/5","type":"function","doc":"List the distributions that are associated with a specified AWS WAF web ACL."},{"ref":"AWS.CloudFront.html#list_field_level_encryption_configs/4","title":"AWS.CloudFront.list_field_level_encryption_configs/4","type":"function","doc":"List all field-level encryption configurations that have been created in CloudFront for this account."},{"ref":"AWS.CloudFront.html#list_field_level_encryption_profiles/4","title":"AWS.CloudFront.list_field_level_encryption_profiles/4","type":"function","doc":"Request a list of field-level encryption profiles that have been created in CloudFront for this account."},{"ref":"AWS.CloudFront.html#list_invalidations/5","title":"AWS.CloudFront.list_invalidations/5","type":"function","doc":"Lists invalidation batches."},{"ref":"AWS.CloudFront.html#list_origin_request_policies/5","title":"AWS.CloudFront.list_origin_request_policies/5","type":"function","doc":"Gets a list of origin request policies. You can optionally apply a filter to return only the managed policies created by AWS, or only the custom policies created in your AWS account. You can optionally specify the maximum number of items to receive in the response. If the total number of items in the list exceeds the maximum that you specify, or the default maximum, the response is paginated. To get the next page of items, send a subsequent request that specifies the NextMarker value from the current response as the Marker value in the subsequent request."},{"ref":"AWS.CloudFront.html#list_public_keys/4","title":"AWS.CloudFront.list_public_keys/4","type":"function","doc":"List all public keys that have been added to CloudFront for this account."},{"ref":"AWS.CloudFront.html#list_realtime_log_configs/4","title":"AWS.CloudFront.list_realtime_log_configs/4","type":"function","doc":"Gets a list of real-time log configurations. You can optionally specify the maximum number of items to receive in the response. If the total number of items in the list exceeds the maximum that you specify, or the default maximum, the response is paginated. To get the next page of items, send a subsequent request that specifies the NextMarker value from the current response as the Marker value in the subsequent request."},{"ref":"AWS.CloudFront.html#list_streaming_distributions/4","title":"AWS.CloudFront.list_streaming_distributions/4","type":"function","doc":"List streaming distributions."},{"ref":"AWS.CloudFront.html#list_tags_for_resource/3","title":"AWS.CloudFront.list_tags_for_resource/3","type":"function","doc":"List tags for a CloudFront resource."},{"ref":"AWS.CloudFront.html#tag_resource/3","title":"AWS.CloudFront.tag_resource/3","type":"function","doc":"Add tags to a CloudFront resource."},{"ref":"AWS.CloudFront.html#untag_resource/3","title":"AWS.CloudFront.untag_resource/3","type":"function","doc":"Remove tags from a CloudFront resource."},{"ref":"AWS.CloudFront.html#update_cache_policy/4","title":"AWS.CloudFront.update_cache_policy/4","type":"function","doc":"Updates a cache policy configuration. When you update a cache policy configuration, all the fields are updated with the values provided in the request. You cannot update some fields independent of others. To update a cache policy configuration: Use GetCachePolicyConfig to get the current configuration. Locally modify the fields in the cache policy configuration that you want to update. Call UpdateCachePolicy by providing the entire cache policy configuration, including the fields that you modified and those that you didnt."},{"ref":"AWS.CloudFront.html#update_cloud_front_origin_access_identity/4","title":"AWS.CloudFront.update_cloud_front_origin_access_identity/4","type":"function","doc":"Update an origin access identity."},{"ref":"AWS.CloudFront.html#update_distribution/4","title":"AWS.CloudFront.update_distribution/4","type":"function","doc":"Updates the configuration for a web distribution. When you update a distribution, there are more required fields than when you create a distribution. When you update your distribution by using this API action, follow the steps here to get the current configuration and then make your updates, to make sure that you include all of the required fields. To view a summary, see Required Fields for Create Distribution and Update Distribution in the Amazon CloudFront Developer Guide. The update process includes getting the current distribution configuration, updating the XML document that is returned to make your changes, and then submitting an UpdateDistribution request to make the updates. For information about updating a distribution using the CloudFront console instead, see Creating a Distribution in the Amazon CloudFront Developer Guide. To update a web distribution using the CloudFront API Submit a GetDistributionConfig request to get the current configuration and an Etag header for the distribution. If you update the distribution again, you must get a new Etag header. Update the XML document that was returned in the response to your GetDistributionConfig request to include your changes. When you edit the XML file, be aware of the following: You must strip out the ETag parameter that is returned. Additional fields are required when you update a distribution. There may be fields included in the XML file for features that you haven&#39;t configured for your distribution. This is expected and required to successfully update the distribution. You can&#39;t change the value of CallerReference. If you try to change this value, CloudFront returns an IllegalUpdate error. The new configuration replaces the existing configuration; the values that you specify in an UpdateDistribution request are not merged into your existing configuration. When you add, delete, or replace values in an element that allows multiple values (for example, CNAME), you must specify all of the values that you want to appear in the updated distribution. In addition, you must update the corresponding Quantity element. Submit an UpdateDistribution request to update the configuration for your distribution: In the request body, include the XML document that you updated in Step The request body must include an XML document with a DistributionConfig element. Set the value of the HTTP If-Match header to the value of the ETag header that CloudFront returned when you submitted the GetDistributionConfig request in Step 1. Review the response to the UpdateDistribution request to confirm that the configuration was successfully updated. Optional: Submit a GetDistribution request to confirm that your changes have propagated. When propagation is complete, the value of Status is Deployed."},{"ref":"AWS.CloudFront.html#update_field_level_encryption_config/4","title":"AWS.CloudFront.update_field_level_encryption_config/4","type":"function","doc":"Update a field-level encryption configuration."},{"ref":"AWS.CloudFront.html#update_field_level_encryption_profile/4","title":"AWS.CloudFront.update_field_level_encryption_profile/4","type":"function","doc":"Update a field-level encryption profile."},{"ref":"AWS.CloudFront.html#update_origin_request_policy/4","title":"AWS.CloudFront.update_origin_request_policy/4","type":"function","doc":"Updates an origin request policy configuration. When you update an origin request policy configuration, all the fields are updated with the values provided in the request. You cannot update some fields independent of others. To update an origin request policy configuration: Use GetOriginRequestPolicyConfig to get the current configuration. Locally modify the fields in the origin request policy configuration that you want to update. Call UpdateOriginRequestPolicy by providing the entire origin request policy configuration, including the fields that you modified and those that you didnt."},{"ref":"AWS.CloudFront.html#update_public_key/4","title":"AWS.CloudFront.update_public_key/4","type":"function","doc":"Update public key information. Note that the only value you can change is the comment."},{"ref":"AWS.CloudFront.html#update_realtime_log_config/3","title":"AWS.CloudFront.update_realtime_log_config/3","type":"function","doc":"Updates a real-time log configuration. When you update a real-time log configuration, all the parameters are updated with the values provided in the request. You cannot update some parameters independent of others. To update a real-time log configuration: Call GetRealtimeLogConfig to get the current real-time log configuration. Locally modify the parameters in the real-time log configuration that you want to update. Call this API (UpdateRealtimeLogConfig) by providing the entire real-time log configuration, including the parameters that you modified and those that you didnt. You cannot update a real-time log configurations Name or ARN."},{"ref":"AWS.CloudFront.html#update_streaming_distribution/4","title":"AWS.CloudFront.update_streaming_distribution/4","type":"function","doc":"Update a streaming distribution."},{"ref":"AWS.CloudHSM.html","title":"AWS.CloudHSM","type":"module","doc":"AWS CloudHSM Service This is documentation for AWS CloudHSM Classic. For more information, see AWS CloudHSM Classic FAQs, the AWS CloudHSM Classic User Guide, and the AWS CloudHSM Classic API Reference. For information about the current version of AWS CloudHSM, see AWS CloudHSM, the AWS CloudHSM User Guide, and the AWS CloudHSM API Reference."},{"ref":"AWS.CloudHSM.html#add_tags_to_resource/3","title":"AWS.CloudHSM.add_tags_to_resource/3","type":"function","doc":"This is documentation for AWS CloudHSM Classic. For more information, see AWS CloudHSM Classic FAQs, the AWS CloudHSM Classic User Guide, and the AWS CloudHSM Classic API Reference. For information about the current version of AWS CloudHSM, see AWS CloudHSM, the AWS CloudHSM User Guide, and the AWS CloudHSM API Reference. Adds or overwrites one or more tags for the specified AWS CloudHSM resource. Each tag consists of a key and a value. Tag keys must be unique to each resource."},{"ref":"AWS.CloudHSM.html#create_hapg/3","title":"AWS.CloudHSM.create_hapg/3","type":"function","doc":"This is documentation for AWS CloudHSM Classic. For more information, see AWS CloudHSM Classic FAQs, the AWS CloudHSM Classic User Guide, and the AWS CloudHSM Classic API Reference. For information about the current version of AWS CloudHSM, see AWS CloudHSM, the AWS CloudHSM User Guide, and the AWS CloudHSM API Reference. Creates a high-availability partition group. A high-availability partition group is a group of partitions that spans multiple physical HSMs."},{"ref":"AWS.CloudHSM.html#create_hsm/3","title":"AWS.CloudHSM.create_hsm/3","type":"function","doc":"This is documentation for AWS CloudHSM Classic. For more information, see AWS CloudHSM Classic FAQs, the AWS CloudHSM Classic User Guide, and the AWS CloudHSM Classic API Reference. For information about the current version of AWS CloudHSM, see AWS CloudHSM, the AWS CloudHSM User Guide, and the AWS CloudHSM API Reference. Creates an uninitialized HSM instance. There is an upfront fee charged for each HSM instance that you create with the CreateHsm operation. If you accidentally provision an HSM and want to request a refund, delete the instance using the DeleteHsm operation, go to the AWS Support Center, create a new case, and select Account and Billing Support. It can take up to 20 minutes to create and provision an HSM. You can monitor the status of the HSM with the DescribeHsm operation. The HSM is ready to be initialized when the status changes to RUNNING."},{"ref":"AWS.CloudHSM.html#create_luna_client/3","title":"AWS.CloudHSM.create_luna_client/3","type":"function","doc":"This is documentation for AWS CloudHSM Classic. For more information, see AWS CloudHSM Classic FAQs, the AWS CloudHSM Classic User Guide, and the AWS CloudHSM Classic API Reference. For information about the current version of AWS CloudHSM, see AWS CloudHSM, the AWS CloudHSM User Guide, and the AWS CloudHSM API Reference. Creates an HSM client."},{"ref":"AWS.CloudHSM.html#delete_hapg/3","title":"AWS.CloudHSM.delete_hapg/3","type":"function","doc":"This is documentation for AWS CloudHSM Classic. For more information, see AWS CloudHSM Classic FAQs, the AWS CloudHSM Classic User Guide, and the AWS CloudHSM Classic API Reference. For information about the current version of AWS CloudHSM, see AWS CloudHSM, the AWS CloudHSM User Guide, and the AWS CloudHSM API Reference. Deletes a high-availability partition group."},{"ref":"AWS.CloudHSM.html#delete_hsm/3","title":"AWS.CloudHSM.delete_hsm/3","type":"function","doc":"This is documentation for AWS CloudHSM Classic. For more information, see AWS CloudHSM Classic FAQs, the AWS CloudHSM Classic User Guide, and the AWS CloudHSM Classic API Reference. For information about the current version of AWS CloudHSM, see AWS CloudHSM, the AWS CloudHSM User Guide, and the AWS CloudHSM API Reference. Deletes an HSM. After completion, this operation cannot be undone and your key material cannot be recovered."},{"ref":"AWS.CloudHSM.html#delete_luna_client/3","title":"AWS.CloudHSM.delete_luna_client/3","type":"function","doc":"This is documentation for AWS CloudHSM Classic. For more information, see AWS CloudHSM Classic FAQs, the AWS CloudHSM Classic User Guide, and the AWS CloudHSM Classic API Reference. For information about the current version of AWS CloudHSM, see AWS CloudHSM, the AWS CloudHSM User Guide, and the AWS CloudHSM API Reference. Deletes a client."},{"ref":"AWS.CloudHSM.html#describe_hapg/3","title":"AWS.CloudHSM.describe_hapg/3","type":"function","doc":"This is documentation for AWS CloudHSM Classic. For more information, see AWS CloudHSM Classic FAQs, the AWS CloudHSM Classic User Guide, and the AWS CloudHSM Classic API Reference. For information about the current version of AWS CloudHSM, see AWS CloudHSM, the AWS CloudHSM User Guide, and the AWS CloudHSM API Reference. Retrieves information about a high-availability partition group."},{"ref":"AWS.CloudHSM.html#describe_hsm/3","title":"AWS.CloudHSM.describe_hsm/3","type":"function","doc":"This is documentation for AWS CloudHSM Classic. For more information, see AWS CloudHSM Classic FAQs, the AWS CloudHSM Classic User Guide, and the AWS CloudHSM Classic API Reference. For information about the current version of AWS CloudHSM, see AWS CloudHSM, the AWS CloudHSM User Guide, and the AWS CloudHSM API Reference. Retrieves information about an HSM. You can identify the HSM by its ARN or its serial number."},{"ref":"AWS.CloudHSM.html#describe_luna_client/3","title":"AWS.CloudHSM.describe_luna_client/3","type":"function","doc":"This is documentation for AWS CloudHSM Classic. For more information, see AWS CloudHSM Classic FAQs, the AWS CloudHSM Classic User Guide, and the AWS CloudHSM Classic API Reference. For information about the current version of AWS CloudHSM, see AWS CloudHSM, the AWS CloudHSM User Guide, and the AWS CloudHSM API Reference. Retrieves information about an HSM client."},{"ref":"AWS.CloudHSM.html#get_config/3","title":"AWS.CloudHSM.get_config/3","type":"function","doc":"This is documentation for AWS CloudHSM Classic. For more information, see AWS CloudHSM Classic FAQs, the AWS CloudHSM Classic User Guide, and the AWS CloudHSM Classic API Reference. For information about the current version of AWS CloudHSM, see AWS CloudHSM, the AWS CloudHSM User Guide, and the AWS CloudHSM API Reference. Gets the configuration files necessary to connect to all high availability partition groups the client is associated with."},{"ref":"AWS.CloudHSM.html#list_available_zones/3","title":"AWS.CloudHSM.list_available_zones/3","type":"function","doc":"This is documentation for AWS CloudHSM Classic. For more information, see AWS CloudHSM Classic FAQs, the AWS CloudHSM Classic User Guide, and the AWS CloudHSM Classic API Reference. For information about the current version of AWS CloudHSM, see AWS CloudHSM, the AWS CloudHSM User Guide, and the AWS CloudHSM API Reference. Lists the Availability Zones that have available AWS CloudHSM capacity."},{"ref":"AWS.CloudHSM.html#list_hapgs/3","title":"AWS.CloudHSM.list_hapgs/3","type":"function","doc":"This is documentation for AWS CloudHSM Classic. For more information, see AWS CloudHSM Classic FAQs, the AWS CloudHSM Classic User Guide, and the AWS CloudHSM Classic API Reference. For information about the current version of AWS CloudHSM, see AWS CloudHSM, the AWS CloudHSM User Guide, and the AWS CloudHSM API Reference. Lists the high-availability partition groups for the account. This operation supports pagination with the use of the NextToken member. If more results are available, the NextToken member of the response contains a token that you pass in the next call to ListHapgs to retrieve the next set of items."},{"ref":"AWS.CloudHSM.html#list_hsms/3","title":"AWS.CloudHSM.list_hsms/3","type":"function","doc":"This is documentation for AWS CloudHSM Classic. For more information, see AWS CloudHSM Classic FAQs, the AWS CloudHSM Classic User Guide, and the AWS CloudHSM Classic API Reference. For information about the current version of AWS CloudHSM, see AWS CloudHSM, the AWS CloudHSM User Guide, and the AWS CloudHSM API Reference. Retrieves the identifiers of all of the HSMs provisioned for the current customer. This operation supports pagination with the use of the NextToken member. If more results are available, the NextToken member of the response contains a token that you pass in the next call to ListHsms to retrieve the next set of items."},{"ref":"AWS.CloudHSM.html#list_luna_clients/3","title":"AWS.CloudHSM.list_luna_clients/3","type":"function","doc":"This is documentation for AWS CloudHSM Classic. For more information, see AWS CloudHSM Classic FAQs, the AWS CloudHSM Classic User Guide, and the AWS CloudHSM Classic API Reference. For information about the current version of AWS CloudHSM, see AWS CloudHSM, the AWS CloudHSM User Guide, and the AWS CloudHSM API Reference. Lists all of the clients. This operation supports pagination with the use of the NextToken member. If more results are available, the NextToken member of the response contains a token that you pass in the next call to ListLunaClients to retrieve the next set of items."},{"ref":"AWS.CloudHSM.html#list_tags_for_resource/3","title":"AWS.CloudHSM.list_tags_for_resource/3","type":"function","doc":"This is documentation for AWS CloudHSM Classic. For more information, see AWS CloudHSM Classic FAQs, the AWS CloudHSM Classic User Guide, and the AWS CloudHSM Classic API Reference. For information about the current version of AWS CloudHSM, see AWS CloudHSM, the AWS CloudHSM User Guide, and the AWS CloudHSM API Reference. Returns a list of all tags for the specified AWS CloudHSM resource."},{"ref":"AWS.CloudHSM.html#modify_hapg/3","title":"AWS.CloudHSM.modify_hapg/3","type":"function","doc":"This is documentation for AWS CloudHSM Classic. For more information, see AWS CloudHSM Classic FAQs, the AWS CloudHSM Classic User Guide, and the AWS CloudHSM Classic API Reference. For information about the current version of AWS CloudHSM, see AWS CloudHSM, the AWS CloudHSM User Guide, and the AWS CloudHSM API Reference. Modifies an existing high-availability partition group."},{"ref":"AWS.CloudHSM.html#modify_hsm/3","title":"AWS.CloudHSM.modify_hsm/3","type":"function","doc":"This is documentation for AWS CloudHSM Classic. For more information, see AWS CloudHSM Classic FAQs, the AWS CloudHSM Classic User Guide, and the AWS CloudHSM Classic API Reference. For information about the current version of AWS CloudHSM, see AWS CloudHSM, the AWS CloudHSM User Guide, and the AWS CloudHSM API Reference. Modifies an HSM. This operation can result in the HSM being offline for up to 15 minutes while the AWS CloudHSM service is reconfigured. If you are modifying a production HSM, you should ensure that your AWS CloudHSM service is configured for high availability, and consider executing this operation during a maintenance window."},{"ref":"AWS.CloudHSM.html#modify_luna_client/3","title":"AWS.CloudHSM.modify_luna_client/3","type":"function","doc":"This is documentation for AWS CloudHSM Classic. For more information, see AWS CloudHSM Classic FAQs, the AWS CloudHSM Classic User Guide, and the AWS CloudHSM Classic API Reference. For information about the current version of AWS CloudHSM, see AWS CloudHSM, the AWS CloudHSM User Guide, and the AWS CloudHSM API Reference. Modifies the certificate used by the client. This action can potentially start a workflow to install the new certificate on the client&#39;s HSMs."},{"ref":"AWS.CloudHSM.html#remove_tags_from_resource/3","title":"AWS.CloudHSM.remove_tags_from_resource/3","type":"function","doc":"This is documentation for AWS CloudHSM Classic. For more information, see AWS CloudHSM Classic FAQs, the AWS CloudHSM Classic User Guide, and the AWS CloudHSM Classic API Reference. For information about the current version of AWS CloudHSM, see AWS CloudHSM, the AWS CloudHSM User Guide, and the AWS CloudHSM API Reference. Removes one or more tags from the specified AWS CloudHSM resource. To remove a tag, specify only the tag key to remove (not the value). To overwrite the value for an existing tag, use AddTagsToResource."},{"ref":"AWS.CloudHSMV2.html","title":"AWS.CloudHSMV2","type":"module","doc":"For more information about AWS CloudHSM, see AWS CloudHSM and the AWS CloudHSM User Guide."},{"ref":"AWS.CloudHSMV2.html#copy_backup_to_region/3","title":"AWS.CloudHSMV2.copy_backup_to_region/3","type":"function","doc":"Copy an AWS CloudHSM cluster backup to a different region."},{"ref":"AWS.CloudHSMV2.html#create_cluster/3","title":"AWS.CloudHSMV2.create_cluster/3","type":"function","doc":"Creates a new AWS CloudHSM cluster."},{"ref":"AWS.CloudHSMV2.html#create_hsm/3","title":"AWS.CloudHSMV2.create_hsm/3","type":"function","doc":"Creates a new hardware security module (HSM) in the specified AWS CloudHSM cluster."},{"ref":"AWS.CloudHSMV2.html#delete_backup/3","title":"AWS.CloudHSMV2.delete_backup/3","type":"function","doc":"Deletes a specified AWS CloudHSM backup. A backup can be restored up to 7 days after the DeleteBackup request is made. For more information on restoring a backup, see RestoreBackup."},{"ref":"AWS.CloudHSMV2.html#delete_cluster/3","title":"AWS.CloudHSMV2.delete_cluster/3","type":"function","doc":"Deletes the specified AWS CloudHSM cluster. Before you can delete a cluster, you must delete all HSMs in the cluster. To see if the cluster contains any HSMs, use DescribeClusters. To delete an HSM, use DeleteHsm."},{"ref":"AWS.CloudHSMV2.html#delete_hsm/3","title":"AWS.CloudHSMV2.delete_hsm/3","type":"function","doc":"Deletes the specified HSM. To specify an HSM, you can use its identifier (ID), the IP address of the HSM&#39;s elastic network interface (ENI), or the ID of the HSM&#39;s ENI. You need to specify only one of these values. To find these values, use DescribeClusters."},{"ref":"AWS.CloudHSMV2.html#describe_backups/3","title":"AWS.CloudHSMV2.describe_backups/3","type":"function","doc":"Gets information about backups of AWS CloudHSM clusters. This is a paginated operation, which means that each response might contain only a subset of all the backups. When the response contains only a subset of backups, it includes a NextToken value. Use this value in a subsequent DescribeBackups request to get more backups. When you receive a response with no NextToken (or an empty or null value), that means there are no more backups to get."},{"ref":"AWS.CloudHSMV2.html#describe_clusters/3","title":"AWS.CloudHSMV2.describe_clusters/3","type":"function","doc":"Gets information about AWS CloudHSM clusters. This is a paginated operation, which means that each response might contain only a subset of all the clusters. When the response contains only a subset of clusters, it includes a NextToken value. Use this value in a subsequent DescribeClusters request to get more clusters. When you receive a response with no NextToken (or an empty or null value), that means there are no more clusters to get."},{"ref":"AWS.CloudHSMV2.html#initialize_cluster/3","title":"AWS.CloudHSMV2.initialize_cluster/3","type":"function","doc":"Claims an AWS CloudHSM cluster by submitting the cluster certificate issued by your issuing certificate authority (CA) and the CA&#39;s root certificate. Before you can claim a cluster, you must sign the cluster&#39;s certificate signing request (CSR) with your issuing CA. To get the cluster&#39;s CSR, use DescribeClusters."},{"ref":"AWS.CloudHSMV2.html#list_tags/3","title":"AWS.CloudHSMV2.list_tags/3","type":"function","doc":"Gets a list of tags for the specified AWS CloudHSM cluster. This is a paginated operation, which means that each response might contain only a subset of all the tags. When the response contains only a subset of tags, it includes a NextToken value. Use this value in a subsequent ListTags request to get more tags. When you receive a response with no NextToken (or an empty or null value), that means there are no more tags to get."},{"ref":"AWS.CloudHSMV2.html#restore_backup/3","title":"AWS.CloudHSMV2.restore_backup/3","type":"function","doc":"Restores a specified AWS CloudHSM backup that is in the PENDING_DELETION state. For mor information on deleting a backup, see DeleteBackup."},{"ref":"AWS.CloudHSMV2.html#tag_resource/3","title":"AWS.CloudHSMV2.tag_resource/3","type":"function","doc":"Adds or overwrites one or more tags for the specified AWS CloudHSM cluster."},{"ref":"AWS.CloudHSMV2.html#untag_resource/3","title":"AWS.CloudHSMV2.untag_resource/3","type":"function","doc":"Removes the specified tag or tags from the specified AWS CloudHSM cluster."},{"ref":"AWS.CloudSearch.html","title":"AWS.CloudSearch","type":"module","doc":"Amazon CloudSearch Configuration Service You use the Amazon CloudSearch configuration service to create, configure, and manage search domains. Configuration service requests are submitted using the AWS Query protocol. AWS Query requests are HTTP or HTTPS requests submitted via HTTP GET or POST with a query parameter named Action. The endpoint for configuration service requests is region-specific: cloudsearch.region.amazonaws.com. For example, cloudsearch.us-east-1.amazonaws.com. For a current list of supported regions and endpoints, see Regions and Endpoints."},{"ref":"AWS.CloudSearch.html#build_suggesters/3","title":"AWS.CloudSearch.build_suggesters/3","type":"function","doc":"Indexes the search suggestions. For more information, see Configuring Suggesters in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#create_domain/3","title":"AWS.CloudSearch.create_domain/3","type":"function","doc":"Creates a new search domain. For more information, see Creating a Search Domain in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#define_analysis_scheme/3","title":"AWS.CloudSearch.define_analysis_scheme/3","type":"function","doc":"Configures an analysis scheme that can be applied to a text or text-array field to define language-specific text processing options. For more information, see Configuring Analysis Schemes in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#define_expression/3","title":"AWS.CloudSearch.define_expression/3","type":"function","doc":"Configures an Expression for the search domain. Used to create new expressions and modify existing ones. If the expression exists, the new configuration replaces the old one. For more information, see Configuring Expressions in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#define_index_field/3","title":"AWS.CloudSearch.define_index_field/3","type":"function","doc":"Configures an IndexField for the search domain. Used to create new fields and modify existing ones. You must specify the name of the domain you are configuring and an index field configuration. The index field configuration specifies a unique name, the index field type, and the options you want to configure for the field. The options you can specify depend on the IndexFieldType. If the field exists, the new configuration replaces the old one. For more information, see Configuring Index Fields in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#define_suggester/3","title":"AWS.CloudSearch.define_suggester/3","type":"function","doc":"Configures a suggester for a domain. A suggester enables you to display possible matches before users finish typing their queries. When you configure a suggester, you must specify the name of the text field you want to search for possible matches and a unique name for the suggester. For more information, see Getting Search Suggestions in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#delete_analysis_scheme/3","title":"AWS.CloudSearch.delete_analysis_scheme/3","type":"function","doc":"Deletes an analysis scheme. For more information, see Configuring Analysis Schemes in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#delete_domain/3","title":"AWS.CloudSearch.delete_domain/3","type":"function","doc":"Permanently deletes a search domain and all of its data. Once a domain has been deleted, it cannot be recovered. For more information, see Deleting a Search Domain in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#delete_expression/3","title":"AWS.CloudSearch.delete_expression/3","type":"function","doc":"Removes an Expression from the search domain. For more information, see Configuring Expressions in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#delete_index_field/3","title":"AWS.CloudSearch.delete_index_field/3","type":"function","doc":"Removes an IndexField from the search domain. For more information, see Configuring Index Fields in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#delete_suggester/3","title":"AWS.CloudSearch.delete_suggester/3","type":"function","doc":"Deletes a suggester. For more information, see Getting Search Suggestions in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#describe_analysis_schemes/3","title":"AWS.CloudSearch.describe_analysis_schemes/3","type":"function","doc":"Gets the analysis schemes configured for a domain. An analysis scheme defines language-specific text processing options for a text field. Can be limited to specific analysis schemes by name. By default, shows all analysis schemes and includes any pending changes to the configuration. Set the Deployed option to true to show the active configuration and exclude pending changes. For more information, see Configuring Analysis Schemes in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#describe_availability_options/3","title":"AWS.CloudSearch.describe_availability_options/3","type":"function","doc":"Gets the availability options configured for a domain. By default, shows the configuration with any pending changes. Set the Deployed option to true to show the active configuration and exclude pending changes. For more information, see Configuring Availability Options in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#describe_domain_endpoint_options/3","title":"AWS.CloudSearch.describe_domain_endpoint_options/3","type":"function","doc":"Returns the domain&#39;s endpoint options, specifically whether all requests to the domain must arrive over HTTPS. For more information, see Configuring Domain Endpoint Options in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#describe_domains/3","title":"AWS.CloudSearch.describe_domains/3","type":"function","doc":"Gets information about the search domains owned by this account. Can be limited to specific domains. Shows all domains by default. To get the number of searchable documents in a domain, use the console or submit a matchall request to your domain&#39;s search endpoint: q=matchall&amp;amp;q.parser=structured&amp;amp;size=0. For more information, see Getting Information about a Search Domain in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#describe_expressions/3","title":"AWS.CloudSearch.describe_expressions/3","type":"function","doc":"Gets the expressions configured for the search domain. Can be limited to specific expressions by name. By default, shows all expressions and includes any pending changes to the configuration. Set the Deployed option to true to show the active configuration and exclude pending changes. For more information, see Configuring Expressions in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#describe_index_fields/3","title":"AWS.CloudSearch.describe_index_fields/3","type":"function","doc":"Gets information about the index fields configured for the search domain. Can be limited to specific fields by name. By default, shows all fields and includes any pending changes to the configuration. Set the Deployed option to true to show the active configuration and exclude pending changes. For more information, see Getting Domain Information in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#describe_scaling_parameters/3","title":"AWS.CloudSearch.describe_scaling_parameters/3","type":"function","doc":"Gets the scaling parameters configured for a domain. A domain&#39;s scaling parameters specify the desired search instance type and replication count. For more information, see Configuring Scaling Options in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#describe_service_access_policies/3","title":"AWS.CloudSearch.describe_service_access_policies/3","type":"function","doc":"Gets information about the access policies that control access to the domain&#39;s document and search endpoints. By default, shows the configuration with any pending changes. Set the Deployed option to true to show the active configuration and exclude pending changes. For more information, see Configuring Access for a Search Domain in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#describe_suggesters/3","title":"AWS.CloudSearch.describe_suggesters/3","type":"function","doc":"Gets the suggesters configured for a domain. A suggester enables you to display possible matches before users finish typing their queries. Can be limited to specific suggesters by name. By default, shows all suggesters and includes any pending changes to the configuration. Set the Deployed option to true to show the active configuration and exclude pending changes. For more information, see Getting Search Suggestions in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#index_documents/3","title":"AWS.CloudSearch.index_documents/3","type":"function","doc":"Tells the search domain to start indexing its documents using the latest indexing options. This operation must be invoked to activate options whose OptionStatus is RequiresIndexDocuments."},{"ref":"AWS.CloudSearch.html#list_domain_names/3","title":"AWS.CloudSearch.list_domain_names/3","type":"function","doc":"Lists all search domains owned by an account."},{"ref":"AWS.CloudSearch.html#update_availability_options/3","title":"AWS.CloudSearch.update_availability_options/3","type":"function","doc":"Configures the availability options for a domain. Enabling the Multi-AZ option expands an Amazon CloudSearch domain to an additional Availability Zone in the same Region to increase fault tolerance in the event of a service disruption. Changes to the Multi-AZ option can take about half an hour to become active. For more information, see Configuring Availability Options in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#update_domain_endpoint_options/3","title":"AWS.CloudSearch.update_domain_endpoint_options/3","type":"function","doc":"Updates the domain&#39;s endpoint options, specifically whether all requests to the domain must arrive over HTTPS. For more information, see Configuring Domain Endpoint Options in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#update_scaling_parameters/3","title":"AWS.CloudSearch.update_scaling_parameters/3","type":"function","doc":"Configures scaling parameters for a domain. A domain&#39;s scaling parameters specify the desired search instance type and replication count. Amazon CloudSearch will still automatically scale your domain based on the volume of data and traffic, but not below the desired instance type and replication count. If the Multi-AZ option is enabled, these values control the resources used per Availability Zone. For more information, see Configuring Scaling Options in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CloudSearch.html#update_service_access_policies/3","title":"AWS.CloudSearch.update_service_access_policies/3","type":"function","doc":"Configures the access rules that control access to the domain&#39;s document and search endpoints. For more information, see Configuring Access for an Amazon CloudSearch Domain."},{"ref":"AWS.CloudTrail.html","title":"AWS.CloudTrail","type":"module","doc":"AWS CloudTrail This is the CloudTrail API Reference. It provides descriptions of actions, data types, common parameters, and common errors for CloudTrail. CloudTrail is a web service that records AWS API calls for your AWS account and delivers log files to an Amazon S3 bucket. The recorded information includes the identity of the user, the start time of the AWS API call, the source IP address, the request parameters, and the response elements returned by the service. As an alternative to the API, you can use one of the AWS SDKs, which consist of libraries and sample code for various programming languages and platforms (Java, Ruby, .NET, iOS, Android, etc.). The SDKs provide a convenient way to create programmatic access to AWSCloudTrail. For example, the SDKs take care of cryptographically signing requests, managing errors, and retrying requests automatically. For information about the AWS SDKs, including how to download and install them, see the Tools for Amazon Web Services page. See the AWS CloudTrail User Guide for information about the data that is included with each AWS API call listed in the log files."},{"ref":"AWS.CloudTrail.html#add_tags/3","title":"AWS.CloudTrail.add_tags/3","type":"function","doc":"Adds one or more tags to a trail, up to a limit of 50. Overwrites an existing tag&#39;s value when a new value is specified for an existing tag key. Tag key names must be unique for a trail; you cannot have two keys with the same name but different values. If you specify a key without a value, the tag will be created with the specified key and a value of null. You can tag a trail that applies to all AWS Regions only from the Region in which the trail was created (also known as its home region)."},{"ref":"AWS.CloudTrail.html#create_trail/3","title":"AWS.CloudTrail.create_trail/3","type":"function","doc":"Creates a trail that specifies the settings for delivery of log data to an Amazon S3 bucket."},{"ref":"AWS.CloudTrail.html#delete_trail/3","title":"AWS.CloudTrail.delete_trail/3","type":"function","doc":"Deletes a trail. This operation must be called from the region in which the trail was created. DeleteTrail cannot be called on the shadow trails (replicated trails in other regions) of a trail that is enabled in all regions."},{"ref":"AWS.CloudTrail.html#describe_trails/3","title":"AWS.CloudTrail.describe_trails/3","type":"function","doc":"Retrieves settings for one or more trails associated with the current region for your account."},{"ref":"AWS.CloudTrail.html#get_event_selectors/3","title":"AWS.CloudTrail.get_event_selectors/3","type":"function","doc":"Describes the settings for the event selectors that you configured for your trail. The information returned for your event selectors includes the following: If your event selector includes read-only events, write-only events, or all events. This applies to both management events and data events. If your event selector includes management events. If your event selector includes data events, the Amazon S3 objects or AWS Lambda functions that you are logging for data events. For more information, see Logging Data and Management Events for Trails in the AWS CloudTrail User Guide."},{"ref":"AWS.CloudTrail.html#get_insight_selectors/3","title":"AWS.CloudTrail.get_insight_selectors/3","type":"function","doc":"Describes the settings for the Insights event selectors that you configured for your trail. GetInsightSelectors shows if CloudTrail Insights event logging is enabled on the trail, and if it is, which insight types are enabled. If you run GetInsightSelectors on a trail that does not have Insights events enabled, the operation throws the exception InsightNotEnabledException For more information, see Logging CloudTrail Insights Events for Trails in the AWS CloudTrail User Guide."},{"ref":"AWS.CloudTrail.html#get_trail/3","title":"AWS.CloudTrail.get_trail/3","type":"function","doc":"Returns settings information for a specified trail."},{"ref":"AWS.CloudTrail.html#get_trail_status/3","title":"AWS.CloudTrail.get_trail_status/3","type":"function","doc":"Returns a JSON-formatted list of information about the specified trail. Fields include information on delivery errors, Amazon SNS and Amazon S3 errors, and start and stop logging times for each trail. This operation returns trail status from a single region. To return trail status from all regions, you must call the operation on each region."},{"ref":"AWS.CloudTrail.html#list_public_keys/3","title":"AWS.CloudTrail.list_public_keys/3","type":"function","doc":"Returns all public keys whose private keys were used to sign the digest files within the specified time range. The public key is needed to validate digest files that were signed with its corresponding private key. CloudTrail uses different private/public key pairs per region. Each digest file is signed with a private key unique to its region. Therefore, when you validate a digest file from a particular region, you must look in the same region for its corresponding public key."},{"ref":"AWS.CloudTrail.html#list_tags/3","title":"AWS.CloudTrail.list_tags/3","type":"function","doc":"Lists the tags for the trail in the current region."},{"ref":"AWS.CloudTrail.html#list_trails/3","title":"AWS.CloudTrail.list_trails/3","type":"function","doc":"Lists trails that are in the current account."},{"ref":"AWS.CloudTrail.html#lookup_events/3","title":"AWS.CloudTrail.lookup_events/3","type":"function","doc":"Looks up management events or CloudTrail Insights events that are captured by CloudTrail. You can look up events that occurred in a region within the last 90 days. Lookup supports the following attributes for management events: AWS access key Event ID Event name Event source Read only Resource name Resource type User name Lookup supports the following attributes for Insights events: Event ID Event name Event source All attributes are optional. The default number of results returned is 50, with a maximum of 50 possible. The response includes a token that you can use to get the next page of results. The rate of lookup requests is limited to two per second per account. If this limit is exceeded, a throttling error occurs."},{"ref":"AWS.CloudTrail.html#put_event_selectors/3","title":"AWS.CloudTrail.put_event_selectors/3","type":"function","doc":"Configures an event selector for your trail. Use event selectors to further specify the management and data event settings for your trail. By default, trails created without specific event selectors will be configured to log all read and write management events, and no data events. When an event occurs in your account, CloudTrail evaluates the event selectors in all trails. For each trail, if the event matches any event selector, the trail processes and logs the event. If the event doesn&#39;t match any event selector, the trail doesn&#39;t log the event. Example You create an event selector for a trail and specify that you want write-only events. The EC2 GetConsoleOutput and RunInstances API operations occur in your account. CloudTrail evaluates whether the events match your event selectors. The RunInstances is a write-only event and it matches your event selector. The trail logs the event. The GetConsoleOutput is a read-only event but it doesn&#39;t match your event selector. The trail doesn&#39;t log the event. The PutEventSelectors operation must be called from the region in which the trail was created; otherwise, an InvalidHomeRegionException is thrown. You can configure up to five event selectors for each trail. For more information, see Logging Data and Management Events for Trails and Limits in AWS CloudTrail in the AWS CloudTrail User Guide."},{"ref":"AWS.CloudTrail.html#put_insight_selectors/3","title":"AWS.CloudTrail.put_insight_selectors/3","type":"function","doc":"Lets you enable Insights event logging by specifying the Insights selectors that you want to enable on an existing trail. You also use PutInsightSelectors to turn off Insights event logging, by passing an empty list of insight types. In this release, only ApiCallRateInsight is supported as an Insights selector."},{"ref":"AWS.CloudTrail.html#remove_tags/3","title":"AWS.CloudTrail.remove_tags/3","type":"function","doc":"Removes the specified tags from a trail."},{"ref":"AWS.CloudTrail.html#start_logging/3","title":"AWS.CloudTrail.start_logging/3","type":"function","doc":"Starts the recording of AWS API calls and log file delivery for a trail. For a trail that is enabled in all regions, this operation must be called from the region in which the trail was created. This operation cannot be called on the shadow trails (replicated trails in other regions) of a trail that is enabled in all regions."},{"ref":"AWS.CloudTrail.html#stop_logging/3","title":"AWS.CloudTrail.stop_logging/3","type":"function","doc":"Suspends the recording of AWS API calls and log file delivery for the specified trail. Under most circumstances, there is no need to use this action. You can update a trail without stopping it first. This action is the only way to stop recording. For a trail enabled in all regions, this operation must be called from the region in which the trail was created, or an InvalidHomeRegionException will occur. This operation cannot be called on the shadow trails (replicated trails in other regions) of a trail enabled in all regions."},{"ref":"AWS.CloudTrail.html#update_trail/3","title":"AWS.CloudTrail.update_trail/3","type":"function","doc":"Updates the settings that specify delivery of log files. Changes to a trail do not require stopping the CloudTrail service. Use this action to designate an existing bucket for log delivery. If the existing bucket has previously been a target for CloudTrail log files, an IAM policy exists for the bucket. UpdateTrail must be called from the region in which the trail was created; otherwise, an InvalidHomeRegionException is thrown."},{"ref":"AWS.CloudWatch.html","title":"AWS.CloudWatch","type":"module","doc":"Amazon CloudWatch monitors your Amazon Web Services (AWS) resources and the applications you run on AWS in real time. You can use CloudWatch to collect and track metrics, which are the variables you want to measure for your resources and applications. CloudWatch alarms send notifications or automatically change the resources you are monitoring based on rules that you define. For example, you can monitor the CPU usage and disk reads and writes of your Amazon EC2 instances. Then, use this data to determine whether you should launch additional instances to handle increased load. You can also use this data to stop under-used instances to save money. In addition to monitoring the built-in metrics that come with AWS, you can monitor your own custom metrics. With CloudWatch, you gain system-wide visibility into resource utilization, application performance, and operational health."},{"ref":"AWS.CloudWatch.html#delete_alarms/3","title":"AWS.CloudWatch.delete_alarms/3","type":"function","doc":"Deletes the specified alarms. You can delete up to 100 alarms in one operation. However, this total can include no more than one composite alarm. For example, you could delete 99 metric alarms and one composite alarms with one operation, but you can&#39;t delete two composite alarms with one operation. In the event of an error, no alarms are deleted. It is possible to create a loop or cycle of composite alarms, where composite alarm A depends on composite alarm B, and composite alarm B also depends on composite alarm A. In this scenario, you can&#39;t delete any composite alarm that is part of the cycle because there is always still a composite alarm that depends on that alarm that you want to delete. To get out of such a situation, you must break the cycle by changing the rule of one of the composite alarms in the cycle to remove a dependency that creates the cycle. The simplest change to make to break a cycle is to change the AlarmRule of one of the alarms to False. Additionally, the evaluation of composite alarms stops if CloudWatch detects a cycle in the evaluation path."},{"ref":"AWS.CloudWatch.html#delete_anomaly_detector/3","title":"AWS.CloudWatch.delete_anomaly_detector/3","type":"function","doc":"Deletes the specified anomaly detection model from your account."},{"ref":"AWS.CloudWatch.html#delete_dashboards/3","title":"AWS.CloudWatch.delete_dashboards/3","type":"function","doc":"Deletes all dashboards that you specify. You can specify up to 100 dashboards to delete. If there is an error during this call, no dashboards are deleted."},{"ref":"AWS.CloudWatch.html#delete_insight_rules/3","title":"AWS.CloudWatch.delete_insight_rules/3","type":"function","doc":"Permanently deletes the specified Contributor Insights rules. If you create a rule, delete it, and then re-create it with the same name, historical data from the first time the rule was created might not be available."},{"ref":"AWS.CloudWatch.html#describe_alarm_history/3","title":"AWS.CloudWatch.describe_alarm_history/3","type":"function","doc":"Retrieves the history for the specified alarm. You can filter the results by date range or item type. If an alarm name is not specified, the histories for either all metric alarms or all composite alarms are returned. CloudWatch retains the history of an alarm even if you delete the alarm."},{"ref":"AWS.CloudWatch.html#describe_alarms/3","title":"AWS.CloudWatch.describe_alarms/3","type":"function","doc":"Retrieves the specified alarms. You can filter the results by specifying a a prefix for the alarm name, the alarm state, or a prefix for any action."},{"ref":"AWS.CloudWatch.html#describe_alarms_for_metric/3","title":"AWS.CloudWatch.describe_alarms_for_metric/3","type":"function","doc":"Retrieves the alarms for the specified metric. To filter the results, specify a statistic, period, or unit."},{"ref":"AWS.CloudWatch.html#describe_anomaly_detectors/3","title":"AWS.CloudWatch.describe_anomaly_detectors/3","type":"function","doc":"Lists the anomaly detection models that you have created in your account. You can list all models in your account or filter the results to only the models that are related to a certain namespace, metric name, or metric dimension."},{"ref":"AWS.CloudWatch.html#describe_insight_rules/3","title":"AWS.CloudWatch.describe_insight_rules/3","type":"function","doc":"Returns a list of all the Contributor Insights rules in your account. All rules in your account are returned with a single operation. For more information about Contributor Insights, see Using Contributor Insights to Analyze High-Cardinality Data."},{"ref":"AWS.CloudWatch.html#disable_alarm_actions/3","title":"AWS.CloudWatch.disable_alarm_actions/3","type":"function","doc":"Disables the actions for the specified alarms. When an alarm&#39;s actions are disabled, the alarm actions do not execute when the alarm state changes."},{"ref":"AWS.CloudWatch.html#disable_insight_rules/3","title":"AWS.CloudWatch.disable_insight_rules/3","type":"function","doc":"Disables the specified Contributor Insights rules. When rules are disabled, they do not analyze log groups and do not incur costs."},{"ref":"AWS.CloudWatch.html#enable_alarm_actions/3","title":"AWS.CloudWatch.enable_alarm_actions/3","type":"function","doc":"Enables the actions for the specified alarms."},{"ref":"AWS.CloudWatch.html#enable_insight_rules/3","title":"AWS.CloudWatch.enable_insight_rules/3","type":"function","doc":"Enables the specified Contributor Insights rules. When rules are enabled, they immediately begin analyzing log data."},{"ref":"AWS.CloudWatch.html#get_dashboard/3","title":"AWS.CloudWatch.get_dashboard/3","type":"function","doc":"Displays the details of the dashboard that you specify. To copy an existing dashboard, use GetDashboard, and then use the data returned within DashboardBody as the template for the new dashboard when you call PutDashboard to create the copy."},{"ref":"AWS.CloudWatch.html#get_insight_rule_report/3","title":"AWS.CloudWatch.get_insight_rule_report/3","type":"function","doc":"This operation returns the time series data collected by a Contributor Insights rule. The data includes the identity and number of contributors to the log group. You can also optionally return one or more statistics about each data point in the time series. These statistics can include the following: UniqueContributors -- the number of unique contributors for each data point. MaxContributorValue -- the value of the top contributor for each data point. The identity of the contributor might change for each data point in the graph. If this rule aggregates by COUNT, the top contributor for each data point is the contributor with the most occurrences in that period. If the rule aggregates by SUM, the top contributor is the contributor with the highest sum in the log field specified by the rule&#39;s Value, during that period. SampleCount -- the number of data points matched by the rule. Sum -- the sum of the values from all contributors during the time period represented by that data point. Minimum -- the minimum value from a single observation during the time period represented by that data point. Maximum -- the maximum value from a single observation during the time period represented by that data point. Average -- the average value from all contributors during the time period represented by that data point."},{"ref":"AWS.CloudWatch.html#get_metric_data/3","title":"AWS.CloudWatch.get_metric_data/3","type":"function","doc":"You can use the GetMetricData API to retrieve as many as 500 different metrics in a single request, with a total of as many as 100,800 data points. You can also optionally perform math expressions on the values of the returned statistics, to create new time series that represent new insights into your data. For example, using Lambda metrics, you could divide the Errors metric by the Invocations metric to get an error rate time series. For more information about metric math expressions, see Metric Math Syntax and Functions in the Amazon CloudWatch User Guide. Calls to the GetMetricData API have a different pricing structure than calls to GetMetricStatistics. For more information about pricing, see Amazon CloudWatch Pricing. Amazon CloudWatch retains metric data as follows: Data points with a period of less than 60 seconds are available for 3 hours. These data points are high-resolution metrics and are available only for custom metrics that have been defined with a StorageResolution of 1. Data points with a period of 60 seconds (1-minute) are available for 15 days. Data points with a period of 300 seconds (5-minute) are available for 63 days. Data points with a period of 3600 seconds (1 hour) are available for 455 days (15 months). Data points that are initially published with a shorter period are aggregated together for long-term storage. For example, if you collect data using a period of 1 minute, the data remains available for 15 days with 1-minute resolution. After 15 days, this data is still available, but is aggregated and retrievable only with a resolution of 5 minutes. After 63 days, the data is further aggregated and is available with a resolution of 1 hour. If you omit Unit in your request, all data that was collected with any unit is returned, along with the corresponding units that were specified when the data was reported to CloudWatch. If you specify a unit, the operation returns only data that was collected with that unit specified. If you specify a unit that does not match the data collected, the results of the operation are null. CloudWatch does not perform unit conversions."},{"ref":"AWS.CloudWatch.html#get_metric_statistics/3","title":"AWS.CloudWatch.get_metric_statistics/3","type":"function","doc":"Gets statistics for the specified metric. The maximum number of data points returned from a single call is 1,440. If you request more than 1,440 data points, CloudWatch returns an error. To reduce the number of data points, you can narrow the specified time range and make multiple requests across adjacent time ranges, or you can increase the specified period. Data points are not returned in chronological order. CloudWatch aggregates data points based on the length of the period that you specify. For example, if you request statistics with a one-hour period, CloudWatch aggregates all data points with time stamps that fall within each one-hour period. Therefore, the number of values aggregated by CloudWatch is larger than the number of data points returned. CloudWatch needs raw data points to calculate percentile statistics. If you publish data using a statistic set instead, you can only retrieve percentile statistics for this data if one of the following conditions is true: The SampleCount value of the statistic set is 1. The Min and the Max values of the statistic set are equal. Percentile statistics are not available for metrics when any of the metric values are negative numbers. Amazon CloudWatch retains metric data as follows: Data points with a period of less than 60 seconds are available for 3 hours. These data points are high-resolution metrics and are available only for custom metrics that have been defined with a StorageResolution of 1. Data points with a period of 60 seconds (1-minute) are available for 15 days. Data points with a period of 300 seconds (5-minute) are available for 63 days. Data points with a period of 3600 seconds (1 hour) are available for 455 days (15 months). Data points that are initially published with a shorter period are aggregated together for long-term storage. For example, if you collect data using a period of 1 minute, the data remains available for 15 days with 1-minute resolution. After 15 days, this data is still available, but is aggregated and retrievable only with a resolution of 5 minutes. After 63 days, the data is further aggregated and is available with a resolution of 1 hour. CloudWatch started retaining 5-minute and 1-hour metric data as of July 9, 2016. For information about metrics and dimensions supported by AWS services, see the Amazon CloudWatch Metrics and Dimensions Reference in the Amazon CloudWatch User Guide."},{"ref":"AWS.CloudWatch.html#get_metric_widget_image/3","title":"AWS.CloudWatch.get_metric_widget_image/3","type":"function","doc":"You can use the GetMetricWidgetImage API to retrieve a snapshot graph of one or more Amazon CloudWatch metrics as a bitmap image. You can then embed this image into your services and products, such as wiki pages, reports, and documents. You could also retrieve images regularly, such as every minute, and create your own custom live dashboard. The graph you retrieve can include all CloudWatch metric graph features, including metric math and horizontal and vertical annotations. There is a limit of 20 transactions per second for this API. Each GetMetricWidgetImage action has the following limits: As many as 100 metrics in the graph. Up to 100 KB uncompressed payload."},{"ref":"AWS.CloudWatch.html#list_dashboards/3","title":"AWS.CloudWatch.list_dashboards/3","type":"function","doc":"Returns a list of the dashboards for your account. If you include DashboardNamePrefix, only those dashboards with names starting with the prefix are listed. Otherwise, all dashboards in your account are listed. ListDashboards returns up to 1000 results on one page. If there are more than 1000 dashboards, you can call ListDashboards again and include the value you received for NextToken in the first call, to receive the next 1000 results."},{"ref":"AWS.CloudWatch.html#list_metrics/3","title":"AWS.CloudWatch.list_metrics/3","type":"function","doc":"List the specified metrics. You can use the returned metrics with GetMetricData or GetMetricStatistics to obtain statistical data. Up to 500 results are returned for any one call. To retrieve additional results, use the returned token with subsequent calls. After you create a metric, allow up to 15 minutes before the metric appears. You can see statistics about the metric sooner by using GetMetricData or GetMetricStatistics. ListMetrics doesn&#39;t return information about metrics if those metrics haven&#39;t reported data in the past two weeks. To retrieve those metrics, use GetMetricData or GetMetricStatistics."},{"ref":"AWS.CloudWatch.html#list_tags_for_resource/3","title":"AWS.CloudWatch.list_tags_for_resource/3","type":"function","doc":"Displays the tags associated with a CloudWatch resource. Currently, alarms and Contributor Insights rules support tagging."},{"ref":"AWS.CloudWatch.html#put_anomaly_detector/3","title":"AWS.CloudWatch.put_anomaly_detector/3","type":"function","doc":"Creates an anomaly detection model for a CloudWatch metric. You can use the model to display a band of expected normal values when the metric is graphed. For more information, see CloudWatch Anomaly Detection."},{"ref":"AWS.CloudWatch.html#put_composite_alarm/3","title":"AWS.CloudWatch.put_composite_alarm/3","type":"function","doc":"Creates or updates a composite alarm. When you create a composite alarm, you specify a rule expression for the alarm that takes into account the alarm states of other alarms that you have created. The composite alarm goes into ALARM state only if all conditions of the rule are met. The alarms specified in a composite alarm&#39;s rule expression can include metric alarms and other composite alarms. Using composite alarms can reduce alarm noise. You can create multiple metric alarms, and also create a composite alarm and set up alerts only for the composite alarm. For example, you could create a composite alarm that goes into ALARM state only when more than one of the underlying metric alarms are in ALARM state. Currently, the only alarm actions that can be taken by composite alarms are notifying SNS topics. It is possible to create a loop or cycle of composite alarms, where composite alarm A depends on composite alarm B, and composite alarm B also depends on composite alarm A. In this scenario, you can&#39;t delete any composite alarm that is part of the cycle because there is always still a composite alarm that depends on that alarm that you want to delete. To get out of such a situation, you must break the cycle by changing the rule of one of the composite alarms in the cycle to remove a dependency that creates the cycle. The simplest change to make to break a cycle is to change the AlarmRule of one of the alarms to False. Additionally, the evaluation of composite alarms stops if CloudWatch detects a cycle in the evaluation path. When this operation creates an alarm, the alarm state is immediately set to INSUFFICIENT_DATA. The alarm is then evaluated and its state is set appropriately. Any actions associated with the new state are then executed. For a composite alarm, this initial time after creation is the only time that the alarm can be in INSUFFICIENT_DATA state. When you update an existing alarm, its state is left unchanged, but the update completely overwrites the previous configuration of the alarm."},{"ref":"AWS.CloudWatch.html#put_dashboard/3","title":"AWS.CloudWatch.put_dashboard/3","type":"function","doc":"Creates a dashboard if it does not already exist, or updates an existing dashboard. If you update a dashboard, the entire contents are replaced with what you specify here. All dashboards in your account are global, not region-specific. A simple way to create a dashboard using PutDashboard is to copy an existing dashboard. To copy an existing dashboard using the console, you can load the dashboard and then use the View/edit source command in the Actions menu to display the JSON block for that dashboard. Another way to copy a dashboard is to use GetDashboard, and then use the data returned within DashboardBody as the template for the new dashboard when you call PutDashboard. When you create a dashboard with PutDashboard, a good practice is to add a text widget at the top of the dashboard with a message that the dashboard was created by script and should not be changed in the console. This message could also point console users to the location of the DashboardBody script or the CloudFormation template used to create the dashboard."},{"ref":"AWS.CloudWatch.html#put_insight_rule/3","title":"AWS.CloudWatch.put_insight_rule/3","type":"function","doc":"Creates a Contributor Insights rule. Rules evaluate log events in a CloudWatch Logs log group, enabling you to find contributor data for the log events in that log group. For more information, see Using Contributor Insights to Analyze High-Cardinality Data. If you create a rule, delete it, and then re-create it with the same name, historical data from the first time the rule was created might not be available."},{"ref":"AWS.CloudWatch.html#put_metric_alarm/3","title":"AWS.CloudWatch.put_metric_alarm/3","type":"function","doc":"Creates or updates an alarm and associates it with the specified metric, metric math expression, or anomaly detection model. Alarms based on anomaly detection models cannot have Auto Scaling actions. When this operation creates an alarm, the alarm state is immediately set to INSUFFICIENT_DATA. The alarm is then evaluated and its state is set appropriately. Any actions associated with the new state are then executed. When you update an existing alarm, its state is left unchanged, but the update completely overwrites the previous configuration of the alarm. If you are an IAM user, you must have Amazon EC2 permissions for some alarm operations: iam:CreateServiceLinkedRole for all alarms with EC2 actions ec2:DescribeInstanceStatus and ec2:DescribeInstances for all alarms on EC2 instance status metrics ec2:StopInstances for alarms with stop actions ec2:TerminateInstances for alarms with terminate actions No specific permissions are needed for alarms with recover actions If you have read/write permissions for Amazon CloudWatch but not for Amazon EC2, you can still create an alarm, but the stop or terminate actions are not performed. However, if you are later granted the required permissions, the alarm actions that you created earlier are performed. If you are using an IAM role (for example, an EC2 instance profile), you cannot stop or terminate the instance using alarm actions. However, you can still see the alarm state and perform any other actions such as Amazon SNS notifications or Auto Scaling policies. If you are using temporary security credentials granted using AWS STS, you cannot stop or terminate an EC2 instance using alarm actions. The first time you create an alarm in the AWS Management Console, the CLI, or by using the PutMetricAlarm API, CloudWatch creates the necessary service-linked role for you. The service-linked role is called AWSServiceRoleForCloudWatchEvents. For more information, see AWS service-linked role."},{"ref":"AWS.CloudWatch.html#put_metric_data/3","title":"AWS.CloudWatch.put_metric_data/3","type":"function","doc":"Publishes metric data points to Amazon CloudWatch. CloudWatch associates the data points with the specified metric. If the specified metric does not exist, CloudWatch creates the metric. When CloudWatch creates a metric, it can take up to fifteen minutes for the metric to appear in calls to ListMetrics. You can publish either individual data points in the Value field, or arrays of values and the number of times each value occurred during the period by using the Values and Counts fields in the MetricDatum structure. Using the Values and Counts method enables you to publish up to 150 values per metric with one PutMetricData request, and supports retrieving percentile statistics on this data. Each PutMetricData request is limited to 40 KB in size for HTTP POST requests. You can send a payload compressed by gzip. Each request is also limited to no more than 20 different metrics. Although the Value parameter accepts numbers of type Double, CloudWatch rejects values that are either too small or too large. Values must be in the range of -2^360 to 2^360. In addition, special values (for example, NaN, +Infinity, -Infinity) are not supported. You can use up to 10 dimensions per metric to further clarify what data the metric collects. Each dimension consists of a Name and Value pair. For more information about specifying dimensions, see Publishing Metrics in the Amazon CloudWatch User Guide. Data points with time stamps from 24 hours ago or longer can take at least 48 hours to become available for GetMetricData or GetMetricStatistics from the time they are submitted. Data points with time stamps between 3 and 24 hours ago can take as much as 2 hours to become available for for GetMetricData or GetMetricStatistics. CloudWatch needs raw data points to calculate percentile statistics. If you publish data using a statistic set instead, you can only retrieve percentile statistics for this data if one of the following conditions is true: The SampleCount value of the statistic set is 1 and Min, Max, and Sum are all equal. The Min and Max are equal, and Sum is equal to Min multiplied by SampleCount."},{"ref":"AWS.CloudWatch.html#set_alarm_state/3","title":"AWS.CloudWatch.set_alarm_state/3","type":"function","doc":"Temporarily sets the state of an alarm for testing purposes. When the updated state differs from the previous value, the action configured for the appropriate state is invoked. For example, if your alarm is configured to send an Amazon SNS message when an alarm is triggered, temporarily changing the alarm state to ALARM sends an SNS message. Metric alarms returns to their actual state quickly, often within seconds. Because the metric alarm state change happens quickly, it is typically only visible in the alarm&#39;s History tab in the Amazon CloudWatch console or through DescribeAlarmHistory. If you use SetAlarmState on a composite alarm, the composite alarm is not guaranteed to return to its actual state. It returns to its actual state only once any of its children alarms change state. It is also reevaluated if you update its configuration. If an alarm triggers EC2 Auto Scaling policies or application Auto Scaling policies, you must include information in the StateReasonData parameter to enable the policy to take the correct action."},{"ref":"AWS.CloudWatch.html#tag_resource/3","title":"AWS.CloudWatch.tag_resource/3","type":"function","doc":"Assigns one or more tags (key-value pairs) to the specified CloudWatch resource. Currently, the only CloudWatch resources that can be tagged are alarms and Contributor Insights rules. Tags can help you organize and categorize your resources. You can also use them to scope user permissions by granting a user permission to access or change only resources with certain tag values. Tags don&#39;t have any semantic meaning to AWS and are interpreted strictly as strings of characters. You can use the TagResource action with an alarm that already has tags. If you specify a new tag key for the alarm, this tag is appended to the list of tags associated with the alarm. If you specify a tag key that is already associated with the alarm, the new tag value that you specify replaces the previous value for that tag. You can associate as many as 50 tags with a CloudWatch resource."},{"ref":"AWS.CloudWatch.html#untag_resource/3","title":"AWS.CloudWatch.untag_resource/3","type":"function","doc":"Removes one or more tags from the specified resource."},{"ref":"AWS.CloudWatchEvents.html","title":"AWS.CloudWatchEvents","type":"module","doc":"Amazon EventBridge helps you to respond to state changes in your AWS resources. When your resources change state, they automatically send events into an event stream. You can create rules that match selected events in the stream and route them to targets to take action. You can also use rules to take action on a predetermined schedule. For example, you can configure rules to: Automatically invoke an AWS Lambda function to update DNS entries when an event notifies you that Amazon EC2 instance enters the running state. Direct specific API records from AWS CloudTrail to an Amazon Kinesis data stream for detailed analysis of potential security or availability risks. Periodically invoke a built-in target to create a snapshot of an Amazon EBS volume. For more information about the features of Amazon EventBridge, see the Amazon EventBridge User Guide."},{"ref":"AWS.CloudWatchEvents.html#activate_event_source/3","title":"AWS.CloudWatchEvents.activate_event_source/3","type":"function","doc":"Activates a partner event source that has been deactivated. Once activated, your matching event bus will start receiving events from the event source."},{"ref":"AWS.CloudWatchEvents.html#create_event_bus/3","title":"AWS.CloudWatchEvents.create_event_bus/3","type":"function","doc":"Creates a new event bus within your account. This can be a custom event bus which you can use to receive events from your custom applications and services, or it can be a partner event bus which can be matched to a partner event source."},{"ref":"AWS.CloudWatchEvents.html#create_partner_event_source/3","title":"AWS.CloudWatchEvents.create_partner_event_source/3","type":"function","doc":"Called by an SaaS partner to create a partner event source. This operation is not used by AWS customers. Each partner event source can be used by one AWS account to create a matching partner event bus in that AWS account. A SaaS partner must create one partner event source for each AWS account that wants to receive those event types. A partner event source creates events based on resources within the SaaS partner&#39;s service or application. An AWS account that creates a partner event bus that matches the partner event source can use that event bus to receive events from the partner, and then process them using AWS Events rules and targets. Partner event source names follow this format: *partner_name*/*event_namespace*/*event_name* partner_name is determined during partner registration and identifies the partner to AWS customers. event_namespace is determined by the partner and is a way for the partner to categorize their events. event_name is determined by the partner, and should uniquely identify an event-generating resource within the partner system. The combination of event_namespace and event_name should help AWS customers decide whether to create an event bus to receive these events."},{"ref":"AWS.CloudWatchEvents.html#deactivate_event_source/3","title":"AWS.CloudWatchEvents.deactivate_event_source/3","type":"function","doc":"You can use this operation to temporarily stop receiving events from the specified partner event source. The matching event bus is not deleted. When you deactivate a partner event source, the source goes into PENDING state. If it remains in PENDING state for more than two weeks, it is deleted. To activate a deactivated partner event source, use ActivateEventSource."},{"ref":"AWS.CloudWatchEvents.html#delete_event_bus/3","title":"AWS.CloudWatchEvents.delete_event_bus/3","type":"function","doc":"Deletes the specified custom event bus or partner event bus. All rules associated with this event bus need to be deleted. You can&#39;t delete your account&#39;s default event bus."},{"ref":"AWS.CloudWatchEvents.html#delete_partner_event_source/3","title":"AWS.CloudWatchEvents.delete_partner_event_source/3","type":"function","doc":"This operation is used by SaaS partners to delete a partner event source. This operation is not used by AWS customers. When you delete an event source, the status of the corresponding partner event bus in the AWS customer account becomes DELETED."},{"ref":"AWS.CloudWatchEvents.html#delete_rule/3","title":"AWS.CloudWatchEvents.delete_rule/3","type":"function","doc":"Deletes the specified rule. Before you can delete the rule, you must remove all targets, using RemoveTargets. When you delete a rule, incoming events might continue to match to the deleted rule. Allow a short period of time for changes to take effect. Managed rules are rules created and managed by another AWS service on your behalf. These rules are created by those other AWS services to support functionality in those services. You can delete these rules using the Force option, but you should do so only if you are sure the other service is not still using that rule."},{"ref":"AWS.CloudWatchEvents.html#describe_event_bus/3","title":"AWS.CloudWatchEvents.describe_event_bus/3","type":"function","doc":"Displays details about an event bus in your account. This can include the external AWS accounts that are permitted to write events to your default event bus, and the associated policy. For custom event buses and partner event buses, it displays the name, ARN, policy, state, and creation time. To enable your account to receive events from other accounts on its default event bus, use PutPermission. For more information about partner event buses, see CreateEventBus."},{"ref":"AWS.CloudWatchEvents.html#describe_event_source/3","title":"AWS.CloudWatchEvents.describe_event_source/3","type":"function","doc":"This operation lists details about a partner event source that is shared with your account."},{"ref":"AWS.CloudWatchEvents.html#describe_partner_event_source/3","title":"AWS.CloudWatchEvents.describe_partner_event_source/3","type":"function","doc":"An SaaS partner can use this operation to list details about a partner event source that they have created. AWS customers do not use this operation. Instead, AWS customers can use DescribeEventSource to see details about a partner event source that is shared with them."},{"ref":"AWS.CloudWatchEvents.html#describe_rule/3","title":"AWS.CloudWatchEvents.describe_rule/3","type":"function","doc":"Describes the specified rule. DescribeRule does not list the targets of a rule. To see the targets associated with a rule, use ListTargetsByRule."},{"ref":"AWS.CloudWatchEvents.html#disable_rule/3","title":"AWS.CloudWatchEvents.disable_rule/3","type":"function","doc":"Disables the specified rule. A disabled rule won&#39;t match any events, and won&#39;t self-trigger if it has a schedule expression. When you disable a rule, incoming events might continue to match to the disabled rule. Allow a short period of time for changes to take effect."},{"ref":"AWS.CloudWatchEvents.html#enable_rule/3","title":"AWS.CloudWatchEvents.enable_rule/3","type":"function","doc":"Enables the specified rule. If the rule does not exist, the operation fails. When you enable a rule, incoming events might not immediately start matching to a newly enabled rule. Allow a short period of time for changes to take effect."},{"ref":"AWS.CloudWatchEvents.html#list_event_buses/3","title":"AWS.CloudWatchEvents.list_event_buses/3","type":"function","doc":"Lists all the event buses in your account, including the default event bus, custom event buses, and partner event buses."},{"ref":"AWS.CloudWatchEvents.html#list_event_sources/3","title":"AWS.CloudWatchEvents.list_event_sources/3","type":"function","doc":"You can use this to see all the partner event sources that have been shared with your AWS account. For more information about partner event sources, see CreateEventBus."},{"ref":"AWS.CloudWatchEvents.html#list_partner_event_source_accounts/3","title":"AWS.CloudWatchEvents.list_partner_event_source_accounts/3","type":"function","doc":"An SaaS partner can use this operation to display the AWS account ID that a particular partner event source name is associated with. This operation is not used by AWS customers."},{"ref":"AWS.CloudWatchEvents.html#list_partner_event_sources/3","title":"AWS.CloudWatchEvents.list_partner_event_sources/3","type":"function","doc":"An SaaS partner can use this operation to list all the partner event source names that they have created. This operation is not used by AWS customers."},{"ref":"AWS.CloudWatchEvents.html#list_rule_names_by_target/3","title":"AWS.CloudWatchEvents.list_rule_names_by_target/3","type":"function","doc":"Lists the rules for the specified target. You can see which of the rules in Amazon EventBridge can invoke a specific target in your account."},{"ref":"AWS.CloudWatchEvents.html#list_rules/3","title":"AWS.CloudWatchEvents.list_rules/3","type":"function","doc":"Lists your Amazon EventBridge rules. You can either list all the rules or you can provide a prefix to match to the rule names. ListRules does not list the targets of a rule. To see the targets associated with a rule, use ListTargetsByRule."},{"ref":"AWS.CloudWatchEvents.html#list_tags_for_resource/3","title":"AWS.CloudWatchEvents.list_tags_for_resource/3","type":"function","doc":"Displays the tags associated with an EventBridge resource. In EventBridge, rules and event buses can be tagged."},{"ref":"AWS.CloudWatchEvents.html#list_targets_by_rule/3","title":"AWS.CloudWatchEvents.list_targets_by_rule/3","type":"function","doc":"Lists the targets assigned to the specified rule."},{"ref":"AWS.CloudWatchEvents.html#put_events/3","title":"AWS.CloudWatchEvents.put_events/3","type":"function","doc":"Sends custom events to Amazon EventBridge so that they can be matched to rules."},{"ref":"AWS.CloudWatchEvents.html#put_partner_events/3","title":"AWS.CloudWatchEvents.put_partner_events/3","type":"function","doc":"This is used by SaaS partners to write events to a customer&#39;s partner event bus. AWS customers do not use this operation."},{"ref":"AWS.CloudWatchEvents.html#put_permission/3","title":"AWS.CloudWatchEvents.put_permission/3","type":"function","doc":"Running PutPermission permits the specified AWS account or AWS organization to put events to the specified event bus. Amazon EventBridge (CloudWatch Events) rules in your account are triggered by these events arriving to an event bus in your account. For another account to send events to your account, that external account must have an EventBridge rule with your account&#39;s event bus as a target. To enable multiple AWS accounts to put events to your event bus, run PutPermission once for each of these accounts. Or, if all the accounts are members of the same AWS organization, you can run PutPermission once specifying Principal as &quot;*&quot; and specifying the AWS organization ID in Condition, to grant permissions to all accounts in that organization. If you grant permissions using an organization, then accounts in that organization must specify a RoleArn with proper permissions when they use PutTarget to add your account&#39;s event bus as a target. For more information, see Sending and Receiving Events Between AWS Accounts in the Amazon EventBridge User Guide. The permission policy on the default event bus cannot exceed 10 KB in size."},{"ref":"AWS.CloudWatchEvents.html#put_rule/3","title":"AWS.CloudWatchEvents.put_rule/3","type":"function","doc":"Creates or updates the specified rule. Rules are enabled by default, or based on value of the state. You can disable a rule using DisableRule. A single rule watches for events from a single event bus. Events generated by AWS services go to your account&#39;s default event bus. Events generated by SaaS partner services or applications go to the matching partner event bus. If you have custom applications or services, you can specify whether their events go to your default event bus or a custom event bus that you have created. For more information, see CreateEventBus. If you are updating an existing rule, the rule is replaced with what you specify in this PutRule command. If you omit arguments in PutRule, the old values for those arguments are not kept. Instead, they are replaced with null values. When you create or update a rule, incoming events might not immediately start matching to new or updated rules. Allow a short period of time for changes to take effect. A rule must contain at least an EventPattern or ScheduleExpression. Rules with EventPatterns are triggered when a matching event is observed. Rules with ScheduleExpressions self-trigger based on the given schedule. A rule can have both an EventPattern and a ScheduleExpression, in which case the rule triggers on matching events as well as on a schedule. When you initially create a rule, you can optionally assign one or more tags to the rule. Tags can help you organize and categorize your resources. You can also use them to scope user permissions, by granting a user permission to access or change only rules with certain tag values. To use the PutRule operation and assign tags, you must have both the events:PutRule and events:TagResource permissions. If you are updating an existing rule, any tags you specify in the PutRule operation are ignored. To update the tags of an existing rule, use TagResource and UntagResource. Most services in AWS treat : or / as the same character in Amazon Resource Names (ARNs). However, EventBridge uses an exact match in event patterns and rules. Be sure to use the correct ARN characters when creating event patterns so that they match the ARN syntax in the event you want to match. In EventBridge, it is possible to create rules that lead to infinite loops, where a rule is fired repeatedly. For example, a rule might detect that ACLs have changed on an S3 bucket, and trigger software to change them to the desired state. If the rule is not written carefully, the subsequent change to the ACLs fires the rule again, creating an infinite loop. To prevent this, write the rules so that the triggered actions do not re-fire the same rule. For example, your rule could fire only if ACLs are found to be in a bad state, instead of after any change. An infinite loop can quickly cause higher than expected charges. We recommend that you use budgeting, which alerts you when charges exceed your specified limit. For more information, see Managing Your Costs with Budgets."},{"ref":"AWS.CloudWatchEvents.html#put_targets/3","title":"AWS.CloudWatchEvents.put_targets/3","type":"function","doc":"Adds the specified targets to the specified rule, or updates the targets if they are already associated with the rule. Targets are the resources that are invoked when a rule is triggered. You can configure the following as targets for Events: EC2 instances SSM Run Command SSM Automation AWS Lambda functions Data streams in Amazon Kinesis Data Streams Data delivery streams in Amazon Kinesis Data Firehose Amazon ECS tasks AWS Step Functions state machines AWS Batch jobs AWS CodeBuild projects Pipelines in AWS CodePipeline Amazon Inspector assessment templates Amazon SNS topics Amazon SQS queues, including FIFO queues The default event bus of another AWS account Amazon API Gateway REST APIs Redshift Clusters to invoke Data API ExecuteStatement on Creating rules with built-in targets is supported only in the AWS Management Console. The built-in targets are EC2 CreateSnapshot API call, EC2 RebootInstances API call, EC2 StopInstances API call, and EC2 TerminateInstances API call. For some target types, PutTargets provides target-specific parameters. If the target is a Kinesis data stream, you can optionally specify which shard the event goes to by using the KinesisParameters argument. To invoke a command on multiple EC2 instances with one rule, you can use the RunCommandParameters field. To be able to make API calls against the resources that you own, Amazon EventBridge (CloudWatch Events) needs the appropriate permissions. For AWS Lambda and Amazon SNS resources, EventBridge relies on resource-based policies. For EC2 instances, Kinesis data streams, AWS Step Functions state machines and API Gateway REST APIs, EventBridge relies on IAM roles that you specify in the RoleARN argument in PutTargets. For more information, see Authentication and Access Control in the Amazon EventBridge User Guide. If another AWS account is in the same region and has granted you permission (using PutPermission), you can send events to that account. Set that account&#39;s event bus as a target of the rules in your account. To send the matched events to the other account, specify that account&#39;s event bus as the Arn value when you run PutTargets. If your account sends events to another account, your account is charged for each sent event. Each event sent to another account is charged as a custom event. The account receiving the event is not charged. For more information, see Amazon EventBridge (CloudWatch Events) Pricing. Input, InputPath, and InputTransformer are not available with PutTarget if the target is an event bus of a different AWS account. If you are setting the event bus of another account as the target, and that account granted permission to your account through an organization instead of directly by the account ID, then you must specify a RoleArn with proper permissions in the Target structure. For more information, see Sending and Receiving Events Between AWS Accounts in the Amazon EventBridge User Guide. For more information about enabling cross-account events, see PutPermission. Input, InputPath, and InputTransformer are mutually exclusive and optional parameters of a target. When a rule is triggered due to a matched event: If none of the following arguments are specified for a target, then the entire event is passed to the target in JSON format (unless the target is Amazon EC2 Run Command or Amazon ECS task, in which case nothing from the event is passed to the target). If Input is specified in the form of valid JSON, then the matched event is overridden with this constant. If InputPath is specified in the form of JSONPath (for example, $.detail), then only the part of the event specified in the path is passed to the target (for example, only the detail part of the event is passed). If InputTransformer is specified, then one or more specified JSONPaths are extracted from the event and used as values in a template that you specify as the input to the target. When you specify InputPath or InputTransformer, you must use JSON dot notation, not bracket notation. When you add targets to a rule and the associated rule triggers soon after, new or updated targets might not be immediately invoked. Allow a short period of time for changes to take effect. This action can partially fail if too many requests are made at the same time. If that happens, FailedEntryCount is non-zero in the response and each entry in FailedEntries provides the ID of the failed target and the error code."},{"ref":"AWS.CloudWatchEvents.html#remove_permission/3","title":"AWS.CloudWatchEvents.remove_permission/3","type":"function","doc":"Revokes the permission of another AWS account to be able to put events to the specified event bus. Specify the account to revoke by the StatementId value that you associated with the account when you granted it permission with PutPermission. You can find the StatementId by using DescribeEventBus."},{"ref":"AWS.CloudWatchEvents.html#remove_targets/3","title":"AWS.CloudWatchEvents.remove_targets/3","type":"function","doc":"Removes the specified targets from the specified rule. When the rule is triggered, those targets are no longer be invoked. When you remove a target, when the associated rule triggers, removed targets might continue to be invoked. Allow a short period of time for changes to take effect. This action can partially fail if too many requests are made at the same time. If that happens, FailedEntryCount is non-zero in the response and each entry in FailedEntries provides the ID of the failed target and the error code."},{"ref":"AWS.CloudWatchEvents.html#tag_resource/3","title":"AWS.CloudWatchEvents.tag_resource/3","type":"function","doc":"Assigns one or more tags (key-value pairs) to the specified EventBridge resource. Tags can help you organize and categorize your resources. You can also use them to scope user permissions by granting a user permission to access or change only resources with certain tag values. In EventBridge, rules and event buses can be tagged. Tags don&#39;t have any semantic meaning to AWS and are interpreted strictly as strings of characters. You can use the TagResource action with a resource that already has tags. If you specify a new tag key, this tag is appended to the list of tags associated with the resource. If you specify a tag key that is already associated with the resource, the new tag value that you specify replaces the previous value for that tag. You can associate as many as 50 tags with a resource."},{"ref":"AWS.CloudWatchEvents.html#test_event_pattern/3","title":"AWS.CloudWatchEvents.test_event_pattern/3","type":"function","doc":"Tests whether the specified event pattern matches the provided event. Most services in AWS treat : or / as the same character in Amazon Resource Names (ARNs). However, EventBridge uses an exact match in event patterns and rules. Be sure to use the correct ARN characters when creating event patterns so that they match the ARN syntax in the event you want to match."},{"ref":"AWS.CloudWatchEvents.html#untag_resource/3","title":"AWS.CloudWatchEvents.untag_resource/3","type":"function","doc":"Removes one or more tags from the specified EventBridge resource. In Amazon EventBridge (CloudWatch Events, rules and event buses can be tagged."},{"ref":"AWS.CloudWatchLogs.html","title":"AWS.CloudWatchLogs","type":"module","doc":"You can use Amazon CloudWatch Logs to monitor, store, and access your log files from EC2 instances, AWS CloudTrail, or other sources. You can then retrieve the associated log data from CloudWatch Logs using the CloudWatch console, CloudWatch Logs commands in the AWS CLI, CloudWatch Logs API, or CloudWatch Logs SDK. You can use CloudWatch Logs to: Monitor logs from EC2 instances in real-time: You can use CloudWatch Logs to monitor applications and systems using log data. For example, CloudWatch Logs can track the number of errors that occur in your application logs and send you a notification whenever the rate of errors exceeds a threshold that you specify. CloudWatch Logs uses your log data for monitoring so no code changes are required. For example, you can monitor application logs for specific literal terms (such as &quot;NullReferenceException&quot;) or count the number of occurrences of a literal term at a particular position in log data (such as &quot;404&quot; status codes in an Apache access log). When the term you are searching for is found, CloudWatch Logs reports the data to a CloudWatch metric that you specify. Monitor AWS CloudTrail logged events: You can create alarms in CloudWatch and receive notifications of particular API activity as captured by CloudTrail. You can use the notification to perform troubleshooting. Archive log data: You can use CloudWatch Logs to store your log data in highly durable storage. You can change the log retention setting so that any log events older than this setting are automatically deleted. The CloudWatch Logs agent makes it easy to quickly send both rotated and non-rotated log data off of a host and into the log service. You can then access the raw log data when you need it."},{"ref":"AWS.CloudWatchLogs.html#associate_kms_key/3","title":"AWS.CloudWatchLogs.associate_kms_key/3","type":"function","doc":"Associates the specified AWS Key Management Service (AWS KMS) customer master key (CMK) with the specified log group. Associating an AWS KMS CMK with a log group overrides any existing associations between the log group and a CMK. After a CMK is associated with a log group, all newly ingested data for the log group is encrypted using the CMK. This association is stored as long as the data encrypted with the CMK is still within Amazon CloudWatch Logs. This enables Amazon CloudWatch Logs to decrypt this data whenever it is requested. CloudWatch Logs supports only symmetric CMKs. Do not use an associate an asymmetric CMK with your log group. For more information, see Using Symmetric and Asymmetric Keys. It can take up to 5 minutes for this operation to take effect. If you attempt to associate a CMK with a log group but the CMK does not exist or the CMK is disabled, you receive an InvalidParameterException error."},{"ref":"AWS.CloudWatchLogs.html#cancel_export_task/3","title":"AWS.CloudWatchLogs.cancel_export_task/3","type":"function","doc":"Cancels the specified export task. The task must be in the PENDING or RUNNING state."},{"ref":"AWS.CloudWatchLogs.html#create_export_task/3","title":"AWS.CloudWatchLogs.create_export_task/3","type":"function","doc":"Creates an export task, which allows you to efficiently export data from a log group to an Amazon S3 bucket. When you perform a CreateExportTask operation, you must use credentials that have permission to write to the S3 bucket that you specify as the destination. This is an asynchronous call. If all the required information is provided, this operation initiates an export task and responds with the ID of the task. After the task has started, you can use DescribeExportTasks to get the status of the export task. Each account can only have one active (RUNNING or PENDING) export task at a time. To cancel an export task, use CancelExportTask. You can export logs from multiple log groups or multiple time ranges to the same S3 bucket. To separate out log data for each export task, you can specify a prefix to be used as the Amazon S3 key prefix for all exported objects. Exporting to S3 buckets that are encrypted with AES-256 is supported. Exporting to S3 buckets encrypted with SSE-KMS is not supported."},{"ref":"AWS.CloudWatchLogs.html#create_log_group/3","title":"AWS.CloudWatchLogs.create_log_group/3","type":"function","doc":"Creates a log group with the specified name. You can create up to 20,000 log groups per account. You must use the following guidelines when naming a log group: Log group names must be unique within a region for an AWS account. Log group names can be between 1 and 512 characters long. Log group names consist of the following characters: a-z, A-Z, 0-9, &#39;_&#39; (underscore), &#39;-&#39; (hyphen), &#39;/&#39; (forward slash), &#39;.&#39; (period), and &#39;#&#39; (number sign) When you create a log group, by default the log events in the log group never expire. To set a retention policy so that events expire and are deleted after a specified time, use PutRetentionPolicy. If you associate a AWS Key Management Service (AWS KMS) customer master key (CMK) with the log group, ingested data is encrypted using the CMK. This association is stored as long as the data encrypted with the CMK is still within Amazon CloudWatch Logs. This enables Amazon CloudWatch Logs to decrypt this data whenever it is requested. If you attempt to associate a CMK with the log group but the CMK does not exist or the CMK is disabled, you receive an InvalidParameterException error. CloudWatch Logs supports only symmetric CMKs. Do not associate an asymmetric CMK with your log group. For more information, see Using Symmetric and Asymmetric Keys."},{"ref":"AWS.CloudWatchLogs.html#create_log_stream/3","title":"AWS.CloudWatchLogs.create_log_stream/3","type":"function","doc":"Creates a log stream for the specified log group. A log stream is a sequence of log events that originate from a single source, such as an application instance or a resource that is being monitored. There is no limit on the number of log streams that you can create for a log group. There is a limit of 50 TPS on CreateLogStream operations, after which transactions are throttled. You must use the following guidelines when naming a log stream: Log stream names must be unique within the log group. Log stream names can be between 1 and 512 characters long. The &#39;:&#39; (colon) and &#39;*&#39; (asterisk) characters are not allowed."},{"ref":"AWS.CloudWatchLogs.html#delete_destination/3","title":"AWS.CloudWatchLogs.delete_destination/3","type":"function","doc":"Deletes the specified destination, and eventually disables all the subscription filters that publish to it. This operation does not delete the physical resource encapsulated by the destination."},{"ref":"AWS.CloudWatchLogs.html#delete_log_group/3","title":"AWS.CloudWatchLogs.delete_log_group/3","type":"function","doc":"Deletes the specified log group and permanently deletes all the archived log events associated with the log group."},{"ref":"AWS.CloudWatchLogs.html#delete_log_stream/3","title":"AWS.CloudWatchLogs.delete_log_stream/3","type":"function","doc":"Deletes the specified log stream and permanently deletes all the archived log events associated with the log stream."},{"ref":"AWS.CloudWatchLogs.html#delete_metric_filter/3","title":"AWS.CloudWatchLogs.delete_metric_filter/3","type":"function","doc":"Deletes the specified metric filter."},{"ref":"AWS.CloudWatchLogs.html#delete_query_definition/3","title":"AWS.CloudWatchLogs.delete_query_definition/3","type":"function","doc":"Deletes a saved CloudWatch Logs Insights query definition. A query definition contains details about a saved CloudWatch Logs Insights query. Each DeleteQueryDefinition operation can delete one query definition. You must have the logs:DeleteQueryDefinition permission to be able to perform this operation."},{"ref":"AWS.CloudWatchLogs.html#delete_resource_policy/3","title":"AWS.CloudWatchLogs.delete_resource_policy/3","type":"function","doc":"Deletes a resource policy from this account. This revokes the access of the identities in that policy to put log events to this account."},{"ref":"AWS.CloudWatchLogs.html#delete_retention_policy/3","title":"AWS.CloudWatchLogs.delete_retention_policy/3","type":"function","doc":"Deletes the specified retention policy. Log events do not expire if they belong to log groups without a retention policy."},{"ref":"AWS.CloudWatchLogs.html#delete_subscription_filter/3","title":"AWS.CloudWatchLogs.delete_subscription_filter/3","type":"function","doc":"Deletes the specified subscription filter."},{"ref":"AWS.CloudWatchLogs.html#describe_destinations/3","title":"AWS.CloudWatchLogs.describe_destinations/3","type":"function","doc":"Lists all your destinations. The results are ASCII-sorted by destination name."},{"ref":"AWS.CloudWatchLogs.html#describe_export_tasks/3","title":"AWS.CloudWatchLogs.describe_export_tasks/3","type":"function","doc":"Lists the specified export tasks. You can list all your export tasks or filter the results based on task ID or task status."},{"ref":"AWS.CloudWatchLogs.html#describe_log_groups/3","title":"AWS.CloudWatchLogs.describe_log_groups/3","type":"function","doc":"Lists the specified log groups. You can list all your log groups or filter the results by prefix. The results are ASCII-sorted by log group name."},{"ref":"AWS.CloudWatchLogs.html#describe_log_streams/3","title":"AWS.CloudWatchLogs.describe_log_streams/3","type":"function","doc":"Lists the log streams for the specified log group. You can list all the log streams or filter the results by prefix. You can also control how the results are ordered. This operation has a limit of five transactions per second, after which transactions are throttled."},{"ref":"AWS.CloudWatchLogs.html#describe_metric_filters/3","title":"AWS.CloudWatchLogs.describe_metric_filters/3","type":"function","doc":"Lists the specified metric filters. You can list all of the metric filters or filter the results by log name, prefix, metric name, or metric namespace. The results are ASCII-sorted by filter name."},{"ref":"AWS.CloudWatchLogs.html#describe_queries/3","title":"AWS.CloudWatchLogs.describe_queries/3","type":"function","doc":"Returns a list of CloudWatch Logs Insights queries that are scheduled, executing, or have been executed recently in this account. You can request all queries or limit it to queries of a specific log group or queries with a certain status."},{"ref":"AWS.CloudWatchLogs.html#describe_query_definitions/3","title":"AWS.CloudWatchLogs.describe_query_definitions/3","type":"function","doc":"This operation returns a paginated list of your saved CloudWatch Logs Insights query definitions. You can use the queryDefinitionNamePrefix parameter to limit the results to only the query definitions that have names that start with a certain string."},{"ref":"AWS.CloudWatchLogs.html#describe_resource_policies/3","title":"AWS.CloudWatchLogs.describe_resource_policies/3","type":"function","doc":"Lists the resource policies in this account."},{"ref":"AWS.CloudWatchLogs.html#describe_subscription_filters/3","title":"AWS.CloudWatchLogs.describe_subscription_filters/3","type":"function","doc":"Lists the subscription filters for the specified log group. You can list all the subscription filters or filter the results by prefix. The results are ASCII-sorted by filter name."},{"ref":"AWS.CloudWatchLogs.html#disassociate_kms_key/3","title":"AWS.CloudWatchLogs.disassociate_kms_key/3","type":"function","doc":"Disassociates the associated AWS Key Management Service (AWS KMS) customer master key (CMK) from the specified log group. After the AWS KMS CMK is disassociated from the log group, AWS CloudWatch Logs stops encrypting newly ingested data for the log group. All previously ingested data remains encrypted, and AWS CloudWatch Logs requires permissions for the CMK whenever the encrypted data is requested. Note that it can take up to 5 minutes for this operation to take effect."},{"ref":"AWS.CloudWatchLogs.html#filter_log_events/3","title":"AWS.CloudWatchLogs.filter_log_events/3","type":"function","doc":"Lists log events from the specified log group. You can list all the log events or filter the results using a filter pattern, a time range, and the name of the log stream. By default, this operation returns as many log events as can fit in 1 MB (up to 10,000 log events) or all the events found within the time range that you specify. If the results include a token, then there are more log events available, and you can get additional results by specifying the token in a subsequent call. This operation can return empty results while there are more log events available through the token. The returned log events are sorted by event timestamp, the timestamp when the event was ingested by CloudWatch Logs, and the ID of the PutLogEvents request."},{"ref":"AWS.CloudWatchLogs.html#get_log_events/3","title":"AWS.CloudWatchLogs.get_log_events/3","type":"function","doc":"Lists log events from the specified log stream. You can list all of the log events or filter using a time range. By default, this operation returns as many log events as can fit in a response size of 1MB (up to 10,000 log events). You can get additional log events by specifying one of the tokens in a subsequent call. This operation can return empty results while there are more log events available through the token."},{"ref":"AWS.CloudWatchLogs.html#get_log_group_fields/3","title":"AWS.CloudWatchLogs.get_log_group_fields/3","type":"function","doc":"Returns a list of the fields that are included in log events in the specified log group, along with the percentage of log events that contain each field. The search is limited to a time period that you specify. In the results, fields that start with @ are fields generated by CloudWatch Logs. For example, @timestamp is the timestamp of each log event. For more information about the fields that are generated by CloudWatch logs, see Supported Logs and Discovered Fields. The response results are sorted by the frequency percentage, starting with the highest percentage."},{"ref":"AWS.CloudWatchLogs.html#get_log_record/3","title":"AWS.CloudWatchLogs.get_log_record/3","type":"function","doc":"Retrieves all of the fields and values of a single log event. All fields are retrieved, even if the original query that produced the logRecordPointer retrieved only a subset of fields. Fields are returned as field name/field value pairs. The full unparsed log event is returned within @message."},{"ref":"AWS.CloudWatchLogs.html#get_query_results/3","title":"AWS.CloudWatchLogs.get_query_results/3","type":"function","doc":"Returns the results from the specified query. Only the fields requested in the query are returned, along with a @ptr field, which is the identifier for the log record. You can use the value of @ptr in a GetLogRecord operation to get the full log record. GetQueryResults does not start a query execution. To run a query, use StartQuery. If the value of the Status field in the output is Running, this operation returns only partial results. If you see a value of Scheduled or Running for the status, you can retry the operation later to see the final results."},{"ref":"AWS.CloudWatchLogs.html#list_tags_log_group/3","title":"AWS.CloudWatchLogs.list_tags_log_group/3","type":"function","doc":"Lists the tags for the specified log group."},{"ref":"AWS.CloudWatchLogs.html#put_destination/3","title":"AWS.CloudWatchLogs.put_destination/3","type":"function","doc":"Creates or updates a destination. This operation is used only to create destinations for cross-account subscriptions. A destination encapsulates a physical resource (such as an Amazon Kinesis stream) and enables you to subscribe to a real-time stream of log events for a different account, ingested using PutLogEvents. Through an access policy, a destination controls what is written to it. By default, PutDestination does not set any access policy with the destination, which means a cross-account user cannot call PutSubscriptionFilter against this destination. To enable this, the destination owner must call PutDestinationPolicy after PutDestination. To perform a PutDestination operation, you must also have the iam:PassRole permission."},{"ref":"AWS.CloudWatchLogs.html#put_destination_policy/3","title":"AWS.CloudWatchLogs.put_destination_policy/3","type":"function","doc":"Creates or updates an access policy associated with an existing destination. An access policy is an IAM policy document that is used to authorize claims to register a subscription filter against a given destination."},{"ref":"AWS.CloudWatchLogs.html#put_log_events/3","title":"AWS.CloudWatchLogs.put_log_events/3","type":"function","doc":"Uploads a batch of log events to the specified log stream. You must include the sequence token obtained from the response of the previous call. An upload in a newly created log stream does not require a sequence token. You can also get the sequence token in the expectedSequenceToken field from InvalidSequenceTokenException. If you call PutLogEvents twice within a narrow time period using the same value for sequenceToken, both calls might be successful or one might be rejected. The batch of events must satisfy the following constraints: The maximum batch size is 1,048,576 bytes. This size is calculated as the sum of all event messages in UTF-8, plus 26 bytes for each log event. None of the log events in the batch can be more than 2 hours in the future. None of the log events in the batch can be older than 14 days or older than the retention period of the log group. The log events in the batch must be in chronological order by their timestamp. The timestamp is the time the event occurred, expressed as the number of milliseconds after Jan 1, 1970 00:00:00 UTC. (In AWS Tools for PowerShell and the AWS SDK for .NET, the timestamp is specified in .NET format: yyyy-mm-ddThh:mm:ss. For example, 2017-09-15T13:45:30.) A batch of log events in a single request cannot span more than 24 hours. Otherwise, the operation fails. The maximum number of log events in a batch is 10,000. There is a quota of 5 requests per second per log stream. Additional requests are throttled. This quota can&#39;t be changed. If a call to PutLogEvents returns &quot;UnrecognizedClientException&quot; the most likely cause is an invalid AWS access key ID or secret key."},{"ref":"AWS.CloudWatchLogs.html#put_metric_filter/3","title":"AWS.CloudWatchLogs.put_metric_filter/3","type":"function","doc":"Creates or updates a metric filter and associates it with the specified log group. Metric filters allow you to configure rules to extract metric data from log events ingested through PutLogEvents. The maximum number of metric filters that can be associated with a log group is 100."},{"ref":"AWS.CloudWatchLogs.html#put_query_definition/3","title":"AWS.CloudWatchLogs.put_query_definition/3","type":"function","doc":"Creates or updates a query definition for CloudWatch Logs Insights. For more information, see Analyzing Log Data with CloudWatch Logs Insights. To update a query definition, specify its queryDefinitionId in your request. The values of name, queryString, and logGroupNames are changed to the values that you specify in your update operation. No current values are retained from the current query definition. For example, if you update a current query definition that includes log groups, and you don&#39;t specify the logGroupNames parameter in your update operation, the query definition changes to contain no log groups. You must have the logs:PutQueryDefinition permission to be able to perform this operation."},{"ref":"AWS.CloudWatchLogs.html#put_resource_policy/3","title":"AWS.CloudWatchLogs.put_resource_policy/3","type":"function","doc":"Creates or updates a resource policy allowing other AWS services to put log events to this account, such as Amazon Route 53. An account can have up to 10 resource policies per AWS Region."},{"ref":"AWS.CloudWatchLogs.html#put_retention_policy/3","title":"AWS.CloudWatchLogs.put_retention_policy/3","type":"function","doc":"Sets the retention of the specified log group. A retention policy allows you to configure the number of days for which to retain log events in the specified log group."},{"ref":"AWS.CloudWatchLogs.html#put_subscription_filter/3","title":"AWS.CloudWatchLogs.put_subscription_filter/3","type":"function","doc":"Creates or updates a subscription filter and associates it with the specified log group. Subscription filters allow you to subscribe to a real-time stream of log events ingested through PutLogEvents and have them delivered to a specific destination. When log events are sent to the receiving service, they are Base64 encoded and compressed with the gzip format. The following destinations are supported for subscription filters: An Amazon Kinesis stream belonging to the same account as the subscription filter, for same-account delivery. A logical destination that belongs to a different account, for cross-account delivery. An Amazon Kinesis Firehose delivery stream that belongs to the same account as the subscription filter, for same-account delivery. An AWS Lambda function that belongs to the same account as the subscription filter, for same-account delivery. There can only be one subscription filter associated with a log group. If you are updating an existing filter, you must specify the correct name in filterName. Otherwise, the call fails because you cannot associate a second filter with a log group. To perform a PutSubscriptionFilter operation, you must also have the iam:PassRole permission."},{"ref":"AWS.CloudWatchLogs.html#start_query/3","title":"AWS.CloudWatchLogs.start_query/3","type":"function","doc":"Schedules a query of a log group using CloudWatch Logs Insights. You specify the log group and time range to query and the query string to use. For more information, see CloudWatch Logs Insights Query Syntax. Queries time out after 15 minutes of execution. If your queries are timing out, reduce the time range being searched or partition your query into a number of queries."},{"ref":"AWS.CloudWatchLogs.html#stop_query/3","title":"AWS.CloudWatchLogs.stop_query/3","type":"function","doc":"Stops a CloudWatch Logs Insights query that is in progress. If the query has already ended, the operation returns an error indicating that the specified query is not running."},{"ref":"AWS.CloudWatchLogs.html#tag_log_group/3","title":"AWS.CloudWatchLogs.tag_log_group/3","type":"function","doc":"Adds or updates the specified tags for the specified log group. To list the tags for a log group, use ListTagsLogGroup. To remove tags, use UntagLogGroup. For more information about tags, see Tag Log Groups in Amazon CloudWatch Logs in the Amazon CloudWatch Logs User Guide."},{"ref":"AWS.CloudWatchLogs.html#test_metric_filter/3","title":"AWS.CloudWatchLogs.test_metric_filter/3","type":"function","doc":"Tests the filter pattern of a metric filter against a sample of log event messages. You can use this operation to validate the correctness of a metric filter pattern."},{"ref":"AWS.CloudWatchLogs.html#untag_log_group/3","title":"AWS.CloudWatchLogs.untag_log_group/3","type":"function","doc":"Removes the specified tags from the specified log group. To list the tags for a log group, use ListTagsLogGroup. To add tags, use TagLogGroup."},{"ref":"AWS.Cloudsearchdomain.html","title":"AWS.Cloudsearchdomain","type":"module","doc":"You use the AmazonCloudSearch2013 API to upload documents to a search domain and search those documents. The endpoints for submitting UploadDocuments, Search, and Suggest requests are domain-specific. To get the endpoints for your domain, use the Amazon CloudSearch configuration service DescribeDomains action. The domain endpoints are also displayed on the domain dashboard in the Amazon CloudSearch console. You submit suggest requests to the search endpoint. For more information, see the Amazon CloudSearch Developer Guide."},{"ref":"AWS.Cloudsearchdomain.html#search/16","title":"AWS.Cloudsearchdomain.search/16","type":"function","doc":"Retrieves a list of documents that match the specified search criteria. How you specify the search criteria depends on which query parser you use. Amazon CloudSearch supports four query parsers: simple: search all text and text-array fields for the specified string. Search for phrases, individual terms, and prefixes. structured: search specific fields, construct compound queries using Boolean operators, and use advanced features such as term boosting and proximity searching. lucene: specify search criteria using the Apache Lucene query parser syntax. dismax: specify search criteria using the simplified subset of the Apache Lucene query parser syntax defined by the DisMax query parser. For more information, see Searching Your Data in the Amazon CloudSearch Developer Guide. The endpoint for submitting Search requests is domain-specific. You submit search requests to a domain&#39;s search endpoint. To get the search endpoint for your domain, use the Amazon CloudSearch configuration service DescribeDomains action. A domain&#39;s endpoints are also displayed on the domain dashboard in the Amazon CloudSearch console."},{"ref":"AWS.Cloudsearchdomain.html#suggest/5","title":"AWS.Cloudsearchdomain.suggest/5","type":"function","doc":"Retrieves autocomplete suggestions for a partial query string. You can use suggestions enable you to display likely matches before users finish typing. In Amazon CloudSearch, suggestions are based on the contents of a particular text field. When you request suggestions, Amazon CloudSearch finds all of the documents whose values in the suggester field start with the specified query string. The beginning of the field must match the query string to be considered a match. For more information about configuring suggesters and retrieving suggestions, see Getting Suggestions in the Amazon CloudSearch Developer Guide. The endpoint for submitting Suggest requests is domain-specific. You submit suggest requests to a domain&#39;s search endpoint. To get the search endpoint for your domain, use the Amazon CloudSearch configuration service DescribeDomains action. A domain&#39;s endpoints are also displayed on the domain dashboard in the Amazon CloudSearch console."},{"ref":"AWS.Cloudsearchdomain.html#upload_documents/3","title":"AWS.Cloudsearchdomain.upload_documents/3","type":"function","doc":"Posts a batch of documents to a search domain for indexing. A document batch is a collection of add and delete operations that represent the documents you want to add, update, or delete from your domain. Batches can be described in either JSON or XML. Each item that you want Amazon CloudSearch to return as a search result (such as a product) is represented as a document. Every document has a unique ID and one or more fields that contain the data that you want to search and return in results. Individual documents cannot contain more than 1 MB of data. The entire batch cannot exceed 5 MB. To get the best possible upload performance, group add and delete operations in batches that are close the 5 MB limit. Submitting a large volume of single-document batches can overload a domain&#39;s document service. The endpoint for submitting UploadDocuments requests is domain-specific. To get the document endpoint for your domain, use the Amazon CloudSearch configuration service DescribeDomains action. A domain&#39;s endpoints are also displayed on the domain dashboard in the Amazon CloudSearch console. For more information about formatting your data for Amazon CloudSearch, see Preparing Your Data in the Amazon CloudSearch Developer Guide. For more information about uploading data for indexing, see Uploading Data in the Amazon CloudSearch Developer Guide."},{"ref":"AWS.CodeBuild.html","title":"AWS.CodeBuild","type":"module","doc":"AWS CodeBuild AWS CodeBuild is a fully managed build service in the cloud. AWS CodeBuild compiles your source code, runs unit tests, and produces artifacts that are ready to deploy. AWS CodeBuild eliminates the need to provision, manage, and scale your own build servers. It provides prepackaged build environments for the most popular programming languages and build tools, such as Apache Maven, Gradle, and more. You can also fully customize build environments in AWS CodeBuild to use your own build tools. AWS CodeBuild scales automatically to meet peak build requests. You pay only for the build time you consume. For more information about AWS CodeBuild, see the AWS CodeBuild User Guide. AWS CodeBuild supports these operations: BatchDeleteBuilds: Deletes one or more builds. BatchGetBuilds: Gets information about one or more builds. BatchGetProjects: Gets information about one or more build projects. A build project defines how AWS CodeBuild runs a build. This includes information such as where to get the source code to build, the build environment to use, the build commands to run, and where to store the build output. A build environment is a representation of operating system, programming language runtime, and tools that AWS CodeBuild uses to run a build. You can add tags to build projects to help manage your resources and costs. BatchGetReportGroups: Returns an array of report groups. BatchGetReports: Returns an array of reports. CreateProject: Creates a build project. CreateReportGroup: Creates a report group. A report group contains a collection of reports. CreateWebhook: For an existing AWS CodeBuild build project that has its source code stored in a GitHub or Bitbucket repository, enables AWS CodeBuild to start rebuilding the source code every time a code change is pushed to the repository. DeleteProject: Deletes a build project. DeleteReport: Deletes a report. DeleteReportGroup: Deletes a report group. DeleteResourcePolicy: Deletes a resource policy that is identified by its resource ARN. DeleteSourceCredentials: Deletes a set of GitHub, GitHub Enterprise, or Bitbucket source credentials. DeleteWebhook: For an existing AWS CodeBuild build project that has its source code stored in a GitHub or Bitbucket repository, stops AWS CodeBuild from rebuilding the source code every time a code change is pushed to the repository. DescribeTestCases: Returns a list of details about test cases for a report. GetResourcePolicy: Gets a resource policy that is identified by its resource ARN. ImportSourceCredentials: Imports the source repository credentials for an AWS CodeBuild project that has its source code stored in a GitHub, GitHub Enterprise, or Bitbucket repository. InvalidateProjectCache: Resets the cache for a project. ListBuilds: Gets a list of build IDs, with each build ID representing a single build. ListBuildsForProject: Gets a list of build IDs for the specified build project, with each build ID representing a single build. ListCuratedEnvironmentImages: Gets information about Docker images that are managed by AWS CodeBuild. ListProjects: Gets a list of build project names, with each build project name representing a single build project. ListReportGroups: Gets a list ARNs for the report groups in the current AWS account. ListReports: Gets a list ARNs for the reports in the current AWS account. ListReportsForReportGroup: Returns a list of ARNs for the reports that belong to a ReportGroup. ListSharedProjects: Gets a list of ARNs associated with projects shared with the current AWS account or user. ListSharedReportGroups: Gets a list of ARNs associated with report groups shared with the current AWS account or user ListSourceCredentials: Returns a list of SourceCredentialsInfo objects. Each SourceCredentialsInfo object includes the authentication type, token ARN, and type of source provider for one set of credentials. PutResourcePolicy: Stores a resource policy for the ARN of a Project or ReportGroup object. StartBuild: Starts running a build. StopBuild: Attempts to stop running a build. UpdateProject: Changes the settings of an existing build project. UpdateReportGroup: Changes a report group. UpdateWebhook: Changes the settings of an existing webhook."},{"ref":"AWS.CodeBuild.html#batch_delete_builds/3","title":"AWS.CodeBuild.batch_delete_builds/3","type":"function","doc":"Deletes one or more builds."},{"ref":"AWS.CodeBuild.html#batch_get_build_batches/3","title":"AWS.CodeBuild.batch_get_build_batches/3","type":"function","doc":"Retrieves information about one or more batch builds."},{"ref":"AWS.CodeBuild.html#batch_get_builds/3","title":"AWS.CodeBuild.batch_get_builds/3","type":"function","doc":"Gets information about one or more builds."},{"ref":"AWS.CodeBuild.html#batch_get_projects/3","title":"AWS.CodeBuild.batch_get_projects/3","type":"function","doc":"Gets information about one or more build projects."},{"ref":"AWS.CodeBuild.html#batch_get_report_groups/3","title":"AWS.CodeBuild.batch_get_report_groups/3","type":"function","doc":"Returns an array of report groups."},{"ref":"AWS.CodeBuild.html#batch_get_reports/3","title":"AWS.CodeBuild.batch_get_reports/3","type":"function","doc":"Returns an array of reports."},{"ref":"AWS.CodeBuild.html#create_project/3","title":"AWS.CodeBuild.create_project/3","type":"function","doc":"Creates a build project."},{"ref":"AWS.CodeBuild.html#create_report_group/3","title":"AWS.CodeBuild.create_report_group/3","type":"function","doc":"Creates a report group. A report group contains a collection of reports."},{"ref":"AWS.CodeBuild.html#create_webhook/3","title":"AWS.CodeBuild.create_webhook/3","type":"function","doc":"For an existing AWS CodeBuild build project that has its source code stored in a GitHub or Bitbucket repository, enables AWS CodeBuild to start rebuilding the source code every time a code change is pushed to the repository. If you enable webhooks for an AWS CodeBuild project, and the project is used as a build step in AWS CodePipeline, then two identical builds are created for each commit. One build is triggered through webhooks, and one through AWS CodePipeline. Because billing is on a per-build basis, you are billed for both builds. Therefore, if you are using AWS CodePipeline, we recommend that you disable webhooks in AWS CodeBuild. In the AWS CodeBuild console, clear the Webhook box. For more information, see step 5 in Change a Build Project&#39;s Settings."},{"ref":"AWS.CodeBuild.html#delete_build_batch/3","title":"AWS.CodeBuild.delete_build_batch/3","type":"function","doc":"Deletes a batch build."},{"ref":"AWS.CodeBuild.html#delete_project/3","title":"AWS.CodeBuild.delete_project/3","type":"function","doc":"Deletes a build project. When you delete a project, its builds are not deleted."},{"ref":"AWS.CodeBuild.html#delete_report/3","title":"AWS.CodeBuild.delete_report/3","type":"function","doc":"Deletes a report."},{"ref":"AWS.CodeBuild.html#delete_report_group/3","title":"AWS.CodeBuild.delete_report_group/3","type":"function","doc":"Deletes a report group. Before you delete a report group, you must delete its reports."},{"ref":"AWS.CodeBuild.html#delete_resource_policy/3","title":"AWS.CodeBuild.delete_resource_policy/3","type":"function","doc":"Deletes a resource policy that is identified by its resource ARN."},{"ref":"AWS.CodeBuild.html#delete_source_credentials/3","title":"AWS.CodeBuild.delete_source_credentials/3","type":"function","doc":"Deletes a set of GitHub, GitHub Enterprise, or Bitbucket source credentials."},{"ref":"AWS.CodeBuild.html#delete_webhook/3","title":"AWS.CodeBuild.delete_webhook/3","type":"function","doc":"For an existing AWS CodeBuild build project that has its source code stored in a GitHub or Bitbucket repository, stops AWS CodeBuild from rebuilding the source code every time a code change is pushed to the repository."},{"ref":"AWS.CodeBuild.html#describe_code_coverages/3","title":"AWS.CodeBuild.describe_code_coverages/3","type":"function","doc":"Retrieves one or more code coverage reports."},{"ref":"AWS.CodeBuild.html#describe_test_cases/3","title":"AWS.CodeBuild.describe_test_cases/3","type":"function","doc":"Returns a list of details about test cases for a report."},{"ref":"AWS.CodeBuild.html#get_resource_policy/3","title":"AWS.CodeBuild.get_resource_policy/3","type":"function","doc":"Gets a resource policy that is identified by its resource ARN."},{"ref":"AWS.CodeBuild.html#import_source_credentials/3","title":"AWS.CodeBuild.import_source_credentials/3","type":"function","doc":"Imports the source repository credentials for an AWS CodeBuild project that has its source code stored in a GitHub, GitHub Enterprise, or Bitbucket repository."},{"ref":"AWS.CodeBuild.html#invalidate_project_cache/3","title":"AWS.CodeBuild.invalidate_project_cache/3","type":"function","doc":"Resets the cache for a project."},{"ref":"AWS.CodeBuild.html#list_build_batches/3","title":"AWS.CodeBuild.list_build_batches/3","type":"function","doc":"Retrieves the identifiers of your build batches in the current region."},{"ref":"AWS.CodeBuild.html#list_build_batches_for_project/3","title":"AWS.CodeBuild.list_build_batches_for_project/3","type":"function","doc":"Retrieves the identifiers of the build batches for a specific project."},{"ref":"AWS.CodeBuild.html#list_builds/3","title":"AWS.CodeBuild.list_builds/3","type":"function","doc":"Gets a list of build IDs, with each build ID representing a single build."},{"ref":"AWS.CodeBuild.html#list_builds_for_project/3","title":"AWS.CodeBuild.list_builds_for_project/3","type":"function","doc":"Gets a list of build IDs for the specified build project, with each build ID representing a single build."},{"ref":"AWS.CodeBuild.html#list_curated_environment_images/3","title":"AWS.CodeBuild.list_curated_environment_images/3","type":"function","doc":"Gets information about Docker images that are managed by AWS CodeBuild."},{"ref":"AWS.CodeBuild.html#list_projects/3","title":"AWS.CodeBuild.list_projects/3","type":"function","doc":"Gets a list of build project names, with each build project name representing a single build project."},{"ref":"AWS.CodeBuild.html#list_report_groups/3","title":"AWS.CodeBuild.list_report_groups/3","type":"function","doc":"Gets a list ARNs for the report groups in the current AWS account."},{"ref":"AWS.CodeBuild.html#list_reports/3","title":"AWS.CodeBuild.list_reports/3","type":"function","doc":"Returns a list of ARNs for the reports in the current AWS account."},{"ref":"AWS.CodeBuild.html#list_reports_for_report_group/3","title":"AWS.CodeBuild.list_reports_for_report_group/3","type":"function","doc":"Returns a list of ARNs for the reports that belong to a ReportGroup."},{"ref":"AWS.CodeBuild.html#list_shared_projects/3","title":"AWS.CodeBuild.list_shared_projects/3","type":"function","doc":"Gets a list of projects that are shared with other AWS accounts or users."},{"ref":"AWS.CodeBuild.html#list_shared_report_groups/3","title":"AWS.CodeBuild.list_shared_report_groups/3","type":"function","doc":"Gets a list of report groups that are shared with other AWS accounts or users."},{"ref":"AWS.CodeBuild.html#list_source_credentials/3","title":"AWS.CodeBuild.list_source_credentials/3","type":"function","doc":"Returns a list of SourceCredentialsInfo objects."},{"ref":"AWS.CodeBuild.html#put_resource_policy/3","title":"AWS.CodeBuild.put_resource_policy/3","type":"function","doc":"Stores a resource policy for the ARN of a Project or ReportGroup object."},{"ref":"AWS.CodeBuild.html#retry_build/3","title":"AWS.CodeBuild.retry_build/3","type":"function","doc":"Restarts a build."},{"ref":"AWS.CodeBuild.html#retry_build_batch/3","title":"AWS.CodeBuild.retry_build_batch/3","type":"function","doc":"Restarts a batch build."},{"ref":"AWS.CodeBuild.html#start_build/3","title":"AWS.CodeBuild.start_build/3","type":"function","doc":"Starts running a build."},{"ref":"AWS.CodeBuild.html#start_build_batch/3","title":"AWS.CodeBuild.start_build_batch/3","type":"function","doc":"Starts a batch build for a project."},{"ref":"AWS.CodeBuild.html#stop_build/3","title":"AWS.CodeBuild.stop_build/3","type":"function","doc":"Attempts to stop running a build."},{"ref":"AWS.CodeBuild.html#stop_build_batch/3","title":"AWS.CodeBuild.stop_build_batch/3","type":"function","doc":"Stops a running batch build."},{"ref":"AWS.CodeBuild.html#update_project/3","title":"AWS.CodeBuild.update_project/3","type":"function","doc":"Changes the settings of a build project."},{"ref":"AWS.CodeBuild.html#update_report_group/3","title":"AWS.CodeBuild.update_report_group/3","type":"function","doc":"Updates a report group."},{"ref":"AWS.CodeBuild.html#update_webhook/3","title":"AWS.CodeBuild.update_webhook/3","type":"function","doc":"Updates the webhook associated with an AWS CodeBuild build project. If you use Bitbucket for your repository, rotateSecret is ignored."},{"ref":"AWS.CodeCommit.html","title":"AWS.CodeCommit","type":"module","doc":"AWS CodeCommit This is the AWS CodeCommit API Reference. This reference provides descriptions of the operations and data types for AWS CodeCommit API along with usage examples. You can use the AWS CodeCommit API to work with the following objects: Repositories, by calling the following: BatchGetRepositories, which returns information about one or more repositories associated with your AWS account. CreateRepository, which creates an AWS CodeCommit repository. DeleteRepository, which deletes an AWS CodeCommit repository. GetRepository, which returns information about a specified repository. ListRepositories, which lists all AWS CodeCommit repositories associated with your AWS account. UpdateRepositoryDescription, which sets or updates the description of the repository. UpdateRepositoryName, which changes the name of the repository. If you change the name of a repository, no other users of that repository can access it until you send them the new HTTPS or SSH URL to use. Branches, by calling the following: CreateBranch, which creates a branch in a specified repository. DeleteBranch, which deletes the specified branch in a repository unless it is the default branch. GetBranch, which returns information about a specified branch. ListBranches, which lists all branches for a specified repository. UpdateDefaultBranch, which changes the default branch for a repository. Files, by calling the following: DeleteFile, which deletes the content of a specified file from a specified branch. GetBlob, which returns the base-64 encoded content of an individual Git blob object in a repository. GetFile, which returns the base-64 encoded content of a specified file. GetFolder, which returns the contents of a specified folder or directory. PutFile, which adds or modifies a single file in a specified repository and branch. Commits, by calling the following: BatchGetCommits, which returns information about one or more commits in a repository. CreateCommit, which creates a commit for changes to a repository. GetCommit, which returns information about a commit, including commit messages and author and committer information. GetDifferences, which returns information about the differences in a valid commit specifier (such as a branch, tag, HEAD, commit ID, or other fully qualified reference). Merges, by calling the following: BatchDescribeMergeConflicts, which returns information about conflicts in a merge between commits in a repository. CreateUnreferencedMergeCommit, which creates an unreferenced commit between two branches or commits for the purpose of comparing them and identifying any potential conflicts. DescribeMergeConflicts, which returns information about merge conflicts between the base, source, and destination versions of a file in a potential merge. GetMergeCommit, which returns information about the merge between a source and destination commit. GetMergeConflicts, which returns information about merge conflicts between the source and destination branch in a pull request. GetMergeOptions, which returns information about the available merge options between two branches or commit specifiers. MergeBranchesByFastForward, which merges two branches using the fast-forward merge option. MergeBranchesBySquash, which merges two branches using the squash merge option. MergeBranchesByThreeWay, which merges two branches using the three-way merge option. Pull requests, by calling the following: CreatePullRequest, which creates a pull request in a specified repository. CreatePullRequestApprovalRule, which creates an approval rule for a specified pull request. DeletePullRequestApprovalRule, which deletes an approval rule for a specified pull request. DescribePullRequestEvents, which returns information about one or more pull request events. EvaluatePullRequestApprovalRules, which evaluates whether a pull request has met all the conditions specified in its associated approval rules. GetCommentsForPullRequest, which returns information about comments on a specified pull request. GetPullRequest, which returns information about a specified pull request. GetPullRequestApprovalStates, which returns information about the approval states for a specified pull request. GetPullRequestOverrideState, which returns information about whether approval rules have been set aside (overriden) for a pull request, and if so, the Amazon Resource Name (ARN) of the user or identity that overrode the rules and their requirements for the pull request. ListPullRequests, which lists all pull requests for a repository. MergePullRequestByFastForward, which merges the source destination branch of a pull request into the specified destination branch for that pull request using the fast-forward merge option. MergePullRequestBySquash, which merges the source destination branch of a pull request into the specified destination branch for that pull request using the squash merge option. MergePullRequestByThreeWay. which merges the source destination branch of a pull request into the specified destination branch for that pull request using the three-way merge option. OverridePullRequestApprovalRules, which sets aside all approval rule requirements for a pull request. PostCommentForPullRequest, which posts a comment to a pull request at the specified line, file, or request. UpdatePullRequestApprovalRuleContent, which updates the structure of an approval rule for a pull request. UpdatePullRequestApprovalState, which updates the state of an approval on a pull request. UpdatePullRequestDescription, which updates the description of a pull request. UpdatePullRequestStatus, which updates the status of a pull request. UpdatePullRequestTitle, which updates the title of a pull request. Approval rule templates, by calling the following: AssociateApprovalRuleTemplateWithRepository, which associates a template with a specified repository. After the template is associated with a repository, AWS CodeCommit creates approval rules that match the template conditions on every pull request created in the specified repository. BatchAssociateApprovalRuleTemplateWithRepositories, which associates a template with one or more specified repositories. After the template is associated with a repository, AWS CodeCommit creates approval rules that match the template conditions on every pull request created in the specified repositories. BatchDisassociateApprovalRuleTemplateFromRepositories, which removes the association between a template and specified repositories so that approval rules based on the template are not automatically created when pull requests are created in those repositories. CreateApprovalRuleTemplate, which creates a template for approval rules that can then be associated with one or more repositories in your AWS account. DeleteApprovalRuleTemplate, which deletes the specified template. It does not remove approval rules on pull requests already created with the template. DisassociateApprovalRuleTemplateFromRepository, which removes the association between a template and a repository so that approval rules based on the template are not automatically created when pull requests are created in the specified repository. GetApprovalRuleTemplate, which returns information about an approval rule template. ListApprovalRuleTemplates, which lists all approval rule templates in the AWS Region in your AWS account. ListAssociatedApprovalRuleTemplatesForRepository, which lists all approval rule templates that are associated with a specified repository. ListRepositoriesForApprovalRuleTemplate, which lists all repositories associated with the specified approval rule template. UpdateApprovalRuleTemplateDescription, which updates the description of an approval rule template. UpdateApprovalRuleTemplateName, which updates the name of an approval rule template. UpdateApprovalRuleTemplateContent, which updates the content of an approval rule template. Comments in a repository, by calling the following: DeleteCommentContent, which deletes the content of a comment on a commit in a repository. GetComment, which returns information about a comment on a commit. GetCommentReactions, which returns information about emoji reactions to comments. GetCommentsForComparedCommit, which returns information about comments on the comparison between two commit specifiers in a repository. PostCommentForComparedCommit, which creates a comment on the comparison between two commit specifiers in a repository. PostCommentReply, which creates a reply to a comment. PutCommentReaction, which creates or updates an emoji reaction to a comment. UpdateComment, which updates the content of a comment on a commit in a repository. Tags used to tag resources in AWS CodeCommit (not Git tags), by calling the following: ListTagsForResource, which gets information about AWS tags for a specified Amazon Resource Name (ARN) in AWS CodeCommit. TagResource, which adds or updates tags for a resource in AWS CodeCommit. UntagResource, which removes tags for a resource in AWS CodeCommit. Triggers, by calling the following: GetRepositoryTriggers, which returns information about triggers configured for a repository. PutRepositoryTriggers, which replaces all triggers for a repository and can be used to create or delete triggers. TestRepositoryTriggers, which tests the functionality of a repository trigger by sending data to the trigger target. For information about how to use AWS CodeCommit, see the AWS CodeCommit User Guide."},{"ref":"AWS.CodeCommit.html#associate_approval_rule_template_with_repository/3","title":"AWS.CodeCommit.associate_approval_rule_template_with_repository/3","type":"function","doc":"Creates an association between an approval rule template and a specified repository. Then, the next time a pull request is created in the repository where the destination reference (if specified) matches the destination reference (branch) for the pull request, an approval rule that matches the template conditions is automatically created for that pull request. If no destination references are specified in the template, an approval rule that matches the template contents is created for all pull requests in that repository."},{"ref":"AWS.CodeCommit.html#batch_associate_approval_rule_template_with_repositories/3","title":"AWS.CodeCommit.batch_associate_approval_rule_template_with_repositories/3","type":"function","doc":"Creates an association between an approval rule template and one or more specified repositories."},{"ref":"AWS.CodeCommit.html#batch_describe_merge_conflicts/3","title":"AWS.CodeCommit.batch_describe_merge_conflicts/3","type":"function","doc":"Returns information about one or more merge conflicts in the attempted merge of two commit specifiers using the squash or three-way merge strategy."},{"ref":"AWS.CodeCommit.html#batch_disassociate_approval_rule_template_from_repositories/3","title":"AWS.CodeCommit.batch_disassociate_approval_rule_template_from_repositories/3","type":"function","doc":"Removes the association between an approval rule template and one or more specified repositories."},{"ref":"AWS.CodeCommit.html#batch_get_commits/3","title":"AWS.CodeCommit.batch_get_commits/3","type":"function","doc":"Returns information about the contents of one or more commits in a repository."},{"ref":"AWS.CodeCommit.html#batch_get_repositories/3","title":"AWS.CodeCommit.batch_get_repositories/3","type":"function","doc":"Returns information about one or more repositories. The description field for a repository accepts all HTML characters and all valid Unicode characters. Applications that do not HTML-encode the description and display it in a webpage can expose users to potentially malicious code. Make sure that you HTML-encode the description field in any application that uses this API to display the repository description on a webpage."},{"ref":"AWS.CodeCommit.html#create_approval_rule_template/3","title":"AWS.CodeCommit.create_approval_rule_template/3","type":"function","doc":"Creates a template for approval rules that can then be associated with one or more repositories in your AWS account. When you associate a template with a repository, AWS CodeCommit creates an approval rule that matches the conditions of the template for all pull requests that meet the conditions of the template. For more information, see AssociateApprovalRuleTemplateWithRepository."},{"ref":"AWS.CodeCommit.html#create_branch/3","title":"AWS.CodeCommit.create_branch/3","type":"function","doc":"Creates a branch in a repository and points the branch to a commit. Calling the create branch operation does not set a repository&#39;s default branch. To do this, call the update default branch operation."},{"ref":"AWS.CodeCommit.html#create_commit/3","title":"AWS.CodeCommit.create_commit/3","type":"function","doc":"Creates a commit for a repository on the tip of a specified branch."},{"ref":"AWS.CodeCommit.html#create_pull_request/3","title":"AWS.CodeCommit.create_pull_request/3","type":"function","doc":"Creates a pull request in the specified repository."},{"ref":"AWS.CodeCommit.html#create_pull_request_approval_rule/3","title":"AWS.CodeCommit.create_pull_request_approval_rule/3","type":"function","doc":"Creates an approval rule for a pull request."},{"ref":"AWS.CodeCommit.html#create_repository/3","title":"AWS.CodeCommit.create_repository/3","type":"function","doc":"Creates a new, empty repository."},{"ref":"AWS.CodeCommit.html#create_unreferenced_merge_commit/3","title":"AWS.CodeCommit.create_unreferenced_merge_commit/3","type":"function","doc":"Creates an unreferenced commit that represents the result of merging two branches using a specified merge strategy. This can help you determine the outcome of a potential merge. This API cannot be used with the fast-forward merge strategy because that strategy does not create a merge commit. This unreferenced merge commit can only be accessed using the GetCommit API or through git commands such as git fetch. To retrieve this commit, you must specify its commit ID or otherwise reference it."},{"ref":"AWS.CodeCommit.html#delete_approval_rule_template/3","title":"AWS.CodeCommit.delete_approval_rule_template/3","type":"function","doc":"Deletes a specified approval rule template. Deleting a template does not remove approval rules on pull requests already created with the template."},{"ref":"AWS.CodeCommit.html#delete_branch/3","title":"AWS.CodeCommit.delete_branch/3","type":"function","doc":"Deletes a branch from a repository, unless that branch is the default branch for the repository."},{"ref":"AWS.CodeCommit.html#delete_comment_content/3","title":"AWS.CodeCommit.delete_comment_content/3","type":"function","doc":"Deletes the content of a comment made on a change, file, or commit in a repository."},{"ref":"AWS.CodeCommit.html#delete_file/3","title":"AWS.CodeCommit.delete_file/3","type":"function","doc":"Deletes a specified file from a specified branch. A commit is created on the branch that contains the revision. The file still exists in the commits earlier to the commit that contains the deletion."},{"ref":"AWS.CodeCommit.html#delete_pull_request_approval_rule/3","title":"AWS.CodeCommit.delete_pull_request_approval_rule/3","type":"function","doc":"Deletes an approval rule from a specified pull request. Approval rules can be deleted from a pull request only if the pull request is open, and if the approval rule was created specifically for a pull request and not generated from an approval rule template associated with the repository where the pull request was created. You cannot delete an approval rule from a merged or closed pull request."},{"ref":"AWS.CodeCommit.html#delete_repository/3","title":"AWS.CodeCommit.delete_repository/3","type":"function","doc":"Deletes a repository. If a specified repository was already deleted, a null repository ID is returned. Deleting a repository also deletes all associated objects and metadata. After a repository is deleted, all future push calls to the deleted repository fail."},{"ref":"AWS.CodeCommit.html#describe_merge_conflicts/3","title":"AWS.CodeCommit.describe_merge_conflicts/3","type":"function","doc":"Returns information about one or more merge conflicts in the attempted merge of two commit specifiers using the squash or three-way merge strategy. If the merge option for the attempted merge is specified as FAST_FORWARD_MERGE, an exception is thrown."},{"ref":"AWS.CodeCommit.html#describe_pull_request_events/3","title":"AWS.CodeCommit.describe_pull_request_events/3","type":"function","doc":"Returns information about one or more pull request events."},{"ref":"AWS.CodeCommit.html#disassociate_approval_rule_template_from_repository/3","title":"AWS.CodeCommit.disassociate_approval_rule_template_from_repository/3","type":"function","doc":"Removes the association between a template and a repository so that approval rules based on the template are not automatically created when pull requests are created in the specified repository. This does not delete any approval rules previously created for pull requests through the template association."},{"ref":"AWS.CodeCommit.html#evaluate_pull_request_approval_rules/3","title":"AWS.CodeCommit.evaluate_pull_request_approval_rules/3","type":"function","doc":"Evaluates whether a pull request has met all the conditions specified in its associated approval rules."},{"ref":"AWS.CodeCommit.html#get_approval_rule_template/3","title":"AWS.CodeCommit.get_approval_rule_template/3","type":"function","doc":"Returns information about a specified approval rule template."},{"ref":"AWS.CodeCommit.html#get_blob/3","title":"AWS.CodeCommit.get_blob/3","type":"function","doc":"Returns the base-64 encoded content of an individual blob in a repository."},{"ref":"AWS.CodeCommit.html#get_branch/3","title":"AWS.CodeCommit.get_branch/3","type":"function","doc":"Returns information about a repository branch, including its name and the last commit ID."},{"ref":"AWS.CodeCommit.html#get_comment/3","title":"AWS.CodeCommit.get_comment/3","type":"function","doc":"Returns the content of a comment made on a change, file, or commit in a repository. Reaction counts might include numbers from user identities who were deleted after the reaction was made. For a count of reactions from active identities, use GetCommentReactions."},{"ref":"AWS.CodeCommit.html#get_comment_reactions/3","title":"AWS.CodeCommit.get_comment_reactions/3","type":"function","doc":"Returns information about reactions to a specified comment ID. Reactions from users who have been deleted will not be included in the count."},{"ref":"AWS.CodeCommit.html#get_comments_for_compared_commit/3","title":"AWS.CodeCommit.get_comments_for_compared_commit/3","type":"function","doc":"Returns information about comments made on the comparison between two commits. Reaction counts might include numbers from user identities who were deleted after the reaction was made. For a count of reactions from active identities, use GetCommentReactions."},{"ref":"AWS.CodeCommit.html#get_comments_for_pull_request/3","title":"AWS.CodeCommit.get_comments_for_pull_request/3","type":"function","doc":"Returns comments made on a pull request. Reaction counts might include numbers from user identities who were deleted after the reaction was made. For a count of reactions from active identities, use GetCommentReactions."},{"ref":"AWS.CodeCommit.html#get_commit/3","title":"AWS.CodeCommit.get_commit/3","type":"function","doc":"Returns information about a commit, including commit message and committer information."},{"ref":"AWS.CodeCommit.html#get_differences/3","title":"AWS.CodeCommit.get_differences/3","type":"function","doc":"Returns information about the differences in a valid commit specifier (such as a branch, tag, HEAD, commit ID, or other fully qualified reference). Results can be limited to a specified path."},{"ref":"AWS.CodeCommit.html#get_file/3","title":"AWS.CodeCommit.get_file/3","type":"function","doc":"Returns the base-64 encoded contents of a specified file and its metadata."},{"ref":"AWS.CodeCommit.html#get_folder/3","title":"AWS.CodeCommit.get_folder/3","type":"function","doc":"Returns the contents of a specified folder in a repository."},{"ref":"AWS.CodeCommit.html#get_merge_commit/3","title":"AWS.CodeCommit.get_merge_commit/3","type":"function","doc":"Returns information about a specified merge commit."},{"ref":"AWS.CodeCommit.html#get_merge_conflicts/3","title":"AWS.CodeCommit.get_merge_conflicts/3","type":"function","doc":"Returns information about merge conflicts between the before and after commit IDs for a pull request in a repository."},{"ref":"AWS.CodeCommit.html#get_merge_options/3","title":"AWS.CodeCommit.get_merge_options/3","type":"function","doc":"Returns information about the merge options available for merging two specified branches. For details about why a merge option is not available, use GetMergeConflicts or DescribeMergeConflicts."},{"ref":"AWS.CodeCommit.html#get_pull_request/3","title":"AWS.CodeCommit.get_pull_request/3","type":"function","doc":"Gets information about a pull request in a specified repository."},{"ref":"AWS.CodeCommit.html#get_pull_request_approval_states/3","title":"AWS.CodeCommit.get_pull_request_approval_states/3","type":"function","doc":"Gets information about the approval states for a specified pull request. Approval states only apply to pull requests that have one or more approval rules applied to them."},{"ref":"AWS.CodeCommit.html#get_pull_request_override_state/3","title":"AWS.CodeCommit.get_pull_request_override_state/3","type":"function","doc":"Returns information about whether approval rules have been set aside (overridden) for a pull request, and if so, the Amazon Resource Name (ARN) of the user or identity that overrode the rules and their requirements for the pull request."},{"ref":"AWS.CodeCommit.html#get_repository/3","title":"AWS.CodeCommit.get_repository/3","type":"function","doc":"Returns information about a repository. The description field for a repository accepts all HTML characters and all valid Unicode characters. Applications that do not HTML-encode the description and display it in a webpage can expose users to potentially malicious code. Make sure that you HTML-encode the description field in any application that uses this API to display the repository description on a webpage."},{"ref":"AWS.CodeCommit.html#get_repository_triggers/3","title":"AWS.CodeCommit.get_repository_triggers/3","type":"function","doc":"Gets information about triggers configured for a repository."},{"ref":"AWS.CodeCommit.html#list_approval_rule_templates/3","title":"AWS.CodeCommit.list_approval_rule_templates/3","type":"function","doc":"Lists all approval rule templates in the specified AWS Region in your AWS account. If an AWS Region is not specified, the AWS Region where you are signed in is used."},{"ref":"AWS.CodeCommit.html#list_associated_approval_rule_templates_for_repository/3","title":"AWS.CodeCommit.list_associated_approval_rule_templates_for_repository/3","type":"function","doc":"Lists all approval rule templates that are associated with a specified repository."},{"ref":"AWS.CodeCommit.html#list_branches/3","title":"AWS.CodeCommit.list_branches/3","type":"function","doc":"Gets information about one or more branches in a repository."},{"ref":"AWS.CodeCommit.html#list_pull_requests/3","title":"AWS.CodeCommit.list_pull_requests/3","type":"function","doc":"Returns a list of pull requests for a specified repository. The return list can be refined by pull request status or pull request author ARN."},{"ref":"AWS.CodeCommit.html#list_repositories/3","title":"AWS.CodeCommit.list_repositories/3","type":"function","doc":"Gets information about one or more repositories."},{"ref":"AWS.CodeCommit.html#list_repositories_for_approval_rule_template/3","title":"AWS.CodeCommit.list_repositories_for_approval_rule_template/3","type":"function","doc":"Lists all repositories associated with the specified approval rule template."},{"ref":"AWS.CodeCommit.html#list_tags_for_resource/3","title":"AWS.CodeCommit.list_tags_for_resource/3","type":"function","doc":"Gets information about AWS tags for a specified Amazon Resource Name (ARN) in AWS CodeCommit. For a list of valid resources in AWS CodeCommit, see CodeCommit Resources and Operations in the AWS CodeCommit User Guide."},{"ref":"AWS.CodeCommit.html#merge_branches_by_fast_forward/3","title":"AWS.CodeCommit.merge_branches_by_fast_forward/3","type":"function","doc":"Merges two branches using the fast-forward merge strategy."},{"ref":"AWS.CodeCommit.html#merge_branches_by_squash/3","title":"AWS.CodeCommit.merge_branches_by_squash/3","type":"function","doc":"Merges two branches using the squash merge strategy."},{"ref":"AWS.CodeCommit.html#merge_branches_by_three_way/3","title":"AWS.CodeCommit.merge_branches_by_three_way/3","type":"function","doc":"Merges two specified branches using the three-way merge strategy."},{"ref":"AWS.CodeCommit.html#merge_pull_request_by_fast_forward/3","title":"AWS.CodeCommit.merge_pull_request_by_fast_forward/3","type":"function","doc":"Attempts to merge the source commit of a pull request into the specified destination branch for that pull request at the specified commit using the fast-forward merge strategy. If the merge is successful, it closes the pull request."},{"ref":"AWS.CodeCommit.html#merge_pull_request_by_squash/3","title":"AWS.CodeCommit.merge_pull_request_by_squash/3","type":"function","doc":"Attempts to merge the source commit of a pull request into the specified destination branch for that pull request at the specified commit using the squash merge strategy. If the merge is successful, it closes the pull request."},{"ref":"AWS.CodeCommit.html#merge_pull_request_by_three_way/3","title":"AWS.CodeCommit.merge_pull_request_by_three_way/3","type":"function","doc":"Attempts to merge the source commit of a pull request into the specified destination branch for that pull request at the specified commit using the three-way merge strategy. If the merge is successful, it closes the pull request."},{"ref":"AWS.CodeCommit.html#override_pull_request_approval_rules/3","title":"AWS.CodeCommit.override_pull_request_approval_rules/3","type":"function","doc":"Sets aside (overrides) all approval rule requirements for a specified pull request."},{"ref":"AWS.CodeCommit.html#post_comment_for_compared_commit/3","title":"AWS.CodeCommit.post_comment_for_compared_commit/3","type":"function","doc":"Posts a comment on the comparison between two commits."},{"ref":"AWS.CodeCommit.html#post_comment_for_pull_request/3","title":"AWS.CodeCommit.post_comment_for_pull_request/3","type":"function","doc":"Posts a comment on a pull request."},{"ref":"AWS.CodeCommit.html#post_comment_reply/3","title":"AWS.CodeCommit.post_comment_reply/3","type":"function","doc":"Posts a comment in reply to an existing comment on a comparison between commits or a pull request."},{"ref":"AWS.CodeCommit.html#put_comment_reaction/3","title":"AWS.CodeCommit.put_comment_reaction/3","type":"function","doc":"Adds or updates a reaction to a specified comment for the user whose identity is used to make the request. You can only add or update a reaction for yourself. You cannot add, modify, or delete a reaction for another user."},{"ref":"AWS.CodeCommit.html#put_file/3","title":"AWS.CodeCommit.put_file/3","type":"function","doc":"Adds or updates a file in a branch in an AWS CodeCommit repository, and generates a commit for the addition in the specified branch."},{"ref":"AWS.CodeCommit.html#put_repository_triggers/3","title":"AWS.CodeCommit.put_repository_triggers/3","type":"function","doc":"Replaces all triggers for a repository. Used to create or delete triggers."},{"ref":"AWS.CodeCommit.html#tag_resource/3","title":"AWS.CodeCommit.tag_resource/3","type":"function","doc":"Adds or updates tags for a resource in AWS CodeCommit. For a list of valid resources in AWS CodeCommit, see CodeCommit Resources and Operations in the AWS CodeCommit User Guide."},{"ref":"AWS.CodeCommit.html#test_repository_triggers/3","title":"AWS.CodeCommit.test_repository_triggers/3","type":"function","doc":"Tests the functionality of repository triggers by sending information to the trigger target. If real data is available in the repository, the test sends data from the last commit. If no data is available, sample data is generated."},{"ref":"AWS.CodeCommit.html#untag_resource/3","title":"AWS.CodeCommit.untag_resource/3","type":"function","doc":"Removes tags for a resource in AWS CodeCommit. For a list of valid resources in AWS CodeCommit, see CodeCommit Resources and Operations in the AWS CodeCommit User Guide."},{"ref":"AWS.CodeCommit.html#update_approval_rule_template_content/3","title":"AWS.CodeCommit.update_approval_rule_template_content/3","type":"function","doc":"Updates the content of an approval rule template. You can change the number of required approvals, the membership of the approval rule, and whether an approval pool is defined."},{"ref":"AWS.CodeCommit.html#update_approval_rule_template_description/3","title":"AWS.CodeCommit.update_approval_rule_template_description/3","type":"function","doc":"Updates the description for a specified approval rule template."},{"ref":"AWS.CodeCommit.html#update_approval_rule_template_name/3","title":"AWS.CodeCommit.update_approval_rule_template_name/3","type":"function","doc":"Updates the name of a specified approval rule template."},{"ref":"AWS.CodeCommit.html#update_comment/3","title":"AWS.CodeCommit.update_comment/3","type":"function","doc":"Replaces the contents of a comment."},{"ref":"AWS.CodeCommit.html#update_default_branch/3","title":"AWS.CodeCommit.update_default_branch/3","type":"function","doc":"Sets or changes the default branch name for the specified repository. If you use this operation to change the default branch name to the current default branch name, a success message is returned even though the default branch did not change."},{"ref":"AWS.CodeCommit.html#update_pull_request_approval_rule_content/3","title":"AWS.CodeCommit.update_pull_request_approval_rule_content/3","type":"function","doc":"Updates the structure of an approval rule created specifically for a pull request. For example, you can change the number of required approvers and the approval pool for approvers."},{"ref":"AWS.CodeCommit.html#update_pull_request_approval_state/3","title":"AWS.CodeCommit.update_pull_request_approval_state/3","type":"function","doc":"Updates the state of a user&#39;s approval on a pull request. The user is derived from the signed-in account when the request is made."},{"ref":"AWS.CodeCommit.html#update_pull_request_description/3","title":"AWS.CodeCommit.update_pull_request_description/3","type":"function","doc":"Replaces the contents of the description of a pull request."},{"ref":"AWS.CodeCommit.html#update_pull_request_status/3","title":"AWS.CodeCommit.update_pull_request_status/3","type":"function","doc":"Updates the status of a pull request."},{"ref":"AWS.CodeCommit.html#update_pull_request_title/3","title":"AWS.CodeCommit.update_pull_request_title/3","type":"function","doc":"Replaces the title of a pull request."},{"ref":"AWS.CodeCommit.html#update_repository_description/3","title":"AWS.CodeCommit.update_repository_description/3","type":"function","doc":"Sets or changes the comment or description for a repository. The description field for a repository accepts all HTML characters and all valid Unicode characters. Applications that do not HTML-encode the description and display it in a webpage can expose users to potentially malicious code. Make sure that you HTML-encode the description field in any application that uses this API to display the repository description on a webpage."},{"ref":"AWS.CodeCommit.html#update_repository_name/3","title":"AWS.CodeCommit.update_repository_name/3","type":"function","doc":"Renames a repository. The repository name must be unique across the calling AWS account. Repository names are limited to 100 alphanumeric, dash, and underscore characters, and cannot include certain characters. The suffix .git is prohibited. For more information about the limits on repository names, see Limits in the AWS CodeCommit User Guide."},{"ref":"AWS.CodeDeploy.html","title":"AWS.CodeDeploy","type":"module","doc":"AWS CodeDeploy AWS CodeDeploy is a deployment service that automates application deployments to Amazon EC2 instances, on-premises instances running in your own facility, serverless AWS Lambda functions, or applications in an Amazon ECS service. You can deploy a nearly unlimited variety of application content, such as an updated Lambda function, updated applications in an Amazon ECS service, code, web and configuration files, executables, packages, scripts, multimedia files, and so on. AWS CodeDeploy can deploy application content stored in Amazon S3 buckets, GitHub repositories, or Bitbucket repositories. You do not need to make changes to your existing code before you can use AWS CodeDeploy. AWS CodeDeploy makes it easier for you to rapidly release new features, helps you avoid downtime during application deployment, and handles the complexity of updating your applications, without many of the risks associated with error-prone manual deployments. AWS CodeDeploy Components Use the information in this guide to help you work with the following AWS CodeDeploy components: Application: A name that uniquely identifies the application you want to deploy. AWS CodeDeploy uses this name, which functions as a container, to ensure the correct combination of revision, deployment configuration, and deployment group are referenced during a deployment. Deployment group: A set of individual instances, CodeDeploy Lambda deployment configuration settings, or an Amazon ECS service and network details. A Lambda deployment group specifies how to route traffic to a new version of a Lambda function. An Amazon ECS deployment group specifies the service created in Amazon ECS to deploy, a load balancer, and a listener to reroute production traffic to an updated containerized application. An EC2/On-premises deployment group contains individually tagged instances, Amazon EC2 instances in Amazon EC2 Auto Scaling groups, or both. All deployment groups can specify optional trigger, alarm, and rollback settings. Deployment configuration: A set of deployment rules and deployment success and failure conditions used by AWS CodeDeploy during a deployment. Deployment: The process and the components used when updating a Lambda function, a containerized application in an Amazon ECS service, or of installing content on one or more instances. Application revisions: For an AWS Lambda deployment, this is an AppSpec file that specifies the Lambda function to be updated and one or more functions to validate deployment lifecycle events. For an Amazon ECS deployment, this is an AppSpec file that specifies the Amazon ECS task definition, container, and port where production traffic is rerouted. For an EC2/On-premises deployment, this is an archive file that contains source contentsource code, webpages, executable files, and deployment scriptsalong with an AppSpec file. Revisions are stored in Amazon S3 buckets or GitHub repositories. For Amazon S3, a revision is uniquely identified by its Amazon S3 object key and its ETag, version, or both. For GitHub, a revision is uniquely identified by its commit ID. This guide also contains information to help you get details about the instances in your deployments, to make on-premises instances available for AWS CodeDeploy deployments, to get details about a Lambda function deployment, and to get details about Amazon ECS service deployments. AWS CodeDeploy Information Resources AWS CodeDeploy User Guide * AWS CodeDeploy API Reference Guide AWS CLI Reference for AWS CodeDeploy AWS CodeDeploy Developer Forum"},{"ref":"AWS.CodeDeploy.html#add_tags_to_on_premises_instances/3","title":"AWS.CodeDeploy.add_tags_to_on_premises_instances/3","type":"function","doc":"Adds tags to on-premises instances."},{"ref":"AWS.CodeDeploy.html#batch_get_application_revisions/3","title":"AWS.CodeDeploy.batch_get_application_revisions/3","type":"function","doc":"Gets information about one or more application revisions. The maximum number of application revisions that can be returned is 25."},{"ref":"AWS.CodeDeploy.html#batch_get_applications/3","title":"AWS.CodeDeploy.batch_get_applications/3","type":"function","doc":"Gets information about one or more applications. The maximum number of applications that can be returned is 100."},{"ref":"AWS.CodeDeploy.html#batch_get_deployment_groups/3","title":"AWS.CodeDeploy.batch_get_deployment_groups/3","type":"function","doc":"Gets information about one or more deployment groups."},{"ref":"AWS.CodeDeploy.html#batch_get_deployment_instances/3","title":"AWS.CodeDeploy.batch_get_deployment_instances/3","type":"function","doc":"This method works, but is deprecated. Use BatchGetDeploymentTargets instead. Returns an array of one or more instances associated with a deployment. This method works with EC2/On-premises and AWS Lambda compute platforms. The newer BatchGetDeploymentTargets works with all compute platforms. The maximum number of instances that can be returned is 25."},{"ref":"AWS.CodeDeploy.html#batch_get_deployment_targets/3","title":"AWS.CodeDeploy.batch_get_deployment_targets/3","type":"function","doc":"Returns an array of one or more targets associated with a deployment. This method works with all compute types and should be used instead of the deprecated BatchGetDeploymentInstances. The maximum number of targets that can be returned is 25. The type of targets returned depends on the deployment&#39;s compute platform or deployment method: EC2/On-premises: Information about EC2 instance targets. AWS Lambda: Information about Lambda functions targets. Amazon ECS: Information about Amazon ECS service targets. CloudFormation: Information about targets of blue/green deployments initiated by a CloudFormation stack update."},{"ref":"AWS.CodeDeploy.html#batch_get_deployments/3","title":"AWS.CodeDeploy.batch_get_deployments/3","type":"function","doc":"Gets information about one or more deployments. The maximum number of deployments that can be returned is 25."},{"ref":"AWS.CodeDeploy.html#batch_get_on_premises_instances/3","title":"AWS.CodeDeploy.batch_get_on_premises_instances/3","type":"function","doc":"Gets information about one or more on-premises instances. The maximum number of on-premises instances that can be returned is 25."},{"ref":"AWS.CodeDeploy.html#continue_deployment/3","title":"AWS.CodeDeploy.continue_deployment/3","type":"function","doc":"For a blue/green deployment, starts the process of rerouting traffic from instances in the original environment to instances in the replacement environment without waiting for a specified wait time to elapse. (Traffic rerouting, which is achieved by registering instances in the replacement environment with the load balancer, can start as soon as all instances have a status of Ready.)"},{"ref":"AWS.CodeDeploy.html#create_application/3","title":"AWS.CodeDeploy.create_application/3","type":"function","doc":"Creates an application."},{"ref":"AWS.CodeDeploy.html#create_deployment/3","title":"AWS.CodeDeploy.create_deployment/3","type":"function","doc":"Deploys an application revision through the specified deployment group."},{"ref":"AWS.CodeDeploy.html#create_deployment_config/3","title":"AWS.CodeDeploy.create_deployment_config/3","type":"function","doc":"Creates a deployment configuration."},{"ref":"AWS.CodeDeploy.html#create_deployment_group/3","title":"AWS.CodeDeploy.create_deployment_group/3","type":"function","doc":"Creates a deployment group to which application revisions are deployed."},{"ref":"AWS.CodeDeploy.html#delete_application/3","title":"AWS.CodeDeploy.delete_application/3","type":"function","doc":"Deletes an application."},{"ref":"AWS.CodeDeploy.html#delete_deployment_config/3","title":"AWS.CodeDeploy.delete_deployment_config/3","type":"function","doc":"Deletes a deployment configuration. A deployment configuration cannot be deleted if it is currently in use. Predefined configurations cannot be deleted."},{"ref":"AWS.CodeDeploy.html#delete_deployment_group/3","title":"AWS.CodeDeploy.delete_deployment_group/3","type":"function","doc":"Deletes a deployment group."},{"ref":"AWS.CodeDeploy.html#delete_git_hub_account_token/3","title":"AWS.CodeDeploy.delete_git_hub_account_token/3","type":"function","doc":"Deletes a GitHub account connection."},{"ref":"AWS.CodeDeploy.html#delete_resources_by_external_id/3","title":"AWS.CodeDeploy.delete_resources_by_external_id/3","type":"function","doc":"Deletes resources linked to an external ID."},{"ref":"AWS.CodeDeploy.html#deregister_on_premises_instance/3","title":"AWS.CodeDeploy.deregister_on_premises_instance/3","type":"function","doc":"Deregisters an on-premises instance."},{"ref":"AWS.CodeDeploy.html#get_application/3","title":"AWS.CodeDeploy.get_application/3","type":"function","doc":"Gets information about an application."},{"ref":"AWS.CodeDeploy.html#get_application_revision/3","title":"AWS.CodeDeploy.get_application_revision/3","type":"function","doc":"Gets information about an application revision."},{"ref":"AWS.CodeDeploy.html#get_deployment/3","title":"AWS.CodeDeploy.get_deployment/3","type":"function","doc":"Gets information about a deployment. The content property of the appSpecContent object in the returned revision is always null. Use GetApplicationRevision and the sha256 property of the returned appSpecContent object to get the content of the deployments AppSpec file."},{"ref":"AWS.CodeDeploy.html#get_deployment_config/3","title":"AWS.CodeDeploy.get_deployment_config/3","type":"function","doc":"Gets information about a deployment configuration."},{"ref":"AWS.CodeDeploy.html#get_deployment_group/3","title":"AWS.CodeDeploy.get_deployment_group/3","type":"function","doc":"Gets information about a deployment group."},{"ref":"AWS.CodeDeploy.html#get_deployment_instance/3","title":"AWS.CodeDeploy.get_deployment_instance/3","type":"function","doc":"Gets information about an instance as part of a deployment."},{"ref":"AWS.CodeDeploy.html#get_deployment_target/3","title":"AWS.CodeDeploy.get_deployment_target/3","type":"function","doc":"Returns information about a deployment target."},{"ref":"AWS.CodeDeploy.html#get_on_premises_instance/3","title":"AWS.CodeDeploy.get_on_premises_instance/3","type":"function","doc":"Gets information about an on-premises instance."},{"ref":"AWS.CodeDeploy.html#list_application_revisions/3","title":"AWS.CodeDeploy.list_application_revisions/3","type":"function","doc":"Lists information about revisions for an application."},{"ref":"AWS.CodeDeploy.html#list_applications/3","title":"AWS.CodeDeploy.list_applications/3","type":"function","doc":"Lists the applications registered with the IAM user or AWS account."},{"ref":"AWS.CodeDeploy.html#list_deployment_configs/3","title":"AWS.CodeDeploy.list_deployment_configs/3","type":"function","doc":"Lists the deployment configurations with the IAM user or AWS account."},{"ref":"AWS.CodeDeploy.html#list_deployment_groups/3","title":"AWS.CodeDeploy.list_deployment_groups/3","type":"function","doc":"Lists the deployment groups for an application registered with the IAM user or AWS account."},{"ref":"AWS.CodeDeploy.html#list_deployment_instances/3","title":"AWS.CodeDeploy.list_deployment_instances/3","type":"function","doc":"The newer BatchGetDeploymentTargets should be used instead because it works with all compute types. ListDeploymentInstances throws an exception if it is used with a compute platform other than EC2/On-premises or AWS Lambda. Lists the instance for a deployment associated with the IAM user or AWS account."},{"ref":"AWS.CodeDeploy.html#list_deployment_targets/3","title":"AWS.CodeDeploy.list_deployment_targets/3","type":"function","doc":"Returns an array of target IDs that are associated a deployment."},{"ref":"AWS.CodeDeploy.html#list_deployments/3","title":"AWS.CodeDeploy.list_deployments/3","type":"function","doc":"Lists the deployments in a deployment group for an application registered with the IAM user or AWS account."},{"ref":"AWS.CodeDeploy.html#list_git_hub_account_token_names/3","title":"AWS.CodeDeploy.list_git_hub_account_token_names/3","type":"function","doc":"Lists the names of stored connections to GitHub accounts."},{"ref":"AWS.CodeDeploy.html#list_on_premises_instances/3","title":"AWS.CodeDeploy.list_on_premises_instances/3","type":"function","doc":"Gets a list of names for one or more on-premises instances. Unless otherwise specified, both registered and deregistered on-premises instance names are listed. To list only registered or deregistered on-premises instance names, use the registration status parameter."},{"ref":"AWS.CodeDeploy.html#list_tags_for_resource/3","title":"AWS.CodeDeploy.list_tags_for_resource/3","type":"function","doc":"Returns a list of tags for the resource identified by a specified Amazon Resource Name (ARN). Tags are used to organize and categorize your CodeDeploy resources."},{"ref":"AWS.CodeDeploy.html#put_lifecycle_event_hook_execution_status/3","title":"AWS.CodeDeploy.put_lifecycle_event_hook_execution_status/3","type":"function","doc":"Sets the result of a Lambda validation function. The function validates lifecycle hooks during a deployment that uses the AWS Lambda or Amazon ECS compute platform. For AWS Lambda deployments, the available lifecycle hooks are BeforeAllowTraffic and AfterAllowTraffic. For Amazon ECS deployments, the available lifecycle hooks are BeforeInstall, AfterInstall, AfterAllowTestTraffic, BeforeAllowTraffic, and AfterAllowTraffic. Lambda validation functions return Succeeded or Failed. For more information, see AppSpec &#39;hooks&#39; Section for an AWS Lambda Deployment and AppSpec &#39;hooks&#39; Section for an Amazon ECS Deployment."},{"ref":"AWS.CodeDeploy.html#register_application_revision/3","title":"AWS.CodeDeploy.register_application_revision/3","type":"function","doc":"Registers with AWS CodeDeploy a revision for the specified application."},{"ref":"AWS.CodeDeploy.html#register_on_premises_instance/3","title":"AWS.CodeDeploy.register_on_premises_instance/3","type":"function","doc":"Registers an on-premises instance. Only one IAM ARN (an IAM session ARN or IAM user ARN) is supported in the request. You cannot use both."},{"ref":"AWS.CodeDeploy.html#remove_tags_from_on_premises_instances/3","title":"AWS.CodeDeploy.remove_tags_from_on_premises_instances/3","type":"function","doc":"Removes one or more tags from one or more on-premises instances."},{"ref":"AWS.CodeDeploy.html#skip_wait_time_for_instance_termination/3","title":"AWS.CodeDeploy.skip_wait_time_for_instance_termination/3","type":"function","doc":"In a blue/green deployment, overrides any specified wait time and starts terminating instances immediately after the traffic routing is complete."},{"ref":"AWS.CodeDeploy.html#stop_deployment/3","title":"AWS.CodeDeploy.stop_deployment/3","type":"function","doc":"Attempts to stop an ongoing deployment."},{"ref":"AWS.CodeDeploy.html#tag_resource/3","title":"AWS.CodeDeploy.tag_resource/3","type":"function","doc":"Associates the list of tags in the input Tags parameter with the resource identified by the ResourceArn input parameter."},{"ref":"AWS.CodeDeploy.html#untag_resource/3","title":"AWS.CodeDeploy.untag_resource/3","type":"function","doc":"Disassociates a resource from a list of tags. The resource is identified by the ResourceArn input parameter. The tags are identified by the list of keys in the TagKeys input parameter."},{"ref":"AWS.CodeDeploy.html#update_application/3","title":"AWS.CodeDeploy.update_application/3","type":"function","doc":"Changes the name of an application."},{"ref":"AWS.CodeDeploy.html#update_deployment_group/3","title":"AWS.CodeDeploy.update_deployment_group/3","type":"function","doc":"Changes information about a deployment group."},{"ref":"AWS.CodeGuruProfiler.html","title":"AWS.CodeGuruProfiler","type":"module","doc":"This section provides documentation for the Amazon CodeGuru Profiler API operations. Amazon CodeGuru Profiler collects runtime performance data from your live applications, and provides recommendations that can help you fine-tune your application performance. Using machine learning algorithms, CodeGuru Profiler can help you find your most expensive lines of code and suggest ways you can improve efficiency and remove CPU bottlenecks. Amazon CodeGuru Profiler provides different visualizations of profiling data to help you identify what code is running on the CPU, see how much time is consumed, and suggest ways to reduce CPU utilization. Amazon CodeGuru Profiler currently supports applications written in all Java virtual machine (JVM) languages. While CodeGuru Profiler supports both visualizations and recommendations for applications written in Java, it can also generate visualizations and a subset of recommendations for applications written in other JVM languages. For more information, see [What is Amazon CodeGuru Profiler](https://docs.aws.amazon.com/codeguru/latest/profiler-ug/what-is-codeguru-profiler.html) in the *Amazon CodeGuru Profiler User Guide*."},{"ref":"AWS.CodeGuruProfiler.html#add_notification_channels/4","title":"AWS.CodeGuruProfiler.add_notification_channels/4","type":"function","doc":"Add up to 2 anomaly notifications channels for a profiling group."},{"ref":"AWS.CodeGuruProfiler.html#batch_get_frame_metric_data/4","title":"AWS.CodeGuruProfiler.batch_get_frame_metric_data/4","type":"function","doc":"Returns the time series of values for a requested list of frame metrics from a time period."},{"ref":"AWS.CodeGuruProfiler.html#configure_agent/4","title":"AWS.CodeGuruProfiler.configure_agent/4","type":"function","doc":"Used by profiler agents to report their current state and to receive remote configuration updates. For example, ConfigureAgent can be used to tell and agent whether to profile or not and for how long to return profiling data."},{"ref":"AWS.CodeGuruProfiler.html#create_profiling_group/3","title":"AWS.CodeGuruProfiler.create_profiling_group/3","type":"function","doc":"Creates a profiling group."},{"ref":"AWS.CodeGuruProfiler.html#delete_profiling_group/4","title":"AWS.CodeGuruProfiler.delete_profiling_group/4","type":"function","doc":"Deletes a profiling group."},{"ref":"AWS.CodeGuruProfiler.html#describe_profiling_group/3","title":"AWS.CodeGuruProfiler.describe_profiling_group/3","type":"function","doc":"Returns a ProfilingGroupDescription object that contains information about the requested profiling group."},{"ref":"AWS.CodeGuruProfiler.html#get_findings_report_account_summary/5","title":"AWS.CodeGuruProfiler.get_findings_report_account_summary/5","type":"function","doc":"Returns a list of FindingsReportSummary objects that contain analysis results for all profiling groups in your AWS account."},{"ref":"AWS.CodeGuruProfiler.html#get_notification_configuration/3","title":"AWS.CodeGuruProfiler.get_notification_configuration/3","type":"function","doc":"Get the current configuration for anomaly notifications for a profiling group."},{"ref":"AWS.CodeGuruProfiler.html#get_policy/3","title":"AWS.CodeGuruProfiler.get_policy/3","type":"function","doc":"Returns the JSON-formatted resource-based policy on a profiling group."},{"ref":"AWS.CodeGuruProfiler.html#get_profile/8","title":"AWS.CodeGuruProfiler.get_profile/8","type":"function","doc":"Gets the aggregated profile of a profiling group for a specified time range. Amazon CodeGuru Profiler collects posted agent profiles for a profiling group into aggregated profiles. Because aggregated profiles expire over timeGetProfileis not idempotent. Specify the time range for the requested aggregated profile using 1 or 2 of the following parameters:startTime,endTime,period. The maximum time range allowed is 7 days. If you specify all 3 parameters, an exception is thrown. If you specify onlyperiod, the latest aggregated profile is returned. Aggregated profiles are available with aggregation periods of 5 minutes, 1 hour, and 1 day, aligned to UTC. The aggregation period of an aggregated profile determines how long it is retained. For more information, see [AggregatedProfileTime](https://docs.aws.amazon.com/codeguru/latest/profiler-api/API_AggregatedProfileTime.html). The aggregated profile&#39;s aggregation period determines how long it is retained by CodeGuru Profiler. * If the aggregation period is 5 minutes, the aggregated profile is retained for 15 days. * If the aggregation period is 1 hour, the aggregated profile is retained for 60 days. * If the aggregation period is 1 day, the aggregated profile is retained for 3 years. There are two use cases for callingGetProfile. 1. If you want to return an aggregated profile that already exists, use [ListProfileTimes](https://docs.aws.amazon.com/codeguru/latest/profiler-api/API_ListProfileTimes.html) to view the time ranges of existing aggregated profiles. Use them in aGetProfilerequest to return a specific, existing aggregated profile. 2. If you want to return an aggregated profile for a time range that doesn&#39;t align with an existing aggregated profile, then CodeGuru Profiler makes a best effort to combine existing aggregated profiles from the requested time range and return them as one aggregated profile. If aggregated profiles do not exist for the full time range requested, then aggregated profiles for a smaller time range are returned. For example, if the requested time range is from 00:00 to 00:20, and the existing aggregated profiles are from 00:15 and 00:25, then the aggregated profiles from 00:15 to 00:20 are returned."},{"ref":"AWS.CodeGuruProfiler.html#get_recommendations/6","title":"AWS.CodeGuruProfiler.get_recommendations/6","type":"function","doc":"Returns a list of Recommendation objects that contain recommendations for a profiling group for a given time period. A list of Anomaly objects that contains details about anomalies detected in the profiling group for the same time period is also returned."},{"ref":"AWS.CodeGuruProfiler.html#list_findings_reports/8","title":"AWS.CodeGuruProfiler.list_findings_reports/8","type":"function","doc":"List the available reports for a given profiling group and time range."},{"ref":"AWS.CodeGuruProfiler.html#list_profile_times/9","title":"AWS.CodeGuruProfiler.list_profile_times/9","type":"function","doc":"Lists the start times of the available aggregated profiles of a profiling group for an aggregation period within the specified time range."},{"ref":"AWS.CodeGuruProfiler.html#list_profiling_groups/5","title":"AWS.CodeGuruProfiler.list_profiling_groups/5","type":"function","doc":"Returns a list of profiling groups. The profiling groups are returned as ProfilingGroupDescription objects."},{"ref":"AWS.CodeGuruProfiler.html#list_tags_for_resource/3","title":"AWS.CodeGuruProfiler.list_tags_for_resource/3","type":"function","doc":"Returns a list of the tags that are assigned to a specified resource."},{"ref":"AWS.CodeGuruProfiler.html#post_agent_profile/4","title":"AWS.CodeGuruProfiler.post_agent_profile/4","type":"function","doc":"Submits profiling data to an aggregated profile of a profiling group. To get an aggregated profile that is created with this profiling data, use GetProfile ."},{"ref":"AWS.CodeGuruProfiler.html#put_permission/5","title":"AWS.CodeGuruProfiler.put_permission/5","type":"function","doc":"Adds permissions to a profiling group&#39;s resource-based policy that are provided using an action group. If a profiling group doesn&#39;t have a resource-based policy, one is created for it using the permissions in the action group and the roles and users in the principals parameter. The one supported action group that can be added isagentPermissionwhich grantsConfigureAgentandPostAgentpermissions. For more information, see [Resource-based policies in CodeGuru Profiler](https://docs.aws.amazon.com/codeguru/latest/profiler-ug/resource-based-policies.html) in the *Amazon CodeGuru Profiler User Guide*, [ConfigureAgent](https://docs.aws.amazon.com/codeguru/latest/profiler-api/API_ConfigureAgent.html), and [PostAgentProfile](https://docs.aws.amazon.com/codeguru/latest/profiler-api/API_PostAgentProfile.html). The first time you callPutPermissionon a profiling group, do not specify arevisionIdbecause it doesn&#39;t have a resource-based policy. Subsequent calls must provide arevisionIdto specify which revision of the resource-based policy to add the permissions to. The response contains the profiling group&#39;s JSON-formatted resource policy."},{"ref":"AWS.CodeGuruProfiler.html#remove_notification_channel/5","title":"AWS.CodeGuruProfiler.remove_notification_channel/5","type":"function","doc":"Remove one anomaly notifications channel for a profiling group."},{"ref":"AWS.CodeGuruProfiler.html#remove_permission/5","title":"AWS.CodeGuruProfiler.remove_permission/5","type":"function","doc":"Removes permissions from a profiling group&#39;s resource-based policy that are provided using an action group. The one supported action group that can be removed is agentPermission which grants ConfigureAgent and PostAgent permissions. For more information, see Resource-based policies in CodeGuru Profiler in the Amazon CodeGuru Profiler User Guide, ConfigureAgent , and PostAgentProfile ."},{"ref":"AWS.CodeGuruProfiler.html#submit_feedback/5","title":"AWS.CodeGuruProfiler.submit_feedback/5","type":"function","doc":"Sends feedback to CodeGuru Profiler about whether the anomaly detected by the analysis is useful or not."},{"ref":"AWS.CodeGuruProfiler.html#tag_resource/4","title":"AWS.CodeGuruProfiler.tag_resource/4","type":"function","doc":"Use to assign one or more tags to a resource."},{"ref":"AWS.CodeGuruProfiler.html#untag_resource/4","title":"AWS.CodeGuruProfiler.untag_resource/4","type":"function","doc":"Use to remove one or more tags from a resource."},{"ref":"AWS.CodeGuruProfiler.html#update_profiling_group/4","title":"AWS.CodeGuruProfiler.update_profiling_group/4","type":"function","doc":"Updates a profiling group."},{"ref":"AWS.CodeGuruReviewer.html","title":"AWS.CodeGuruReviewer","type":"module","doc":"This section provides documentation for the Amazon CodeGuru Reviewer API operations. CodeGuru Reviewer is a service that uses program analysis and machine learning to detect potential defects that are difficult for developers to find and recommends fixes in your Java code. By proactively detecting and providing recommendations for addressing code defects and implementing best practices, CodeGuru Reviewer improves the overall quality and maintainability of your code base during the code review stage. For more information about CodeGuru Reviewer, see the Amazon CodeGuru Reviewer User Guide.*"},{"ref":"AWS.CodeGuruReviewer.html#associate_repository/3","title":"AWS.CodeGuruReviewer.associate_repository/3","type":"function","doc":"Use to associate an AWS CodeCommit repository or a repostory managed by AWS CodeStar Connections with Amazon CodeGuru Reviewer. When you associate a repository, CodeGuru Reviewer reviews source code changes in the repository&#39;s pull requests and provides automatic recommendations. You can view recommendations using the CodeGuru Reviewer console. For more information, see Recommendations in Amazon CodeGuru Reviewer in the Amazon CodeGuru Reviewer User Guide. If you associate a CodeCommit repository, it must be in the same AWS Region and AWS account where its CodeGuru Reviewer code reviews are configured. Bitbucket and GitHub Enterprise Server repositories are managed by AWS CodeStar Connections to connect to CodeGuru Reviewer. For more information, see Connect to a repository source provider in the Amazon CodeGuru Reviewer User Guide. You cannot use the CodeGuru Reviewer SDK or the AWS CLI to associate a GitHub repository with Amazon CodeGuru Reviewer. To associate a GitHub repository, use the console. For more information, see Getting started with CodeGuru Reviewer in the CodeGuru Reviewer User Guide."},{"ref":"AWS.CodeGuruReviewer.html#create_code_review/3","title":"AWS.CodeGuruReviewer.create_code_review/3","type":"function","doc":"Use to create a code review for a repository analysis."},{"ref":"AWS.CodeGuruReviewer.html#describe_code_review/3","title":"AWS.CodeGuruReviewer.describe_code_review/3","type":"function","doc":"Returns the metadata associated with the code review along with its status."},{"ref":"AWS.CodeGuruReviewer.html#describe_recommendation_feedback/5","title":"AWS.CodeGuruReviewer.describe_recommendation_feedback/5","type":"function","doc":"Describes the customer feedback for a CodeGuru Reviewer recommendation."},{"ref":"AWS.CodeGuruReviewer.html#describe_repository_association/3","title":"AWS.CodeGuruReviewer.describe_repository_association/3","type":"function","doc":"Returns a RepositoryAssociation object that contains information about the requested repository association."},{"ref":"AWS.CodeGuruReviewer.html#disassociate_repository/4","title":"AWS.CodeGuruReviewer.disassociate_repository/4","type":"function","doc":"Removes the association between Amazon CodeGuru Reviewer and a repository."},{"ref":"AWS.CodeGuruReviewer.html#list_code_reviews/8","title":"AWS.CodeGuruReviewer.list_code_reviews/8","type":"function","doc":"Lists all the code reviews that the customer has created in the past 90 days."},{"ref":"AWS.CodeGuruReviewer.html#list_recommendation_feedback/7","title":"AWS.CodeGuruReviewer.list_recommendation_feedback/7","type":"function","doc":"Returns a list of RecommendationFeedbackSummary objects that contain customer recommendation feedback for all CodeGuru Reviewer users."},{"ref":"AWS.CodeGuruReviewer.html#list_recommendations/5","title":"AWS.CodeGuruReviewer.list_recommendations/5","type":"function","doc":"Returns the list of all recommendations for a completed code review."},{"ref":"AWS.CodeGuruReviewer.html#list_repository_associations/8","title":"AWS.CodeGuruReviewer.list_repository_associations/8","type":"function","doc":"Returns a list of RepositoryAssociationSummary objects that contain summary information about a repository association. You can filter the returned list by ProviderType , Name , State , and Owner ."},{"ref":"AWS.CodeGuruReviewer.html#put_recommendation_feedback/3","title":"AWS.CodeGuruReviewer.put_recommendation_feedback/3","type":"function","doc":"Stores customer feedback for a CodeGuru Reviewer recommendation. When this API is called again with different reactions the previous feedback is overwritten."},{"ref":"AWS.CodePipeline.html","title":"AWS.CodePipeline","type":"module","doc":"AWS CodePipeline Overview This is the AWS CodePipeline API Reference. This guide provides descriptions of the actions and data types for AWS CodePipeline. Some functionality for your pipeline can only be configured through the API. For more information, see the AWS CodePipeline User Guide. You can use the AWS CodePipeline API to work with pipelines, stages, actions, and transitions. Pipelines are models of automated release processes. Each pipeline is uniquely named, and consists of stages, actions, and transitions. You can work with pipelines by calling: CreatePipeline, which creates a uniquely named pipeline. DeletePipeline, which deletes the specified pipeline. GetPipeline, which returns information about the pipeline structure and pipeline metadata, including the pipeline Amazon Resource Name (ARN). GetPipelineExecution, which returns information about a specific execution of a pipeline. GetPipelineState, which returns information about the current state of the stages and actions of a pipeline. ListActionExecutions, which returns action-level details for past executions. The details include full stage and action-level details, including individual action duration, status, any errors that occurred during the execution, and input and output artifact location details. ListPipelines, which gets a summary of all of the pipelines associated with your account. ListPipelineExecutions, which gets a summary of the most recent executions for a pipeline. StartPipelineExecution, which runs the most recent revision of an artifact through the pipeline. StopPipelineExecution, which stops the specified pipeline execution from continuing through the pipeline. UpdatePipeline, which updates a pipeline with edits or changes to the structure of the pipeline. Pipelines include stages. Each stage contains one or more actions that must complete before the next stage begins. A stage results in success or failure. If a stage fails, the pipeline stops at that stage and remains stopped until either a new version of an artifact appears in the source location, or a user takes action to rerun the most recent artifact through the pipeline. You can call GetPipelineState, which displays the status of a pipeline, including the status of stages in the pipeline, or GetPipeline, which returns the entire structure of the pipeline, including the stages of that pipeline. For more information about the structure of stages and actions, see AWS CodePipeline Pipeline Structure Reference. Pipeline stages include actions that are categorized into categories such as source or build actions performed in a stage of a pipeline. For example, you can use a source action to import artifacts into a pipeline from a source such as Amazon S3. Like stages, you do not work with actions directly in most cases, but you do define and interact with actions when working with pipeline operations such as CreatePipeline and GetPipelineState. Valid action categories are: Source Build Test Deploy Approval Invoke Pipelines also include transitions, which allow the transition of artifacts from one stage to the next in a pipeline after the actions in one stage complete. You can work with transitions by calling: DisableStageTransition, which prevents artifacts from transitioning to the next stage in a pipeline. EnableStageTransition, which enables transition of artifacts between stages in a pipeline. Using the API to integrate with AWS CodePipeline For third-party integrators or developers who want to create their own integrations with AWS CodePipeline, the expected sequence varies from the standard API user. To integrate with AWS CodePipeline, developers need to work with the following items: Jobs, which are instances of an action. For example, a job for a source action might import a revision of an artifact from a source. You can work with jobs by calling: AcknowledgeJob, which confirms whether a job worker has received the specified job. GetJobDetails, which returns the details of a job. PollForJobs, which determines whether there are any jobs to act on. PutJobFailureResult, which provides details of a job failure. PutJobSuccessResult, which provides details of a job success. Third party jobs, which are instances of an action created by a partner action and integrated into AWS CodePipeline. Partner actions are created by members of the AWS Partner Network. You can work with third party jobs by calling: AcknowledgeThirdPartyJob, which confirms whether a job worker has received the specified job. GetThirdPartyJobDetails, which requests the details of a job for a partner action. PollForThirdPartyJobs, which determines whether there are any jobs to act on. PutThirdPartyJobFailureResult, which provides details of a job failure. PutThirdPartyJobSuccessResult, which provides details of a job success."},{"ref":"AWS.CodePipeline.html#acknowledge_job/3","title":"AWS.CodePipeline.acknowledge_job/3","type":"function","doc":"Returns information about a specified job and whether that job has been received by the job worker. Used for custom actions only."},{"ref":"AWS.CodePipeline.html#acknowledge_third_party_job/3","title":"AWS.CodePipeline.acknowledge_third_party_job/3","type":"function","doc":"Confirms a job worker has received the specified job. Used for partner actions only."},{"ref":"AWS.CodePipeline.html#create_custom_action_type/3","title":"AWS.CodePipeline.create_custom_action_type/3","type":"function","doc":"Creates a new custom action that can be used in all pipelines associated with the AWS account. Only used for custom actions."},{"ref":"AWS.CodePipeline.html#create_pipeline/3","title":"AWS.CodePipeline.create_pipeline/3","type":"function","doc":"Creates a pipeline. In the pipeline structure, you must include either artifactStore or artifactStores in your pipeline, but you cannot use both. If you create a cross-region action in your pipeline, you must use artifactStores."},{"ref":"AWS.CodePipeline.html#delete_custom_action_type/3","title":"AWS.CodePipeline.delete_custom_action_type/3","type":"function","doc":"Marks a custom action as deleted. PollForJobs for the custom action fails after the action is marked for deletion. Used for custom actions only. To re-create a custom action after it has been deleted you must use a string in the version field that has never been used before. This string can be an incremented version number, for example. To restore a deleted custom action, use a JSON file that is identical to the deleted action, including the original string in the version field."},{"ref":"AWS.CodePipeline.html#delete_pipeline/3","title":"AWS.CodePipeline.delete_pipeline/3","type":"function","doc":"Deletes the specified pipeline."},{"ref":"AWS.CodePipeline.html#delete_webhook/3","title":"AWS.CodePipeline.delete_webhook/3","type":"function","doc":"Deletes a previously created webhook by name. Deleting the webhook stops AWS CodePipeline from starting a pipeline every time an external event occurs. The API returns successfully when trying to delete a webhook that is already deleted. If a deleted webhook is re-created by calling PutWebhook with the same name, it will have a different URL."},{"ref":"AWS.CodePipeline.html#deregister_webhook_with_third_party/3","title":"AWS.CodePipeline.deregister_webhook_with_third_party/3","type":"function","doc":"Removes the connection between the webhook that was created by CodePipeline and the external tool with events to be detected. Currently supported only for webhooks that target an action type of GitHub."},{"ref":"AWS.CodePipeline.html#disable_stage_transition/3","title":"AWS.CodePipeline.disable_stage_transition/3","type":"function","doc":"Prevents artifacts in a pipeline from transitioning to the next stage in the pipeline."},{"ref":"AWS.CodePipeline.html#enable_stage_transition/3","title":"AWS.CodePipeline.enable_stage_transition/3","type":"function","doc":"Enables artifacts in a pipeline to transition to a stage in a pipeline."},{"ref":"AWS.CodePipeline.html#get_job_details/3","title":"AWS.CodePipeline.get_job_details/3","type":"function","doc":"Returns information about a job. Used for custom actions only. When this API is called, AWS CodePipeline returns temporary credentials for the S3 bucket used to store artifacts for the pipeline, if the action requires access to that S3 bucket for input or output artifacts. This API also returns any secret values defined for the action."},{"ref":"AWS.CodePipeline.html#get_pipeline/3","title":"AWS.CodePipeline.get_pipeline/3","type":"function","doc":"Returns the metadata, structure, stages, and actions of a pipeline. Can be used to return the entire structure of a pipeline in JSON format, which can then be modified and used to update the pipeline structure with UpdatePipeline."},{"ref":"AWS.CodePipeline.html#get_pipeline_execution/3","title":"AWS.CodePipeline.get_pipeline_execution/3","type":"function","doc":"Returns information about an execution of a pipeline, including details about artifacts, the pipeline execution ID, and the name, version, and status of the pipeline."},{"ref":"AWS.CodePipeline.html#get_pipeline_state/3","title":"AWS.CodePipeline.get_pipeline_state/3","type":"function","doc":"Returns information about the state of a pipeline, including the stages and actions. Values returned in the revisionId and revisionUrl fields indicate the source revision information, such as the commit ID, for the current state."},{"ref":"AWS.CodePipeline.html#get_third_party_job_details/3","title":"AWS.CodePipeline.get_third_party_job_details/3","type":"function","doc":"Requests the details of a job for a third party action. Used for partner actions only. When this API is called, AWS CodePipeline returns temporary credentials for the S3 bucket used to store artifacts for the pipeline, if the action requires access to that S3 bucket for input or output artifacts. This API also returns any secret values defined for the action."},{"ref":"AWS.CodePipeline.html#list_action_executions/3","title":"AWS.CodePipeline.list_action_executions/3","type":"function","doc":"Lists the action executions that have occurred in a pipeline."},{"ref":"AWS.CodePipeline.html#list_action_types/3","title":"AWS.CodePipeline.list_action_types/3","type":"function","doc":"Gets a summary of all AWS CodePipeline action types associated with your account."},{"ref":"AWS.CodePipeline.html#list_pipeline_executions/3","title":"AWS.CodePipeline.list_pipeline_executions/3","type":"function","doc":"Gets a summary of the most recent executions for a pipeline."},{"ref":"AWS.CodePipeline.html#list_pipelines/3","title":"AWS.CodePipeline.list_pipelines/3","type":"function","doc":"Gets a summary of all of the pipelines associated with your account."},{"ref":"AWS.CodePipeline.html#list_tags_for_resource/3","title":"AWS.CodePipeline.list_tags_for_resource/3","type":"function","doc":"Gets the set of key-value pairs (metadata) that are used to manage the resource."},{"ref":"AWS.CodePipeline.html#list_webhooks/3","title":"AWS.CodePipeline.list_webhooks/3","type":"function","doc":"Gets a listing of all the webhooks in this AWS Region for this account. The output lists all webhooks and includes the webhook URL and ARN and the configuration for each webhook."},{"ref":"AWS.CodePipeline.html#poll_for_jobs/3","title":"AWS.CodePipeline.poll_for_jobs/3","type":"function","doc":"Returns information about any jobs for AWS CodePipeline to act on. PollForJobs is valid only for action types with &quot;Custom&quot; in the owner field. If the action type contains &quot;AWS&quot; or &quot;ThirdParty&quot; in the owner field, the PollForJobs action returns an error. When this API is called, AWS CodePipeline returns temporary credentials for the S3 bucket used to store artifacts for the pipeline, if the action requires access to that S3 bucket for input or output artifacts. This API also returns any secret values defined for the action."},{"ref":"AWS.CodePipeline.html#poll_for_third_party_jobs/3","title":"AWS.CodePipeline.poll_for_third_party_jobs/3","type":"function","doc":"Determines whether there are any third party jobs for a job worker to act on. Used for partner actions only. When this API is called, AWS CodePipeline returns temporary credentials for the S3 bucket used to store artifacts for the pipeline, if the action requires access to that S3 bucket for input or output artifacts."},{"ref":"AWS.CodePipeline.html#put_action_revision/3","title":"AWS.CodePipeline.put_action_revision/3","type":"function","doc":"Provides information to AWS CodePipeline about new revisions to a source."},{"ref":"AWS.CodePipeline.html#put_approval_result/3","title":"AWS.CodePipeline.put_approval_result/3","type":"function","doc":"Provides the response to a manual approval request to AWS CodePipeline. Valid responses include Approved and Rejected."},{"ref":"AWS.CodePipeline.html#put_job_failure_result/3","title":"AWS.CodePipeline.put_job_failure_result/3","type":"function","doc":"Represents the failure of a job as returned to the pipeline by a job worker. Used for custom actions only."},{"ref":"AWS.CodePipeline.html#put_job_success_result/3","title":"AWS.CodePipeline.put_job_success_result/3","type":"function","doc":"Represents the success of a job as returned to the pipeline by a job worker. Used for custom actions only."},{"ref":"AWS.CodePipeline.html#put_third_party_job_failure_result/3","title":"AWS.CodePipeline.put_third_party_job_failure_result/3","type":"function","doc":"Represents the failure of a third party job as returned to the pipeline by a job worker. Used for partner actions only."},{"ref":"AWS.CodePipeline.html#put_third_party_job_success_result/3","title":"AWS.CodePipeline.put_third_party_job_success_result/3","type":"function","doc":"Represents the success of a third party job as returned to the pipeline by a job worker. Used for partner actions only."},{"ref":"AWS.CodePipeline.html#put_webhook/3","title":"AWS.CodePipeline.put_webhook/3","type":"function","doc":"Defines a webhook and returns a unique webhook URL generated by CodePipeline. This URL can be supplied to third party source hosting providers to call every time there&#39;s a code change. When CodePipeline receives a POST request on this URL, the pipeline defined in the webhook is started as long as the POST request satisfied the authentication and filtering requirements supplied when defining the webhook. RegisterWebhookWithThirdParty and DeregisterWebhookWithThirdParty APIs can be used to automatically configure supported third parties to call the generated webhook URL."},{"ref":"AWS.CodePipeline.html#register_webhook_with_third_party/3","title":"AWS.CodePipeline.register_webhook_with_third_party/3","type":"function","doc":"Configures a connection between the webhook that was created and the external tool with events to be detected."},{"ref":"AWS.CodePipeline.html#retry_stage_execution/3","title":"AWS.CodePipeline.retry_stage_execution/3","type":"function","doc":"Resumes the pipeline execution by retrying the last failed actions in a stage. You can retry a stage immediately if any of the actions in the stage fail. When you retry, all actions that are still in progress continue working, and failed actions are triggered again."},{"ref":"AWS.CodePipeline.html#start_pipeline_execution/3","title":"AWS.CodePipeline.start_pipeline_execution/3","type":"function","doc":"Starts the specified pipeline. Specifically, it begins processing the latest commit to the source location specified as part of the pipeline."},{"ref":"AWS.CodePipeline.html#stop_pipeline_execution/3","title":"AWS.CodePipeline.stop_pipeline_execution/3","type":"function","doc":"Stops the specified pipeline execution. You choose to either stop the pipeline execution by completing in-progress actions without starting subsequent actions, or by abandoning in-progress actions. While completing or abandoning in-progress actions, the pipeline execution is in a Stopping state. After all in-progress actions are completed or abandoned, the pipeline execution is in a Stopped state."},{"ref":"AWS.CodePipeline.html#tag_resource/3","title":"AWS.CodePipeline.tag_resource/3","type":"function","doc":"Adds to or modifies the tags of the given resource. Tags are metadata that can be used to manage a resource."},{"ref":"AWS.CodePipeline.html#untag_resource/3","title":"AWS.CodePipeline.untag_resource/3","type":"function","doc":"Removes tags from an AWS resource."},{"ref":"AWS.CodePipeline.html#update_pipeline/3","title":"AWS.CodePipeline.update_pipeline/3","type":"function","doc":"Updates a specified pipeline with edits or changes to its structure. Use a JSON file with the pipeline structure and UpdatePipeline to provide the full structure of the pipeline. Updating the pipeline increases the version number of the pipeline by 1."},{"ref":"AWS.CodeStar.html","title":"AWS.CodeStar","type":"module","doc":"AWS CodeStar This is the API reference for AWS CodeStar. This reference provides descriptions of the operations and data types for the AWS CodeStar API along with usage examples. You can use the AWS CodeStar API to work with: Projects and their resources, by calling the following: DeleteProject, which deletes a project. DescribeProject, which lists the attributes of a project. ListProjects, which lists all projects associated with your AWS account. ListResources, which lists the resources associated with a project. ListTagsForProject, which lists the tags associated with a project. TagProject, which adds tags to a project. UntagProject, which removes tags from a project. UpdateProject, which updates the attributes of a project. Teams and team members, by calling the following: AssociateTeamMember, which adds an IAM user to the team for a project. DisassociateTeamMember, which removes an IAM user from the team for a project. ListTeamMembers, which lists all the IAM users in the team for a project, including their roles and attributes. UpdateTeamMember, which updates a team member&#39;s attributes in a project. Users, by calling the following: CreateUserProfile, which creates a user profile that contains data associated with the user across all projects. DeleteUserProfile, which deletes all user profile information across all projects. DescribeUserProfile, which describes the profile of a user. ListUserProfiles, which lists all user profiles. UpdateUserProfile, which updates the profile for a user."},{"ref":"AWS.CodeStar.html#associate_team_member/3","title":"AWS.CodeStar.associate_team_member/3","type":"function","doc":"Adds an IAM user to the team for an AWS CodeStar project."},{"ref":"AWS.CodeStar.html#create_project/3","title":"AWS.CodeStar.create_project/3","type":"function","doc":"Creates a project, including project resources. This action creates a project based on a submitted project request. A set of source code files and a toolchain template file can be included with the project request. If these are not provided, an empty project is created."},{"ref":"AWS.CodeStar.html#create_user_profile/3","title":"AWS.CodeStar.create_user_profile/3","type":"function","doc":"Creates a profile for a user that includes user preferences, such as the display name and email address assocciated with the user, in AWS CodeStar. The user profile is not project-specific. Information in the user profile is displayed wherever the user&#39;s information appears to other users in AWS CodeStar."},{"ref":"AWS.CodeStar.html#delete_project/3","title":"AWS.CodeStar.delete_project/3","type":"function","doc":"Deletes a project, including project resources. Does not delete users associated with the project, but does delete the IAM roles that allowed access to the project."},{"ref":"AWS.CodeStar.html#delete_user_profile/3","title":"AWS.CodeStar.delete_user_profile/3","type":"function","doc":"Deletes a user profile in AWS CodeStar, including all personal preference data associated with that profile, such as display name and email address. It does not delete the history of that user, for example the history of commits made by that user."},{"ref":"AWS.CodeStar.html#describe_project/3","title":"AWS.CodeStar.describe_project/3","type":"function","doc":"Describes a project and its resources."},{"ref":"AWS.CodeStar.html#describe_user_profile/3","title":"AWS.CodeStar.describe_user_profile/3","type":"function","doc":"Describes a user in AWS CodeStar and the user attributes across all projects."},{"ref":"AWS.CodeStar.html#disassociate_team_member/3","title":"AWS.CodeStar.disassociate_team_member/3","type":"function","doc":"Removes a user from a project. Removing a user from a project also removes the IAM policies from that user that allowed access to the project and its resources. Disassociating a team member does not remove that user&#39;s profile from AWS CodeStar. It does not remove the user from IAM."},{"ref":"AWS.CodeStar.html#list_projects/3","title":"AWS.CodeStar.list_projects/3","type":"function","doc":"Lists all projects in AWS CodeStar associated with your AWS account."},{"ref":"AWS.CodeStar.html#list_resources/3","title":"AWS.CodeStar.list_resources/3","type":"function","doc":"Lists resources associated with a project in AWS CodeStar."},{"ref":"AWS.CodeStar.html#list_tags_for_project/3","title":"AWS.CodeStar.list_tags_for_project/3","type":"function","doc":"Gets the tags for a project."},{"ref":"AWS.CodeStar.html#list_team_members/3","title":"AWS.CodeStar.list_team_members/3","type":"function","doc":"Lists all team members associated with a project."},{"ref":"AWS.CodeStar.html#list_user_profiles/3","title":"AWS.CodeStar.list_user_profiles/3","type":"function","doc":"Lists all the user profiles configured for your AWS account in AWS CodeStar."},{"ref":"AWS.CodeStar.html#tag_project/3","title":"AWS.CodeStar.tag_project/3","type":"function","doc":"Adds tags to a project."},{"ref":"AWS.CodeStar.html#untag_project/3","title":"AWS.CodeStar.untag_project/3","type":"function","doc":"Removes tags from a project."},{"ref":"AWS.CodeStar.html#update_project/3","title":"AWS.CodeStar.update_project/3","type":"function","doc":"Updates a project in AWS CodeStar."},{"ref":"AWS.CodeStar.html#update_team_member/3","title":"AWS.CodeStar.update_team_member/3","type":"function","doc":"Updates a team member&#39;s attributes in an AWS CodeStar project. For example, you can change a team member&#39;s role in the project, or change whether they have remote access to project resources."},{"ref":"AWS.CodeStar.html#update_user_profile/3","title":"AWS.CodeStar.update_user_profile/3","type":"function","doc":"Updates a user&#39;s profile in AWS CodeStar. The user profile is not project-specific. Information in the user profile is displayed wherever the user&#39;s information appears to other users in AWS CodeStar."},{"ref":"AWS.CodeStarConnections.html","title":"AWS.CodeStarConnections","type":"module","doc":"AWS CodeStar Connections The CodeStar Connections feature is in preview release and is subject to change. This AWS CodeStar Connections API Reference provides descriptions and usage examples of the operations and data types for the AWS CodeStar Connections API. You can use the connections API to work with connections and installations. Connections are configurations that you use to connect AWS resources to external code repositories. Each connection is a resource that can be given to services such as CodePipeline to connect to a third-party repository such as Bitbucket. For example, you can add the connection in CodePipeline so that it triggers your pipeline when a code change is made to your third-party code repository. Each connection is named and associated with a unique ARN that is used to reference the connection. When you create a connection, the console initiates a third-party connection handshake. Installations are the apps that are used to conduct this handshake. For example, the installation for the Bitbucket provider type is the Bitbucket Cloud app. When you create a connection, you can choose an existing installation or create one. When you want to create a connection to an installed provider type such as GitHub Enterprise Server, you create a host for your connections. You can work with connections by calling: CreateConnection, which creates a uniquely named connection that can be referenced by services such as CodePipeline. DeleteConnection, which deletes the specified connection. GetConnection, which returns information about the connection, including the connection status. ListConnections, which lists the connections associated with your account. You can work with hosts by calling: CreateHost, which creates a host that represents the infrastructure where your provider is installed. DeleteHost, which deletes the specified host. GetHost, which returns information about the host, including the setup status. ListHosts, which lists the hosts associated with your account. You can work with tags in AWS CodeStar Connections by calling the following: ListTagsForResource, which gets information about AWS tags for a specified Amazon Resource Name (ARN) in AWS CodeStar Connections. TagResource, which adds or updates tags for a resource in AWS CodeStar Connections. UntagResource, which removes tags for a resource in AWS CodeStar Connections. For information about how to use AWS CodeStar Connections, see the Developer Tools User Guide."},{"ref":"AWS.CodeStarConnections.html#create_connection/3","title":"AWS.CodeStarConnections.create_connection/3","type":"function","doc":"Creates a connection that can then be given to other AWS services like CodePipeline so that it can access third-party code repositories. The connection is in pending status until the third-party connection handshake is completed from the console."},{"ref":"AWS.CodeStarConnections.html#create_host/3","title":"AWS.CodeStarConnections.create_host/3","type":"function","doc":"Creates a resource that represents the infrastructure where a third-party provider is installed. The host is used when you create connections to an installed third-party provider type, such as GitHub Enterprise Server. You create one host for all connections to that provider. A host created through the CLI or the SDK is in PENDING status by default. You can make its status AVAILABLE by setting up the host in the console."},{"ref":"AWS.CodeStarConnections.html#delete_connection/3","title":"AWS.CodeStarConnections.delete_connection/3","type":"function","doc":"The connection to be deleted."},{"ref":"AWS.CodeStarConnections.html#delete_host/3","title":"AWS.CodeStarConnections.delete_host/3","type":"function","doc":"The host to be deleted. Before you delete a host, all connections associated to the host must be deleted. A host cannot be deleted if it is in the VPC_CONFIG_INITIALIZING or VPC_CONFIG_DELETING state."},{"ref":"AWS.CodeStarConnections.html#get_connection/3","title":"AWS.CodeStarConnections.get_connection/3","type":"function","doc":"Returns the connection ARN and details such as status, owner, and provider type."},{"ref":"AWS.CodeStarConnections.html#get_host/3","title":"AWS.CodeStarConnections.get_host/3","type":"function","doc":"Returns the host ARN and details such as status, provider type, endpoint, and, if applicable, the VPC configuration."},{"ref":"AWS.CodeStarConnections.html#list_connections/3","title":"AWS.CodeStarConnections.list_connections/3","type":"function","doc":"Lists the connections associated with your account."},{"ref":"AWS.CodeStarConnections.html#list_hosts/3","title":"AWS.CodeStarConnections.list_hosts/3","type":"function","doc":"Lists the hosts associated with your account."},{"ref":"AWS.CodeStarConnections.html#list_tags_for_resource/3","title":"AWS.CodeStarConnections.list_tags_for_resource/3","type":"function","doc":"Gets the set of key-value pairs (metadata) that are used to manage the resource."},{"ref":"AWS.CodeStarConnections.html#tag_resource/3","title":"AWS.CodeStarConnections.tag_resource/3","type":"function","doc":"Adds to or modifies the tags of the given resource. Tags are metadata that can be used to manage a resource."},{"ref":"AWS.CodeStarConnections.html#untag_resource/3","title":"AWS.CodeStarConnections.untag_resource/3","type":"function","doc":"Removes tags from an AWS resource."},{"ref":"AWS.Codeartifact.html","title":"AWS.Codeartifact","type":"module","doc":"AWS CodeArtifact is a fully managed artifact repository compatible with language-native package managers and build tools such as npm, Apache Maven, and pip. You can use CodeArtifact to share packages with development teams and pull packages. Packages can be pulled from both public and CodeArtifact repositories. You can also create an upstream relationship between a CodeArtifact repository and another repository, which effectively merges their contents from the point of view of a package manager client. AWS CodeArtifact Components Use the information in this guide to help you work with the following CodeArtifact components: Repository: A CodeArtifact repository contains a set of package versions, each of which maps to a set of assets, or files. Repositories are polyglot, so a single repository can contain packages of any supported type. Each repository exposes endpoints for fetching and publishing packages using tools like the npm CLI, the Maven CLI ( mvn ), and pip . You can create up to 100 repositories per AWS account. Domain: Repositories are aggregated into a higher-level entity known as a domain. All package assets and metadata are stored in the domain, but are consumed through repositories. A given package asset, such as a Maven JAR file, is stored once per domain, no matter how many repositories it&#39;s present in. All of the assets and metadata in a domain are encrypted with the same customer master key (CMK) stored in AWS Key Management Service (AWS KMS). Each repository is a member of a single domain and can&#39;t be moved to a different domain. The domain allows organizational policy to be applied across multiple repositories, such as which accounts can access repositories in the domain, and which public repositories can be used as sources of packages. Although an organization can have multiple domains, we recommend a single production domain that contains all published artifacts so that teams can find and share packages across their organization. Package: A package is a bundle of software and the metadata required to resolve dependencies and install the software. CodeArtifact supports npm, PyPI, and Maven package formats. In CodeArtifact, a package consists of: A name (for example, webpack is the name of a popular npm package) An optional namespace (for example, @types in @types/node) A set of versions (for example, 1.0.0, 1.0.1, 1.0.2, etc.) Package-level metadata (for example, npm tags) Package version: A version of a package, such as @types/node 12.6.9. The version number format and semantics vary for different package formats. For example, npm package versions must conform to the Semantic Versioning specification. In CodeArtifact, a package version consists of the version identifier, metadata at the package version level, and a set of assets. Upstream repository: One repository is upstream of another when the package versions in it can be accessed from the repository endpoint of the downstream repository, effectively merging the contents of the two repositories from the point of view of a client. CodeArtifact allows creating an upstream relationship between two repositories. Asset: An individual file stored in CodeArtifact associated with a package version, such as an npm .tgz file or Maven POM and JAR files. CodeArtifact supports these operations: AssociateExternalConnection: Adds an existing external connection to a repository. CopyPackageVersions: Copies package versions from one repository to another repository in the same domain. CreateDomain: Creates a domain CreateRepository: Creates a CodeArtifact repository in a domain. DeleteDomain: Deletes a domain. You cannot delete a domain that contains repositories. DeleteDomainPermissionsPolicy: Deletes the resource policy that is set on a domain. DeletePackageVersions: Deletes versions of a package. After a package has been deleted, it can be republished, but its assets and metadata cannot be restored because they have been permanently removed from storage. DeleteRepository: Deletes a repository. DeleteRepositoryPermissionsPolicy: Deletes the resource policy that is set on a repository. DescribeDomain: Returns a DomainDescription object that contains information about the requested domain. DescribePackageVersion: Returns a [PackageVersionDescription](https://docs.aws.amazon.com/codeartifact/latest/APIReference/API_PackageVersionDescription.html) object that contains details about a package version. DescribeRepository: Returns a RepositoryDescription object that contains detailed information about the requested repository. DisposePackageVersions: Disposes versions of a package. A package version with the status Disposed cannot be restored because they have been permanently removed from storage. DisassociateExternalConnection: Removes an existing external connection from a repository. GetAuthorizationToken: Generates a temporary authorization token for accessing repositories in the domain. The token expires the authorization period has passed. The default authorization period is 12 hours and can be customized to any length with a maximum of 12 hours. GetDomainPermissionsPolicy: Returns the policy of a resource that is attached to the specified domain. GetPackageVersionAsset: Returns the contents of an asset that is in a package version. GetPackageVersionReadme: Gets the readme file or descriptive text for a package version. GetRepositoryEndpoint: Returns the endpoint of a repository for a specific package format. A repository has one endpoint for each package format: npm pypi maven GetRepositoryPermissionsPolicy: Returns the resource policy that is set on a repository. ListDomains: Returns a list of DomainSummary objects. Each returned DomainSummary object contains information about a domain. ListPackages: Lists the packages in a repository. ListPackageVersionAssets: Lists the assets for a given package version. ListPackageVersionDependencies: Returns a list of the direct dependencies for a package version. ListPackageVersions: Returns a list of package versions for a specified package in a repository. ListRepositories: Returns a list of repositories owned by the AWS account that called this method. ListRepositoriesInDomain: Returns a list of the repositories in a domain. PutDomainPermissionsPolicy: Attaches a resource policy to a domain. PutRepositoryPermissionsPolicy: Sets the resource policy on a repository that specifies permissions to access it. UpdatePackageVersionsStatus: Updates the status of one or more versions of a package. UpdateRepository: Updates the properties of a repository."},{"ref":"AWS.Codeartifact.html#associate_external_connection/3","title":"AWS.Codeartifact.associate_external_connection/3","type":"function","doc":"Adds an existing external connection to a repository. One external connection is allowed per repository. A repository can have one or more upstream repositories, or an external connection."},{"ref":"AWS.Codeartifact.html#copy_package_versions/3","title":"AWS.Codeartifact.copy_package_versions/3","type":"function","doc":"Copies package versions from one repository to another repository in the same domain. You must specify versions or versionRevisions. You cannot specify both."},{"ref":"AWS.Codeartifact.html#create_domain/3","title":"AWS.Codeartifact.create_domain/3","type":"function","doc":"Creates a domain. CodeArtifact domains make it easier to manage multiple repositories across an organization. You can use a domain to apply permissions across many repositories owned by different AWS accounts. An asset is stored only once in a domain, even if it&#39;s in multiple repositories. Although you can have multiple domains, we recommend a single production domain that contains all published artifacts so that your development teams can find and share packages. You can use a second pre-production domain to test changes to the production domain configuration."},{"ref":"AWS.Codeartifact.html#create_repository/3","title":"AWS.Codeartifact.create_repository/3","type":"function","doc":"Creates a repository."},{"ref":"AWS.Codeartifact.html#delete_domain/3","title":"AWS.Codeartifact.delete_domain/3","type":"function","doc":"Deletes a domain. You cannot delete a domain that contains repositories. If you want to delete a domain with repositories, first delete its repositories."},{"ref":"AWS.Codeartifact.html#delete_domain_permissions_policy/3","title":"AWS.Codeartifact.delete_domain_permissions_policy/3","type":"function","doc":"Deletes the resource policy set on a domain."},{"ref":"AWS.Codeartifact.html#delete_package_versions/3","title":"AWS.Codeartifact.delete_package_versions/3","type":"function","doc":"Deletes one or more versions of a package. A deleted package version cannot be restored in your repository. If you want to remove a package version from your repository and be able to restore it later, set its status to Archived. Archived packages cannot be downloaded from a repository and don&#39;t show up with list package APIs (for example, [ListackageVersions](https://docs.aws.amazon.com/codeartifact/latest/APIReference/API_ListPackageVersions.html)), but you can restore them using [UpdatePackageVersionsStatus](https://docs.aws.amazon.com/codeartifact/latest/APIReference/API_UpdatePackageVersionsStatus.html)."},{"ref":"AWS.Codeartifact.html#delete_repository/3","title":"AWS.Codeartifact.delete_repository/3","type":"function","doc":"Deletes a repository."},{"ref":"AWS.Codeartifact.html#delete_repository_permissions_policy/3","title":"AWS.Codeartifact.delete_repository_permissions_policy/3","type":"function","doc":"Deletes the resource policy that is set on a repository. After a resource policy is deleted, the permissions allowed and denied by the deleted policy are removed. The effect of deleting a resource policy might not be immediate. Use DeleteRepositoryPermissionsPolicy with caution. After a policy is deleted, AWS users, roles, and accounts lose permissions to perform the repository actions granted by the deleted policy."},{"ref":"AWS.Codeartifact.html#describe_domain/4","title":"AWS.Codeartifact.describe_domain/4","type":"function","doc":"Returns a DomainDescription object that contains information about the requested domain."},{"ref":"AWS.Codeartifact.html#describe_package_version/9","title":"AWS.Codeartifact.describe_package_version/9","type":"function","doc":"Returns a PackageVersionDescription object that contains information about the requested package version."},{"ref":"AWS.Codeartifact.html#describe_repository/5","title":"AWS.Codeartifact.describe_repository/5","type":"function","doc":"Returns a RepositoryDescription object that contains detailed information about the requested repository."},{"ref":"AWS.Codeartifact.html#disassociate_external_connection/3","title":"AWS.Codeartifact.disassociate_external_connection/3","type":"function","doc":"Removes an existing external connection from a repository."},{"ref":"AWS.Codeartifact.html#dispose_package_versions/3","title":"AWS.Codeartifact.dispose_package_versions/3","type":"function","doc":"Deletes the assets in package versions and sets the package versions&#39; status to Disposed. A disposed package version cannot be restored in your repository because its assets are deleted. To view all disposed package versions in a repository, use [ListackageVersions](https://docs.aws.amazon.com/codeartifact/latest/APIReference/API_ListPackageVersions.html) and set the [status](https://docs.aws.amazon.com/codeartifact/latest/APIReference/API_ListPackageVersions.html#API_ListPackageVersions_RequestSyntax) parameter to Disposed. To view information about a disposed package version, use [ListPackageVersions](https://docs.aws.amazon.com/codeartifact/latest/APIReference/API_ListPackageVersions.html) and set the [status](https://docs.aws.amazon.com/API_ListPackageVersions.html#codeartifact-ListPackageVersions-response-status) parameter to Disposed."},{"ref":"AWS.Codeartifact.html#get_authorization_token/3","title":"AWS.Codeartifact.get_authorization_token/3","type":"function","doc":"Generates a temporary authentication token for accessing repositories in the domain. This API requires the codeartifact:GetAuthorizationToken and sts:GetServiceBearerToken permissions. CodeArtifact authorization tokens are valid for a period of 12 hours when created with the login command. You can call login periodically to refresh the token. When you create an authorization token with the GetAuthorizationToken API, you can set a custom authorization period, up to a maximum of 12 hours, with the durationSeconds parameter. The authorization period begins after login or GetAuthorizationToken is called. If login or GetAuthorizationToken is called while assuming a role, the token lifetime is independent of the maximum session duration of the role. For example, if you call sts assume-role and specify a session duration of 15 minutes, then generate a CodeArtifact authorization token, the token will be valid for the full authorization period even though this is longer than the 15-minute session duration. See Using IAM Roles for more information on controlling session duration."},{"ref":"AWS.Codeartifact.html#get_domain_permissions_policy/4","title":"AWS.Codeartifact.get_domain_permissions_policy/4","type":"function","doc":"Returns the resource policy attached to the specified domain. The policy is a resource-based policy, not an identity-based policy. For more information, see Identity-based policies and resource-based policies in the AWS Identity and Access Management User Guide."},{"ref":"AWS.Codeartifact.html#get_package_version_asset/11","title":"AWS.Codeartifact.get_package_version_asset/11","type":"function","doc":"Returns an asset (or file) that is in a package. For example, for a Maven package version, use GetPackageVersionAsset to download a JAR file, a POM file, or any other assets in the package version."},{"ref":"AWS.Codeartifact.html#get_package_version_readme/9","title":"AWS.Codeartifact.get_package_version_readme/9","type":"function","doc":"Gets the readme file or descriptive text for a package version. For packages that do not contain a readme file, CodeArtifact extracts a description from a metadata file. For example, from the &lt;description&gt; element in the pom.xml file of a Maven package. The returned text might contain formatting. For example, it might contain formatting for Markdown or reStructuredText."},{"ref":"AWS.Codeartifact.html#get_repository_endpoint/6","title":"AWS.Codeartifact.get_repository_endpoint/6","type":"function","doc":"Returns the endpoint of a repository for a specific package format. A repository has one endpoint for each package format: npm pypi maven"},{"ref":"AWS.Codeartifact.html#get_repository_permissions_policy/5","title":"AWS.Codeartifact.get_repository_permissions_policy/5","type":"function","doc":"Returns the resource policy that is set on a repository."},{"ref":"AWS.Codeartifact.html#list_domains/3","title":"AWS.Codeartifact.list_domains/3","type":"function","doc":"Returns a list of [DomainSummary](https://docs.aws.amazon.com/codeartifact/latest/APIReference/API_PackageVersionDescription.html) objects for all domains owned by the AWS account that makes this call. Each returned DomainSummary object contains information about a domain."},{"ref":"AWS.Codeartifact.html#list_package_version_assets/3","title":"AWS.Codeartifact.list_package_version_assets/3","type":"function","doc":"Returns a list of AssetSummary objects for assets in a package version."},{"ref":"AWS.Codeartifact.html#list_package_version_dependencies/3","title":"AWS.Codeartifact.list_package_version_dependencies/3","type":"function","doc":"Returns the direct dependencies for a package version. The dependencies are returned as PackageDependency objects. CodeArtifact extracts the dependencies for a package version from the metadata file for the package format (for example, the package.json file for npm packages and the pom.xml file for Maven). Any package version dependencies that are not listed in the configuration file are not returned."},{"ref":"AWS.Codeartifact.html#list_package_versions/3","title":"AWS.Codeartifact.list_package_versions/3","type":"function","doc":"Returns a list of PackageVersionSummary objects for package versions in a repository that match the request parameters."},{"ref":"AWS.Codeartifact.html#list_packages/3","title":"AWS.Codeartifact.list_packages/3","type":"function","doc":"Returns a list of PackageSummary objects for packages in a repository that match the request parameters."},{"ref":"AWS.Codeartifact.html#list_repositories/3","title":"AWS.Codeartifact.list_repositories/3","type":"function","doc":"Returns a list of RepositorySummary objects. Each RepositorySummary contains information about a repository in the specified AWS account and that matches the input parameters."},{"ref":"AWS.Codeartifact.html#list_repositories_in_domain/3","title":"AWS.Codeartifact.list_repositories_in_domain/3","type":"function","doc":"Returns a list of RepositorySummary objects. Each RepositorySummary contains information about a repository in the specified domain and that matches the input parameters."},{"ref":"AWS.Codeartifact.html#put_domain_permissions_policy/3","title":"AWS.Codeartifact.put_domain_permissions_policy/3","type":"function","doc":"Sets a resource policy on a domain that specifies permissions to access it."},{"ref":"AWS.Codeartifact.html#put_repository_permissions_policy/3","title":"AWS.Codeartifact.put_repository_permissions_policy/3","type":"function","doc":"Sets the resource policy on a repository that specifies permissions to access it."},{"ref":"AWS.Codeartifact.html#update_package_versions_status/3","title":"AWS.Codeartifact.update_package_versions_status/3","type":"function","doc":"Updates the status of one or more versions of a package."},{"ref":"AWS.Codeartifact.html#update_repository/3","title":"AWS.Codeartifact.update_repository/3","type":"function","doc":"Update the properties of a repository."},{"ref":"AWS.Codestarnotifications.html","title":"AWS.Codestarnotifications","type":"module","doc":"This AWS CodeStar Notifications API Reference provides descriptions and usage examples of the operations and data types for the AWS CodeStar Notifications API. You can use the AWS CodeStar Notifications API to work with the following objects: Notification rules, by calling the following: CreateNotificationRule, which creates a notification rule for a resource in your account. DeleteNotificationRule, which deletes a notification rule. DescribeNotificationRule, which provides information about a notification rule. ListNotificationRules, which lists the notification rules associated with your account. UpdateNotificationRule, which changes the name, events, or targets associated with a notification rule. Subscribe, which subscribes a target to a notification rule. Unsubscribe, which removes a target from a notification rule. Targets, by calling the following: DeleteTarget, which removes a notification rule target (SNS topic) from a notification rule. ListTargets, which lists the targets associated with a notification rule. Events, by calling the following: ListEventTypes, which lists the event types you can include in a notification rule. Tags, by calling the following: ListTagsForResource, which lists the tags already associated with a notification rule in your account. TagResource, which associates a tag you provide with a notification rule in your account. UntagResource, which removes a tag from a notification rule in your account. For information about how to use AWS CodeStar Notifications, see link in the CodeStarNotifications User Guide."},{"ref":"AWS.Codestarnotifications.html#create_notification_rule/3","title":"AWS.Codestarnotifications.create_notification_rule/3","type":"function","doc":"Creates a notification rule for a resource. The rule specifies the events you want notifications about and the targets (such as SNS topics) where you want to receive them."},{"ref":"AWS.Codestarnotifications.html#delete_notification_rule/3","title":"AWS.Codestarnotifications.delete_notification_rule/3","type":"function","doc":"Deletes a notification rule for a resource."},{"ref":"AWS.Codestarnotifications.html#delete_target/3","title":"AWS.Codestarnotifications.delete_target/3","type":"function","doc":"Deletes a specified target for notifications."},{"ref":"AWS.Codestarnotifications.html#describe_notification_rule/3","title":"AWS.Codestarnotifications.describe_notification_rule/3","type":"function","doc":"Returns information about a specified notification rule."},{"ref":"AWS.Codestarnotifications.html#list_event_types/3","title":"AWS.Codestarnotifications.list_event_types/3","type":"function","doc":"Returns information about the event types available for configuring notifications."},{"ref":"AWS.Codestarnotifications.html#list_notification_rules/3","title":"AWS.Codestarnotifications.list_notification_rules/3","type":"function","doc":"Returns a list of the notification rules for an AWS account."},{"ref":"AWS.Codestarnotifications.html#list_tags_for_resource/3","title":"AWS.Codestarnotifications.list_tags_for_resource/3","type":"function","doc":"Returns a list of the tags associated with a notification rule."},{"ref":"AWS.Codestarnotifications.html#list_targets/3","title":"AWS.Codestarnotifications.list_targets/3","type":"function","doc":"Returns a list of the notification rule targets for an AWS account."},{"ref":"AWS.Codestarnotifications.html#subscribe/3","title":"AWS.Codestarnotifications.subscribe/3","type":"function","doc":"Creates an association between a notification rule and an SNS topic so that the associated target can receive notifications when the events described in the rule are triggered."},{"ref":"AWS.Codestarnotifications.html#tag_resource/3","title":"AWS.Codestarnotifications.tag_resource/3","type":"function","doc":"Associates a set of provided tags with a notification rule."},{"ref":"AWS.Codestarnotifications.html#unsubscribe/3","title":"AWS.Codestarnotifications.unsubscribe/3","type":"function","doc":"Removes an association between a notification rule and an Amazon SNS topic so that subscribers to that topic stop receiving notifications when the events described in the rule are triggered."},{"ref":"AWS.Codestarnotifications.html#untag_resource/3","title":"AWS.Codestarnotifications.untag_resource/3","type":"function","doc":"Removes the association between one or more provided tags and a notification rule."},{"ref":"AWS.Codestarnotifications.html#update_notification_rule/3","title":"AWS.Codestarnotifications.update_notification_rule/3","type":"function","doc":"Updates a notification rule for a resource. You can change the events that trigger the notification rule, the status of the rule, and the targets that receive the notifications. To add or remove tags for a notification rule, you must use TagResource and UntagResource."},{"ref":"AWS.CognitoIdentity.html","title":"AWS.CognitoIdentity","type":"module","doc":"Amazon Cognito Federated Identities Amazon Cognito Federated Identities is a web service that delivers scoped temporary credentials to mobile devices and other untrusted environments. It uniquely identifies a device and supplies the user with a consistent identity over the lifetime of an application. Using Amazon Cognito Federated Identities, you can enable authentication with one or more third-party identity providers (Facebook, Google, or Login with Amazon) or an Amazon Cognito user pool, and you can also choose to support unauthenticated access from your app. Cognito delivers a unique identifier for each user and acts as an OpenID token provider trusted by AWS Security Token Service (STS) to access temporary, limited-privilege AWS credentials. For a description of the authentication flow from the Amazon Cognito Developer Guide see Authentication Flow. For more information see Amazon Cognito Federated Identities."},{"ref":"AWS.CognitoIdentity.html#create_identity_pool/3","title":"AWS.CognitoIdentity.create_identity_pool/3","type":"function","doc":"Creates a new identity pool. The identity pool is a store of user identity information that is specific to your AWS account. The keys for SupportedLoginProviders are as follows: Facebook: graph.facebook.com Google: accounts.google.com Amazon: www.amazon.com Twitter: api.twitter.com Digits: www.digits.com You must use AWS Developer credentials to call this API."},{"ref":"AWS.CognitoIdentity.html#delete_identities/3","title":"AWS.CognitoIdentity.delete_identities/3","type":"function","doc":"Deletes identities from an identity pool. You can specify a list of 1-60 identities that you want to delete. You must use AWS Developer credentials to call this API."},{"ref":"AWS.CognitoIdentity.html#delete_identity_pool/3","title":"AWS.CognitoIdentity.delete_identity_pool/3","type":"function","doc":"Deletes an identity pool. Once a pool is deleted, users will not be able to authenticate with the pool. You must use AWS Developer credentials to call this API."},{"ref":"AWS.CognitoIdentity.html#describe_identity/3","title":"AWS.CognitoIdentity.describe_identity/3","type":"function","doc":"Returns metadata related to the given identity, including when the identity was created and any associated linked logins. You must use AWS Developer credentials to call this API."},{"ref":"AWS.CognitoIdentity.html#describe_identity_pool/3","title":"AWS.CognitoIdentity.describe_identity_pool/3","type":"function","doc":"Gets details about a particular identity pool, including the pool name, ID description, creation date, and current number of users. You must use AWS Developer credentials to call this API."},{"ref":"AWS.CognitoIdentity.html#get_credentials_for_identity/3","title":"AWS.CognitoIdentity.get_credentials_for_identity/3","type":"function","doc":"Returns credentials for the provided identity ID. Any provided logins will be validated against supported login providers. If the token is for cognito-identity.amazonaws.com, it will be passed through to AWS Security Token Service with the appropriate role for the token. This is a public API. You do not need any credentials to call this API."},{"ref":"AWS.CognitoIdentity.html#get_id/3","title":"AWS.CognitoIdentity.get_id/3","type":"function","doc":"Generates (or retrieves) a Cognito ID. Supplying multiple logins will create an implicit linked account. This is a public API. You do not need any credentials to call this API."},{"ref":"AWS.CognitoIdentity.html#get_identity_pool_roles/3","title":"AWS.CognitoIdentity.get_identity_pool_roles/3","type":"function","doc":"Gets the roles for an identity pool. You must use AWS Developer credentials to call this API."},{"ref":"AWS.CognitoIdentity.html#get_open_id_token/3","title":"AWS.CognitoIdentity.get_open_id_token/3","type":"function","doc":"Gets an OpenID token, using a known Cognito ID. This known Cognito ID is returned by GetId. You can optionally add additional logins for the identity. Supplying multiple logins creates an implicit link. The OpenId token is valid for 10 minutes. This is a public API. You do not need any credentials to call this API."},{"ref":"AWS.CognitoIdentity.html#get_open_id_token_for_developer_identity/3","title":"AWS.CognitoIdentity.get_open_id_token_for_developer_identity/3","type":"function","doc":"Registers (or retrieves) a Cognito IdentityId and an OpenID Connect token for a user authenticated by your backend authentication process. Supplying multiple logins will create an implicit linked account. You can only specify one developer provider as part of the Logins map, which is linked to the identity pool. The developer provider is the &quot;domain&quot; by which Cognito will refer to your users. You can use GetOpenIdTokenForDeveloperIdentity to create a new identity and to link new logins (that is, user credentials issued by a public provider or developer provider) to an existing identity. When you want to create a new identity, the IdentityId should be null. When you want to associate a new login with an existing authenticated/unauthenticated identity, you can do so by providing the existing IdentityId. This API will create the identity in the specified IdentityPoolId. You must use AWS Developer credentials to call this API."},{"ref":"AWS.CognitoIdentity.html#list_identities/3","title":"AWS.CognitoIdentity.list_identities/3","type":"function","doc":"Lists the identities in an identity pool. You must use AWS Developer credentials to call this API."},{"ref":"AWS.CognitoIdentity.html#list_identity_pools/3","title":"AWS.CognitoIdentity.list_identity_pools/3","type":"function","doc":"Lists all of the Cognito identity pools registered for your account. You must use AWS Developer credentials to call this API."},{"ref":"AWS.CognitoIdentity.html#list_tags_for_resource/3","title":"AWS.CognitoIdentity.list_tags_for_resource/3","type":"function","doc":"Lists the tags that are assigned to an Amazon Cognito identity pool. A tag is a label that you can apply to identity pools to categorize and manage them in different ways, such as by purpose, owner, environment, or other criteria. You can use this action up to 10 times per second, per account."},{"ref":"AWS.CognitoIdentity.html#lookup_developer_identity/3","title":"AWS.CognitoIdentity.lookup_developer_identity/3","type":"function","doc":"Retrieves the IdentityID associated with a DeveloperUserIdentifier or the list of DeveloperUserIdentifier values associated with an IdentityId for an existing identity. Either IdentityID or DeveloperUserIdentifier must not be null. If you supply only one of these values, the other value will be searched in the database and returned as a part of the response. If you supply both, DeveloperUserIdentifier will be matched against IdentityID. If the values are verified against the database, the response returns both values and is the same as the request. Otherwise a ResourceConflictException is thrown. LookupDeveloperIdentity is intended for low-throughput control plane operations: for example, to enable customer service to locate an identity ID by username. If you are using it for higher-volume operations such as user authentication, your requests are likely to be throttled. GetOpenIdTokenForDeveloperIdentity is a better option for higher-volume operations for user authentication. You must use AWS Developer credentials to call this API."},{"ref":"AWS.CognitoIdentity.html#merge_developer_identities/3","title":"AWS.CognitoIdentity.merge_developer_identities/3","type":"function","doc":"Merges two users having different IdentityIds, existing in the same identity pool, and identified by the same developer provider. You can use this action to request that discrete users be merged and identified as a single user in the Cognito environment. Cognito associates the given source user (SourceUserIdentifier) with the IdentityId of the DestinationUserIdentifier. Only developer-authenticated users can be merged. If the users to be merged are associated with the same public provider, but as two different users, an exception will be thrown. The number of linked logins is limited to 20. So, the number of linked logins for the source user, SourceUserIdentifier, and the destination user, DestinationUserIdentifier, together should not be larger than 20. Otherwise, an exception will be thrown. You must use AWS Developer credentials to call this API."},{"ref":"AWS.CognitoIdentity.html#set_identity_pool_roles/3","title":"AWS.CognitoIdentity.set_identity_pool_roles/3","type":"function","doc":"Sets the roles for an identity pool. These roles are used when making calls to GetCredentialsForIdentity action. You must use AWS Developer credentials to call this API."},{"ref":"AWS.CognitoIdentity.html#tag_resource/3","title":"AWS.CognitoIdentity.tag_resource/3","type":"function","doc":"Assigns a set of tags to an Amazon Cognito identity pool. A tag is a label that you can use to categorize and manage identity pools in different ways, such as by purpose, owner, environment, or other criteria. Each tag consists of a key and value, both of which you define. A key is a general category for more specific values. For example, if you have two versions of an identity pool, one for testing and another for production, you might assign an Environment tag key to both identity pools. The value of this key might be Test for one identity pool and Production for the other. Tags are useful for cost tracking and access control. You can activate your tags so that they appear on the Billing and Cost Management console, where you can track the costs associated with your identity pools. In an IAM policy, you can constrain permissions for identity pools based on specific tags or tag values. You can use this action up to 5 times per second, per account. An identity pool can have as many as 50 tags."},{"ref":"AWS.CognitoIdentity.html#unlink_developer_identity/3","title":"AWS.CognitoIdentity.unlink_developer_identity/3","type":"function","doc":"Unlinks a DeveloperUserIdentifier from an existing identity. Unlinked developer users will be considered new identities next time they are seen. If, for a given Cognito identity, you remove all federated identities as well as the developer user identifier, the Cognito identity becomes inaccessible. You must use AWS Developer credentials to call this API."},{"ref":"AWS.CognitoIdentity.html#unlink_identity/3","title":"AWS.CognitoIdentity.unlink_identity/3","type":"function","doc":"Unlinks a federated identity from an existing account. Unlinked logins will be considered new identities next time they are seen. Removing the last linked login will make this identity inaccessible. This is a public API. You do not need any credentials to call this API."},{"ref":"AWS.CognitoIdentity.html#untag_resource/3","title":"AWS.CognitoIdentity.untag_resource/3","type":"function","doc":"Removes the specified tags from an Amazon Cognito identity pool. You can use this action up to 5 times per second, per account"},{"ref":"AWS.CognitoIdentity.html#update_identity_pool/3","title":"AWS.CognitoIdentity.update_identity_pool/3","type":"function","doc":"Updates an identity pool. You must use AWS Developer credentials to call this API."},{"ref":"AWS.CognitoIdentityProvider.html","title":"AWS.CognitoIdentityProvider","type":"module","doc":"Using the Amazon Cognito User Pools API, you can create a user pool to manage directories and users. You can authenticate a user to obtain tokens related to user identity and access policies. This API reference provides information about user pools in Amazon Cognito User Pools. For more information, see the Amazon Cognito Documentation."},{"ref":"AWS.CognitoIdentityProvider.html#add_custom_attributes/3","title":"AWS.CognitoIdentityProvider.add_custom_attributes/3","type":"function","doc":"Adds additional user attributes to the user pool schema."},{"ref":"AWS.CognitoIdentityProvider.html#admin_add_user_to_group/3","title":"AWS.CognitoIdentityProvider.admin_add_user_to_group/3","type":"function","doc":"Adds the specified user to the specified group. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#admin_confirm_sign_up/3","title":"AWS.CognitoIdentityProvider.admin_confirm_sign_up/3","type":"function","doc":"Confirms user registration as an admin without using a confirmation code. Works on any user. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#admin_create_user/3","title":"AWS.CognitoIdentityProvider.admin_create_user/3","type":"function","doc":"Creates a new user in the specified user pool. If MessageAction is not set, the default is to send a welcome message via email or phone (SMS). This message is based on a template that you configured in your call to create or update a user pool. This template includes your custom sign-up instructions and placeholders for user name and temporary password. Alternatively, you can call AdminCreateUser with SUPPRESS for the MessageAction parameter, and Amazon Cognito will not send any email. In either case, the user will be in the FORCE_CHANGE_PASSWORD state until they sign in and change their password. AdminCreateUser requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#admin_delete_user/3","title":"AWS.CognitoIdentityProvider.admin_delete_user/3","type":"function","doc":"Deletes a user as an administrator. Works on any user. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#admin_delete_user_attributes/3","title":"AWS.CognitoIdentityProvider.admin_delete_user_attributes/3","type":"function","doc":"Deletes the user attributes in a user pool as an administrator. Works on any user. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#admin_disable_provider_for_user/3","title":"AWS.CognitoIdentityProvider.admin_disable_provider_for_user/3","type":"function","doc":"Disables the user from signing in with the specified external (SAML or social) identity provider. If the user to disable is a Cognito User Pools native username + password user, they are not permitted to use their password to sign-in. If the user to disable is a linked external IdP user, any link between that user and an existing user is removed. The next time the external user (no longer attached to the previously linked DestinationUser) signs in, they must create a new user account. See AdminLinkProviderForUser. This action is enabled only for admin access and requires developer credentials. The ProviderName must match the value specified when creating an IdP for the pool. To disable a native username + password user, the ProviderName value must be Cognito and the ProviderAttributeName must be Cognito_Subject, with the ProviderAttributeValue being the name that is used in the user pool for the user. The ProviderAttributeName must always be Cognito_Subject for social identity providers. The ProviderAttributeValue must always be the exact subject that was used when the user was originally linked as a source user. For de-linking a SAML identity, there are two scenarios. If the linked identity has not yet been used to sign-in, the ProviderAttributeName and ProviderAttributeValue must be the same values that were used for the SourceUser when the identities were originally linked using AdminLinkProviderForUser call. (If the linking was done with ProviderAttributeName set to Cognito_Subject, the same applies here). However, if the user has already signed in, the ProviderAttributeName must be Cognito_Subject and ProviderAttributeValue must be the subject of the SAML assertion."},{"ref":"AWS.CognitoIdentityProvider.html#admin_disable_user/3","title":"AWS.CognitoIdentityProvider.admin_disable_user/3","type":"function","doc":"Disables the specified user. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#admin_enable_user/3","title":"AWS.CognitoIdentityProvider.admin_enable_user/3","type":"function","doc":"Enables the specified user as an administrator. Works on any user. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#admin_forget_device/3","title":"AWS.CognitoIdentityProvider.admin_forget_device/3","type":"function","doc":"Forgets the device, as an administrator. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#admin_get_device/3","title":"AWS.CognitoIdentityProvider.admin_get_device/3","type":"function","doc":"Gets the device, as an administrator. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#admin_get_user/3","title":"AWS.CognitoIdentityProvider.admin_get_user/3","type":"function","doc":"Gets the specified user by user name in a user pool as an administrator. Works on any user. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#admin_initiate_auth/3","title":"AWS.CognitoIdentityProvider.admin_initiate_auth/3","type":"function","doc":"Initiates the authentication flow, as an administrator. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#admin_link_provider_for_user/3","title":"AWS.CognitoIdentityProvider.admin_link_provider_for_user/3","type":"function","doc":"Links an existing user account in a user pool (DestinationUser) to an identity from an external identity provider (SourceUser) based on a specified attribute name and value from the external identity provider. This allows you to create a link from the existing user account to an external federated user identity that has not yet been used to sign in, so that the federated user identity can be used to sign in as the existing user account. For example, if there is an existing user with a username and password, this API links that user to a federated user identity, so that when the federated user identity is used, the user signs in as the existing user account. The maximum number of federated identities linked to a user is 5. Because this API allows a user with an external federated identity to sign in as an existing user in the user pool, it is critical that it only be used with external identity providers and provider attributes that have been trusted by the application owner. This action is enabled only for admin access and requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#admin_list_devices/3","title":"AWS.CognitoIdentityProvider.admin_list_devices/3","type":"function","doc":"Lists devices, as an administrator. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#admin_list_groups_for_user/3","title":"AWS.CognitoIdentityProvider.admin_list_groups_for_user/3","type":"function","doc":"Lists the groups that the user belongs to. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#admin_list_user_auth_events/3","title":"AWS.CognitoIdentityProvider.admin_list_user_auth_events/3","type":"function","doc":"Lists a history of user activity and any risks detected as part of Amazon Cognito advanced security."},{"ref":"AWS.CognitoIdentityProvider.html#admin_remove_user_from_group/3","title":"AWS.CognitoIdentityProvider.admin_remove_user_from_group/3","type":"function","doc":"Removes the specified user from the specified group. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#admin_reset_user_password/3","title":"AWS.CognitoIdentityProvider.admin_reset_user_password/3","type":"function","doc":"Resets the specified user&#39;s password in a user pool as an administrator. Works on any user. When a developer calls this API, the current password is invalidated, so it must be changed. If a user tries to sign in after the API is called, the app will get a PasswordResetRequiredException exception back and should direct the user down the flow to reset the password, which is the same as the forgot password flow. In addition, if the user pool has phone verification selected and a verified phone number exists for the user, or if email verification is selected and a verified email exists for the user, calling this API will also result in sending a message to the end user with the code to change their password. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#admin_respond_to_auth_challenge/3","title":"AWS.CognitoIdentityProvider.admin_respond_to_auth_challenge/3","type":"function","doc":"Responds to an authentication challenge, as an administrator. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#admin_set_user_m_f_a_preference/3","title":"AWS.CognitoIdentityProvider.admin_set_user_m_f_a_preference/3","type":"function","doc":"Sets the user&#39;s multi-factor authentication (MFA) preference, including which MFA options are enabled and if any are preferred. Only one factor can be set as preferred. The preferred MFA factor will be used to authenticate a user if multiple factors are enabled. If multiple options are enabled and no preference is set, a challenge to choose an MFA option will be returned during sign in."},{"ref":"AWS.CognitoIdentityProvider.html#admin_set_user_password/3","title":"AWS.CognitoIdentityProvider.admin_set_user_password/3","type":"function","doc":"Sets the specified user&#39;s password in a user pool as an administrator. Works on any user. The password can be temporary or permanent. If it is temporary, the user status will be placed into the FORCE_CHANGE_PASSWORD state. When the user next tries to sign in, the InitiateAuth/AdminInitiateAuth response will contain the NEW_PASSWORD_REQUIRED challenge. If the user does not sign in before it expires, the user will not be able to sign in and their password will need to be reset by an administrator. Once the user has set a new password, or the password is permanent, the user status will be set to Confirmed."},{"ref":"AWS.CognitoIdentityProvider.html#admin_set_user_settings/3","title":"AWS.CognitoIdentityProvider.admin_set_user_settings/3","type":"function","doc":"This action is no longer supported. You can use it to configure only SMS MFA. You can&#39;t use it to configure TOTP software token MFA. To configure either type of MFA, use AdminSetUserMFAPreference instead."},{"ref":"AWS.CognitoIdentityProvider.html#admin_update_auth_event_feedback/3","title":"AWS.CognitoIdentityProvider.admin_update_auth_event_feedback/3","type":"function","doc":"Provides feedback for an authentication event as to whether it was from a valid user. This feedback is used for improving the risk evaluation decision for the user pool as part of Amazon Cognito advanced security."},{"ref":"AWS.CognitoIdentityProvider.html#admin_update_device_status/3","title":"AWS.CognitoIdentityProvider.admin_update_device_status/3","type":"function","doc":"Updates the device status as an administrator. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#admin_update_user_attributes/3","title":"AWS.CognitoIdentityProvider.admin_update_user_attributes/3","type":"function","doc":"Updates the specified user&#39;s attributes, including developer attributes, as an administrator. Works on any user. For custom attributes, you must prepend the custom: prefix to the attribute name. In addition to updating user attributes, this API can also be used to mark phone and email as verified. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#admin_user_global_sign_out/3","title":"AWS.CognitoIdentityProvider.admin_user_global_sign_out/3","type":"function","doc":"Signs out users from all devices, as an administrator. It also invalidates all refresh tokens issued to a user. The user&#39;s current access and Id tokens remain valid until their expiry. Access and Id tokens expire one hour after they are issued. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#associate_software_token/3","title":"AWS.CognitoIdentityProvider.associate_software_token/3","type":"function","doc":"Returns a unique generated shared secret key code for the user account. The request takes an access token or a session string, but not both."},{"ref":"AWS.CognitoIdentityProvider.html#change_password/3","title":"AWS.CognitoIdentityProvider.change_password/3","type":"function","doc":"Changes the password for a specified user in a user pool."},{"ref":"AWS.CognitoIdentityProvider.html#confirm_device/3","title":"AWS.CognitoIdentityProvider.confirm_device/3","type":"function","doc":"Confirms tracking of the device. This API call is the call that begins device tracking."},{"ref":"AWS.CognitoIdentityProvider.html#confirm_forgot_password/3","title":"AWS.CognitoIdentityProvider.confirm_forgot_password/3","type":"function","doc":"Allows a user to enter a confirmation code to reset a forgotten password."},{"ref":"AWS.CognitoIdentityProvider.html#confirm_sign_up/3","title":"AWS.CognitoIdentityProvider.confirm_sign_up/3","type":"function","doc":"Confirms registration of a user and handles the existing alias from a previous user."},{"ref":"AWS.CognitoIdentityProvider.html#create_group/3","title":"AWS.CognitoIdentityProvider.create_group/3","type":"function","doc":"Creates a new group in the specified user pool. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#create_identity_provider/3","title":"AWS.CognitoIdentityProvider.create_identity_provider/3","type":"function","doc":"Creates an identity provider for a user pool."},{"ref":"AWS.CognitoIdentityProvider.html#create_resource_server/3","title":"AWS.CognitoIdentityProvider.create_resource_server/3","type":"function","doc":"Creates a new OAuth2.0 resource server and defines custom scopes in it."},{"ref":"AWS.CognitoIdentityProvider.html#create_user_import_job/3","title":"AWS.CognitoIdentityProvider.create_user_import_job/3","type":"function","doc":"Creates the user import job."},{"ref":"AWS.CognitoIdentityProvider.html#create_user_pool/3","title":"AWS.CognitoIdentityProvider.create_user_pool/3","type":"function","doc":"Creates a new Amazon Cognito user pool and sets the password policy for the pool."},{"ref":"AWS.CognitoIdentityProvider.html#create_user_pool_client/3","title":"AWS.CognitoIdentityProvider.create_user_pool_client/3","type":"function","doc":"Creates the user pool client."},{"ref":"AWS.CognitoIdentityProvider.html#create_user_pool_domain/3","title":"AWS.CognitoIdentityProvider.create_user_pool_domain/3","type":"function","doc":"Creates a new domain for a user pool."},{"ref":"AWS.CognitoIdentityProvider.html#delete_group/3","title":"AWS.CognitoIdentityProvider.delete_group/3","type":"function","doc":"Deletes a group. Currently only groups with no members can be deleted. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#delete_identity_provider/3","title":"AWS.CognitoIdentityProvider.delete_identity_provider/3","type":"function","doc":"Deletes an identity provider for a user pool."},{"ref":"AWS.CognitoIdentityProvider.html#delete_resource_server/3","title":"AWS.CognitoIdentityProvider.delete_resource_server/3","type":"function","doc":"Deletes a resource server."},{"ref":"AWS.CognitoIdentityProvider.html#delete_user/3","title":"AWS.CognitoIdentityProvider.delete_user/3","type":"function","doc":"Allows a user to delete himself or herself."},{"ref":"AWS.CognitoIdentityProvider.html#delete_user_attributes/3","title":"AWS.CognitoIdentityProvider.delete_user_attributes/3","type":"function","doc":"Deletes the attributes for a user."},{"ref":"AWS.CognitoIdentityProvider.html#delete_user_pool/3","title":"AWS.CognitoIdentityProvider.delete_user_pool/3","type":"function","doc":"Deletes the specified Amazon Cognito user pool."},{"ref":"AWS.CognitoIdentityProvider.html#delete_user_pool_client/3","title":"AWS.CognitoIdentityProvider.delete_user_pool_client/3","type":"function","doc":"Allows the developer to delete the user pool client."},{"ref":"AWS.CognitoIdentityProvider.html#delete_user_pool_domain/3","title":"AWS.CognitoIdentityProvider.delete_user_pool_domain/3","type":"function","doc":"Deletes a domain for a user pool."},{"ref":"AWS.CognitoIdentityProvider.html#describe_identity_provider/3","title":"AWS.CognitoIdentityProvider.describe_identity_provider/3","type":"function","doc":"Gets information about a specific identity provider."},{"ref":"AWS.CognitoIdentityProvider.html#describe_resource_server/3","title":"AWS.CognitoIdentityProvider.describe_resource_server/3","type":"function","doc":"Describes a resource server."},{"ref":"AWS.CognitoIdentityProvider.html#describe_risk_configuration/3","title":"AWS.CognitoIdentityProvider.describe_risk_configuration/3","type":"function","doc":"Describes the risk configuration."},{"ref":"AWS.CognitoIdentityProvider.html#describe_user_import_job/3","title":"AWS.CognitoIdentityProvider.describe_user_import_job/3","type":"function","doc":"Describes the user import job."},{"ref":"AWS.CognitoIdentityProvider.html#describe_user_pool/3","title":"AWS.CognitoIdentityProvider.describe_user_pool/3","type":"function","doc":"Returns the configuration information and metadata of the specified user pool."},{"ref":"AWS.CognitoIdentityProvider.html#describe_user_pool_client/3","title":"AWS.CognitoIdentityProvider.describe_user_pool_client/3","type":"function","doc":"Client method for returning the configuration information and metadata of the specified user pool app client."},{"ref":"AWS.CognitoIdentityProvider.html#describe_user_pool_domain/3","title":"AWS.CognitoIdentityProvider.describe_user_pool_domain/3","type":"function","doc":"Gets information about a domain."},{"ref":"AWS.CognitoIdentityProvider.html#forget_device/3","title":"AWS.CognitoIdentityProvider.forget_device/3","type":"function","doc":"Forgets the specified device."},{"ref":"AWS.CognitoIdentityProvider.html#forgot_password/3","title":"AWS.CognitoIdentityProvider.forgot_password/3","type":"function","doc":"Calling this API causes a message to be sent to the end user with a confirmation code that is required to change the user&#39;s password. For the Username parameter, you can use the username or user alias. The method used to send the confirmation code is sent according to the specified AccountRecoverySetting. For more information, see Recovering User Accounts in the Amazon Cognito Developer Guide. If neither a verified phone number nor a verified email exists, an InvalidParameterException is thrown. To use the confirmation code for resetting the password, call ConfirmForgotPassword."},{"ref":"AWS.CognitoIdentityProvider.html#get_csv_header/3","title":"AWS.CognitoIdentityProvider.get_csv_header/3","type":"function","doc":"Gets the header information for the .csv file to be used as input for the user import job."},{"ref":"AWS.CognitoIdentityProvider.html#get_device/3","title":"AWS.CognitoIdentityProvider.get_device/3","type":"function","doc":"Gets the device."},{"ref":"AWS.CognitoIdentityProvider.html#get_group/3","title":"AWS.CognitoIdentityProvider.get_group/3","type":"function","doc":"Gets a group. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#get_identity_provider_by_identifier/3","title":"AWS.CognitoIdentityProvider.get_identity_provider_by_identifier/3","type":"function","doc":"Gets the specified identity provider."},{"ref":"AWS.CognitoIdentityProvider.html#get_signing_certificate/3","title":"AWS.CognitoIdentityProvider.get_signing_certificate/3","type":"function","doc":"This method takes a user pool ID, and returns the signing certificate."},{"ref":"AWS.CognitoIdentityProvider.html#get_u_i_customization/3","title":"AWS.CognitoIdentityProvider.get_u_i_customization/3","type":"function","doc":"Gets the UI Customization information for a particular app client&#39;s app UI, if there is something set. If nothing is set for the particular client, but there is an existing pool level customization (app clientId will be ALL), then that is returned. If nothing is present, then an empty shape is returned."},{"ref":"AWS.CognitoIdentityProvider.html#get_user/3","title":"AWS.CognitoIdentityProvider.get_user/3","type":"function","doc":"Gets the user attributes and metadata for a user."},{"ref":"AWS.CognitoIdentityProvider.html#get_user_attribute_verification_code/3","title":"AWS.CognitoIdentityProvider.get_user_attribute_verification_code/3","type":"function","doc":"Gets the user attribute verification code for the specified attribute name."},{"ref":"AWS.CognitoIdentityProvider.html#get_user_pool_mfa_config/3","title":"AWS.CognitoIdentityProvider.get_user_pool_mfa_config/3","type":"function","doc":"Gets the user pool multi-factor authentication (MFA) configuration."},{"ref":"AWS.CognitoIdentityProvider.html#global_sign_out/3","title":"AWS.CognitoIdentityProvider.global_sign_out/3","type":"function","doc":"Signs out users from all devices. It also invalidates all refresh tokens issued to a user. The user&#39;s current access and Id tokens remain valid until their expiry. Access and Id tokens expire one hour after they are issued."},{"ref":"AWS.CognitoIdentityProvider.html#initiate_auth/3","title":"AWS.CognitoIdentityProvider.initiate_auth/3","type":"function","doc":"Initiates the authentication flow."},{"ref":"AWS.CognitoIdentityProvider.html#list_devices/3","title":"AWS.CognitoIdentityProvider.list_devices/3","type":"function","doc":"Lists the devices."},{"ref":"AWS.CognitoIdentityProvider.html#list_groups/3","title":"AWS.CognitoIdentityProvider.list_groups/3","type":"function","doc":"Lists the groups associated with a user pool. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#list_identity_providers/3","title":"AWS.CognitoIdentityProvider.list_identity_providers/3","type":"function","doc":"Lists information about all identity providers for a user pool."},{"ref":"AWS.CognitoIdentityProvider.html#list_resource_servers/3","title":"AWS.CognitoIdentityProvider.list_resource_servers/3","type":"function","doc":"Lists the resource servers for a user pool."},{"ref":"AWS.CognitoIdentityProvider.html#list_tags_for_resource/3","title":"AWS.CognitoIdentityProvider.list_tags_for_resource/3","type":"function","doc":"Lists the tags that are assigned to an Amazon Cognito user pool. A tag is a label that you can apply to user pools to categorize and manage them in different ways, such as by purpose, owner, environment, or other criteria. You can use this action up to 10 times per second, per account."},{"ref":"AWS.CognitoIdentityProvider.html#list_user_import_jobs/3","title":"AWS.CognitoIdentityProvider.list_user_import_jobs/3","type":"function","doc":"Lists the user import jobs."},{"ref":"AWS.CognitoIdentityProvider.html#list_user_pool_clients/3","title":"AWS.CognitoIdentityProvider.list_user_pool_clients/3","type":"function","doc":"Lists the clients that have been created for the specified user pool."},{"ref":"AWS.CognitoIdentityProvider.html#list_user_pools/3","title":"AWS.CognitoIdentityProvider.list_user_pools/3","type":"function","doc":"Lists the user pools associated with an AWS account."},{"ref":"AWS.CognitoIdentityProvider.html#list_users/3","title":"AWS.CognitoIdentityProvider.list_users/3","type":"function","doc":"Lists the users in the Amazon Cognito user pool."},{"ref":"AWS.CognitoIdentityProvider.html#list_users_in_group/3","title":"AWS.CognitoIdentityProvider.list_users_in_group/3","type":"function","doc":"Lists the users in the specified group. Calling this action requires developer credentials."},{"ref":"AWS.CognitoIdentityProvider.html#resend_confirmation_code/3","title":"AWS.CognitoIdentityProvider.resend_confirmation_code/3","type":"function","doc":"Resends the confirmation (for confirmation of registration) to a specific user in the user pool."},{"ref":"AWS.CognitoIdentityProvider.html#respond_to_auth_challenge/3","title":"AWS.CognitoIdentityProvider.respond_to_auth_challenge/3","type":"function","doc":"Responds to the authentication challenge."},{"ref":"AWS.CognitoIdentityProvider.html#set_risk_configuration/3","title":"AWS.CognitoIdentityProvider.set_risk_configuration/3","type":"function","doc":"Configures actions on detected risks. To delete the risk configuration for UserPoolId or ClientId, pass null values for all four configuration types. To enable Amazon Cognito advanced security features, update the user pool to include the UserPoolAddOns keyAdvancedSecurityMode."},{"ref":"AWS.CognitoIdentityProvider.html#set_u_i_customization/3","title":"AWS.CognitoIdentityProvider.set_u_i_customization/3","type":"function","doc":"Sets the UI customization information for a user pool&#39;s built-in app UI. You can specify app UI customization settings for a single client (with a specific clientId) or for all clients (by setting the clientId to ALL). If you specify ALL, the default configuration will be used for every client that has no UI customization set previously. If you specify UI customization settings for a particular client, it will no longer fall back to the ALL configuration. To use this API, your user pool must have a domain associated with it. Otherwise, there is no place to host the app&#39;s pages, and the service will throw an error."},{"ref":"AWS.CognitoIdentityProvider.html#set_user_m_f_a_preference/3","title":"AWS.CognitoIdentityProvider.set_user_m_f_a_preference/3","type":"function","doc":"Set the user&#39;s multi-factor authentication (MFA) method preference, including which MFA factors are enabled and if any are preferred. Only one factor can be set as preferred. The preferred MFA factor will be used to authenticate a user if multiple factors are enabled. If multiple options are enabled and no preference is set, a challenge to choose an MFA option will be returned during sign in."},{"ref":"AWS.CognitoIdentityProvider.html#set_user_pool_mfa_config/3","title":"AWS.CognitoIdentityProvider.set_user_pool_mfa_config/3","type":"function","doc":"Set the user pool multi-factor authentication (MFA) configuration."},{"ref":"AWS.CognitoIdentityProvider.html#set_user_settings/3","title":"AWS.CognitoIdentityProvider.set_user_settings/3","type":"function","doc":"This action is no longer supported. You can use it to configure only SMS MFA. You can&#39;t use it to configure TOTP software token MFA. To configure either type of MFA, use SetUserMFAPreference instead."},{"ref":"AWS.CognitoIdentityProvider.html#sign_up/3","title":"AWS.CognitoIdentityProvider.sign_up/3","type":"function","doc":"Registers the user in the specified user pool and creates a user name, password, and user attributes."},{"ref":"AWS.CognitoIdentityProvider.html#start_user_import_job/3","title":"AWS.CognitoIdentityProvider.start_user_import_job/3","type":"function","doc":"Starts the user import."},{"ref":"AWS.CognitoIdentityProvider.html#stop_user_import_job/3","title":"AWS.CognitoIdentityProvider.stop_user_import_job/3","type":"function","doc":"Stops the user import job."},{"ref":"AWS.CognitoIdentityProvider.html#tag_resource/3","title":"AWS.CognitoIdentityProvider.tag_resource/3","type":"function","doc":"Assigns a set of tags to an Amazon Cognito user pool. A tag is a label that you can use to categorize and manage user pools in different ways, such as by purpose, owner, environment, or other criteria. Each tag consists of a key and value, both of which you define. A key is a general category for more specific values. For example, if you have two versions of a user pool, one for testing and another for production, you might assign an Environment tag key to both user pools. The value of this key might be Test for one user pool and Production for the other. Tags are useful for cost tracking and access control. You can activate your tags so that they appear on the Billing and Cost Management console, where you can track the costs associated with your user pools. In an IAM policy, you can constrain permissions for user pools based on specific tags or tag values. You can use this action up to 5 times per second, per account. A user pool can have as many as 50 tags."},{"ref":"AWS.CognitoIdentityProvider.html#untag_resource/3","title":"AWS.CognitoIdentityProvider.untag_resource/3","type":"function","doc":"Removes the specified tags from an Amazon Cognito user pool. You can use this action up to 5 times per second, per account"},{"ref":"AWS.CognitoIdentityProvider.html#update_auth_event_feedback/3","title":"AWS.CognitoIdentityProvider.update_auth_event_feedback/3","type":"function","doc":"Provides the feedback for an authentication event whether it was from a valid user or not. This feedback is used for improving the risk evaluation decision for the user pool as part of Amazon Cognito advanced security."},{"ref":"AWS.CognitoIdentityProvider.html#update_device_status/3","title":"AWS.CognitoIdentityProvider.update_device_status/3","type":"function","doc":"Updates the device status."},{"ref":"AWS.CognitoIdentityProvider.html#update_group/3","title":"AWS.CognitoIdentityProvider.update_group/3","type":"function","doc":"Updates the specified group with the specified attributes. Calling this action requires developer credentials. If you don&#39;t provide a value for an attribute, it will be set to the default value."},{"ref":"AWS.CognitoIdentityProvider.html#update_identity_provider/3","title":"AWS.CognitoIdentityProvider.update_identity_provider/3","type":"function","doc":"Updates identity provider information for a user pool."},{"ref":"AWS.CognitoIdentityProvider.html#update_resource_server/3","title":"AWS.CognitoIdentityProvider.update_resource_server/3","type":"function","doc":"Updates the name and scopes of resource server. All other fields are read-only. If you don&#39;t provide a value for an attribute, it will be set to the default value."},{"ref":"AWS.CognitoIdentityProvider.html#update_user_attributes/3","title":"AWS.CognitoIdentityProvider.update_user_attributes/3","type":"function","doc":"Allows a user to update a specific attribute (one at a time)."},{"ref":"AWS.CognitoIdentityProvider.html#update_user_pool/3","title":"AWS.CognitoIdentityProvider.update_user_pool/3","type":"function","doc":"Updates the specified user pool with the specified attributes. You can get a list of the current user pool settings using DescribeUserPool. If you don&#39;t provide a value for an attribute, it will be set to the default value."},{"ref":"AWS.CognitoIdentityProvider.html#update_user_pool_client/3","title":"AWS.CognitoIdentityProvider.update_user_pool_client/3","type":"function","doc":"Updates the specified user pool app client with the specified attributes. You can get a list of the current user pool app client settings using DescribeUserPoolClient. If you don&#39;t provide a value for an attribute, it will be set to the default value."},{"ref":"AWS.CognitoIdentityProvider.html#update_user_pool_domain/3","title":"AWS.CognitoIdentityProvider.update_user_pool_domain/3","type":"function","doc":"Updates the Secure Sockets Layer (SSL) certificate for the custom domain for your user pool. You can use this operation to provide the Amazon Resource Name (ARN) of a new certificate to Amazon Cognito. You cannot use it to change the domain for a user pool. A custom domain is used to host the Amazon Cognito hosted UI, which provides sign-up and sign-in pages for your application. When you set up a custom domain, you provide a certificate that you manage with AWS Certificate Manager (ACM). When necessary, you can use this operation to change the certificate that you applied to your custom domain. Usually, this is unnecessary following routine certificate renewal with ACM. When you renew your existing certificate in ACM, the ARN for your certificate remains the same, and your custom domain uses the new certificate automatically. However, if you replace your existing certificate with a new one, ACM gives the new certificate a new ARN. To apply the new certificate to your custom domain, you must provide this ARN to Amazon Cognito. When you add your new certificate in ACM, you must choose US East (N. Virginia) as the AWS Region. After you submit your request, Amazon Cognito requires up to 1 hour to distribute your new certificate to your custom domain. For more information about adding a custom domain to your user pool, see Using Your Own Domain for the Hosted UI."},{"ref":"AWS.CognitoIdentityProvider.html#verify_software_token/3","title":"AWS.CognitoIdentityProvider.verify_software_token/3","type":"function","doc":"Use this API to register a user&#39;s entered TOTP code and mark the user&#39;s software token MFA status as &quot;verified&quot; if successful. The request takes an access token or a session string, but not both."},{"ref":"AWS.CognitoIdentityProvider.html#verify_user_attribute/3","title":"AWS.CognitoIdentityProvider.verify_user_attribute/3","type":"function","doc":"Verifies the specified user attributes in the user pool."},{"ref":"AWS.CognitoSync.html","title":"AWS.CognitoSync","type":"module","doc":"Amazon Cognito Sync Amazon Cognito Sync provides an AWS service and client library that enable cross-device syncing of application-related user data. High-level client libraries are available for both iOS and Android. You can use these libraries to persist data locally so that it&#39;s available even if the device is offline. Developer credentials don&#39;t need to be stored on the mobile device to access the service. You can use Amazon Cognito to obtain a normalized user ID and credentials. User data is persisted in a dataset that can store up to 1 MB of key-value pairs, and you can have up to 20 datasets per user identity. With Amazon Cognito Sync, the data stored for each identity is accessible only to credentials assigned to that identity. In order to use the Cognito Sync service, you need to make API calls using credentials retrieved with Amazon Cognito Identity service. If you want to use Cognito Sync in an Android or iOS application, you will probably want to make API calls via the AWS Mobile SDK. To learn more, see the Developer Guide for Android and the Developer Guide for iOS."},{"ref":"AWS.CognitoSync.html#bulk_publish/4","title":"AWS.CognitoSync.bulk_publish/4","type":"function","doc":"Initiates a bulk publish of all existing datasets for an Identity Pool to the configured stream. Customers are limited to one successful bulk publish per 24 hours. Bulk publish is an asynchronous request, customers can see the status of the request via the GetBulkPublishDetails operation. This API can only be called with developer credentials. You cannot call this API with the temporary user credentials provided by Cognito Identity."},{"ref":"AWS.CognitoSync.html#delete_dataset/6","title":"AWS.CognitoSync.delete_dataset/6","type":"function","doc":"Deletes the specific dataset. The dataset will be deleted permanently, and the action can&#39;t be undone. Datasets that this dataset was merged with will no longer report the merge. Any subsequent operation on this dataset will result in a ResourceNotFoundException. This API can be called with temporary user credentials provided by Cognito Identity or with developer credentials."},{"ref":"AWS.CognitoSync.html#describe_dataset/5","title":"AWS.CognitoSync.describe_dataset/5","type":"function","doc":"Gets meta data about a dataset by identity and dataset name. With Amazon Cognito Sync, each identity has access only to its own data. Thus, the credentials used to make this API call need to have access to the identity data. This API can be called with temporary user credentials provided by Cognito Identity or with developer credentials. You should use Cognito Identity credentials to make this API call."},{"ref":"AWS.CognitoSync.html#describe_identity_pool_usage/3","title":"AWS.CognitoSync.describe_identity_pool_usage/3","type":"function","doc":"Gets usage details (for example, data storage) about a particular identity pool. This API can only be called with developer credentials. You cannot call this API with the temporary user credentials provided by Cognito Identity."},{"ref":"AWS.CognitoSync.html#describe_identity_usage/4","title":"AWS.CognitoSync.describe_identity_usage/4","type":"function","doc":"Gets usage information for an identity, including number of datasets and data usage. This API can be called with temporary user credentials provided by Cognito Identity or with developer credentials."},{"ref":"AWS.CognitoSync.html#get_bulk_publish_details/4","title":"AWS.CognitoSync.get_bulk_publish_details/4","type":"function","doc":"Get the status of the last BulkPublish operation for an identity pool. This API can only be called with developer credentials. You cannot call this API with the temporary user credentials provided by Cognito Identity."},{"ref":"AWS.CognitoSync.html#get_cognito_events/3","title":"AWS.CognitoSync.get_cognito_events/3","type":"function","doc":"Gets the events and the corresponding Lambda functions associated with an identity pool. This API can only be called with developer credentials. You cannot call this API with the temporary user credentials provided by Cognito Identity."},{"ref":"AWS.CognitoSync.html#get_identity_pool_configuration/3","title":"AWS.CognitoSync.get_identity_pool_configuration/3","type":"function","doc":"Gets the configuration settings of an identity pool. This API can only be called with developer credentials. You cannot call this API with the temporary user credentials provided by Cognito Identity."},{"ref":"AWS.CognitoSync.html#list_datasets/6","title":"AWS.CognitoSync.list_datasets/6","type":"function","doc":"Lists datasets for an identity. With Amazon Cognito Sync, each identity has access only to its own data. Thus, the credentials used to make this API call need to have access to the identity data. ListDatasets can be called with temporary user credentials provided by Cognito Identity or with developer credentials. You should use the Cognito Identity credentials to make this API call."},{"ref":"AWS.CognitoSync.html#list_identity_pool_usage/4","title":"AWS.CognitoSync.list_identity_pool_usage/4","type":"function","doc":"Gets a list of identity pools registered with Cognito. ListIdentityPoolUsage can only be called with developer credentials. You cannot make this API call with the temporary user credentials provided by Cognito Identity."},{"ref":"AWS.CognitoSync.html#list_records/9","title":"AWS.CognitoSync.list_records/9","type":"function","doc":"Gets paginated records, optionally changed after a particular sync count for a dataset and identity. With Amazon Cognito Sync, each identity has access only to its own data. Thus, the credentials used to make this API call need to have access to the identity data. ListRecords can be called with temporary user credentials provided by Cognito Identity or with developer credentials. You should use Cognito Identity credentials to make this API call."},{"ref":"AWS.CognitoSync.html#register_device/5","title":"AWS.CognitoSync.register_device/5","type":"function","doc":"Registers a device to receive push sync notifications. This API can only be called with temporary credentials provided by Cognito Identity. You cannot call this API with developer credentials."},{"ref":"AWS.CognitoSync.html#set_cognito_events/4","title":"AWS.CognitoSync.set_cognito_events/4","type":"function","doc":"Sets the AWS Lambda function for a given event type for an identity pool. This request only updates the key/value pair specified. Other key/values pairs are not updated. To remove a key value pair, pass a empty value for the particular key. This API can only be called with developer credentials. You cannot call this API with the temporary user credentials provided by Cognito Identity."},{"ref":"AWS.CognitoSync.html#set_identity_pool_configuration/4","title":"AWS.CognitoSync.set_identity_pool_configuration/4","type":"function","doc":"Sets the necessary configuration for push sync. This API can only be called with developer credentials. You cannot call this API with the temporary user credentials provided by Cognito Identity."},{"ref":"AWS.CognitoSync.html#subscribe_to_dataset/7","title":"AWS.CognitoSync.subscribe_to_dataset/7","type":"function","doc":"Subscribes to receive notifications when a dataset is modified by another device. This API can only be called with temporary credentials provided by Cognito Identity. You cannot call this API with developer credentials."},{"ref":"AWS.CognitoSync.html#unsubscribe_from_dataset/7","title":"AWS.CognitoSync.unsubscribe_from_dataset/7","type":"function","doc":"Unsubscribes from receiving notifications when a dataset is modified by another device. This API can only be called with temporary credentials provided by Cognito Identity. You cannot call this API with developer credentials."},{"ref":"AWS.CognitoSync.html#update_records/6","title":"AWS.CognitoSync.update_records/6","type":"function","doc":"Posts updates to records and adds and deletes records for a dataset and user. The sync count in the record patch is your last known sync count for that record. The server will reject an UpdateRecords request with a ResourceConflictException if you try to patch a record with a new value but a stale sync count. For example, if the sync count on the server is 5 for a key called highScore and you try and submit a new highScore with sync count of 4, the request will be rejected. To obtain the current sync count for a record, call ListRecords. On a successful update of the record, the response returns the new sync count for that record. You should present that sync count the next time you try to update that same record. When the record does not exist, specify the sync count as 0. This API can be called with temporary user credentials provided by Cognito Identity or with developer credentials."},{"ref":"AWS.Comprehend.html","title":"AWS.Comprehend","type":"module","doc":"Amazon Comprehend is an AWS service for gaining insight into the content of documents. Use these actions to determine the topics contained in your documents, the topics they discuss, the predominant sentiment expressed in them, the predominant language used, and more."},{"ref":"AWS.Comprehend.html#batch_detect_dominant_language/3","title":"AWS.Comprehend.batch_detect_dominant_language/3","type":"function","doc":"Determines the dominant language of the input text for a batch of documents. For a list of languages that Amazon Comprehend can detect, see Amazon Comprehend Supported Languages."},{"ref":"AWS.Comprehend.html#batch_detect_entities/3","title":"AWS.Comprehend.batch_detect_entities/3","type":"function","doc":"Inspects the text of a batch of documents for named entities and returns information about them. For more information about named entities, see how-entities"},{"ref":"AWS.Comprehend.html#batch_detect_key_phrases/3","title":"AWS.Comprehend.batch_detect_key_phrases/3","type":"function","doc":"Detects the key noun phrases found in a batch of documents."},{"ref":"AWS.Comprehend.html#batch_detect_sentiment/3","title":"AWS.Comprehend.batch_detect_sentiment/3","type":"function","doc":"Inspects a batch of documents and returns an inference of the prevailing sentiment, POSITIVE, NEUTRAL, MIXED, or NEGATIVE, in each one."},{"ref":"AWS.Comprehend.html#batch_detect_syntax/3","title":"AWS.Comprehend.batch_detect_syntax/3","type":"function","doc":"Inspects the text of a batch of documents for the syntax and part of speech of the words in the document and returns information about them. For more information, see how-syntax."},{"ref":"AWS.Comprehend.html#classify_document/3","title":"AWS.Comprehend.classify_document/3","type":"function","doc":"Creates a new document classification request to analyze a single document in real-time, using a previously created and trained custom model and an endpoint."},{"ref":"AWS.Comprehend.html#create_document_classifier/3","title":"AWS.Comprehend.create_document_classifier/3","type":"function","doc":"Creates a new document classifier that you can use to categorize documents. To create a classifier, you provide a set of training documents that labeled with the categories that you want to use. After the classifier is trained you can use it to categorize a set of labeled documents into the categories. For more information, see how-document-classification."},{"ref":"AWS.Comprehend.html#create_endpoint/3","title":"AWS.Comprehend.create_endpoint/3","type":"function","doc":"Creates a model-specific endpoint for synchronous inference for a previously trained custom model"},{"ref":"AWS.Comprehend.html#create_entity_recognizer/3","title":"AWS.Comprehend.create_entity_recognizer/3","type":"function","doc":"Creates an entity recognizer using submitted files. After your CreateEntityRecognizer request is submitted, you can check job status using the API."},{"ref":"AWS.Comprehend.html#delete_document_classifier/3","title":"AWS.Comprehend.delete_document_classifier/3","type":"function","doc":"Deletes a previously created document classifier Only those classifiers that are in terminated states (IN_ERROR, TRAINED) will be deleted. If an active inference job is using the model, a ResourceInUseException will be returned. This is an asynchronous action that puts the classifier into a DELETING state, and it is then removed by a background job. Once removed, the classifier disappears from your account and is no longer available for use."},{"ref":"AWS.Comprehend.html#delete_endpoint/3","title":"AWS.Comprehend.delete_endpoint/3","type":"function","doc":"Deletes a model-specific endpoint for a previously-trained custom model. All endpoints must be deleted in order for the model to be deleted."},{"ref":"AWS.Comprehend.html#delete_entity_recognizer/3","title":"AWS.Comprehend.delete_entity_recognizer/3","type":"function","doc":"Deletes an entity recognizer. Only those recognizers that are in terminated states (IN_ERROR, TRAINED) will be deleted. If an active inference job is using the model, a ResourceInUseException will be returned. This is an asynchronous action that puts the recognizer into a DELETING state, and it is then removed by a background job. Once removed, the recognizer disappears from your account and is no longer available for use."},{"ref":"AWS.Comprehend.html#describe_document_classification_job/3","title":"AWS.Comprehend.describe_document_classification_job/3","type":"function","doc":"Gets the properties associated with a document classification job. Use this operation to get the status of a classification job."},{"ref":"AWS.Comprehend.html#describe_document_classifier/3","title":"AWS.Comprehend.describe_document_classifier/3","type":"function","doc":"Gets the properties associated with a document classifier."},{"ref":"AWS.Comprehend.html#describe_dominant_language_detection_job/3","title":"AWS.Comprehend.describe_dominant_language_detection_job/3","type":"function","doc":"Gets the properties associated with a dominant language detection job. Use this operation to get the status of a detection job."},{"ref":"AWS.Comprehend.html#describe_endpoint/3","title":"AWS.Comprehend.describe_endpoint/3","type":"function","doc":"Gets the properties associated with a specific endpoint. Use this operation to get the status of an endpoint."},{"ref":"AWS.Comprehend.html#describe_entities_detection_job/3","title":"AWS.Comprehend.describe_entities_detection_job/3","type":"function","doc":"Gets the properties associated with an entities detection job. Use this operation to get the status of a detection job."},{"ref":"AWS.Comprehend.html#describe_entity_recognizer/3","title":"AWS.Comprehend.describe_entity_recognizer/3","type":"function","doc":"Provides details about an entity recognizer including status, S3 buckets containing training data, recognizer metadata, metrics, and so on."},{"ref":"AWS.Comprehend.html#describe_key_phrases_detection_job/3","title":"AWS.Comprehend.describe_key_phrases_detection_job/3","type":"function","doc":"Gets the properties associated with a key phrases detection job. Use this operation to get the status of a detection job."},{"ref":"AWS.Comprehend.html#describe_pii_entities_detection_job/3","title":"AWS.Comprehend.describe_pii_entities_detection_job/3","type":"function","doc":"Gets the properties associated with a PII entities detection job. For example, you can use this operation to get the job status."},{"ref":"AWS.Comprehend.html#describe_sentiment_detection_job/3","title":"AWS.Comprehend.describe_sentiment_detection_job/3","type":"function","doc":"Gets the properties associated with a sentiment detection job. Use this operation to get the status of a detection job."},{"ref":"AWS.Comprehend.html#describe_topics_detection_job/3","title":"AWS.Comprehend.describe_topics_detection_job/3","type":"function","doc":"Gets the properties associated with a topic detection job. Use this operation to get the status of a detection job."},{"ref":"AWS.Comprehend.html#detect_dominant_language/3","title":"AWS.Comprehend.detect_dominant_language/3","type":"function","doc":"Determines the dominant language of the input text. For a list of languages that Amazon Comprehend can detect, see Amazon Comprehend Supported Languages."},{"ref":"AWS.Comprehend.html#detect_entities/3","title":"AWS.Comprehend.detect_entities/3","type":"function","doc":"Inspects text for named entities, and returns information about them. For more information, about named entities, see how-entities."},{"ref":"AWS.Comprehend.html#detect_key_phrases/3","title":"AWS.Comprehend.detect_key_phrases/3","type":"function","doc":"Detects the key noun phrases found in the text."},{"ref":"AWS.Comprehend.html#detect_pii_entities/3","title":"AWS.Comprehend.detect_pii_entities/3","type":"function","doc":"Inspects the input text for entities that contain personally identifiable information (PII) and returns information about them."},{"ref":"AWS.Comprehend.html#detect_sentiment/3","title":"AWS.Comprehend.detect_sentiment/3","type":"function","doc":"Inspects text and returns an inference of the prevailing sentiment (POSITIVE, NEUTRAL, MIXED, or NEGATIVE)."},{"ref":"AWS.Comprehend.html#detect_syntax/3","title":"AWS.Comprehend.detect_syntax/3","type":"function","doc":"Inspects text for syntax and the part of speech of words in the document. For more information, how-syntax."},{"ref":"AWS.Comprehend.html#list_document_classification_jobs/3","title":"AWS.Comprehend.list_document_classification_jobs/3","type":"function","doc":"Gets a list of the documentation classification jobs that you have submitted."},{"ref":"AWS.Comprehend.html#list_document_classifiers/3","title":"AWS.Comprehend.list_document_classifiers/3","type":"function","doc":"Gets a list of the document classifiers that you have created."},{"ref":"AWS.Comprehend.html#list_dominant_language_detection_jobs/3","title":"AWS.Comprehend.list_dominant_language_detection_jobs/3","type":"function","doc":"Gets a list of the dominant language detection jobs that you have submitted."},{"ref":"AWS.Comprehend.html#list_endpoints/3","title":"AWS.Comprehend.list_endpoints/3","type":"function","doc":"Gets a list of all existing endpoints that you&#39;ve created."},{"ref":"AWS.Comprehend.html#list_entities_detection_jobs/3","title":"AWS.Comprehend.list_entities_detection_jobs/3","type":"function","doc":"Gets a list of the entity detection jobs that you have submitted."},{"ref":"AWS.Comprehend.html#list_entity_recognizers/3","title":"AWS.Comprehend.list_entity_recognizers/3","type":"function","doc":"Gets a list of the properties of all entity recognizers that you created, including recognizers currently in training. Allows you to filter the list of recognizers based on criteria such as status and submission time. This call returns up to 500 entity recognizers in the list, with a default number of 100 recognizers in the list. The results of this list are not in any particular order. Please get the list and sort locally if needed."},{"ref":"AWS.Comprehend.html#list_key_phrases_detection_jobs/3","title":"AWS.Comprehend.list_key_phrases_detection_jobs/3","type":"function","doc":"Get a list of key phrase detection jobs that you have submitted."},{"ref":"AWS.Comprehend.html#list_pii_entities_detection_jobs/3","title":"AWS.Comprehend.list_pii_entities_detection_jobs/3","type":"function","doc":"Gets a list of the PII entity detection jobs that you have submitted."},{"ref":"AWS.Comprehend.html#list_sentiment_detection_jobs/3","title":"AWS.Comprehend.list_sentiment_detection_jobs/3","type":"function","doc":"Gets a list of sentiment detection jobs that you have submitted."},{"ref":"AWS.Comprehend.html#list_tags_for_resource/3","title":"AWS.Comprehend.list_tags_for_resource/3","type":"function","doc":"Lists all tags associated with a given Amazon Comprehend resource."},{"ref":"AWS.Comprehend.html#list_topics_detection_jobs/3","title":"AWS.Comprehend.list_topics_detection_jobs/3","type":"function","doc":"Gets a list of the topic detection jobs that you have submitted."},{"ref":"AWS.Comprehend.html#start_document_classification_job/3","title":"AWS.Comprehend.start_document_classification_job/3","type":"function","doc":"Starts an asynchronous document classification job. Use the operation to track the progress of the job."},{"ref":"AWS.Comprehend.html#start_dominant_language_detection_job/3","title":"AWS.Comprehend.start_dominant_language_detection_job/3","type":"function","doc":"Starts an asynchronous dominant language detection job for a collection of documents. Use the operation to track the status of a job."},{"ref":"AWS.Comprehend.html#start_entities_detection_job/3","title":"AWS.Comprehend.start_entities_detection_job/3","type":"function","doc":"Starts an asynchronous entity detection job for a collection of documents. Use the operation to track the status of a job. This API can be used for either standard entity detection or custom entity recognition. In order to be used for custom entity recognition, the optional EntityRecognizerArn must be used in order to provide access to the recognizer being used to detect the custom entity."},{"ref":"AWS.Comprehend.html#start_key_phrases_detection_job/3","title":"AWS.Comprehend.start_key_phrases_detection_job/3","type":"function","doc":"Starts an asynchronous key phrase detection job for a collection of documents. Use the operation to track the status of a job."},{"ref":"AWS.Comprehend.html#start_pii_entities_detection_job/3","title":"AWS.Comprehend.start_pii_entities_detection_job/3","type":"function","doc":"Starts an asynchronous PII entity detection job for a collection of documents."},{"ref":"AWS.Comprehend.html#start_sentiment_detection_job/3","title":"AWS.Comprehend.start_sentiment_detection_job/3","type":"function","doc":"Starts an asynchronous sentiment detection job for a collection of documents. use the operation to track the status of a job."},{"ref":"AWS.Comprehend.html#start_topics_detection_job/3","title":"AWS.Comprehend.start_topics_detection_job/3","type":"function","doc":"Starts an asynchronous topic detection job. Use the DescribeTopicDetectionJob operation to track the status of a job."},{"ref":"AWS.Comprehend.html#stop_dominant_language_detection_job/3","title":"AWS.Comprehend.stop_dominant_language_detection_job/3","type":"function","doc":"Stops a dominant language detection job in progress. If the job state is IN_PROGRESS the job is marked for termination and put into the STOP_REQUESTED state. If the job completes before it can be stopped, it is put into the COMPLETED state; otherwise the job is stopped and put into the STOPPED state. If the job is in the COMPLETED or FAILED state when you call the StopDominantLanguageDetectionJob operation, the operation returns a 400 Internal Request Exception. When a job is stopped, any documents already processed are written to the output location."},{"ref":"AWS.Comprehend.html#stop_entities_detection_job/3","title":"AWS.Comprehend.stop_entities_detection_job/3","type":"function","doc":"Stops an entities detection job in progress. If the job state is IN_PROGRESS the job is marked for termination and put into the STOP_REQUESTED state. If the job completes before it can be stopped, it is put into the COMPLETED state; otherwise the job is stopped and put into the STOPPED state. If the job is in the COMPLETED or FAILED state when you call the StopDominantLanguageDetectionJob operation, the operation returns a 400 Internal Request Exception. When a job is stopped, any documents already processed are written to the output location."},{"ref":"AWS.Comprehend.html#stop_key_phrases_detection_job/3","title":"AWS.Comprehend.stop_key_phrases_detection_job/3","type":"function","doc":"Stops a key phrases detection job in progress. If the job state is IN_PROGRESS the job is marked for termination and put into the STOP_REQUESTED state. If the job completes before it can be stopped, it is put into the COMPLETED state; otherwise the job is stopped and put into the STOPPED state. If the job is in the COMPLETED or FAILED state when you call the StopDominantLanguageDetectionJob operation, the operation returns a 400 Internal Request Exception. When a job is stopped, any documents already processed are written to the output location."},{"ref":"AWS.Comprehend.html#stop_pii_entities_detection_job/3","title":"AWS.Comprehend.stop_pii_entities_detection_job/3","type":"function","doc":"Stops a PII entities detection job in progress."},{"ref":"AWS.Comprehend.html#stop_sentiment_detection_job/3","title":"AWS.Comprehend.stop_sentiment_detection_job/3","type":"function","doc":"Stops a sentiment detection job in progress. If the job state is IN_PROGRESS the job is marked for termination and put into the STOP_REQUESTED state. If the job completes before it can be stopped, it is put into the COMPLETED state; otherwise the job is be stopped and put into the STOPPED state. If the job is in the COMPLETED or FAILED state when you call the StopDominantLanguageDetectionJob operation, the operation returns a 400 Internal Request Exception. When a job is stopped, any documents already processed are written to the output location."},{"ref":"AWS.Comprehend.html#stop_training_document_classifier/3","title":"AWS.Comprehend.stop_training_document_classifier/3","type":"function","doc":"Stops a document classifier training job while in progress. If the training job state is TRAINING, the job is marked for termination and put into the STOP_REQUESTED state. If the training job completes before it can be stopped, it is put into the TRAINED; otherwise the training job is stopped and put into the STOPPED state and the service sends back an HTTP 200 response with an empty HTTP body."},{"ref":"AWS.Comprehend.html#stop_training_entity_recognizer/3","title":"AWS.Comprehend.stop_training_entity_recognizer/3","type":"function","doc":"Stops an entity recognizer training job while in progress. If the training job state is TRAINING, the job is marked for termination and put into the STOP_REQUESTED state. If the training job completes before it can be stopped, it is put into the TRAINED; otherwise the training job is stopped and putted into the STOPPED state and the service sends back an HTTP 200 response with an empty HTTP body."},{"ref":"AWS.Comprehend.html#tag_resource/3","title":"AWS.Comprehend.tag_resource/3","type":"function","doc":"Associates a specific tag with an Amazon Comprehend resource. A tag is a key-value pair that adds as a metadata to a resource used by Amazon Comprehend. For example, a tag with &quot;Sales&quot; as the key might be added to a resource to indicate its use by the sales department."},{"ref":"AWS.Comprehend.html#untag_resource/3","title":"AWS.Comprehend.untag_resource/3","type":"function","doc":"Removes a specific tag associated with an Amazon Comprehend resource."},{"ref":"AWS.Comprehend.html#update_endpoint/3","title":"AWS.Comprehend.update_endpoint/3","type":"function","doc":"Updates information about the specified endpoint."},{"ref":"AWS.ComprehendMedical.html","title":"AWS.ComprehendMedical","type":"module","doc":"Amazon Comprehend Medical extracts structured information from unstructured clinical text. Use these actions to gain insight in your documents."},{"ref":"AWS.ComprehendMedical.html#describe_entities_detection_v2_job/3","title":"AWS.ComprehendMedical.describe_entities_detection_v2_job/3","type":"function","doc":"Gets the properties associated with a medical entities detection job. Use this operation to get the status of a detection job."},{"ref":"AWS.ComprehendMedical.html#describe_i_c_d10_c_m_inference_job/3","title":"AWS.ComprehendMedical.describe_i_c_d10_c_m_inference_job/3","type":"function","doc":"Gets the properties associated with an InferICD10CM job. Use this operation to get the status of an inference job."},{"ref":"AWS.ComprehendMedical.html#describe_p_h_i_detection_job/3","title":"AWS.ComprehendMedical.describe_p_h_i_detection_job/3","type":"function","doc":"Gets the properties associated with a protected health information (PHI) detection job. Use this operation to get the status of a detection job."},{"ref":"AWS.ComprehendMedical.html#describe_rx_norm_inference_job/3","title":"AWS.ComprehendMedical.describe_rx_norm_inference_job/3","type":"function","doc":"Gets the properties associated with an InferRxNorm job. Use this operation to get the status of an inference job."},{"ref":"AWS.ComprehendMedical.html#detect_entities/3","title":"AWS.ComprehendMedical.detect_entities/3","type":"function","doc":"The DetectEntities operation is deprecated. You should use the DetectEntitiesV2 operation instead. Inspects the clinical text for a variety of medical entities and returns specific information about them such as entity category, location, and confidence score on that information ."},{"ref":"AWS.ComprehendMedical.html#detect_entities_v2/3","title":"AWS.ComprehendMedical.detect_entities_v2/3","type":"function","doc":"Inspects the clinical text for a variety of medical entities and returns specific information about them such as entity category, location, and confidence score on that information. Amazon Comprehend Medical only detects medical entities in English language texts. The DetectEntitiesV2 operation replaces the DetectEntities operation. This new action uses a different model for determining the entities in your medical text and changes the way that some entities are returned in the output. You should use the DetectEntitiesV2 operation in all new applications. The DetectEntitiesV2 operation returns the Acuity and Direction entities as attributes instead of types."},{"ref":"AWS.ComprehendMedical.html#detect_p_h_i/3","title":"AWS.ComprehendMedical.detect_p_h_i/3","type":"function","doc":"Inspects the clinical text for protected health information (PHI) entities and returns the entity category, location, and confidence score for each entity. Amazon Comprehend Medical only detects entities in English language texts."},{"ref":"AWS.ComprehendMedical.html#infer_i_c_d10_c_m/3","title":"AWS.ComprehendMedical.infer_i_c_d10_c_m/3","type":"function","doc":"InferICD10CM detects medical conditions as entities listed in a patient record and links those entities to normalized concept identifiers in the ICD-10-CM knowledge base from the Centers for Disease Control. Amazon Comprehend Medical only detects medical entities in English language texts."},{"ref":"AWS.ComprehendMedical.html#infer_rx_norm/3","title":"AWS.ComprehendMedical.infer_rx_norm/3","type":"function","doc":"InferRxNorm detects medications as entities listed in a patient record and links to the normalized concept identifiers in the RxNorm database from the National Library of Medicine. Amazon Comprehend Medical only detects medical entities in English language texts."},{"ref":"AWS.ComprehendMedical.html#list_entities_detection_v2_jobs/3","title":"AWS.ComprehendMedical.list_entities_detection_v2_jobs/3","type":"function","doc":"Gets a list of medical entity detection jobs that you have submitted."},{"ref":"AWS.ComprehendMedical.html#list_i_c_d10_c_m_inference_jobs/3","title":"AWS.ComprehendMedical.list_i_c_d10_c_m_inference_jobs/3","type":"function","doc":"Gets a list of InferICD10CM jobs that you have submitted."},{"ref":"AWS.ComprehendMedical.html#list_p_h_i_detection_jobs/3","title":"AWS.ComprehendMedical.list_p_h_i_detection_jobs/3","type":"function","doc":"Gets a list of protected health information (PHI) detection jobs that you have submitted."},{"ref":"AWS.ComprehendMedical.html#list_rx_norm_inference_jobs/3","title":"AWS.ComprehendMedical.list_rx_norm_inference_jobs/3","type":"function","doc":"Gets a list of InferRxNorm jobs that you have submitted."},{"ref":"AWS.ComprehendMedical.html#start_entities_detection_v2_job/3","title":"AWS.ComprehendMedical.start_entities_detection_v2_job/3","type":"function","doc":"Starts an asynchronous medical entity detection job for a collection of documents. Use the DescribeEntitiesDetectionV2Job operation to track the status of a job."},{"ref":"AWS.ComprehendMedical.html#start_i_c_d10_c_m_inference_job/3","title":"AWS.ComprehendMedical.start_i_c_d10_c_m_inference_job/3","type":"function","doc":"Starts an asynchronous job to detect medical conditions and link them to the ICD-10-CM ontology. Use the DescribeICD10CMInferenceJob operation to track the status of a job."},{"ref":"AWS.ComprehendMedical.html#start_p_h_i_detection_job/3","title":"AWS.ComprehendMedical.start_p_h_i_detection_job/3","type":"function","doc":"Starts an asynchronous job to detect protected health information (PHI). Use the DescribePHIDetectionJob operation to track the status of a job."},{"ref":"AWS.ComprehendMedical.html#start_rx_norm_inference_job/3","title":"AWS.ComprehendMedical.start_rx_norm_inference_job/3","type":"function","doc":"Starts an asynchronous job to detect medication entities and link them to the RxNorm ontology. Use the DescribeRxNormInferenceJob operation to track the status of a job."},{"ref":"AWS.ComprehendMedical.html#stop_entities_detection_v2_job/3","title":"AWS.ComprehendMedical.stop_entities_detection_v2_job/3","type":"function","doc":"Stops a medical entities detection job in progress."},{"ref":"AWS.ComprehendMedical.html#stop_i_c_d10_c_m_inference_job/3","title":"AWS.ComprehendMedical.stop_i_c_d10_c_m_inference_job/3","type":"function","doc":"Stops an InferICD10CM inference job in progress."},{"ref":"AWS.ComprehendMedical.html#stop_p_h_i_detection_job/3","title":"AWS.ComprehendMedical.stop_p_h_i_detection_job/3","type":"function","doc":"Stops a protected health information (PHI) detection job in progress."},{"ref":"AWS.ComprehendMedical.html#stop_rx_norm_inference_job/3","title":"AWS.ComprehendMedical.stop_rx_norm_inference_job/3","type":"function","doc":"Stops an InferRxNorm inference job in progress."},{"ref":"AWS.ComputeOptimizer.html","title":"AWS.ComputeOptimizer","type":"module","doc":"AWS Compute Optimizer is a service that analyzes the configuration and utilization metrics of your AWS resources, such as EC2 instances and Auto Scaling groups. It reports whether your resources are optimal, and generates optimization recommendations to reduce the cost and improve the performance of your workloads. Compute Optimizer also provides recent utilization metric data, as well as projected utilization metric data for the recommendations, which you can use to evaluate which recommendation provides the best price-performance trade-off. The analysis of your usage patterns can help you decide when to move or resize your running resources, and still meet your performance and capacity requirements. For more information about Compute Optimizer, including the required permissions to use the service, see the AWS Compute Optimizer User Guide."},{"ref":"AWS.ComputeOptimizer.html#describe_recommendation_export_jobs/3","title":"AWS.ComputeOptimizer.describe_recommendation_export_jobs/3","type":"function","doc":"Describes recommendation export jobs created in the last seven days. Use the ExportAutoScalingGroupRecommendations or ExportEC2InstanceRecommendations actions to request an export of your recommendations. Then use the DescribeRecommendationExportJobs action to view your export jobs."},{"ref":"AWS.ComputeOptimizer.html#export_auto_scaling_group_recommendations/3","title":"AWS.ComputeOptimizer.export_auto_scaling_group_recommendations/3","type":"function","doc":"Exports optimization recommendations for Auto Scaling groups. Recommendations are exported in a comma-separated values (.csv) file, and its metadata in a JavaScript Object Notation (.json) file, to an existing Amazon Simple Storage Service (Amazon S3) bucket that you specify. For more information, see Exporting Recommendations in the Compute Optimizer User Guide. You can have only one Auto Scaling group export job in progress per AWS Region."},{"ref":"AWS.ComputeOptimizer.html#export_e_c2_instance_recommendations/3","title":"AWS.ComputeOptimizer.export_e_c2_instance_recommendations/3","type":"function","doc":"Exports optimization recommendations for Amazon EC2 instances. Recommendations are exported in a comma-separated values (.csv) file, and its metadata in a JavaScript Object Notation (.json) file, to an existing Amazon Simple Storage Service (Amazon S3) bucket that you specify. For more information, see Exporting Recommendations in the Compute Optimizer User Guide. You can have only one Amazon EC2 instance export job in progress per AWS Region."},{"ref":"AWS.ComputeOptimizer.html#get_auto_scaling_group_recommendations/3","title":"AWS.ComputeOptimizer.get_auto_scaling_group_recommendations/3","type":"function","doc":"Returns Auto Scaling group recommendations. AWS Compute Optimizer generates recommendations for Amazon EC2 Auto Scaling groups that meet a specific set of requirements. For more information, see the Supported resources and requirements in the AWS Compute Optimizer User Guide."},{"ref":"AWS.ComputeOptimizer.html#get_e_c2_instance_recommendations/3","title":"AWS.ComputeOptimizer.get_e_c2_instance_recommendations/3","type":"function","doc":"Returns Amazon EC2 instance recommendations. AWS Compute Optimizer generates recommendations for Amazon Elastic Compute Cloud (Amazon EC2) instances that meet a specific set of requirements. For more information, see the Supported resources and requirements in the AWS Compute Optimizer User Guide."},{"ref":"AWS.ComputeOptimizer.html#get_e_c2_recommendation_projected_metrics/3","title":"AWS.ComputeOptimizer.get_e_c2_recommendation_projected_metrics/3","type":"function","doc":"Returns the projected utilization metrics of Amazon EC2 instance recommendations. The Cpu and Memory metrics are the only projected utilization metrics returned when you run this action. Additionally, the Memory metric is returned only for resources that have the unified CloudWatch agent installed on them. For more information, see Enabling Memory Utilization with the CloudWatch Agent."},{"ref":"AWS.ComputeOptimizer.html#get_enrollment_status/3","title":"AWS.ComputeOptimizer.get_enrollment_status/3","type":"function","doc":"Returns the enrollment (opt in) status of an account to the AWS Compute Optimizer service. If the account is the master account of an organization, this action also confirms the enrollment status of member accounts within the organization."},{"ref":"AWS.ComputeOptimizer.html#get_recommendation_summaries/3","title":"AWS.ComputeOptimizer.get_recommendation_summaries/3","type":"function","doc":"Returns the optimization findings for an account. For example, it returns the number of Amazon EC2 instances in an account that are under-provisioned, over-provisioned, or optimized. It also returns the number of Auto Scaling groups in an account that are not optimized, or optimized."},{"ref":"AWS.ComputeOptimizer.html#update_enrollment_status/3","title":"AWS.ComputeOptimizer.update_enrollment_status/3","type":"function","doc":"Updates the enrollment (opt in) status of an account to the AWS Compute Optimizer service. If the account is a master account of an organization, this action can also be used to enroll member accounts within the organization."},{"ref":"AWS.Config.html","title":"AWS.Config","type":"module","doc":"AWS Config AWS Config provides a way to keep track of the configurations of all the AWS resources associated with your AWS account. You can use AWS Config to get the current and historical configurations of each AWS resource and also to get information about the relationship between the resources. An AWS resource can be an Amazon Compute Cloud (Amazon EC2) instance, an Elastic Block Store (EBS) volume, an elastic network Interface (ENI), or a security group. For a complete list of resources currently supported by AWS Config, see Supported AWS Resources. You can access and manage AWS Config through the AWS Management Console, the AWS Command Line Interface (AWS CLI), the AWS Config API, or the AWS SDKs for AWS Config. This reference guide contains documentation for the AWS Config API and the AWS CLI commands that you can use to manage AWS Config. The AWS Config API uses the Signature Version 4 protocol for signing requests. For more information about how to sign a request with this protocol, see Signature Version 4 Signing Process. For detailed information about AWS Config features and their associated actions or commands, as well as how to work with AWS Management Console, see What Is AWS Config in the AWS Config Developer Guide."},{"ref":"AWS.Config.html#batch_get_aggregate_resource_config/3","title":"AWS.Config.batch_get_aggregate_resource_config/3","type":"function","doc":"Returns the current configuration items for resources that are present in your AWS Config aggregator. The operation also returns a list of resources that are not processed in the current request. If there are no unprocessed resources, the operation returns an empty unprocessedResourceIdentifiers list. The API does not return results for deleted resources. The API does not return tags and relationships."},{"ref":"AWS.Config.html#batch_get_resource_config/3","title":"AWS.Config.batch_get_resource_config/3","type":"function","doc":"Returns the current configuration for one or more requested resources. The operation also returns a list of resources that are not processed in the current request. If there are no unprocessed resources, the operation returns an empty unprocessedResourceKeys list. The API does not return results for deleted resources. The API does not return any tags for the requested resources. This information is filtered out of the supplementaryConfiguration section of the API response."},{"ref":"AWS.Config.html#delete_aggregation_authorization/3","title":"AWS.Config.delete_aggregation_authorization/3","type":"function","doc":"Deletes the authorization granted to the specified configuration aggregator account in a specified region."},{"ref":"AWS.Config.html#delete_config_rule/3","title":"AWS.Config.delete_config_rule/3","type":"function","doc":"Deletes the specified AWS Config rule and all of its evaluation results. AWS Config sets the state of a rule to DELETING until the deletion is complete. You cannot update a rule while it is in this state. If you make a PutConfigRule or DeleteConfigRule request for the rule, you will receive a ResourceInUseException. You can check the state of a rule by using the DescribeConfigRules request."},{"ref":"AWS.Config.html#delete_configuration_aggregator/3","title":"AWS.Config.delete_configuration_aggregator/3","type":"function","doc":"Deletes the specified configuration aggregator and the aggregated data associated with the aggregator."},{"ref":"AWS.Config.html#delete_configuration_recorder/3","title":"AWS.Config.delete_configuration_recorder/3","type":"function","doc":"Deletes the configuration recorder. After the configuration recorder is deleted, AWS Config will not record resource configuration changes until you create a new configuration recorder. This action does not delete the configuration information that was previously recorded. You will be able to access the previously recorded information by using the GetResourceConfigHistory action, but you will not be able to access this information in the AWS Config console until you create a new configuration recorder."},{"ref":"AWS.Config.html#delete_conformance_pack/3","title":"AWS.Config.delete_conformance_pack/3","type":"function","doc":"Deletes the specified conformance pack and all the AWS Config rules, remediation actions, and all evaluation results within that conformance pack. AWS Config sets the conformance pack to DELETE_IN_PROGRESS until the deletion is complete. You cannot update a conformance pack while it is in this state."},{"ref":"AWS.Config.html#delete_delivery_channel/3","title":"AWS.Config.delete_delivery_channel/3","type":"function","doc":"Deletes the delivery channel. Before you can delete the delivery channel, you must stop the configuration recorder by using the StopConfigurationRecorder action."},{"ref":"AWS.Config.html#delete_evaluation_results/3","title":"AWS.Config.delete_evaluation_results/3","type":"function","doc":"Deletes the evaluation results for the specified AWS Config rule. You can specify one AWS Config rule per request. After you delete the evaluation results, you can call the StartConfigRulesEvaluation API to start evaluating your AWS resources against the rule."},{"ref":"AWS.Config.html#delete_organization_config_rule/3","title":"AWS.Config.delete_organization_config_rule/3","type":"function","doc":"Deletes the specified organization config rule and all of its evaluation results from all member accounts in that organization. Only a master account and a delegated administrator account can delete an organization config rule. When calling this API with a delegated administrator, you must ensure AWS Organizations ListDelegatedAdministrator permissions are added. AWS Config sets the state of a rule to DELETE_IN_PROGRESS until the deletion is complete. You cannot update a rule while it is in this state."},{"ref":"AWS.Config.html#delete_organization_conformance_pack/3","title":"AWS.Config.delete_organization_conformance_pack/3","type":"function","doc":"Deletes the specified organization conformance pack and all of the config rules and remediation actions from all member accounts in that organization. Only a master account or a delegated administrator account can delete an organization conformance pack. When calling this API with a delegated administrator, you must ensure AWS Organizations ListDelegatedAdministrator permissions are added. AWS Config sets the state of a conformance pack to DELETE_IN_PROGRESS until the deletion is complete. You cannot update a conformance pack while it is in this state."},{"ref":"AWS.Config.html#delete_pending_aggregation_request/3","title":"AWS.Config.delete_pending_aggregation_request/3","type":"function","doc":"Deletes pending authorization requests for a specified aggregator account in a specified region."},{"ref":"AWS.Config.html#delete_remediation_configuration/3","title":"AWS.Config.delete_remediation_configuration/3","type":"function","doc":"Deletes the remediation configuration."},{"ref":"AWS.Config.html#delete_remediation_exceptions/3","title":"AWS.Config.delete_remediation_exceptions/3","type":"function","doc":"Deletes one or more remediation exceptions mentioned in the resource keys. AWS Config generates a remediation exception when a problem occurs executing a remediation action to a specific resource. Remediation exceptions blocks auto-remediation until the exception is cleared."},{"ref":"AWS.Config.html#delete_resource_config/3","title":"AWS.Config.delete_resource_config/3","type":"function","doc":"Records the configuration state for a custom resource that has been deleted. This API records a new ConfigurationItem with a ResourceDeleted status. You can retrieve the ConfigurationItems recorded for this resource in your AWS Config History."},{"ref":"AWS.Config.html#delete_retention_configuration/3","title":"AWS.Config.delete_retention_configuration/3","type":"function","doc":"Deletes the retention configuration."},{"ref":"AWS.Config.html#deliver_config_snapshot/3","title":"AWS.Config.deliver_config_snapshot/3","type":"function","doc":"Schedules delivery of a configuration snapshot to the Amazon S3 bucket in the specified delivery channel. After the delivery has started, AWS Config sends the following notifications using an Amazon SNS topic that you have specified. Notification of the start of the delivery. Notification of the completion of the delivery, if the delivery was successfully completed. Notification of delivery failure, if the delivery failed."},{"ref":"AWS.Config.html#describe_aggregate_compliance_by_config_rules/3","title":"AWS.Config.describe_aggregate_compliance_by_config_rules/3","type":"function","doc":"Returns a list of compliant and noncompliant rules with the number of resources for compliant and noncompliant rules. The results can return an empty result page, but if you have a nextToken, the results are displayed on the next page."},{"ref":"AWS.Config.html#describe_aggregation_authorizations/3","title":"AWS.Config.describe_aggregation_authorizations/3","type":"function","doc":"Returns a list of authorizations granted to various aggregator accounts and regions."},{"ref":"AWS.Config.html#describe_compliance_by_config_rule/3","title":"AWS.Config.describe_compliance_by_config_rule/3","type":"function","doc":"Indicates whether the specified AWS Config rules are compliant. If a rule is noncompliant, this action returns the number of AWS resources that do not comply with the rule. A rule is compliant if all of the evaluated resources comply with it. It is noncompliant if any of these resources do not comply. If AWS Config has no current evaluation results for the rule, it returns INSUFFICIENT_DATA. This result might indicate one of the following conditions: AWS Config has never invoked an evaluation for the rule. To check whether it has, use the DescribeConfigRuleEvaluationStatus action to get the LastSuccessfulInvocationTime and LastFailedInvocationTime. The rule&#39;s AWS Lambda function is failing to send evaluation results to AWS Config. Verify that the role you assigned to your configuration recorder includes the config:PutEvaluations permission. If the rule is a custom rule, verify that the AWS Lambda execution role includes the config:PutEvaluations permission. The rule&#39;s AWS Lambda function has returned NOT_APPLICABLE for all evaluation results. This can occur if the resources were deleted or removed from the rule&#39;s scope."},{"ref":"AWS.Config.html#describe_compliance_by_resource/3","title":"AWS.Config.describe_compliance_by_resource/3","type":"function","doc":"Indicates whether the specified AWS resources are compliant. If a resource is noncompliant, this action returns the number of AWS Config rules that the resource does not comply with. A resource is compliant if it complies with all the AWS Config rules that evaluate it. It is noncompliant if it does not comply with one or more of these rules. If AWS Config has no current evaluation results for the resource, it returns INSUFFICIENT_DATA. This result might indicate one of the following conditions about the rules that evaluate the resource: AWS Config has never invoked an evaluation for the rule. To check whether it has, use the DescribeConfigRuleEvaluationStatus action to get the LastSuccessfulInvocationTime and LastFailedInvocationTime. The rule&#39;s AWS Lambda function is failing to send evaluation results to AWS Config. Verify that the role that you assigned to your configuration recorder includes the config:PutEvaluations permission. If the rule is a custom rule, verify that the AWS Lambda execution role includes the config:PutEvaluations permission. The rule&#39;s AWS Lambda function has returned NOT_APPLICABLE for all evaluation results. This can occur if the resources were deleted or removed from the rule&#39;s scope."},{"ref":"AWS.Config.html#describe_config_rule_evaluation_status/3","title":"AWS.Config.describe_config_rule_evaluation_status/3","type":"function","doc":"Returns status information for each of your AWS managed Config rules. The status includes information such as the last time AWS Config invoked the rule, the last time AWS Config failed to invoke the rule, and the related error for the last failure."},{"ref":"AWS.Config.html#describe_config_rules/3","title":"AWS.Config.describe_config_rules/3","type":"function","doc":"Returns details about your AWS Config rules."},{"ref":"AWS.Config.html#describe_configuration_aggregator_sources_status/3","title":"AWS.Config.describe_configuration_aggregator_sources_status/3","type":"function","doc":"Returns status information for sources within an aggregator. The status includes information about the last time AWS Config verified authorization between the source account and an aggregator account. In case of a failure, the status contains the related error code or message."},{"ref":"AWS.Config.html#describe_configuration_aggregators/3","title":"AWS.Config.describe_configuration_aggregators/3","type":"function","doc":"Returns the details of one or more configuration aggregators. If the configuration aggregator is not specified, this action returns the details for all the configuration aggregators associated with the account."},{"ref":"AWS.Config.html#describe_configuration_recorder_status/3","title":"AWS.Config.describe_configuration_recorder_status/3","type":"function","doc":"Returns the current status of the specified configuration recorder. If a configuration recorder is not specified, this action returns the status of all configuration recorders associated with the account. Currently, you can specify only one configuration recorder per region in your account."},{"ref":"AWS.Config.html#describe_configuration_recorders/3","title":"AWS.Config.describe_configuration_recorders/3","type":"function","doc":"Returns the details for the specified configuration recorders. If the configuration recorder is not specified, this action returns the details for all configuration recorders associated with the account. Currently, you can specify only one configuration recorder per region in your account."},{"ref":"AWS.Config.html#describe_conformance_pack_compliance/3","title":"AWS.Config.describe_conformance_pack_compliance/3","type":"function","doc":"Returns compliance details for each rule in that conformance pack. You must provide exact rule names."},{"ref":"AWS.Config.html#describe_conformance_pack_status/3","title":"AWS.Config.describe_conformance_pack_status/3","type":"function","doc":"Provides one or more conformance packs deployment status. If there are no conformance packs then you will see an empty result."},{"ref":"AWS.Config.html#describe_conformance_packs/3","title":"AWS.Config.describe_conformance_packs/3","type":"function","doc":"Returns a list of one or more conformance packs."},{"ref":"AWS.Config.html#describe_delivery_channel_status/3","title":"AWS.Config.describe_delivery_channel_status/3","type":"function","doc":"Returns the current status of the specified delivery channel. If a delivery channel is not specified, this action returns the current status of all delivery channels associated with the account. Currently, you can specify only one delivery channel per region in your account."},{"ref":"AWS.Config.html#describe_delivery_channels/3","title":"AWS.Config.describe_delivery_channels/3","type":"function","doc":"Returns details about the specified delivery channel. If a delivery channel is not specified, this action returns the details of all delivery channels associated with the account. Currently, you can specify only one delivery channel per region in your account."},{"ref":"AWS.Config.html#describe_organization_config_rule_statuses/3","title":"AWS.Config.describe_organization_config_rule_statuses/3","type":"function","doc":"Provides organization config rule deployment status for an organization. Only a master account and a delegated administrator account can call this API. When calling this API with a delegated administrator, you must ensure AWS Organizations ListDelegatedAdministrator permissions are added. The status is not considered successful until organization config rule is successfully deployed in all the member accounts with an exception of excluded accounts. When you specify the limit and the next token, you receive a paginated response. Limit and next token are not applicable if you specify organization config rule names. It is only applicable, when you request all the organization config rules."},{"ref":"AWS.Config.html#describe_organization_config_rules/3","title":"AWS.Config.describe_organization_config_rules/3","type":"function","doc":"Returns a list of organization config rules. Only a master account and a delegated administrator account can call this API. When calling this API with a delegated administrator, you must ensure AWS Organizations ListDelegatedAdministrator permissions are added. When you specify the limit and the next token, you receive a paginated response. Limit and next token are not applicable if you specify organization config rule names. It is only applicable, when you request all the organization config rules."},{"ref":"AWS.Config.html#describe_organization_conformance_pack_statuses/3","title":"AWS.Config.describe_organization_conformance_pack_statuses/3","type":"function","doc":"Provides organization conformance pack deployment status for an organization. Only a master account and a delegated administrator account can call this API. When calling this API with a delegated administrator, you must ensure AWS Organizations ListDelegatedAdministrator permissions are added. The status is not considered successful until organization conformance pack is successfully deployed in all the member accounts with an exception of excluded accounts. When you specify the limit and the next token, you receive a paginated response. Limit and next token are not applicable if you specify organization conformance pack names. They are only applicable, when you request all the organization conformance packs."},{"ref":"AWS.Config.html#describe_organization_conformance_packs/3","title":"AWS.Config.describe_organization_conformance_packs/3","type":"function","doc":"Returns a list of organization conformance packs. Only a master account and a delegated administrator account can call this API. When calling this API with a delegated administrator, you must ensure AWS Organizations ListDelegatedAdministrator permissions are added. When you specify the limit and the next token, you receive a paginated response. Limit and next token are not applicable if you specify organization conformance packs names. They are only applicable, when you request all the organization conformance packs."},{"ref":"AWS.Config.html#describe_pending_aggregation_requests/3","title":"AWS.Config.describe_pending_aggregation_requests/3","type":"function","doc":"Returns a list of all pending aggregation requests."},{"ref":"AWS.Config.html#describe_remediation_configurations/3","title":"AWS.Config.describe_remediation_configurations/3","type":"function","doc":"Returns the details of one or more remediation configurations."},{"ref":"AWS.Config.html#describe_remediation_exceptions/3","title":"AWS.Config.describe_remediation_exceptions/3","type":"function","doc":"Returns the details of one or more remediation exceptions. A detailed view of a remediation exception for a set of resources that includes an explanation of an exception and the time when the exception will be deleted. When you specify the limit and the next token, you receive a paginated response. AWS Config generates a remediation exception when a problem occurs executing a remediation action to a specific resource. Remediation exceptions blocks auto-remediation until the exception is cleared. When you specify the limit and the next token, you receive a paginated response. Limit and next token are not applicable if you request resources in batch. It is only applicable, when you request all resources."},{"ref":"AWS.Config.html#describe_remediation_execution_status/3","title":"AWS.Config.describe_remediation_execution_status/3","type":"function","doc":"Provides a detailed view of a Remediation Execution for a set of resources including state, timestamps for when steps for the remediation execution occur, and any error messages for steps that have failed. When you specify the limit and the next token, you receive a paginated response."},{"ref":"AWS.Config.html#describe_retention_configurations/3","title":"AWS.Config.describe_retention_configurations/3","type":"function","doc":"Returns the details of one or more retention configurations. If the retention configuration name is not specified, this action returns the details for all the retention configurations for that account. Currently, AWS Config supports only one retention configuration per region in your account."},{"ref":"AWS.Config.html#get_aggregate_compliance_details_by_config_rule/3","title":"AWS.Config.get_aggregate_compliance_details_by_config_rule/3","type":"function","doc":"Returns the evaluation results for the specified AWS Config rule for a specific resource in a rule. The results indicate which AWS resources were evaluated by the rule, when each resource was last evaluated, and whether each resource complies with the rule. The results can return an empty result page. But if you have a nextToken, the results are displayed on the next page."},{"ref":"AWS.Config.html#get_aggregate_config_rule_compliance_summary/3","title":"AWS.Config.get_aggregate_config_rule_compliance_summary/3","type":"function","doc":"Returns the number of compliant and noncompliant rules for one or more accounts and regions in an aggregator. The results can return an empty result page, but if you have a nextToken, the results are displayed on the next page."},{"ref":"AWS.Config.html#get_aggregate_discovered_resource_counts/3","title":"AWS.Config.get_aggregate_discovered_resource_counts/3","type":"function","doc":"Returns the resource counts across accounts and regions that are present in your AWS Config aggregator. You can request the resource counts by providing filters and GroupByKey. For example, if the input contains accountID 12345678910 and region us-east-1 in filters, the API returns the count of resources in account ID 12345678910 and region us-east-1. If the input contains ACCOUNT_ID as a GroupByKey, the API returns resource counts for all source accounts that are present in your aggregator."},{"ref":"AWS.Config.html#get_aggregate_resource_config/3","title":"AWS.Config.get_aggregate_resource_config/3","type":"function","doc":"Returns configuration item that is aggregated for your specific resource in a specific source account and region."},{"ref":"AWS.Config.html#get_compliance_details_by_config_rule/3","title":"AWS.Config.get_compliance_details_by_config_rule/3","type":"function","doc":"Returns the evaluation results for the specified AWS Config rule. The results indicate which AWS resources were evaluated by the rule, when each resource was last evaluated, and whether each resource complies with the rule."},{"ref":"AWS.Config.html#get_compliance_details_by_resource/3","title":"AWS.Config.get_compliance_details_by_resource/3","type":"function","doc":"Returns the evaluation results for the specified AWS resource. The results indicate which AWS Config rules were used to evaluate the resource, when each rule was last used, and whether the resource complies with each rule."},{"ref":"AWS.Config.html#get_compliance_summary_by_config_rule/3","title":"AWS.Config.get_compliance_summary_by_config_rule/3","type":"function","doc":"Returns the number of AWS Config rules that are compliant and noncompliant, up to a maximum of 25 for each."},{"ref":"AWS.Config.html#get_compliance_summary_by_resource_type/3","title":"AWS.Config.get_compliance_summary_by_resource_type/3","type":"function","doc":"Returns the number of resources that are compliant and the number that are noncompliant. You can specify one or more resource types to get these numbers for each resource type. The maximum number returned is 100."},{"ref":"AWS.Config.html#get_conformance_pack_compliance_details/3","title":"AWS.Config.get_conformance_pack_compliance_details/3","type":"function","doc":"Returns compliance details of a conformance pack for all AWS resources that are monitered by conformance pack."},{"ref":"AWS.Config.html#get_conformance_pack_compliance_summary/3","title":"AWS.Config.get_conformance_pack_compliance_summary/3","type":"function","doc":"Returns compliance details for the conformance pack based on the cumulative compliance results of all the rules in that conformance pack."},{"ref":"AWS.Config.html#get_discovered_resource_counts/3","title":"AWS.Config.get_discovered_resource_counts/3","type":"function","doc":"Returns the resource types, the number of each resource type, and the total number of resources that AWS Config is recording in this region for your AWS account. Example AWS Config is recording three resource types in the US East (Ohio) Region for your account: 25 EC2 instances, 20 IAM users, and 15 S3 buckets. You make a call to the GetDiscoveredResourceCounts action and specify that you want all resource types. AWS Config returns the following: The resource types (EC2 instances, IAM users, and S3 buckets). The number of each resource type (25, 20, and 15). The total number of all resources (60). The response is paginated. By default, AWS Config lists 100 ResourceCount objects on each page. You can customize this number with the limit parameter. The response includes a nextToken string. To get the next page of results, run the request again and specify the string for the nextToken parameter. If you make a call to the GetDiscoveredResourceCounts action, you might not immediately receive resource counts in the following situations: You are a new AWS Config customer. You just enabled resource recording. It might take a few minutes for AWS Config to record and count your resources. Wait a few minutes and then retry the GetDiscoveredResourceCounts action."},{"ref":"AWS.Config.html#get_organization_config_rule_detailed_status/3","title":"AWS.Config.get_organization_config_rule_detailed_status/3","type":"function","doc":"Returns detailed status for each member account within an organization for a given organization config rule. Only a master account and a delegated administrator account can call this API. When calling this API with a delegated administrator, you must ensure AWS Organizations ListDelegatedAdministrator permissions are added."},{"ref":"AWS.Config.html#get_organization_conformance_pack_detailed_status/3","title":"AWS.Config.get_organization_conformance_pack_detailed_status/3","type":"function","doc":"Returns detailed status for each member account within an organization for a given organization conformance pack. Only a master account and a delegated administrator account can call this API. When calling this API with a delegated administrator, you must ensure AWS Organizations ListDelegatedAdministrator permissions are added."},{"ref":"AWS.Config.html#get_resource_config_history/3","title":"AWS.Config.get_resource_config_history/3","type":"function","doc":"Returns a list of configuration items for the specified resource. The list contains details about each state of the resource during the specified time interval. If you specified a retention period to retain your ConfigurationItems between a minimum of 30 days and a maximum of 7 years (2557 days), AWS Config returns the ConfigurationItems for the specified retention period. The response is paginated. By default, AWS Config returns a limit of 10 configuration items per page. You can customize this number with the limit parameter. The response includes a nextToken string. To get the next page of results, run the request again and specify the string for the nextToken parameter. Each call to the API is limited to span a duration of seven days. It is likely that the number of records returned is smaller than the specified limit. In such cases, you can make another call, using the nextToken."},{"ref":"AWS.Config.html#list_aggregate_discovered_resources/3","title":"AWS.Config.list_aggregate_discovered_resources/3","type":"function","doc":"Accepts a resource type and returns a list of resource identifiers that are aggregated for a specific resource type across accounts and regions. A resource identifier includes the resource type, ID, (if available) the custom resource name, source account, and source region. You can narrow the results to include only resources that have specific resource IDs, or a resource name, or source account ID, or source region. For example, if the input consists of accountID 12345678910 and the region is us-east-1 for resource type AWS::EC2::Instance then the API returns all the EC2 instance identifiers of accountID 12345678910 and region us-east-1."},{"ref":"AWS.Config.html#list_discovered_resources/3","title":"AWS.Config.list_discovered_resources/3","type":"function","doc":"Accepts a resource type and returns a list of resource identifiers for the resources of that type. A resource identifier includes the resource type, ID, and (if available) the custom resource name. The results consist of resources that AWS Config has discovered, including those that AWS Config is not currently recording. You can narrow the results to include only resources that have specific resource IDs or a resource name. You can specify either resource IDs or a resource name, but not both, in the same request. The response is paginated. By default, AWS Config lists 100 resource identifiers on each page. You can customize this number with the limit parameter. The response includes a nextToken string. To get the next page of results, run the request again and specify the string for the nextToken parameter."},{"ref":"AWS.Config.html#list_tags_for_resource/3","title":"AWS.Config.list_tags_for_resource/3","type":"function","doc":"List the tags for AWS Config resource."},{"ref":"AWS.Config.html#put_aggregation_authorization/3","title":"AWS.Config.put_aggregation_authorization/3","type":"function","doc":"Authorizes the aggregator account and region to collect data from the source account and region."},{"ref":"AWS.Config.html#put_config_rule/3","title":"AWS.Config.put_config_rule/3","type":"function","doc":"Adds or updates an AWS Config rule for evaluating whether your AWS resources comply with your desired configurations. You can use this action for custom AWS Config rules and AWS managed Config rules. A custom AWS Config rule is a rule that you develop and maintain. An AWS managed Config rule is a customizable, predefined rule that AWS Config provides. If you are adding a new custom AWS Config rule, you must first create the AWS Lambda function that the rule invokes to evaluate your resources. When you use the PutConfigRule action to add the rule to AWS Config, you must specify the Amazon Resource Name (ARN) that AWS Lambda assigns to the function. Specify the ARN for the SourceIdentifier key. This key is part of the Source object, which is part of the ConfigRule object. If you are adding an AWS managed Config rule, specify the rule&#39;s identifier for the SourceIdentifier key. To reference AWS managed Config rule identifiers, see About AWS Managed Config Rules. For any new rule that you add, specify the ConfigRuleName in the ConfigRule object. Do not specify the ConfigRuleArn or the ConfigRuleId. These values are generated by AWS Config for new rules. If you are updating a rule that you added previously, you can specify the rule by ConfigRuleName, ConfigRuleId, or ConfigRuleArn in the ConfigRule data type that you use in this request. The maximum number of rules that AWS Config supports is 150. For information about requesting a rule limit increase, see AWS Config Limits in the AWS General Reference Guide. For more information about developing and using AWS Config rules, see Evaluating AWS Resource Configurations with AWS Config in the AWS Config Developer Guide."},{"ref":"AWS.Config.html#put_configuration_aggregator/3","title":"AWS.Config.put_configuration_aggregator/3","type":"function","doc":"Creates and updates the configuration aggregator with the selected source accounts and regions. The source account can be individual account(s) or an organization. AWS Config should be enabled in source accounts and regions you want to aggregate. If your source type is an organization, you must be signed in to the master account and all features must be enabled in your organization. AWS Config calls EnableAwsServiceAccess API to enable integration between AWS Config and AWS Organizations."},{"ref":"AWS.Config.html#put_configuration_recorder/3","title":"AWS.Config.put_configuration_recorder/3","type":"function","doc":"Creates a new configuration recorder to record the selected resource configurations. You can use this action to change the role roleARN or the recordingGroup of an existing recorder. To change the role, call the action on the existing configuration recorder and specify a role. Currently, you can specify only one configuration recorder per region in your account. If ConfigurationRecorder does not have the recordingGroup parameter specified, the default is to record all supported resource types."},{"ref":"AWS.Config.html#put_conformance_pack/3","title":"AWS.Config.put_conformance_pack/3","type":"function","doc":"Creates or updates a conformance pack. A conformance pack is a collection of AWS Config rules that can be easily deployed in an account and a region and across AWS Organization. This API creates a service linked role AWSServiceRoleForConfigConforms in your account. The service linked role is created only when the role does not exist in your account. You must specify either the TemplateS3Uri or the TemplateBody parameter, but not both. If you provide both AWS Config uses the TemplateS3Uri parameter and ignores the TemplateBody parameter."},{"ref":"AWS.Config.html#put_delivery_channel/3","title":"AWS.Config.put_delivery_channel/3","type":"function","doc":"Creates a delivery channel object to deliver configuration information to an Amazon S3 bucket and Amazon SNS topic. Before you can create a delivery channel, you must create a configuration recorder. You can use this action to change the Amazon S3 bucket or an Amazon SNS topic of the existing delivery channel. To change the Amazon S3 bucket or an Amazon SNS topic, call this action and specify the changed values for the S3 bucket and the SNS topic. If you specify a different value for either the S3 bucket or the SNS topic, this action will keep the existing value for the parameter that is not changed. You can have only one delivery channel per region in your account."},{"ref":"AWS.Config.html#put_evaluations/3","title":"AWS.Config.put_evaluations/3","type":"function","doc":"Used by an AWS Lambda function to deliver evaluation results to AWS Config. This action is required in every AWS Lambda function that is invoked by an AWS Config rule."},{"ref":"AWS.Config.html#put_organization_config_rule/3","title":"AWS.Config.put_organization_config_rule/3","type":"function","doc":"Adds or updates organization config rule for your entire organization evaluating whether your AWS resources comply with your desired configurations. Only a master account and a delegated administrator can create or update an organization config rule. When calling this API with a delegated administrator, you must ensure AWS Organizations ListDelegatedAdministrator permissions are added. This API enables organization service access through the EnableAWSServiceAccess action and creates a service linked role AWSServiceRoleForConfigMultiAccountSetup in the master or delegated administrator account of your organization. The service linked role is created only when the role does not exist in the caller account. AWS Config verifies the existence of role with GetRole action. To use this API with delegated administrator, register a delegated administrator by calling AWS Organization register-delegated-administrator for config-multiaccountsetup.amazonaws.com. You can use this action to create both custom AWS Config rules and AWS managed Config rules. If you are adding a new custom AWS Config rule, you must first create AWS Lambda function in the master account or a delegated administrator that the rule invokes to evaluate your resources. When you use the PutOrganizationConfigRule action to add the rule to AWS Config, you must specify the Amazon Resource Name (ARN) that AWS Lambda assigns to the function. If you are adding an AWS managed Config rule, specify the rule&#39;s identifier for the RuleIdentifier key. The maximum number of organization config rules that AWS Config supports is 150 and 3 delegated administrator per organization. Prerequisite: Ensure you call EnableAllFeatures API to enable all features in an organization. Specify either OrganizationCustomRuleMetadata or OrganizationManagedRuleMetadata."},{"ref":"AWS.Config.html#put_organization_conformance_pack/3","title":"AWS.Config.put_organization_conformance_pack/3","type":"function","doc":"Deploys conformance packs across member accounts in an AWS Organization. Only a master account and a delegated administrator can call this API. When calling this API with a delegated administrator, you must ensure AWS Organizations ListDelegatedAdministrator permissions are added. This API enables organization service access for config-multiaccountsetup.amazonaws.com through the EnableAWSServiceAccess action and creates a service linked role AWSServiceRoleForConfigMultiAccountSetup in the master or delegated administrator account of your organization. The service linked role is created only when the role does not exist in the caller account. To use this API with delegated administrator, register a delegated administrator by calling AWS Organization register-delegate-admin for config-multiaccountsetup.amazonaws.com. Prerequisite: Ensure you call EnableAllFeatures API to enable all features in an organization. You must specify either the TemplateS3Uri or the TemplateBody parameter, but not both. If you provide both AWS Config uses the TemplateS3Uri parameter and ignores the TemplateBody parameter. AWS Config sets the state of a conformance pack to CREATE_IN_PROGRESS and UPDATE_IN_PROGRESS until the conformance pack is created or updated. You cannot update a conformance pack while it is in this state. You can create 6 conformance packs with 25 AWS Config rules in each pack and 3 delegated administrator per organization."},{"ref":"AWS.Config.html#put_remediation_configurations/3","title":"AWS.Config.put_remediation_configurations/3","type":"function","doc":"Adds or updates the remediation configuration with a specific AWS Config rule with the selected target or action. The API creates the RemediationConfiguration object for the AWS Config rule. The AWS Config rule must already exist for you to add a remediation configuration. The target (SSM document) must exist and have permissions to use the target. If you make backward incompatible changes to the SSM document, you must call this again to ensure the remediations can run."},{"ref":"AWS.Config.html#put_remediation_exceptions/3","title":"AWS.Config.put_remediation_exceptions/3","type":"function","doc":"A remediation exception is when a specific resource is no longer considered for auto-remediation. This API adds a new exception or updates an exisiting exception for a specific resource with a specific AWS Config rule. AWS Config generates a remediation exception when a problem occurs executing a remediation action to a specific resource. Remediation exceptions blocks auto-remediation until the exception is cleared."},{"ref":"AWS.Config.html#put_resource_config/3","title":"AWS.Config.put_resource_config/3","type":"function","doc":"Records the configuration state for the resource provided in the request. The configuration state of a resource is represented in AWS Config as Configuration Items. Once this API records the configuration item, you can retrieve the list of configuration items for the custom resource type using existing AWS Config APIs. The custom resource type must be registered with AWS CloudFormation. This API accepts the configuration item registered with AWS CloudFormation. When you call this API, AWS Config only stores configuration state of the resource provided in the request. This API does not change or remediate the configuration of the resource. Write-only schema properites are not recorded as part of the published configuration item."},{"ref":"AWS.Config.html#put_retention_configuration/3","title":"AWS.Config.put_retention_configuration/3","type":"function","doc":"Creates and updates the retention configuration with details about retention period (number of days) that AWS Config stores your historical information. The API creates the RetentionConfiguration object and names the object as default. When you have a RetentionConfiguration object named default, calling the API modifies the default object. Currently, AWS Config supports only one retention configuration per region in your account."},{"ref":"AWS.Config.html#select_aggregate_resource_config/3","title":"AWS.Config.select_aggregate_resource_config/3","type":"function","doc":"Accepts a structured query language (SQL) SELECT command and an aggregator to query configuration state of AWS resources across multiple accounts and regions, performs the corresponding search, and returns resource configurations matching the properties. For more information about query components, see the Query Components section in the AWS Config Developer Guide."},{"ref":"AWS.Config.html#select_resource_config/3","title":"AWS.Config.select_resource_config/3","type":"function","doc":"Accepts a structured query language (SQL) SELECT command, performs the corresponding search, and returns resource configurations matching the properties. For more information about query components, see the Query Components section in the AWS Config Developer Guide."},{"ref":"AWS.Config.html#start_config_rules_evaluation/3","title":"AWS.Config.start_config_rules_evaluation/3","type":"function","doc":"Runs an on-demand evaluation for the specified AWS Config rules against the last known configuration state of the resources. Use StartConfigRulesEvaluation when you want to test that a rule you updated is working as expected. StartConfigRulesEvaluation does not re-record the latest configuration state for your resources. It re-runs an evaluation against the last known state of your resources. You can specify up to 25 AWS Config rules per request. An existing StartConfigRulesEvaluation call for the specified rules must complete before you can call the API again. If you chose to have AWS Config stream to an Amazon SNS topic, you will receive a ConfigRuleEvaluationStarted notification when the evaluation starts. You don&#39;t need to call the StartConfigRulesEvaluation API to run an evaluation for a new rule. When you create a rule, AWS Config evaluates your resources against the rule automatically. The StartConfigRulesEvaluation API is useful if you want to run on-demand evaluations, such as the following example: You have a custom rule that evaluates your IAM resources every 24 hours. You update your Lambda function to add additional conditions to your rule. Instead of waiting for the next periodic evaluation, you call the StartConfigRulesEvaluation API. AWS Config invokes your Lambda function and evaluates your IAM resources. Your custom rule will still run periodic evaluations every 24 hours."},{"ref":"AWS.Config.html#start_configuration_recorder/3","title":"AWS.Config.start_configuration_recorder/3","type":"function","doc":"Starts recording configurations of the AWS resources you have selected to record in your AWS account. You must have created at least one delivery channel to successfully start the configuration recorder."},{"ref":"AWS.Config.html#start_remediation_execution/3","title":"AWS.Config.start_remediation_execution/3","type":"function","doc":"Runs an on-demand remediation for the specified AWS Config rules against the last known remediation configuration. It runs an execution against the current state of your resources. Remediation execution is asynchronous. You can specify up to 100 resource keys per request. An existing StartRemediationExecution call for the specified resource keys must complete before you can call the API again."},{"ref":"AWS.Config.html#stop_configuration_recorder/3","title":"AWS.Config.stop_configuration_recorder/3","type":"function","doc":"Stops recording configurations of the AWS resources you have selected to record in your AWS account."},{"ref":"AWS.Config.html#tag_resource/3","title":"AWS.Config.tag_resource/3","type":"function","doc":"Associates the specified tags to a resource with the specified resourceArn. If existing tags on a resource are not specified in the request parameters, they are not changed. When a resource is deleted, the tags associated with that resource are deleted as well."},{"ref":"AWS.Config.html#untag_resource/3","title":"AWS.Config.untag_resource/3","type":"function","doc":"Deletes specified tags from a resource."},{"ref":"AWS.Connect.html","title":"AWS.Connect","type":"module","doc":"Amazon Connect is a cloud-based contact center solution that makes it easy to set up and manage a customer contact center and provide reliable customer engagement at any scale. Amazon Connect provides rich metrics and real-time reporting that allow you to optimize contact routing. You can also resolve customer issues more efficiently by putting customers in touch with the right agents. There are limits to the number of Amazon Connect resources that you can create and limits to the number of requests that you can make per second. For more information, see Amazon Connect Service Quotas in the Amazon Connect Administrator Guide. To connect programmatically to an AWS service, you use an endpoint. For a list of Amazon Connect endpoints, see Amazon Connect Endpoints. Working with contact flows? Check out the Amazon Connect Flow language."},{"ref":"AWS.Connect.html#associate_routing_profile_queues/5","title":"AWS.Connect.associate_routing_profile_queues/5","type":"function","doc":"Associates a set of queues with a routing profile."},{"ref":"AWS.Connect.html#create_contact_flow/4","title":"AWS.Connect.create_contact_flow/4","type":"function","doc":"Creates a contact flow for the specified Amazon Connect instance. You can also create and update contact flows using the Amazon Connect Flow language."},{"ref":"AWS.Connect.html#create_routing_profile/4","title":"AWS.Connect.create_routing_profile/4","type":"function","doc":"Creates a new routing profile."},{"ref":"AWS.Connect.html#create_user/4","title":"AWS.Connect.create_user/4","type":"function","doc":"Creates a user account for the specified Amazon Connect instance. For information about how to create user accounts using the Amazon Connect console, see Add Users in the Amazon Connect Administrator Guide."},{"ref":"AWS.Connect.html#delete_user/5","title":"AWS.Connect.delete_user/5","type":"function","doc":"Deletes a user account from the specified Amazon Connect instance. For information about what happens to a user&#39;s data when their account is deleted, see Delete Users from Your Amazon Connect Instance in the Amazon Connect Administrator Guide."},{"ref":"AWS.Connect.html#describe_contact_flow/4","title":"AWS.Connect.describe_contact_flow/4","type":"function","doc":"Describes the specified contact flow. You can also create and update contact flows using the Amazon Connect Flow language."},{"ref":"AWS.Connect.html#describe_routing_profile/4","title":"AWS.Connect.describe_routing_profile/4","type":"function","doc":"Describes the specified routing profile."},{"ref":"AWS.Connect.html#describe_user/4","title":"AWS.Connect.describe_user/4","type":"function","doc":"Describes the specified user account. You can find the instance ID in the console (its the final part of the ARN). The console does not display the user IDs. Instead, list the users and note the IDs provided in the output."},{"ref":"AWS.Connect.html#describe_user_hierarchy_group/4","title":"AWS.Connect.describe_user_hierarchy_group/4","type":"function","doc":"Describes the specified hierarchy group."},{"ref":"AWS.Connect.html#describe_user_hierarchy_structure/3","title":"AWS.Connect.describe_user_hierarchy_structure/3","type":"function","doc":"Describes the hierarchy structure of the specified Amazon Connect instance."},{"ref":"AWS.Connect.html#disassociate_routing_profile_queues/5","title":"AWS.Connect.disassociate_routing_profile_queues/5","type":"function","doc":"Disassociates a set of queues from a routing profile."},{"ref":"AWS.Connect.html#get_contact_attributes/4","title":"AWS.Connect.get_contact_attributes/4","type":"function","doc":"Retrieves the contact attributes for the specified contact."},{"ref":"AWS.Connect.html#get_current_metric_data/4","title":"AWS.Connect.get_current_metric_data/4","type":"function","doc":"Gets the real-time metric data from the specified Amazon Connect instance. For a description of each metric, see Real-time Metrics Definitions in the Amazon Connect Administrator Guide."},{"ref":"AWS.Connect.html#get_federation_token/3","title":"AWS.Connect.get_federation_token/3","type":"function","doc":"Retrieves a token for federation."},{"ref":"AWS.Connect.html#get_metric_data/4","title":"AWS.Connect.get_metric_data/4","type":"function","doc":"Gets historical metric data from the specified Amazon Connect instance. For a description of each historical metric, see Historical Metrics Definitions in the Amazon Connect Administrator Guide."},{"ref":"AWS.Connect.html#list_contact_flows/6","title":"AWS.Connect.list_contact_flows/6","type":"function","doc":"Provides information about the contact flows for the specified Amazon Connect instance. You can also create and update contact flows using the Amazon Connect Flow language. For more information about contact flows, see Contact Flows in the Amazon Connect Administrator Guide."},{"ref":"AWS.Connect.html#list_hours_of_operations/5","title":"AWS.Connect.list_hours_of_operations/5","type":"function","doc":"Provides information about the hours of operation for the specified Amazon Connect instance. For more information about hours of operation, see Set the Hours of Operation for a Queue in the Amazon Connect Administrator Guide."},{"ref":"AWS.Connect.html#list_phone_numbers/7","title":"AWS.Connect.list_phone_numbers/7","type":"function","doc":"Provides information about the phone numbers for the specified Amazon Connect instance. For more information about phone numbers, see Set Up Phone Numbers for Your Contact Center in the Amazon Connect Administrator Guide."},{"ref":"AWS.Connect.html#list_prompts/5","title":"AWS.Connect.list_prompts/5","type":"function","doc":"Provides information about the prompts for the specified Amazon Connect instance."},{"ref":"AWS.Connect.html#list_queues/6","title":"AWS.Connect.list_queues/6","type":"function","doc":"Provides information about the queues for the specified Amazon Connect instance. For more information about queues, see Queues: Standard and Agent in the Amazon Connect Administrator Guide."},{"ref":"AWS.Connect.html#list_routing_profile_queues/6","title":"AWS.Connect.list_routing_profile_queues/6","type":"function","doc":"List the queues associated with a routing profile."},{"ref":"AWS.Connect.html#list_routing_profiles/5","title":"AWS.Connect.list_routing_profiles/5","type":"function","doc":"Provides summary information about the routing profiles for the specified Amazon Connect instance. For more information about routing profiles, see Routing Profiles and Create a Routing Profile in the Amazon Connect Administrator Guide."},{"ref":"AWS.Connect.html#list_security_profiles/5","title":"AWS.Connect.list_security_profiles/5","type":"function","doc":"Provides summary information about the security profiles for the specified Amazon Connect instance. For more information about security profiles, see Security Profiles in the Amazon Connect Administrator Guide."},{"ref":"AWS.Connect.html#list_tags_for_resource/3","title":"AWS.Connect.list_tags_for_resource/3","type":"function","doc":"Lists the tags for the specified resource. For sample policies that use tags, see Amazon Connect Identity-Based Policy Examples in the Amazon Connect Administrator Guide."},{"ref":"AWS.Connect.html#list_user_hierarchy_groups/5","title":"AWS.Connect.list_user_hierarchy_groups/5","type":"function","doc":"Provides summary information about the hierarchy groups for the specified Amazon Connect instance. For more information about agent hierarchies, see Set Up Agent Hierarchies in the Amazon Connect Administrator Guide."},{"ref":"AWS.Connect.html#list_users/5","title":"AWS.Connect.list_users/5","type":"function","doc":"Provides summary information about the users for the specified Amazon Connect instance."},{"ref":"AWS.Connect.html#resume_contact_recording/3","title":"AWS.Connect.resume_contact_recording/3","type":"function","doc":"When a contact is being recorded, and the recording has been suspended using SuspendContactRecording, this API resumes recording the call. Only voice recordings are supported at this time."},{"ref":"AWS.Connect.html#start_chat_contact/3","title":"AWS.Connect.start_chat_contact/3","type":"function","doc":"Initiates a contact flow to start a new chat for the customer. Response of this API provides a token required to obtain credentials from the CreateParticipantConnection API in the Amazon Connect Participant Service. When a new chat contact is successfully created, clients need to subscribe to the participants connection for the created chat within 5 minutes. This is achieved by invoking CreateParticipantConnection with WEBSOCKET and CONNECTION_CREDENTIALS. A 429 error occurs in two situations: API rate limit is exceeded. API TPS throttling returns a TooManyRequests exception from the API Gateway. The quota for concurrent active chats is exceeded. Active chat throttling returns a LimitExceededException. For more information about how chat works, see Chat in the Amazon Connect Administrator Guide."},{"ref":"AWS.Connect.html#start_contact_recording/3","title":"AWS.Connect.start_contact_recording/3","type":"function","doc":"This API starts recording the contact when the agent joins the call. StartContactRecording is a one-time action. For example, if you use StopContactRecording to stop recording an ongoing call, you can&#39;t use StartContactRecording to restart it. For scenarios where the recording has started and you want to suspend and resume it, such as when collecting sensitive information (for example, a credit card number), use SuspendContactRecording and ResumeContactRecording. You can use this API to override the recording behavior configured in the Set recording behavior block. Only voice recordings are supported at this time."},{"ref":"AWS.Connect.html#start_outbound_voice_contact/3","title":"AWS.Connect.start_outbound_voice_contact/3","type":"function","doc":"This API places an outbound call to a contact, and then initiates the contact flow. It performs the actions in the contact flow that&#39;s specified (in ContactFlowId). Agents are not involved in initiating the outbound API (that is, dialing the contact). If the contact flow places an outbound call to a contact, and then puts the contact in queue, that&#39;s when the call is routed to the agent, like any other inbound case. There is a 60 second dialing timeout for this operation. If the call is not connected after 60 seconds, it fails. UK numbers with a 447 prefix are not allowed by default. Before you can dial these UK mobile numbers, you must submit a service quota increase request. For more information, see Amazon Connect Service Quotas in the Amazon Connect Administrator Guide."},{"ref":"AWS.Connect.html#stop_contact/3","title":"AWS.Connect.stop_contact/3","type":"function","doc":"Ends the specified contact."},{"ref":"AWS.Connect.html#stop_contact_recording/3","title":"AWS.Connect.stop_contact_recording/3","type":"function","doc":"When a contact is being recorded, this API stops recording the call. StopContactRecording is a one-time action. If you use StopContactRecording to stop recording an ongoing call, you can&#39;t use StartContactRecording to restart it. For scenarios where the recording has started and you want to suspend it for sensitive information (for example, to collect a credit card number), and then restart it, use SuspendContactRecording and ResumeContactRecording. Only voice recordings are supported at this time."},{"ref":"AWS.Connect.html#suspend_contact_recording/3","title":"AWS.Connect.suspend_contact_recording/3","type":"function","doc":"When a contact is being recorded, this API suspends recording the call. For example, you might suspend the call recording while collecting sensitive information, such as a credit card number. Then use ResumeContactRecording to restart recording. The period of time that the recording is suspended is filled with silence in the final recording. Only voice recordings are supported at this time."},{"ref":"AWS.Connect.html#tag_resource/4","title":"AWS.Connect.tag_resource/4","type":"function","doc":"Adds the specified tags to the specified resource. The supported resource types are users, routing profiles, and contact flows. For sample policies that use tags, see Amazon Connect Identity-Based Policy Examples in the Amazon Connect Administrator Guide."},{"ref":"AWS.Connect.html#untag_resource/4","title":"AWS.Connect.untag_resource/4","type":"function","doc":"Removes the specified tags from the specified resource."},{"ref":"AWS.Connect.html#update_contact_attributes/3","title":"AWS.Connect.update_contact_attributes/3","type":"function","doc":"Creates or updates the contact attributes associated with the specified contact. You can add or update attributes for both ongoing and completed contacts. For example, you can update the customer&#39;s name or the reason the customer called while the call is active, or add notes about steps that the agent took during the call that are displayed to the next agent that takes the call. You can also update attributes for a contact using data from your CRM application and save the data with the contact in Amazon Connect. You could also flag calls for additional analysis, such as legal review or identifying abusive callers. Contact attributes are available in Amazon Connect for 24 months, and are then deleted. This operation is also available in the Amazon Connect Flow language. See UpdateContactAttributes. Important: You cannot use the operation to update attributes for contacts that occurred prior to the release of the API, September 12, 2018. You can update attributes only for contacts that started after the release of the API. If you attempt to update attributes for a contact that occurred prior to the release of the API, a 400 error is returned. This applies also to queued callbacks that were initiated prior to the release of the API but are still active in your instance."},{"ref":"AWS.Connect.html#update_contact_flow_content/5","title":"AWS.Connect.update_contact_flow_content/5","type":"function","doc":"Updates the specified contact flow. You can also create and update contact flows using the Amazon Connect Flow language."},{"ref":"AWS.Connect.html#update_contact_flow_name/5","title":"AWS.Connect.update_contact_flow_name/5","type":"function","doc":"The name of the contact flow."},{"ref":"AWS.Connect.html#update_routing_profile_concurrency/5","title":"AWS.Connect.update_routing_profile_concurrency/5","type":"function","doc":"Updates the channels that agents can handle in the Contact Control Panel (CCP) for a routing profile."},{"ref":"AWS.Connect.html#update_routing_profile_default_outbound_queue/5","title":"AWS.Connect.update_routing_profile_default_outbound_queue/5","type":"function","doc":"Updates the default outbound queue of a routing profile."},{"ref":"AWS.Connect.html#update_routing_profile_name/5","title":"AWS.Connect.update_routing_profile_name/5","type":"function","doc":"Updates the name and description of a routing profile. The request accepts the following data in JSON format. At least Name or Description must be provided."},{"ref":"AWS.Connect.html#update_routing_profile_queues/5","title":"AWS.Connect.update_routing_profile_queues/5","type":"function","doc":"Updates the properties associated with a set of queues for a routing profile."},{"ref":"AWS.Connect.html#update_user_hierarchy/5","title":"AWS.Connect.update_user_hierarchy/5","type":"function","doc":"Assigns the specified hierarchy group to the specified user."},{"ref":"AWS.Connect.html#update_user_identity_info/5","title":"AWS.Connect.update_user_identity_info/5","type":"function","doc":"Updates the identity information for the specified user. Someone with the ability to invoke UpdateUserIndentityInfo can change the login credentials of other users by changing their email address. This poses a security risk to your organization. They can change the email address of a user to the attacker&#39;s email address, and then reset the password through email. We strongly recommend limiting who has the ability to invoke UpdateUserIndentityInfo. For more information, see Best Practices for Security Profiles in the Amazon Connect Administrator Guide."},{"ref":"AWS.Connect.html#update_user_phone_config/5","title":"AWS.Connect.update_user_phone_config/5","type":"function","doc":"Updates the phone configuration settings for the specified user."},{"ref":"AWS.Connect.html#update_user_routing_profile/5","title":"AWS.Connect.update_user_routing_profile/5","type":"function","doc":"Assigns the specified routing profile to the specified user."},{"ref":"AWS.Connect.html#update_user_security_profiles/5","title":"AWS.Connect.update_user_security_profiles/5","type":"function","doc":"Assigns the specified security profiles to the specified user."},{"ref":"AWS.ConnectParticipant.html","title":"AWS.ConnectParticipant","type":"module","doc":"Amazon Connect is a cloud-based contact center solution that makes it easy to set up and manage a customer contact center and provide reliable customer engagement at any scale. Amazon Connect enables customer contacts through voice or chat. The APIs described here are used by chat participants, such as agents and customers."},{"ref":"AWS.ConnectParticipant.html#create_participant_connection/3","title":"AWS.ConnectParticipant.create_participant_connection/3","type":"function","doc":"Creates the participant&#39;s connection. Note that ParticipantToken is used for invoking this API instead of ConnectionToken. The participant token is valid for the lifetime of the participant  until the they are part of a contact. The response URL for WEBSOCKET Type has a connect expiry timeout of 100s. Clients must manually connect to the returned websocket URL and subscribe to the desired topic. For chat, you need to publish the following on the established websocket connection: {&quot;topic&quot;:&quot;aws/subscribe&quot;,&quot;content&quot;:{&quot;topics&quot;:[&quot;aws/chat&quot;]}} Upon websocket URL expiry, as specified in the response ConnectionExpiry parameter, clients need to call this API again to obtain a new websocket URL and perform the same steps as before."},{"ref":"AWS.ConnectParticipant.html#disconnect_participant/3","title":"AWS.ConnectParticipant.disconnect_participant/3","type":"function","doc":"Disconnects a participant. Note that ConnectionToken is used for invoking this API instead of ParticipantToken."},{"ref":"AWS.ConnectParticipant.html#get_transcript/3","title":"AWS.ConnectParticipant.get_transcript/3","type":"function","doc":"Retrieves a transcript of the session. Note that ConnectionToken is used for invoking this API instead of ParticipantToken."},{"ref":"AWS.ConnectParticipant.html#send_event/3","title":"AWS.ConnectParticipant.send_event/3","type":"function","doc":"Sends an event. Note that ConnectionToken is used for invoking this API instead of ParticipantToken."},{"ref":"AWS.ConnectParticipant.html#send_message/3","title":"AWS.ConnectParticipant.send_message/3","type":"function","doc":"Sends a message. Note that ConnectionToken is used for invoking this API instead of ParticipantToken."},{"ref":"AWS.CostExplorer.html","title":"AWS.CostExplorer","type":"module","doc":"The Cost Explorer API enables you to programmatically query your cost and usage data. You can query for aggregated data such as total monthly costs or total daily usage. You can also query for granular data, such as the number of daily write operations for Amazon DynamoDB database tables in your production environment. Service Endpoint The Cost Explorer API provides the following endpoint: https://ce.us-east-1.amazonaws.com For information about costs associated with the Cost Explorer API, see AWS Cost Management Pricing."},{"ref":"AWS.CostExplorer.html#create_anomaly_monitor/3","title":"AWS.CostExplorer.create_anomaly_monitor/3","type":"function","doc":"Creates a new cost anomaly detection monitor with the requested type and monitor specification."},{"ref":"AWS.CostExplorer.html#create_anomaly_subscription/3","title":"AWS.CostExplorer.create_anomaly_subscription/3","type":"function","doc":"Adds a subscription to a cost anomaly detection monitor. You can use each subscription to define subscribers with email or SNS notifications. Email subscribers can set a dollar threshold and a time frequency for receiving notifications."},{"ref":"AWS.CostExplorer.html#create_cost_category_definition/3","title":"AWS.CostExplorer.create_cost_category_definition/3","type":"function","doc":"Creates a new Cost Category with the requested name and rules."},{"ref":"AWS.CostExplorer.html#delete_anomaly_monitor/3","title":"AWS.CostExplorer.delete_anomaly_monitor/3","type":"function","doc":"Deletes a cost anomaly monitor."},{"ref":"AWS.CostExplorer.html#delete_anomaly_subscription/3","title":"AWS.CostExplorer.delete_anomaly_subscription/3","type":"function","doc":"Deletes a cost anomaly subscription."},{"ref":"AWS.CostExplorer.html#delete_cost_category_definition/3","title":"AWS.CostExplorer.delete_cost_category_definition/3","type":"function","doc":"Deletes a Cost Category. Expenses from this month going forward will no longer be categorized with this Cost Category."},{"ref":"AWS.CostExplorer.html#describe_cost_category_definition/3","title":"AWS.CostExplorer.describe_cost_category_definition/3","type":"function","doc":"Returns the name, ARN, rules, definition, and effective dates of a Cost Category that&#39;s defined in the account. You have the option to use EffectiveOn to return a Cost Category that is active on a specific date. If there is no EffectiveOn specified, youll see a Cost Category that is effective on the current date. If Cost Category is still effective, EffectiveEnd is omitted in the response."},{"ref":"AWS.CostExplorer.html#get_anomalies/3","title":"AWS.CostExplorer.get_anomalies/3","type":"function","doc":"Retrieves all of the cost anomalies detected on your account, during the time period specified by the DateInterval object."},{"ref":"AWS.CostExplorer.html#get_anomaly_monitors/3","title":"AWS.CostExplorer.get_anomaly_monitors/3","type":"function","doc":"Retrieves the cost anomaly monitor definitions for your account. You can filter using a list of cost anomaly monitor Amazon Resource Names (ARNs)."},{"ref":"AWS.CostExplorer.html#get_anomaly_subscriptions/3","title":"AWS.CostExplorer.get_anomaly_subscriptions/3","type":"function","doc":"Retrieves the cost anomaly subscription objects for your account. You can filter using a list of cost anomaly monitor Amazon Resource Names (ARNs)."},{"ref":"AWS.CostExplorer.html#get_cost_and_usage/3","title":"AWS.CostExplorer.get_cost_and_usage/3","type":"function","doc":"Retrieves cost and usage metrics for your account. You can specify which cost and usage-related metric, such as BlendedCosts or UsageQuantity, that you want the request to return. You can also filter and group your data by various dimensions, such as SERVICE or AZ, in a specific time range. For a complete list of valid dimensions, see the GetDimensionValues operation. Master account in an organization in AWS Organizations have access to all member accounts."},{"ref":"AWS.CostExplorer.html#get_cost_and_usage_with_resources/3","title":"AWS.CostExplorer.get_cost_and_usage_with_resources/3","type":"function","doc":"Retrieves cost and usage metrics with resources for your account. You can specify which cost and usage-related metric, such as BlendedCosts or UsageQuantity, that you want the request to return. You can also filter and group your data by various dimensions, such as SERVICE or AZ, in a specific time range. For a complete list of valid dimensions, see the GetDimensionValues operation. Master account in an organization in AWS Organizations have access to all member accounts. This API is currently available for the Amazon Elastic Compute Cloud  Compute service only. This is an opt-in only feature. You can enable this feature from the Cost Explorer Settings page. For information on how to access the Settings page, see Controlling Access for Cost Explorer in the AWS Billing and Cost Management User Guide."},{"ref":"AWS.CostExplorer.html#get_cost_forecast/3","title":"AWS.CostExplorer.get_cost_forecast/3","type":"function","doc":"Retrieves a forecast for how much Amazon Web Services predicts that you will spend over the forecast time period that you select, based on your past costs."},{"ref":"AWS.CostExplorer.html#get_dimension_values/3","title":"AWS.CostExplorer.get_dimension_values/3","type":"function","doc":"Retrieves all available filter values for a specified filter over a period of time. You can search the dimension values for an arbitrary string."},{"ref":"AWS.CostExplorer.html#get_reservation_coverage/3","title":"AWS.CostExplorer.get_reservation_coverage/3","type":"function","doc":"Retrieves the reservation coverage for your account. This enables you to see how much of your Amazon Elastic Compute Cloud, Amazon ElastiCache, Amazon Relational Database Service, or Amazon Redshift usage is covered by a reservation. An organization&#39;s master account can see the coverage of the associated member accounts. This supports dimensions, Cost Categories, and nested expressions. For any time period, you can filter data about reservation usage by the following dimensions: AZ CACHE_ENGINE DATABASE_ENGINE DEPLOYMENT_OPTION INSTANCE_TYPE LINKED_ACCOUNT OPERATING_SYSTEM PLATFORM REGION SERVICE TAG TENANCY To determine valid values for a dimension, use the GetDimensionValues operation."},{"ref":"AWS.CostExplorer.html#get_reservation_purchase_recommendation/3","title":"AWS.CostExplorer.get_reservation_purchase_recommendation/3","type":"function","doc":"Gets recommendations for which reservations to purchase. These recommendations could help you reduce your costs. Reservations provide a discounted hourly rate (up to 75%) compared to On-Demand pricing. AWS generates your recommendations by identifying your On-Demand usage during a specific time period and collecting your usage into categories that are eligible for a reservation. After AWS has these categories, it simulates every combination of reservations in each category of usage to identify the best number of each type of RI to purchase to maximize your estimated savings. For example, AWS automatically aggregates your Amazon EC2 Linux, shared tenancy, and c4 family usage in the US West (Oregon) Region and recommends that you buy size-flexible regional reservations to apply to the c4 family usage. AWS recommends the smallest size instance in an instance family. This makes it easier to purchase a size-flexible RI. AWS also shows the equal number of normalized units so that you can purchase any instance size that you want. For this example, your RI recommendation would be for c4.large because that is the smallest size instance in the c4 instance family."},{"ref":"AWS.CostExplorer.html#get_reservation_utilization/3","title":"AWS.CostExplorer.get_reservation_utilization/3","type":"function","doc":"Retrieves the reservation utilization for your account. Master account in an organization have access to member accounts. You can filter data by dimensions in a time period. You can use GetDimensionValues to determine the possible dimension values. Currently, you can group only by SUBSCRIPTION_ID."},{"ref":"AWS.CostExplorer.html#get_rightsizing_recommendation/3","title":"AWS.CostExplorer.get_rightsizing_recommendation/3","type":"function","doc":"Creates recommendations that help you save cost by identifying idle and underutilized Amazon EC2 instances. Recommendations are generated to either downsize or terminate instances, along with providing savings detail and metrics. For details on calculation and function, see Optimizing Your Cost with Rightsizing Recommendations in the AWS Billing and Cost Management User Guide."},{"ref":"AWS.CostExplorer.html#get_savings_plans_coverage/3","title":"AWS.CostExplorer.get_savings_plans_coverage/3","type":"function","doc":"Retrieves the Savings Plans covered for your account. This enables you to see how much of your cost is covered by a Savings Plan. An organizations master account can see the coverage of the associated member accounts. This supports dimensions, Cost Categories, and nested expressions. For any time period, you can filter data for Savings Plans usage with the following dimensions: LINKED_ACCOUNT REGION SERVICE INSTANCE_FAMILY To determine valid values for a dimension, use the GetDimensionValues operation."},{"ref":"AWS.CostExplorer.html#get_savings_plans_purchase_recommendation/3","title":"AWS.CostExplorer.get_savings_plans_purchase_recommendation/3","type":"function","doc":"Retrieves your request parameters, Savings Plan Recommendations Summary and Details."},{"ref":"AWS.CostExplorer.html#get_savings_plans_utilization/3","title":"AWS.CostExplorer.get_savings_plans_utilization/3","type":"function","doc":"Retrieves the Savings Plans utilization for your account across date ranges with daily or monthly granularity. Master account in an organization have access to member accounts. You can use GetDimensionValues in SAVINGS_PLANS to determine the possible dimension values. You cannot group by any dimension values for GetSavingsPlansUtilization."},{"ref":"AWS.CostExplorer.html#get_savings_plans_utilization_details/3","title":"AWS.CostExplorer.get_savings_plans_utilization_details/3","type":"function","doc":"Retrieves attribute data along with aggregate utilization and savings data for a given time period. This doesn&#39;t support granular or grouped data (daily/monthly) in response. You can&#39;t retrieve data by dates in a single response similar to GetSavingsPlanUtilization, but you have the option to make multiple calls to GetSavingsPlanUtilizationDetails by providing individual dates. You can use GetDimensionValues in SAVINGS_PLANS to determine the possible dimension values. GetSavingsPlanUtilizationDetails internally groups data by SavingsPlansArn."},{"ref":"AWS.CostExplorer.html#get_tags/3","title":"AWS.CostExplorer.get_tags/3","type":"function","doc":"Queries for available tag keys and tag values for a specified period. You can search the tag values for an arbitrary string."},{"ref":"AWS.CostExplorer.html#get_usage_forecast/3","title":"AWS.CostExplorer.get_usage_forecast/3","type":"function","doc":"Retrieves a forecast for how much Amazon Web Services predicts that you will use over the forecast time period that you select, based on your past usage."},{"ref":"AWS.CostExplorer.html#list_cost_category_definitions/3","title":"AWS.CostExplorer.list_cost_category_definitions/3","type":"function","doc":"Returns the name, ARN, NumberOfRules and effective dates of all Cost Categories defined in the account. You have the option to use EffectiveOn to return a list of Cost Categories that were active on a specific date. If there is no EffectiveOn specified, youll see Cost Categories that are effective on the current date. If Cost Category is still effective, EffectiveEnd is omitted in the response. ListCostCategoryDefinitions supports pagination. The request can have a MaxResults range up to 100."},{"ref":"AWS.CostExplorer.html#provide_anomaly_feedback/3","title":"AWS.CostExplorer.provide_anomaly_feedback/3","type":"function","doc":"Modifies the feedback property of a given cost anomaly."},{"ref":"AWS.CostExplorer.html#update_anomaly_monitor/3","title":"AWS.CostExplorer.update_anomaly_monitor/3","type":"function","doc":"Updates an existing cost anomaly monitor. The changes made are applied going forward, and does not change anomalies detected in the past."},{"ref":"AWS.CostExplorer.html#update_anomaly_subscription/3","title":"AWS.CostExplorer.update_anomaly_subscription/3","type":"function","doc":"Updates an existing cost anomaly monitor subscription."},{"ref":"AWS.CostExplorer.html#update_cost_category_definition/3","title":"AWS.CostExplorer.update_cost_category_definition/3","type":"function","doc":"Updates an existing Cost Category. Changes made to the Cost Category rules will be used to categorize the current months expenses and future expenses. This wont change categorization for the previous months."},{"ref":"AWS.CostandUsageReport.html","title":"AWS.CostandUsageReport","type":"module","doc":"The AWS Cost and Usage Report API enables you to programmatically create, query, and delete AWS Cost and Usage report definitions. AWS Cost and Usage reports track the monthly AWS costs and usage associated with your AWS account. The report contains line items for each unique combination of AWS product, usage type, and operation that your AWS account uses. You can configure the AWS Cost and Usage report to show only the data that you want, using the AWS Cost and Usage API. Service Endpoint The AWS Cost and Usage Report API provides the following endpoint: cur.us-east-1.amazonaws.com"},{"ref":"AWS.CostandUsageReport.html#delete_report_definition/3","title":"AWS.CostandUsageReport.delete_report_definition/3","type":"function","doc":"Deletes the specified report."},{"ref":"AWS.CostandUsageReport.html#describe_report_definitions/3","title":"AWS.CostandUsageReport.describe_report_definitions/3","type":"function","doc":"Lists the AWS Cost and Usage reports available to this account."},{"ref":"AWS.CostandUsageReport.html#modify_report_definition/3","title":"AWS.CostandUsageReport.modify_report_definition/3","type":"function","doc":"Allows you to programatically update your report preferences."},{"ref":"AWS.CostandUsageReport.html#put_report_definition/3","title":"AWS.CostandUsageReport.put_report_definition/3","type":"function","doc":"Creates a new report using the description that you provide."},{"ref":"AWS.DAX.html","title":"AWS.DAX","type":"module","doc":"DAX is a managed caching service engineered for Amazon DynamoDB. DAX dramatically speeds up database reads by caching frequently-accessed data from DynamoDB, so applications can access that data with sub-millisecond latency. You can create a DAX cluster easily, using the AWS Management Console. With a few simple modifications to your code, your application can begin taking advantage of the DAX cluster and realize significant improvements in read performance."},{"ref":"AWS.DAX.html#create_cluster/3","title":"AWS.DAX.create_cluster/3","type":"function","doc":"Creates a DAX cluster. All nodes in the cluster run the same DAX caching software."},{"ref":"AWS.DAX.html#create_parameter_group/3","title":"AWS.DAX.create_parameter_group/3","type":"function","doc":"Creates a new parameter group. A parameter group is a collection of parameters that you apply to all of the nodes in a DAX cluster."},{"ref":"AWS.DAX.html#create_subnet_group/3","title":"AWS.DAX.create_subnet_group/3","type":"function","doc":"Creates a new subnet group."},{"ref":"AWS.DAX.html#decrease_replication_factor/3","title":"AWS.DAX.decrease_replication_factor/3","type":"function","doc":"Removes one or more nodes from a DAX cluster. You cannot use DecreaseReplicationFactor to remove the last node in a DAX cluster. If you need to do this, use DeleteCluster instead."},{"ref":"AWS.DAX.html#delete_cluster/3","title":"AWS.DAX.delete_cluster/3","type":"function","doc":"Deletes a previously provisioned DAX cluster. DeleteCluster deletes all associated nodes, node endpoints and the DAX cluster itself. When you receive a successful response from this action, DAX immediately begins deleting the cluster; you cannot cancel or revert this action."},{"ref":"AWS.DAX.html#delete_parameter_group/3","title":"AWS.DAX.delete_parameter_group/3","type":"function","doc":"Deletes the specified parameter group. You cannot delete a parameter group if it is associated with any DAX clusters."},{"ref":"AWS.DAX.html#delete_subnet_group/3","title":"AWS.DAX.delete_subnet_group/3","type":"function","doc":"Deletes a subnet group. You cannot delete a subnet group if it is associated with any DAX clusters."},{"ref":"AWS.DAX.html#describe_clusters/3","title":"AWS.DAX.describe_clusters/3","type":"function","doc":"Returns information about all provisioned DAX clusters if no cluster identifier is specified, or about a specific DAX cluster if a cluster identifier is supplied. If the cluster is in the CREATING state, only cluster level information will be displayed until all of the nodes are successfully provisioned. If the cluster is in the DELETING state, only cluster level information will be displayed. If nodes are currently being added to the DAX cluster, node endpoint information and creation time for the additional nodes will not be displayed until they are completely provisioned. When the DAX cluster state is available, the cluster is ready for use. If nodes are currently being removed from the DAX cluster, no endpoint information for the removed nodes is displayed."},{"ref":"AWS.DAX.html#describe_default_parameters/3","title":"AWS.DAX.describe_default_parameters/3","type":"function","doc":"Returns the default system parameter information for the DAX caching software."},{"ref":"AWS.DAX.html#describe_events/3","title":"AWS.DAX.describe_events/3","type":"function","doc":"Returns events related to DAX clusters and parameter groups. You can obtain events specific to a particular DAX cluster or parameter group by providing the name as a parameter. By default, only the events occurring within the last 24 hours are returned; however, you can retrieve up to 14 days&#39; worth of events if necessary."},{"ref":"AWS.DAX.html#describe_parameter_groups/3","title":"AWS.DAX.describe_parameter_groups/3","type":"function","doc":"Returns a list of parameter group descriptions. If a parameter group name is specified, the list will contain only the descriptions for that group."},{"ref":"AWS.DAX.html#describe_parameters/3","title":"AWS.DAX.describe_parameters/3","type":"function","doc":"Returns the detailed parameter list for a particular parameter group."},{"ref":"AWS.DAX.html#describe_subnet_groups/3","title":"AWS.DAX.describe_subnet_groups/3","type":"function","doc":"Returns a list of subnet group descriptions. If a subnet group name is specified, the list will contain only the description of that group."},{"ref":"AWS.DAX.html#increase_replication_factor/3","title":"AWS.DAX.increase_replication_factor/3","type":"function","doc":"Adds one or more nodes to a DAX cluster."},{"ref":"AWS.DAX.html#list_tags/3","title":"AWS.DAX.list_tags/3","type":"function","doc":"List all of the tags for a DAX cluster. You can call ListTags up to 10 times per second, per account."},{"ref":"AWS.DAX.html#reboot_node/3","title":"AWS.DAX.reboot_node/3","type":"function","doc":"Reboots a single node of a DAX cluster. The reboot action takes place as soon as possible. During the reboot, the node status is set to REBOOTING. RebootNode restarts the DAX engine process and does not remove the contents of the cache."},{"ref":"AWS.DAX.html#tag_resource/3","title":"AWS.DAX.tag_resource/3","type":"function","doc":"Associates a set of tags with a DAX resource. You can call TagResource up to 5 times per second, per account."},{"ref":"AWS.DAX.html#untag_resource/3","title":"AWS.DAX.untag_resource/3","type":"function","doc":"Removes the association of tags from a DAX resource. You can call UntagResource up to 5 times per second, per account."},{"ref":"AWS.DAX.html#update_cluster/3","title":"AWS.DAX.update_cluster/3","type":"function","doc":"Modifies the settings for a DAX cluster. You can use this action to change one or more cluster configuration parameters by specifying the parameters and the new values."},{"ref":"AWS.DAX.html#update_parameter_group/3","title":"AWS.DAX.update_parameter_group/3","type":"function","doc":"Modifies the parameters of a parameter group. You can modify up to 20 parameters in a single request by submitting a list parameter name and value pairs."},{"ref":"AWS.DAX.html#update_subnet_group/3","title":"AWS.DAX.update_subnet_group/3","type":"function","doc":"Modifies an existing subnet group."},{"ref":"AWS.DLM.html","title":"AWS.DLM","type":"module","doc":"Amazon Data Lifecycle Manager With Amazon Data Lifecycle Manager, you can manage the lifecycle of your AWS resources. You create lifecycle policies, which are used to automate operations on the specified resources. Amazon DLM supports Amazon EBS volumes and snapshots. For information about using Amazon DLM with Amazon EBS, see Automating the Amazon EBS Snapshot Lifecycle in the Amazon EC2 User Guide."},{"ref":"AWS.DLM.html#create_lifecycle_policy/3","title":"AWS.DLM.create_lifecycle_policy/3","type":"function","doc":"Creates a policy to manage the lifecycle of the specified AWS resources. You can create up to 100 lifecycle policies."},{"ref":"AWS.DLM.html#delete_lifecycle_policy/4","title":"AWS.DLM.delete_lifecycle_policy/4","type":"function","doc":"Deletes the specified lifecycle policy and halts the automated operations that the policy specified."},{"ref":"AWS.DLM.html#get_lifecycle_policies/7","title":"AWS.DLM.get_lifecycle_policies/7","type":"function","doc":"Gets summary information about all or the specified data lifecycle policies. To get complete information about a policy, use GetLifecyclePolicy."},{"ref":"AWS.DLM.html#get_lifecycle_policy/3","title":"AWS.DLM.get_lifecycle_policy/3","type":"function","doc":"Gets detailed information about the specified lifecycle policy."},{"ref":"AWS.DLM.html#list_tags_for_resource/3","title":"AWS.DLM.list_tags_for_resource/3","type":"function","doc":"Lists the tags for the specified resource."},{"ref":"AWS.DLM.html#tag_resource/4","title":"AWS.DLM.tag_resource/4","type":"function","doc":"Adds the specified tags to the specified resource."},{"ref":"AWS.DLM.html#untag_resource/4","title":"AWS.DLM.untag_resource/4","type":"function","doc":"Removes the specified tags from the specified resource."},{"ref":"AWS.DLM.html#update_lifecycle_policy/4","title":"AWS.DLM.update_lifecycle_policy/4","type":"function","doc":"Updates the specified lifecycle policy."},{"ref":"AWS.DataExchange.html","title":"AWS.DataExchange","type":"module","doc":"This is the API reference for AWS Data Exchange."},{"ref":"AWS.DataExchange.html#cancel_job/4","title":"AWS.DataExchange.cancel_job/4","type":"function","doc":"This operation cancels a job. Jobs can be cancelled only when they are in the WAITING state."},{"ref":"AWS.DataExchange.html#create_data_set/3","title":"AWS.DataExchange.create_data_set/3","type":"function","doc":"This operation creates a data set."},{"ref":"AWS.DataExchange.html#create_job/3","title":"AWS.DataExchange.create_job/3","type":"function","doc":"This operation creates a job."},{"ref":"AWS.DataExchange.html#create_revision/4","title":"AWS.DataExchange.create_revision/4","type":"function","doc":"This operation creates a revision for a data set."},{"ref":"AWS.DataExchange.html#delete_asset/6","title":"AWS.DataExchange.delete_asset/6","type":"function","doc":"This operation deletes an asset."},{"ref":"AWS.DataExchange.html#delete_data_set/4","title":"AWS.DataExchange.delete_data_set/4","type":"function","doc":"This operation deletes a data set."},{"ref":"AWS.DataExchange.html#delete_revision/5","title":"AWS.DataExchange.delete_revision/5","type":"function","doc":"This operation deletes a revision."},{"ref":"AWS.DataExchange.html#get_asset/5","title":"AWS.DataExchange.get_asset/5","type":"function","doc":"This operation returns information about an asset."},{"ref":"AWS.DataExchange.html#get_data_set/3","title":"AWS.DataExchange.get_data_set/3","type":"function","doc":"This operation returns information about a data set."},{"ref":"AWS.DataExchange.html#get_job/3","title":"AWS.DataExchange.get_job/3","type":"function","doc":"This operation returns information about a job."},{"ref":"AWS.DataExchange.html#get_revision/4","title":"AWS.DataExchange.get_revision/4","type":"function","doc":"This operation returns information about a revision."},{"ref":"AWS.DataExchange.html#list_data_set_revisions/5","title":"AWS.DataExchange.list_data_set_revisions/5","type":"function","doc":"This operation lists a data set&#39;s revisions sorted by CreatedAt in descending order."},{"ref":"AWS.DataExchange.html#list_data_sets/5","title":"AWS.DataExchange.list_data_sets/5","type":"function","doc":"This operation lists your data sets. When listing by origin OWNED, results are sorted by CreatedAt in descending order. When listing by origin ENTITLED, there is no order and the maxResults parameter is ignored."},{"ref":"AWS.DataExchange.html#list_jobs/6","title":"AWS.DataExchange.list_jobs/6","type":"function","doc":"This operation lists your jobs sorted by CreatedAt in descending order."},{"ref":"AWS.DataExchange.html#list_revision_assets/6","title":"AWS.DataExchange.list_revision_assets/6","type":"function","doc":"This operation lists a revision&#39;s assets sorted alphabetically in descending order."},{"ref":"AWS.DataExchange.html#list_tags_for_resource/3","title":"AWS.DataExchange.list_tags_for_resource/3","type":"function","doc":"This operation lists the tags on the resource."},{"ref":"AWS.DataExchange.html#start_job/4","title":"AWS.DataExchange.start_job/4","type":"function","doc":"This operation starts a job."},{"ref":"AWS.DataExchange.html#tag_resource/4","title":"AWS.DataExchange.tag_resource/4","type":"function","doc":"This operation tags a resource."},{"ref":"AWS.DataExchange.html#untag_resource/4","title":"AWS.DataExchange.untag_resource/4","type":"function","doc":"This operation removes one or more tags from a resource."},{"ref":"AWS.DataExchange.html#update_asset/6","title":"AWS.DataExchange.update_asset/6","type":"function","doc":"This operation updates an asset."},{"ref":"AWS.DataExchange.html#update_data_set/4","title":"AWS.DataExchange.update_data_set/4","type":"function","doc":"This operation updates a data set."},{"ref":"AWS.DataExchange.html#update_revision/5","title":"AWS.DataExchange.update_revision/5","type":"function","doc":"This operation updates a revision."},{"ref":"AWS.DataSync.html","title":"AWS.DataSync","type":"module","doc":"AWS DataSync AWS DataSync is a managed data transfer service that makes it simpler for you to automate moving data between on-premises storage and Amazon Simple Storage Service (Amazon S3) or Amazon Elastic File System (Amazon EFS). This API interface reference for AWS DataSync contains documentation for a programming interface that you can use to manage AWS DataSync."},{"ref":"AWS.DataSync.html#cancel_task_execution/3","title":"AWS.DataSync.cancel_task_execution/3","type":"function","doc":"Cancels execution of a task. When you cancel a task execution, the transfer of some files is abruptly interrupted. The contents of files that are transferred to the destination might be incomplete or inconsistent with the source files. However, if you start a new task execution on the same task and you allow the task execution to complete, file content on the destination is complete and consistent. This applies to other unexpected failures that interrupt a task execution. In all of these cases, AWS DataSync successfully complete the transfer when you start the next task execution."},{"ref":"AWS.DataSync.html#create_agent/3","title":"AWS.DataSync.create_agent/3","type":"function","doc":"Activates an AWS DataSync agent that you have deployed on your host. The activation process associates your agent with your account. In the activation process, you specify information such as the AWS Region that you want to activate the agent in. You activate the agent in the AWS Region where your target locations (in Amazon S3 or Amazon EFS) reside. Your tasks are created in this AWS Region. You can activate the agent in a VPC (virtual private cloud) or provide the agent access to a VPC endpoint so you can run tasks without going over the public internet. You can use an agent for more than one location. If a task uses multiple agents, all of them need to have status AVAILABLE for the task to run. If you use multiple agents for a source location, the status of all the agents must be AVAILABLE for the task to run. Agents are automatically updated by AWS on a regular basis, using a mechanism that ensures minimal interruption to your tasks."},{"ref":"AWS.DataSync.html#create_location_efs/3","title":"AWS.DataSync.create_location_efs/3","type":"function","doc":"Creates an endpoint for an Amazon EFS file system."},{"ref":"AWS.DataSync.html#create_location_fsx_windows/3","title":"AWS.DataSync.create_location_fsx_windows/3","type":"function","doc":"Creates an endpoint for an Amazon FSx for Windows file system."},{"ref":"AWS.DataSync.html#create_location_nfs/3","title":"AWS.DataSync.create_location_nfs/3","type":"function","doc":"Defines a file system on a Network File System (NFS) server that can be read from or written to."},{"ref":"AWS.DataSync.html#create_location_object_storage/3","title":"AWS.DataSync.create_location_object_storage/3","type":"function","doc":"Creates an endpoint for a self-managed object storage bucket. For more information about self-managed object storage locations, see create-object-location."},{"ref":"AWS.DataSync.html#create_location_s3/3","title":"AWS.DataSync.create_location_s3/3","type":"function","doc":"Creates an endpoint for an Amazon S3 bucket. For more information, see https://docs.aws.amazon.com/datasync/latest/userguide/create-locations-cli.html#create-location-s3-cli in the AWS DataSync User Guide."},{"ref":"AWS.DataSync.html#create_location_smb/3","title":"AWS.DataSync.create_location_smb/3","type":"function","doc":"Defines a file system on a Server Message Block (SMB) server that can be read from or written to."},{"ref":"AWS.DataSync.html#create_task/3","title":"AWS.DataSync.create_task/3","type":"function","doc":"Creates a task. A task is a set of two locations (source and destination) and a set of Options that you use to control the behavior of a task. If you don&#39;t specify Options when you create a task, AWS DataSync populates them with service defaults. When you create a task, it first enters the CREATING state. During CREATING AWS DataSync attempts to mount the on-premises Network File System (NFS) location. The task transitions to the AVAILABLE state without waiting for the AWS location to become mounted. If required, AWS DataSync mounts the AWS location before each task execution. If an agent that is associated with a source (NFS) location goes offline, the task transitions to the UNAVAILABLE status. If the status of the task remains in the CREATING status for more than a few minutes, it means that your agent might be having trouble mounting the source NFS file system. Check the task&#39;s ErrorCode and ErrorDetail. Mount issues are often caused by either a misconfigured firewall or a mistyped NFS server hostname."},{"ref":"AWS.DataSync.html#delete_agent/3","title":"AWS.DataSync.delete_agent/3","type":"function","doc":"Deletes an agent. To specify which agent to delete, use the Amazon Resource Name (ARN) of the agent in your request. The operation disassociates the agent from your AWS account. However, it doesn&#39;t delete the agent virtual machine (VM) from your on-premises environment."},{"ref":"AWS.DataSync.html#delete_location/3","title":"AWS.DataSync.delete_location/3","type":"function","doc":"Deletes the configuration of a location used by AWS DataSync."},{"ref":"AWS.DataSync.html#delete_task/3","title":"AWS.DataSync.delete_task/3","type":"function","doc":"Deletes a task."},{"ref":"AWS.DataSync.html#describe_agent/3","title":"AWS.DataSync.describe_agent/3","type":"function","doc":"Returns metadata such as the name, the network interfaces, and the status (that is, whether the agent is running or not) for an agent. To specify which agent to describe, use the Amazon Resource Name (ARN) of the agent in your request."},{"ref":"AWS.DataSync.html#describe_location_efs/3","title":"AWS.DataSync.describe_location_efs/3","type":"function","doc":"Returns metadata, such as the path information about an Amazon EFS location."},{"ref":"AWS.DataSync.html#describe_location_fsx_windows/3","title":"AWS.DataSync.describe_location_fsx_windows/3","type":"function","doc":"Returns metadata, such as the path information about an Amazon FSx for Windows location."},{"ref":"AWS.DataSync.html#describe_location_nfs/3","title":"AWS.DataSync.describe_location_nfs/3","type":"function","doc":"Returns metadata, such as the path information, about an NFS location."},{"ref":"AWS.DataSync.html#describe_location_object_storage/3","title":"AWS.DataSync.describe_location_object_storage/3","type":"function","doc":"Returns metadata about a self-managed object storage server location. For more information about self-managed object storage locations, see create-object-location."},{"ref":"AWS.DataSync.html#describe_location_s3/3","title":"AWS.DataSync.describe_location_s3/3","type":"function","doc":"Returns metadata, such as bucket name, about an Amazon S3 bucket location."},{"ref":"AWS.DataSync.html#describe_location_smb/3","title":"AWS.DataSync.describe_location_smb/3","type":"function","doc":"Returns metadata, such as the path and user information about an SMB location."},{"ref":"AWS.DataSync.html#describe_task/3","title":"AWS.DataSync.describe_task/3","type":"function","doc":"Returns metadata about a task."},{"ref":"AWS.DataSync.html#describe_task_execution/3","title":"AWS.DataSync.describe_task_execution/3","type":"function","doc":"Returns detailed metadata about a task that is being executed."},{"ref":"AWS.DataSync.html#list_agents/3","title":"AWS.DataSync.list_agents/3","type":"function","doc":"Returns a list of agents owned by an AWS account in the AWS Region specified in the request. The returned list is ordered by agent Amazon Resource Name (ARN). By default, this operation returns a maximum of 100 agents. This operation supports pagination that enables you to optionally reduce the number of agents returned in a response. If you have more agents than are returned in a response (that is, the response returns only a truncated list of your agents), the response contains a marker that you can specify in your next request to fetch the next page of agents."},{"ref":"AWS.DataSync.html#list_locations/3","title":"AWS.DataSync.list_locations/3","type":"function","doc":"Returns a list of source and destination locations. If you have more locations than are returned in a response (that is, the response returns only a truncated list of your agents), the response contains a token that you can specify in your next request to fetch the next page of locations."},{"ref":"AWS.DataSync.html#list_tags_for_resource/3","title":"AWS.DataSync.list_tags_for_resource/3","type":"function","doc":"Returns all the tags associated with a specified resource."},{"ref":"AWS.DataSync.html#list_task_executions/3","title":"AWS.DataSync.list_task_executions/3","type":"function","doc":"Returns a list of executed tasks."},{"ref":"AWS.DataSync.html#list_tasks/3","title":"AWS.DataSync.list_tasks/3","type":"function","doc":"Returns a list of all the tasks."},{"ref":"AWS.DataSync.html#start_task_execution/3","title":"AWS.DataSync.start_task_execution/3","type":"function","doc":"Starts a specific invocation of a task. A TaskExecution value represents an individual run of a task. Each task can have at most one TaskExecution at a time. TaskExecution has the following transition phases: INITIALIZING | PREPARING | TRANSFERRING | VERIFYING | SUCCESS/FAILURE. For detailed information, see the Task Execution section in the Components and Terminology topic in the AWS DataSync User Guide."},{"ref":"AWS.DataSync.html#tag_resource/3","title":"AWS.DataSync.tag_resource/3","type":"function","doc":"Applies a key-value pair to an AWS resource."},{"ref":"AWS.DataSync.html#untag_resource/3","title":"AWS.DataSync.untag_resource/3","type":"function","doc":"Removes a tag from an AWS resource."},{"ref":"AWS.DataSync.html#update_agent/3","title":"AWS.DataSync.update_agent/3","type":"function","doc":"Updates the name of an agent."},{"ref":"AWS.DataSync.html#update_task/3","title":"AWS.DataSync.update_task/3","type":"function","doc":"Updates the metadata associated with a task."},{"ref":"AWS.DatabaseMigration.html","title":"AWS.DatabaseMigration","type":"module","doc":"AWS Database Migration Service AWS Database Migration Service (AWS DMS) can migrate your data to and from the most widely used commercial and open-source databases such as Oracle, PostgreSQL, Microsoft SQL Server, Amazon Redshift, MariaDB, Amazon Aurora, MySQL, and SAP Adaptive Server Enterprise (ASE). The service supports homogeneous migrations such as Oracle to Oracle, as well as heterogeneous migrations between different database platforms, such as Oracle to MySQL or SQL Server to PostgreSQL. For more information about AWS DMS, see What Is AWS Database Migration Service? in the AWS Database Migration User Guide."},{"ref":"AWS.DatabaseMigration.html#add_tags_to_resource/3","title":"AWS.DatabaseMigration.add_tags_to_resource/3","type":"function","doc":"Adds metadata tags to an AWS DMS resource, including replication instance, endpoint, security group, and migration task. These tags can also be used with cost allocation reporting to track cost associated with DMS resources, or used in a Condition statement in an IAM policy for DMS. For more information, see Tag data type description."},{"ref":"AWS.DatabaseMigration.html#apply_pending_maintenance_action/3","title":"AWS.DatabaseMigration.apply_pending_maintenance_action/3","type":"function","doc":"Applies a pending maintenance action to a resource (for example, to a replication instance)."},{"ref":"AWS.DatabaseMigration.html#cancel_replication_task_assessment_run/3","title":"AWS.DatabaseMigration.cancel_replication_task_assessment_run/3","type":"function","doc":"Cancels a single premigration assessment run. This operation prevents any individual assessments from running if they haven&#39;t started running. It also attempts to cancel any individual assessments that are currently running."},{"ref":"AWS.DatabaseMigration.html#create_endpoint/3","title":"AWS.DatabaseMigration.create_endpoint/3","type":"function","doc":"Creates an endpoint using the provided settings."},{"ref":"AWS.DatabaseMigration.html#create_event_subscription/3","title":"AWS.DatabaseMigration.create_event_subscription/3","type":"function","doc":"Creates an AWS DMS event notification subscription. You can specify the type of source (SourceType) you want to be notified of, provide a list of AWS DMS source IDs (SourceIds) that triggers the events, and provide a list of event categories (EventCategories) for events you want to be notified of. If you specify both the SourceType and SourceIds, such as SourceType = replication-instance and SourceIdentifier = my-replinstance, you will be notified of all the replication instance events for the specified source. If you specify a SourceType but don&#39;t specify a SourceIdentifier, you receive notice of the events for that source type for all your AWS DMS sources. If you don&#39;t specify either SourceType nor SourceIdentifier, you will be notified of events generated from all AWS DMS sources belonging to your customer account. For more information about AWS DMS events, see Working with Events and Notifications in the AWS Database Migration Service User Guide."},{"ref":"AWS.DatabaseMigration.html#create_replication_instance/3","title":"AWS.DatabaseMigration.create_replication_instance/3","type":"function","doc":"Creates the replication instance using the specified parameters. AWS DMS requires that your account have certain roles with appropriate permissions before you can create a replication instance. For information on the required roles, see Creating the IAM Roles to Use With the AWS CLI and AWS DMS API. For information on the required permissions, see IAM Permissions Needed to Use AWS DMS."},{"ref":"AWS.DatabaseMigration.html#create_replication_subnet_group/3","title":"AWS.DatabaseMigration.create_replication_subnet_group/3","type":"function","doc":"Creates a replication subnet group given a list of the subnet IDs in a VPC."},{"ref":"AWS.DatabaseMigration.html#create_replication_task/3","title":"AWS.DatabaseMigration.create_replication_task/3","type":"function","doc":"Creates a replication task using the specified parameters."},{"ref":"AWS.DatabaseMigration.html#delete_certificate/3","title":"AWS.DatabaseMigration.delete_certificate/3","type":"function","doc":"Deletes the specified certificate."},{"ref":"AWS.DatabaseMigration.html#delete_connection/3","title":"AWS.DatabaseMigration.delete_connection/3","type":"function","doc":"Deletes the connection between a replication instance and an endpoint."},{"ref":"AWS.DatabaseMigration.html#delete_endpoint/3","title":"AWS.DatabaseMigration.delete_endpoint/3","type":"function","doc":"Deletes the specified endpoint. All tasks associated with the endpoint must be deleted before you can delete the endpoint."},{"ref":"AWS.DatabaseMigration.html#delete_event_subscription/3","title":"AWS.DatabaseMigration.delete_event_subscription/3","type":"function","doc":"Deletes an AWS DMS event subscription."},{"ref":"AWS.DatabaseMigration.html#delete_replication_instance/3","title":"AWS.DatabaseMigration.delete_replication_instance/3","type":"function","doc":"Deletes the specified replication instance. You must delete any migration tasks that are associated with the replication instance before you can delete it."},{"ref":"AWS.DatabaseMigration.html#delete_replication_subnet_group/3","title":"AWS.DatabaseMigration.delete_replication_subnet_group/3","type":"function","doc":"Deletes a subnet group."},{"ref":"AWS.DatabaseMigration.html#delete_replication_task/3","title":"AWS.DatabaseMigration.delete_replication_task/3","type":"function","doc":"Deletes the specified replication task."},{"ref":"AWS.DatabaseMigration.html#delete_replication_task_assessment_run/3","title":"AWS.DatabaseMigration.delete_replication_task_assessment_run/3","type":"function","doc":"Deletes the record of a single premigration assessment run. This operation removes all metadata that AWS DMS maintains about this assessment run. However, the operation leaves untouched all information about this assessment run that is stored in your Amazon S3 bucket."},{"ref":"AWS.DatabaseMigration.html#describe_account_attributes/3","title":"AWS.DatabaseMigration.describe_account_attributes/3","type":"function","doc":"Lists all of the AWS DMS attributes for a customer account. These attributes include AWS DMS quotas for the account and a unique account identifier in a particular DMS region. DMS quotas include a list of resource quotas supported by the account, such as the number of replication instances allowed. The description for each resource quota, includes the quota name, current usage toward that quota, and the quota&#39;s maximum value. DMS uses the unique account identifier to name each artifact used by DMS in the given region. This command does not take any parameters."},{"ref":"AWS.DatabaseMigration.html#describe_applicable_individual_assessments/3","title":"AWS.DatabaseMigration.describe_applicable_individual_assessments/3","type":"function","doc":"Provides a list of individual assessments that you can specify for a new premigration assessment run, given one or more parameters. If you specify an existing migration task, this operation provides the default individual assessments you can specify for that task. Otherwise, the specified parameters model elements of a possible migration task on which to base a premigration assessment run. To use these migration task modeling parameters, you must specify an existing replication instance, a source database engine, a target database engine, and a migration type. This combination of parameters potentially limits the default individual assessments available for an assessment run created for a corresponding migration task. If you specify no parameters, this operation provides a list of all possible individual assessments that you can specify for an assessment run. If you specify any one of the task modeling parameters, you must specify all of them or the operation cannot provide a list of individual assessments. The only parameter that you can specify alone is for an existing migration task. The specified task definition then determines the default list of individual assessments that you can specify in an assessment run for the task."},{"ref":"AWS.DatabaseMigration.html#describe_certificates/3","title":"AWS.DatabaseMigration.describe_certificates/3","type":"function","doc":"Provides a description of the certificate."},{"ref":"AWS.DatabaseMigration.html#describe_connections/3","title":"AWS.DatabaseMigration.describe_connections/3","type":"function","doc":"Describes the status of the connections that have been made between the replication instance and an endpoint. Connections are created when you test an endpoint."},{"ref":"AWS.DatabaseMigration.html#describe_endpoint_types/3","title":"AWS.DatabaseMigration.describe_endpoint_types/3","type":"function","doc":"Returns information about the type of endpoints available."},{"ref":"AWS.DatabaseMigration.html#describe_endpoints/3","title":"AWS.DatabaseMigration.describe_endpoints/3","type":"function","doc":"Returns information about the endpoints for your account in the current region."},{"ref":"AWS.DatabaseMigration.html#describe_event_categories/3","title":"AWS.DatabaseMigration.describe_event_categories/3","type":"function","doc":"Lists categories for all event source types, or, if specified, for a specified source type. You can see a list of the event categories and source types in Working with Events and Notifications in the AWS Database Migration Service User Guide."},{"ref":"AWS.DatabaseMigration.html#describe_event_subscriptions/3","title":"AWS.DatabaseMigration.describe_event_subscriptions/3","type":"function","doc":"Lists all the event subscriptions for a customer account. The description of a subscription includes SubscriptionName, SNSTopicARN, CustomerID, SourceType, SourceID, CreationTime, and Status. If you specify SubscriptionName, this action lists the description for that subscription."},{"ref":"AWS.DatabaseMigration.html#describe_events/3","title":"AWS.DatabaseMigration.describe_events/3","type":"function","doc":"Lists events for a given source identifier and source type. You can also specify a start and end time. For more information on AWS DMS events, see Working with Events and Notifications in the AWS Database Migration User Guide."},{"ref":"AWS.DatabaseMigration.html#describe_orderable_replication_instances/3","title":"AWS.DatabaseMigration.describe_orderable_replication_instances/3","type":"function","doc":"Returns information about the replication instance types that can be created in the specified region."},{"ref":"AWS.DatabaseMigration.html#describe_pending_maintenance_actions/3","title":"AWS.DatabaseMigration.describe_pending_maintenance_actions/3","type":"function","doc":"For internal use only"},{"ref":"AWS.DatabaseMigration.html#describe_refresh_schemas_status/3","title":"AWS.DatabaseMigration.describe_refresh_schemas_status/3","type":"function","doc":"Returns the status of the RefreshSchemas operation."},{"ref":"AWS.DatabaseMigration.html#describe_replication_instance_task_logs/3","title":"AWS.DatabaseMigration.describe_replication_instance_task_logs/3","type":"function","doc":"Returns information about the task logs for the specified task."},{"ref":"AWS.DatabaseMigration.html#describe_replication_instances/3","title":"AWS.DatabaseMigration.describe_replication_instances/3","type":"function","doc":"Returns information about replication instances for your account in the current region."},{"ref":"AWS.DatabaseMigration.html#describe_replication_subnet_groups/3","title":"AWS.DatabaseMigration.describe_replication_subnet_groups/3","type":"function","doc":"Returns information about the replication subnet groups."},{"ref":"AWS.DatabaseMigration.html#describe_replication_task_assessment_results/3","title":"AWS.DatabaseMigration.describe_replication_task_assessment_results/3","type":"function","doc":"Returns the task assessment results from Amazon S3. This action always returns the latest results."},{"ref":"AWS.DatabaseMigration.html#describe_replication_task_assessment_runs/3","title":"AWS.DatabaseMigration.describe_replication_task_assessment_runs/3","type":"function","doc":"Returns a paginated list of premigration assessment runs based on filter settings. These filter settings can specify a combination of premigration assessment runs, migration tasks, replication instances, and assessment run status values. This operation doesn&#39;t return information about individual assessments. For this information, see the DescribeReplicationTaskIndividualAssessments operation."},{"ref":"AWS.DatabaseMigration.html#describe_replication_task_individual_assessments/3","title":"AWS.DatabaseMigration.describe_replication_task_individual_assessments/3","type":"function","doc":"Returns a paginated list of individual assessments based on filter settings. These filter settings can specify a combination of premigration assessment runs, migration tasks, and assessment status values."},{"ref":"AWS.DatabaseMigration.html#describe_replication_tasks/3","title":"AWS.DatabaseMigration.describe_replication_tasks/3","type":"function","doc":"Returns information about replication tasks for your account in the current region."},{"ref":"AWS.DatabaseMigration.html#describe_schemas/3","title":"AWS.DatabaseMigration.describe_schemas/3","type":"function","doc":"Returns information about the schema for the specified endpoint."},{"ref":"AWS.DatabaseMigration.html#describe_table_statistics/3","title":"AWS.DatabaseMigration.describe_table_statistics/3","type":"function","doc":"Returns table statistics on the database migration task, including table name, rows inserted, rows updated, and rows deleted. Note that the &quot;last updated&quot; column the DMS console only indicates the time that AWS DMS last updated the table statistics record for a table. It does not indicate the time of the last update to the table."},{"ref":"AWS.DatabaseMigration.html#import_certificate/3","title":"AWS.DatabaseMigration.import_certificate/3","type":"function","doc":"Uploads the specified certificate."},{"ref":"AWS.DatabaseMigration.html#list_tags_for_resource/3","title":"AWS.DatabaseMigration.list_tags_for_resource/3","type":"function","doc":"Lists all metadata tags attached to an AWS DMS resource, including replication instance, endpoint, security group, and migration task. For more information, see Tag data type description."},{"ref":"AWS.DatabaseMigration.html#modify_endpoint/3","title":"AWS.DatabaseMigration.modify_endpoint/3","type":"function","doc":"Modifies the specified endpoint."},{"ref":"AWS.DatabaseMigration.html#modify_event_subscription/3","title":"AWS.DatabaseMigration.modify_event_subscription/3","type":"function","doc":"Modifies an existing AWS DMS event notification subscription."},{"ref":"AWS.DatabaseMigration.html#modify_replication_instance/3","title":"AWS.DatabaseMigration.modify_replication_instance/3","type":"function","doc":"Modifies the replication instance to apply new settings. You can change one or more parameters by specifying these parameters and the new values in the request. Some settings are applied during the maintenance window."},{"ref":"AWS.DatabaseMigration.html#modify_replication_subnet_group/3","title":"AWS.DatabaseMigration.modify_replication_subnet_group/3","type":"function","doc":"Modifies the settings for the specified replication subnet group."},{"ref":"AWS.DatabaseMigration.html#modify_replication_task/3","title":"AWS.DatabaseMigration.modify_replication_task/3","type":"function","doc":"Modifies the specified replication task. You can&#39;t modify the task endpoints. The task must be stopped before you can modify it. For more information about AWS DMS tasks, see Working with Migration Tasks in the AWS Database Migration Service User Guide."},{"ref":"AWS.DatabaseMigration.html#reboot_replication_instance/3","title":"AWS.DatabaseMigration.reboot_replication_instance/3","type":"function","doc":"Reboots a replication instance. Rebooting results in a momentary outage, until the replication instance becomes available again."},{"ref":"AWS.DatabaseMigration.html#refresh_schemas/3","title":"AWS.DatabaseMigration.refresh_schemas/3","type":"function","doc":"Populates the schema for the specified endpoint. This is an asynchronous operation and can take several minutes. You can check the status of this operation by calling the DescribeRefreshSchemasStatus operation."},{"ref":"AWS.DatabaseMigration.html#reload_tables/3","title":"AWS.DatabaseMigration.reload_tables/3","type":"function","doc":"Reloads the target database table with the source data."},{"ref":"AWS.DatabaseMigration.html#remove_tags_from_resource/3","title":"AWS.DatabaseMigration.remove_tags_from_resource/3","type":"function","doc":"Removes metadata tags from an AWS DMS resource, including replication instance, endpoint, security group, and migration task. For more information, see Tag data type description."},{"ref":"AWS.DatabaseMigration.html#start_replication_task/3","title":"AWS.DatabaseMigration.start_replication_task/3","type":"function","doc":"Starts the replication task. For more information about AWS DMS tasks, see Working with Migration Tasks in the AWS Database Migration Service User Guide."},{"ref":"AWS.DatabaseMigration.html#start_replication_task_assessment/3","title":"AWS.DatabaseMigration.start_replication_task_assessment/3","type":"function","doc":"Starts the replication task assessment for unsupported data types in the source database."},{"ref":"AWS.DatabaseMigration.html#start_replication_task_assessment_run/3","title":"AWS.DatabaseMigration.start_replication_task_assessment_run/3","type":"function","doc":"Starts a new premigration assessment run for one or more individual assessments of a migration task. The assessments that you can specify depend on the source and target database engine and the migration type defined for the given task. To run this operation, your migration task must already be created. After you run this operation, you can review the status of each individual assessment. You can also run the migration task manually after the assessment run and its individual assessments complete."},{"ref":"AWS.DatabaseMigration.html#stop_replication_task/3","title":"AWS.DatabaseMigration.stop_replication_task/3","type":"function","doc":"Stops the replication task."},{"ref":"AWS.DatabaseMigration.html#test_connection/3","title":"AWS.DatabaseMigration.test_connection/3","type":"function","doc":"Tests the connection between the replication instance and the endpoint."},{"ref":"AWS.Datapipeline.html","title":"AWS.Datapipeline","type":"module","doc":"AWS Data Pipeline configures and manages a data-driven workflow called a pipeline. AWS Data Pipeline handles the details of scheduling and ensuring that data dependencies are met so that your application can focus on processing the data. AWS Data Pipeline provides a JAR implementation of a task runner called AWS Data Pipeline Task Runner. AWS Data Pipeline Task Runner provides logic for common data management scenarios, such as performing database queries and running data analysis using Amazon Elastic MapReduce (Amazon EMR). You can use AWS Data Pipeline Task Runner as your task runner, or you can write your own task runner to provide custom data management. AWS Data Pipeline implements two main sets of functionality. Use the first set to create a pipeline and define data sources, schedules, dependencies, and the transforms to be performed on the data. Use the second set in your task runner application to receive the next task ready for processing. The logic for performing the task, such as querying the data, running data analysis, or converting the data from one format to another, is contained within the task runner. The task runner performs the task assigned to it by the web service, reporting progress to the web service as it does so. When the task is done, the task runner reports the final success or failure of the task to the web service."},{"ref":"AWS.Datapipeline.html#activate_pipeline/3","title":"AWS.Datapipeline.activate_pipeline/3","type":"function","doc":"Validates the specified pipeline and starts processing pipeline tasks. If the pipeline does not pass validation, activation fails. If you need to pause the pipeline to investigate an issue with a component, such as a data source or script, call DeactivatePipeline. To activate a finished pipeline, modify the end date for the pipeline and then activate it."},{"ref":"AWS.Datapipeline.html#add_tags/3","title":"AWS.Datapipeline.add_tags/3","type":"function","doc":"Adds or modifies tags for the specified pipeline."},{"ref":"AWS.Datapipeline.html#create_pipeline/3","title":"AWS.Datapipeline.create_pipeline/3","type":"function","doc":"Creates a new, empty pipeline. Use PutPipelineDefinition to populate the pipeline."},{"ref":"AWS.Datapipeline.html#deactivate_pipeline/3","title":"AWS.Datapipeline.deactivate_pipeline/3","type":"function","doc":"Deactivates the specified running pipeline. The pipeline is set to the DEACTIVATING state until the deactivation process completes. To resume a deactivated pipeline, use ActivatePipeline. By default, the pipeline resumes from the last completed execution. Optionally, you can specify the date and time to resume the pipeline."},{"ref":"AWS.Datapipeline.html#delete_pipeline/3","title":"AWS.Datapipeline.delete_pipeline/3","type":"function","doc":"Deletes a pipeline, its pipeline definition, and its run history. AWS Data Pipeline attempts to cancel instances associated with the pipeline that are currently being processed by task runners. Deleting a pipeline cannot be undone. You cannot query or restore a deleted pipeline. To temporarily pause a pipeline instead of deleting it, call SetStatus with the status set to PAUSE on individual components. Components that are paused by SetStatus can be resumed."},{"ref":"AWS.Datapipeline.html#describe_objects/3","title":"AWS.Datapipeline.describe_objects/3","type":"function","doc":"Gets the object definitions for a set of objects associated with the pipeline. Object definitions are composed of a set of fields that define the properties of the object."},{"ref":"AWS.Datapipeline.html#describe_pipelines/3","title":"AWS.Datapipeline.describe_pipelines/3","type":"function","doc":"Retrieves metadata about one or more pipelines. The information retrieved includes the name of the pipeline, the pipeline identifier, its current state, and the user account that owns the pipeline. Using account credentials, you can retrieve metadata about pipelines that you or your IAM users have created. If you are using an IAM user account, you can retrieve metadata about only those pipelines for which you have read permissions. To retrieve the full pipeline definition instead of metadata about the pipeline, call GetPipelineDefinition."},{"ref":"AWS.Datapipeline.html#evaluate_expression/3","title":"AWS.Datapipeline.evaluate_expression/3","type":"function","doc":"Task runners call EvaluateExpression to evaluate a string in the context of the specified object. For example, a task runner can evaluate SQL queries stored in Amazon S3."},{"ref":"AWS.Datapipeline.html#get_pipeline_definition/3","title":"AWS.Datapipeline.get_pipeline_definition/3","type":"function","doc":"Gets the definition of the specified pipeline. You can call GetPipelineDefinition to retrieve the pipeline definition that you provided using PutPipelineDefinition."},{"ref":"AWS.Datapipeline.html#list_pipelines/3","title":"AWS.Datapipeline.list_pipelines/3","type":"function","doc":"Lists the pipeline identifiers for all active pipelines that you have permission to access."},{"ref":"AWS.Datapipeline.html#poll_for_task/3","title":"AWS.Datapipeline.poll_for_task/3","type":"function","doc":"Task runners call PollForTask to receive a task to perform from AWS Data Pipeline. The task runner specifies which tasks it can perform by setting a value for the workerGroup parameter. The task returned can come from any of the pipelines that match the workerGroup value passed in by the task runner and that was launched using the IAM user credentials specified by the task runner. If tasks are ready in the work queue, PollForTask returns a response immediately. If no tasks are available in the queue, PollForTask uses long-polling and holds on to a poll connection for up to a 90 seconds, during which time the first newly scheduled task is handed to the task runner. To accomodate this, set the socket timeout in your task runner to 90 seconds. The task runner should not call PollForTask again on the same workerGroup until it receives a response, and this can take up to 90 seconds."},{"ref":"AWS.Datapipeline.html#put_pipeline_definition/3","title":"AWS.Datapipeline.put_pipeline_definition/3","type":"function","doc":"Adds tasks, schedules, and preconditions to the specified pipeline. You can use PutPipelineDefinition to populate a new pipeline. PutPipelineDefinition also validates the configuration as it adds it to the pipeline. Changes to the pipeline are saved unless one of the following three validation errors exists in the pipeline. An object is missing a name or identifier field. A string or reference field is empty. The number of objects in the pipeline exceeds the maximum allowed objects. The pipeline is in a FINISHED state. Pipeline object definitions are passed to the PutPipelineDefinition action and returned by the GetPipelineDefinition action."},{"ref":"AWS.Datapipeline.html#query_objects/3","title":"AWS.Datapipeline.query_objects/3","type":"function","doc":"Queries the specified pipeline for the names of objects that match the specified set of conditions."},{"ref":"AWS.Datapipeline.html#remove_tags/3","title":"AWS.Datapipeline.remove_tags/3","type":"function","doc":"Removes existing tags from the specified pipeline."},{"ref":"AWS.Datapipeline.html#report_task_progress/3","title":"AWS.Datapipeline.report_task_progress/3","type":"function","doc":"Task runners call ReportTaskProgress when assigned a task to acknowledge that it has the task. If the web service does not receive this acknowledgement within 2 minutes, it assigns the task in a subsequent PollForTask call. After this initial acknowledgement, the task runner only needs to report progress every 15 minutes to maintain its ownership of the task. You can change this reporting time from 15 minutes by specifying a reportProgressTimeout field in your pipeline. If a task runner does not report its status after 5 minutes, AWS Data Pipeline assumes that the task runner is unable to process the task and reassigns the task in a subsequent response to PollForTask. Task runners should call ReportTaskProgress every 60 seconds."},{"ref":"AWS.Datapipeline.html#report_task_runner_heartbeat/3","title":"AWS.Datapipeline.report_task_runner_heartbeat/3","type":"function","doc":"Task runners call ReportTaskRunnerHeartbeat every 15 minutes to indicate that they are operational. If the AWS Data Pipeline Task Runner is launched on a resource managed by AWS Data Pipeline, the web service can use this call to detect when the task runner application has failed and restart a new instance."},{"ref":"AWS.Datapipeline.html#set_status/3","title":"AWS.Datapipeline.set_status/3","type":"function","doc":"Requests that the status of the specified physical or logical pipeline objects be updated in the specified pipeline. This update might not occur immediately, but is eventually consistent. The status that can be set depends on the type of object (for example, DataNode or Activity). You cannot perform this operation on FINISHED pipelines and attempting to do so returns InvalidRequestException."},{"ref":"AWS.Datapipeline.html#set_task_status/3","title":"AWS.Datapipeline.set_task_status/3","type":"function","doc":"Task runners call SetTaskStatus to notify AWS Data Pipeline that a task is completed and provide information about the final status. A task runner makes this call regardless of whether the task was sucessful. A task runner does not need to call SetTaskStatus for tasks that are canceled by the web service during a call to ReportTaskProgress."},{"ref":"AWS.Datapipeline.html#validate_pipeline_definition/3","title":"AWS.Datapipeline.validate_pipeline_definition/3","type":"function","doc":"Validates the specified pipeline definition to ensure that it is well formed and can be run without error."},{"ref":"AWS.Detective.html","title":"AWS.Detective","type":"module","doc":"Detective uses machine learning and purpose-built visualizations to help you analyze and investigate security issues across your Amazon Web Services (AWS) workloads. Detective automatically extracts time-based events such as login attempts, API calls, and network traffic from AWS CloudTrail and Amazon Virtual Private Cloud (Amazon VPC) flow logs. It also extracts findings detected by Amazon GuardDuty. The Detective API primarily supports the creation and management of behavior graphs. A behavior graph contains the extracted data from a set of member accounts, and is created and managed by a master account. Every behavior graph is specific to a Region. You can only use the API to manage graphs that belong to the Region that is associated with the currently selected endpoint. A Detective master account can use the Detective API to do the following: Enable and disable Detective. Enabling Detective creates a new behavior graph. View the list of member accounts in a behavior graph. Add member accounts to a behavior graph. Remove member accounts from a behavior graph. A member account can use the Detective API to do the following: View the list of behavior graphs that they are invited to. Accept an invitation to contribute to a behavior graph. Decline an invitation to contribute to a behavior graph. Remove their account from a behavior graph. All API actions are logged as CloudTrail events. See Logging Detective API Calls with CloudTrail."},{"ref":"AWS.Detective.html#accept_invitation/3","title":"AWS.Detective.accept_invitation/3","type":"function","doc":"Accepts an invitation for the member account to contribute data to a behavior graph. This operation can only be called by an invited member account. The request provides the ARN of behavior graph. The member account status in the graph must be INVITED."},{"ref":"AWS.Detective.html#create_graph/3","title":"AWS.Detective.create_graph/3","type":"function","doc":"Creates a new behavior graph for the calling account, and sets that account as the master account. This operation is called by the account that is enabling Detective. Before you try to enable Detective, make sure that your account has been enrolled in Amazon GuardDuty for at least 48 hours. If you do not meet this requirement, you cannot enable Detective. If you do meet the GuardDuty prerequisite, then when you make the request to enable Detective, it checks whether your data volume is within the Detective quota. If it exceeds the quota, then you cannot enable Detective. The operation also enables Detective for the calling account in the currently selected Region. It returns the ARN of the new behavior graph. CreateGraph triggers a process to create the corresponding data tables for the new behavior graph. An account can only be the master account for one behavior graph within a Region. If the same account calls CreateGraph with the same master account, it always returns the same behavior graph ARN. It does not create a new behavior graph."},{"ref":"AWS.Detective.html#create_members/3","title":"AWS.Detective.create_members/3","type":"function","doc":"Sends a request to invite the specified AWS accounts to be member accounts in the behavior graph. This operation can only be called by the master account for a behavior graph. CreateMembers verifies the accounts and then sends invitations to the verified accounts. The request provides the behavior graph ARN and the list of accounts to invite. The response separates the requested accounts into two lists: The accounts that CreateMembers was able to start the verification for. This list includes member accounts that are being verified, that have passed verification and are being sent an invitation, and that have failed verification. The accounts that CreateMembers was unable to process. This list includes accounts that were already invited to be member accounts in the behavior graph."},{"ref":"AWS.Detective.html#delete_graph/3","title":"AWS.Detective.delete_graph/3","type":"function","doc":"Disables the specified behavior graph and queues it to be deleted. This operation removes the graph from each member account&#39;s list of behavior graphs. DeleteGraph can only be called by the master account for a behavior graph."},{"ref":"AWS.Detective.html#delete_members/3","title":"AWS.Detective.delete_members/3","type":"function","doc":"Deletes one or more member accounts from the master account behavior graph. This operation can only be called by a Detective master account. That account cannot use DeleteMembers to delete their own account from the behavior graph. To disable a behavior graph, the master account uses the DeleteGraph API method."},{"ref":"AWS.Detective.html#disassociate_membership/3","title":"AWS.Detective.disassociate_membership/3","type":"function","doc":"Removes the member account from the specified behavior graph. This operation can only be called by a member account that has the ENABLED status."},{"ref":"AWS.Detective.html#get_members/3","title":"AWS.Detective.get_members/3","type":"function","doc":"Returns the membership details for specified member accounts for a behavior graph."},{"ref":"AWS.Detective.html#list_graphs/3","title":"AWS.Detective.list_graphs/3","type":"function","doc":"Returns the list of behavior graphs that the calling account is a master of. This operation can only be called by a master account. Because an account can currently only be the master of one behavior graph within a Region, the results always contain a single graph."},{"ref":"AWS.Detective.html#list_invitations/3","title":"AWS.Detective.list_invitations/3","type":"function","doc":"Retrieves the list of open and accepted behavior graph invitations for the member account. This operation can only be called by a member account. Open invitations are invitations that the member account has not responded to. The results do not include behavior graphs for which the member account declined the invitation. The results also do not include behavior graphs that the member account resigned from or was removed from."},{"ref":"AWS.Detective.html#list_members/3","title":"AWS.Detective.list_members/3","type":"function","doc":"Retrieves the list of member accounts for a behavior graph. Does not return member accounts that were removed from the behavior graph."},{"ref":"AWS.Detective.html#reject_invitation/3","title":"AWS.Detective.reject_invitation/3","type":"function","doc":"Rejects an invitation to contribute the account data to a behavior graph. This operation must be called by a member account that has the INVITED status."},{"ref":"AWS.Detective.html#start_monitoring_member/3","title":"AWS.Detective.start_monitoring_member/3","type":"function","doc":"Sends a request to enable data ingest for a member account that has a status of ACCEPTED_BUT_DISABLED. For valid member accounts, the status is updated as follows. If Detective enabled the member account, then the new status is ENABLED. If Detective cannot enable the member account, the status remains ACCEPTED_BUT_DISABLED."},{"ref":"AWS.DeviceFarm.html","title":"AWS.DeviceFarm","type":"module","doc":"Welcome to the AWS Device Farm API documentation, which contains APIs for: Testing on desktop browsers Device Farm makes it possible for you to test your web applications on desktop browsers using Selenium. The APIs for desktop browser testing contain TestGrid in their names. For more information, see Testing Web Applications on Selenium with Device Farm. Testing on real mobile devices Device Farm makes it possible for you to test apps on physical phones, tablets, and other devices in the cloud. For more information, see the Device Farm Developer Guide."},{"ref":"AWS.DeviceFarm.html#create_device_pool/3","title":"AWS.DeviceFarm.create_device_pool/3","type":"function","doc":"Creates a device pool."},{"ref":"AWS.DeviceFarm.html#create_instance_profile/3","title":"AWS.DeviceFarm.create_instance_profile/3","type":"function","doc":"Creates a profile that can be applied to one or more private fleet device instances."},{"ref":"AWS.DeviceFarm.html#create_network_profile/3","title":"AWS.DeviceFarm.create_network_profile/3","type":"function","doc":"Creates a network profile."},{"ref":"AWS.DeviceFarm.html#create_project/3","title":"AWS.DeviceFarm.create_project/3","type":"function","doc":"Creates a project."},{"ref":"AWS.DeviceFarm.html#create_remote_access_session/3","title":"AWS.DeviceFarm.create_remote_access_session/3","type":"function","doc":"Specifies and starts a remote access session."},{"ref":"AWS.DeviceFarm.html#create_test_grid_project/3","title":"AWS.DeviceFarm.create_test_grid_project/3","type":"function","doc":"Creates a Selenium testing project. Projects are used to track TestGridSession instances."},{"ref":"AWS.DeviceFarm.html#create_test_grid_url/3","title":"AWS.DeviceFarm.create_test_grid_url/3","type":"function","doc":"Creates a signed, short-term URL that can be passed to a Selenium RemoteWebDriver constructor."},{"ref":"AWS.DeviceFarm.html#create_upload/3","title":"AWS.DeviceFarm.create_upload/3","type":"function","doc":"Uploads an app or test scripts."},{"ref":"AWS.DeviceFarm.html#create_v_p_c_e_configuration/3","title":"AWS.DeviceFarm.create_v_p_c_e_configuration/3","type":"function","doc":"Creates a configuration record in Device Farm for your Amazon Virtual Private Cloud (VPC) endpoint."},{"ref":"AWS.DeviceFarm.html#delete_device_pool/3","title":"AWS.DeviceFarm.delete_device_pool/3","type":"function","doc":"Deletes a device pool given the pool ARN. Does not allow deletion of curated pools owned by the system."},{"ref":"AWS.DeviceFarm.html#delete_instance_profile/3","title":"AWS.DeviceFarm.delete_instance_profile/3","type":"function","doc":"Deletes a profile that can be applied to one or more private device instances."},{"ref":"AWS.DeviceFarm.html#delete_network_profile/3","title":"AWS.DeviceFarm.delete_network_profile/3","type":"function","doc":"Deletes a network profile."},{"ref":"AWS.DeviceFarm.html#delete_project/3","title":"AWS.DeviceFarm.delete_project/3","type":"function","doc":"Deletes an AWS Device Farm project, given the project ARN. Deleting this resource does not stop an in-progress run."},{"ref":"AWS.DeviceFarm.html#delete_remote_access_session/3","title":"AWS.DeviceFarm.delete_remote_access_session/3","type":"function","doc":"Deletes a completed remote access session and its results."},{"ref":"AWS.DeviceFarm.html#delete_run/3","title":"AWS.DeviceFarm.delete_run/3","type":"function","doc":"Deletes the run, given the run ARN. Deleting this resource does not stop an in-progress run."},{"ref":"AWS.DeviceFarm.html#delete_test_grid_project/3","title":"AWS.DeviceFarm.delete_test_grid_project/3","type":"function","doc":"Deletes a Selenium testing project and all content generated under it. You cannot undo this operation. You cannot delete a project if it has active sessions."},{"ref":"AWS.DeviceFarm.html#delete_upload/3","title":"AWS.DeviceFarm.delete_upload/3","type":"function","doc":"Deletes an upload given the upload ARN."},{"ref":"AWS.DeviceFarm.html#delete_v_p_c_e_configuration/3","title":"AWS.DeviceFarm.delete_v_p_c_e_configuration/3","type":"function","doc":"Deletes a configuration for your Amazon Virtual Private Cloud (VPC) endpoint."},{"ref":"AWS.DeviceFarm.html#get_account_settings/3","title":"AWS.DeviceFarm.get_account_settings/3","type":"function","doc":"Returns the number of unmetered iOS or unmetered Android devices that have been purchased by the account."},{"ref":"AWS.DeviceFarm.html#get_device/3","title":"AWS.DeviceFarm.get_device/3","type":"function","doc":"Gets information about a unique device type."},{"ref":"AWS.DeviceFarm.html#get_device_instance/3","title":"AWS.DeviceFarm.get_device_instance/3","type":"function","doc":"Returns information about a device instance that belongs to a private device fleet."},{"ref":"AWS.DeviceFarm.html#get_device_pool/3","title":"AWS.DeviceFarm.get_device_pool/3","type":"function","doc":"Gets information about a device pool."},{"ref":"AWS.DeviceFarm.html#get_device_pool_compatibility/3","title":"AWS.DeviceFarm.get_device_pool_compatibility/3","type":"function","doc":"Gets information about compatibility with a device pool."},{"ref":"AWS.DeviceFarm.html#get_instance_profile/3","title":"AWS.DeviceFarm.get_instance_profile/3","type":"function","doc":"Returns information about the specified instance profile."},{"ref":"AWS.DeviceFarm.html#get_job/3","title":"AWS.DeviceFarm.get_job/3","type":"function","doc":"Gets information about a job."},{"ref":"AWS.DeviceFarm.html#get_network_profile/3","title":"AWS.DeviceFarm.get_network_profile/3","type":"function","doc":"Returns information about a network profile."},{"ref":"AWS.DeviceFarm.html#get_offering_status/3","title":"AWS.DeviceFarm.get_offering_status/3","type":"function","doc":"Gets the current status and future status of all offerings purchased by an AWS account. The response indicates how many offerings are currently available and the offerings that will be available in the next period. The API returns a NotEligible error if the user is not permitted to invoke the operation. If you must be able to invoke this operation, contact aws-devicefarm-support@amazon.com."},{"ref":"AWS.DeviceFarm.html#get_project/3","title":"AWS.DeviceFarm.get_project/3","type":"function","doc":"Gets information about a project."},{"ref":"AWS.DeviceFarm.html#get_remote_access_session/3","title":"AWS.DeviceFarm.get_remote_access_session/3","type":"function","doc":"Returns a link to a currently running remote access session."},{"ref":"AWS.DeviceFarm.html#get_run/3","title":"AWS.DeviceFarm.get_run/3","type":"function","doc":"Gets information about a run."},{"ref":"AWS.DeviceFarm.html#get_suite/3","title":"AWS.DeviceFarm.get_suite/3","type":"function","doc":"Gets information about a suite."},{"ref":"AWS.DeviceFarm.html#get_test/3","title":"AWS.DeviceFarm.get_test/3","type":"function","doc":"Gets information about a test."},{"ref":"AWS.DeviceFarm.html#get_test_grid_project/3","title":"AWS.DeviceFarm.get_test_grid_project/3","type":"function","doc":"Retrieves information about a Selenium testing project."},{"ref":"AWS.DeviceFarm.html#get_test_grid_session/3","title":"AWS.DeviceFarm.get_test_grid_session/3","type":"function","doc":"A session is an instance of a browser created through a RemoteWebDriver with the URL from CreateTestGridUrlResult$url. You can use the following to look up sessions: The session ARN (GetTestGridSessionRequest$sessionArn). The project ARN and a session ID (GetTestGridSessionRequest$projectArn and GetTestGridSessionRequest$sessionId)."},{"ref":"AWS.DeviceFarm.html#get_upload/3","title":"AWS.DeviceFarm.get_upload/3","type":"function","doc":"Gets information about an upload."},{"ref":"AWS.DeviceFarm.html#get_v_p_c_e_configuration/3","title":"AWS.DeviceFarm.get_v_p_c_e_configuration/3","type":"function","doc":"Returns information about the configuration settings for your Amazon Virtual Private Cloud (VPC) endpoint."},{"ref":"AWS.DeviceFarm.html#install_to_remote_access_session/3","title":"AWS.DeviceFarm.install_to_remote_access_session/3","type":"function","doc":"Installs an application to the device in a remote access session. For Android applications, the file must be in .apk format. For iOS applications, the file must be in .ipa format."},{"ref":"AWS.DeviceFarm.html#list_artifacts/3","title":"AWS.DeviceFarm.list_artifacts/3","type":"function","doc":"Gets information about artifacts."},{"ref":"AWS.DeviceFarm.html#list_device_instances/3","title":"AWS.DeviceFarm.list_device_instances/3","type":"function","doc":"Returns information about the private device instances associated with one or more AWS accounts."},{"ref":"AWS.DeviceFarm.html#list_device_pools/3","title":"AWS.DeviceFarm.list_device_pools/3","type":"function","doc":"Gets information about device pools."},{"ref":"AWS.DeviceFarm.html#list_devices/3","title":"AWS.DeviceFarm.list_devices/3","type":"function","doc":"Gets information about unique device types."},{"ref":"AWS.DeviceFarm.html#list_instance_profiles/3","title":"AWS.DeviceFarm.list_instance_profiles/3","type":"function","doc":"Returns information about all the instance profiles in an AWS account."},{"ref":"AWS.DeviceFarm.html#list_jobs/3","title":"AWS.DeviceFarm.list_jobs/3","type":"function","doc":"Gets information about jobs for a given test run."},{"ref":"AWS.DeviceFarm.html#list_network_profiles/3","title":"AWS.DeviceFarm.list_network_profiles/3","type":"function","doc":"Returns the list of available network profiles."},{"ref":"AWS.DeviceFarm.html#list_offering_promotions/3","title":"AWS.DeviceFarm.list_offering_promotions/3","type":"function","doc":"Returns a list of offering promotions. Each offering promotion record contains the ID and description of the promotion. The API returns a NotEligible error if the caller is not permitted to invoke the operation. Contact aws-devicefarm-support@amazon.com if you must be able to invoke this operation."},{"ref":"AWS.DeviceFarm.html#list_offering_transactions/3","title":"AWS.DeviceFarm.list_offering_transactions/3","type":"function","doc":"Returns a list of all historical purchases, renewals, and system renewal transactions for an AWS account. The list is paginated and ordered by a descending timestamp (most recent transactions are first). The API returns a NotEligible error if the user is not permitted to invoke the operation. If you must be able to invoke this operation, contact aws-devicefarm-support@amazon.com."},{"ref":"AWS.DeviceFarm.html#list_offerings/3","title":"AWS.DeviceFarm.list_offerings/3","type":"function","doc":"Returns a list of products or offerings that the user can manage through the API. Each offering record indicates the recurring price per unit and the frequency for that offering. The API returns a NotEligible error if the user is not permitted to invoke the operation. If you must be able to invoke this operation, contact aws-devicefarm-support@amazon.com."},{"ref":"AWS.DeviceFarm.html#list_projects/3","title":"AWS.DeviceFarm.list_projects/3","type":"function","doc":"Gets information about projects."},{"ref":"AWS.DeviceFarm.html#list_remote_access_sessions/3","title":"AWS.DeviceFarm.list_remote_access_sessions/3","type":"function","doc":"Returns a list of all currently running remote access sessions."},{"ref":"AWS.DeviceFarm.html#list_runs/3","title":"AWS.DeviceFarm.list_runs/3","type":"function","doc":"Gets information about runs, given an AWS Device Farm project ARN."},{"ref":"AWS.DeviceFarm.html#list_samples/3","title":"AWS.DeviceFarm.list_samples/3","type":"function","doc":"Gets information about samples, given an AWS Device Farm job ARN."},{"ref":"AWS.DeviceFarm.html#list_suites/3","title":"AWS.DeviceFarm.list_suites/3","type":"function","doc":"Gets information about test suites for a given job."},{"ref":"AWS.DeviceFarm.html#list_tags_for_resource/3","title":"AWS.DeviceFarm.list_tags_for_resource/3","type":"function","doc":"List the tags for an AWS Device Farm resource."},{"ref":"AWS.DeviceFarm.html#list_test_grid_projects/3","title":"AWS.DeviceFarm.list_test_grid_projects/3","type":"function","doc":"Gets a list of all Selenium testing projects in your account."},{"ref":"AWS.DeviceFarm.html#list_test_grid_session_actions/3","title":"AWS.DeviceFarm.list_test_grid_session_actions/3","type":"function","doc":"Returns a list of the actions taken in a TestGridSession."},{"ref":"AWS.DeviceFarm.html#list_test_grid_session_artifacts/3","title":"AWS.DeviceFarm.list_test_grid_session_artifacts/3","type":"function","doc":"Retrieves a list of artifacts created during the session."},{"ref":"AWS.DeviceFarm.html#list_test_grid_sessions/3","title":"AWS.DeviceFarm.list_test_grid_sessions/3","type":"function","doc":"Retrieves a list of sessions for a TestGridProject."},{"ref":"AWS.DeviceFarm.html#list_tests/3","title":"AWS.DeviceFarm.list_tests/3","type":"function","doc":"Gets information about tests in a given test suite."},{"ref":"AWS.DeviceFarm.html#list_unique_problems/3","title":"AWS.DeviceFarm.list_unique_problems/3","type":"function","doc":"Gets information about unique problems, such as exceptions or crashes. Unique problems are defined as a single instance of an error across a run, job, or suite. For example, if a call in your application consistently raises an exception (OutOfBoundsException in MyActivity.java:386), ListUniqueProblems returns a single entry instead of many individual entries for that exception."},{"ref":"AWS.DeviceFarm.html#list_uploads/3","title":"AWS.DeviceFarm.list_uploads/3","type":"function","doc":"Gets information about uploads, given an AWS Device Farm project ARN."},{"ref":"AWS.DeviceFarm.html#list_v_p_c_e_configurations/3","title":"AWS.DeviceFarm.list_v_p_c_e_configurations/3","type":"function","doc":"Returns information about all Amazon Virtual Private Cloud (VPC) endpoint configurations in the AWS account."},{"ref":"AWS.DeviceFarm.html#purchase_offering/3","title":"AWS.DeviceFarm.purchase_offering/3","type":"function","doc":"Immediately purchases offerings for an AWS account. Offerings renew with the latest total purchased quantity for an offering, unless the renewal was overridden. The API returns a NotEligible error if the user is not permitted to invoke the operation. If you must be able to invoke this operation, contact aws-devicefarm-support@amazon.com."},{"ref":"AWS.DeviceFarm.html#renew_offering/3","title":"AWS.DeviceFarm.renew_offering/3","type":"function","doc":"Explicitly sets the quantity of devices to renew for an offering, starting from the effectiveDate of the next period. The API returns a NotEligible error if the user is not permitted to invoke the operation. If you must be able to invoke this operation, contact aws-devicefarm-support@amazon.com."},{"ref":"AWS.DeviceFarm.html#schedule_run/3","title":"AWS.DeviceFarm.schedule_run/3","type":"function","doc":"Schedules a run."},{"ref":"AWS.DeviceFarm.html#stop_job/3","title":"AWS.DeviceFarm.stop_job/3","type":"function","doc":"Initiates a stop request for the current job. AWS Device Farm immediately stops the job on the device where tests have not started. You are not billed for this device. On the device where tests have started, setup suite and teardown suite tests run to completion on the device. You are billed for setup, teardown, and any tests that were in progress or already completed."},{"ref":"AWS.DeviceFarm.html#stop_remote_access_session/3","title":"AWS.DeviceFarm.stop_remote_access_session/3","type":"function","doc":"Ends a specified remote access session."},{"ref":"AWS.DeviceFarm.html#stop_run/3","title":"AWS.DeviceFarm.stop_run/3","type":"function","doc":"Initiates a stop request for the current test run. AWS Device Farm immediately stops the run on devices where tests have not started. You are not billed for these devices. On devices where tests have started executing, setup suite and teardown suite tests run to completion on those devices. You are billed for setup, teardown, and any tests that were in progress or already completed."},{"ref":"AWS.DeviceFarm.html#tag_resource/3","title":"AWS.DeviceFarm.tag_resource/3","type":"function","doc":"Associates the specified tags to a resource with the specified resourceArn. If existing tags on a resource are not specified in the request parameters, they are not changed. When a resource is deleted, the tags associated with that resource are also deleted."},{"ref":"AWS.DeviceFarm.html#untag_resource/3","title":"AWS.DeviceFarm.untag_resource/3","type":"function","doc":"Deletes the specified tags from a resource."},{"ref":"AWS.DeviceFarm.html#update_device_instance/3","title":"AWS.DeviceFarm.update_device_instance/3","type":"function","doc":"Updates information about a private device instance."},{"ref":"AWS.DeviceFarm.html#update_device_pool/3","title":"AWS.DeviceFarm.update_device_pool/3","type":"function","doc":"Modifies the name, description, and rules in a device pool given the attributes and the pool ARN. Rule updates are all-or-nothing, meaning they can only be updated as a whole (or not at all)."},{"ref":"AWS.DeviceFarm.html#update_instance_profile/3","title":"AWS.DeviceFarm.update_instance_profile/3","type":"function","doc":"Updates information about an existing private device instance profile."},{"ref":"AWS.DeviceFarm.html#update_network_profile/3","title":"AWS.DeviceFarm.update_network_profile/3","type":"function","doc":"Updates the network profile."},{"ref":"AWS.DeviceFarm.html#update_project/3","title":"AWS.DeviceFarm.update_project/3","type":"function","doc":"Modifies the specified project name, given the project ARN and a new name."},{"ref":"AWS.DeviceFarm.html#update_test_grid_project/3","title":"AWS.DeviceFarm.update_test_grid_project/3","type":"function","doc":"Change details of a project."},{"ref":"AWS.DeviceFarm.html#update_upload/3","title":"AWS.DeviceFarm.update_upload/3","type":"function","doc":"Updates an uploaded test spec."},{"ref":"AWS.DeviceFarm.html#update_v_p_c_e_configuration/3","title":"AWS.DeviceFarm.update_v_p_c_e_configuration/3","type":"function","doc":"Updates information about an Amazon Virtual Private Cloud (VPC) endpoint configuration."},{"ref":"AWS.DirectConnect.html","title":"AWS.DirectConnect","type":"module","doc":"AWS Direct Connect links your internal network to an AWS Direct Connect location over a standard Ethernet fiber-optic cable. One end of the cable is connected to your router, the other to an AWS Direct Connect router. With this connection in place, you can create virtual interfaces directly to the AWS cloud (for example, to Amazon EC2 and Amazon S3) and to Amazon VPC, bypassing Internet service providers in your network path. A connection provides access to all AWS Regions except the China (Beijing) and (China) Ningxia Regions. AWS resources in the China Regions can only be accessed through locations associated with those Regions."},{"ref":"AWS.DirectConnect.html#accept_direct_connect_gateway_association_proposal/3","title":"AWS.DirectConnect.accept_direct_connect_gateway_association_proposal/3","type":"function","doc":"Accepts a proposal request to attach a virtual private gateway or transit gateway to a Direct Connect gateway."},{"ref":"AWS.DirectConnect.html#allocate_connection_on_interconnect/3","title":"AWS.DirectConnect.allocate_connection_on_interconnect/3","type":"function","doc":"Deprecated. Use AllocateHostedConnection instead. Creates a hosted connection on an interconnect. Allocates a VLAN number and a specified amount of bandwidth for use by a hosted connection on the specified interconnect. Intended for use by AWS Direct Connect Partners only."},{"ref":"AWS.DirectConnect.html#allocate_hosted_connection/3","title":"AWS.DirectConnect.allocate_hosted_connection/3","type":"function","doc":"Creates a hosted connection on the specified interconnect or a link aggregation group (LAG) of interconnects. Allocates a VLAN number and a specified amount of capacity (bandwidth) for use by a hosted connection on the specified interconnect or LAG of interconnects. AWS polices the hosted connection for the specified capacity and the AWS Direct Connect Partner must also police the hosted connection for the specified capacity. Intended for use by AWS Direct Connect Partners only."},{"ref":"AWS.DirectConnect.html#allocate_private_virtual_interface/3","title":"AWS.DirectConnect.allocate_private_virtual_interface/3","type":"function","doc":"Provisions a private virtual interface to be owned by the specified AWS account. Virtual interfaces created using this action must be confirmed by the owner using ConfirmPrivateVirtualInterface. Until then, the virtual interface is in the Confirming state and is not available to handle traffic."},{"ref":"AWS.DirectConnect.html#allocate_public_virtual_interface/3","title":"AWS.DirectConnect.allocate_public_virtual_interface/3","type":"function","doc":"Provisions a public virtual interface to be owned by the specified AWS account. The owner of a connection calls this function to provision a public virtual interface to be owned by the specified AWS account. Virtual interfaces created using this function must be confirmed by the owner using ConfirmPublicVirtualInterface. Until this step has been completed, the virtual interface is in the confirming state and is not available to handle traffic. When creating an IPv6 public virtual interface, omit the Amazon address and customer address. IPv6 addresses are automatically assigned from the Amazon pool of IPv6 addresses; you cannot specify custom IPv6 addresses."},{"ref":"AWS.DirectConnect.html#allocate_transit_virtual_interface/3","title":"AWS.DirectConnect.allocate_transit_virtual_interface/3","type":"function","doc":"Provisions a transit virtual interface to be owned by the specified AWS account. Use this type of interface to connect a transit gateway to your Direct Connect gateway. The owner of a connection provisions a transit virtual interface to be owned by the specified AWS account. After you create a transit virtual interface, it must be confirmed by the owner using ConfirmTransitVirtualInterface. Until this step has been completed, the transit virtual interface is in the requested state and is not available to handle traffic."},{"ref":"AWS.DirectConnect.html#associate_connection_with_lag/3","title":"AWS.DirectConnect.associate_connection_with_lag/3","type":"function","doc":"Associates an existing connection with a link aggregation group (LAG). The connection is interrupted and re-established as a member of the LAG (connectivity to AWS is interrupted). The connection must be hosted on the same AWS Direct Connect endpoint as the LAG, and its bandwidth must match the bandwidth for the LAG. You can re-associate a connection that&#39;s currently associated with a different LAG; however, if removing the connection would cause the original LAG to fall below its setting for minimum number of operational connections, the request fails. Any virtual interfaces that are directly associated with the connection are automatically re-associated with the LAG. If the connection was originally associated with a different LAG, the virtual interfaces remain associated with the original LAG. For interconnects, any hosted connections are automatically re-associated with the LAG. If the interconnect was originally associated with a different LAG, the hosted connections remain associated with the original LAG."},{"ref":"AWS.DirectConnect.html#associate_hosted_connection/3","title":"AWS.DirectConnect.associate_hosted_connection/3","type":"function","doc":"Associates a hosted connection and its virtual interfaces with a link aggregation group (LAG) or interconnect. If the target interconnect or LAG has an existing hosted connection with a conflicting VLAN number or IP address, the operation fails. This action temporarily interrupts the hosted connection&#39;s connectivity to AWS as it is being migrated. Intended for use by AWS Direct Connect Partners only."},{"ref":"AWS.DirectConnect.html#associate_virtual_interface/3","title":"AWS.DirectConnect.associate_virtual_interface/3","type":"function","doc":"Associates a virtual interface with a specified link aggregation group (LAG) or connection. Connectivity to AWS is temporarily interrupted as the virtual interface is being migrated. If the target connection or LAG has an associated virtual interface with a conflicting VLAN number or a conflicting IP address, the operation fails. Virtual interfaces associated with a hosted connection cannot be associated with a LAG; hosted connections must be migrated along with their virtual interfaces using AssociateHostedConnection. To reassociate a virtual interface to a new connection or LAG, the requester must own either the virtual interface itself or the connection to which the virtual interface is currently associated. Additionally, the requester must own the connection or LAG for the association."},{"ref":"AWS.DirectConnect.html#confirm_connection/3","title":"AWS.DirectConnect.confirm_connection/3","type":"function","doc":"Confirms the creation of the specified hosted connection on an interconnect. Upon creation, the hosted connection is initially in the Ordering state, and remains in this state until the owner confirms creation of the hosted connection."},{"ref":"AWS.DirectConnect.html#confirm_private_virtual_interface/3","title":"AWS.DirectConnect.confirm_private_virtual_interface/3","type":"function","doc":"Accepts ownership of a private virtual interface created by another AWS account. After the virtual interface owner makes this call, the virtual interface is created and attached to the specified virtual private gateway or Direct Connect gateway, and is made available to handle traffic."},{"ref":"AWS.DirectConnect.html#confirm_public_virtual_interface/3","title":"AWS.DirectConnect.confirm_public_virtual_interface/3","type":"function","doc":"Accepts ownership of a public virtual interface created by another AWS account. After the virtual interface owner makes this call, the specified virtual interface is created and made available to handle traffic."},{"ref":"AWS.DirectConnect.html#confirm_transit_virtual_interface/3","title":"AWS.DirectConnect.confirm_transit_virtual_interface/3","type":"function","doc":"Accepts ownership of a transit virtual interface created by another AWS account. After the owner of the transit virtual interface makes this call, the specified transit virtual interface is created and made available to handle traffic."},{"ref":"AWS.DirectConnect.html#create_bgp_peer/3","title":"AWS.DirectConnect.create_bgp_peer/3","type":"function","doc":"Creates a BGP peer on the specified virtual interface. You must create a BGP peer for the corresponding address family (IPv4/IPv6) in order to access AWS resources that also use that address family. If logical redundancy is not supported by the connection, interconnect, or LAG, the BGP peer cannot be in the same address family as an existing BGP peer on the virtual interface. When creating a IPv6 BGP peer, omit the Amazon address and customer address. IPv6 addresses are automatically assigned from the Amazon pool of IPv6 addresses; you cannot specify custom IPv6 addresses. For a public virtual interface, the Autonomous System Number (ASN) must be private or already whitelisted for the virtual interface."},{"ref":"AWS.DirectConnect.html#create_connection/3","title":"AWS.DirectConnect.create_connection/3","type":"function","doc":"Creates a connection between a customer network and a specific AWS Direct Connect location. A connection links your internal network to an AWS Direct Connect location over a standard Ethernet fiber-optic cable. One end of the cable is connected to your router, the other to an AWS Direct Connect router. To find the locations for your Region, use DescribeLocations. You can automatically add the new connection to a link aggregation group (LAG) by specifying a LAG ID in the request. This ensures that the new connection is allocated on the same AWS Direct Connect endpoint that hosts the specified LAG. If there are no available ports on the endpoint, the request fails and no connection is created."},{"ref":"AWS.DirectConnect.html#create_direct_connect_gateway/3","title":"AWS.DirectConnect.create_direct_connect_gateway/3","type":"function","doc":"Creates a Direct Connect gateway, which is an intermediate object that enables you to connect a set of virtual interfaces and virtual private gateways. A Direct Connect gateway is global and visible in any AWS Region after it is created. The virtual interfaces and virtual private gateways that are connected through a Direct Connect gateway can be in different AWS Regions. This enables you to connect to a VPC in any Region, regardless of the Region in which the virtual interfaces are located, and pass traffic between them."},{"ref":"AWS.DirectConnect.html#create_direct_connect_gateway_association/3","title":"AWS.DirectConnect.create_direct_connect_gateway_association/3","type":"function","doc":"Creates an association between a Direct Connect gateway and a virtual private gateway. The virtual private gateway must be attached to a VPC and must not be associated with another Direct Connect gateway."},{"ref":"AWS.DirectConnect.html#create_direct_connect_gateway_association_proposal/3","title":"AWS.DirectConnect.create_direct_connect_gateway_association_proposal/3","type":"function","doc":"Creates a proposal to associate the specified virtual private gateway or transit gateway with the specified Direct Connect gateway. You can associate a Direct Connect gateway and virtual private gateway or transit gateway that is owned by any AWS account."},{"ref":"AWS.DirectConnect.html#create_interconnect/3","title":"AWS.DirectConnect.create_interconnect/3","type":"function","doc":"Creates an interconnect between an AWS Direct Connect Partner&#39;s network and a specific AWS Direct Connect location. An interconnect is a connection that is capable of hosting other connections. The AWS Direct Connect partner can use an interconnect to provide AWS Direct Connect hosted connections to customers through their own network services. Like a standard connection, an interconnect links the partner&#39;s network to an AWS Direct Connect location over a standard Ethernet fiber-optic cable. One end is connected to the partner&#39;s router, the other to an AWS Direct Connect router. You can automatically add the new interconnect to a link aggregation group (LAG) by specifying a LAG ID in the request. This ensures that the new interconnect is allocated on the same AWS Direct Connect endpoint that hosts the specified LAG. If there are no available ports on the endpoint, the request fails and no interconnect is created. For each end customer, the AWS Direct Connect Partner provisions a connection on their interconnect by calling AllocateHostedConnection. The end customer can then connect to AWS resources by creating a virtual interface on their connection, using the VLAN assigned to them by the AWS Direct Connect Partner. Intended for use by AWS Direct Connect Partners only."},{"ref":"AWS.DirectConnect.html#create_lag/3","title":"AWS.DirectConnect.create_lag/3","type":"function","doc":"Creates a link aggregation group (LAG) with the specified number of bundled physical dedicated connections between the customer network and a specific AWS Direct Connect location. A LAG is a logical interface that uses the Link Aggregation Control Protocol (LACP) to aggregate multiple interfaces, enabling you to treat them as a single interface. All connections in a LAG must use the same bandwidth (either 1Gbps or 10Gbps) and must terminate at the same AWS Direct Connect endpoint. You can have up to 10 dedicated connections per LAG. Regardless of this limit, if you request more connections for the LAG than AWS Direct Connect can allocate on a single endpoint, no LAG is created. You can specify an existing physical dedicated connection or interconnect to include in the LAG (which counts towards the total number of connections). Doing so interrupts the current physical dedicated connection, and re-establishes them as a member of the LAG. The LAG will be created on the same AWS Direct Connect endpoint to which the dedicated connection terminates. Any virtual interfaces associated with the dedicated connection are automatically disassociated and re-associated with the LAG. The connection ID does not change. If the AWS account used to create a LAG is a registered AWS Direct Connect Partner, the LAG is automatically enabled to host sub-connections. For a LAG owned by a partner, any associated virtual interfaces cannot be directly configured."},{"ref":"AWS.DirectConnect.html#create_private_virtual_interface/3","title":"AWS.DirectConnect.create_private_virtual_interface/3","type":"function","doc":"Creates a private virtual interface. A virtual interface is the VLAN that transports AWS Direct Connect traffic. A private virtual interface can be connected to either a Direct Connect gateway or a Virtual Private Gateway (VGW). Connecting the private virtual interface to a Direct Connect gateway enables the possibility for connecting to multiple VPCs, including VPCs in different AWS Regions. Connecting the private virtual interface to a VGW only provides access to a single VPC within the same Region. Setting the MTU of a virtual interface to 9001 (jumbo frames) can cause an update to the underlying physical connection if it wasn&#39;t updated to support jumbo frames. Updating the connection disrupts network connectivity for all virtual interfaces associated with the connection for up to 30 seconds. To check whether your connection supports jumbo frames, call DescribeConnections. To check whether your virtual interface supports jumbo frames, call DescribeVirtualInterfaces."},{"ref":"AWS.DirectConnect.html#create_public_virtual_interface/3","title":"AWS.DirectConnect.create_public_virtual_interface/3","type":"function","doc":"Creates a public virtual interface. A virtual interface is the VLAN that transports AWS Direct Connect traffic. A public virtual interface supports sending traffic to public services of AWS such as Amazon S3. When creating an IPv6 public virtual interface (addressFamily is ipv6), leave the customer and amazon address fields blank to use auto-assigned IPv6 space. Custom IPv6 addresses are not supported."},{"ref":"AWS.DirectConnect.html#create_transit_virtual_interface/3","title":"AWS.DirectConnect.create_transit_virtual_interface/3","type":"function","doc":"Creates a transit virtual interface. A transit virtual interface should be used to access one or more transit gateways associated with Direct Connect gateways. A transit virtual interface enables the connection of multiple VPCs attached to a transit gateway to a Direct Connect gateway. If you associate your transit gateway with one or more Direct Connect gateways, the Autonomous System Number (ASN) used by the transit gateway and the Direct Connect gateway must be different. For example, if you use the default ASN 64512 for both your the transit gateway and Direct Connect gateway, the association request fails. Setting the MTU of a virtual interface to 8500 (jumbo frames) can cause an update to the underlying physical connection if it wasn&#39;t updated to support jumbo frames. Updating the connection disrupts network connectivity for all virtual interfaces associated with the connection for up to 30 seconds. To check whether your connection supports jumbo frames, call DescribeConnections. To check whether your virtual interface supports jumbo frames, call DescribeVirtualInterfaces."},{"ref":"AWS.DirectConnect.html#delete_bgp_peer/3","title":"AWS.DirectConnect.delete_bgp_peer/3","type":"function","doc":"Deletes the specified BGP peer on the specified virtual interface with the specified customer address and ASN. You cannot delete the last BGP peer from a virtual interface."},{"ref":"AWS.DirectConnect.html#delete_connection/3","title":"AWS.DirectConnect.delete_connection/3","type":"function","doc":"Deletes the specified connection. Deleting a connection only stops the AWS Direct Connect port hour and data transfer charges. If you are partnering with any third parties to connect with the AWS Direct Connect location, you must cancel your service with them separately."},{"ref":"AWS.DirectConnect.html#delete_direct_connect_gateway/3","title":"AWS.DirectConnect.delete_direct_connect_gateway/3","type":"function","doc":"Deletes the specified Direct Connect gateway. You must first delete all virtual interfaces that are attached to the Direct Connect gateway and disassociate all virtual private gateways associated with the Direct Connect gateway."},{"ref":"AWS.DirectConnect.html#delete_direct_connect_gateway_association/3","title":"AWS.DirectConnect.delete_direct_connect_gateway_association/3","type":"function","doc":"Deletes the association between the specified Direct Connect gateway and virtual private gateway. We recommend that you specify the associationID to delete the association. Alternatively, if you own virtual gateway and a Direct Connect gateway association, you can specify the virtualGatewayId and directConnectGatewayId to delete an association."},{"ref":"AWS.DirectConnect.html#delete_direct_connect_gateway_association_proposal/3","title":"AWS.DirectConnect.delete_direct_connect_gateway_association_proposal/3","type":"function","doc":"Deletes the association proposal request between the specified Direct Connect gateway and virtual private gateway or transit gateway."},{"ref":"AWS.DirectConnect.html#delete_interconnect/3","title":"AWS.DirectConnect.delete_interconnect/3","type":"function","doc":"Deletes the specified interconnect. Intended for use by AWS Direct Connect Partners only."},{"ref":"AWS.DirectConnect.html#delete_lag/3","title":"AWS.DirectConnect.delete_lag/3","type":"function","doc":"Deletes the specified link aggregation group (LAG). You cannot delete a LAG if it has active virtual interfaces or hosted connections."},{"ref":"AWS.DirectConnect.html#delete_virtual_interface/3","title":"AWS.DirectConnect.delete_virtual_interface/3","type":"function","doc":"Deletes a virtual interface."},{"ref":"AWS.DirectConnect.html#describe_connection_loa/3","title":"AWS.DirectConnect.describe_connection_loa/3","type":"function","doc":"Deprecated. Use DescribeLoa instead. Gets the LOA-CFA for a connection. The Letter of Authorization - Connecting Facility Assignment (LOA-CFA) is a document that your APN partner or service provider uses when establishing your cross connect to AWS at the colocation facility. For more information, see Requesting Cross Connects at AWS Direct Connect Locations in the AWS Direct Connect User Guide."},{"ref":"AWS.DirectConnect.html#describe_connections/3","title":"AWS.DirectConnect.describe_connections/3","type":"function","doc":"Displays the specified connection or all connections in this Region."},{"ref":"AWS.DirectConnect.html#describe_connections_on_interconnect/3","title":"AWS.DirectConnect.describe_connections_on_interconnect/3","type":"function","doc":"Deprecated. Use DescribeHostedConnections instead. Lists the connections that have been provisioned on the specified interconnect. Intended for use by AWS Direct Connect Partners only."},{"ref":"AWS.DirectConnect.html#describe_direct_connect_gateway_association_proposals/3","title":"AWS.DirectConnect.describe_direct_connect_gateway_association_proposals/3","type":"function","doc":"Describes one or more association proposals for connection between a virtual private gateway or transit gateway and a Direct Connect gateway."},{"ref":"AWS.DirectConnect.html#describe_direct_connect_gateway_associations/3","title":"AWS.DirectConnect.describe_direct_connect_gateway_associations/3","type":"function","doc":"Lists the associations between your Direct Connect gateways and virtual private gateways. You must specify a Direct Connect gateway, a virtual private gateway, or both. If you specify a Direct Connect gateway, the response contains all virtual private gateways associated with the Direct Connect gateway. If you specify a virtual private gateway, the response contains all Direct Connect gateways associated with the virtual private gateway. If you specify both, the response contains the association between the Direct Connect gateway and the virtual private gateway."},{"ref":"AWS.DirectConnect.html#describe_direct_connect_gateway_attachments/3","title":"AWS.DirectConnect.describe_direct_connect_gateway_attachments/3","type":"function","doc":"Lists the attachments between your Direct Connect gateways and virtual interfaces. You must specify a Direct Connect gateway, a virtual interface, or both. If you specify a Direct Connect gateway, the response contains all virtual interfaces attached to the Direct Connect gateway. If you specify a virtual interface, the response contains all Direct Connect gateways attached to the virtual interface. If you specify both, the response contains the attachment between the Direct Connect gateway and the virtual interface."},{"ref":"AWS.DirectConnect.html#describe_direct_connect_gateways/3","title":"AWS.DirectConnect.describe_direct_connect_gateways/3","type":"function","doc":"Lists all your Direct Connect gateways or only the specified Direct Connect gateway. Deleted Direct Connect gateways are not returned."},{"ref":"AWS.DirectConnect.html#describe_hosted_connections/3","title":"AWS.DirectConnect.describe_hosted_connections/3","type":"function","doc":"Lists the hosted connections that have been provisioned on the specified interconnect or link aggregation group (LAG). Intended for use by AWS Direct Connect Partners only."},{"ref":"AWS.DirectConnect.html#describe_interconnect_loa/3","title":"AWS.DirectConnect.describe_interconnect_loa/3","type":"function","doc":"Deprecated. Use DescribeLoa instead. Gets the LOA-CFA for the specified interconnect. The Letter of Authorization - Connecting Facility Assignment (LOA-CFA) is a document that is used when establishing your cross connect to AWS at the colocation facility. For more information, see Requesting Cross Connects at AWS Direct Connect Locations in the AWS Direct Connect User Guide."},{"ref":"AWS.DirectConnect.html#describe_interconnects/3","title":"AWS.DirectConnect.describe_interconnects/3","type":"function","doc":"Lists the interconnects owned by the AWS account or only the specified interconnect."},{"ref":"AWS.DirectConnect.html#describe_lags/3","title":"AWS.DirectConnect.describe_lags/3","type":"function","doc":"Describes all your link aggregation groups (LAG) or the specified LAG."},{"ref":"AWS.DirectConnect.html#describe_loa/3","title":"AWS.DirectConnect.describe_loa/3","type":"function","doc":"Gets the LOA-CFA for a connection, interconnect, or link aggregation group (LAG). The Letter of Authorization - Connecting Facility Assignment (LOA-CFA) is a document that is used when establishing your cross connect to AWS at the colocation facility. For more information, see Requesting Cross Connects at AWS Direct Connect Locations in the AWS Direct Connect User Guide."},{"ref":"AWS.DirectConnect.html#describe_locations/3","title":"AWS.DirectConnect.describe_locations/3","type":"function","doc":"Lists the AWS Direct Connect locations in the current AWS Region. These are the locations that can be selected when calling CreateConnection or CreateInterconnect."},{"ref":"AWS.DirectConnect.html#describe_tags/3","title":"AWS.DirectConnect.describe_tags/3","type":"function","doc":"Describes the tags associated with the specified AWS Direct Connect resources."},{"ref":"AWS.DirectConnect.html#describe_virtual_gateways/3","title":"AWS.DirectConnect.describe_virtual_gateways/3","type":"function","doc":"Lists the virtual private gateways owned by the AWS account. You can create one or more AWS Direct Connect private virtual interfaces linked to a virtual private gateway."},{"ref":"AWS.DirectConnect.html#describe_virtual_interfaces/3","title":"AWS.DirectConnect.describe_virtual_interfaces/3","type":"function","doc":"Displays all virtual interfaces for an AWS account. Virtual interfaces deleted fewer than 15 minutes before you make the request are also returned. If you specify a connection ID, only the virtual interfaces associated with the connection are returned. If you specify a virtual interface ID, then only a single virtual interface is returned. A virtual interface (VLAN) transmits the traffic between the AWS Direct Connect location and the customer network."},{"ref":"AWS.DirectConnect.html#disassociate_connection_from_lag/3","title":"AWS.DirectConnect.disassociate_connection_from_lag/3","type":"function","doc":"Disassociates a connection from a link aggregation group (LAG). The connection is interrupted and re-established as a standalone connection (the connection is not deleted; to delete the connection, use the DeleteConnection request). If the LAG has associated virtual interfaces or hosted connections, they remain associated with the LAG. A disassociated connection owned by an AWS Direct Connect Partner is automatically converted to an interconnect. If disassociating the connection would cause the LAG to fall below its setting for minimum number of operational connections, the request fails, except when it&#39;s the last member of the LAG. If all connections are disassociated, the LAG continues to exist as an empty LAG with no physical connections."},{"ref":"AWS.DirectConnect.html#list_virtual_interface_test_history/3","title":"AWS.DirectConnect.list_virtual_interface_test_history/3","type":"function","doc":"Lists the virtual interface failover test history."},{"ref":"AWS.DirectConnect.html#start_bgp_failover_test/3","title":"AWS.DirectConnect.start_bgp_failover_test/3","type":"function","doc":"Starts the virtual interface failover test that verifies your configuration meets your resiliency requirements by placing the BGP peering session in the DOWN state. You can then send traffic to verify that there are no outages. You can run the test on public, private, transit, and hosted virtual interfaces. You can use ListVirtualInterfaceTestHistory to view the virtual interface test history. If you need to stop the test before the test interval completes, use StopBgpFailoverTest."},{"ref":"AWS.DirectConnect.html#stop_bgp_failover_test/3","title":"AWS.DirectConnect.stop_bgp_failover_test/3","type":"function","doc":"Stops the virtual interface failover test."},{"ref":"AWS.DirectConnect.html#tag_resource/3","title":"AWS.DirectConnect.tag_resource/3","type":"function","doc":"Adds the specified tags to the specified AWS Direct Connect resource. Each resource can have a maximum of 50 tags. Each tag consists of a key and an optional value. If a tag with the same key is already associated with the resource, this action updates its value."},{"ref":"AWS.DirectConnect.html#untag_resource/3","title":"AWS.DirectConnect.untag_resource/3","type":"function","doc":"Removes one or more tags from the specified AWS Direct Connect resource."},{"ref":"AWS.DirectConnect.html#update_direct_connect_gateway_association/3","title":"AWS.DirectConnect.update_direct_connect_gateway_association/3","type":"function","doc":"Updates the specified attributes of the Direct Connect gateway association. Add or remove prefixes from the association."},{"ref":"AWS.DirectConnect.html#update_lag/3","title":"AWS.DirectConnect.update_lag/3","type":"function","doc":"Updates the attributes of the specified link aggregation group (LAG). You can update the following attributes: The name of the LAG. The value for the minimum number of connections that must be operational for the LAG itself to be operational. When you create a LAG, the default value for the minimum number of operational connections is zero (0). If you update this value and the number of operational connections falls below the specified value, the LAG automatically goes down to avoid over-utilization of the remaining connections. Adjust this value with care, as it could force the LAG down if it is set higher than the current number of operational connections."},{"ref":"AWS.DirectConnect.html#update_virtual_interface_attributes/3","title":"AWS.DirectConnect.update_virtual_interface_attributes/3","type":"function","doc":"Updates the specified attributes of the specified virtual private interface. Setting the MTU of a virtual interface to 9001 (jumbo frames) can cause an update to the underlying physical connection if it wasn&#39;t updated to support jumbo frames. Updating the connection disrupts network connectivity for all virtual interfaces associated with the connection for up to 30 seconds. To check whether your connection supports jumbo frames, call DescribeConnections. To check whether your virtual q interface supports jumbo frames, call DescribeVirtualInterfaces."},{"ref":"AWS.Directory.html","title":"AWS.Directory","type":"module","doc":"AWS Directory Service AWS Directory Service is a web service that makes it easy for you to setup and run directories in the AWS cloud, or connect your AWS resources with an existing on-premises Microsoft Active Directory. This guide provides detailed information about AWS Directory Service operations, data types, parameters, and errors. For information about AWS Directory Services features, see AWS Directory Service and the AWS Directory Service Administration Guide. AWS provides SDKs that consist of libraries and sample code for various programming languages and platforms (Java, Ruby, .Net, iOS, Android, etc.). The SDKs provide a convenient way to create programmatic access to AWS Directory Service and other AWS services. For more information about the AWS SDKs, including how to download and install them, see Tools for Amazon Web Services."},{"ref":"AWS.Directory.html#accept_shared_directory/3","title":"AWS.Directory.accept_shared_directory/3","type":"function","doc":"Accepts a directory sharing request that was sent from the directory owner account."},{"ref":"AWS.Directory.html#add_ip_routes/3","title":"AWS.Directory.add_ip_routes/3","type":"function","doc":"If the DNS server for your on-premises domain uses a publicly addressable IP address, you must add a CIDR address block to correctly route traffic to and from your Microsoft AD on Amazon Web Services. AddIpRoutes adds this address block. You can also use AddIpRoutes to facilitate routing traffic that uses public IP ranges from your Microsoft AD on AWS to a peer VPC. Before you call AddIpRoutes, ensure that all of the required permissions have been explicitly granted through a policy. For details about what permissions are required to run the AddIpRoutes operation, see AWS Directory Service API Permissions: Actions, Resources, and Conditions Reference."},{"ref":"AWS.Directory.html#add_tags_to_resource/3","title":"AWS.Directory.add_tags_to_resource/3","type":"function","doc":"Adds or overwrites one or more tags for the specified directory. Each directory can have a maximum of 50 tags. Each tag consists of a key and optional value. Tag keys must be unique to each resource."},{"ref":"AWS.Directory.html#cancel_schema_extension/3","title":"AWS.Directory.cancel_schema_extension/3","type":"function","doc":"Cancels an in-progress schema extension to a Microsoft AD directory. Once a schema extension has started replicating to all domain controllers, the task can no longer be canceled. A schema extension can be canceled during any of the following states; Initializing, CreatingSnapshot, and UpdatingSchema."},{"ref":"AWS.Directory.html#connect_directory/3","title":"AWS.Directory.connect_directory/3","type":"function","doc":"Creates an AD Connector to connect to an on-premises directory. Before you call ConnectDirectory, ensure that all of the required permissions have been explicitly granted through a policy. For details about what permissions are required to run the ConnectDirectory operation, see AWS Directory Service API Permissions: Actions, Resources, and Conditions Reference."},{"ref":"AWS.Directory.html#create_alias/3","title":"AWS.Directory.create_alias/3","type":"function","doc":"Creates an alias for a directory and assigns the alias to the directory. The alias is used to construct the access URL for the directory, such as http://&lt;alias&gt;.awsapps.com. After an alias has been created, it cannot be deleted or reused, so this operation should only be used when absolutely necessary."},{"ref":"AWS.Directory.html#create_computer/3","title":"AWS.Directory.create_computer/3","type":"function","doc":"Creates a computer account in the specified directory, and joins the computer to the directory."},{"ref":"AWS.Directory.html#create_conditional_forwarder/3","title":"AWS.Directory.create_conditional_forwarder/3","type":"function","doc":"Creates a conditional forwarder associated with your AWS directory. Conditional forwarders are required in order to set up a trust relationship with another domain. The conditional forwarder points to the trusted domain."},{"ref":"AWS.Directory.html#create_directory/3","title":"AWS.Directory.create_directory/3","type":"function","doc":"Creates a Simple AD directory. For more information, see Simple Active Directory in the AWS Directory Service Admin Guide. Before you call CreateDirectory, ensure that all of the required permissions have been explicitly granted through a policy. For details about what permissions are required to run the CreateDirectory operation, see AWS Directory Service API Permissions: Actions, Resources, and Conditions Reference."},{"ref":"AWS.Directory.html#create_log_subscription/3","title":"AWS.Directory.create_log_subscription/3","type":"function","doc":"Creates a subscription to forward real-time Directory Service domain controller security logs to the specified Amazon CloudWatch log group in your AWS account."},{"ref":"AWS.Directory.html#create_microsoft_a_d/3","title":"AWS.Directory.create_microsoft_a_d/3","type":"function","doc":"Creates a Microsoft AD directory in the AWS Cloud. For more information, see AWS Managed Microsoft AD in the AWS Directory Service Admin Guide. Before you call CreateMicrosoftAD, ensure that all of the required permissions have been explicitly granted through a policy. For details about what permissions are required to run the CreateMicrosoftAD operation, see AWS Directory Service API Permissions: Actions, Resources, and Conditions Reference."},{"ref":"AWS.Directory.html#create_snapshot/3","title":"AWS.Directory.create_snapshot/3","type":"function","doc":"Creates a snapshot of a Simple AD or Microsoft AD directory in the AWS cloud. You cannot take snapshots of AD Connector directories."},{"ref":"AWS.Directory.html#create_trust/3","title":"AWS.Directory.create_trust/3","type":"function","doc":"AWS Directory Service for Microsoft Active Directory allows you to configure trust relationships. For example, you can establish a trust between your AWS Managed Microsoft AD directory, and your existing on-premises Microsoft Active Directory. This would allow you to provide users and groups access to resources in either domain, with a single set of credentials. This action initiates the creation of the AWS side of a trust relationship between an AWS Managed Microsoft AD directory and an external domain. You can create either a forest trust or an external trust."},{"ref":"AWS.Directory.html#delete_conditional_forwarder/3","title":"AWS.Directory.delete_conditional_forwarder/3","type":"function","doc":"Deletes a conditional forwarder that has been set up for your AWS directory."},{"ref":"AWS.Directory.html#delete_directory/3","title":"AWS.Directory.delete_directory/3","type":"function","doc":"Deletes an AWS Directory Service directory. Before you call DeleteDirectory, ensure that all of the required permissions have been explicitly granted through a policy. For details about what permissions are required to run the DeleteDirectory operation, see AWS Directory Service API Permissions: Actions, Resources, and Conditions Reference."},{"ref":"AWS.Directory.html#delete_log_subscription/3","title":"AWS.Directory.delete_log_subscription/3","type":"function","doc":"Deletes the specified log subscription."},{"ref":"AWS.Directory.html#delete_snapshot/3","title":"AWS.Directory.delete_snapshot/3","type":"function","doc":"Deletes a directory snapshot."},{"ref":"AWS.Directory.html#delete_trust/3","title":"AWS.Directory.delete_trust/3","type":"function","doc":"Deletes an existing trust relationship between your AWS Managed Microsoft AD directory and an external domain."},{"ref":"AWS.Directory.html#deregister_certificate/3","title":"AWS.Directory.deregister_certificate/3","type":"function","doc":"Deletes from the system the certificate that was registered for a secured LDAP connection."},{"ref":"AWS.Directory.html#deregister_event_topic/3","title":"AWS.Directory.deregister_event_topic/3","type":"function","doc":"Removes the specified directory as a publisher to the specified SNS topic."},{"ref":"AWS.Directory.html#describe_certificate/3","title":"AWS.Directory.describe_certificate/3","type":"function","doc":"Displays information about the certificate registered for a secured LDAP connection."},{"ref":"AWS.Directory.html#describe_conditional_forwarders/3","title":"AWS.Directory.describe_conditional_forwarders/3","type":"function","doc":"Obtains information about the conditional forwarders for this account. If no input parameters are provided for RemoteDomainNames, this request describes all conditional forwarders for the specified directory ID."},{"ref":"AWS.Directory.html#describe_directories/3","title":"AWS.Directory.describe_directories/3","type":"function","doc":"Obtains information about the directories that belong to this account. You can retrieve information about specific directories by passing the directory identifiers in the DirectoryIds parameter. Otherwise, all directories that belong to the current account are returned. This operation supports pagination with the use of the NextToken request and response parameters. If more results are available, the DescribeDirectoriesResult.NextToken member contains a token that you pass in the next call to DescribeDirectories to retrieve the next set of items. You can also specify a maximum number of return results with the Limit parameter."},{"ref":"AWS.Directory.html#describe_domain_controllers/3","title":"AWS.Directory.describe_domain_controllers/3","type":"function","doc":"Provides information about any domain controllers in your directory."},{"ref":"AWS.Directory.html#describe_event_topics/3","title":"AWS.Directory.describe_event_topics/3","type":"function","doc":"Obtains information about which SNS topics receive status messages from the specified directory. If no input parameters are provided, such as DirectoryId or TopicName, this request describes all of the associations in the account."},{"ref":"AWS.Directory.html#describe_l_d_a_p_s_settings/3","title":"AWS.Directory.describe_l_d_a_p_s_settings/3","type":"function","doc":"Describes the status of LDAP security for the specified directory."},{"ref":"AWS.Directory.html#describe_shared_directories/3","title":"AWS.Directory.describe_shared_directories/3","type":"function","doc":"Returns the shared directories in your account."},{"ref":"AWS.Directory.html#describe_snapshots/3","title":"AWS.Directory.describe_snapshots/3","type":"function","doc":"Obtains information about the directory snapshots that belong to this account. This operation supports pagination with the use of the NextToken request and response parameters. If more results are available, the DescribeSnapshots.NextToken member contains a token that you pass in the next call to DescribeSnapshots to retrieve the next set of items. You can also specify a maximum number of return results with the Limit parameter."},{"ref":"AWS.Directory.html#describe_trusts/3","title":"AWS.Directory.describe_trusts/3","type":"function","doc":"Obtains information about the trust relationships for this account. If no input parameters are provided, such as DirectoryId or TrustIds, this request describes all the trust relationships belonging to the account."},{"ref":"AWS.Directory.html#disable_l_d_a_p_s/3","title":"AWS.Directory.disable_l_d_a_p_s/3","type":"function","doc":"Deactivates LDAP secure calls for the specified directory."},{"ref":"AWS.Directory.html#disable_radius/3","title":"AWS.Directory.disable_radius/3","type":"function","doc":"Disables multi-factor authentication (MFA) with the Remote Authentication Dial In User Service (RADIUS) server for an AD Connector or Microsoft AD directory."},{"ref":"AWS.Directory.html#disable_sso/3","title":"AWS.Directory.disable_sso/3","type":"function","doc":"Disables single-sign on for a directory."},{"ref":"AWS.Directory.html#enable_l_d_a_p_s/3","title":"AWS.Directory.enable_l_d_a_p_s/3","type":"function","doc":"Activates the switch for the specific directory to always use LDAP secure calls."},{"ref":"AWS.Directory.html#enable_radius/3","title":"AWS.Directory.enable_radius/3","type":"function","doc":"Enables multi-factor authentication (MFA) with the Remote Authentication Dial In User Service (RADIUS) server for an AD Connector or Microsoft AD directory."},{"ref":"AWS.Directory.html#enable_sso/3","title":"AWS.Directory.enable_sso/3","type":"function","doc":"Enables single sign-on for a directory. Single sign-on allows users in your directory to access certain AWS services from a computer joined to the directory without having to enter their credentials separately."},{"ref":"AWS.Directory.html#get_directory_limits/3","title":"AWS.Directory.get_directory_limits/3","type":"function","doc":"Obtains directory limit information for the current Region."},{"ref":"AWS.Directory.html#get_snapshot_limits/3","title":"AWS.Directory.get_snapshot_limits/3","type":"function","doc":"Obtains the manual snapshot limits for a directory."},{"ref":"AWS.Directory.html#list_certificates/3","title":"AWS.Directory.list_certificates/3","type":"function","doc":"For the specified directory, lists all the certificates registered for a secured LDAP connection."},{"ref":"AWS.Directory.html#list_ip_routes/3","title":"AWS.Directory.list_ip_routes/3","type":"function","doc":"Lists the address blocks that you have added to a directory."},{"ref":"AWS.Directory.html#list_log_subscriptions/3","title":"AWS.Directory.list_log_subscriptions/3","type":"function","doc":"Lists the active log subscriptions for the AWS account."},{"ref":"AWS.Directory.html#list_schema_extensions/3","title":"AWS.Directory.list_schema_extensions/3","type":"function","doc":"Lists all schema extensions applied to a Microsoft AD Directory."},{"ref":"AWS.Directory.html#list_tags_for_resource/3","title":"AWS.Directory.list_tags_for_resource/3","type":"function","doc":"Lists all tags on a directory."},{"ref":"AWS.Directory.html#register_certificate/3","title":"AWS.Directory.register_certificate/3","type":"function","doc":"Registers a certificate for secured LDAP connection."},{"ref":"AWS.Directory.html#register_event_topic/3","title":"AWS.Directory.register_event_topic/3","type":"function","doc":"Associates a directory with an SNS topic. This establishes the directory as a publisher to the specified SNS topic. You can then receive email or text (SMS) messages when the status of your directory changes. You get notified if your directory goes from an Active status to an Impaired or Inoperable status. You also receive a notification when the directory returns to an Active status."},{"ref":"AWS.Directory.html#reject_shared_directory/3","title":"AWS.Directory.reject_shared_directory/3","type":"function","doc":"Rejects a directory sharing request that was sent from the directory owner account."},{"ref":"AWS.Directory.html#remove_ip_routes/3","title":"AWS.Directory.remove_ip_routes/3","type":"function","doc":"Removes IP address blocks from a directory."},{"ref":"AWS.Directory.html#remove_tags_from_resource/3","title":"AWS.Directory.remove_tags_from_resource/3","type":"function","doc":"Removes tags from a directory."},{"ref":"AWS.Directory.html#reset_user_password/3","title":"AWS.Directory.reset_user_password/3","type":"function","doc":"Resets the password for any user in your AWS Managed Microsoft AD or Simple AD directory. You can reset the password for any user in your directory with the following exceptions: For Simple AD, you cannot reset the password for any user that is a member of either the Domain Admins or Enterprise Admins group except for the administrator user. For AWS Managed Microsoft AD, you can only reset the password for a user that is in an OU based off of the NetBIOS name that you typed when you created your directory. For example, you cannot reset the password for a user in the AWS Reserved OU. For more information about the OU structure for an AWS Managed Microsoft AD directory, see What Gets Created in the AWS Directory Service Administration Guide."},{"ref":"AWS.Directory.html#restore_from_snapshot/3","title":"AWS.Directory.restore_from_snapshot/3","type":"function","doc":"Restores a directory using an existing directory snapshot. When you restore a directory from a snapshot, any changes made to the directory after the snapshot date are overwritten. This action returns as soon as the restore operation is initiated. You can monitor the progress of the restore operation by calling the DescribeDirectories operation with the directory identifier. When the DirectoryDescription.Stage value changes to Active, the restore operation is complete."},{"ref":"AWS.Directory.html#share_directory/3","title":"AWS.Directory.share_directory/3","type":"function","doc":"Shares a specified directory (DirectoryId) in your AWS account (directory owner) with another AWS account (directory consumer). With this operation you can use your directory from any AWS account and from any Amazon VPC within an AWS Region. When you share your AWS Managed Microsoft AD directory, AWS Directory Service creates a shared directory in the directory consumer account. This shared directory contains the metadata to provide access to the directory within the directory owner account. The shared directory is visible in all VPCs in the directory consumer account. The ShareMethod parameter determines whether the specified directory can be shared between AWS accounts inside the same AWS organization (ORGANIZATIONS). It also determines whether you can share the directory with any other AWS account either inside or outside of the organization (HANDSHAKE). The ShareNotes parameter is only used when HANDSHAKE is called, which sends a directory sharing request to the directory consumer."},{"ref":"AWS.Directory.html#start_schema_extension/3","title":"AWS.Directory.start_schema_extension/3","type":"function","doc":"Applies a schema extension to a Microsoft AD directory."},{"ref":"AWS.Directory.html#unshare_directory/3","title":"AWS.Directory.unshare_directory/3","type":"function","doc":"Stops the directory sharing between the directory owner and consumer accounts."},{"ref":"AWS.Directory.html#update_conditional_forwarder/3","title":"AWS.Directory.update_conditional_forwarder/3","type":"function","doc":"Updates a conditional forwarder that has been set up for your AWS directory."},{"ref":"AWS.Directory.html#update_number_of_domain_controllers/3","title":"AWS.Directory.update_number_of_domain_controllers/3","type":"function","doc":"Adds or removes domain controllers to or from the directory. Based on the difference between current value and new value (provided through this API call), domain controllers will be added or removed. It may take up to 45 minutes for any new domain controllers to become fully active once the requested number of domain controllers is updated. During this time, you cannot make another update request."},{"ref":"AWS.Directory.html#update_radius/3","title":"AWS.Directory.update_radius/3","type":"function","doc":"Updates the Remote Authentication Dial In User Service (RADIUS) server information for an AD Connector or Microsoft AD directory."},{"ref":"AWS.Directory.html#update_trust/3","title":"AWS.Directory.update_trust/3","type":"function","doc":"Updates the trust that has been set up between your AWS Managed Microsoft AD directory and an on-premises Active Directory."},{"ref":"AWS.Directory.html#verify_trust/3","title":"AWS.Directory.verify_trust/3","type":"function","doc":"AWS Directory Service for Microsoft Active Directory allows you to configure and verify trust relationships. This action verifies a trust relationship between your AWS Managed Microsoft AD directory and an external domain."},{"ref":"AWS.DocDB.html","title":"AWS.DocDB","type":"module","doc":"Amazon DocumentDB API documentation"},{"ref":"AWS.DocDB.html#add_tags_to_resource/3","title":"AWS.DocDB.add_tags_to_resource/3","type":"function","doc":"Adds metadata tags to an Amazon DocumentDB resource. You can use these tags with cost allocation reporting to track costs that are associated with Amazon DocumentDB resources. or in a Condition statement in an AWS Identity and Access Management (IAM) policy for Amazon DocumentDB."},{"ref":"AWS.DocDB.html#apply_pending_maintenance_action/3","title":"AWS.DocDB.apply_pending_maintenance_action/3","type":"function","doc":"Applies a pending maintenance action to a resource (for example, to an Amazon DocumentDB instance)."},{"ref":"AWS.DocDB.html#copy_d_b_cluster_parameter_group/3","title":"AWS.DocDB.copy_d_b_cluster_parameter_group/3","type":"function","doc":"Copies the specified cluster parameter group."},{"ref":"AWS.DocDB.html#copy_d_b_cluster_snapshot/3","title":"AWS.DocDB.copy_d_b_cluster_snapshot/3","type":"function","doc":"Copies a snapshot of a cluster. To copy a cluster snapshot from a shared manual cluster snapshot, SourceDBClusterSnapshotIdentifier must be the Amazon Resource Name (ARN) of the shared cluster snapshot. You can only copy a shared DB cluster snapshot, whether encrypted or not, in the same AWS Region. To cancel the copy operation after it is in progress, delete the target cluster snapshot identified by TargetDBClusterSnapshotIdentifier while that cluster snapshot is in the copying status."},{"ref":"AWS.DocDB.html#create_d_b_cluster/3","title":"AWS.DocDB.create_d_b_cluster/3","type":"function","doc":"Creates a new Amazon DocumentDB cluster."},{"ref":"AWS.DocDB.html#create_d_b_cluster_parameter_group/3","title":"AWS.DocDB.create_d_b_cluster_parameter_group/3","type":"function","doc":"Creates a new cluster parameter group. Parameters in a cluster parameter group apply to all of the instances in a cluster. A cluster parameter group is initially created with the default parameters for the database engine used by instances in the cluster. In Amazon DocumentDB, you cannot make modifications directly to the default.docdb3.6 cluster parameter group. If your Amazon DocumentDB cluster is using the default cluster parameter group and you want to modify a value in it, you must first create a new parameter group or copy an existing parameter group, modify it, and then apply the modified parameter group to your cluster. For the new cluster parameter group and associated settings to take effect, you must then reboot the instances in the cluster without failover. For more information, see Modifying Amazon DocumentDB Cluster Parameter Groups."},{"ref":"AWS.DocDB.html#create_d_b_cluster_snapshot/3","title":"AWS.DocDB.create_d_b_cluster_snapshot/3","type":"function","doc":"Creates a snapshot of a cluster."},{"ref":"AWS.DocDB.html#create_d_b_instance/3","title":"AWS.DocDB.create_d_b_instance/3","type":"function","doc":"Creates a new instance."},{"ref":"AWS.DocDB.html#create_d_b_subnet_group/3","title":"AWS.DocDB.create_d_b_subnet_group/3","type":"function","doc":"Creates a new subnet group. subnet groups must contain at least one subnet in at least two Availability Zones in the AWS Region."},{"ref":"AWS.DocDB.html#delete_d_b_cluster/3","title":"AWS.DocDB.delete_d_b_cluster/3","type":"function","doc":"Deletes a previously provisioned cluster. When you delete a cluster, all automated backups for that cluster are deleted and can&#39;t be recovered. Manual DB cluster snapshots of the specified cluster are not deleted."},{"ref":"AWS.DocDB.html#delete_d_b_cluster_parameter_group/3","title":"AWS.DocDB.delete_d_b_cluster_parameter_group/3","type":"function","doc":"Deletes a specified cluster parameter group. The cluster parameter group to be deleted can&#39;t be associated with any clusters."},{"ref":"AWS.DocDB.html#delete_d_b_cluster_snapshot/3","title":"AWS.DocDB.delete_d_b_cluster_snapshot/3","type":"function","doc":"Deletes a cluster snapshot. If the snapshot is being copied, the copy operation is terminated. The cluster snapshot must be in the available state to be deleted."},{"ref":"AWS.DocDB.html#delete_d_b_instance/3","title":"AWS.DocDB.delete_d_b_instance/3","type":"function","doc":"Deletes a previously provisioned instance."},{"ref":"AWS.DocDB.html#delete_d_b_subnet_group/3","title":"AWS.DocDB.delete_d_b_subnet_group/3","type":"function","doc":"Deletes a subnet group. The specified database subnet group must not be associated with any DB instances."},{"ref":"AWS.DocDB.html#describe_certificates/3","title":"AWS.DocDB.describe_certificates/3","type":"function","doc":"Returns a list of certificate authority (CA) certificates provided by Amazon DocumentDB for this AWS account."},{"ref":"AWS.DocDB.html#describe_d_b_cluster_parameter_groups/3","title":"AWS.DocDB.describe_d_b_cluster_parameter_groups/3","type":"function","doc":"Returns a list of DBClusterParameterGroup descriptions. If a DBClusterParameterGroupName parameter is specified, the list contains only the description of the specified cluster parameter group."},{"ref":"AWS.DocDB.html#describe_d_b_cluster_parameters/3","title":"AWS.DocDB.describe_d_b_cluster_parameters/3","type":"function","doc":"Returns the detailed parameter list for a particular cluster parameter group."},{"ref":"AWS.DocDB.html#describe_d_b_cluster_snapshot_attributes/3","title":"AWS.DocDB.describe_d_b_cluster_snapshot_attributes/3","type":"function","doc":"Returns a list of cluster snapshot attribute names and values for a manual DB cluster snapshot. When you share snapshots with other AWS accounts, DescribeDBClusterSnapshotAttributes returns the restore attribute and a list of IDs for the AWS accounts that are authorized to copy or restore the manual cluster snapshot. If all is included in the list of values for the restore attribute, then the manual cluster snapshot is public and can be copied or restored by all AWS accounts."},{"ref":"AWS.DocDB.html#describe_d_b_cluster_snapshots/3","title":"AWS.DocDB.describe_d_b_cluster_snapshots/3","type":"function","doc":"Returns information about cluster snapshots. This API operation supports pagination."},{"ref":"AWS.DocDB.html#describe_d_b_clusters/3","title":"AWS.DocDB.describe_d_b_clusters/3","type":"function","doc":"Returns information about provisioned Amazon DocumentDB clusters. This API operation supports pagination. For certain management features such as cluster and instance lifecycle management, Amazon DocumentDB leverages operational technology that is shared with Amazon RDS and Amazon Neptune. Use the filterName=engine,Values=docdb filter parameter to return only Amazon DocumentDB clusters."},{"ref":"AWS.DocDB.html#describe_d_b_engine_versions/3","title":"AWS.DocDB.describe_d_b_engine_versions/3","type":"function","doc":"Returns a list of the available engines."},{"ref":"AWS.DocDB.html#describe_d_b_instances/3","title":"AWS.DocDB.describe_d_b_instances/3","type":"function","doc":"Returns information about provisioned Amazon DocumentDB instances. This API supports pagination."},{"ref":"AWS.DocDB.html#describe_d_b_subnet_groups/3","title":"AWS.DocDB.describe_d_b_subnet_groups/3","type":"function","doc":"Returns a list of DBSubnetGroup descriptions. If a DBSubnetGroupName is specified, the list will contain only the descriptions of the specified DBSubnetGroup."},{"ref":"AWS.DocDB.html#describe_engine_default_cluster_parameters/3","title":"AWS.DocDB.describe_engine_default_cluster_parameters/3","type":"function","doc":"Returns the default engine and system parameter information for the cluster database engine."},{"ref":"AWS.DocDB.html#describe_event_categories/3","title":"AWS.DocDB.describe_event_categories/3","type":"function","doc":"Displays a list of categories for all event source types, or, if specified, for a specified source type."},{"ref":"AWS.DocDB.html#describe_events/3","title":"AWS.DocDB.describe_events/3","type":"function","doc":"Returns events related to instances, security groups, snapshots, and DB parameter groups for the past 14 days. You can obtain events specific to a particular DB instance, security group, snapshot, or parameter group by providing the name as a parameter. By default, the events of the past hour are returned."},{"ref":"AWS.DocDB.html#describe_orderable_d_b_instance_options/3","title":"AWS.DocDB.describe_orderable_d_b_instance_options/3","type":"function","doc":"Returns a list of orderable instance options for the specified engine."},{"ref":"AWS.DocDB.html#describe_pending_maintenance_actions/3","title":"AWS.DocDB.describe_pending_maintenance_actions/3","type":"function","doc":"Returns a list of resources (for example, instances) that have at least one pending maintenance action."},{"ref":"AWS.DocDB.html#failover_d_b_cluster/3","title":"AWS.DocDB.failover_d_b_cluster/3","type":"function","doc":"Forces a failover for a cluster. A failover for a cluster promotes one of the Amazon DocumentDB replicas (read-only instances) in the cluster to be the primary instance (the cluster writer). If the primary instance fails, Amazon DocumentDB automatically fails over to an Amazon DocumentDB replica, if one exists. You can force a failover when you want to simulate a failure of a primary instance for testing."},{"ref":"AWS.DocDB.html#list_tags_for_resource/3","title":"AWS.DocDB.list_tags_for_resource/3","type":"function","doc":"Lists all tags on an Amazon DocumentDB resource."},{"ref":"AWS.DocDB.html#modify_d_b_cluster/3","title":"AWS.DocDB.modify_d_b_cluster/3","type":"function","doc":"Modifies a setting for an Amazon DocumentDB cluster. You can change one or more database configuration parameters by specifying these parameters and the new values in the request."},{"ref":"AWS.DocDB.html#modify_d_b_cluster_parameter_group/3","title":"AWS.DocDB.modify_d_b_cluster_parameter_group/3","type":"function","doc":"Modifies the parameters of a cluster parameter group. To modify more than one parameter, submit a list of the following: ParameterName, ParameterValue, and ApplyMethod. A maximum of 20 parameters can be modified in a single request. Changes to dynamic parameters are applied immediately. Changes to static parameters require a reboot or maintenance window before the change can take effect. After you create a cluster parameter group, you should wait at least 5 minutes before creating your first cluster that uses that cluster parameter group as the default parameter group. This allows Amazon DocumentDB to fully complete the create action before the parameter group is used as the default for a new cluster. This step is especially important for parameters that are critical when creating the default database for a cluster, such as the character set for the default database defined by the character_set_database parameter."},{"ref":"AWS.DocDB.html#modify_d_b_cluster_snapshot_attribute/3","title":"AWS.DocDB.modify_d_b_cluster_snapshot_attribute/3","type":"function","doc":"Adds an attribute and values to, or removes an attribute and values from, a manual DB cluster snapshot. To share a manual cluster snapshot with other AWS accounts, specify restore as the AttributeName, and use the ValuesToAdd parameter to add a list of IDs of the AWS accounts that are authorized to restore the manual cluster snapshot. Use the value all to make the manual cluster snapshot public, which means that it can be copied or restored by all AWS accounts. Do not add the all value for any manual DB cluster snapshots that contain private information that you don&#39;t want available to all AWS accounts. If a manual cluster snapshot is encrypted, it can be shared, but only by specifying a list of authorized AWS account IDs for the ValuesToAdd parameter. You can&#39;t use all as a value for that parameter in this case."},{"ref":"AWS.DocDB.html#modify_d_b_instance/3","title":"AWS.DocDB.modify_d_b_instance/3","type":"function","doc":"Modifies settings for an instance. You can change one or more database configuration parameters by specifying these parameters and the new values in the request."},{"ref":"AWS.DocDB.html#modify_d_b_subnet_group/3","title":"AWS.DocDB.modify_d_b_subnet_group/3","type":"function","doc":"Modifies an existing subnet group. subnet groups must contain at least one subnet in at least two Availability Zones in the AWS Region."},{"ref":"AWS.DocDB.html#reboot_d_b_instance/3","title":"AWS.DocDB.reboot_d_b_instance/3","type":"function","doc":"You might need to reboot your instance, usually for maintenance reasons. For example, if you make certain changes, or if you change the cluster parameter group that is associated with the instance, you must reboot the instance for the changes to take effect. Rebooting an instance restarts the database engine service. Rebooting an instance results in a momentary outage, during which the instance status is set to rebooting."},{"ref":"AWS.DocDB.html#remove_tags_from_resource/3","title":"AWS.DocDB.remove_tags_from_resource/3","type":"function","doc":"Removes metadata tags from an Amazon DocumentDB resource."},{"ref":"AWS.DocDB.html#reset_d_b_cluster_parameter_group/3","title":"AWS.DocDB.reset_d_b_cluster_parameter_group/3","type":"function","doc":"Modifies the parameters of a cluster parameter group to the default value. To reset specific parameters, submit a list of the following: ParameterName and ApplyMethod. To reset the entire cluster parameter group, specify the DBClusterParameterGroupName and ResetAllParameters parameters. When you reset the entire group, dynamic parameters are updated immediately and static parameters are set to pending-reboot to take effect on the next DB instance reboot."},{"ref":"AWS.DocDB.html#restore_d_b_cluster_from_snapshot/3","title":"AWS.DocDB.restore_d_b_cluster_from_snapshot/3","type":"function","doc":"Creates a new cluster from a snapshot or cluster snapshot. If a snapshot is specified, the target cluster is created from the source DB snapshot with a default configuration and default security group. If a cluster snapshot is specified, the target cluster is created from the source cluster restore point with the same configuration as the original source DB cluster, except that the new cluster is created with the default security group."},{"ref":"AWS.DocDB.html#restore_d_b_cluster_to_point_in_time/3","title":"AWS.DocDB.restore_d_b_cluster_to_point_in_time/3","type":"function","doc":"Restores a cluster to an arbitrary point in time. Users can restore to any point in time before LatestRestorableTime for up to BackupRetentionPeriod days. The target cluster is created from the source cluster with the same configuration as the original cluster, except that the new cluster is created with the default security group."},{"ref":"AWS.DocDB.html#start_d_b_cluster/3","title":"AWS.DocDB.start_d_b_cluster/3","type":"function","doc":"Restarts the stopped cluster that is specified by DBClusterIdentifier. For more information, see Stopping and Starting an Amazon DocumentDB Cluster."},{"ref":"AWS.DocDB.html#stop_d_b_cluster/3","title":"AWS.DocDB.stop_d_b_cluster/3","type":"function","doc":"Stops the running cluster that is specified by DBClusterIdentifier. The cluster must be in the available state. For more information, see Stopping and Starting an Amazon DocumentDB Cluster."},{"ref":"AWS.DynamoDB.html","title":"AWS.DynamoDB","type":"module","doc":"Amazon DynamoDB Amazon DynamoDB is a fully managed NoSQL database service that provides fast and predictable performance with seamless scalability. DynamoDB lets you offload the administrative burdens of operating and scaling a distributed database, so that you don&#39;t have to worry about hardware provisioning, setup and configuration, replication, software patching, or cluster scaling. With DynamoDB, you can create database tables that can store and retrieve any amount of data, and serve any level of request traffic. You can scale up or scale down your tables&#39; throughput capacity without downtime or performance degradation, and use the AWS Management Console to monitor resource utilization and performance metrics. DynamoDB automatically spreads the data and traffic for your tables over a sufficient number of servers to handle your throughput and storage requirements, while maintaining consistent and fast performance. All of your data is stored on solid state disks (SSDs) and automatically replicated across multiple Availability Zones in an AWS region, providing built-in high availability and data durability."},{"ref":"AWS.DynamoDB.html#batch_get_item/3","title":"AWS.DynamoDB.batch_get_item/3","type":"function","doc":"The BatchGetItem operation returns the attributes of one or more items from one or more tables. You identify requested items by primary key. A single operation can retrieve up to 16 MB of data, which can contain as many as 100 items. BatchGetItem returns a partial result if the response size limit is exceeded, the table&#39;s provisioned throughput is exceeded, or an internal processing failure occurs. If a partial result is returned, the operation returns a value for UnprocessedKeys. You can use this value to retry the operation starting with the next item to get. If you request more than 100 items, BatchGetItem returns a ValidationException with the message &quot;Too many items requested for the BatchGetItem call.&quot; For example, if you ask to retrieve 100 items, but each individual item is 300 KB in size, the system returns 52 items (so as not to exceed the 16 MB limit). It also returns an appropriate UnprocessedKeys value so you can get the next page of results. If desired, your application can include its own logic to assemble the pages of results into one dataset. If none of the items can be processed due to insufficient provisioned throughput on all of the tables in the request, then BatchGetItem returns a ProvisionedThroughputExceededException. If at least one of the items is successfully processed, then BatchGetItem completes successfully, while returning the keys of the unread items in UnprocessedKeys. If DynamoDB returns any unprocessed items, you should retry the batch operation on those items. However, we strongly recommend that you use an exponential backoff algorithm. If you retry the batch operation immediately, the underlying read or write requests can still fail due to throttling on the individual tables. If you delay the batch operation using exponential backoff, the individual requests in the batch are much more likely to succeed. For more information, see Batch Operations and Error Handling in the Amazon DynamoDB Developer Guide. By default, BatchGetItem performs eventually consistent reads on every table in the request. If you want strongly consistent reads instead, you can set ConsistentRead to true for any or all tables. In order to minimize response latency, BatchGetItem retrieves items in parallel. When designing your application, keep in mind that DynamoDB does not return items in any particular order. To help parse the response by item, include the primary key values for the items in your request in the ProjectionExpression parameter. If a requested item does not exist, it is not returned in the result. Requests for nonexistent items consume the minimum read capacity units according to the type of read. For more information, see Working with Tables in the Amazon DynamoDB Developer Guide."},{"ref":"AWS.DynamoDB.html#batch_write_item/3","title":"AWS.DynamoDB.batch_write_item/3","type":"function","doc":"The BatchWriteItem operation puts or deletes multiple items in one or more tables. A single call to BatchWriteItem can write up to 16 MB of data, which can comprise as many as 25 put or delete requests. Individual items to be written can be as large as 400 KB. BatchWriteItem cannot update items. To update items, use the UpdateItem action. The individual PutItem and DeleteItem operations specified in BatchWriteItem are atomic; however BatchWriteItem as a whole is not. If any requested operations fail because the table&#39;s provisioned throughput is exceeded or an internal processing failure occurs, the failed operations are returned in the UnprocessedItems response parameter. You can investigate and optionally resend the requests. Typically, you would call BatchWriteItem in a loop. Each iteration would check for unprocessed items and submit a new BatchWriteItem request with those unprocessed items until all items have been processed. If none of the items can be processed due to insufficient provisioned throughput on all of the tables in the request, then BatchWriteItem returns a ProvisionedThroughputExceededException. If DynamoDB returns any unprocessed items, you should retry the batch operation on those items. However, we strongly recommend that you use an exponential backoff algorithm. If you retry the batch operation immediately, the underlying read or write requests can still fail due to throttling on the individual tables. If you delay the batch operation using exponential backoff, the individual requests in the batch are much more likely to succeed. For more information, see Batch Operations and Error Handling in the Amazon DynamoDB Developer Guide. With BatchWriteItem, you can efficiently write or delete large amounts of data, such as from Amazon EMR, or copy data from another database into DynamoDB. In order to improve performance with these large-scale operations, BatchWriteItem does not behave in the same way as individual PutItem and DeleteItem calls would. For example, you cannot specify conditions on individual put and delete requests, and BatchWriteItem does not return deleted items in the response. If you use a programming language that supports concurrency, you can use threads to write items in parallel. Your application must include the necessary logic to manage the threads. With languages that don&#39;t support threading, you must update or delete the specified items one at a time. In both situations, BatchWriteItem performs the specified put and delete operations in parallel, giving you the power of the thread pool approach without having to introduce complexity into your application. Parallel processing reduces latency, but each specified put and delete request consumes the same number of write capacity units whether it is processed in parallel or not. Delete operations on nonexistent items consume one write capacity unit. If one or more of the following is true, DynamoDB rejects the entire batch write operation: One or more tables specified in the BatchWriteItem request does not exist. Primary key attributes specified on an item in the request do not match those in the corresponding table&#39;s primary key schema. You try to perform multiple operations on the same item in the same BatchWriteItem request. For example, you cannot put and delete the same item in the same BatchWriteItem request. Your request contains at least two items with identical hash and range keys (which essentially is two put operations). There are more than 25 requests in the batch. Any individual item in a batch exceeds 400 KB. The total request size exceeds 16 MB."},{"ref":"AWS.DynamoDB.html#create_backup/3","title":"AWS.DynamoDB.create_backup/3","type":"function","doc":"Creates a backup for an existing table. Each time you create an on-demand backup, the entire table data is backed up. There is no limit to the number of on-demand backups that can be taken. When you create an on-demand backup, a time marker of the request is cataloged, and the backup is created asynchronously, by applying all changes until the time of the request to the last full table snapshot. Backup requests are processed instantaneously and become available for restore within minutes. You can call CreateBackup at a maximum rate of 50 times per second. All backups in DynamoDB work without consuming any provisioned throughput on the table. If you submit a backup request on 2018-12-14 at 14:25:00, the backup is guaranteed to contain all data committed to the table up to 14:24:00, and data committed after 14:26:00 will not be. The backup might contain data modifications made between 14:24:00 and 14:26:00. On-demand backup does not support causal consistency. Along with data, the following are also included on the backups: Global secondary indexes (GSIs) Local secondary indexes (LSIs) Streams Provisioned read and write capacity"},{"ref":"AWS.DynamoDB.html#create_global_table/3","title":"AWS.DynamoDB.create_global_table/3","type":"function","doc":"Creates a global table from an existing table. A global table creates a replication relationship between two or more DynamoDB tables with the same table name in the provided Regions. This operation only applies to Version 2017.11.29 of global tables. If you want to add a new replica table to a global table, each of the following conditions must be true: The table must have the same primary key as all of the other replicas. The table must have the same name as all of the other replicas. The table must have DynamoDB Streams enabled, with the stream containing both the new and the old images of the item. None of the replica tables in the global table can contain any data. If global secondary indexes are specified, then the following conditions must also be met: The global secondary indexes must have the same name. The global secondary indexes must have the same hash key and sort key (if present). If local secondary indexes are specified, then the following conditions must also be met: The local secondary indexes must have the same name. The local secondary indexes must have the same hash key and sort key (if present). Write capacity settings should be set consistently across your replica tables and secondary indexes. DynamoDB strongly recommends enabling auto scaling to manage the write capacity settings for all of your global tables replicas and indexes. If you prefer to manage write capacity settings manually, you should provision equal replicated write capacity units to your replica tables. You should also provision equal replicated write capacity units to matching secondary indexes across your global table."},{"ref":"AWS.DynamoDB.html#create_table/3","title":"AWS.DynamoDB.create_table/3","type":"function","doc":"The CreateTable operation adds a new table to your account. In an AWS account, table names must be unique within each Region. That is, you can have two tables with same name if you create the tables in different Regions. CreateTable is an asynchronous operation. Upon receiving a CreateTable request, DynamoDB immediately returns a response with a TableStatus of CREATING. After the table is created, DynamoDB sets the TableStatus to ACTIVE. You can perform read and write operations only on an ACTIVE table. You can optionally define secondary indexes on the new table, as part of the CreateTable operation. If you want to create multiple tables with secondary indexes on them, you must create the tables sequentially. Only one table with secondary indexes can be in the CREATING state at any given time. You can use the DescribeTable action to check the table status."},{"ref":"AWS.DynamoDB.html#delete_backup/3","title":"AWS.DynamoDB.delete_backup/3","type":"function","doc":"Deletes an existing backup of a table. You can call DeleteBackup at a maximum rate of 10 times per second."},{"ref":"AWS.DynamoDB.html#delete_item/3","title":"AWS.DynamoDB.delete_item/3","type":"function","doc":"Deletes a single item in a table by primary key. You can perform a conditional delete operation that deletes the item if it exists, or if it has an expected attribute value. In addition to deleting an item, you can also return the item&#39;s attribute values in the same operation, using the ReturnValues parameter. Unless you specify conditions, the DeleteItem is an idempotent operation; running it multiple times on the same item or attribute does not result in an error response. Conditional deletes are useful for deleting items only if specific conditions are met. If those conditions are met, DynamoDB performs the delete. Otherwise, the item is not deleted."},{"ref":"AWS.DynamoDB.html#delete_table/3","title":"AWS.DynamoDB.delete_table/3","type":"function","doc":"The DeleteTable operation deletes a table and all of its items. After a DeleteTable request, the specified table is in the DELETING state until DynamoDB completes the deletion. If the table is in the ACTIVE state, you can delete it. If a table is in CREATING or UPDATING states, then DynamoDB returns a ResourceInUseException. If the specified table does not exist, DynamoDB returns a ResourceNotFoundException. If table is already in the DELETING state, no error is returned. DynamoDB might continue to accept data read and write operations, such as GetItem and PutItem, on a table in the DELETING state until the table deletion is complete. When you delete a table, any indexes on that table are also deleted. If you have DynamoDB Streams enabled on the table, then the corresponding stream on that table goes into the DISABLED state, and the stream is automatically deleted after 24 hours. Use the DescribeTable action to check the status of the table."},{"ref":"AWS.DynamoDB.html#describe_backup/3","title":"AWS.DynamoDB.describe_backup/3","type":"function","doc":"Describes an existing backup of a table. You can call DescribeBackup at a maximum rate of 10 times per second."},{"ref":"AWS.DynamoDB.html#describe_continuous_backups/3","title":"AWS.DynamoDB.describe_continuous_backups/3","type":"function","doc":"Checks the status of continuous backups and point in time recovery on the specified table. Continuous backups are ENABLED on all tables at table creation. If point in time recovery is enabled, PointInTimeRecoveryStatus will be set to ENABLED. After continuous backups and point in time recovery are enabled, you can restore to any point in time within EarliestRestorableDateTime and LatestRestorableDateTime. LatestRestorableDateTime is typically 5 minutes before the current time. You can restore your table to any point in time during the last 35 days. You can call DescribeContinuousBackups at a maximum rate of 10 times per second."},{"ref":"AWS.DynamoDB.html#describe_contributor_insights/3","title":"AWS.DynamoDB.describe_contributor_insights/3","type":"function","doc":"Returns information about contributor insights, for a given table or global secondary index."},{"ref":"AWS.DynamoDB.html#describe_endpoints/3","title":"AWS.DynamoDB.describe_endpoints/3","type":"function","doc":"Returns the regional endpoint information."},{"ref":"AWS.DynamoDB.html#describe_global_table/3","title":"AWS.DynamoDB.describe_global_table/3","type":"function","doc":"Returns information about the specified global table. This operation only applies to Version 2017.11.29 of global tables. If you are using global tables Version 2019.11.21 you can use DescribeTable instead."},{"ref":"AWS.DynamoDB.html#describe_global_table_settings/3","title":"AWS.DynamoDB.describe_global_table_settings/3","type":"function","doc":"Describes Region-specific settings for a global table. This operation only applies to Version 2017.11.29 of global tables."},{"ref":"AWS.DynamoDB.html#describe_limits/3","title":"AWS.DynamoDB.describe_limits/3","type":"function","doc":"Returns the current provisioned-capacity quotas for your AWS account in a Region, both for the Region as a whole and for any one DynamoDB table that you create there. When you establish an AWS account, the account has initial quotas on the maximum read capacity units and write capacity units that you can provision across all of your DynamoDB tables in a given Region. Also, there are per-table quotas that apply when you create a table there. For more information, see Service, Account, and Table Quotas page in the Amazon DynamoDB Developer Guide. Although you can increase these quotas by filing a case at AWS Support Center, obtaining the increase is not instantaneous. The DescribeLimits action lets you write code to compare the capacity you are currently using to those quotas imposed by your account so that you have enough time to apply for an increase before you hit a quota. For example, you could use one of the AWS SDKs to do the following: Call DescribeLimits for a particular Region to obtain your current account quotas on provisioned capacity there. Create a variable to hold the aggregate read capacity units provisioned for all your tables in that Region, and one to hold the aggregate write capacity units. Zero them both. Call ListTables to obtain a list of all your DynamoDB tables. For each table name listed by ListTables, do the following: Call DescribeTable with the table name. Use the data returned by DescribeTable to add the read capacity units and write capacity units provisioned for the table itself to your variables. If the table has one or more global secondary indexes (GSIs), loop over these GSIs and add their provisioned capacity values to your variables as well. Report the account quotas for that Region returned by DescribeLimits, along with the total current provisioned capacity levels you have calculated. This will let you see whether you are getting close to your account-level quotas. The per-table quotas apply only when you are creating a new table. They restrict the sum of the provisioned capacity of the new table itself and all its global secondary indexes. For existing tables and their GSIs, DynamoDB doesn&#39;t let you increase provisioned capacity extremely rapidly, but the only quota that applies is that the aggregate provisioned capacity over all your tables and GSIs cannot exceed either of the per-account quotas. DescribeLimits should only be called periodically. You can expect throttling errors if you call it more than once in a minute. The DescribeLimits Request element has no content."},{"ref":"AWS.DynamoDB.html#describe_table/3","title":"AWS.DynamoDB.describe_table/3","type":"function","doc":"Returns information about the table, including the current status of the table, when it was created, the primary key schema, and any indexes on the table. If you issue a DescribeTable request immediately after a CreateTable request, DynamoDB might return a ResourceNotFoundException. This is because DescribeTable uses an eventually consistent query, and the metadata for your table might not be available at that moment. Wait for a few seconds, and then try the DescribeTable request again."},{"ref":"AWS.DynamoDB.html#describe_table_replica_auto_scaling/3","title":"AWS.DynamoDB.describe_table_replica_auto_scaling/3","type":"function","doc":"Describes auto scaling settings across replicas of the global table at once. This operation only applies to Version 2019.11.21 of global tables."},{"ref":"AWS.DynamoDB.html#describe_time_to_live/3","title":"AWS.DynamoDB.describe_time_to_live/3","type":"function","doc":"Gives a description of the Time to Live (TTL) status on the specified table."},{"ref":"AWS.DynamoDB.html#get_item/3","title":"AWS.DynamoDB.get_item/3","type":"function","doc":"The GetItem operation returns a set of attributes for the item with the given primary key. If there is no matching item, GetItem does not return any data and there will be no Item element in the response. GetItem provides an eventually consistent read by default. If your application requires a strongly consistent read, set ConsistentRead to true. Although a strongly consistent read might take more time than an eventually consistent read, it always returns the last updated value."},{"ref":"AWS.DynamoDB.html#list_backups/3","title":"AWS.DynamoDB.list_backups/3","type":"function","doc":"List backups associated with an AWS account. To list backups for a given table, specify TableName. ListBackups returns a paginated list of results with at most 1 MB worth of items in a page. You can also specify a maximum number of entries to be returned in a page. In the request, start time is inclusive, but end time is exclusive. Note that these boundaries are for the time at which the original backup was requested. You can call ListBackups a maximum of five times per second."},{"ref":"AWS.DynamoDB.html#list_contributor_insights/3","title":"AWS.DynamoDB.list_contributor_insights/3","type":"function","doc":"Returns a list of ContributorInsightsSummary for a table and all its global secondary indexes."},{"ref":"AWS.DynamoDB.html#list_global_tables/3","title":"AWS.DynamoDB.list_global_tables/3","type":"function","doc":"Lists all global tables that have a replica in the specified Region. This operation only applies to Version 2017.11.29 of global tables."},{"ref":"AWS.DynamoDB.html#list_tables/3","title":"AWS.DynamoDB.list_tables/3","type":"function","doc":"Returns an array of table names associated with the current account and endpoint. The output from ListTables is paginated, with each page returning a maximum of 100 table names."},{"ref":"AWS.DynamoDB.html#list_tags_of_resource/3","title":"AWS.DynamoDB.list_tags_of_resource/3","type":"function","doc":"List all tags on an Amazon DynamoDB resource. You can call ListTagsOfResource up to 10 times per second, per account. For an overview on tagging DynamoDB resources, see Tagging for DynamoDB in the Amazon DynamoDB Developer Guide."},{"ref":"AWS.DynamoDB.html#put_item/3","title":"AWS.DynamoDB.put_item/3","type":"function","doc":"Creates a new item, or replaces an old item with a new item. If an item that has the same primary key as the new item already exists in the specified table, the new item completely replaces the existing item. You can perform a conditional put operation (add a new item if one with the specified primary key doesn&#39;t exist), or replace an existing item if it has certain attribute values. You can return the item&#39;s attribute values in the same operation, using the ReturnValues parameter. This topic provides general information about the PutItem API. For information on how to call the PutItem API using the AWS SDK in specific languages, see the following: PutItem in the AWS Command Line Interface PutItem in the AWS SDK for .NET PutItem in the AWS SDK for C++ PutItem in the AWS SDK for Go PutItem in the AWS SDK for Java PutItem in the AWS SDK for JavaScript PutItem in the AWS SDK for PHP V3 PutItem in the AWS SDK for Python PutItem in the AWS SDK for Ruby V2 When you add an item, the primary key attributes are the only required attributes. Attribute values cannot be null. Empty String and Binary attribute values are allowed. Attribute values of type String and Binary must have a length greater than zero if the attribute is used as a key attribute for a table or index. Set type attributes cannot be empty. Invalid Requests with empty values will be rejected with a ValidationException exception. To prevent a new item from replacing an existing item, use a conditional expression that contains the attribute_not_exists function with the name of the attribute being used as the partition key for the table. Since every record must contain that attribute, the attribute_not_exists function will only succeed if no matching item exists. For more information about PutItem, see Working with Items in the Amazon DynamoDB Developer Guide."},{"ref":"AWS.DynamoDB.html#query/3","title":"AWS.DynamoDB.query/3","type":"function","doc":"The Query operation finds items based on primary key values. You can query any table or secondary index that has a composite primary key (a partition key and a sort key). Use the KeyConditionExpression parameter to provide a specific value for the partition key. The Query operation will return all of the items from the table or index with that partition key value. You can optionally narrow the scope of the Query operation by specifying a sort key value and a comparison operator in KeyConditionExpression. To further refine the Query results, you can optionally provide a FilterExpression. A FilterExpression determines which items within the results should be returned to you. All of the other results are discarded. A Query operation always returns a result set. If no matching items are found, the result set will be empty. Queries that do not return results consume the minimum number of read capacity units for that type of read operation. DynamoDB calculates the number of read capacity units consumed based on item size, not on the amount of data that is returned to an application. The number of capacity units consumed will be the same whether you request all of the attributes (the default behavior) or just some of them (using a projection expression). The number will also be the same whether or not you use a FilterExpression. Query results are always sorted by the sort key value. If the data type of the sort key is Number, the results are returned in numeric order; otherwise, the results are returned in order of UTF-8 bytes. By default, the sort order is ascending. To reverse the order, set the ScanIndexForward parameter to false. A single Query operation will read up to the maximum number of items set (if using the Limit parameter) or a maximum of 1 MB of data and then apply any filtering to the results using FilterExpression. If LastEvaluatedKey is present in the response, you will need to paginate the result set. For more information, see Paginating the Results in the Amazon DynamoDB Developer Guide. FilterExpression is applied after a Query finishes, but before the results are returned. A FilterExpression cannot contain partition key or sort key attributes. You need to specify those attributes in the KeyConditionExpression. A Query operation can return an empty result set and a LastEvaluatedKey if all the items read for the page of results are filtered out. You can query a table, a local secondary index, or a global secondary index. For a query on a table or on a local secondary index, you can set the ConsistentRead parameter to true and obtain a strongly consistent result. Global secondary indexes support eventually consistent reads only, so do not specify ConsistentRead when querying a global secondary index."},{"ref":"AWS.DynamoDB.html#restore_table_from_backup/3","title":"AWS.DynamoDB.restore_table_from_backup/3","type":"function","doc":"Creates a new table from an existing backup. Any number of users can execute up to 4 concurrent restores (any type of restore) in a given account. You can call RestoreTableFromBackup at a maximum rate of 10 times per second. You must manually set up the following on the restored table: Auto scaling policies IAM policies Amazon CloudWatch metrics and alarms Tags Stream settings Time to Live (TTL) settings"},{"ref":"AWS.DynamoDB.html#restore_table_to_point_in_time/3","title":"AWS.DynamoDB.restore_table_to_point_in_time/3","type":"function","doc":"Restores the specified table to the specified point in time within EarliestRestorableDateTime and LatestRestorableDateTime. You can restore your table to any point in time during the last 35 days. Any number of users can execute up to 4 concurrent restores (any type of restore) in a given account. When you restore using point in time recovery, DynamoDB restores your table data to the state based on the selected date and time (day:hour:minute:second) to a new table. Along with data, the following are also included on the new restored table using point in time recovery: Global secondary indexes (GSIs) Local secondary indexes (LSIs) Provisioned read and write capacity Encryption settings All these settings come from the current settings of the source table at the time of restore. You must manually set up the following on the restored table: Auto scaling policies IAM policies Amazon CloudWatch metrics and alarms Tags Stream settings Time to Live (TTL) settings Point in time recovery settings"},{"ref":"AWS.DynamoDB.html#scan/3","title":"AWS.DynamoDB.scan/3","type":"function","doc":"The Scan operation returns one or more items and item attributes by accessing every item in a table or a secondary index. To have DynamoDB return fewer items, you can provide a FilterExpression operation. If the total number of scanned items exceeds the maximum dataset size limit of 1 MB, the scan stops and results are returned to the user as a LastEvaluatedKey value to continue the scan in a subsequent operation. The results also include the number of items exceeding the limit. A scan can result in no table data meeting the filter criteria. A single Scan operation reads up to the maximum number of items set (if using the Limit parameter) or a maximum of 1 MB of data and then apply any filtering to the results using FilterExpression. If LastEvaluatedKey is present in the response, you need to paginate the result set. For more information, see Paginating the Results in the Amazon DynamoDB Developer Guide. Scan operations proceed sequentially; however, for faster performance on a large table or secondary index, applications can request a parallel Scan operation by providing the Segment and TotalSegments parameters. For more information, see Parallel Scan in the Amazon DynamoDB Developer Guide. Scan uses eventually consistent reads when accessing the data in a table; therefore, the result set might not include the changes to data in the table immediately before the operation began. If you need a consistent copy of the data, as of the time that the Scan begins, you can set the ConsistentRead parameter to true."},{"ref":"AWS.DynamoDB.html#tag_resource/3","title":"AWS.DynamoDB.tag_resource/3","type":"function","doc":"Associate a set of tags with an Amazon DynamoDB resource. You can then activate these user-defined tags so that they appear on the Billing and Cost Management console for cost allocation tracking. You can call TagResource up to five times per second, per account. For an overview on tagging DynamoDB resources, see Tagging for DynamoDB in the Amazon DynamoDB Developer Guide."},{"ref":"AWS.DynamoDB.html#transact_get_items/3","title":"AWS.DynamoDB.transact_get_items/3","type":"function","doc":"TransactGetItems is a synchronous operation that atomically retrieves multiple items from one or more tables (but not from indexes) in a single account and Region. A TransactGetItems call can contain up to 25 TransactGetItem objects, each of which contains a Get structure that specifies an item to retrieve from a table in the account and Region. A call to TransactGetItems cannot retrieve items from tables in more than one AWS account or Region. The aggregate size of the items in the transaction cannot exceed 4 MB. DynamoDB rejects the entire TransactGetItems request if any of the following is true: A conflicting operation is in the process of updating an item to be read. There is insufficient provisioned capacity for the transaction to be completed. There is a user error, such as an invalid data format. The aggregate size of the items in the transaction cannot exceed 4 MB."},{"ref":"AWS.DynamoDB.html#transact_write_items/3","title":"AWS.DynamoDB.transact_write_items/3","type":"function","doc":"TransactWriteItems is a synchronous write operation that groups up to 25 action requests. These actions can target items in different tables, but not in different AWS accounts or Regions, and no two actions can target the same item. For example, you cannot both ConditionCheck and Update the same item. The aggregate size of the items in the transaction cannot exceed 4 MB. The actions are completed atomically so that either all of them succeed, or all of them fail. They are defined by the following objects: Put   Initiates a PutItem operation to write a new item. This structure specifies the primary key of the item to be written, the name of the table to write it in, an optional condition expression that must be satisfied for the write to succeed, a list of the item&#39;s attributes, and a field indicating whether to retrieve the item&#39;s attributes if the condition is not met. Update   Initiates an UpdateItem operation to update an existing item. This structure specifies the primary key of the item to be updated, the name of the table where it resides, an optional condition expression that must be satisfied for the update to succeed, an expression that defines one or more attributes to be updated, and a field indicating whether to retrieve the item&#39;s attributes if the condition is not met. Delete   Initiates a DeleteItem operation to delete an existing item. This structure specifies the primary key of the item to be deleted, the name of the table where it resides, an optional condition expression that must be satisfied for the deletion to succeed, and a field indicating whether to retrieve the item&#39;s attributes if the condition is not met. ConditionCheck   Applies a condition to an item that is not being modified by the transaction. This structure specifies the primary key of the item to be checked, the name of the table where it resides, a condition expression that must be satisfied for the transaction to succeed, and a field indicating whether to retrieve the item&#39;s attributes if the condition is not met. DynamoDB rejects the entire TransactWriteItems request if any of the following is true: A condition in one of the condition expressions is not met. An ongoing operation is in the process of updating the same item. There is insufficient provisioned capacity for the transaction to be completed. An item size becomes too large (bigger than 400 KB), a local secondary index (LSI) becomes too large, or a similar validation error occurs because of changes made by the transaction. The aggregate size of the items in the transaction exceeds 4 MB. There is a user error, such as an invalid data format."},{"ref":"AWS.DynamoDB.html#untag_resource/3","title":"AWS.DynamoDB.untag_resource/3","type":"function","doc":"Removes the association of tags from an Amazon DynamoDB resource. You can call UntagResource up to five times per second, per account. For an overview on tagging DynamoDB resources, see Tagging for DynamoDB in the Amazon DynamoDB Developer Guide."},{"ref":"AWS.DynamoDB.html#update_continuous_backups/3","title":"AWS.DynamoDB.update_continuous_backups/3","type":"function","doc":"UpdateContinuousBackups enables or disables point in time recovery for the specified table. A successful UpdateContinuousBackups call returns the current ContinuousBackupsDescription. Continuous backups are ENABLED on all tables at table creation. If point in time recovery is enabled, PointInTimeRecoveryStatus will be set to ENABLED. Once continuous backups and point in time recovery are enabled, you can restore to any point in time within EarliestRestorableDateTime and LatestRestorableDateTime. LatestRestorableDateTime is typically 5 minutes before the current time. You can restore your table to any point in time during the last 35 days."},{"ref":"AWS.DynamoDB.html#update_contributor_insights/3","title":"AWS.DynamoDB.update_contributor_insights/3","type":"function","doc":"Updates the status for contributor insights for a specific table or index."},{"ref":"AWS.DynamoDB.html#update_global_table/3","title":"AWS.DynamoDB.update_global_table/3","type":"function","doc":"Adds or removes replicas in the specified global table. The global table must already exist to be able to use this operation. Any replica to be added must be empty, have the same name as the global table, have the same key schema, have DynamoDB Streams enabled, and have the same provisioned and maximum write capacity units. Although you can use UpdateGlobalTable to add replicas and remove replicas in a single request, for simplicity we recommend that you issue separate requests for adding or removing replicas. If global secondary indexes are specified, then the following conditions must also be met: The global secondary indexes must have the same name. The global secondary indexes must have the same hash key and sort key (if present). The global secondary indexes must have the same provisioned and maximum write capacity units."},{"ref":"AWS.DynamoDB.html#update_global_table_settings/3","title":"AWS.DynamoDB.update_global_table_settings/3","type":"function","doc":"Updates settings for a global table."},{"ref":"AWS.DynamoDB.html#update_item/3","title":"AWS.DynamoDB.update_item/3","type":"function","doc":"Edits an existing item&#39;s attributes, or adds a new item to the table if it does not already exist. You can put, delete, or add attribute values. You can also perform a conditional update on an existing item (insert a new attribute name-value pair if it doesn&#39;t exist, or replace an existing name-value pair if it has certain expected attribute values). You can also return the item&#39;s attribute values in the same UpdateItem operation using the ReturnValues parameter."},{"ref":"AWS.DynamoDB.html#update_table/3","title":"AWS.DynamoDB.update_table/3","type":"function","doc":"Modifies the provisioned throughput settings, global secondary indexes, or DynamoDB Streams settings for a given table. You can only perform one of the following operations at once: Modify the provisioned throughput settings of the table. Enable or disable DynamoDB Streams on the table. Remove a global secondary index from the table. Create a new global secondary index on the table. After the index begins backfilling, you can use UpdateTable to perform other operations. UpdateTable is an asynchronous operation; while it is executing, the table status changes from ACTIVE to UPDATING. While it is UPDATING, you cannot issue another UpdateTable request. When the table returns to the ACTIVE state, the UpdateTable operation is complete."},{"ref":"AWS.DynamoDB.html#update_table_replica_auto_scaling/3","title":"AWS.DynamoDB.update_table_replica_auto_scaling/3","type":"function","doc":"Updates auto scaling settings on your global tables at once. This operation only applies to Version 2019.11.21 of global tables."},{"ref":"AWS.DynamoDB.html#update_time_to_live/3","title":"AWS.DynamoDB.update_time_to_live/3","type":"function","doc":"The UpdateTimeToLive method enables or disables Time to Live (TTL) for the specified table. A successful UpdateTimeToLive call returns the current TimeToLiveSpecification. It can take up to one hour for the change to fully process. Any additional UpdateTimeToLive calls for the same table during this one hour duration result in a ValidationException. TTL compares the current time in epoch time format to the time stored in the TTL attribute of an item. If the epoch time value stored in the attribute is less than the current time, the item is marked as expired and subsequently deleted. The epoch time format is the number of seconds elapsed since 12:00:00 AM January 1, 1970 UTC. DynamoDB deletes expired items on a best-effort basis to ensure availability of throughput for other data operations. DynamoDB typically deletes expired items within two days of expiration. The exact duration within which an item gets deleted after expiration is specific to the nature of the workload. Items that have expired and not been deleted will still show up in reads, queries, and scans. As items are deleted, they are removed from any local secondary index and global secondary index immediately in the same eventually consistent way as a standard delete operation. For more information, see Time To Live in the Amazon DynamoDB Developer Guide."},{"ref":"AWS.DynamoDBStreams.html","title":"AWS.DynamoDBStreams","type":"module","doc":"Amazon DynamoDB Amazon DynamoDB Streams provides API actions for accessing streams and processing stream records. To learn more about application development with Streams, see Capturing Table Activity with DynamoDB Streams in the Amazon DynamoDB Developer Guide."},{"ref":"AWS.DynamoDBStreams.html#describe_stream/3","title":"AWS.DynamoDBStreams.describe_stream/3","type":"function","doc":"Returns information about a stream, including the current status of the stream, its Amazon Resource Name (ARN), the composition of its shards, and its corresponding DynamoDB table. You can call DescribeStream at a maximum rate of 10 times per second. Each shard in the stream has a SequenceNumberRange associated with it. If the SequenceNumberRange has a StartingSequenceNumber but no EndingSequenceNumber, then the shard is still open (able to receive more stream records). If both StartingSequenceNumber and EndingSequenceNumber are present, then that shard is closed and can no longer receive more data."},{"ref":"AWS.DynamoDBStreams.html#get_records/3","title":"AWS.DynamoDBStreams.get_records/3","type":"function","doc":"Retrieves the stream records from a given shard. Specify a shard iterator using the ShardIterator parameter. The shard iterator specifies the position in the shard from which you want to start reading stream records sequentially. If there are no stream records available in the portion of the shard that the iterator points to, GetRecords returns an empty list. Note that it might take multiple calls to get to a portion of the shard that contains stream records. GetRecords can retrieve a maximum of 1 MB of data or 1000 stream records, whichever comes first."},{"ref":"AWS.DynamoDBStreams.html#get_shard_iterator/3","title":"AWS.DynamoDBStreams.get_shard_iterator/3","type":"function","doc":"Returns a shard iterator. A shard iterator provides information about how to retrieve the stream records from within a shard. Use the shard iterator in a subsequent GetRecords request to read the stream records from the shard. A shard iterator expires 15 minutes after it is returned to the requester."},{"ref":"AWS.DynamoDBStreams.html#list_streams/3","title":"AWS.DynamoDBStreams.list_streams/3","type":"function","doc":"Returns an array of stream ARNs associated with the current account and endpoint. If the TableName parameter is present, then ListStreams will return only the streams ARNs for that table. You can call ListStreams at a maximum rate of 5 times per second."},{"ref":"AWS.EBS.html","title":"AWS.EBS","type":"module","doc":"You can use the Amazon Elastic Block Store (Amazon EBS) direct APIs to create EBS snapshots, write data directly to your snapshots, read data on your snapshots, and identify the differences or changes between two snapshots. If youre an independent software vendor (ISV) who offers backup services for Amazon EBS, the EBS direct APIs make it more efficient and cost-effective to track incremental changes on your EBS volumes through snapshots. This can be done without having to create new volumes from snapshots, and then use Amazon Elastic Compute Cloud (Amazon EC2) instances to compare the differences. You can create incremental snapshots directly from data on-premises into EBS volumes and the cloud to use for quick disaster recovery. With the ability to write and read snapshots, you can write your on-premises data to an EBS snapshot during a disaster. Then after recovery, you can restore it back to AWS or on-premises from the snapshot. You no longer need to build and maintain complex mechanisms to copy data to and from Amazon EBS. This API reference provides detailed information about the actions, data types, parameters, and errors of the EBS direct APIs. For more information about the elements that make up the EBS direct APIs, and examples of how to use them effectively, see Accessing the Contents of an EBS Snapshot in the Amazon Elastic Compute Cloud User Guide. For more information about the supported AWS Regions, endpoints, and service quotas for the EBS direct APIs, see Amazon Elastic Block Store Endpoints and Quotas in the AWS General Reference."},{"ref":"AWS.EBS.html#complete_snapshot/4","title":"AWS.EBS.complete_snapshot/4","type":"function","doc":"Seals and completes the snapshot after all of the required blocks of data have been written to it. Completing the snapshot changes the status to completed. You cannot write new blocks to a snapshot after it has been completed."},{"ref":"AWS.EBS.html#get_snapshot_block/5","title":"AWS.EBS.get_snapshot_block/5","type":"function","doc":"Returns the data in a block in an Amazon Elastic Block Store snapshot."},{"ref":"AWS.EBS.html#list_changed_blocks/7","title":"AWS.EBS.list_changed_blocks/7","type":"function","doc":"Returns information about the blocks that are different between two Amazon Elastic Block Store snapshots of the same volume/snapshot lineage."},{"ref":"AWS.EBS.html#list_snapshot_blocks/6","title":"AWS.EBS.list_snapshot_blocks/6","type":"function","doc":"Returns information about the blocks in an Amazon Elastic Block Store snapshot."},{"ref":"AWS.EBS.html#put_snapshot_block/5","title":"AWS.EBS.put_snapshot_block/5","type":"function","doc":"Writes a block of data to a snapshot. If the specified block contains data, the existing data is overwritten. The target snapshot must be in the pending state. Data written to a snapshot must be aligned with 512-byte sectors."},{"ref":"AWS.EBS.html#start_snapshot/3","title":"AWS.EBS.start_snapshot/3","type":"function","doc":"Creates a new Amazon EBS snapshot. The new snapshot enters the pending state after the request completes. After creating the snapshot, use PutSnapshotBlock to write blocks of data to the snapshot."},{"ref":"AWS.EC2InstanceConnect.html","title":"AWS.EC2InstanceConnect","type":"module","doc":"AWS EC2 Connect Service is a service that enables system administrators to publish temporary SSH keys to their EC2 instances in order to establish connections to their instances without leaving a permanent authentication option."},{"ref":"AWS.EC2InstanceConnect.html#send_s_s_h_public_key/3","title":"AWS.EC2InstanceConnect.send_s_s_h_public_key/3","type":"function","doc":"Pushes an SSH public key to a particular OS user on a given EC2 instance for 60 seconds."},{"ref":"AWS.ECR.html","title":"AWS.ECR","type":"module","doc":"Amazon Elastic Container Registry Amazon Elastic Container Registry (Amazon ECR) is a managed container image registry service. Customers can use the familiar Docker CLI, or their preferred client, to push, pull, and manage images. Amazon ECR provides a secure, scalable, and reliable registry for your Docker or Open Container Initiative (OCI) images. Amazon ECR supports private repositories with resource-based permissions using IAM so that specific users or Amazon EC2 instances can access repositories and images."},{"ref":"AWS.ECR.html#batch_check_layer_availability/3","title":"AWS.ECR.batch_check_layer_availability/3","type":"function","doc":"Checks the availability of one or more image layers in a repository. When an image is pushed to a repository, each image layer is checked to verify if it has been uploaded before. If it has been uploaded, then the image layer is skipped. This operation is used by the Amazon ECR proxy and is not generally used by customers for pulling and pushing images. In most cases, you should use the docker CLI to pull, tag, and push images."},{"ref":"AWS.ECR.html#batch_delete_image/3","title":"AWS.ECR.batch_delete_image/3","type":"function","doc":"Deletes a list of specified images within a repository. Images are specified with either an imageTag or imageDigest. You can remove a tag from an image by specifying the image&#39;s tag in your request. When you remove the last tag from an image, the image is deleted from your repository. You can completely delete an image (and all of its tags) by specifying the image&#39;s digest in your request."},{"ref":"AWS.ECR.html#batch_get_image/3","title":"AWS.ECR.batch_get_image/3","type":"function","doc":"Gets detailed information for an image. Images are specified with either an imageTag or imageDigest. When an image is pulled, the BatchGetImage API is called once to retrieve the image manifest."},{"ref":"AWS.ECR.html#complete_layer_upload/3","title":"AWS.ECR.complete_layer_upload/3","type":"function","doc":"Informs Amazon ECR that the image layer upload has completed for a specified registry, repository name, and upload ID. You can optionally provide a sha256 digest of the image layer for data validation purposes. When an image is pushed, the CompleteLayerUpload API is called once per each new image layer to verify that the upload has completed. This operation is used by the Amazon ECR proxy and is not generally used by customers for pulling and pushing images. In most cases, you should use the docker CLI to pull, tag, and push images."},{"ref":"AWS.ECR.html#create_repository/3","title":"AWS.ECR.create_repository/3","type":"function","doc":"Creates a repository. For more information, see Amazon ECR Repositories in the Amazon Elastic Container Registry User Guide."},{"ref":"AWS.ECR.html#delete_lifecycle_policy/3","title":"AWS.ECR.delete_lifecycle_policy/3","type":"function","doc":"Deletes the lifecycle policy associated with the specified repository."},{"ref":"AWS.ECR.html#delete_repository/3","title":"AWS.ECR.delete_repository/3","type":"function","doc":"Deletes a repository. If the repository contains images, you must either delete all images in the repository or use the force option to delete the repository."},{"ref":"AWS.ECR.html#delete_repository_policy/3","title":"AWS.ECR.delete_repository_policy/3","type":"function","doc":"Deletes the repository policy associated with the specified repository."},{"ref":"AWS.ECR.html#describe_image_scan_findings/3","title":"AWS.ECR.describe_image_scan_findings/3","type":"function","doc":"Returns the scan findings for the specified image."},{"ref":"AWS.ECR.html#describe_images/3","title":"AWS.ECR.describe_images/3","type":"function","doc":"Returns metadata about the images in a repository. Beginning with Docker version 1.9, the Docker client compresses image layers before pushing them to a V2 Docker registry. The output of the docker images command shows the uncompressed image size, so it may return a larger image size than the image sizes returned by DescribeImages."},{"ref":"AWS.ECR.html#describe_repositories/3","title":"AWS.ECR.describe_repositories/3","type":"function","doc":"Describes image repositories in a registry."},{"ref":"AWS.ECR.html#get_authorization_token/3","title":"AWS.ECR.get_authorization_token/3","type":"function","doc":"Retrieves an authorization token. An authorization token represents your IAM authentication credentials and can be used to access any Amazon ECR registry that your IAM principal has access to. The authorization token is valid for 12 hours. The authorizationToken returned is a base64 encoded string that can be decoded and used in a docker login command to authenticate to a registry. The AWS CLI offers an get-login-password command that simplifies the login process. For more information, see Registry Authentication in the Amazon Elastic Container Registry User Guide."},{"ref":"AWS.ECR.html#get_download_url_for_layer/3","title":"AWS.ECR.get_download_url_for_layer/3","type":"function","doc":"Retrieves the pre-signed Amazon S3 download URL corresponding to an image layer. You can only get URLs for image layers that are referenced in an image. When an image is pulled, the GetDownloadUrlForLayer API is called once per image layer that is not already cached. This operation is used by the Amazon ECR proxy and is not generally used by customers for pulling and pushing images. In most cases, you should use the docker CLI to pull, tag, and push images."},{"ref":"AWS.ECR.html#get_lifecycle_policy/3","title":"AWS.ECR.get_lifecycle_policy/3","type":"function","doc":"Retrieves the lifecycle policy for the specified repository."},{"ref":"AWS.ECR.html#get_lifecycle_policy_preview/3","title":"AWS.ECR.get_lifecycle_policy_preview/3","type":"function","doc":"Retrieves the results of the lifecycle policy preview request for the specified repository."},{"ref":"AWS.ECR.html#get_repository_policy/3","title":"AWS.ECR.get_repository_policy/3","type":"function","doc":"Retrieves the repository policy for the specified repository."},{"ref":"AWS.ECR.html#initiate_layer_upload/3","title":"AWS.ECR.initiate_layer_upload/3","type":"function","doc":"Notifies Amazon ECR that you intend to upload an image layer. When an image is pushed, the InitiateLayerUpload API is called once per image layer that has not already been uploaded. Whether or not an image layer has been uploaded is determined by the BatchCheckLayerAvailability API action. This operation is used by the Amazon ECR proxy and is not generally used by customers for pulling and pushing images. In most cases, you should use the docker CLI to pull, tag, and push images."},{"ref":"AWS.ECR.html#list_images/3","title":"AWS.ECR.list_images/3","type":"function","doc":"Lists all the image IDs for the specified repository. You can filter images based on whether or not they are tagged by using the tagStatus filter and specifying either TAGGED, UNTAGGED or ANY. For example, you can filter your results to return only UNTAGGED images and then pipe that result to a BatchDeleteImage operation to delete them. Or, you can filter your results to return only TAGGED images to list all of the tags in your repository."},{"ref":"AWS.ECR.html#list_tags_for_resource/3","title":"AWS.ECR.list_tags_for_resource/3","type":"function","doc":"List the tags for an Amazon ECR resource."},{"ref":"AWS.ECR.html#put_image/3","title":"AWS.ECR.put_image/3","type":"function","doc":"Creates or updates the image manifest and tags associated with an image. When an image is pushed and all new image layers have been uploaded, the PutImage API is called once to create or update the image manifest and the tags associated with the image. This operation is used by the Amazon ECR proxy and is not generally used by customers for pulling and pushing images. In most cases, you should use the docker CLI to pull, tag, and push images."},{"ref":"AWS.ECR.html#put_image_scanning_configuration/3","title":"AWS.ECR.put_image_scanning_configuration/3","type":"function","doc":"Updates the image scanning configuration for the specified repository."},{"ref":"AWS.ECR.html#put_image_tag_mutability/3","title":"AWS.ECR.put_image_tag_mutability/3","type":"function","doc":"Updates the image tag mutability settings for the specified repository. For more information, see Image Tag Mutability in the Amazon Elastic Container Registry User Guide."},{"ref":"AWS.ECR.html#put_lifecycle_policy/3","title":"AWS.ECR.put_lifecycle_policy/3","type":"function","doc":"Creates or updates the lifecycle policy for the specified repository. For more information, see Lifecycle Policy Template."},{"ref":"AWS.ECR.html#set_repository_policy/3","title":"AWS.ECR.set_repository_policy/3","type":"function","doc":"Applies a repository policy to the specified repository to control access permissions. For more information, see Amazon ECR Repository Policies in the Amazon Elastic Container Registry User Guide."},{"ref":"AWS.ECR.html#start_image_scan/3","title":"AWS.ECR.start_image_scan/3","type":"function","doc":"Starts an image vulnerability scan. An image scan can only be started once per day on an individual image. This limit includes if an image was scanned on initial push. For more information, see Image Scanning in the Amazon Elastic Container Registry User Guide."},{"ref":"AWS.ECR.html#start_lifecycle_policy_preview/3","title":"AWS.ECR.start_lifecycle_policy_preview/3","type":"function","doc":"Starts a preview of a lifecycle policy for the specified repository. This allows you to see the results before associating the lifecycle policy with the repository."},{"ref":"AWS.ECR.html#tag_resource/3","title":"AWS.ECR.tag_resource/3","type":"function","doc":"Adds specified tags to a resource with the specified ARN. Existing tags on a resource are not changed if they are not specified in the request parameters."},{"ref":"AWS.ECR.html#untag_resource/3","title":"AWS.ECR.untag_resource/3","type":"function","doc":"Deletes specified tags from a resource."},{"ref":"AWS.ECR.html#upload_layer_part/3","title":"AWS.ECR.upload_layer_part/3","type":"function","doc":"Uploads an image layer part to Amazon ECR. When an image is pushed, each new image layer is uploaded in parts. The maximum size of each image layer part can be 20971520 bytes (or about 20MB). The UploadLayerPart API is called once per each new image layer part. This operation is used by the Amazon ECR proxy and is not generally used by customers for pulling and pushing images. In most cases, you should use the docker CLI to pull, tag, and push images."},{"ref":"AWS.ECS.html","title":"AWS.ECS","type":"module","doc":"Amazon Elastic Container Service Amazon Elastic Container Service (Amazon ECS) is a highly scalable, fast, container management service that makes it easy to run, stop, and manage Docker containers on a cluster. You can host your cluster on a serverless infrastructure that is managed by Amazon ECS by launching your services or tasks using the Fargate launch type. For more control, you can host your tasks on a cluster of Amazon Elastic Compute Cloud (Amazon EC2) instances that you manage by using the EC2 launch type. For more information about launch types, see Amazon ECS Launch Types. Amazon ECS lets you launch and stop container-based applications with simple API calls, allows you to get the state of your cluster from a centralized service, and gives you access to many familiar Amazon EC2 features. You can use Amazon ECS to schedule the placement of containers across your cluster based on your resource needs, isolation policies, and availability requirements. Amazon ECS eliminates the need for you to operate your own cluster management and configuration management systems or worry about scaling your management infrastructure."},{"ref":"AWS.ECS.html#create_capacity_provider/3","title":"AWS.ECS.create_capacity_provider/3","type":"function","doc":"Creates a new capacity provider. Capacity providers are associated with an Amazon ECS cluster and are used in capacity provider strategies to facilitate cluster auto scaling. Only capacity providers using an Auto Scaling group can be created. Amazon ECS tasks on AWS Fargate use the FARGATE and FARGATE_SPOT capacity providers which are already created and available to all accounts in Regions supported by AWS Fargate."},{"ref":"AWS.ECS.html#create_cluster/3","title":"AWS.ECS.create_cluster/3","type":"function","doc":"Creates a new Amazon ECS cluster. By default, your account receives a default cluster when you launch your first container instance. However, you can create your own cluster with a unique name with the CreateCluster action. When you call the CreateCluster API operation, Amazon ECS attempts to create the Amazon ECS service-linked role for your account so that required resources in other AWS services can be managed on your behalf. However, if the IAM user that makes the call does not have permissions to create the service-linked role, it is not created. For more information, see Using Service-Linked Roles for Amazon ECS in the Amazon Elastic Container Service Developer Guide."},{"ref":"AWS.ECS.html#create_service/3","title":"AWS.ECS.create_service/3","type":"function","doc":"Runs and maintains a desired number of tasks from a specified task definition. If the number of tasks running in a service drops below the desiredCount, Amazon ECS runs another copy of the task in the specified cluster. To update an existing service, see the UpdateService action. In addition to maintaining the desired count of tasks in your service, you can optionally run your service behind one or more load balancers. The load balancers distribute traffic across the tasks that are associated with the service. For more information, see Service Load Balancing in the Amazon Elastic Container Service Developer Guide. Tasks for services that do not use a load balancer are considered healthy if they&#39;re in the RUNNING state. Tasks for services that do use a load balancer are considered healthy if they&#39;re in the RUNNING state and the container instance that they&#39;re hosted on is reported as healthy by the load balancer. There are two service scheduler strategies available: REPLICA - The replica scheduling strategy places and maintains the desired number of tasks across your cluster. By default, the service scheduler spreads tasks across Availability Zones. You can use task placement strategies and constraints to customize task placement decisions. For more information, see Service Scheduler Concepts in the Amazon Elastic Container Service Developer Guide. DAEMON - The daemon scheduling strategy deploys exactly one task on each active container instance that meets all of the task placement constraints that you specify in your cluster. The service scheduler also evaluates the task placement constraints for running tasks and will stop tasks that do not meet the placement constraints. When using this strategy, you don&#39;t need to specify a desired number of tasks, a task placement strategy, or use Service Auto Scaling policies. For more information, see Service Scheduler Concepts in the Amazon Elastic Container Service Developer Guide. You can optionally specify a deployment configuration for your service. The deployment is triggered by changing properties, such as the task definition or the desired count of a service, with an UpdateService operation. The default value for a replica service for minimumHealthyPercent is 100%. The default value for a daemon service for minimumHealthyPercent is 0%. If a service is using the ECS deployment controller, the minimum healthy percent represents a lower limit on the number of tasks in a service that must remain in the RUNNING state during a deployment, as a percentage of the desired number of tasks (rounded up to the nearest integer), and while any container instances are in the DRAINING state if the service contains tasks using the EC2 launch type. This parameter enables you to deploy without using additional cluster capacity. For example, if your service has a desired number of four tasks and a minimum healthy percent of 50%, the scheduler might stop two existing tasks to free up cluster capacity before starting two new tasks. Tasks for services that do not use a load balancer are considered healthy if they&#39;re in the RUNNING state. Tasks for services that do use a load balancer are considered healthy if they&#39;re in the RUNNING state and they&#39;re reported as healthy by the load balancer. The default value for minimum healthy percent is 100%. If a service is using the ECS deployment controller, the maximum percent parameter represents an upper limit on the number of tasks in a service that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desired number of tasks (rounded down to the nearest integer), and while any container instances are in the DRAINING state if the service contains tasks using the EC2 launch type. This parameter enables you to define the deployment batch size. For example, if your service has a desired number of four tasks and a maximum percent value of 200%, the scheduler may start four new tasks before stopping the four older tasks (provided that the cluster resources required to do this are available). The default value for maximum percent is 200%. If a service is using either the CODE_DEPLOY or EXTERNAL deployment controller types and tasks that use the EC2 launch type, the minimum healthy percent and maximum percent values are used only to define the lower and upper limit on the number of the tasks in the service that remain in the RUNNING state while the container instances are in the DRAINING state. If the tasks in the service use the Fargate launch type, the minimum healthy percent and maximum percent values aren&#39;t used, although they&#39;re currently visible when describing your service. When creating a service that uses the EXTERNAL deployment controller, you can specify only parameters that aren&#39;t controlled at the task set level. The only required parameter is the service name. You control your services using the CreateTaskSet operation. For more information, see Amazon ECS Deployment Types in the Amazon Elastic Container Service Developer Guide. When the service scheduler launches new tasks, it determines task placement in your cluster using the following logic: Determine which of the container instances in your cluster can support your service&#39;s task definition (for example, they have the required CPU, memory, ports, and container instance attributes). By default, the service scheduler attempts to balance tasks across Availability Zones in this manner (although you can choose a different placement strategy) with the placementStrategy parameter): Sort the valid container instances, giving priority to instances that have the fewest number of running tasks for this service in their respective Availability Zone. For example, if zone A has one running service task and zones B and C each have zero, valid container instances in either zone B or C are considered optimal for placement. Place the new service task on a valid container instance in an optimal Availability Zone (based on the previous steps), favoring container instances with the fewest number of running tasks for this service."},{"ref":"AWS.ECS.html#create_task_set/3","title":"AWS.ECS.create_task_set/3","type":"function","doc":"Create a task set in the specified cluster and service. This is used when a service uses the EXTERNAL deployment controller type. For more information, see Amazon ECS Deployment Types in the Amazon Elastic Container Service Developer Guide."},{"ref":"AWS.ECS.html#delete_account_setting/3","title":"AWS.ECS.delete_account_setting/3","type":"function","doc":"Disables an account setting for a specified IAM user, IAM role, or the root user for an account."},{"ref":"AWS.ECS.html#delete_attributes/3","title":"AWS.ECS.delete_attributes/3","type":"function","doc":"Deletes one or more custom attributes from an Amazon ECS resource."},{"ref":"AWS.ECS.html#delete_capacity_provider/3","title":"AWS.ECS.delete_capacity_provider/3","type":"function","doc":"Deletes the specified capacity provider. The FARGATE and FARGATE_SPOT capacity providers are reserved and cannot be deleted. You can disassociate them from a cluster using either the PutClusterCapacityProviders API or by deleting the cluster. Prior to a capacity provider being deleted, the capacity provider must be removed from the capacity provider strategy from all services. The UpdateService API can be used to remove a capacity provider from a service&#39;s capacity provider strategy. When updating a service, the forceNewDeployment option can be used to ensure that any tasks using the Amazon EC2 instance capacity provided by the capacity provider are transitioned to use the capacity from the remaining capacity providers. Only capacity providers that are not associated with a cluster can be deleted. To remove a capacity provider from a cluster, you can either use PutClusterCapacityProviders or delete the cluster."},{"ref":"AWS.ECS.html#delete_cluster/3","title":"AWS.ECS.delete_cluster/3","type":"function","doc":"Deletes the specified cluster. The cluster will transition to the INACTIVE state. Clusters with an INACTIVE status may remain discoverable in your account for a period of time. However, this behavior is subject to change in the future, so you should not rely on INACTIVE clusters persisting. You must deregister all container instances from this cluster before you may delete it. You can list the container instances in a cluster with ListContainerInstances and deregister them with DeregisterContainerInstance."},{"ref":"AWS.ECS.html#delete_service/3","title":"AWS.ECS.delete_service/3","type":"function","doc":"Deletes a specified service within a cluster. You can delete a service if you have no running tasks in it and the desired task count is zero. If the service is actively maintaining tasks, you cannot delete it, and you must update the service to a desired task count of zero. For more information, see UpdateService. When you delete a service, if there are still running tasks that require cleanup, the service status moves from ACTIVE to DRAINING, and the service is no longer visible in the console or in the ListServices API operation. After all tasks have transitioned to either STOPPING or STOPPED status, the service status moves from DRAINING to INACTIVE. Services in the DRAINING or INACTIVE status can still be viewed with the DescribeServices API operation. However, in the future, INACTIVE services may be cleaned up and purged from Amazon ECS record keeping, and DescribeServices calls on those services return a ServiceNotFoundException error. If you attempt to create a new service with the same name as an existing service in either ACTIVE or DRAINING status, you receive an error."},{"ref":"AWS.ECS.html#delete_task_set/3","title":"AWS.ECS.delete_task_set/3","type":"function","doc":"Deletes a specified task set within a service. This is used when a service uses the EXTERNAL deployment controller type. For more information, see Amazon ECS Deployment Types in the Amazon Elastic Container Service Developer Guide."},{"ref":"AWS.ECS.html#deregister_container_instance/3","title":"AWS.ECS.deregister_container_instance/3","type":"function","doc":"Deregisters an Amazon ECS container instance from the specified cluster. This instance is no longer available to run tasks. If you intend to use the container instance for some other purpose after deregistration, you should stop all of the tasks running on the container instance before deregistration. That prevents any orphaned tasks from consuming resources. Deregistering a container instance removes the instance from a cluster, but it does not terminate the EC2 instance. If you are finished using the instance, be sure to terminate it in the Amazon EC2 console to stop billing. If you terminate a running container instance, Amazon ECS automatically deregisters the instance from your cluster (stopped container instances or instances with disconnected agents are not automatically deregistered when terminated)."},{"ref":"AWS.ECS.html#deregister_task_definition/3","title":"AWS.ECS.deregister_task_definition/3","type":"function","doc":"Deregisters the specified task definition by family and revision. Upon deregistration, the task definition is marked as INACTIVE. Existing tasks and services that reference an INACTIVE task definition continue to run without disruption. Existing services that reference an INACTIVE task definition can still scale up or down by modifying the service&#39;s desired count. You cannot use an INACTIVE task definition to run new tasks or create new services, and you cannot update an existing service to reference an INACTIVE task definition. However, there may be up to a 10-minute window following deregistration where these restrictions have not yet taken effect. At this time, INACTIVE task definitions remain discoverable in your account indefinitely. However, this behavior is subject to change in the future, so you should not rely on INACTIVE task definitions persisting beyond the lifecycle of any associated tasks and services."},{"ref":"AWS.ECS.html#describe_capacity_providers/3","title":"AWS.ECS.describe_capacity_providers/3","type":"function","doc":"Describes one or more of your capacity providers."},{"ref":"AWS.ECS.html#describe_clusters/3","title":"AWS.ECS.describe_clusters/3","type":"function","doc":"Describes one or more of your clusters."},{"ref":"AWS.ECS.html#describe_container_instances/3","title":"AWS.ECS.describe_container_instances/3","type":"function","doc":"Describes Amazon Elastic Container Service container instances. Returns metadata about registered and remaining resources on each container instance requested."},{"ref":"AWS.ECS.html#describe_services/3","title":"AWS.ECS.describe_services/3","type":"function","doc":"Describes the specified services running in your cluster."},{"ref":"AWS.ECS.html#describe_task_definition/3","title":"AWS.ECS.describe_task_definition/3","type":"function","doc":"Describes a task definition. You can specify a family and revision to find information about a specific task definition, or you can simply specify the family to find the latest ACTIVE revision in that family. You can only describe INACTIVE task definitions while an active task or service references them."},{"ref":"AWS.ECS.html#describe_task_sets/3","title":"AWS.ECS.describe_task_sets/3","type":"function","doc":"Describes the task sets in the specified cluster and service. This is used when a service uses the EXTERNAL deployment controller type. For more information, see Amazon ECS Deployment Types in the Amazon Elastic Container Service Developer Guide."},{"ref":"AWS.ECS.html#describe_tasks/3","title":"AWS.ECS.describe_tasks/3","type":"function","doc":"Describes a specified task or tasks."},{"ref":"AWS.ECS.html#discover_poll_endpoint/3","title":"AWS.ECS.discover_poll_endpoint/3","type":"function","doc":"This action is only used by the Amazon ECS agent, and it is not intended for use outside of the agent. Returns an endpoint for the Amazon ECS agent to poll for updates."},{"ref":"AWS.ECS.html#list_account_settings/3","title":"AWS.ECS.list_account_settings/3","type":"function","doc":"Lists the account settings for a specified principal."},{"ref":"AWS.ECS.html#list_attributes/3","title":"AWS.ECS.list_attributes/3","type":"function","doc":"Lists the attributes for Amazon ECS resources within a specified target type and cluster. When you specify a target type and cluster, ListAttributes returns a list of attribute objects, one for each attribute on each resource. You can filter the list of results to a single attribute name to only return results that have that name. You can also filter the results by attribute name and value, for example, to see which container instances in a cluster are running a Linux AMI (ecs.os-type=linux)."},{"ref":"AWS.ECS.html#list_clusters/3","title":"AWS.ECS.list_clusters/3","type":"function","doc":"Returns a list of existing clusters."},{"ref":"AWS.ECS.html#list_container_instances/3","title":"AWS.ECS.list_container_instances/3","type":"function","doc":"Returns a list of container instances in a specified cluster. You can filter the results of a ListContainerInstances operation with cluster query language statements inside the filter parameter. For more information, see Cluster Query Language in the Amazon Elastic Container Service Developer Guide."},{"ref":"AWS.ECS.html#list_services/3","title":"AWS.ECS.list_services/3","type":"function","doc":"Lists the services that are running in a specified cluster."},{"ref":"AWS.ECS.html#list_tags_for_resource/3","title":"AWS.ECS.list_tags_for_resource/3","type":"function","doc":"List the tags for an Amazon ECS resource."},{"ref":"AWS.ECS.html#list_task_definition_families/3","title":"AWS.ECS.list_task_definition_families/3","type":"function","doc":"Returns a list of task definition families that are registered to your account (which may include task definition families that no longer have any ACTIVE task definition revisions). You can filter out task definition families that do not contain any ACTIVE task definition revisions by setting the status parameter to ACTIVE. You can also filter the results with the familyPrefix parameter."},{"ref":"AWS.ECS.html#list_task_definitions/3","title":"AWS.ECS.list_task_definitions/3","type":"function","doc":"Returns a list of task definitions that are registered to your account. You can filter the results by family name with the familyPrefix parameter or by status with the status parameter."},{"ref":"AWS.ECS.html#list_tasks/3","title":"AWS.ECS.list_tasks/3","type":"function","doc":"Returns a list of tasks for a specified cluster. You can filter the results by family name, by a particular container instance, or by the desired status of the task with the family, containerInstance, and desiredStatus parameters. Recently stopped tasks might appear in the returned results. Currently, stopped tasks appear in the returned results for at least one hour."},{"ref":"AWS.ECS.html#put_account_setting/3","title":"AWS.ECS.put_account_setting/3","type":"function","doc":"Modifies an account setting. Account settings are set on a per-Region basis. If you change the account setting for the root user, the default settings for all of the IAM users and roles for which no individual account setting has been specified are reset. For more information, see Account Settings in the Amazon Elastic Container Service Developer Guide. When serviceLongArnFormat, taskLongArnFormat, or containerInstanceLongArnFormat are specified, the Amazon Resource Name (ARN) and resource ID format of the resource type for a specified IAM user, IAM role, or the root user for an account is affected. The opt-in and opt-out account setting must be set for each Amazon ECS resource separately. The ARN and resource ID format of a resource will be defined by the opt-in status of the IAM user or role that created the resource. You must enable this setting to use Amazon ECS features such as resource tagging. When awsvpcTrunking is specified, the elastic network interface (ENI) limit for any new container instances that support the feature is changed. If awsvpcTrunking is enabled, any new container instances that support the feature are launched have the increased ENI limits available to them. For more information, see Elastic Network Interface Trunking in the Amazon Elastic Container Service Developer Guide. When containerInsights is specified, the default setting indicating whether CloudWatch Container Insights is enabled for your clusters is changed. If containerInsights is enabled, any new clusters that are created will have Container Insights enabled unless you disable it during cluster creation. For more information, see CloudWatch Container Insights in the Amazon Elastic Container Service Developer Guide."},{"ref":"AWS.ECS.html#put_account_setting_default/3","title":"AWS.ECS.put_account_setting_default/3","type":"function","doc":"Modifies an account setting for all IAM users on an account for whom no individual account setting has been specified. Account settings are set on a per-Region basis."},{"ref":"AWS.ECS.html#put_attributes/3","title":"AWS.ECS.put_attributes/3","type":"function","doc":"Create or update an attribute on an Amazon ECS resource. If the attribute does not exist, it is created. If the attribute exists, its value is replaced with the specified value. To delete an attribute, use DeleteAttributes. For more information, see Attributes in the Amazon Elastic Container Service Developer Guide."},{"ref":"AWS.ECS.html#put_cluster_capacity_providers/3","title":"AWS.ECS.put_cluster_capacity_providers/3","type":"function","doc":"Modifies the available capacity providers and the default capacity provider strategy for a cluster. You must specify both the available capacity providers and a default capacity provider strategy for the cluster. If the specified cluster has existing capacity providers associated with it, you must specify all existing capacity providers in addition to any new ones you want to add. Any existing capacity providers associated with a cluster that are omitted from a PutClusterCapacityProviders API call will be disassociated with the cluster. You can only disassociate an existing capacity provider from a cluster if it&#39;s not being used by any existing tasks. When creating a service or running a task on a cluster, if no capacity provider or launch type is specified, then the cluster&#39;s default capacity provider strategy is used. It is recommended to define a default capacity provider strategy for your cluster, however you may specify an empty array ([]) to bypass defining a default strategy."},{"ref":"AWS.ECS.html#register_container_instance/3","title":"AWS.ECS.register_container_instance/3","type":"function","doc":"This action is only used by the Amazon ECS agent, and it is not intended for use outside of the agent. Registers an EC2 instance into the specified cluster. This instance becomes available to place containers on."},{"ref":"AWS.ECS.html#register_task_definition/3","title":"AWS.ECS.register_task_definition/3","type":"function","doc":"Registers a new task definition from the supplied family and containerDefinitions. Optionally, you can add data volumes to your containers with the volumes parameter. For more information about task definition parameters and defaults, see Amazon ECS Task Definitions in the Amazon Elastic Container Service Developer Guide. You can specify an IAM role for your task with the taskRoleArn parameter. When you specify an IAM role for a task, its containers can then use the latest versions of the AWS CLI or SDKs to make API requests to the AWS services that are specified in the IAM policy associated with the role. For more information, see IAM Roles for Tasks in the Amazon Elastic Container Service Developer Guide. You can specify a Docker networking mode for the containers in your task definition with the networkMode parameter. The available network modes correspond to those described in Network settings in the Docker run reference. If you specify the awsvpc network mode, the task is allocated an elastic network interface, and you must specify a NetworkConfiguration when you create a service or run a task with the task definition. For more information, see Task Networking in the Amazon Elastic Container Service Developer Guide."},{"ref":"AWS.ECS.html#run_task/3","title":"AWS.ECS.run_task/3","type":"function","doc":"Starts a new task using the specified task definition. You can allow Amazon ECS to place tasks for you, or you can customize how Amazon ECS places tasks using placement constraints and placement strategies. For more information, see Scheduling Tasks in the Amazon Elastic Container Service Developer Guide. Alternatively, you can use StartTask to use your own scheduler or place tasks manually on specific container instances. The Amazon ECS API follows an eventual consistency model, due to the distributed nature of the system supporting the API. This means that the result of an API command you run that affects your Amazon ECS resources might not be immediately visible to all subsequent commands you run. Keep this in mind when you carry out an API command that immediately follows a previous API command. To manage eventual consistency, you can do the following: Confirm the state of the resource before you run a command to modify it. Run the DescribeTasks command using an exponential backoff algorithm to ensure that you allow enough time for the previous command to propagate through the system. To do this, run the DescribeTasks command repeatedly, starting with a couple of seconds of wait time and increasing gradually up to five minutes of wait time. Add wait time between subsequent commands, even if the DescribeTasks command returns an accurate response. Apply an exponential backoff algorithm starting with a couple of seconds of wait time, and increase gradually up to about five minutes of wait time."},{"ref":"AWS.ECS.html#start_task/3","title":"AWS.ECS.start_task/3","type":"function","doc":"Starts a new task from the specified task definition on the specified container instance or instances. Alternatively, you can use RunTask to place tasks for you. For more information, see Scheduling Tasks in the Amazon Elastic Container Service Developer Guide."},{"ref":"AWS.ECS.html#stop_task/3","title":"AWS.ECS.stop_task/3","type":"function","doc":"Stops a running task. Any tags associated with the task will be deleted. When StopTask is called on a task, the equivalent of docker stop is issued to the containers running in the task. This results in a SIGTERM value and a default 30-second timeout, after which the SIGKILL value is sent and the containers are forcibly stopped. If the container handles the SIGTERM value gracefully and exits within 30 seconds from receiving it, no SIGKILL value is sent. The default 30-second timeout can be configured on the Amazon ECS container agent with the ECS_CONTAINER_STOP_TIMEOUT variable. For more information, see Amazon ECS Container Agent Configuration in the Amazon Elastic Container Service Developer Guide."},{"ref":"AWS.ECS.html#submit_attachment_state_changes/3","title":"AWS.ECS.submit_attachment_state_changes/3","type":"function","doc":"This action is only used by the Amazon ECS agent, and it is not intended for use outside of the agent. Sent to acknowledge that an attachment changed states."},{"ref":"AWS.ECS.html#submit_container_state_change/3","title":"AWS.ECS.submit_container_state_change/3","type":"function","doc":"This action is only used by the Amazon ECS agent, and it is not intended for use outside of the agent. Sent to acknowledge that a container changed states."},{"ref":"AWS.ECS.html#submit_task_state_change/3","title":"AWS.ECS.submit_task_state_change/3","type":"function","doc":"This action is only used by the Amazon ECS agent, and it is not intended for use outside of the agent. Sent to acknowledge that a task changed states."},{"ref":"AWS.ECS.html#tag_resource/3","title":"AWS.ECS.tag_resource/3","type":"function","doc":"Associates the specified tags to a resource with the specified resourceArn. If existing tags on a resource are not specified in the request parameters, they are not changed. When a resource is deleted, the tags associated with that resource are deleted as well."},{"ref":"AWS.ECS.html#untag_resource/3","title":"AWS.ECS.untag_resource/3","type":"function","doc":"Deletes specified tags from a resource."},{"ref":"AWS.ECS.html#update_cluster_settings/3","title":"AWS.ECS.update_cluster_settings/3","type":"function","doc":"Modifies the settings to use for a cluster."},{"ref":"AWS.ECS.html#update_container_agent/3","title":"AWS.ECS.update_container_agent/3","type":"function","doc":"Updates the Amazon ECS container agent on a specified container instance. Updating the Amazon ECS container agent does not interrupt running tasks or services on the container instance. The process for updating the agent differs depending on whether your container instance was launched with the Amazon ECS-optimized AMI or another operating system. UpdateContainerAgent requires the Amazon ECS-optimized AMI or Amazon Linux with the ecs-init service installed and running. For help updating the Amazon ECS container agent on other operating systems, see Manually Updating the Amazon ECS Container Agent in the Amazon Elastic Container Service Developer Guide."},{"ref":"AWS.ECS.html#update_container_instances_state/3","title":"AWS.ECS.update_container_instances_state/3","type":"function","doc":"Modifies the status of an Amazon ECS container instance. Once a container instance has reached an ACTIVE state, you can change the status of a container instance to DRAINING to manually remove an instance from a cluster, for example to perform system updates, update the Docker daemon, or scale down the cluster size. A container instance cannot be changed to DRAINING until it has reached an ACTIVE status. If the instance is in any other status, an error will be received. When you set a container instance to DRAINING, Amazon ECS prevents new tasks from being scheduled for placement on the container instance and replacement service tasks are started on other container instances in the cluster if the resources are available. Service tasks on the container instance that are in the PENDING state are stopped immediately. Service tasks on the container instance that are in the RUNNING state are stopped and replaced according to the service&#39;s deployment configuration parameters, minimumHealthyPercent and maximumPercent. You can change the deployment configuration of your service using UpdateService. If minimumHealthyPercent is below 100%, the scheduler can ignore desiredCount temporarily during task replacement. For example, desiredCount is four tasks, a minimum of 50% allows the scheduler to stop two existing tasks before starting two new tasks. If the minimum is 100%, the service scheduler can&#39;t remove existing tasks until the replacement tasks are considered healthy. Tasks for services that do not use a load balancer are considered healthy if they are in the RUNNING state. Tasks for services that use a load balancer are considered healthy if they are in the RUNNING state and the container instance they are hosted on is reported as healthy by the load balancer. The maximumPercent parameter represents an upper limit on the number of running tasks during task replacement, which enables you to define the replacement batch size. For example, if desiredCount is four tasks, a maximum of 200% starts four new tasks before stopping the four tasks to be drained, provided that the cluster resources required to do this are available. If the maximum is 100%, then replacement tasks can&#39;t start until the draining tasks have stopped. Any PENDING or RUNNING tasks that do not belong to a service are not affected. You must wait for them to finish or stop them manually. A container instance has completed draining when it has no more RUNNING tasks. You can verify this using ListTasks. When a container instance has been drained, you can set a container instance to ACTIVE status and once it has reached that status the Amazon ECS scheduler can begin scheduling tasks on the instance again."},{"ref":"AWS.ECS.html#update_service/3","title":"AWS.ECS.update_service/3","type":"function","doc":"Updating the task placement strategies and constraints on an Amazon ECS service remains in preview and is a Beta Service as defined by and subject to the Beta Service Participation Service Terms located at https://aws.amazon.com/service-terms (&quot;Beta Terms&quot;). These Beta Terms apply to your participation in this preview. Modifies the parameters of a service. For services using the rolling update (ECS) deployment controller, the desired count, deployment configuration, network configuration, task placement constraints and strategies, or task definition used can be updated. For services using the blue/green (CODE_DEPLOY) deployment controller, only the desired count, deployment configuration, task placement constraints and strategies, and health check grace period can be updated using this API. If the network configuration, platform version, or task definition need to be updated, a new AWS CodeDeploy deployment should be created. For more information, see CreateDeployment in the AWS CodeDeploy API Reference. For services using an external deployment controller, you can update only the desired count, task placement constraints and strategies, and health check grace period using this API. If the launch type, load balancer, network configuration, platform version, or task definition need to be updated, you should create a new task set. For more information, see CreateTaskSet. You can add to or subtract from the number of instantiations of a task definition in a service by specifying the cluster that the service is running in and a new desiredCount parameter. If you have updated the Docker image of your application, you can create a new task definition with that image and deploy it to your service. The service scheduler uses the minimum healthy percent and maximum percent parameters (in the service&#39;s deployment configuration) to determine the deployment strategy. If your updated Docker image uses the same tag as what is in the existing task definition for your service (for example, my_image:latest), you do not need to create a new revision of your task definition. You can update the service using the forceNewDeployment option. The new tasks launched by the deployment pull the current image/tag combination from your repository when they start. You can also update the deployment configuration of a service. When a deployment is triggered by updating the task definition of a service, the service scheduler uses the deployment configuration parameters, minimumHealthyPercent and maximumPercent, to determine the deployment strategy. If minimumHealthyPercent is below 100%, the scheduler can ignore desiredCount temporarily during a deployment. For example, if desiredCount is four tasks, a minimum of 50% allows the scheduler to stop two existing tasks before starting two new tasks. Tasks for services that do not use a load balancer are considered healthy if they are in the RUNNING state. Tasks for services that use a load balancer are considered healthy if they are in the RUNNING state and the container instance they are hosted on is reported as healthy by the load balancer. The maximumPercent parameter represents an upper limit on the number of running tasks during a deployment, which enables you to define the deployment batch size. For example, if desiredCount is four tasks, a maximum of 200% starts four new tasks before stopping the four older tasks (provided that the cluster resources required to do this are available). When UpdateService stops a task during a deployment, the equivalent of docker stop is issued to the containers running in the task. This results in a SIGTERM and a 30-second timeout, after which SIGKILL is sent and the containers are forcibly stopped. If the container handles the SIGTERM gracefully and exits within 30 seconds from receiving it, no SIGKILL is sent. When the service scheduler launches new tasks, it determines task placement in your cluster with the following logic: Determine which of the container instances in your cluster can support your service&#39;s task definition (for example, they have the required CPU, memory, ports, and container instance attributes). By default, the service scheduler attempts to balance tasks across Availability Zones in this manner (although you can choose a different placement strategy): Sort the valid container instances by the fewest number of running tasks for this service in the same Availability Zone as the instance. For example, if zone A has one running service task and zones B and C each have zero, valid container instances in either zone B or C are considered optimal for placement. Place the new service task on a valid container instance in an optimal Availability Zone (based on the previous steps), favoring container instances with the fewest number of running tasks for this service. When the service scheduler stops running tasks, it attempts to maintain balance across the Availability Zones in your cluster using the following logic: Sort the container instances by the largest number of running tasks for this service in the same Availability Zone as the instance. For example, if zone A has one running service task and zones B and C each have two, container instances in either zone B or C are considered optimal for termination. Stop the task on a container instance in an optimal Availability Zone (based on the previous steps), favoring container instances with the largest number of running tasks for this service."},{"ref":"AWS.ECS.html#update_service_primary_task_set/3","title":"AWS.ECS.update_service_primary_task_set/3","type":"function","doc":"Modifies which task set in a service is the primary task set. Any parameters that are updated on the primary task set in a service will transition to the service. This is used when a service uses the EXTERNAL deployment controller type. For more information, see Amazon ECS Deployment Types in the Amazon Elastic Container Service Developer Guide."},{"ref":"AWS.ECS.html#update_task_set/3","title":"AWS.ECS.update_task_set/3","type":"function","doc":"Modifies a task set. This is used when a service uses the EXTERNAL deployment controller type. For more information, see Amazon ECS Deployment Types in the Amazon Elastic Container Service Developer Guide."},{"ref":"AWS.EFS.html","title":"AWS.EFS","type":"module","doc":"Amazon Elastic File System Amazon Elastic File System (Amazon EFS) provides simple, scalable file storage for use with Amazon EC2 instances in the AWS Cloud. With Amazon EFS, storage capacity is elastic, growing and shrinking automatically as you add and remove files, so your applications have the storage they need, when they need it. For more information, see the User Guide."},{"ref":"AWS.EFS.html#create_access_point/3","title":"AWS.EFS.create_access_point/3","type":"function","doc":"Creates an EFS access point. An access point is an application-specific view into an EFS file system that applies an operating system user and group, and a file system path, to any file system request made through the access point. The operating system user and group override any identity information provided by the NFS client. The file system path is exposed as the access point&#39;s root directory. Applications using the access point can only access data in its own directory and below. To learn more, see Mounting a File System Using EFS Access Points. This operation requires permissions for the elasticfilesystem:CreateAccessPoint action."},{"ref":"AWS.EFS.html#create_file_system/3","title":"AWS.EFS.create_file_system/3","type":"function","doc":"Creates a new, empty file system. The operation requires a creation token in the request that Amazon EFS uses to ensure idempotent creation (calling the operation with same creation token has no effect). If a file system does not currently exist that is owned by the caller&#39;s AWS account with the specified creation token, this operation does the following: Creates a new, empty file system. The file system will have an Amazon EFS assigned ID, and an initial lifecycle state creating. Returns with the description of the created file system. Otherwise, this operation returns a FileSystemAlreadyExists error with the ID of the existing file system. For basic use cases, you can use a randomly generated UUID for the creation token. The idempotent operation allows you to retry a CreateFileSystem call without risk of creating an extra file system. This can happen when an initial call fails in a way that leaves it uncertain whether or not a file system was actually created. An example might be that a transport level timeout occurred or your connection was reset. As long as you use the same creation token, if the initial call had succeeded in creating a file system, the client can learn of its existence from the FileSystemAlreadyExists error. The CreateFileSystem call returns while the file system&#39;s lifecycle state is still creating. You can check the file system creation status by calling the DescribeFileSystems operation, which among other things returns the file system state. This operation also takes an optional PerformanceMode parameter that you choose for your file system. We recommend generalPurpose performance mode for most file systems. File systems using the maxIO performance mode can scale to higher levels of aggregate throughput and operations per second with a tradeoff of slightly higher latencies for most file operations. The performance mode can&#39;t be changed after the file system has been created. For more information, see Amazon EFS: Performance Modes. After the file system is fully created, Amazon EFS sets its lifecycle state to available, at which point you can create one or more mount targets for the file system in your VPC. For more information, see CreateMountTarget. You mount your Amazon EFS file system on an EC2 instances in your VPC by using the mount target. For more information, see Amazon EFS: How it Works. This operation requires permissions for the elasticfilesystem:CreateFileSystem action."},{"ref":"AWS.EFS.html#create_mount_target/3","title":"AWS.EFS.create_mount_target/3","type":"function","doc":"Creates a mount target for a file system. You can then mount the file system on EC2 instances by using the mount target. You can create one mount target in each Availability Zone in your VPC. All EC2 instances in a VPC within a given Availability Zone share a single mount target for a given file system. If you have multiple subnets in an Availability Zone, you create a mount target in one of the subnets. EC2 instances do not need to be in the same subnet as the mount target in order to access their file system. For more information, see Amazon EFS: How it Works. In the request, you also specify a file system ID for which you are creating the mount target and the file system&#39;s lifecycle state must be available. For more information, see DescribeFileSystems. In the request, you also provide a subnet ID, which determines the following: VPC in which Amazon EFS creates the mount target Availability Zone in which Amazon EFS creates the mount target IP address range from which Amazon EFS selects the IP address of the mount target (if you don&#39;t specify an IP address in the request) After creating the mount target, Amazon EFS returns a response that includes, a MountTargetId and an IpAddress. You use this IP address when mounting the file system in an EC2 instance. You can also use the mount target&#39;s DNS name when mounting the file system. The EC2 instance on which you mount the file system by using the mount target can resolve the mount target&#39;s DNS name to its IP address. For more information, see How it Works: Implementation Overview. Note that you can create mount targets for a file system in only one VPC, and there can be only one mount target per Availability Zone. That is, if the file system already has one or more mount targets created for it, the subnet specified in the request to add another mount target must meet the following requirements: Must belong to the same VPC as the subnets of the existing mount targets Must not be in the same Availability Zone as any of the subnets of the existing mount targets If the request satisfies the requirements, Amazon EFS does the following: Creates a new mount target in the specified subnet. Also creates a new network interface in the subnet as follows: If the request provides an IpAddress, Amazon EFS assigns that IP address to the network interface. Otherwise, Amazon EFS assigns a free address in the subnet (in the same way that the Amazon EC2 CreateNetworkInterface call does when a request does not specify a primary private IP address). If the request provides SecurityGroups, this network interface is associated with those security groups. Otherwise, it belongs to the default security group for the subnet&#39;s VPC. Assigns the description Mount target *fsmt-id* for file system *fs-id* where *fsmt-id* is the mount target ID, and *fs-id* is the FileSystemId. Sets the requesterManaged property of the network interface to true, and the requesterId value to EFS. Each Amazon EFS mount target has one corresponding requester-managed EC2 network interface. After the network interface is created, Amazon EFS sets the NetworkInterfaceId field in the mount target&#39;s description to the network interface ID, and the IpAddress field to its address. If network interface creation fails, the entire CreateMountTarget operation fails. The CreateMountTarget call returns only after creating the network interface, but while the mount target state is still creating, you can check the mount target creation status by calling the DescribeMountTargets operation, which among other things returns the mount target state. We recommend that you create a mount target in each of the Availability Zones. There are cost considerations for using a file system in an Availability Zone through a mount target created in another Availability Zone. For more information, see Amazon EFS. In addition, by always using a mount target local to the instance&#39;s Availability Zone, you eliminate a partial failure scenario. If the Availability Zone in which your mount target is created goes down, then you can&#39;t access your file system through that mount target. This operation requires permissions for the following action on the file system: elasticfilesystem:CreateMountTarget This operation also requires permissions for the following Amazon EC2 actions: ec2:DescribeSubnets ec2:DescribeNetworkInterfaces ec2:CreateNetworkInterface"},{"ref":"AWS.EFS.html#create_tags/4","title":"AWS.EFS.create_tags/4","type":"function","doc":"Creates or overwrites tags associated with a file system. Each tag is a key-value pair. If a tag key specified in the request already exists on the file system, this operation overwrites its value with the value provided in the request. If you add the Name tag to your file system, Amazon EFS returns it in the response to the DescribeFileSystems operation. This operation requires permission for the elasticfilesystem:CreateTags action."},{"ref":"AWS.EFS.html#delete_access_point/4","title":"AWS.EFS.delete_access_point/4","type":"function","doc":"Deletes the specified access point. After deletion is complete, new clients can no longer connect to the access points. Clients connected to the access point at the time of deletion will continue to function until they terminate their connection. This operation requires permissions for the elasticfilesystem:DeleteAccessPoint action."},{"ref":"AWS.EFS.html#delete_file_system/4","title":"AWS.EFS.delete_file_system/4","type":"function","doc":"Deletes a file system, permanently severing access to its contents. Upon return, the file system no longer exists and you can&#39;t access any contents of the deleted file system. You can&#39;t delete a file system that is in use. That is, if the file system has any mount targets, you must first delete them. For more information, see DescribeMountTargets and DeleteMountTarget. The DeleteFileSystem call returns while the file system state is still deleting. You can check the file system deletion status by calling the DescribeFileSystems operation, which returns a list of file systems in your account. If you pass file system ID or creation token for the deleted file system, the DescribeFileSystems returns a 404 FileSystemNotFound error. This operation requires permissions for the elasticfilesystem:DeleteFileSystem action."},{"ref":"AWS.EFS.html#delete_file_system_policy/4","title":"AWS.EFS.delete_file_system_policy/4","type":"function","doc":"Deletes the FileSystemPolicy for the specified file system. The default FileSystemPolicy goes into effect once the existing policy is deleted. For more information about the default file system policy, see Using Resource-based Policies with EFS. This operation requires permissions for the elasticfilesystem:DeleteFileSystemPolicy action."},{"ref":"AWS.EFS.html#delete_mount_target/4","title":"AWS.EFS.delete_mount_target/4","type":"function","doc":"Deletes the specified mount target. This operation forcibly breaks any mounts of the file system by using the mount target that is being deleted, which might disrupt instances or applications using those mounts. To avoid applications getting cut off abruptly, you might consider unmounting any mounts of the mount target, if feasible. The operation also deletes the associated network interface. Uncommitted writes might be lost, but breaking a mount target using this operation does not corrupt the file system itself. The file system you created remains. You can mount an EC2 instance in your VPC by using another mount target. This operation requires permissions for the following action on the file system: elasticfilesystem:DeleteMountTarget The DeleteMountTarget call returns while the mount target state is still deleting. You can check the mount target deletion by calling the DescribeMountTargets operation, which returns a list of mount target descriptions for the given file system. The operation also requires permissions for the following Amazon EC2 action on the mount target&#39;s network interface: ec2:DeleteNetworkInterface"},{"ref":"AWS.EFS.html#delete_tags/4","title":"AWS.EFS.delete_tags/4","type":"function","doc":"Deletes the specified tags from a file system. If the DeleteTags request includes a tag key that doesn&#39;t exist, Amazon EFS ignores it and doesn&#39;t cause an error. For more information about tags and related restrictions, see Tag Restrictions in the AWS Billing and Cost Management User Guide. This operation requires permissions for the elasticfilesystem:DeleteTags action."},{"ref":"AWS.EFS.html#describe_access_points/6","title":"AWS.EFS.describe_access_points/6","type":"function","doc":"Returns the description of a specific Amazon EFS access point if the AccessPointId is provided. If you provide an EFS FileSystemId, it returns descriptions of all access points for that file system. You can provide either an AccessPointId or a FileSystemId in the request, but not both. This operation requires permissions for the elasticfilesystem:DescribeAccessPoints action."},{"ref":"AWS.EFS.html#describe_backup_policy/3","title":"AWS.EFS.describe_backup_policy/3","type":"function","doc":"Returns the backup policy for the specified EFS file system."},{"ref":"AWS.EFS.html#describe_file_system_policy/3","title":"AWS.EFS.describe_file_system_policy/3","type":"function","doc":"Returns the FileSystemPolicy for the specified EFS file system. This operation requires permissions for the elasticfilesystem:DescribeFileSystemPolicy action."},{"ref":"AWS.EFS.html#describe_file_systems/6","title":"AWS.EFS.describe_file_systems/6","type":"function","doc":"Returns the description of a specific Amazon EFS file system if either the file system CreationToken or the FileSystemId is provided. Otherwise, it returns descriptions of all file systems owned by the caller&#39;s AWS account in the AWS Region of the endpoint that you&#39;re calling. When retrieving all file system descriptions, you can optionally specify the MaxItems parameter to limit the number of descriptions in a response. Currently, this number is automatically set to If more file system descriptions remain, Amazon EFS returns a NextMarker, an opaque token, in the response. In this case, you should send a subsequent request with the Marker request parameter set to the value of NextMarker. To retrieve a list of your file system descriptions, this operation is used in an iterative process, where DescribeFileSystems is called first without the Marker and then the operation continues to call it with the Marker parameter set to the value of the NextMarker from the previous response until the response has no NextMarker. The order of file systems returned in the response of one DescribeFileSystems call and the order of file systems returned across the responses of a multi-call iteration is unspecified. This operation requires permissions for the elasticfilesystem:DescribeFileSystems action."},{"ref":"AWS.EFS.html#describe_lifecycle_configuration/3","title":"AWS.EFS.describe_lifecycle_configuration/3","type":"function","doc":"Returns the current LifecycleConfiguration object for the specified Amazon EFS file system. EFS lifecycle management uses the LifecycleConfiguration object to identify which files to move to the EFS Infrequent Access (IA) storage class. For a file system without a LifecycleConfiguration object, the call returns an empty array in the response. This operation requires permissions for the elasticfilesystem:DescribeLifecycleConfiguration operation."},{"ref":"AWS.EFS.html#describe_mount_target_security_groups/3","title":"AWS.EFS.describe_mount_target_security_groups/3","type":"function","doc":"Returns the security groups currently in effect for a mount target. This operation requires that the network interface of the mount target has been created and the lifecycle state of the mount target is not deleted. This operation requires permissions for the following actions: elasticfilesystem:DescribeMountTargetSecurityGroups action on the mount target&#39;s file system. ec2:DescribeNetworkInterfaceAttribute action on the mount target&#39;s network interface."},{"ref":"AWS.EFS.html#describe_mount_targets/7","title":"AWS.EFS.describe_mount_targets/7","type":"function","doc":"Returns the descriptions of all the current mount targets, or a specific mount target, for a file system. When requesting all of the current mount targets, the order of mount targets returned in the response is unspecified. This operation requires permissions for the elasticfilesystem:DescribeMountTargets action, on either the file system ID that you specify in FileSystemId, or on the file system of the mount target that you specify in MountTargetId."},{"ref":"AWS.EFS.html#describe_tags/5","title":"AWS.EFS.describe_tags/5","type":"function","doc":"Returns the tags associated with a file system. The order of tags returned in the response of one DescribeTags call and the order of tags returned across the responses of a multiple-call iteration (when using pagination) is unspecified. This operation requires permissions for the elasticfilesystem:DescribeTags action."},{"ref":"AWS.EFS.html#list_tags_for_resource/5","title":"AWS.EFS.list_tags_for_resource/5","type":"function","doc":"Lists all tags for a top-level EFS resource. You must provide the ID of the resource that you want to retrieve the tags for. This operation requires permissions for the elasticfilesystem:DescribeAccessPoints action."},{"ref":"AWS.EFS.html#modify_mount_target_security_groups/4","title":"AWS.EFS.modify_mount_target_security_groups/4","type":"function","doc":"Modifies the set of security groups in effect for a mount target. When you create a mount target, Amazon EFS also creates a new network interface. For more information, see CreateMountTarget. This operation replaces the security groups in effect for the network interface associated with a mount target, with the SecurityGroups provided in the request. This operation requires that the network interface of the mount target has been created and the lifecycle state of the mount target is not deleted. The operation requires permissions for the following actions: elasticfilesystem:ModifyMountTargetSecurityGroups action on the mount target&#39;s file system. ec2:ModifyNetworkInterfaceAttribute action on the mount target&#39;s network interface."},{"ref":"AWS.EFS.html#put_backup_policy/4","title":"AWS.EFS.put_backup_policy/4","type":"function","doc":"Updates the file system&#39;s backup policy. Use this action to start or stop automatic backups of the file system."},{"ref":"AWS.EFS.html#put_file_system_policy/4","title":"AWS.EFS.put_file_system_policy/4","type":"function","doc":"Applies an Amazon EFS FileSystemPolicy to an Amazon EFS file system. A file system policy is an IAM resource-based policy and can contain multiple policy statements. A file system always has exactly one file system policy, which can be the default policy or an explicit policy set or updated using this API operation. When an explicit policy is set, it overrides the default policy. For more information about the default file system policy, see Default EFS File System Policy. This operation requires permissions for the elasticfilesystem:PutFileSystemPolicy action."},{"ref":"AWS.EFS.html#put_lifecycle_configuration/4","title":"AWS.EFS.put_lifecycle_configuration/4","type":"function","doc":"Enables lifecycle management by creating a new LifecycleConfiguration object. A LifecycleConfiguration object defines when files in an Amazon EFS file system are automatically transitioned to the lower-cost EFS Infrequent Access (IA) storage class. A LifecycleConfiguration applies to all files in a file system. Each Amazon EFS file system supports one lifecycle configuration, which applies to all files in the file system. If a LifecycleConfiguration object already exists for the specified file system, a PutLifecycleConfiguration call modifies the existing configuration. A PutLifecycleConfiguration call with an empty LifecyclePolicies array in the request body deletes any existing LifecycleConfiguration and disables lifecycle management. In the request, specify the following: The ID for the file system for which you are enabling, disabling, or modifying lifecycle management. A LifecyclePolicies array of LifecyclePolicy objects that define when files are moved to the IA storage class. The array can contain only one LifecyclePolicy item. This operation requires permissions for the elasticfilesystem:PutLifecycleConfiguration operation. To apply a LifecycleConfiguration object to an encrypted file system, you need the same AWS Key Management Service (AWS KMS) permissions as when you created the encrypted file system."},{"ref":"AWS.EFS.html#tag_resource/4","title":"AWS.EFS.tag_resource/4","type":"function","doc":"Creates a tag for an EFS resource. You can create tags for EFS file systems and access points using this API operation. This operation requires permissions for the elasticfilesystem:TagResource action."},{"ref":"AWS.EFS.html#untag_resource/4","title":"AWS.EFS.untag_resource/4","type":"function","doc":"Removes tags from an EFS resource. You can remove tags from EFS file systems and access points using this API operation. This operation requires permissions for the elasticfilesystem:UntagResource action."},{"ref":"AWS.EFS.html#update_file_system/4","title":"AWS.EFS.update_file_system/4","type":"function","doc":"Updates the throughput mode or the amount of provisioned throughput of an existing file system."},{"ref":"AWS.EKS.html","title":"AWS.EKS","type":"module","doc":"Amazon Elastic Kubernetes Service (Amazon EKS) is a managed service that makes it easy for you to run Kubernetes on AWS without needing to stand up or maintain your own Kubernetes control plane. Kubernetes is an open-source system for automating the deployment, scaling, and management of containerized applications. Amazon EKS runs up-to-date versions of the open-source Kubernetes software, so you can use all the existing plugins and tooling from the Kubernetes community. Applications running on Amazon EKS are fully compatible with applications running on any standard Kubernetes environment, whether running in on-premises data centers or public clouds. This means that you can easily migrate any standard Kubernetes application to Amazon EKS without any code modification required."},{"ref":"AWS.EKS.html#create_cluster/3","title":"AWS.EKS.create_cluster/3","type":"function","doc":"Creates an Amazon EKS control plane. The Amazon EKS control plane consists of control plane instances that run the Kubernetes software, such as etcd and the API server. The control plane runs in an account managed by AWS, and the Kubernetes API is exposed via the Amazon EKS API server endpoint. Each Amazon EKS cluster control plane is single-tenant and unique and runs on its own set of Amazon EC2 instances. The cluster control plane is provisioned across multiple Availability Zones and fronted by an Elastic Load Balancing Network Load Balancer. Amazon EKS also provisions elastic network interfaces in your VPC subnets to provide connectivity from the control plane instances to the worker nodes (for example, to support kubectl exec, logs, and proxy data flows). Amazon EKS worker nodes run in your AWS account and connect to your cluster&#39;s control plane via the Kubernetes API server endpoint and a certificate file that is created for your cluster. You can use the endpointPublicAccess and endpointPrivateAccess parameters to enable or disable public and private access to your cluster&#39;s Kubernetes API server endpoint. By default, public access is enabled, and private access is disabled. For more information, see Amazon EKS Cluster Endpoint Access Control in the Amazon EKS User Guide . You can use the logging parameter to enable or disable exporting the Kubernetes control plane logs for your cluster to CloudWatch Logs. By default, cluster control plane logs aren&#39;t exported to CloudWatch Logs. For more information, see Amazon EKS Cluster Control Plane Logs in the Amazon EKS User Guide . CloudWatch Logs ingestion, archive storage, and data scanning rates apply to exported control plane logs. For more information, see Amazon CloudWatch Pricing. Cluster creation typically takes between 10 and 15 minutes. After you create an Amazon EKS cluster, you must configure your Kubernetes tooling to communicate with the API server and launch worker nodes into your cluster. For more information, see Managing Cluster Authentication and Launching Amazon EKS Worker Nodes in the Amazon EKS User Guide."},{"ref":"AWS.EKS.html#create_fargate_profile/4","title":"AWS.EKS.create_fargate_profile/4","type":"function","doc":"Creates an AWS Fargate profile for your Amazon EKS cluster. You must have at least one Fargate profile in a cluster to be able to run pods on Fargate. The Fargate profile allows an administrator to declare which pods run on Fargate and specify which pods run on which Fargate profile. This declaration is done through the profiles selectors. Each profile can have up to five selectors that contain a namespace and labels. A namespace is required for every selector. The label field consists of multiple optional key-value pairs. Pods that match the selectors are scheduled on Fargate. If a to-be-scheduled pod matches any of the selectors in the Fargate profile, then that pod is run on Fargate. When you create a Fargate profile, you must specify a pod execution role to use with the pods that are scheduled with the profile. This role is added to the cluster&#39;s Kubernetes Role Based Access Control (RBAC) for authorization so that the kubelet that is running on the Fargate infrastructure can register with your Amazon EKS cluster so that it can appear in your cluster as a node. The pod execution role also provides IAM permissions to the Fargate infrastructure to allow read access to Amazon ECR image repositories. For more information, see Pod Execution Role in the Amazon EKS User Guide. Fargate profiles are immutable. However, you can create a new updated profile to replace an existing profile and then delete the original after the updated profile has finished creating. If any Fargate profiles in a cluster are in the DELETING status, you must wait for that Fargate profile to finish deleting before you can create any other profiles in that cluster. For more information, see AWS Fargate Profile in the Amazon EKS User Guide."},{"ref":"AWS.EKS.html#create_nodegroup/4","title":"AWS.EKS.create_nodegroup/4","type":"function","doc":"Creates a managed worker node group for an Amazon EKS cluster. You can only create a node group for your cluster that is equal to the current Kubernetes version for the cluster. All node groups are created with the latest AMI release version for the respective minor Kubernetes version of the cluster, unless you deploy a custom AMI using a launch template. For more information about using launch templates, see Launch template support. An Amazon EKS managed node group is an Amazon EC2 Auto Scaling group and associated Amazon EC2 instances that are managed by AWS for an Amazon EKS cluster. Each node group uses a version of the Amazon EKS-optimized Amazon Linux 2 AMI. For more information, see Managed Node Groups in the Amazon EKS User Guide."},{"ref":"AWS.EKS.html#delete_cluster/4","title":"AWS.EKS.delete_cluster/4","type":"function","doc":"Deletes the Amazon EKS cluster control plane. If you have active services in your cluster that are associated with a load balancer, you must delete those services before deleting the cluster so that the load balancers are deleted properly. Otherwise, you can have orphaned resources in your VPC that prevent you from being able to delete the VPC. For more information, see Deleting a Cluster in the Amazon EKS User Guide. If you have managed node groups or Fargate profiles attached to the cluster, you must delete them first. For more information, see DeleteNodegroup and DeleteFargateProfile."},{"ref":"AWS.EKS.html#delete_fargate_profile/5","title":"AWS.EKS.delete_fargate_profile/5","type":"function","doc":"Deletes an AWS Fargate profile. When you delete a Fargate profile, any pods running on Fargate that were created with the profile are deleted. If those pods match another Fargate profile, then they are scheduled on Fargate with that profile. If they no longer match any Fargate profiles, then they are not scheduled on Fargate and they may remain in a pending state. Only one Fargate profile in a cluster can be in the DELETING status at a time. You must wait for a Fargate profile to finish deleting before you can delete any other profiles in that cluster."},{"ref":"AWS.EKS.html#delete_nodegroup/5","title":"AWS.EKS.delete_nodegroup/5","type":"function","doc":"Deletes an Amazon EKS node group for a cluster."},{"ref":"AWS.EKS.html#describe_cluster/3","title":"AWS.EKS.describe_cluster/3","type":"function","doc":"Returns descriptive information about an Amazon EKS cluster. The API server endpoint and certificate authority data returned by this operation are required for kubelet and kubectl to communicate with your Kubernetes API server. For more information, see Create a kubeconfig for Amazon EKS. The API server endpoint and certificate authority data aren&#39;t available until the cluster reaches the ACTIVE state."},{"ref":"AWS.EKS.html#describe_fargate_profile/4","title":"AWS.EKS.describe_fargate_profile/4","type":"function","doc":"Returns descriptive information about an AWS Fargate profile."},{"ref":"AWS.EKS.html#describe_nodegroup/4","title":"AWS.EKS.describe_nodegroup/4","type":"function","doc":"Returns descriptive information about an Amazon EKS node group."},{"ref":"AWS.EKS.html#describe_update/5","title":"AWS.EKS.describe_update/5","type":"function","doc":"Returns descriptive information about an update against your Amazon EKS cluster or associated managed node group. When the status of the update is Succeeded, the update is complete. If an update fails, the status is Failed, and an error detail explains the reason for the failure."},{"ref":"AWS.EKS.html#list_clusters/4","title":"AWS.EKS.list_clusters/4","type":"function","doc":"Lists the Amazon EKS clusters in your AWS account in the specified Region."},{"ref":"AWS.EKS.html#list_fargate_profiles/5","title":"AWS.EKS.list_fargate_profiles/5","type":"function","doc":"Lists the AWS Fargate profiles associated with the specified cluster in your AWS account in the specified Region."},{"ref":"AWS.EKS.html#list_nodegroups/5","title":"AWS.EKS.list_nodegroups/5","type":"function","doc":"Lists the Amazon EKS managed node groups associated with the specified cluster in your AWS account in the specified Region. Self-managed node groups are not listed."},{"ref":"AWS.EKS.html#list_tags_for_resource/3","title":"AWS.EKS.list_tags_for_resource/3","type":"function","doc":"List the tags for an Amazon EKS resource."},{"ref":"AWS.EKS.html#list_updates/6","title":"AWS.EKS.list_updates/6","type":"function","doc":"Lists the updates associated with an Amazon EKS cluster or managed node group in your AWS account, in the specified Region."},{"ref":"AWS.EKS.html#tag_resource/4","title":"AWS.EKS.tag_resource/4","type":"function","doc":"Associates the specified tags to a resource with the specified resourceArn. If existing tags on a resource are not specified in the request parameters, they are not changed. When a resource is deleted, the tags associated with that resource are deleted as well. Tags that you create for Amazon EKS resources do not propagate to any other resources associated with the cluster. For example, if you tag a cluster with this operation, that tag does not automatically propagate to the subnets and worker nodes associated with the cluster."},{"ref":"AWS.EKS.html#untag_resource/4","title":"AWS.EKS.untag_resource/4","type":"function","doc":"Deletes specified tags from a resource."},{"ref":"AWS.EKS.html#update_cluster_config/4","title":"AWS.EKS.update_cluster_config/4","type":"function","doc":"Updates an Amazon EKS cluster configuration. Your cluster continues to function during the update. The response output includes an update ID that you can use to track the status of your cluster update with the DescribeUpdate API operation. You can use this API operation to enable or disable exporting the Kubernetes control plane logs for your cluster to CloudWatch Logs. By default, cluster control plane logs aren&#39;t exported to CloudWatch Logs. For more information, see Amazon EKS Cluster Control Plane Logs in the Amazon EKS User Guide . CloudWatch Logs ingestion, archive storage, and data scanning rates apply to exported control plane logs. For more information, see Amazon CloudWatch Pricing. You can also use this API operation to enable or disable public and private access to your cluster&#39;s Kubernetes API server endpoint. By default, public access is enabled, and private access is disabled. For more information, see Amazon EKS Cluster Endpoint Access Control in the Amazon EKS User Guide . At this time, you can not update the subnets or security group IDs for an existing cluster. Cluster updates are asynchronous, and they should finish within a few minutes. During an update, the cluster status moves to UPDATING (this status transition is eventually consistent). When the update is complete (either Failed or Successful), the cluster status moves to Active."},{"ref":"AWS.EKS.html#update_cluster_version/4","title":"AWS.EKS.update_cluster_version/4","type":"function","doc":"Updates an Amazon EKS cluster to the specified Kubernetes version. Your cluster continues to function during the update. The response output includes an update ID that you can use to track the status of your cluster update with the DescribeUpdate API operation. Cluster updates are asynchronous, and they should finish within a few minutes. During an update, the cluster status moves to UPDATING (this status transition is eventually consistent). When the update is complete (either Failed or Successful), the cluster status moves to Active. If your cluster has managed node groups attached to it, all of your node groups Kubernetes versions must match the clusters Kubernetes version in order to update the cluster to a new Kubernetes version."},{"ref":"AWS.EKS.html#update_nodegroup_config/5","title":"AWS.EKS.update_nodegroup_config/5","type":"function","doc":"Updates an Amazon EKS managed node group configuration. Your node group continues to function during the update. The response output includes an update ID that you can use to track the status of your node group update with the DescribeUpdate API operation. Currently you can update the Kubernetes labels for a node group or the scaling configuration."},{"ref":"AWS.EKS.html#update_nodegroup_version/5","title":"AWS.EKS.update_nodegroup_version/5","type":"function","doc":"Updates the Kubernetes version or AMI version of an Amazon EKS managed node group. You can update a node group using a launch template only if the node group was originally deployed with a launch template. If you need to update a custom AMI in a node group that was deployed with a launch template, then update your custom AMI, specify the new ID in a new version of the launch template, and then update the node group to the new version of the launch template. If you update without a launch template, then you can update to the latest available AMI version of a node group&#39;s current Kubernetes version by not specifying a Kubernetes version in the request. You can update to the latest AMI version of your cluster&#39;s current Kubernetes version by specifying your cluster&#39;s Kubernetes version in the request. For more information, see Amazon EKS-Optimized Linux AMI Versions in the Amazon EKS User Guide. You cannot roll back a node group to an earlier Kubernetes version or AMI version. When a node in a managed node group is terminated due to a scaling action or update, the pods in that node are drained first. Amazon EKS attempts to drain the nodes gracefully and will fail if it is unable to do so. You can force the update if Amazon EKS is unable to drain the nodes as a result of a pod disruption budget issue."},{"ref":"AWS.EMR.html","title":"AWS.EMR","type":"module","doc":"Amazon EMR is a web service that makes it easy to process large amounts of data efficiently. Amazon EMR uses Hadoop processing combined with several AWS products to do tasks such as web indexing, data mining, log file analysis, machine learning, scientific simulation, and data warehousing."},{"ref":"AWS.EMR.html#add_instance_fleet/3","title":"AWS.EMR.add_instance_fleet/3","type":"function","doc":"Adds an instance fleet to a running cluster. The instance fleet configuration is available only in Amazon EMR versions 4.8.0 and later, excluding 5.0.x."},{"ref":"AWS.EMR.html#add_instance_groups/3","title":"AWS.EMR.add_instance_groups/3","type":"function","doc":"Adds one or more instance groups to a running cluster."},{"ref":"AWS.EMR.html#add_job_flow_steps/3","title":"AWS.EMR.add_job_flow_steps/3","type":"function","doc":"AddJobFlowSteps adds new steps to a running cluster. A maximum of 256 steps are allowed in each job flow. If your cluster is long-running (such as a Hive data warehouse) or complex, you may require more than 256 steps to process your data. You can bypass the 256-step limitation in various ways, including using SSH to connect to the master node and submitting queries directly to the software running on the master node, such as Hive and Hadoop. For more information on how to do this, see Add More than 256 Steps to a Cluster in the Amazon EMR Management Guide. A step specifies the location of a JAR file stored either on the master node of the cluster or in Amazon S3. Each step is performed by the main function of the main class of the JAR file. The main class can be specified either in the manifest of the JAR or by using the MainFunction parameter of the step. Amazon EMR executes each step in the order listed. For a step to be considered complete, the main function must exit with a zero exit code and all Hadoop jobs started while the step was running must have completed and run successfully. You can only add steps to a cluster that is in one of the following states: STARTING, BOOTSTRAPPING, RUNNING, or WAITING."},{"ref":"AWS.EMR.html#add_tags/3","title":"AWS.EMR.add_tags/3","type":"function","doc":"Adds tags to an Amazon EMR resource. Tags make it easier to associate clusters in various ways, such as grouping clusters to track your Amazon EMR resource allocation costs. For more information, see Tag Clusters."},{"ref":"AWS.EMR.html#cancel_steps/3","title":"AWS.EMR.cancel_steps/3","type":"function","doc":"Cancels a pending step or steps in a running cluster. Available only in Amazon EMR versions 4.8.0 and later, excluding version 5.0.0. A maximum of 256 steps are allowed in each CancelSteps request. CancelSteps is idempotent but asynchronous; it does not guarantee a step will be canceled, even if the request is successfully submitted. You can only cancel steps that are in a PENDING state."},{"ref":"AWS.EMR.html#create_security_configuration/3","title":"AWS.EMR.create_security_configuration/3","type":"function","doc":"Creates a security configuration, which is stored in the service and can be specified when a cluster is created."},{"ref":"AWS.EMR.html#delete_security_configuration/3","title":"AWS.EMR.delete_security_configuration/3","type":"function","doc":"Deletes a security configuration."},{"ref":"AWS.EMR.html#describe_cluster/3","title":"AWS.EMR.describe_cluster/3","type":"function","doc":"Provides cluster-level details including status, hardware and software configuration, VPC settings, and so on."},{"ref":"AWS.EMR.html#describe_job_flows/3","title":"AWS.EMR.describe_job_flows/3","type":"function","doc":"This API is deprecated and will eventually be removed. We recommend you use ListClusters, DescribeCluster, ListSteps, ListInstanceGroups and ListBootstrapActions instead. DescribeJobFlows returns a list of job flows that match all of the supplied parameters. The parameters can include a list of job flow IDs, job flow states, and restrictions on job flow creation date and time. Regardless of supplied parameters, only job flows created within the last two months are returned. If no parameters are supplied, then job flows matching either of the following criteria are returned: Job flows created and completed in the last two weeks Job flows created within the last two months that are in one of the following states: RUNNING, WAITING, SHUTTING_DOWN, STARTING Amazon EMR can return a maximum of 512 job flow descriptions."},{"ref":"AWS.EMR.html#describe_notebook_execution/3","title":"AWS.EMR.describe_notebook_execution/3","type":"function","doc":"Provides details of a notebook execution."},{"ref":"AWS.EMR.html#describe_security_configuration/3","title":"AWS.EMR.describe_security_configuration/3","type":"function","doc":"Provides the details of a security configuration by returning the configuration JSON."},{"ref":"AWS.EMR.html#describe_step/3","title":"AWS.EMR.describe_step/3","type":"function","doc":"Provides more detail about the cluster step."},{"ref":"AWS.EMR.html#get_block_public_access_configuration/3","title":"AWS.EMR.get_block_public_access_configuration/3","type":"function","doc":"Returns the Amazon EMR block public access configuration for your AWS account in the current Region. For more information see Configure Block Public Access for Amazon EMR in the Amazon EMR Management Guide."},{"ref":"AWS.EMR.html#get_managed_scaling_policy/3","title":"AWS.EMR.get_managed_scaling_policy/3","type":"function","doc":"Fetches the attached managed scaling policy for an Amazon EMR cluster."},{"ref":"AWS.EMR.html#list_bootstrap_actions/3","title":"AWS.EMR.list_bootstrap_actions/3","type":"function","doc":"Provides information about the bootstrap actions associated with a cluster."},{"ref":"AWS.EMR.html#list_clusters/3","title":"AWS.EMR.list_clusters/3","type":"function","doc":"Provides the status of all clusters visible to this AWS account. Allows you to filter the list of clusters based on certain criteria; for example, filtering by cluster creation date and time or by status. This call returns a maximum of 50 clusters per call, but returns a marker to track the paging of the cluster list across multiple ListClusters calls."},{"ref":"AWS.EMR.html#list_instance_fleets/3","title":"AWS.EMR.list_instance_fleets/3","type":"function","doc":"Lists all available details about the instance fleets in a cluster. The instance fleet configuration is available only in Amazon EMR versions 4.8.0 and later, excluding 5.0.x versions."},{"ref":"AWS.EMR.html#list_instance_groups/3","title":"AWS.EMR.list_instance_groups/3","type":"function","doc":"Provides all available details about the instance groups in a cluster."},{"ref":"AWS.EMR.html#list_instances/3","title":"AWS.EMR.list_instances/3","type":"function","doc":"Provides information for all active EC2 instances and EC2 instances terminated in the last 30 days, up to a maximum of 2,000. EC2 instances in any of the following states are considered active: AWAITING_FULFILLMENT, PROVISIONING, BOOTSTRAPPING, RUNNING."},{"ref":"AWS.EMR.html#list_notebook_executions/3","title":"AWS.EMR.list_notebook_executions/3","type":"function","doc":"Provides summaries of all notebook executions. You can filter the list based on multiple criteria such as status, time range, and editor id. Returns a maximum of 50 notebook executions and a marker to track the paging of a longer notebook execution list across multiple ListNotebookExecution calls."},{"ref":"AWS.EMR.html#list_security_configurations/3","title":"AWS.EMR.list_security_configurations/3","type":"function","doc":"Lists all the security configurations visible to this account, providing their creation dates and times, and their names. This call returns a maximum of 50 clusters per call, but returns a marker to track the paging of the cluster list across multiple ListSecurityConfigurations calls."},{"ref":"AWS.EMR.html#list_steps/3","title":"AWS.EMR.list_steps/3","type":"function","doc":"Provides a list of steps for the cluster in reverse order unless you specify stepIds with the request of filter by StepStates. You can specify a maximum of ten stepIDs."},{"ref":"AWS.EMR.html#modify_cluster/3","title":"AWS.EMR.modify_cluster/3","type":"function","doc":"Modifies the number of steps that can be executed concurrently for the cluster specified using ClusterID."},{"ref":"AWS.EMR.html#modify_instance_fleet/3","title":"AWS.EMR.modify_instance_fleet/3","type":"function","doc":"Modifies the target On-Demand and target Spot capacities for the instance fleet with the specified InstanceFleetID within the cluster specified using ClusterID. The call either succeeds or fails atomically. The instance fleet configuration is available only in Amazon EMR versions 4.8.0 and later, excluding 5.0.x versions."},{"ref":"AWS.EMR.html#modify_instance_groups/3","title":"AWS.EMR.modify_instance_groups/3","type":"function","doc":"ModifyInstanceGroups modifies the number of nodes and configuration settings of an instance group. The input parameters include the new target instance count for the group and the instance group ID. The call will either succeed or fail atomically."},{"ref":"AWS.EMR.html#put_auto_scaling_policy/3","title":"AWS.EMR.put_auto_scaling_policy/3","type":"function","doc":"Creates or updates an automatic scaling policy for a core instance group or task instance group in an Amazon EMR cluster. The automatic scaling policy defines how an instance group dynamically adds and terminates EC2 instances in response to the value of a CloudWatch metric."},{"ref":"AWS.EMR.html#put_block_public_access_configuration/3","title":"AWS.EMR.put_block_public_access_configuration/3","type":"function","doc":"Creates or updates an Amazon EMR block public access configuration for your AWS account in the current Region. For more information see Configure Block Public Access for Amazon EMR in the Amazon EMR Management Guide."},{"ref":"AWS.EMR.html#put_managed_scaling_policy/3","title":"AWS.EMR.put_managed_scaling_policy/3","type":"function","doc":"Creates or updates a managed scaling policy for an Amazon EMR cluster. The managed scaling policy defines the limits for resources, such as EC2 instances that can be added or terminated from a cluster. The policy only applies to the core and task nodes. The master node cannot be scaled after initial configuration."},{"ref":"AWS.EMR.html#remove_auto_scaling_policy/3","title":"AWS.EMR.remove_auto_scaling_policy/3","type":"function","doc":"Removes an automatic scaling policy from a specified instance group within an EMR cluster."},{"ref":"AWS.EMR.html#remove_managed_scaling_policy/3","title":"AWS.EMR.remove_managed_scaling_policy/3","type":"function","doc":"Removes a managed scaling policy from a specified EMR cluster."},{"ref":"AWS.EMR.html#remove_tags/3","title":"AWS.EMR.remove_tags/3","type":"function","doc":"Removes tags from an Amazon EMR resource. Tags make it easier to associate clusters in various ways, such as grouping clusters to track your Amazon EMR resource allocation costs. For more information, see Tag Clusters. The following example removes the stack tag with value Prod from a cluster:"},{"ref":"AWS.EMR.html#run_job_flow/3","title":"AWS.EMR.run_job_flow/3","type":"function","doc":"RunJobFlow creates and starts running a new cluster (job flow). The cluster runs the steps specified. After the steps complete, the cluster stops and the HDFS partition is lost. To prevent loss of data, configure the last step of the job flow to store results in Amazon S3. If the JobFlowInstancesConfig KeepJobFlowAliveWhenNoSteps parameter is set to TRUE, the cluster transitions to the WAITING state rather than shutting down after the steps have completed. For additional protection, you can set the JobFlowInstancesConfig TerminationProtected parameter to TRUE to lock the cluster and prevent it from being terminated by API call, user intervention, or in the event of a job flow error. A maximum of 256 steps are allowed in each job flow. If your cluster is long-running (such as a Hive data warehouse) or complex, you may require more than 256 steps to process your data. You can bypass the 256-step limitation in various ways, including using the SSH shell to connect to the master node and submitting queries directly to the software running on the master node, such as Hive and Hadoop. For more information on how to do this, see Add More than 256 Steps to a Cluster in the Amazon EMR Management Guide. For long running clusters, we recommend that you periodically store your results. The instance fleets configuration is available only in Amazon EMR versions 4.8.0 and later, excluding 5.0.x versions. The RunJobFlow request can contain InstanceFleets parameters or InstanceGroups parameters, but not both."},{"ref":"AWS.EMR.html#set_termination_protection/3","title":"AWS.EMR.set_termination_protection/3","type":"function","doc":"SetTerminationProtection locks a cluster (job flow) so the EC2 instances in the cluster cannot be terminated by user intervention, an API call, or in the event of a job-flow error. The cluster still terminates upon successful completion of the job flow. Calling SetTerminationProtection on a cluster is similar to calling the Amazon EC2 DisableAPITermination API on all EC2 instances in a cluster. SetTerminationProtection is used to prevent accidental termination of a cluster and to ensure that in the event of an error, the instances persist so that you can recover any data stored in their ephemeral instance storage. To terminate a cluster that has been locked by setting SetTerminationProtection to true, you must first unlock the job flow by a subsequent call to SetTerminationProtection in which you set the value to false. For more information, seeManaging Cluster Termination in the Amazon EMR Management Guide."},{"ref":"AWS.EMR.html#set_visible_to_all_users/3","title":"AWS.EMR.set_visible_to_all_users/3","type":"function","doc":"Sets the Cluster$VisibleToAllUsers value, which determines whether the cluster is visible to all IAM users of the AWS account associated with the cluster. Only the IAM user who created the cluster or the AWS account root user can call this action. The default value, true, indicates that all IAM users in the AWS account can perform cluster actions if they have the proper IAM policy permissions. If set to false, only the IAM user that created the cluster can perform actions. This action works on running clusters. You can override the default true setting when you create a cluster by using the VisibleToAllUsers parameter with RunJobFlow."},{"ref":"AWS.EMR.html#start_notebook_execution/3","title":"AWS.EMR.start_notebook_execution/3","type":"function","doc":"Starts a notebook execution."},{"ref":"AWS.EMR.html#stop_notebook_execution/3","title":"AWS.EMR.stop_notebook_execution/3","type":"function","doc":"Stops a notebook execution."},{"ref":"AWS.EMR.html#terminate_job_flows/3","title":"AWS.EMR.terminate_job_flows/3","type":"function","doc":"TerminateJobFlows shuts a list of clusters (job flows) down. When a job flow is shut down, any step not yet completed is canceled and the EC2 instances on which the cluster is running are stopped. Any log files not already saved are uploaded to Amazon S3 if a LogUri was specified when the cluster was created. The maximum number of clusters allowed is 10. The call to TerminateJobFlows is asynchronous. Depending on the configuration of the cluster, it may take up to 1-5 minutes for the cluster to completely terminate and release allocated resources, such as Amazon EC2 instances."},{"ref":"AWS.ElastiCache.html","title":"AWS.ElastiCache","type":"module","doc":"Amazon ElastiCache Amazon ElastiCache is a web service that makes it easier to set up, operate, and scale a distributed cache in the cloud. With ElastiCache, customers get all of the benefits of a high-performance, in-memory cache with less of the administrative burden involved in launching and managing a distributed cache. The service makes setup, scaling, and cluster failure handling much simpler than in a self-managed cache deployment. In addition, through integration with Amazon CloudWatch, customers get enhanced visibility into the key performance statistics associated with their cache and can receive alarms if a part of their cache runs hot."},{"ref":"AWS.ElastiCache.html#add_tags_to_resource/3","title":"AWS.ElastiCache.add_tags_to_resource/3","type":"function","doc":"Adds up to 50 cost allocation tags to the named resource. A cost allocation tag is a key-value pair where the key and value are case-sensitive. You can use cost allocation tags to categorize and track your AWS costs. When you apply tags to your ElastiCache resources, AWS generates a cost allocation report as a comma-separated value (CSV) file with your usage and costs aggregated by your tags. You can apply tags that represent business categories (such as cost centers, application names, or owners) to organize your costs across multiple services. For more information, see Using Cost Allocation Tags in Amazon ElastiCache in the ElastiCache User Guide."},{"ref":"AWS.ElastiCache.html#authorize_cache_security_group_ingress/3","title":"AWS.ElastiCache.authorize_cache_security_group_ingress/3","type":"function","doc":"Allows network ingress to a cache security group. Applications using ElastiCache must be running on Amazon EC2, and Amazon EC2 security groups are used as the authorization mechanism. You cannot authorize ingress from an Amazon EC2 security group in one region to an ElastiCache cluster in another region."},{"ref":"AWS.ElastiCache.html#batch_apply_update_action/3","title":"AWS.ElastiCache.batch_apply_update_action/3","type":"function","doc":"Apply the service update. For more information on service updates and applying them, see Applying Service Updates."},{"ref":"AWS.ElastiCache.html#batch_stop_update_action/3","title":"AWS.ElastiCache.batch_stop_update_action/3","type":"function","doc":"Stop the service update. For more information on service updates and stopping them, see Stopping Service Updates."},{"ref":"AWS.ElastiCache.html#complete_migration/3","title":"AWS.ElastiCache.complete_migration/3","type":"function","doc":"Complete the migration of data."},{"ref":"AWS.ElastiCache.html#copy_snapshot/3","title":"AWS.ElastiCache.copy_snapshot/3","type":"function","doc":"Makes a copy of an existing snapshot. This operation is valid for Redis only. Users or groups that have permissions to use the CopySnapshot operation can create their own Amazon S3 buckets and copy snapshots to it. To control access to your snapshots, use an IAM policy to control who has the ability to use the CopySnapshot operation. For more information about using IAM to control the use of ElastiCache operations, see Exporting Snapshots and Authentication &amp; Access Control. You could receive the following error messages. Error Messages Error Message: The S3 bucket %s is outside of the region. Solution: Create an Amazon S3 bucket in the same region as your snapshot. For more information, see Step 1: Create an Amazon S3 Bucket in the ElastiCache User Guide. Error Message: The S3 bucket %s does not exist. Solution: Create an Amazon S3 bucket in the same region as your snapshot. For more information, see Step 1: Create an Amazon S3 Bucket in the ElastiCache User Guide. Error Message: The S3 bucket %s is not owned by the authenticated user. Solution: Create an Amazon S3 bucket in the same region as your snapshot. For more information, see Step 1: Create an Amazon S3 Bucket in the ElastiCache User Guide. Error Message: The authenticated user does not have sufficient permissions to perform the desired activity. Solution: Contact your system administrator to get the needed permissions. Error Message: The S3 bucket %s already contains an object with key %s. Solution: Give the TargetSnapshotName a new and unique value. If exporting a snapshot, you could alternatively create a new Amazon S3 bucket and use this same value for TargetSnapshotName. Error Message: ElastiCache has not been granted READ permissions %s on the S3 Bucket. Solution: Add List and Read permissions on the bucket. For more information, see Step 2: Grant ElastiCache Access to Your Amazon S3 Bucket in the ElastiCache User Guide. Error Message: ElastiCache has not been granted WRITE permissions %s on the S3 Bucket. Solution: Add Upload/Delete permissions on the bucket. For more information, see Step 2: Grant ElastiCache Access to Your Amazon S3 Bucket in the ElastiCache User Guide. Error Message: ElastiCache has not been granted READ_ACP permissions %s on the S3 Bucket. Solution: Add View Permissions on the bucket. For more information, see Step 2: Grant ElastiCache Access to Your Amazon S3 Bucket in the ElastiCache User Guide."},{"ref":"AWS.ElastiCache.html#create_cache_cluster/3","title":"AWS.ElastiCache.create_cache_cluster/3","type":"function","doc":"Creates a cluster. All nodes in the cluster run the same protocol-compliant cache engine software, either Memcached or Redis. This operation is not supported for Redis (cluster mode enabled) clusters."},{"ref":"AWS.ElastiCache.html#create_cache_parameter_group/3","title":"AWS.ElastiCache.create_cache_parameter_group/3","type":"function","doc":"Creates a new Amazon ElastiCache cache parameter group. An ElastiCache cache parameter group is a collection of parameters and their values that are applied to all of the nodes in any cluster or replication group using the CacheParameterGroup. A newly created CacheParameterGroup is an exact duplicate of the default parameter group for the CacheParameterGroupFamily. To customize the newly created CacheParameterGroup you can change the values of specific parameters. For more information, see: * ModifyCacheParameterGroup in the ElastiCache API Reference. Parameters and Parameter Groups in the ElastiCache User Guide."},{"ref":"AWS.ElastiCache.html#create_cache_security_group/3","title":"AWS.ElastiCache.create_cache_security_group/3","type":"function","doc":"Creates a new cache security group. Use a cache security group to control access to one or more clusters. Cache security groups are only used when you are creating a cluster outside of an Amazon Virtual Private Cloud (Amazon VPC). If you are creating a cluster inside of a VPC, use a cache subnet group instead. For more information, see CreateCacheSubnetGroup."},{"ref":"AWS.ElastiCache.html#create_cache_subnet_group/3","title":"AWS.ElastiCache.create_cache_subnet_group/3","type":"function","doc":"Creates a new cache subnet group. Use this parameter only when you are creating a cluster in an Amazon Virtual Private Cloud (Amazon VPC)."},{"ref":"AWS.ElastiCache.html#create_global_replication_group/3","title":"AWS.ElastiCache.create_global_replication_group/3","type":"function","doc":"Global Datastore for Redis offers fully managed, fast, reliable and secure cross-region replication. Using Global Datastore for Redis, you can create cross-region read replica clusters for ElastiCache for Redis to enable low-latency reads and disaster recovery across regions. For more information, see Replication Across Regions Using Global Datastore. The GlobalReplicationGroupIdSuffix is the name of the Global Datastore. The PrimaryReplicationGroupId represents the name of the primary cluster that accepts writes and will replicate updates to the secondary cluster."},{"ref":"AWS.ElastiCache.html#create_replication_group/3","title":"AWS.ElastiCache.create_replication_group/3","type":"function","doc":"Creates a Redis (cluster mode disabled) or a Redis (cluster mode enabled) replication group. This API can be used to create a standalone regional replication group or a secondary replication group associated with a Global Datastore. A Redis (cluster mode disabled) replication group is a collection of clusters, where one of the clusters is a read/write primary and the others are read-only replicas. Writes to the primary are asynchronously propagated to the replicas. A Redis (cluster mode enabled) replication group is a collection of 1 to 90 node groups (shards). Each node group (shard) has one read/write primary node and up to 5 read-only replica nodes. Writes to the primary are asynchronously propagated to the replicas. Redis (cluster mode enabled) replication groups partition the data across node groups (shards). When a Redis (cluster mode disabled) replication group has been successfully created, you can add one or more read replicas to it, up to a total of 5 read replicas. If you need to increase or decrease the number of node groups (console: shards), you can avail yourself of ElastiCache for Redis&#39; scaling. For more information, see Scaling ElastiCache for Redis Clusters in the ElastiCache User Guide. This operation is valid for Redis only."},{"ref":"AWS.ElastiCache.html#create_snapshot/3","title":"AWS.ElastiCache.create_snapshot/3","type":"function","doc":"Creates a copy of an entire cluster or replication group at a specific moment in time. This operation is valid for Redis only."},{"ref":"AWS.ElastiCache.html#create_user/3","title":"AWS.ElastiCache.create_user/3","type":"function","doc":"For Redis engine version 6.04 onwards: Creates a Redis user. For more information, see Using Role Based Access Control (RBAC)."},{"ref":"AWS.ElastiCache.html#create_user_group/3","title":"AWS.ElastiCache.create_user_group/3","type":"function","doc":"For Redis engine version 6.04 onwards: Creates a Redis user group. For more information, see Using Role Based Access Control (RBAC)"},{"ref":"AWS.ElastiCache.html#decrease_node_groups_in_global_replication_group/3","title":"AWS.ElastiCache.decrease_node_groups_in_global_replication_group/3","type":"function","doc":"Decreases the number of node groups in a Global Datastore"},{"ref":"AWS.ElastiCache.html#decrease_replica_count/3","title":"AWS.ElastiCache.decrease_replica_count/3","type":"function","doc":"Dynamically decreases the number of replicas in a Redis (cluster mode disabled) replication group or the number of replica nodes in one or more node groups (shards) of a Redis (cluster mode enabled) replication group. This operation is performed with no cluster down time."},{"ref":"AWS.ElastiCache.html#delete_cache_cluster/3","title":"AWS.ElastiCache.delete_cache_cluster/3","type":"function","doc":"Deletes a previously provisioned cluster. DeleteCacheCluster deletes all associated cache nodes, node endpoints and the cluster itself. When you receive a successful response from this operation, Amazon ElastiCache immediately begins deleting the cluster; you cannot cancel or revert this operation. This operation is not valid for: Redis (cluster mode enabled) clusters A cluster that is the last read replica of a replication group A node group (shard) that has Multi-AZ mode enabled A cluster from a Redis (cluster mode enabled) replication group A cluster that is not in the available state"},{"ref":"AWS.ElastiCache.html#delete_cache_parameter_group/3","title":"AWS.ElastiCache.delete_cache_parameter_group/3","type":"function","doc":"Deletes the specified cache parameter group. You cannot delete a cache parameter group if it is associated with any cache clusters."},{"ref":"AWS.ElastiCache.html#delete_cache_security_group/3","title":"AWS.ElastiCache.delete_cache_security_group/3","type":"function","doc":"Deletes a cache security group. You cannot delete a cache security group if it is associated with any clusters."},{"ref":"AWS.ElastiCache.html#delete_cache_subnet_group/3","title":"AWS.ElastiCache.delete_cache_subnet_group/3","type":"function","doc":"Deletes a cache subnet group. You cannot delete a cache subnet group if it is associated with any clusters."},{"ref":"AWS.ElastiCache.html#delete_global_replication_group/3","title":"AWS.ElastiCache.delete_global_replication_group/3","type":"function","doc":"Deleting a Global Datastore is a two-step process: First, you must DisassociateGlobalReplicationGroup to remove the secondary clusters in the Global Datastore. Once the Global Datastore contains only the primary cluster, you can use DeleteGlobalReplicationGroup API to delete the Global Datastore while retainining the primary cluster using Retain= true. Since the Global Datastore has only a primary cluster, you can delete the Global Datastore while retaining the primary by setting RetainPrimaryCluster=true. When you receive a successful response from this operation, Amazon ElastiCache immediately begins deleting the selected resources; you cannot cancel or revert this operation."},{"ref":"AWS.ElastiCache.html#delete_replication_group/3","title":"AWS.ElastiCache.delete_replication_group/3","type":"function","doc":"Deletes an existing replication group. By default, this operation deletes the entire replication group, including the primary/primaries and all of the read replicas. If the replication group has only one primary, you can optionally delete only the read replicas, while retaining the primary by setting RetainPrimaryCluster=true. When you receive a successful response from this operation, Amazon ElastiCache immediately begins deleting the selected resources; you cannot cancel or revert this operation. This operation is valid for Redis only."},{"ref":"AWS.ElastiCache.html#delete_snapshot/3","title":"AWS.ElastiCache.delete_snapshot/3","type":"function","doc":"Deletes an existing snapshot. When you receive a successful response from this operation, ElastiCache immediately begins deleting the snapshot; you cannot cancel or revert this operation. This operation is valid for Redis only."},{"ref":"AWS.ElastiCache.html#delete_user/3","title":"AWS.ElastiCache.delete_user/3","type":"function","doc":"For Redis engine version 6.04 onwards: Deletes a user. The user will be removed from all user groups and in turn removed from all replication groups. For more information, see Using Role Based Access Control (RBAC)."},{"ref":"AWS.ElastiCache.html#delete_user_group/3","title":"AWS.ElastiCache.delete_user_group/3","type":"function","doc":"For Redis engine version 6.04 onwards: Deletes a ser group. The user group must first be disassociated from the replcation group before it can be deleted. For more information, see Using Role Based Access Control (RBAC)."},{"ref":"AWS.ElastiCache.html#describe_cache_clusters/3","title":"AWS.ElastiCache.describe_cache_clusters/3","type":"function","doc":"Returns information about all provisioned clusters if no cluster identifier is specified, or about a specific cache cluster if a cluster identifier is supplied. By default, abbreviated information about the clusters is returned. You can use the optional ShowCacheNodeInfo flag to retrieve detailed information about the cache nodes associated with the clusters. These details include the DNS address and port for the cache node endpoint. If the cluster is in the creating state, only cluster-level information is displayed until all of the nodes are successfully provisioned. If the cluster is in the deleting state, only cluster-level information is displayed. If cache nodes are currently being added to the cluster, node endpoint information and creation time for the additional nodes are not displayed until they are completely provisioned. When the cluster state is available, the cluster is ready for use. If cache nodes are currently being removed from the cluster, no endpoint information for the removed nodes is displayed."},{"ref":"AWS.ElastiCache.html#describe_cache_engine_versions/3","title":"AWS.ElastiCache.describe_cache_engine_versions/3","type":"function","doc":"Returns a list of the available cache engines and their versions."},{"ref":"AWS.ElastiCache.html#describe_cache_parameter_groups/3","title":"AWS.ElastiCache.describe_cache_parameter_groups/3","type":"function","doc":"Returns a list of cache parameter group descriptions. If a cache parameter group name is specified, the list contains only the descriptions for that group."},{"ref":"AWS.ElastiCache.html#describe_cache_parameters/3","title":"AWS.ElastiCache.describe_cache_parameters/3","type":"function","doc":"Returns the detailed parameter list for a particular cache parameter group."},{"ref":"AWS.ElastiCache.html#describe_cache_security_groups/3","title":"AWS.ElastiCache.describe_cache_security_groups/3","type":"function","doc":"Returns a list of cache security group descriptions. If a cache security group name is specified, the list contains only the description of that group. This applicable only when you have ElastiCache in Classic setup"},{"ref":"AWS.ElastiCache.html#describe_cache_subnet_groups/3","title":"AWS.ElastiCache.describe_cache_subnet_groups/3","type":"function","doc":"Returns a list of cache subnet group descriptions. If a subnet group name is specified, the list contains only the description of that group. This is applicable only when you have ElastiCache in VPC setup. All ElastiCache clusters now launch in VPC by default."},{"ref":"AWS.ElastiCache.html#describe_engine_default_parameters/3","title":"AWS.ElastiCache.describe_engine_default_parameters/3","type":"function","doc":"Returns the default engine and system parameter information for the specified cache engine."},{"ref":"AWS.ElastiCache.html#describe_events/3","title":"AWS.ElastiCache.describe_events/3","type":"function","doc":"Returns events related to clusters, cache security groups, and cache parameter groups. You can obtain events specific to a particular cluster, cache security group, or cache parameter group by providing the name as a parameter. By default, only the events occurring within the last hour are returned; however, you can retrieve up to 14 days&#39; worth of events if necessary."},{"ref":"AWS.ElastiCache.html#describe_global_replication_groups/3","title":"AWS.ElastiCache.describe_global_replication_groups/3","type":"function","doc":"Returns information about a particular global replication group. If no identifier is specified, returns information about all Global Datastores."},{"ref":"AWS.ElastiCache.html#describe_replication_groups/3","title":"AWS.ElastiCache.describe_replication_groups/3","type":"function","doc":"Returns information about a particular replication group. If no identifier is specified, DescribeReplicationGroups returns information about all replication groups. This operation is valid for Redis only."},{"ref":"AWS.ElastiCache.html#describe_reserved_cache_nodes/3","title":"AWS.ElastiCache.describe_reserved_cache_nodes/3","type":"function","doc":"Returns information about reserved cache nodes for this account, or about a specified reserved cache node."},{"ref":"AWS.ElastiCache.html#describe_reserved_cache_nodes_offerings/3","title":"AWS.ElastiCache.describe_reserved_cache_nodes_offerings/3","type":"function","doc":"Lists available reserved cache node offerings."},{"ref":"AWS.ElastiCache.html#describe_service_updates/3","title":"AWS.ElastiCache.describe_service_updates/3","type":"function","doc":"Returns details of the service updates"},{"ref":"AWS.ElastiCache.html#describe_snapshots/3","title":"AWS.ElastiCache.describe_snapshots/3","type":"function","doc":"Returns information about cluster or replication group snapshots. By default, DescribeSnapshots lists all of your snapshots; it can optionally describe a single snapshot, or just the snapshots associated with a particular cache cluster. This operation is valid for Redis only."},{"ref":"AWS.ElastiCache.html#describe_update_actions/3","title":"AWS.ElastiCache.describe_update_actions/3","type":"function","doc":"Returns details of the update actions"},{"ref":"AWS.ElastiCache.html#describe_user_groups/3","title":"AWS.ElastiCache.describe_user_groups/3","type":"function","doc":"Returns a list of user groups."},{"ref":"AWS.ElastiCache.html#describe_users/3","title":"AWS.ElastiCache.describe_users/3","type":"function","doc":"Returns a list of users."},{"ref":"AWS.ElastiCache.html#disassociate_global_replication_group/3","title":"AWS.ElastiCache.disassociate_global_replication_group/3","type":"function","doc":"Remove a secondary cluster from the Global Datastore using the Global Datastore name. The secondary cluster will no longer receive updates from the primary cluster, but will remain as a standalone cluster in that AWS region."},{"ref":"AWS.ElastiCache.html#failover_global_replication_group/3","title":"AWS.ElastiCache.failover_global_replication_group/3","type":"function","doc":"Used to failover the primary region to a selected secondary region. The selected secondary region will become primary, and all other clusters will become secondary."},{"ref":"AWS.ElastiCache.html#increase_node_groups_in_global_replication_group/3","title":"AWS.ElastiCache.increase_node_groups_in_global_replication_group/3","type":"function","doc":"Increase the number of node groups in the Global Datastore"},{"ref":"AWS.ElastiCache.html#increase_replica_count/3","title":"AWS.ElastiCache.increase_replica_count/3","type":"function","doc":"Dynamically increases the number of replics in a Redis (cluster mode disabled) replication group or the number of replica nodes in one or more node groups (shards) of a Redis (cluster mode enabled) replication group. This operation is performed with no cluster down time."},{"ref":"AWS.ElastiCache.html#list_allowed_node_type_modifications/3","title":"AWS.ElastiCache.list_allowed_node_type_modifications/3","type":"function","doc":"Lists all available node types that you can scale your Redis cluster&#39;s or replication group&#39;s current node type. When you use the ModifyCacheCluster or ModifyReplicationGroup operations to scale your cluster or replication group, the value of the CacheNodeType parameter must be one of the node types returned by this operation."},{"ref":"AWS.ElastiCache.html#list_tags_for_resource/3","title":"AWS.ElastiCache.list_tags_for_resource/3","type":"function","doc":"Lists all cost allocation tags currently on the named resource. A cost allocation tag is a key-value pair where the key is case-sensitive and the value is optional. You can use cost allocation tags to categorize and track your AWS costs. If the cluster is not in the available state, ListTagsForResource returns an error. You can have a maximum of 50 cost allocation tags on an ElastiCache resource. For more information, see Monitoring Costs with Tags."},{"ref":"AWS.ElastiCache.html#modify_cache_cluster/3","title":"AWS.ElastiCache.modify_cache_cluster/3","type":"function","doc":"Modifies the settings for a cluster. You can use this operation to change one or more cluster configuration parameters by specifying the parameters and the new values."},{"ref":"AWS.ElastiCache.html#modify_cache_parameter_group/3","title":"AWS.ElastiCache.modify_cache_parameter_group/3","type":"function","doc":"Modifies the parameters of a cache parameter group. You can modify up to 20 parameters in a single request by submitting a list parameter name and value pairs."},{"ref":"AWS.ElastiCache.html#modify_cache_subnet_group/3","title":"AWS.ElastiCache.modify_cache_subnet_group/3","type":"function","doc":"Modifies an existing cache subnet group."},{"ref":"AWS.ElastiCache.html#modify_global_replication_group/3","title":"AWS.ElastiCache.modify_global_replication_group/3","type":"function","doc":"Modifies the settings for a Global Datastore."},{"ref":"AWS.ElastiCache.html#modify_replication_group/3","title":"AWS.ElastiCache.modify_replication_group/3","type":"function","doc":"Modifies the settings for a replication group. Scaling for Amazon ElastiCache for Redis (cluster mode enabled) in the ElastiCache User Guide * ModifyReplicationGroupShardConfiguration in the ElastiCache API Reference This operation is valid for Redis only."},{"ref":"AWS.ElastiCache.html#modify_replication_group_shard_configuration/3","title":"AWS.ElastiCache.modify_replication_group_shard_configuration/3","type":"function","doc":"Modifies a replication group&#39;s shards (node groups) by allowing you to add shards, remove shards, or rebalance the keyspaces among exisiting shards."},{"ref":"AWS.ElastiCache.html#modify_user/3","title":"AWS.ElastiCache.modify_user/3","type":"function","doc":"Changes user password(s) and/or access string."},{"ref":"AWS.ElastiCache.html#modify_user_group/3","title":"AWS.ElastiCache.modify_user_group/3","type":"function","doc":"Changes the list of users that belong to the user group."},{"ref":"AWS.ElastiCache.html#purchase_reserved_cache_nodes_offering/3","title":"AWS.ElastiCache.purchase_reserved_cache_nodes_offering/3","type":"function","doc":"Allows you to purchase a reserved cache node offering."},{"ref":"AWS.ElastiCache.html#rebalance_slots_in_global_replication_group/3","title":"AWS.ElastiCache.rebalance_slots_in_global_replication_group/3","type":"function","doc":"Redistribute slots to ensure uniform distribution across existing shards in the cluster."},{"ref":"AWS.ElastiCache.html#reboot_cache_cluster/3","title":"AWS.ElastiCache.reboot_cache_cluster/3","type":"function","doc":"Reboots some, or all, of the cache nodes within a provisioned cluster. This operation applies any modified cache parameter groups to the cluster. The reboot operation takes place as soon as possible, and results in a momentary outage to the cluster. During the reboot, the cluster status is set to REBOOTING. The reboot causes the contents of the cache (for each cache node being rebooted) to be lost. When the reboot is complete, a cluster event is created. Rebooting a cluster is currently supported on Memcached and Redis (cluster mode disabled) clusters. Rebooting is not supported on Redis (cluster mode enabled) clusters. If you make changes to parameters that require a Redis (cluster mode enabled) cluster reboot for the changes to be applied, see Rebooting a Cluster for an alternate process."},{"ref":"AWS.ElastiCache.html#remove_tags_from_resource/3","title":"AWS.ElastiCache.remove_tags_from_resource/3","type":"function","doc":"Removes the tags identified by the TagKeys list from the named resource."},{"ref":"AWS.ElastiCache.html#reset_cache_parameter_group/3","title":"AWS.ElastiCache.reset_cache_parameter_group/3","type":"function","doc":"Modifies the parameters of a cache parameter group to the engine or system default value. You can reset specific parameters by submitting a list of parameter names. To reset the entire cache parameter group, specify the ResetAllParameters and CacheParameterGroupName parameters."},{"ref":"AWS.ElastiCache.html#revoke_cache_security_group_ingress/3","title":"AWS.ElastiCache.revoke_cache_security_group_ingress/3","type":"function","doc":"Revokes ingress from a cache security group. Use this operation to disallow access from an Amazon EC2 security group that had been previously authorized."},{"ref":"AWS.ElastiCache.html#start_migration/3","title":"AWS.ElastiCache.start_migration/3","type":"function","doc":"Start the migration of data."},{"ref":"AWS.ElastiCache.html#test_failover/3","title":"AWS.ElastiCache.test_failover/3","type":"function","doc":"Represents the input of a TestFailover operation which test automatic failover on a specified node group (called shard in the console) in a replication group (called cluster in the console). Note the following A customer can use this operation to test automatic failover on up to 5 shards (called node groups in the ElastiCache API and AWS CLI) in any rolling 24-hour period. If calling this operation on shards in different clusters (called replication groups in the API and CLI), the calls can be made concurrently. If calling this operation multiple times on different shards in the same Redis (cluster mode enabled) replication group, the first node replacement must complete before a subsequent call can be made. To determine whether the node replacement is complete you can check Events using the Amazon ElastiCache console, the AWS CLI, or the ElastiCache API. Look for the following automatic failover related events, listed here in order of occurrance: Replication group message: `Test Failover API called for node group ` 2. Cache cluster message: `Failover from master node to replica node completed` 3. Replication group message: `Failover from master node to replica node completed` 4. Cache cluster message: `Recovering cache nodes ` 5. Cache cluster message: `Finished recovery for cache nodes ` For more information see: * [Viewing ElastiCache Events](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/ECEvents.Viewing.html) in the *ElastiCache User Guide* * [DescribeEvents](https://docs.aws.amazon.com/AmazonElastiCache/latest/APIReference/API_DescribeEvents.html) in the ElastiCache API Reference Also see, [Testing Multi-AZ ](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/AutoFailover.html#auto-failover-test) in the *ElastiCache User Guide*."},{"ref":"AWS.ElasticBeanstalk.html","title":"AWS.ElasticBeanstalk","type":"module","doc":"AWS Elastic Beanstalk AWS Elastic Beanstalk makes it easy for you to create, deploy, and manage scalable, fault-tolerant applications running on the Amazon Web Services cloud. For more information about this product, go to the AWS Elastic Beanstalk details page. The location of the latest AWS Elastic Beanstalk WSDL is https://elasticbeanstalk.s3.amazonaws.com/doc/2010-12-01/AWSElasticBeanstalk.wsdl. To install the Software Development Kits (SDKs), Integrated Development Environment (IDE) Toolkits, and command line tools that enable you to access the API, go to Tools for Amazon Web Services. Endpoints For a list of region-specific endpoints that AWS Elastic Beanstalk supports, go to Regions and Endpoints in the Amazon Web Services Glossary."},{"ref":"AWS.ElasticBeanstalk.html#abort_environment_update/3","title":"AWS.ElasticBeanstalk.abort_environment_update/3","type":"function","doc":"Cancels in-progress environment configuration update or application version deployment."},{"ref":"AWS.ElasticBeanstalk.html#apply_environment_managed_action/3","title":"AWS.ElasticBeanstalk.apply_environment_managed_action/3","type":"function","doc":"Applies a scheduled managed action immediately. A managed action can be applied only if its status is Scheduled. Get the status and action ID of a managed action with DescribeEnvironmentManagedActions."},{"ref":"AWS.ElasticBeanstalk.html#associate_environment_operations_role/3","title":"AWS.ElasticBeanstalk.associate_environment_operations_role/3","type":"function","doc":"Add or change the operations role used by an environment. After this call is made, Elastic Beanstalk uses the associated operations role for permissions to downstream services during subsequent calls acting on this environment. For more information, see Operations roles in the AWS Elastic Beanstalk Developer Guide."},{"ref":"AWS.ElasticBeanstalk.html#check_d_n_s_availability/3","title":"AWS.ElasticBeanstalk.check_d_n_s_availability/3","type":"function","doc":"Checks if the specified CNAME is available."},{"ref":"AWS.ElasticBeanstalk.html#compose_environments/3","title":"AWS.ElasticBeanstalk.compose_environments/3","type":"function","doc":"Create or update a group of environments that each run a separate component of a single application. Takes a list of version labels that specify application source bundles for each of the environments to create or update. The name of each environment and other required information must be included in the source bundles in an environment manifest named env.yaml. See Compose Environments for details."},{"ref":"AWS.ElasticBeanstalk.html#create_application/3","title":"AWS.ElasticBeanstalk.create_application/3","type":"function","doc":"Creates an application that has one configuration template named default and no application versions."},{"ref":"AWS.ElasticBeanstalk.html#create_application_version/3","title":"AWS.ElasticBeanstalk.create_application_version/3","type":"function","doc":"Creates an application version for the specified application. You can create an application version from a source bundle in Amazon S3, a commit in AWS CodeCommit, or the output of an AWS CodeBuild build as follows: Specify a commit in an AWS CodeCommit repository with SourceBuildInformation. Specify a build in an AWS CodeBuild with SourceBuildInformation and BuildConfiguration. Specify a source bundle in S3 with SourceBundle Omit both SourceBuildInformation and SourceBundle to use the default sample application. After you create an application version with a specified Amazon S3 bucket and key location, you can&#39;t change that Amazon S3 location. If you change the Amazon S3 location, you receive an exception when you attempt to launch an environment from the application version."},{"ref":"AWS.ElasticBeanstalk.html#create_configuration_template/3","title":"AWS.ElasticBeanstalk.create_configuration_template/3","type":"function","doc":"Creates an AWS Elastic Beanstalk configuration template, associated with a specific Elastic Beanstalk application. You define application configuration settings in a configuration template. You can then use the configuration template to deploy different versions of the application with the same configuration settings. Templates aren&#39;t associated with any environment. The EnvironmentName response element is always null. Related Topics DescribeConfigurationOptions DescribeConfigurationSettings ListAvailableSolutionStacks"},{"ref":"AWS.ElasticBeanstalk.html#create_environment/3","title":"AWS.ElasticBeanstalk.create_environment/3","type":"function","doc":"Launches an AWS Elastic Beanstalk environment for the specified application using the specified configuration."},{"ref":"AWS.ElasticBeanstalk.html#create_platform_version/3","title":"AWS.ElasticBeanstalk.create_platform_version/3","type":"function","doc":"Create a new version of your custom platform."},{"ref":"AWS.ElasticBeanstalk.html#create_storage_location/3","title":"AWS.ElasticBeanstalk.create_storage_location/3","type":"function","doc":"Creates a bucket in Amazon S3 to store application versions, logs, and other files used by Elastic Beanstalk environments. The Elastic Beanstalk console and EB CLI call this API the first time you create an environment in a region. If the storage location already exists, CreateStorageLocation still returns the bucket name but does not create a new bucket."},{"ref":"AWS.ElasticBeanstalk.html#delete_application/3","title":"AWS.ElasticBeanstalk.delete_application/3","type":"function","doc":"Deletes the specified application along with all associated versions and configurations. The application versions will not be deleted from your Amazon S3 bucket. You cannot delete an application that has a running environment."},{"ref":"AWS.ElasticBeanstalk.html#delete_application_version/3","title":"AWS.ElasticBeanstalk.delete_application_version/3","type":"function","doc":"Deletes the specified version from the specified application. You cannot delete an application version that is associated with a running environment."},{"ref":"AWS.ElasticBeanstalk.html#delete_configuration_template/3","title":"AWS.ElasticBeanstalk.delete_configuration_template/3","type":"function","doc":"Deletes the specified configuration template. When you launch an environment using a configuration template, the environment gets a copy of the template. You can delete or modify the environment&#39;s copy of the template without affecting the running environment."},{"ref":"AWS.ElasticBeanstalk.html#delete_environment_configuration/3","title":"AWS.ElasticBeanstalk.delete_environment_configuration/3","type":"function","doc":"Deletes the draft configuration associated with the running environment. Updating a running environment with any configuration changes creates a draft configuration set. You can get the draft configuration using DescribeConfigurationSettings while the update is in progress or if the update fails. The DeploymentStatus for the draft configuration indicates whether the deployment is in process or has failed. The draft configuration remains in existence until it is deleted with this action."},{"ref":"AWS.ElasticBeanstalk.html#delete_platform_version/3","title":"AWS.ElasticBeanstalk.delete_platform_version/3","type":"function","doc":"Deletes the specified version of a custom platform."},{"ref":"AWS.ElasticBeanstalk.html#describe_account_attributes/3","title":"AWS.ElasticBeanstalk.describe_account_attributes/3","type":"function","doc":"Returns attributes related to AWS Elastic Beanstalk that are associated with the calling AWS account. The result currently has one set of attributesresource quotas."},{"ref":"AWS.ElasticBeanstalk.html#describe_application_versions/3","title":"AWS.ElasticBeanstalk.describe_application_versions/3","type":"function","doc":"Retrieve a list of application versions."},{"ref":"AWS.ElasticBeanstalk.html#describe_applications/3","title":"AWS.ElasticBeanstalk.describe_applications/3","type":"function","doc":"Returns the descriptions of existing applications."},{"ref":"AWS.ElasticBeanstalk.html#describe_configuration_options/3","title":"AWS.ElasticBeanstalk.describe_configuration_options/3","type":"function","doc":"Describes the configuration options that are used in a particular configuration template or environment, or that a specified solution stack defines. The description includes the values the options, their default values, and an indication of the required action on a running environment if an option value is changed."},{"ref":"AWS.ElasticBeanstalk.html#describe_configuration_settings/3","title":"AWS.ElasticBeanstalk.describe_configuration_settings/3","type":"function","doc":"Returns a description of the settings for the specified configuration set, that is, either a configuration template or the configuration set associated with a running environment. When describing the settings for the configuration set associated with a running environment, it is possible to receive two sets of setting descriptions. One is the deployed configuration set, and the other is a draft configuration of an environment that is either in the process of deployment or that failed to deploy. Related Topics DeleteEnvironmentConfiguration"},{"ref":"AWS.ElasticBeanstalk.html#describe_environment_health/3","title":"AWS.ElasticBeanstalk.describe_environment_health/3","type":"function","doc":"Returns information about the overall health of the specified environment. The DescribeEnvironmentHealth operation is only available with AWS Elastic Beanstalk Enhanced Health."},{"ref":"AWS.ElasticBeanstalk.html#describe_environment_managed_action_history/3","title":"AWS.ElasticBeanstalk.describe_environment_managed_action_history/3","type":"function","doc":"Lists an environment&#39;s completed and failed managed actions."},{"ref":"AWS.ElasticBeanstalk.html#describe_environment_managed_actions/3","title":"AWS.ElasticBeanstalk.describe_environment_managed_actions/3","type":"function","doc":"Lists an environment&#39;s upcoming and in-progress managed actions."},{"ref":"AWS.ElasticBeanstalk.html#describe_environment_resources/3","title":"AWS.ElasticBeanstalk.describe_environment_resources/3","type":"function","doc":"Returns AWS resources for this environment."},{"ref":"AWS.ElasticBeanstalk.html#describe_environments/3","title":"AWS.ElasticBeanstalk.describe_environments/3","type":"function","doc":"Returns descriptions for existing environments."},{"ref":"AWS.ElasticBeanstalk.html#describe_events/3","title":"AWS.ElasticBeanstalk.describe_events/3","type":"function","doc":"Returns list of event descriptions matching criteria up to the last 6 weeks. This action returns the most recent 1,000 events from the specified NextToken."},{"ref":"AWS.ElasticBeanstalk.html#describe_instances_health/3","title":"AWS.ElasticBeanstalk.describe_instances_health/3","type":"function","doc":"Retrieves detailed information about the health of instances in your AWS Elastic Beanstalk. This operation requires enhanced health reporting."},{"ref":"AWS.ElasticBeanstalk.html#describe_platform_version/3","title":"AWS.ElasticBeanstalk.describe_platform_version/3","type":"function","doc":"Describes a platform version. Provides full details. Compare to ListPlatformVersions, which provides summary information about a list of platform versions. For definitions of platform version and other platform-related terms, see AWS Elastic Beanstalk Platforms Glossary."},{"ref":"AWS.ElasticBeanstalk.html#disassociate_environment_operations_role/3","title":"AWS.ElasticBeanstalk.disassociate_environment_operations_role/3","type":"function","doc":"Disassociate the operations role from an environment. After this call is made, Elastic Beanstalk uses the caller&#39;s permissions for permissions to downstream services during subsequent calls acting on this environment. For more information, see Operations roles in the AWS Elastic Beanstalk Developer Guide."},{"ref":"AWS.ElasticBeanstalk.html#list_available_solution_stacks/3","title":"AWS.ElasticBeanstalk.list_available_solution_stacks/3","type":"function","doc":"Returns a list of the available solution stack names, with the public version first and then in reverse chronological order."},{"ref":"AWS.ElasticBeanstalk.html#list_platform_branches/3","title":"AWS.ElasticBeanstalk.list_platform_branches/3","type":"function","doc":"Lists the platform branches available for your account in an AWS Region. Provides summary information about each platform branch. For definitions of platform branch and other platform-related terms, see AWS Elastic Beanstalk Platforms Glossary."},{"ref":"AWS.ElasticBeanstalk.html#list_platform_versions/3","title":"AWS.ElasticBeanstalk.list_platform_versions/3","type":"function","doc":"Lists the platform versions available for your account in an AWS Region. Provides summary information about each platform version. Compare to DescribePlatformVersion, which provides full details about a single platform version. For definitions of platform version and other platform-related terms, see AWS Elastic Beanstalk Platforms Glossary."},{"ref":"AWS.ElasticBeanstalk.html#list_tags_for_resource/3","title":"AWS.ElasticBeanstalk.list_tags_for_resource/3","type":"function","doc":"Return the tags applied to an AWS Elastic Beanstalk resource. The response contains a list of tag key-value pairs. Elastic Beanstalk supports tagging of all of its resources. For details about resource tagging, see Tagging Application Resources."},{"ref":"AWS.ElasticBeanstalk.html#rebuild_environment/3","title":"AWS.ElasticBeanstalk.rebuild_environment/3","type":"function","doc":"Deletes and recreates all of the AWS resources (for example: the Auto Scaling group, load balancer, etc.) for a specified environment and forces a restart."},{"ref":"AWS.ElasticBeanstalk.html#request_environment_info/3","title":"AWS.ElasticBeanstalk.request_environment_info/3","type":"function","doc":"Initiates a request to compile the specified type of information of the deployed environment. Setting the InfoType to tail compiles the last lines from the application server log files of every Amazon EC2 instance in your environment. Setting the InfoType to bundle compresses the application server log files for every Amazon EC2 instance into a .zip file. Legacy and .NET containers do not support bundle logs. Use RetrieveEnvironmentInfo to obtain the set of logs. Related Topics RetrieveEnvironmentInfo"},{"ref":"AWS.ElasticBeanstalk.html#restart_app_server/3","title":"AWS.ElasticBeanstalk.restart_app_server/3","type":"function","doc":"Causes the environment to restart the application container server running on each Amazon EC2 instance."},{"ref":"AWS.ElasticBeanstalk.html#retrieve_environment_info/3","title":"AWS.ElasticBeanstalk.retrieve_environment_info/3","type":"function","doc":"Retrieves the compiled information from a RequestEnvironmentInfo request. Related Topics RequestEnvironmentInfo"},{"ref":"AWS.ElasticBeanstalk.html#swap_environment_c_n_a_m_es/3","title":"AWS.ElasticBeanstalk.swap_environment_c_n_a_m_es/3","type":"function","doc":"Swaps the CNAMEs of two environments."},{"ref":"AWS.ElasticBeanstalk.html#terminate_environment/3","title":"AWS.ElasticBeanstalk.terminate_environment/3","type":"function","doc":"Terminates the specified environment."},{"ref":"AWS.ElasticBeanstalk.html#update_application/3","title":"AWS.ElasticBeanstalk.update_application/3","type":"function","doc":"Updates the specified application to have the specified properties. If a property (for example, description) is not provided, the value remains unchanged. To clear these properties, specify an empty string."},{"ref":"AWS.ElasticBeanstalk.html#update_application_resource_lifecycle/3","title":"AWS.ElasticBeanstalk.update_application_resource_lifecycle/3","type":"function","doc":"Modifies lifecycle settings for an application."},{"ref":"AWS.ElasticBeanstalk.html#update_application_version/3","title":"AWS.ElasticBeanstalk.update_application_version/3","type":"function","doc":"Updates the specified application version to have the specified properties. If a property (for example, description) is not provided, the value remains unchanged. To clear properties, specify an empty string."},{"ref":"AWS.ElasticBeanstalk.html#update_configuration_template/3","title":"AWS.ElasticBeanstalk.update_configuration_template/3","type":"function","doc":"Updates the specified configuration template to have the specified properties or configuration option values. If a property (for example, ApplicationName) is not provided, its value remains unchanged. To clear such properties, specify an empty string. Related Topics DescribeConfigurationOptions"},{"ref":"AWS.ElasticBeanstalk.html#update_environment/3","title":"AWS.ElasticBeanstalk.update_environment/3","type":"function","doc":"Updates the environment description, deploys a new application version, updates the configuration settings to an entirely new configuration template, or updates select configuration option values in the running environment. Attempting to update both the release and configuration is not allowed and AWS Elastic Beanstalk returns an InvalidParameterCombination error. When updating the configuration settings to a new template or individual settings, a draft configuration is created and DescribeConfigurationSettings for this environment returns two setting descriptions with different DeploymentStatus values."},{"ref":"AWS.ElasticBeanstalk.html#update_tags_for_resource/3","title":"AWS.ElasticBeanstalk.update_tags_for_resource/3","type":"function","doc":"Update the list of tags applied to an AWS Elastic Beanstalk resource. Two lists can be passed: TagsToAdd for tags to add or update, and TagsToRemove. Elastic Beanstalk supports tagging of all of its resources. For details about resource tagging, see Tagging Application Resources. If you create a custom IAM user policy to control permission to this operation, specify one of the following two virtual actions (or both) instead of the API operation name: Definitions elasticbeanstalk:AddTags Controls permission to call UpdateTagsForResource and pass a list of tags to add in the TagsToAdd parameter. elasticbeanstalk:RemoveTags Controls permission to call UpdateTagsForResource and pass a list of tag keys to remove in the TagsToRemove parameter. For details about creating a custom user policy, see Creating a Custom User Policy."},{"ref":"AWS.ElasticBeanstalk.html#validate_configuration_settings/3","title":"AWS.ElasticBeanstalk.validate_configuration_settings/3","type":"function","doc":"Takes a set of configuration settings and either a configuration template or environment, and determines whether those values are valid. This action returns a list of messages indicating any errors or warnings associated with the selection of option values."},{"ref":"AWS.ElasticInference.html","title":"AWS.ElasticInference","type":"module","doc":"Elastic Inference public APIs."},{"ref":"AWS.ElasticInference.html#describe_accelerator_offerings/3","title":"AWS.ElasticInference.describe_accelerator_offerings/3","type":"function","doc":"Describes the locations in which a given accelerator type or set of types is present in a given region."},{"ref":"AWS.ElasticInference.html#describe_accelerator_types/2","title":"AWS.ElasticInference.describe_accelerator_types/2","type":"function","doc":"Describes the accelerator types available in a given region, as well as their characteristics, such as memory and throughput."},{"ref":"AWS.ElasticInference.html#describe_accelerators/3","title":"AWS.ElasticInference.describe_accelerators/3","type":"function","doc":"Describes information over a provided set of accelerators belonging to an account."},{"ref":"AWS.ElasticInference.html#list_tags_for_resource/3","title":"AWS.ElasticInference.list_tags_for_resource/3","type":"function","doc":"Returns all tags of an Elastic Inference Accelerator."},{"ref":"AWS.ElasticInference.html#tag_resource/4","title":"AWS.ElasticInference.tag_resource/4","type":"function","doc":"Adds the specified tags to an Elastic Inference Accelerator."},{"ref":"AWS.ElasticInference.html#untag_resource/4","title":"AWS.ElasticInference.untag_resource/4","type":"function","doc":"Removes the specified tags from an Elastic Inference Accelerator."},{"ref":"AWS.ElasticLoadBalancing.html","title":"AWS.ElasticLoadBalancing","type":"module","doc":"Elastic Load Balancing A load balancer can distribute incoming traffic across your EC2 instances. This enables you to increase the availability of your application. The load balancer also monitors the health of its registered instances and ensures that it routes traffic only to healthy instances. You configure your load balancer to accept incoming traffic by specifying one or more listeners, which are configured with a protocol and port number for connections from clients to the load balancer and a protocol and port number for connections from the load balancer to the instances. Elastic Load Balancing supports three types of load balancers: Application Load Balancers, Network Load Balancers, and Classic Load Balancers. You can select a load balancer based on your application needs. For more information, see the Elastic Load Balancing User Guide. This reference covers the 2012-06-01 API, which supports Classic Load Balancers. The 2015-12-01 API supports Application Load Balancers and Network Load Balancers. To get started, create a load balancer with one or more listeners using CreateLoadBalancer. Register your instances with the load balancer using RegisterInstancesWithLoadBalancer. All Elastic Load Balancing operations are idempotent, which means that they complete at most one time. If you repeat an operation, it succeeds with a 200 OK response code."},{"ref":"AWS.ElasticLoadBalancing.html#add_tags/3","title":"AWS.ElasticLoadBalancing.add_tags/3","type":"function","doc":"Adds the specified tags to the specified load balancer. Each load balancer can have a maximum of 10 tags. Each tag consists of a key and an optional value. If a tag with the same key is already associated with the load balancer, AddTags updates its value. For more information, see Tag Your Classic Load Balancer in the Classic Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancing.html#apply_security_groups_to_load_balancer/3","title":"AWS.ElasticLoadBalancing.apply_security_groups_to_load_balancer/3","type":"function","doc":"Associates one or more security groups with your load balancer in a virtual private cloud (VPC). The specified security groups override the previously associated security groups. For more information, see Security Groups for Load Balancers in a VPC in the Classic Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancing.html#attach_load_balancer_to_subnets/3","title":"AWS.ElasticLoadBalancing.attach_load_balancer_to_subnets/3","type":"function","doc":"Adds one or more subnets to the set of configured subnets for the specified load balancer. The load balancer evenly distributes requests across all registered subnets. For more information, see Add or Remove Subnets for Your Load Balancer in a VPC in the Classic Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancing.html#configure_health_check/3","title":"AWS.ElasticLoadBalancing.configure_health_check/3","type":"function","doc":"Specifies the health check settings to use when evaluating the health state of your EC2 instances. For more information, see Configure Health Checks for Your Load Balancer in the Classic Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancing.html#create_app_cookie_stickiness_policy/3","title":"AWS.ElasticLoadBalancing.create_app_cookie_stickiness_policy/3","type":"function","doc":"Generates a stickiness policy with sticky session lifetimes that follow that of an application-generated cookie. This policy can be associated only with HTTP/HTTPS listeners. This policy is similar to the policy created by CreateLBCookieStickinessPolicy, except that the lifetime of the special Elastic Load Balancing cookie, AWSELB, follows the lifetime of the application-generated cookie specified in the policy configuration. The load balancer only inserts a new stickiness cookie when the application response includes a new application cookie. If the application cookie is explicitly removed or expires, the session stops being sticky until a new application cookie is issued. For more information, see Application-Controlled Session Stickiness in the Classic Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancing.html#create_l_b_cookie_stickiness_policy/3","title":"AWS.ElasticLoadBalancing.create_l_b_cookie_stickiness_policy/3","type":"function","doc":"Generates a stickiness policy with sticky session lifetimes controlled by the lifetime of the browser (user-agent) or a specified expiration period. This policy can be associated only with HTTP/HTTPS listeners. When a load balancer implements this policy, the load balancer uses a special cookie to track the instance for each request. When the load balancer receives a request, it first checks to see if this cookie is present in the request. If so, the load balancer sends the request to the application server specified in the cookie. If not, the load balancer sends the request to a server that is chosen based on the existing load-balancing algorithm. A cookie is inserted into the response for binding subsequent requests from the same user to that server. The validity of the cookie is based on the cookie expiration time, which is specified in the policy configuration. For more information, see Duration-Based Session Stickiness in the Classic Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancing.html#create_load_balancer/3","title":"AWS.ElasticLoadBalancing.create_load_balancer/3","type":"function","doc":"Creates a Classic Load Balancer. You can add listeners, security groups, subnets, and tags when you create your load balancer, or you can add them later using CreateLoadBalancerListeners, ApplySecurityGroupsToLoadBalancer, AttachLoadBalancerToSubnets, and AddTags. To describe your current load balancers, see DescribeLoadBalancers. When you are finished with a load balancer, you can delete it using DeleteLoadBalancer. You can create up to 20 load balancers per region per account. You can request an increase for the number of load balancers for your account. For more information, see Limits for Your Classic Load Balancer in the Classic Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancing.html#create_load_balancer_listeners/3","title":"AWS.ElasticLoadBalancing.create_load_balancer_listeners/3","type":"function","doc":"Creates one or more listeners for the specified load balancer. If a listener with the specified port does not already exist, it is created; otherwise, the properties of the new listener must match the properties of the existing listener. For more information, see Listeners for Your Classic Load Balancer in the Classic Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancing.html#create_load_balancer_policy/3","title":"AWS.ElasticLoadBalancing.create_load_balancer_policy/3","type":"function","doc":"Creates a policy with the specified attributes for the specified load balancer. Policies are settings that are saved for your load balancer and that can be applied to the listener or the application server, depending on the policy type."},{"ref":"AWS.ElasticLoadBalancing.html#delete_load_balancer/3","title":"AWS.ElasticLoadBalancing.delete_load_balancer/3","type":"function","doc":"Deletes the specified load balancer. If you are attempting to recreate a load balancer, you must reconfigure all settings. The DNS name associated with a deleted load balancer are no longer usable. The name and associated DNS record of the deleted load balancer no longer exist and traffic sent to any of its IP addresses is no longer delivered to your instances. If the load balancer does not exist or has already been deleted, the call to DeleteLoadBalancer still succeeds."},{"ref":"AWS.ElasticLoadBalancing.html#delete_load_balancer_listeners/3","title":"AWS.ElasticLoadBalancing.delete_load_balancer_listeners/3","type":"function","doc":"Deletes the specified listeners from the specified load balancer."},{"ref":"AWS.ElasticLoadBalancing.html#delete_load_balancer_policy/3","title":"AWS.ElasticLoadBalancing.delete_load_balancer_policy/3","type":"function","doc":"Deletes the specified policy from the specified load balancer. This policy must not be enabled for any listeners."},{"ref":"AWS.ElasticLoadBalancing.html#deregister_instances_from_load_balancer/3","title":"AWS.ElasticLoadBalancing.deregister_instances_from_load_balancer/3","type":"function","doc":"Deregisters the specified instances from the specified load balancer. After the instance is deregistered, it no longer receives traffic from the load balancer. You can use DescribeLoadBalancers to verify that the instance is deregistered from the load balancer. For more information, see Register or De-Register EC2 Instances in the Classic Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancing.html#describe_account_limits/3","title":"AWS.ElasticLoadBalancing.describe_account_limits/3","type":"function","doc":"Describes the current Elastic Load Balancing resource limits for your AWS account. For more information, see Limits for Your Classic Load Balancer in the Classic Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancing.html#describe_instance_health/3","title":"AWS.ElasticLoadBalancing.describe_instance_health/3","type":"function","doc":"Describes the state of the specified instances with respect to the specified load balancer. If no instances are specified, the call describes the state of all instances that are currently registered with the load balancer. If instances are specified, their state is returned even if they are no longer registered with the load balancer. The state of terminated instances is not returned."},{"ref":"AWS.ElasticLoadBalancing.html#describe_load_balancer_attributes/3","title":"AWS.ElasticLoadBalancing.describe_load_balancer_attributes/3","type":"function","doc":"Describes the attributes for the specified load balancer."},{"ref":"AWS.ElasticLoadBalancing.html#describe_load_balancer_policies/3","title":"AWS.ElasticLoadBalancing.describe_load_balancer_policies/3","type":"function","doc":"Describes the specified policies. If you specify a load balancer name, the action returns the descriptions of all policies created for the load balancer. If you specify a policy name associated with your load balancer, the action returns the description of that policy. If you don&#39;t specify a load balancer name, the action returns descriptions of the specified sample policies, or descriptions of all sample policies. The names of the sample policies have the ELBSample- prefix."},{"ref":"AWS.ElasticLoadBalancing.html#describe_load_balancer_policy_types/3","title":"AWS.ElasticLoadBalancing.describe_load_balancer_policy_types/3","type":"function","doc":"Describes the specified load balancer policy types or all load balancer policy types. The description of each type indicates how it can be used. For example, some policies can be used only with layer 7 listeners, some policies can be used only with layer 4 listeners, and some policies can be used only with your EC2 instances. You can use CreateLoadBalancerPolicy to create a policy configuration for any of these policy types. Then, depending on the policy type, use either SetLoadBalancerPoliciesOfListener or SetLoadBalancerPoliciesForBackendServer to set the policy."},{"ref":"AWS.ElasticLoadBalancing.html#describe_load_balancers/3","title":"AWS.ElasticLoadBalancing.describe_load_balancers/3","type":"function","doc":"Describes the specified the load balancers. If no load balancers are specified, the call describes all of your load balancers."},{"ref":"AWS.ElasticLoadBalancing.html#describe_tags/3","title":"AWS.ElasticLoadBalancing.describe_tags/3","type":"function","doc":"Describes the tags associated with the specified load balancers."},{"ref":"AWS.ElasticLoadBalancing.html#detach_load_balancer_from_subnets/3","title":"AWS.ElasticLoadBalancing.detach_load_balancer_from_subnets/3","type":"function","doc":"Removes the specified subnets from the set of configured subnets for the load balancer. After a subnet is removed, all EC2 instances registered with the load balancer in the removed subnet go into the OutOfService state. Then, the load balancer balances the traffic among the remaining routable subnets."},{"ref":"AWS.ElasticLoadBalancing.html#disable_availability_zones_for_load_balancer/3","title":"AWS.ElasticLoadBalancing.disable_availability_zones_for_load_balancer/3","type":"function","doc":"Removes the specified Availability Zones from the set of Availability Zones for the specified load balancer in EC2-Classic or a default VPC. For load balancers in a non-default VPC, use DetachLoadBalancerFromSubnets. There must be at least one Availability Zone registered with a load balancer at all times. After an Availability Zone is removed, all instances registered with the load balancer that are in the removed Availability Zone go into the OutOfService state. Then, the load balancer attempts to equally balance the traffic among its remaining Availability Zones. For more information, see Add or Remove Availability Zones in the Classic Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancing.html#enable_availability_zones_for_load_balancer/3","title":"AWS.ElasticLoadBalancing.enable_availability_zones_for_load_balancer/3","type":"function","doc":"Adds the specified Availability Zones to the set of Availability Zones for the specified load balancer in EC2-Classic or a default VPC. For load balancers in a non-default VPC, use AttachLoadBalancerToSubnets. The load balancer evenly distributes requests across all its registered Availability Zones that contain instances. For more information, see Add or Remove Availability Zones in the Classic Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancing.html#modify_load_balancer_attributes/3","title":"AWS.ElasticLoadBalancing.modify_load_balancer_attributes/3","type":"function","doc":"Modifies the attributes of the specified load balancer. You can modify the load balancer attributes, such as AccessLogs, ConnectionDraining, and CrossZoneLoadBalancing by either enabling or disabling them. Or, you can modify the load balancer attribute ConnectionSettings by specifying an idle connection timeout value for your load balancer. For more information, see the following in the Classic Load Balancers Guide: Cross-Zone Load Balancing Connection Draining Access Logs Idle Connection Timeout"},{"ref":"AWS.ElasticLoadBalancing.html#register_instances_with_load_balancer/3","title":"AWS.ElasticLoadBalancing.register_instances_with_load_balancer/3","type":"function","doc":"Adds the specified instances to the specified load balancer. The instance must be a running instance in the same network as the load balancer (EC2-Classic or the same VPC). If you have EC2-Classic instances and a load balancer in a VPC with ClassicLink enabled, you can link the EC2-Classic instances to that VPC and then register the linked EC2-Classic instances with the load balancer in the VPC. Note that RegisterInstanceWithLoadBalancer completes when the request has been registered. Instance registration takes a little time to complete. To check the state of the registered instances, use DescribeLoadBalancers or DescribeInstanceHealth. After the instance is registered, it starts receiving traffic and requests from the load balancer. Any instance that is not in one of the Availability Zones registered for the load balancer is moved to the OutOfService state. If an Availability Zone is added to the load balancer later, any instances registered with the load balancer move to the InService state. To deregister instances from a load balancer, use DeregisterInstancesFromLoadBalancer. For more information, see Register or De-Register EC2 Instances in the Classic Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancing.html#remove_tags/3","title":"AWS.ElasticLoadBalancing.remove_tags/3","type":"function","doc":"Removes one or more tags from the specified load balancer."},{"ref":"AWS.ElasticLoadBalancing.html#set_load_balancer_listener_s_s_l_certificate/3","title":"AWS.ElasticLoadBalancing.set_load_balancer_listener_s_s_l_certificate/3","type":"function","doc":"Sets the certificate that terminates the specified listener&#39;s SSL connections. The specified certificate replaces any prior certificate that was used on the same load balancer and port. For more information about updating your SSL certificate, see Replace the SSL Certificate for Your Load Balancer in the Classic Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancing.html#set_load_balancer_policies_for_backend_server/3","title":"AWS.ElasticLoadBalancing.set_load_balancer_policies_for_backend_server/3","type":"function","doc":"Replaces the set of policies associated with the specified port on which the EC2 instance is listening with a new set of policies. At this time, only the back-end server authentication policy type can be applied to the instance ports; this policy type is composed of multiple public key policies. Each time you use SetLoadBalancerPoliciesForBackendServer to enable the policies, use the PolicyNames parameter to list the policies that you want to enable. You can use DescribeLoadBalancers or DescribeLoadBalancerPolicies to verify that the policy is associated with the EC2 instance. For more information about enabling back-end instance authentication, see Configure Back-end Instance Authentication in the Classic Load Balancers Guide. For more information about Proxy Protocol, see Configure Proxy Protocol Support in the Classic Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancing.html#set_load_balancer_policies_of_listener/3","title":"AWS.ElasticLoadBalancing.set_load_balancer_policies_of_listener/3","type":"function","doc":"Replaces the current set of policies for the specified load balancer port with the specified set of policies. To enable back-end server authentication, use SetLoadBalancerPoliciesForBackendServer. For more information about setting policies, see Update the SSL Negotiation Configuration, Duration-Based Session Stickiness, and Application-Controlled Session Stickiness in the Classic Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancingv2.html","title":"AWS.ElasticLoadBalancingv2","type":"module","doc":"Elastic Load Balancing A load balancer distributes incoming traffic across targets, such as your EC2 instances. This enables you to increase the availability of your application. The load balancer also monitors the health of its registered targets and ensures that it routes traffic only to healthy targets. You configure your load balancer to accept incoming traffic by specifying one or more listeners, which are configured with a protocol and port number for connections from clients to the load balancer. You configure a target group with a protocol and port number for connections from the load balancer to the targets, and with health check settings to be used when checking the health status of the targets. Elastic Load Balancing supports the following types of load balancers: Application Load Balancers, Network Load Balancers, and Classic Load Balancers. This reference covers Application Load Balancers and Network Load Balancers. An Application Load Balancer makes routing and load balancing decisions at the application layer (HTTP/HTTPS). A Network Load Balancer makes routing and load balancing decisions at the transport layer (TCP/TLS). Both Application Load Balancers and Network Load Balancers can route requests to one or more ports on each EC2 instance or container instance in your virtual private cloud (VPC). For more information, see the Elastic Load Balancing User Guide. All Elastic Load Balancing operations are idempotent, which means that they complete at most one time. If you repeat an operation, it succeeds."},{"ref":"AWS.ElasticLoadBalancingv2.html#add_listener_certificates/3","title":"AWS.ElasticLoadBalancingv2.add_listener_certificates/3","type":"function","doc":"Adds the specified SSL server certificate to the certificate list for the specified HTTPS or TLS listener. If the certificate in already in the certificate list, the call is successful but the certificate is not added again. To get the certificate list for a listener, use DescribeListenerCertificates. To remove certificates from the certificate list for a listener, use RemoveListenerCertificates. To replace the default certificate for a listener, use ModifyListener. For more information, see SSL Certificates in the Application Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancingv2.html#add_tags/3","title":"AWS.ElasticLoadBalancingv2.add_tags/3","type":"function","doc":"Adds the specified tags to the specified Elastic Load Balancing resource. You can tag your Application Load Balancers, Network Load Balancers, target groups, listeners, and rules. Each tag consists of a key and an optional value. If a resource already has a tag with the same key, AddTags updates its value. To list the current tags for your resources, use DescribeTags. To remove tags from your resources, use RemoveTags."},{"ref":"AWS.ElasticLoadBalancingv2.html#create_listener/3","title":"AWS.ElasticLoadBalancingv2.create_listener/3","type":"function","doc":"Creates a listener for the specified Application Load Balancer or Network Load Balancer. To update a listener, use ModifyListener. When you are finished with a listener, you can delete it using DeleteListener. If you are finished with both the listener and the load balancer, you can delete them both using DeleteLoadBalancer. This operation is idempotent, which means that it completes at most one time. If you attempt to create multiple listeners with the same settings, each call succeeds. For more information, see Listeners for Your Application Load Balancers in the Application Load Balancers Guide and Listeners for Your Network Load Balancers in the Network Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancingv2.html#create_load_balancer/3","title":"AWS.ElasticLoadBalancingv2.create_load_balancer/3","type":"function","doc":"Creates an Application Load Balancer or a Network Load Balancer. When you create a load balancer, you can specify security groups, public subnets, IP address type, and tags. Otherwise, you could do so later using SetSecurityGroups, SetSubnets, SetIpAddressType, and AddTags. To create listeners for your load balancer, use CreateListener. To describe your current load balancers, see DescribeLoadBalancers. When you are finished with a load balancer, you can delete it using DeleteLoadBalancer. For limit information, see Limits for Your Application Load Balancer in the Application Load Balancers Guide and Limits for Your Network Load Balancer in the Network Load Balancers Guide. This operation is idempotent, which means that it completes at most one time. If you attempt to create multiple load balancers with the same settings, each call succeeds. For more information, see Application Load Balancers in the Application Load Balancers Guide and Network Load Balancers in the Network Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancingv2.html#create_rule/3","title":"AWS.ElasticLoadBalancingv2.create_rule/3","type":"function","doc":"Creates a rule for the specified listener. The listener must be associated with an Application Load Balancer. Each rule consists of a priority, one or more actions, and one or more conditions. Rules are evaluated in priority order, from the lowest value to the highest value. When the conditions for a rule are met, its actions are performed. If the conditions for no rules are met, the actions for the default rule are performed. For more information, see Listener Rules in the Application Load Balancers Guide. To view your current rules, use DescribeRules. To update a rule, use ModifyRule. To set the priorities of your rules, use SetRulePriorities. To delete a rule, use DeleteRule."},{"ref":"AWS.ElasticLoadBalancingv2.html#create_target_group/3","title":"AWS.ElasticLoadBalancingv2.create_target_group/3","type":"function","doc":"Creates a target group. To register targets with the target group, use RegisterTargets. To update the health check settings for the target group, use ModifyTargetGroup. To monitor the health of targets in the target group, use DescribeTargetHealth. To route traffic to the targets in a target group, specify the target group in an action using CreateListener or CreateRule. To delete a target group, use DeleteTargetGroup. This operation is idempotent, which means that it completes at most one time. If you attempt to create multiple target groups with the same settings, each call succeeds. For more information, see Target Groups for Your Application Load Balancers in the Application Load Balancers Guide or Target Groups for Your Network Load Balancers in the Network Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancingv2.html#delete_listener/3","title":"AWS.ElasticLoadBalancingv2.delete_listener/3","type":"function","doc":"Deletes the specified listener. Alternatively, your listener is deleted when you delete the load balancer to which it is attached, using DeleteLoadBalancer."},{"ref":"AWS.ElasticLoadBalancingv2.html#delete_load_balancer/3","title":"AWS.ElasticLoadBalancingv2.delete_load_balancer/3","type":"function","doc":"Deletes the specified Application Load Balancer or Network Load Balancer and its attached listeners. You can&#39;t delete a load balancer if deletion protection is enabled. If the load balancer does not exist or has already been deleted, the call succeeds. Deleting a load balancer does not affect its registered targets. For example, your EC2 instances continue to run and are still registered to their target groups. If you no longer need these EC2 instances, you can stop or terminate them."},{"ref":"AWS.ElasticLoadBalancingv2.html#delete_rule/3","title":"AWS.ElasticLoadBalancingv2.delete_rule/3","type":"function","doc":"Deletes the specified rule. You can&#39;t delete the default rule."},{"ref":"AWS.ElasticLoadBalancingv2.html#delete_target_group/3","title":"AWS.ElasticLoadBalancingv2.delete_target_group/3","type":"function","doc":"Deletes the specified target group. You can delete a target group if it is not referenced by any actions. Deleting a target group also deletes any associated health checks."},{"ref":"AWS.ElasticLoadBalancingv2.html#deregister_targets/3","title":"AWS.ElasticLoadBalancingv2.deregister_targets/3","type":"function","doc":"Deregisters the specified targets from the specified target group. After the targets are deregistered, they no longer receive traffic from the load balancer."},{"ref":"AWS.ElasticLoadBalancingv2.html#describe_account_limits/3","title":"AWS.ElasticLoadBalancingv2.describe_account_limits/3","type":"function","doc":"Describes the current Elastic Load Balancing resource limits for your AWS account. For more information, see Limits for Your Application Load Balancers in the Application Load Balancer Guide or Limits for Your Network Load Balancers in the Network Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancingv2.html#describe_listener_certificates/3","title":"AWS.ElasticLoadBalancingv2.describe_listener_certificates/3","type":"function","doc":"Describes the default certificate and the certificate list for the specified HTTPS or TLS listener. If the default certificate is also in the certificate list, it appears twice in the results (once with IsDefault set to true and once with IsDefault set to false). For more information, see SSL Certificates in the Application Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancingv2.html#describe_listeners/3","title":"AWS.ElasticLoadBalancingv2.describe_listeners/3","type":"function","doc":"Describes the specified listeners or the listeners for the specified Application Load Balancer or Network Load Balancer. You must specify either a load balancer or one or more listeners. For an HTTPS or TLS listener, the output includes the default certificate for the listener. To describe the certificate list for the listener, use DescribeListenerCertificates."},{"ref":"AWS.ElasticLoadBalancingv2.html#describe_load_balancer_attributes/3","title":"AWS.ElasticLoadBalancingv2.describe_load_balancer_attributes/3","type":"function","doc":"Describes the attributes for the specified Application Load Balancer or Network Load Balancer. For more information, see Load Balancer Attributes in the Application Load Balancers Guide or Load Balancer Attributes in the Network Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancingv2.html#describe_load_balancers/3","title":"AWS.ElasticLoadBalancingv2.describe_load_balancers/3","type":"function","doc":"Describes the specified load balancers or all of your load balancers. To describe the listeners for a load balancer, use DescribeListeners. To describe the attributes for a load balancer, use DescribeLoadBalancerAttributes."},{"ref":"AWS.ElasticLoadBalancingv2.html#describe_rules/3","title":"AWS.ElasticLoadBalancingv2.describe_rules/3","type":"function","doc":"Describes the specified rules or the rules for the specified listener. You must specify either a listener or one or more rules."},{"ref":"AWS.ElasticLoadBalancingv2.html#describe_s_s_l_policies/3","title":"AWS.ElasticLoadBalancingv2.describe_s_s_l_policies/3","type":"function","doc":"Describes the specified policies or all policies used for SSL negotiation. For more information, see Security Policies in the Application Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancingv2.html#describe_tags/3","title":"AWS.ElasticLoadBalancingv2.describe_tags/3","type":"function","doc":"Describes the tags for the specified Elastic Load Balancing resources. You can describe the tags for one or more Application Load Balancers, Network Load Balancers, target groups, listeners, or rules."},{"ref":"AWS.ElasticLoadBalancingv2.html#describe_target_group_attributes/3","title":"AWS.ElasticLoadBalancingv2.describe_target_group_attributes/3","type":"function","doc":"Describes the attributes for the specified target group. For more information, see Target Group Attributes in the Application Load Balancers Guide or Target Group Attributes in the Network Load Balancers Guide."},{"ref":"AWS.ElasticLoadBalancingv2.html#describe_target_groups/3","title":"AWS.ElasticLoadBalancingv2.describe_target_groups/3","type":"function","doc":"Describes the specified target groups or all of your target groups. By default, all target groups are described. Alternatively, you can specify one of the following to filter the results: the ARN of the load balancer, the names of one or more target groups, or the ARNs of one or more target groups. To describe the targets for a target group, use DescribeTargetHealth. To describe the attributes of a target group, use DescribeTargetGroupAttributes."},{"ref":"AWS.ElasticLoadBalancingv2.html#describe_target_health/3","title":"AWS.ElasticLoadBalancingv2.describe_target_health/3","type":"function","doc":"Describes the health of the specified targets or all of your targets."},{"ref":"AWS.ElasticLoadBalancingv2.html#modify_listener/3","title":"AWS.ElasticLoadBalancingv2.modify_listener/3","type":"function","doc":"Replaces the specified properties of the specified listener. Any properties that you do not specify remain unchanged. Changing the protocol from HTTPS to HTTP, or from TLS to TCP, removes the security policy and default certificate properties. If you change the protocol from HTTP to HTTPS, or from TCP to TLS, you must add the security policy and default certificate properties. To add an item to a list, remove an item from a list, or update an item in a list, you must provide the entire list. For example, to add an action, specify a list with the current actions plus the new action."},{"ref":"AWS.ElasticLoadBalancingv2.html#modify_load_balancer_attributes/3","title":"AWS.ElasticLoadBalancingv2.modify_load_balancer_attributes/3","type":"function","doc":"Modifies the specified attributes of the specified Application Load Balancer or Network Load Balancer. If any of the specified attributes can&#39;t be modified as requested, the call fails. Any existing attributes that you do not modify retain their current values."},{"ref":"AWS.ElasticLoadBalancingv2.html#modify_rule/3","title":"AWS.ElasticLoadBalancingv2.modify_rule/3","type":"function","doc":"Replaces the specified properties of the specified rule. Any properties that you do not specify are unchanged. To add an item to a list, remove an item from a list, or update an item in a list, you must provide the entire list. For example, to add an action, specify a list with the current actions plus the new action. To modify the actions for the default rule, use ModifyListener."},{"ref":"AWS.ElasticLoadBalancingv2.html#modify_target_group/3","title":"AWS.ElasticLoadBalancingv2.modify_target_group/3","type":"function","doc":"Modifies the health checks used when evaluating the health state of the targets in the specified target group. To monitor the health of the targets, use DescribeTargetHealth."},{"ref":"AWS.ElasticLoadBalancingv2.html#modify_target_group_attributes/3","title":"AWS.ElasticLoadBalancingv2.modify_target_group_attributes/3","type":"function","doc":"Modifies the specified attributes of the specified target group."},{"ref":"AWS.ElasticLoadBalancingv2.html#register_targets/3","title":"AWS.ElasticLoadBalancingv2.register_targets/3","type":"function","doc":"Registers the specified targets with the specified target group. If the target is an EC2 instance, it must be in the running state when you register it. By default, the load balancer routes requests to registered targets using the protocol and port for the target group. Alternatively, you can override the port for a target when you register it. You can register each EC2 instance or IP address with the same target group multiple times using different ports. With a Network Load Balancer, you cannot register instances by instance ID if they have the following instance types: C1, CC1, CC2, CG1, CG2, CR1, CS1, G1, G2, HI1, HS1, M1, M2, M3, and T1. You can register instances of these types by IP address. To remove a target from a target group, use DeregisterTargets."},{"ref":"AWS.ElasticLoadBalancingv2.html#remove_listener_certificates/3","title":"AWS.ElasticLoadBalancingv2.remove_listener_certificates/3","type":"function","doc":"Removes the specified certificate from the certificate list for the specified HTTPS or TLS listener. You can&#39;t remove the default certificate for a listener. To replace the default certificate, call ModifyListener. To list the certificates for your listener, use DescribeListenerCertificates."},{"ref":"AWS.ElasticLoadBalancingv2.html#remove_tags/3","title":"AWS.ElasticLoadBalancingv2.remove_tags/3","type":"function","doc":"Removes the specified tags from the specified Elastic Load Balancing resources. You can remove the tags for one or more Application Load Balancers, Network Load Balancers, target groups, listeners, or rules. To list the current tags for your resources, use DescribeTags."},{"ref":"AWS.ElasticLoadBalancingv2.html#set_ip_address_type/3","title":"AWS.ElasticLoadBalancingv2.set_ip_address_type/3","type":"function","doc":"Sets the type of IP addresses used by the subnets of the specified Application Load Balancer or Network Load Balancer."},{"ref":"AWS.ElasticLoadBalancingv2.html#set_rule_priorities/3","title":"AWS.ElasticLoadBalancingv2.set_rule_priorities/3","type":"function","doc":"Sets the priorities of the specified rules. You can reorder the rules as long as there are no priority conflicts in the new order. Any existing rules that you do not specify retain their current priority."},{"ref":"AWS.ElasticLoadBalancingv2.html#set_security_groups/3","title":"AWS.ElasticLoadBalancingv2.set_security_groups/3","type":"function","doc":"Associates the specified security groups with the specified Application Load Balancer. The specified security groups override the previously associated security groups. You can&#39;t specify a security group for a Network Load Balancer."},{"ref":"AWS.ElasticLoadBalancingv2.html#set_subnets/3","title":"AWS.ElasticLoadBalancingv2.set_subnets/3","type":"function","doc":"Enables the Availability Zones for the specified public subnets for the specified load balancer. The specified subnets replace the previously enabled subnets. When you specify subnets for a Network Load Balancer, you must include all subnets that were enabled previously, with their existing configurations, plus any additional subnets."},{"ref":"AWS.ElasticTranscoder.html","title":"AWS.ElasticTranscoder","type":"module","doc":"AWS Elastic Transcoder Service The AWS Elastic Transcoder Service."},{"ref":"AWS.ElasticTranscoder.html#cancel_job/4","title":"AWS.ElasticTranscoder.cancel_job/4","type":"function","doc":"The CancelJob operation cancels an unfinished job. You can only cancel a job that has a status of Submitted. To prevent a pipeline from starting to process a job while you&#39;re getting the job identifier, use UpdatePipelineStatus to temporarily pause the pipeline."},{"ref":"AWS.ElasticTranscoder.html#create_job/3","title":"AWS.ElasticTranscoder.create_job/3","type":"function","doc":"When you create a job, Elastic Transcoder returns JSON data that includes the values that you specified plus information about the job that is created. If you have specified more than one output for your jobs (for example, one output for the Kindle Fire and another output for the Apple iPhone 4s), you currently must use the Elastic Transcoder API to list the jobs (as opposed to the AWS Console)."},{"ref":"AWS.ElasticTranscoder.html#create_pipeline/3","title":"AWS.ElasticTranscoder.create_pipeline/3","type":"function","doc":"The CreatePipeline operation creates a pipeline with settings that you specify."},{"ref":"AWS.ElasticTranscoder.html#create_preset/3","title":"AWS.ElasticTranscoder.create_preset/3","type":"function","doc":"The CreatePreset operation creates a preset with settings that you specify. Elastic Transcoder checks the CreatePreset settings to ensure that they meet Elastic Transcoder requirements and to determine whether they comply with H.264 standards. If your settings are not valid for Elastic Transcoder, Elastic Transcoder returns an HTTP 400 response (ValidationException) and does not create the preset. If the settings are valid for Elastic Transcoder but aren&#39;t strictly compliant with the H.264 standard, Elastic Transcoder creates the preset and returns a warning message in the response. This helps you determine whether your settings comply with the H.264 standard while giving you greater flexibility with respect to the video that Elastic Transcoder produces. Elastic Transcoder uses the H.264 video-compression format. For more information, see the International Telecommunication Union publication Recommendation ITU-T H.264: Advanced video coding for generic audiovisual services."},{"ref":"AWS.ElasticTranscoder.html#delete_pipeline/4","title":"AWS.ElasticTranscoder.delete_pipeline/4","type":"function","doc":"The DeletePipeline operation removes a pipeline. You can only delete a pipeline that has never been used or that is not currently in use (doesn&#39;t contain any active jobs). If the pipeline is currently in use, DeletePipeline returns an error."},{"ref":"AWS.ElasticTranscoder.html#delete_preset/4","title":"AWS.ElasticTranscoder.delete_preset/4","type":"function","doc":"The DeletePreset operation removes a preset that you&#39;ve added in an AWS region. You can&#39;t delete the default presets that are included with Elastic Transcoder."},{"ref":"AWS.ElasticTranscoder.html#list_jobs_by_pipeline/5","title":"AWS.ElasticTranscoder.list_jobs_by_pipeline/5","type":"function","doc":"The ListJobsByPipeline operation gets a list of the jobs currently in a pipeline. Elastic Transcoder returns all of the jobs currently in the specified pipeline. The response body contains one element for each job that satisfies the search criteria."},{"ref":"AWS.ElasticTranscoder.html#list_jobs_by_status/5","title":"AWS.ElasticTranscoder.list_jobs_by_status/5","type":"function","doc":"The ListJobsByStatus operation gets a list of jobs that have a specified status. The response body contains one element for each job that satisfies the search criteria."},{"ref":"AWS.ElasticTranscoder.html#list_pipelines/4","title":"AWS.ElasticTranscoder.list_pipelines/4","type":"function","doc":"The ListPipelines operation gets a list of the pipelines associated with the current AWS account."},{"ref":"AWS.ElasticTranscoder.html#list_presets/4","title":"AWS.ElasticTranscoder.list_presets/4","type":"function","doc":"The ListPresets operation gets a list of the default presets included with Elastic Transcoder and the presets that you&#39;ve added in an AWS region."},{"ref":"AWS.ElasticTranscoder.html#read_job/3","title":"AWS.ElasticTranscoder.read_job/3","type":"function","doc":"The ReadJob operation returns detailed information about a job."},{"ref":"AWS.ElasticTranscoder.html#read_pipeline/3","title":"AWS.ElasticTranscoder.read_pipeline/3","type":"function","doc":"The ReadPipeline operation gets detailed information about a pipeline."},{"ref":"AWS.ElasticTranscoder.html#read_preset/3","title":"AWS.ElasticTranscoder.read_preset/3","type":"function","doc":"The ReadPreset operation gets detailed information about a preset."},{"ref":"AWS.ElasticTranscoder.html#test_role/3","title":"AWS.ElasticTranscoder.test_role/3","type":"function","doc":"The TestRole operation tests the IAM role used to create the pipeline. The TestRole action lets you determine whether the IAM role you are using has sufficient permissions to let Elastic Transcoder perform tasks associated with the transcoding process. The action attempts to assume the specified IAM role, checks read access to the input and output buckets, and tries to send a test notification to Amazon SNS topics that you specify."},{"ref":"AWS.ElasticTranscoder.html#update_pipeline/4","title":"AWS.ElasticTranscoder.update_pipeline/4","type":"function","doc":"Use the UpdatePipeline operation to update settings for a pipeline. When you change pipeline settings, your changes take effect immediately. Jobs that you have already submitted and that Elastic Transcoder has not started to process are affected in addition to jobs that you submit after you change settings."},{"ref":"AWS.ElasticTranscoder.html#update_pipeline_notifications/4","title":"AWS.ElasticTranscoder.update_pipeline_notifications/4","type":"function","doc":"With the UpdatePipelineNotifications operation, you can update Amazon Simple Notification Service (Amazon SNS) notifications for a pipeline. When you update notifications for a pipeline, Elastic Transcoder returns the values that you specified in the request."},{"ref":"AWS.ElasticTranscoder.html#update_pipeline_status/4","title":"AWS.ElasticTranscoder.update_pipeline_status/4","type":"function","doc":"The UpdatePipelineStatus operation pauses or reactivates a pipeline, so that the pipeline stops or restarts the processing of jobs. Changing the pipeline status is useful if you want to cancel one or more jobs. You can&#39;t cancel jobs after Elastic Transcoder has started processing them; if you pause the pipeline to which you submitted the jobs, you have more time to get the job IDs for the jobs that you want to cancel, and to send a CancelJob request."},{"ref":"AWS.Elasticsearch.html","title":"AWS.Elasticsearch","type":"module","doc":"Amazon Elasticsearch Configuration Service Use the Amazon Elasticsearch Configuration API to create, configure, and manage Elasticsearch domains. For sample code that uses the Configuration API, see the Amazon Elasticsearch Service Developer Guide. The guide also contains sample code for sending signed HTTP requests to the Elasticsearch APIs. The endpoint for configuration service requests is region-specific: es.region.amazonaws.com. For example, es.us-east-1.amazonaws.com. For a current list of supported regions and endpoints, see Regions and Endpoints."},{"ref":"AWS.Elasticsearch.html#accept_inbound_cross_cluster_search_connection/4","title":"AWS.Elasticsearch.accept_inbound_cross_cluster_search_connection/4","type":"function","doc":"Allows the destination domain owner to accept an inbound cross-cluster search connection request."},{"ref":"AWS.Elasticsearch.html#add_tags/3","title":"AWS.Elasticsearch.add_tags/3","type":"function","doc":"Attaches tags to an existing Elasticsearch domain. Tags are a set of case-sensitive key value pairs. An Elasticsearch domain may have up to 10 tags. See Tagging Amazon Elasticsearch Service Domains for more information."},{"ref":"AWS.Elasticsearch.html#associate_package/5","title":"AWS.Elasticsearch.associate_package/5","type":"function","doc":"Associates a package with an Amazon ES domain."},{"ref":"AWS.Elasticsearch.html#cancel_elasticsearch_service_software_update/3","title":"AWS.Elasticsearch.cancel_elasticsearch_service_software_update/3","type":"function","doc":"Cancels a scheduled service software update for an Amazon ES domain. You can only perform this operation before the AutomatedUpdateDate and when the UpdateStatus is in the PENDING_UPDATE state."},{"ref":"AWS.Elasticsearch.html#create_elasticsearch_domain/3","title":"AWS.Elasticsearch.create_elasticsearch_domain/3","type":"function","doc":"Creates a new Elasticsearch domain. For more information, see Creating Elasticsearch Domains in the Amazon Elasticsearch Service Developer Guide."},{"ref":"AWS.Elasticsearch.html#create_outbound_cross_cluster_search_connection/3","title":"AWS.Elasticsearch.create_outbound_cross_cluster_search_connection/3","type":"function","doc":"Creates a new cross-cluster search connection from a source domain to a destination domain."},{"ref":"AWS.Elasticsearch.html#create_package/3","title":"AWS.Elasticsearch.create_package/3","type":"function","doc":"Create a package for use with Amazon ES domains."},{"ref":"AWS.Elasticsearch.html#delete_elasticsearch_domain/4","title":"AWS.Elasticsearch.delete_elasticsearch_domain/4","type":"function","doc":"Permanently deletes the specified Elasticsearch domain and all of its data. Once a domain is deleted, it cannot be recovered."},{"ref":"AWS.Elasticsearch.html#delete_elasticsearch_service_role/3","title":"AWS.Elasticsearch.delete_elasticsearch_service_role/3","type":"function","doc":"Deletes the service-linked role that Elasticsearch Service uses to manage and maintain VPC domains. Role deletion will fail if any existing VPC domains use the role. You must delete any such Elasticsearch domains before deleting the role. See Deleting Elasticsearch Service Role in VPC Endpoints for Amazon Elasticsearch Service Domains."},{"ref":"AWS.Elasticsearch.html#delete_inbound_cross_cluster_search_connection/4","title":"AWS.Elasticsearch.delete_inbound_cross_cluster_search_connection/4","type":"function","doc":"Allows the destination domain owner to delete an existing inbound cross-cluster search connection."},{"ref":"AWS.Elasticsearch.html#delete_outbound_cross_cluster_search_connection/4","title":"AWS.Elasticsearch.delete_outbound_cross_cluster_search_connection/4","type":"function","doc":"Allows the source domain owner to delete an existing outbound cross-cluster search connection."},{"ref":"AWS.Elasticsearch.html#delete_package/4","title":"AWS.Elasticsearch.delete_package/4","type":"function","doc":"Delete the package."},{"ref":"AWS.Elasticsearch.html#describe_elasticsearch_domain/3","title":"AWS.Elasticsearch.describe_elasticsearch_domain/3","type":"function","doc":"Returns domain configuration information about the specified Elasticsearch domain, including the domain ID, domain endpoint, and domain ARN."},{"ref":"AWS.Elasticsearch.html#describe_elasticsearch_domain_config/3","title":"AWS.Elasticsearch.describe_elasticsearch_domain_config/3","type":"function","doc":"Provides cluster configuration information about the specified Elasticsearch domain, such as the state, creation date, update version, and update date for cluster options."},{"ref":"AWS.Elasticsearch.html#describe_elasticsearch_domains/3","title":"AWS.Elasticsearch.describe_elasticsearch_domains/3","type":"function","doc":"Returns domain configuration information about the specified Elasticsearch domains, including the domain ID, domain endpoint, and domain ARN."},{"ref":"AWS.Elasticsearch.html#describe_elasticsearch_instance_type_limits/5","title":"AWS.Elasticsearch.describe_elasticsearch_instance_type_limits/5","type":"function","doc":"Describe Elasticsearch Limits for a given InstanceType and ElasticsearchVersion. When modifying existing Domain, specify the DomainName to know what Limits are supported for modifying."},{"ref":"AWS.Elasticsearch.html#describe_inbound_cross_cluster_search_connections/3","title":"AWS.Elasticsearch.describe_inbound_cross_cluster_search_connections/3","type":"function","doc":"Lists all the inbound cross-cluster search connections for a destination domain."},{"ref":"AWS.Elasticsearch.html#describe_outbound_cross_cluster_search_connections/3","title":"AWS.Elasticsearch.describe_outbound_cross_cluster_search_connections/3","type":"function","doc":"Lists all the outbound cross-cluster search connections for a source domain."},{"ref":"AWS.Elasticsearch.html#describe_packages/3","title":"AWS.Elasticsearch.describe_packages/3","type":"function","doc":"Describes all packages available to Amazon ES. Includes options for filtering, limiting the number of results, and pagination."},{"ref":"AWS.Elasticsearch.html#describe_reserved_elasticsearch_instance_offerings/5","title":"AWS.Elasticsearch.describe_reserved_elasticsearch_instance_offerings/5","type":"function","doc":"Lists available reserved Elasticsearch instance offerings."},{"ref":"AWS.Elasticsearch.html#describe_reserved_elasticsearch_instances/5","title":"AWS.Elasticsearch.describe_reserved_elasticsearch_instances/5","type":"function","doc":"Returns information about reserved Elasticsearch instances for this account."},{"ref":"AWS.Elasticsearch.html#dissociate_package/5","title":"AWS.Elasticsearch.dissociate_package/5","type":"function","doc":"Dissociates a package from the Amazon ES domain."},{"ref":"AWS.Elasticsearch.html#get_compatible_elasticsearch_versions/3","title":"AWS.Elasticsearch.get_compatible_elasticsearch_versions/3","type":"function","doc":"Returns a list of upgrade compatible Elastisearch versions. You can optionally pass a DomainName to get all upgrade compatible Elasticsearch versions for that specific domain."},{"ref":"AWS.Elasticsearch.html#get_upgrade_history/5","title":"AWS.Elasticsearch.get_upgrade_history/5","type":"function","doc":"Retrieves the complete history of the last 10 upgrades that were performed on the domain."},{"ref":"AWS.Elasticsearch.html#get_upgrade_status/3","title":"AWS.Elasticsearch.get_upgrade_status/3","type":"function","doc":"Retrieves the latest status of the last upgrade or upgrade eligibility check that was performed on the domain."},{"ref":"AWS.Elasticsearch.html#list_domain_names/2","title":"AWS.Elasticsearch.list_domain_names/2","type":"function","doc":"Returns the name of all Elasticsearch domains owned by the current user&#39;s account."},{"ref":"AWS.Elasticsearch.html#list_domains_for_package/5","title":"AWS.Elasticsearch.list_domains_for_package/5","type":"function","doc":"Lists all Amazon ES domains associated with the package."},{"ref":"AWS.Elasticsearch.html#list_elasticsearch_instance_types/6","title":"AWS.Elasticsearch.list_elasticsearch_instance_types/6","type":"function","doc":"List all Elasticsearch instance types that are supported for given ElasticsearchVersion"},{"ref":"AWS.Elasticsearch.html#list_elasticsearch_versions/4","title":"AWS.Elasticsearch.list_elasticsearch_versions/4","type":"function","doc":"List all supported Elasticsearch versions"},{"ref":"AWS.Elasticsearch.html#list_packages_for_domain/5","title":"AWS.Elasticsearch.list_packages_for_domain/5","type":"function","doc":"Lists all packages associated with the Amazon ES domain."},{"ref":"AWS.Elasticsearch.html#list_tags/3","title":"AWS.Elasticsearch.list_tags/3","type":"function","doc":"Returns all tags for the given Elasticsearch domain."},{"ref":"AWS.Elasticsearch.html#purchase_reserved_elasticsearch_instance_offering/3","title":"AWS.Elasticsearch.purchase_reserved_elasticsearch_instance_offering/3","type":"function","doc":"Allows you to purchase reserved Elasticsearch instances."},{"ref":"AWS.Elasticsearch.html#reject_inbound_cross_cluster_search_connection/4","title":"AWS.Elasticsearch.reject_inbound_cross_cluster_search_connection/4","type":"function","doc":"Allows the destination domain owner to reject an inbound cross-cluster search connection request."},{"ref":"AWS.Elasticsearch.html#remove_tags/3","title":"AWS.Elasticsearch.remove_tags/3","type":"function","doc":"Removes the specified set of tags from the specified Elasticsearch domain."},{"ref":"AWS.Elasticsearch.html#start_elasticsearch_service_software_update/3","title":"AWS.Elasticsearch.start_elasticsearch_service_software_update/3","type":"function","doc":"Schedules a service software update for an Amazon ES domain."},{"ref":"AWS.Elasticsearch.html#update_elasticsearch_domain_config/4","title":"AWS.Elasticsearch.update_elasticsearch_domain_config/4","type":"function","doc":"Modifies the cluster configuration of the specified Elasticsearch domain, setting as setting the instance type and the number of instances."},{"ref":"AWS.Elasticsearch.html#upgrade_elasticsearch_domain/3","title":"AWS.Elasticsearch.upgrade_elasticsearch_domain/3","type":"function","doc":"Allows you to either upgrade your domain or perform an Upgrade eligibility check to a compatible Elasticsearch version."},{"ref":"AWS.Entitlement.Marketplace.html","title":"AWS.Entitlement.Marketplace","type":"module","doc":"AWS Marketplace Entitlement Service This reference provides descriptions of the AWS Marketplace Entitlement Service API. AWS Marketplace Entitlement Service is used to determine the entitlement of a customer to a given product. An entitlement represents capacity in a product owned by the customer. For example, a customer might own some number of users or seats in an SaaS application or some amount of data capacity in a multi-tenant database. Getting Entitlement Records GetEntitlements- Gets the entitlements for a Marketplace product."},{"ref":"AWS.Entitlement.Marketplace.html#get_entitlements/3","title":"AWS.Entitlement.Marketplace.get_entitlements/3","type":"function","doc":"GetEntitlements retrieves entitlement values for a given product. The results can be filtered based on customer identifier or product dimensions."},{"ref":"AWS.EventBridge.html","title":"AWS.EventBridge","type":"module","doc":"Amazon EventBridge helps you to respond to state changes in your AWS resources. When your resources change state, they automatically send events into an event stream. You can create rules that match selected events in the stream and route them to targets to take action. You can also use rules to take action on a predetermined schedule. For example, you can configure rules to: Automatically invoke an AWS Lambda function to update DNS entries when an event notifies you that Amazon EC2 instance enters the running state. Direct specific API records from AWS CloudTrail to an Amazon Kinesis data stream for detailed analysis of potential security or availability risks. Periodically invoke a built-in target to create a snapshot of an Amazon EBS volume. For more information about the features of Amazon EventBridge, see the Amazon EventBridge User Guide."},{"ref":"AWS.EventBridge.html#activate_event_source/3","title":"AWS.EventBridge.activate_event_source/3","type":"function","doc":"Activates a partner event source that has been deactivated. Once activated, your matching event bus will start receiving events from the event source."},{"ref":"AWS.EventBridge.html#create_event_bus/3","title":"AWS.EventBridge.create_event_bus/3","type":"function","doc":"Creates a new event bus within your account. This can be a custom event bus which you can use to receive events from your custom applications and services, or it can be a partner event bus which can be matched to a partner event source."},{"ref":"AWS.EventBridge.html#create_partner_event_source/3","title":"AWS.EventBridge.create_partner_event_source/3","type":"function","doc":"Called by an SaaS partner to create a partner event source. This operation is not used by AWS customers. Each partner event source can be used by one AWS account to create a matching partner event bus in that AWS account. A SaaS partner must create one partner event source for each AWS account that wants to receive those event types. A partner event source creates events based on resources within the SaaS partner&#39;s service or application. An AWS account that creates a partner event bus that matches the partner event source can use that event bus to receive events from the partner, and then process them using AWS Events rules and targets. Partner event source names follow this format: *partner_name*/*event_namespace*/*event_name* partner_name is determined during partner registration and identifies the partner to AWS customers. event_namespace is determined by the partner and is a way for the partner to categorize their events. event_name is determined by the partner, and should uniquely identify an event-generating resource within the partner system. The combination of event_namespace and event_name should help AWS customers decide whether to create an event bus to receive these events."},{"ref":"AWS.EventBridge.html#deactivate_event_source/3","title":"AWS.EventBridge.deactivate_event_source/3","type":"function","doc":"You can use this operation to temporarily stop receiving events from the specified partner event source. The matching event bus is not deleted. When you deactivate a partner event source, the source goes into PENDING state. If it remains in PENDING state for more than two weeks, it is deleted. To activate a deactivated partner event source, use ActivateEventSource."},{"ref":"AWS.EventBridge.html#delete_event_bus/3","title":"AWS.EventBridge.delete_event_bus/3","type":"function","doc":"Deletes the specified custom event bus or partner event bus. All rules associated with this event bus need to be deleted. You can&#39;t delete your account&#39;s default event bus."},{"ref":"AWS.EventBridge.html#delete_partner_event_source/3","title":"AWS.EventBridge.delete_partner_event_source/3","type":"function","doc":"This operation is used by SaaS partners to delete a partner event source. This operation is not used by AWS customers. When you delete an event source, the status of the corresponding partner event bus in the AWS customer account becomes DELETED."},{"ref":"AWS.EventBridge.html#delete_rule/3","title":"AWS.EventBridge.delete_rule/3","type":"function","doc":"Deletes the specified rule. Before you can delete the rule, you must remove all targets, using RemoveTargets. When you delete a rule, incoming events might continue to match to the deleted rule. Allow a short period of time for changes to take effect. Managed rules are rules created and managed by another AWS service on your behalf. These rules are created by those other AWS services to support functionality in those services. You can delete these rules using the Force option, but you should do so only if you are sure the other service is not still using that rule."},{"ref":"AWS.EventBridge.html#describe_event_bus/3","title":"AWS.EventBridge.describe_event_bus/3","type":"function","doc":"Displays details about an event bus in your account. This can include the external AWS accounts that are permitted to write events to your default event bus, and the associated policy. For custom event buses and partner event buses, it displays the name, ARN, policy, state, and creation time. To enable your account to receive events from other accounts on its default event bus, use PutPermission. For more information about partner event buses, see CreateEventBus."},{"ref":"AWS.EventBridge.html#describe_event_source/3","title":"AWS.EventBridge.describe_event_source/3","type":"function","doc":"This operation lists details about a partner event source that is shared with your account."},{"ref":"AWS.EventBridge.html#describe_partner_event_source/3","title":"AWS.EventBridge.describe_partner_event_source/3","type":"function","doc":"An SaaS partner can use this operation to list details about a partner event source that they have created. AWS customers do not use this operation. Instead, AWS customers can use DescribeEventSource to see details about a partner event source that is shared with them."},{"ref":"AWS.EventBridge.html#describe_rule/3","title":"AWS.EventBridge.describe_rule/3","type":"function","doc":"Describes the specified rule. DescribeRule does not list the targets of a rule. To see the targets associated with a rule, use ListTargetsByRule."},{"ref":"AWS.EventBridge.html#disable_rule/3","title":"AWS.EventBridge.disable_rule/3","type":"function","doc":"Disables the specified rule. A disabled rule won&#39;t match any events, and won&#39;t self-trigger if it has a schedule expression. When you disable a rule, incoming events might continue to match to the disabled rule. Allow a short period of time for changes to take effect."},{"ref":"AWS.EventBridge.html#enable_rule/3","title":"AWS.EventBridge.enable_rule/3","type":"function","doc":"Enables the specified rule. If the rule does not exist, the operation fails. When you enable a rule, incoming events might not immediately start matching to a newly enabled rule. Allow a short period of time for changes to take effect."},{"ref":"AWS.EventBridge.html#list_event_buses/3","title":"AWS.EventBridge.list_event_buses/3","type":"function","doc":"Lists all the event buses in your account, including the default event bus, custom event buses, and partner event buses."},{"ref":"AWS.EventBridge.html#list_event_sources/3","title":"AWS.EventBridge.list_event_sources/3","type":"function","doc":"You can use this to see all the partner event sources that have been shared with your AWS account. For more information about partner event sources, see CreateEventBus."},{"ref":"AWS.EventBridge.html#list_partner_event_source_accounts/3","title":"AWS.EventBridge.list_partner_event_source_accounts/3","type":"function","doc":"An SaaS partner can use this operation to display the AWS account ID that a particular partner event source name is associated with. This operation is not used by AWS customers."},{"ref":"AWS.EventBridge.html#list_partner_event_sources/3","title":"AWS.EventBridge.list_partner_event_sources/3","type":"function","doc":"An SaaS partner can use this operation to list all the partner event source names that they have created. This operation is not used by AWS customers."},{"ref":"AWS.EventBridge.html#list_rule_names_by_target/3","title":"AWS.EventBridge.list_rule_names_by_target/3","type":"function","doc":"Lists the rules for the specified target. You can see which of the rules in Amazon EventBridge can invoke a specific target in your account."},{"ref":"AWS.EventBridge.html#list_rules/3","title":"AWS.EventBridge.list_rules/3","type":"function","doc":"Lists your Amazon EventBridge rules. You can either list all the rules or you can provide a prefix to match to the rule names. ListRules does not list the targets of a rule. To see the targets associated with a rule, use ListTargetsByRule."},{"ref":"AWS.EventBridge.html#list_tags_for_resource/3","title":"AWS.EventBridge.list_tags_for_resource/3","type":"function","doc":"Displays the tags associated with an EventBridge resource. In EventBridge, rules and event buses can be tagged."},{"ref":"AWS.EventBridge.html#list_targets_by_rule/3","title":"AWS.EventBridge.list_targets_by_rule/3","type":"function","doc":"Lists the targets assigned to the specified rule."},{"ref":"AWS.EventBridge.html#put_events/3","title":"AWS.EventBridge.put_events/3","type":"function","doc":"Sends custom events to Amazon EventBridge so that they can be matched to rules."},{"ref":"AWS.EventBridge.html#put_partner_events/3","title":"AWS.EventBridge.put_partner_events/3","type":"function","doc":"This is used by SaaS partners to write events to a customer&#39;s partner event bus. AWS customers do not use this operation."},{"ref":"AWS.EventBridge.html#put_permission/3","title":"AWS.EventBridge.put_permission/3","type":"function","doc":"Running PutPermission permits the specified AWS account or AWS organization to put events to the specified event bus. Amazon EventBridge (CloudWatch Events) rules in your account are triggered by these events arriving to an event bus in your account. For another account to send events to your account, that external account must have an EventBridge rule with your account&#39;s event bus as a target. To enable multiple AWS accounts to put events to your event bus, run PutPermission once for each of these accounts. Or, if all the accounts are members of the same AWS organization, you can run PutPermission once specifying Principal as &quot;*&quot; and specifying the AWS organization ID in Condition, to grant permissions to all accounts in that organization. If you grant permissions using an organization, then accounts in that organization must specify a RoleArn with proper permissions when they use PutTarget to add your account&#39;s event bus as a target. For more information, see Sending and Receiving Events Between AWS Accounts in the Amazon EventBridge User Guide. The permission policy on the default event bus cannot exceed 10 KB in size."},{"ref":"AWS.EventBridge.html#put_rule/3","title":"AWS.EventBridge.put_rule/3","type":"function","doc":"Creates or updates the specified rule. Rules are enabled by default, or based on value of the state. You can disable a rule using DisableRule. A single rule watches for events from a single event bus. Events generated by AWS services go to your account&#39;s default event bus. Events generated by SaaS partner services or applications go to the matching partner event bus. If you have custom applications or services, you can specify whether their events go to your default event bus or a custom event bus that you have created. For more information, see CreateEventBus. If you are updating an existing rule, the rule is replaced with what you specify in this PutRule command. If you omit arguments in PutRule, the old values for those arguments are not kept. Instead, they are replaced with null values. When you create or update a rule, incoming events might not immediately start matching to new or updated rules. Allow a short period of time for changes to take effect. A rule must contain at least an EventPattern or ScheduleExpression. Rules with EventPatterns are triggered when a matching event is observed. Rules with ScheduleExpressions self-trigger based on the given schedule. A rule can have both an EventPattern and a ScheduleExpression, in which case the rule triggers on matching events as well as on a schedule. When you initially create a rule, you can optionally assign one or more tags to the rule. Tags can help you organize and categorize your resources. You can also use them to scope user permissions, by granting a user permission to access or change only rules with certain tag values. To use the PutRule operation and assign tags, you must have both the events:PutRule and events:TagResource permissions. If you are updating an existing rule, any tags you specify in the PutRule operation are ignored. To update the tags of an existing rule, use TagResource and UntagResource. Most services in AWS treat : or / as the same character in Amazon Resource Names (ARNs). However, EventBridge uses an exact match in event patterns and rules. Be sure to use the correct ARN characters when creating event patterns so that they match the ARN syntax in the event you want to match. In EventBridge, it is possible to create rules that lead to infinite loops, where a rule is fired repeatedly. For example, a rule might detect that ACLs have changed on an S3 bucket, and trigger software to change them to the desired state. If the rule is not written carefully, the subsequent change to the ACLs fires the rule again, creating an infinite loop. To prevent this, write the rules so that the triggered actions do not re-fire the same rule. For example, your rule could fire only if ACLs are found to be in a bad state, instead of after any change. An infinite loop can quickly cause higher than expected charges. We recommend that you use budgeting, which alerts you when charges exceed your specified limit. For more information, see Managing Your Costs with Budgets."},{"ref":"AWS.EventBridge.html#put_targets/3","title":"AWS.EventBridge.put_targets/3","type":"function","doc":"Adds the specified targets to the specified rule, or updates the targets if they are already associated with the rule. Targets are the resources that are invoked when a rule is triggered. You can configure the following as targets for Events: EC2 instances SSM Run Command SSM Automation AWS Lambda functions Data streams in Amazon Kinesis Data Streams Data delivery streams in Amazon Kinesis Data Firehose Amazon ECS tasks AWS Step Functions state machines AWS Batch jobs AWS CodeBuild projects Pipelines in AWS CodePipeline Amazon Inspector assessment templates Amazon SNS topics Amazon SQS queues, including FIFO queues The default event bus of another AWS account Amazon API Gateway REST APIs Redshift Clusters to invoke Data API ExecuteStatement on Creating rules with built-in targets is supported only in the AWS Management Console. The built-in targets are EC2 CreateSnapshot API call, EC2 RebootInstances API call, EC2 StopInstances API call, and EC2 TerminateInstances API call. For some target types, PutTargets provides target-specific parameters. If the target is a Kinesis data stream, you can optionally specify which shard the event goes to by using the KinesisParameters argument. To invoke a command on multiple EC2 instances with one rule, you can use the RunCommandParameters field. To be able to make API calls against the resources that you own, Amazon EventBridge (CloudWatch Events) needs the appropriate permissions. For AWS Lambda and Amazon SNS resources, EventBridge relies on resource-based policies. For EC2 instances, Kinesis data streams, AWS Step Functions state machines and API Gateway REST APIs, EventBridge relies on IAM roles that you specify in the RoleARN argument in PutTargets. For more information, see Authentication and Access Control in the Amazon EventBridge User Guide. If another AWS account is in the same region and has granted you permission (using PutPermission), you can send events to that account. Set that account&#39;s event bus as a target of the rules in your account. To send the matched events to the other account, specify that account&#39;s event bus as the Arn value when you run PutTargets. If your account sends events to another account, your account is charged for each sent event. Each event sent to another account is charged as a custom event. The account receiving the event is not charged. For more information, see Amazon EventBridge (CloudWatch Events) Pricing. Input, InputPath, and InputTransformer are not available with PutTarget if the target is an event bus of a different AWS account. If you are setting the event bus of another account as the target, and that account granted permission to your account through an organization instead of directly by the account ID, then you must specify a RoleArn with proper permissions in the Target structure. For more information, see Sending and Receiving Events Between AWS Accounts in the Amazon EventBridge User Guide. For more information about enabling cross-account events, see PutPermission. Input, InputPath, and InputTransformer are mutually exclusive and optional parameters of a target. When a rule is triggered due to a matched event: If none of the following arguments are specified for a target, then the entire event is passed to the target in JSON format (unless the target is Amazon EC2 Run Command or Amazon ECS task, in which case nothing from the event is passed to the target). If Input is specified in the form of valid JSON, then the matched event is overridden with this constant. If InputPath is specified in the form of JSONPath (for example, $.detail), then only the part of the event specified in the path is passed to the target (for example, only the detail part of the event is passed). If InputTransformer is specified, then one or more specified JSONPaths are extracted from the event and used as values in a template that you specify as the input to the target. When you specify InputPath or InputTransformer, you must use JSON dot notation, not bracket notation. When you add targets to a rule and the associated rule triggers soon after, new or updated targets might not be immediately invoked. Allow a short period of time for changes to take effect. This action can partially fail if too many requests are made at the same time. If that happens, FailedEntryCount is non-zero in the response and each entry in FailedEntries provides the ID of the failed target and the error code."},{"ref":"AWS.EventBridge.html#remove_permission/3","title":"AWS.EventBridge.remove_permission/3","type":"function","doc":"Revokes the permission of another AWS account to be able to put events to the specified event bus. Specify the account to revoke by the StatementId value that you associated with the account when you granted it permission with PutPermission. You can find the StatementId by using DescribeEventBus."},{"ref":"AWS.EventBridge.html#remove_targets/3","title":"AWS.EventBridge.remove_targets/3","type":"function","doc":"Removes the specified targets from the specified rule. When the rule is triggered, those targets are no longer be invoked. When you remove a target, when the associated rule triggers, removed targets might continue to be invoked. Allow a short period of time for changes to take effect. This action can partially fail if too many requests are made at the same time. If that happens, FailedEntryCount is non-zero in the response and each entry in FailedEntries provides the ID of the failed target and the error code."},{"ref":"AWS.EventBridge.html#tag_resource/3","title":"AWS.EventBridge.tag_resource/3","type":"function","doc":"Assigns one or more tags (key-value pairs) to the specified EventBridge resource. Tags can help you organize and categorize your resources. You can also use them to scope user permissions by granting a user permission to access or change only resources with certain tag values. In EventBridge, rules and event buses can be tagged. Tags don&#39;t have any semantic meaning to AWS and are interpreted strictly as strings of characters. You can use the TagResource action with a resource that already has tags. If you specify a new tag key, this tag is appended to the list of tags associated with the resource. If you specify a tag key that is already associated with the resource, the new tag value that you specify replaces the previous value for that tag. You can associate as many as 50 tags with a resource."},{"ref":"AWS.EventBridge.html#test_event_pattern/3","title":"AWS.EventBridge.test_event_pattern/3","type":"function","doc":"Tests whether the specified event pattern matches the provided event. Most services in AWS treat : or / as the same character in Amazon Resource Names (ARNs). However, EventBridge uses an exact match in event patterns and rules. Be sure to use the correct ARN characters when creating event patterns so that they match the ARN syntax in the event you want to match."},{"ref":"AWS.EventBridge.html#untag_resource/3","title":"AWS.EventBridge.untag_resource/3","type":"function","doc":"Removes one or more tags from the specified EventBridge resource. In Amazon EventBridge (CloudWatch Events, rules and event buses can be tagged."},{"ref":"AWS.FMS.html","title":"AWS.FMS","type":"module","doc":"AWS Firewall Manager This is the AWS Firewall Manager API Reference. This guide is for developers who need detailed information about the AWS Firewall Manager API actions, data types, and errors. For detailed information about AWS Firewall Manager features, see the AWS Firewall Manager Developer Guide."},{"ref":"AWS.FMS.html#associate_admin_account/3","title":"AWS.FMS.associate_admin_account/3","type":"function","doc":"Sets the AWS Firewall Manager administrator account. AWS Firewall Manager must be associated with the master account of your AWS organization or associated with a member account that has the appropriate permissions. If the account ID that you submit is not an AWS Organizations master account, AWS Firewall Manager will set the appropriate permissions for the given member account. The account that you associate with AWS Firewall Manager is called the AWS Firewall Manager administrator account."},{"ref":"AWS.FMS.html#delete_apps_list/3","title":"AWS.FMS.delete_apps_list/3","type":"function","doc":"Permanently deletes an AWS Firewall Manager applications list."},{"ref":"AWS.FMS.html#delete_notification_channel/3","title":"AWS.FMS.delete_notification_channel/3","type":"function","doc":"Deletes an AWS Firewall Manager association with the IAM role and the Amazon Simple Notification Service (SNS) topic that is used to record AWS Firewall Manager SNS logs."},{"ref":"AWS.FMS.html#delete_policy/3","title":"AWS.FMS.delete_policy/3","type":"function","doc":"Permanently deletes an AWS Firewall Manager policy."},{"ref":"AWS.FMS.html#delete_protocols_list/3","title":"AWS.FMS.delete_protocols_list/3","type":"function","doc":"Permanently deletes an AWS Firewall Manager protocols list."},{"ref":"AWS.FMS.html#disassociate_admin_account/3","title":"AWS.FMS.disassociate_admin_account/3","type":"function","doc":"Disassociates the account that has been set as the AWS Firewall Manager administrator account. To set a different account as the administrator account, you must submit an AssociateAdminAccount request."},{"ref":"AWS.FMS.html#get_admin_account/3","title":"AWS.FMS.get_admin_account/3","type":"function","doc":"Returns the AWS Organizations master account that is associated with AWS Firewall Manager as the AWS Firewall Manager administrator."},{"ref":"AWS.FMS.html#get_apps_list/3","title":"AWS.FMS.get_apps_list/3","type":"function","doc":"Returns information about the specified AWS Firewall Manager applications list."},{"ref":"AWS.FMS.html#get_compliance_detail/3","title":"AWS.FMS.get_compliance_detail/3","type":"function","doc":"Returns detailed compliance information about the specified member account. Details include resources that are in and out of compliance with the specified policy. Resources are considered noncompliant for AWS WAF and Shield Advanced policies if the specified policy has not been applied to them. Resources are considered noncompliant for security group policies if they are in scope of the policy, they violate one or more of the policy rules, and remediation is disabled or not possible."},{"ref":"AWS.FMS.html#get_notification_channel/3","title":"AWS.FMS.get_notification_channel/3","type":"function","doc":"Information about the Amazon Simple Notification Service (SNS) topic that is used to record AWS Firewall Manager SNS logs."},{"ref":"AWS.FMS.html#get_policy/3","title":"AWS.FMS.get_policy/3","type":"function","doc":"Returns information about the specified AWS Firewall Manager policy."},{"ref":"AWS.FMS.html#get_protection_status/3","title":"AWS.FMS.get_protection_status/3","type":"function","doc":"If you created a Shield Advanced policy, returns policy-level attack summary information in the event of a potential DDoS attack. Other policy types are currently unsupported."},{"ref":"AWS.FMS.html#get_protocols_list/3","title":"AWS.FMS.get_protocols_list/3","type":"function","doc":"Returns information about the specified AWS Firewall Manager protocols list."},{"ref":"AWS.FMS.html#get_violation_details/3","title":"AWS.FMS.get_violation_details/3","type":"function","doc":"Retrieves violations for a resource based on the specified AWS Firewall Manager policy and AWS account."},{"ref":"AWS.FMS.html#list_apps_lists/3","title":"AWS.FMS.list_apps_lists/3","type":"function","doc":"Returns an array of AppsListDataSummary objects."},{"ref":"AWS.FMS.html#list_compliance_status/3","title":"AWS.FMS.list_compliance_status/3","type":"function","doc":"Returns an array of PolicyComplianceStatus objects. Use PolicyComplianceStatus to get a summary of which member accounts are protected by the specified policy."},{"ref":"AWS.FMS.html#list_member_accounts/3","title":"AWS.FMS.list_member_accounts/3","type":"function","doc":"Returns a MemberAccounts object that lists the member accounts in the administrator&#39;s AWS organization. The ListMemberAccounts must be submitted by the account that is set as the AWS Firewall Manager administrator."},{"ref":"AWS.FMS.html#list_policies/3","title":"AWS.FMS.list_policies/3","type":"function","doc":"Returns an array of PolicySummary objects."},{"ref":"AWS.FMS.html#list_protocols_lists/3","title":"AWS.FMS.list_protocols_lists/3","type":"function","doc":"Returns an array of ProtocolsListDataSummary objects."},{"ref":"AWS.FMS.html#list_tags_for_resource/3","title":"AWS.FMS.list_tags_for_resource/3","type":"function","doc":"Retrieves the list of tags for the specified AWS resource."},{"ref":"AWS.FMS.html#put_apps_list/3","title":"AWS.FMS.put_apps_list/3","type":"function","doc":"Creates an AWS Firewall Manager applications list."},{"ref":"AWS.FMS.html#put_notification_channel/3","title":"AWS.FMS.put_notification_channel/3","type":"function","doc":"Designates the IAM role and Amazon Simple Notification Service (SNS) topic that AWS Firewall Manager uses to record SNS logs."},{"ref":"AWS.FMS.html#put_policy/3","title":"AWS.FMS.put_policy/3","type":"function","doc":"Creates an AWS Firewall Manager policy. Firewall Manager provides the following types of policies: A Shield Advanced policy, which applies Shield Advanced protection to specified accounts and resources An AWS WAF policy (type WAFV2), which defines rule groups to run first in the corresponding AWS WAF web ACL and rule groups to run last in the web ACL. An AWS WAF Classic policy (type WAF), which defines a rule group. A security group policy, which manages VPC security groups across your AWS organization. Each policy is specific to one of the types. If you want to enforce more than one policy type across accounts, create multiple policies. You can create multiple policies for each type. You must be subscribed to Shield Advanced to create a Shield Advanced policy. For more information about subscribing to Shield Advanced, see CreateSubscription."},{"ref":"AWS.FMS.html#put_protocols_list/3","title":"AWS.FMS.put_protocols_list/3","type":"function","doc":"Creates an AWS Firewall Manager protocols list."},{"ref":"AWS.FMS.html#tag_resource/3","title":"AWS.FMS.tag_resource/3","type":"function","doc":"Adds one or more tags to an AWS resource."},{"ref":"AWS.FMS.html#untag_resource/3","title":"AWS.FMS.untag_resource/3","type":"function","doc":"Removes one or more tags from an AWS resource."},{"ref":"AWS.FSx.html","title":"AWS.FSx","type":"module","doc":"Amazon FSx is a fully managed service that makes it easy for storage and application administrators to launch and use shared file storage."},{"ref":"AWS.FSx.html#cancel_data_repository_task/3","title":"AWS.FSx.cancel_data_repository_task/3","type":"function","doc":"Cancels an existing Amazon FSx for Lustre data repository task if that task is in either the PENDING or EXECUTING state. When you cancel a task, Amazon FSx does the following. Any files that FSx has already exported are not reverted. FSx continues to export any files that are &quot;in-flight&quot; when the cancel operation is received. FSx does not export any files that have not yet been exported."},{"ref":"AWS.FSx.html#create_backup/3","title":"AWS.FSx.create_backup/3","type":"function","doc":"Creates a backup of an existing Amazon FSx file system. Creating regular backups for your file system is a best practice, enabling you to restore a file system from a backup if an issue arises with the original file system. For Amazon FSx for Lustre file systems, you can create a backup only for file systems with the following configuration: a Persistent deployment type is not linked to a data respository. For more information about backing up Amazon FSx for Lustre file systems, see Working with FSx for Lustre backups. For more information about backing up Amazon FSx for Lustre file systems, see Working with FSx for Windows backups. If a backup with the specified client request token exists, and the parameters match, this operation returns the description of the existing backup. If a backup specified client request token exists, and the parameters don&#39;t match, this operation returns IncompatibleParameterError. If a backup with the specified client request token doesn&#39;t exist, CreateBackup does the following: Creates a new Amazon FSx backup with an assigned ID, and an initial lifecycle state of CREATING. Returns the description of the backup. By using the idempotent operation, you can retry a CreateBackup operation without the risk of creating an extra backup. This approach can be useful when an initial call fails in a way that makes it unclear whether a backup was created. If you use the same client request token and the initial call created a backup, the operation returns a successful result because all the parameters are the same. The CreateBackup operation returns while the backup&#39;s lifecycle state is still CREATING. You can check the backup creation status by calling the DescribeBackups operation, which returns the backup state along with other information."},{"ref":"AWS.FSx.html#create_data_repository_task/3","title":"AWS.FSx.create_data_repository_task/3","type":"function","doc":"Creates an Amazon FSx for Lustre data repository task. You use data repository tasks to perform bulk operations between your Amazon FSx file system and its linked data repository. An example of a data repository task is exporting any data and metadata changes, including POSIX metadata, to files, directories, and symbolic links (symlinks) from your FSx file system to its linked data repository. A CreateDataRepositoryTask operation will fail if a data repository is not linked to the FSx file system. To learn more about data repository tasks, see Using Data Repository Tasks. To learn more about linking a data repository to your file system, see Setting the Export Prefix."},{"ref":"AWS.FSx.html#create_file_system/3","title":"AWS.FSx.create_file_system/3","type":"function","doc":"Creates a new, empty Amazon FSx file system. If a file system with the specified client request token exists and the parameters match, CreateFileSystem returns the description of the existing file system. If a file system specified client request token exists and the parameters don&#39;t match, this call returns IncompatibleParameterError. If a file system with the specified client request token doesn&#39;t exist, CreateFileSystem does the following: Creates a new, empty Amazon FSx file system with an assigned ID, and an initial lifecycle state of CREATING. Returns the description of the file system. This operation requires a client request token in the request that Amazon FSx uses to ensure idempotent creation. This means that calling the operation multiple times with the same client request token has no effect. By using the idempotent operation, you can retry a CreateFileSystem operation without the risk of creating an extra file system. This approach can be useful when an initial call fails in a way that makes it unclear whether a file system was created. Examples are if a transport level timeout occurred, or your connection was reset. If you use the same client request token and the initial call created a file system, the client receives success as long as the parameters are the same. The CreateFileSystem call returns while the file system&#39;s lifecycle state is still CREATING. You can check the file-system creation status by calling the DescribeFileSystems operation, which returns the file system state along with other information."},{"ref":"AWS.FSx.html#create_file_system_from_backup/3","title":"AWS.FSx.create_file_system_from_backup/3","type":"function","doc":"Creates a new Amazon FSx file system from an existing Amazon FSx backup. If a file system with the specified client request token exists and the parameters match, this operation returns the description of the file system. If a client request token specified by the file system exists and the parameters don&#39;t match, this call returns IncompatibleParameterError. If a file system with the specified client request token doesn&#39;t exist, this operation does the following: Creates a new Amazon FSx file system from backup with an assigned ID, and an initial lifecycle state of CREATING. Returns the description of the file system. Parameters like Active Directory, default share name, automatic backup, and backup settings default to the parameters of the file system that was backed up, unless overridden. You can explicitly supply other settings. By using the idempotent operation, you can retry a CreateFileSystemFromBackup call without the risk of creating an extra file system. This approach can be useful when an initial call fails in a way that makes it unclear whether a file system was created. Examples are if a transport level timeout occurred, or your connection was reset. If you use the same client request token and the initial call created a file system, the client receives success as long as the parameters are the same. The CreateFileSystemFromBackup call returns while the file system&#39;s lifecycle state is still CREATING. You can check the file-system creation status by calling the DescribeFileSystems operation, which returns the file system state along with other information."},{"ref":"AWS.FSx.html#delete_backup/3","title":"AWS.FSx.delete_backup/3","type":"function","doc":"Deletes an Amazon FSx backup, deleting its contents. After deletion, the backup no longer exists, and its data is gone. The DeleteBackup call returns instantly. The backup will not show up in later DescribeBackups calls. The data in a deleted backup is also deleted and can&#39;t be recovered by any means."},{"ref":"AWS.FSx.html#delete_file_system/3","title":"AWS.FSx.delete_file_system/3","type":"function","doc":"Deletes a file system, deleting its contents. After deletion, the file system no longer exists, and its data is gone. Any existing automatic backups will also be deleted. By default, when you delete an Amazon FSx for Windows File Server file system, a final backup is created upon deletion. This final backup is not subject to the file system&#39;s retention policy, and must be manually deleted. The DeleteFileSystem action returns while the file system has the DELETING status. You can check the file system deletion status by calling the DescribeFileSystems action, which returns a list of file systems in your account. If you pass the file system ID for a deleted file system, the DescribeFileSystems returns a FileSystemNotFound error. Deleting an Amazon FSx for Lustre file system will fail with a 400 BadRequest if a data repository task is in a PENDING or EXECUTING state. The data in a deleted file system is also deleted and can&#39;t be recovered by any means."},{"ref":"AWS.FSx.html#describe_backups/3","title":"AWS.FSx.describe_backups/3","type":"function","doc":"Returns the description of specific Amazon FSx backups, if a BackupIds value is provided for that backup. Otherwise, it returns all backups owned by your AWS account in the AWS Region of the endpoint that you&#39;re calling. When retrieving all backups, you can optionally specify the MaxResults parameter to limit the number of backups in a response. If more backups remain, Amazon FSx returns a NextToken value in the response. In this case, send a later request with the NextToken request parameter set to the value of NextToken from the last response. This action is used in an iterative process to retrieve a list of your backups. DescribeBackups is called first without a NextTokenvalue. Then the action continues to be called with the NextToken parameter set to the value of the last NextToken value until a response has no NextToken. When using this action, keep the following in mind: The implementation might return fewer than MaxResults file system descriptions while still including a NextToken value. The order of backups returned in the response of one DescribeBackups call and the order of backups returned across the responses of a multi-call iteration is unspecified."},{"ref":"AWS.FSx.html#describe_data_repository_tasks/3","title":"AWS.FSx.describe_data_repository_tasks/3","type":"function","doc":"Returns the description of specific Amazon FSx for Lustre data repository tasks, if one or more TaskIds values are provided in the request, or if filters are used in the request. You can use filters to narrow the response to include just tasks for specific file systems, or tasks in a specific lifecycle state. Otherwise, it returns all data repository tasks owned by your AWS account in the AWS Region of the endpoint that you&#39;re calling. When retrieving all tasks, you can paginate the response by using the optional MaxResults parameter to limit the number of tasks returned in a response. If more tasks remain, Amazon FSx returns a NextToken value in the response. In this case, send a later request with the NextToken request parameter set to the value of NextToken from the last response."},{"ref":"AWS.FSx.html#describe_file_systems/3","title":"AWS.FSx.describe_file_systems/3","type":"function","doc":"Returns the description of specific Amazon FSx file systems, if a FileSystemIds value is provided for that file system. Otherwise, it returns descriptions of all file systems owned by your AWS account in the AWS Region of the endpoint that you&#39;re calling. When retrieving all file system descriptions, you can optionally specify the MaxResults parameter to limit the number of descriptions in a response. If more file system descriptions remain, Amazon FSx returns a NextToken value in the response. In this case, send a later request with the NextToken request parameter set to the value of NextToken from the last response. This action is used in an iterative process to retrieve a list of your file system descriptions. DescribeFileSystems is called first without a NextTokenvalue. Then the action continues to be called with the NextToken parameter set to the value of the last NextToken value until a response has no NextToken. When using this action, keep the following in mind: The implementation might return fewer than MaxResults file system descriptions while still including a NextToken value. The order of file systems returned in the response of one DescribeFileSystems call and the order of file systems returned across the responses of a multicall iteration is unspecified."},{"ref":"AWS.FSx.html#list_tags_for_resource/3","title":"AWS.FSx.list_tags_for_resource/3","type":"function","doc":"Lists tags for an Amazon FSx file systems and backups in the case of Amazon FSx for Windows File Server. When retrieving all tags, you can optionally specify the MaxResults parameter to limit the number of tags in a response. If more tags remain, Amazon FSx returns a NextToken value in the response. In this case, send a later request with the NextToken request parameter set to the value of NextToken from the last response. This action is used in an iterative process to retrieve a list of your tags. ListTagsForResource is called first without a NextTokenvalue. Then the action continues to be called with the NextToken parameter set to the value of the last NextToken value until a response has no NextToken. When using this action, keep the following in mind: The implementation might return fewer than MaxResults file system descriptions while still including a NextToken value. The order of tags returned in the response of one ListTagsForResource call and the order of tags returned across the responses of a multi-call iteration is unspecified."},{"ref":"AWS.FSx.html#tag_resource/3","title":"AWS.FSx.tag_resource/3","type":"function","doc":"Tags an Amazon FSx resource."},{"ref":"AWS.FSx.html#untag_resource/3","title":"AWS.FSx.untag_resource/3","type":"function","doc":"This action removes a tag from an Amazon FSx resource."},{"ref":"AWS.FSx.html#update_file_system/3","title":"AWS.FSx.update_file_system/3","type":"function","doc":"Use this operation to update the configuration of an existing Amazon FSx file system. You can update multiple properties in a single request. For Amazon FSx for Windows File Server file systems, you can update the following properties: AutomaticBackupRetentionDays DailyAutomaticBackupStartTime SelfManagedActiveDirectoryConfiguration StorageCapacity ThroughputCapacity WeeklyMaintenanceStartTime For Amazon FSx for Lustre file systems, you can update the following properties: AutoImportPolicy AutomaticBackupRetentionDays DailyAutomaticBackupStartTime WeeklyMaintenanceStartTime"},{"ref":"AWS.Firehose.html","title":"AWS.Firehose","type":"module","doc":"Amazon Kinesis Data Firehose API Reference Amazon Kinesis Data Firehose is a fully managed service that delivers real-time streaming data to destinations such as Amazon Simple Storage Service (Amazon S3), Amazon Elasticsearch Service (Amazon ES), Amazon Redshift, and Splunk."},{"ref":"AWS.Firehose.html#create_delivery_stream/3","title":"AWS.Firehose.create_delivery_stream/3","type":"function","doc":"Creates a Kinesis Data Firehose delivery stream. By default, you can create up to 50 delivery streams per AWS Region. This is an asynchronous operation that immediately returns. The initial status of the delivery stream is CREATING. After the delivery stream is created, its status is ACTIVE and it now accepts data. If the delivery stream creation fails, the status transitions to CREATING_FAILED. Attempts to send data to a delivery stream that is not in the ACTIVE state cause an exception. To check the state of a delivery stream, use DescribeDeliveryStream. If the status of a delivery stream is CREATING_FAILED, this status doesn&#39;t change, and you can&#39;t invoke CreateDeliveryStream again on it. However, you can invoke the DeleteDeliveryStream operation to delete it. A Kinesis Data Firehose delivery stream can be configured to receive records directly from providers using PutRecord or PutRecordBatch, or it can be configured to use an existing Kinesis stream as its source. To specify a Kinesis data stream as input, set the DeliveryStreamType parameter to KinesisStreamAsSource, and provide the Kinesis stream Amazon Resource Name (ARN) and role ARN in the KinesisStreamSourceConfiguration parameter. To create a delivery stream with server-side encryption (SSE) enabled, include DeliveryStreamEncryptionConfigurationInput in your request. This is optional. You can also invoke StartDeliveryStreamEncryption to turn on SSE for an existing delivery stream that doesn&#39;t have SSE enabled. A delivery stream is configured with a single destination: Amazon S3, Amazon ES, Amazon Redshift, or Splunk. You must specify only one of the following destination configuration parameters: ExtendedS3DestinationConfiguration, S3DestinationConfiguration, ElasticsearchDestinationConfiguration, RedshiftDestinationConfiguration, or SplunkDestinationConfiguration. When you specify S3DestinationConfiguration, you can also provide the following optional values: BufferingHints, EncryptionConfiguration, and CompressionFormat. By default, if no BufferingHints value is provided, Kinesis Data Firehose buffers data up to 5 MB or for 5 minutes, whichever condition is satisfied first. BufferingHints is a hint, so there are some cases where the service cannot adhere to these conditions strictly. For example, record boundaries might be such that the size is a little over or under the configured buffering size. By default, no encryption is performed. We strongly recommend that you enable encryption to ensure secure data storage in Amazon S3. A few notes about Amazon Redshift as a destination: An Amazon Redshift destination requires an S3 bucket as intermediate location. Kinesis Data Firehose first delivers data to Amazon S3 and then uses COPY syntax to load data into an Amazon Redshift table. This is specified in the RedshiftDestinationConfiguration.S3Configuration parameter. The compression formats SNAPPY or ZIP cannot be specified in RedshiftDestinationConfiguration.S3Configuration because the Amazon Redshift COPY operation that reads from the S3 bucket doesn&#39;t support these compression formats. We strongly recommend that you use the user name and password you provide exclusively with Kinesis Data Firehose, and that the permissions for the account are restricted for Amazon Redshift INSERT permissions. Kinesis Data Firehose assumes the IAM role that is configured as part of the destination. The role should allow the Kinesis Data Firehose principal to assume the role, and the role should have permissions that allow the service to deliver the data. For more information, see Grant Kinesis Data Firehose Access to an Amazon S3 Destination in the Amazon Kinesis Data Firehose Developer Guide."},{"ref":"AWS.Firehose.html#delete_delivery_stream/3","title":"AWS.Firehose.delete_delivery_stream/3","type":"function","doc":"Deletes a delivery stream and its data. To check the state of a delivery stream, use DescribeDeliveryStream. You can delete a delivery stream only if it is in one of the following states: ACTIVE, DELETING, CREATING_FAILED, or DELETING_FAILED. You can&#39;t delete a delivery stream that is in the CREATING state. While the deletion request is in process, the delivery stream is in the DELETING state. While the delivery stream is in the DELETING state, the service might continue to accept records, but it doesn&#39;t make any guarantees with respect to delivering the data. Therefore, as a best practice, first stop any applications that are sending records before you delete a delivery stream."},{"ref":"AWS.Firehose.html#describe_delivery_stream/3","title":"AWS.Firehose.describe_delivery_stream/3","type":"function","doc":"Describes the specified delivery stream and its status. For example, after your delivery stream is created, call DescribeDeliveryStream to see whether the delivery stream is ACTIVE and therefore ready for data to be sent to it. If the status of a delivery stream is CREATING_FAILED, this status doesn&#39;t change, and you can&#39;t invoke CreateDeliveryStream again on it. However, you can invoke the DeleteDeliveryStream operation to delete it. If the status is DELETING_FAILED, you can force deletion by invoking DeleteDeliveryStream again but with DeleteDeliveryStreamInput$AllowForceDelete set to true."},{"ref":"AWS.Firehose.html#list_delivery_streams/3","title":"AWS.Firehose.list_delivery_streams/3","type":"function","doc":"Lists your delivery streams in alphabetical order of their names. The number of delivery streams might be too large to return using a single call to ListDeliveryStreams. You can limit the number of delivery streams returned, using the Limit parameter. To determine whether there are more delivery streams to list, check the value of HasMoreDeliveryStreams in the output. If there are more delivery streams to list, you can request them by calling this operation again and setting the ExclusiveStartDeliveryStreamName parameter to the name of the last delivery stream returned in the last call."},{"ref":"AWS.Firehose.html#list_tags_for_delivery_stream/3","title":"AWS.Firehose.list_tags_for_delivery_stream/3","type":"function","doc":"Lists the tags for the specified delivery stream. This operation has a limit of five transactions per second per account."},{"ref":"AWS.Firehose.html#put_record/3","title":"AWS.Firehose.put_record/3","type":"function","doc":"Writes a single data record into an Amazon Kinesis Data Firehose delivery stream. To write multiple data records into a delivery stream, use PutRecordBatch. Applications using these operations are referred to as producers. By default, each delivery stream can take in up to 2,000 transactions per second, 5,000 records per second, or 5 MB per second. If you use PutRecord and PutRecordBatch, the limits are an aggregate across these two operations for each delivery stream. For more information about limits and how to request an increase, see Amazon Kinesis Data Firehose Limits. You must specify the name of the delivery stream and the data record when using PutRecord. The data record consists of a data blob that can be up to 1,000 KB in size, and any kind of data. For example, it can be a segment from a log file, geographic location data, website clickstream data, and so on. Kinesis Data Firehose buffers records before delivering them to the destination. To disambiguate the data blobs at the destination, a common solution is to use delimiters in the data, such as a newline () or some other character unique within the data. This allows the consumer application to parse individual data items when reading the data from the destination. The PutRecord operation returns a RecordId, which is a unique string assigned to each record. Producer applications can use this ID for purposes such as auditability and investigation. If the PutRecord operation throws a ServiceUnavailableException, back off and retry. If the exception persists, it is possible that the throughput limits have been exceeded for the delivery stream. Data records sent to Kinesis Data Firehose are stored for 24 hours from the time they are added to a delivery stream as it tries to send the records to the destination. If the destination is unreachable for more than 24 hours, the data is no longer available. Don&#39;t concatenate two or more base64 strings to form the data fields of your records. Instead, concatenate the raw data, then perform base64 encoding."},{"ref":"AWS.Firehose.html#put_record_batch/3","title":"AWS.Firehose.put_record_batch/3","type":"function","doc":"Writes multiple data records into a delivery stream in a single call, which can achieve higher throughput per producer than when writing single records. To write single data records into a delivery stream, use PutRecord. Applications using these operations are referred to as producers. For information about service quota, see Amazon Kinesis Data Firehose Quota. Each PutRecordBatch request supports up to 500 records. Each record in the request can be as large as 1,000 KB (before 64-bit encoding), up to a limit of 4 MB for the entire request. These limits cannot be changed. You must specify the name of the delivery stream and the data record when using PutRecord. The data record consists of a data blob that can be up to 1,000 KB in size, and any kind of data. For example, it could be a segment from a log file, geographic location data, website clickstream data, and so on. Kinesis Data Firehose buffers records before delivering them to the destination. To disambiguate the data blobs at the destination, a common solution is to use delimiters in the data, such as a newline () or some other character unique within the data. This allows the consumer application to parse individual data items when reading the data from the destination. The PutRecordBatch response includes a count of failed records, FailedPutCount, and an array of responses, RequestResponses. Even if the PutRecordBatch call succeeds, the value of FailedPutCount may be greater than 0, indicating that there are records for which the operation didn&#39;t succeed. Each entry in the RequestResponses array provides additional information about the processed record. It directly correlates with a record in the request array using the same ordering, from the top to the bottom. The response array always includes the same number of records as the request array. RequestResponses includes both successfully and unsuccessfully processed records. Kinesis Data Firehose tries to process all records in each PutRecordBatch request. A single record failure does not stop the processing of subsequent records. A successfully processed record includes a RecordId value, which is unique for the record. An unsuccessfully processed record includes ErrorCode and ErrorMessage values. ErrorCode reflects the type of error, and is one of the following values: ServiceUnavailableException or InternalFailure. ErrorMessage provides more detailed information about the error. If there is an internal server error or a timeout, the write might have completed or it might have failed. If FailedPutCount is greater than 0, retry the request, resending only those records that might have failed processing. This minimizes the possible duplicate records and also reduces the total bytes sent (and corresponding charges). We recommend that you handle any duplicates at the destination. If PutRecordBatch throws ServiceUnavailableException, back off and retry. If the exception persists, it is possible that the throughput limits have been exceeded for the delivery stream. Data records sent to Kinesis Data Firehose are stored for 24 hours from the time they are added to a delivery stream as it attempts to send the records to the destination. If the destination is unreachable for more than 24 hours, the data is no longer available. Don&#39;t concatenate two or more base64 strings to form the data fields of your records. Instead, concatenate the raw data, then perform base64 encoding."},{"ref":"AWS.Firehose.html#start_delivery_stream_encryption/3","title":"AWS.Firehose.start_delivery_stream_encryption/3","type":"function","doc":"Enables server-side encryption (SSE) for the delivery stream. This operation is asynchronous. It returns immediately. When you invoke it, Kinesis Data Firehose first sets the encryption status of the stream to ENABLING, and then to ENABLED. The encryption status of a delivery stream is the Status property in DeliveryStreamEncryptionConfiguration. If the operation fails, the encryption status changes to ENABLING_FAILED. You can continue to read and write data to your delivery stream while the encryption status is ENABLING, but the data is not encrypted. It can take up to 5 seconds after the encryption status changes to ENABLED before all records written to the delivery stream are encrypted. To find out whether a record or a batch of records was encrypted, check the response elements PutRecordOutput$Encrypted and PutRecordBatchOutput$Encrypted, respectively. To check the encryption status of a delivery stream, use DescribeDeliveryStream. Even if encryption is currently enabled for a delivery stream, you can still invoke this operation on it to change the ARN of the CMK or both its type and ARN. If you invoke this method to change the CMK, and the old CMK is of type CUSTOMER_MANAGED_CMK, Kinesis Data Firehose schedules the grant it had on the old CMK for retirement. If the new CMK is of type CUSTOMER_MANAGED_CMK, Kinesis Data Firehose creates a grant that enables it to use the new CMK to encrypt and decrypt data and to manage the grant. If a delivery stream already has encryption enabled and then you invoke this operation to change the ARN of the CMK or both its type and ARN and you get ENABLING_FAILED, this only means that the attempt to change the CMK failed. In this case, encryption remains enabled with the old CMK. If the encryption status of your delivery stream is ENABLING_FAILED, you can invoke this operation again with a valid CMK. The CMK must be enabled and the key policy mustn&#39;t explicitly deny the permission for Kinesis Data Firehose to invoke KMS encrypt and decrypt operations. You can enable SSE for a delivery stream only if it&#39;s a delivery stream that uses DirectPut as its source. The StartDeliveryStreamEncryption and StopDeliveryStreamEncryption operations have a combined limit of 25 calls per delivery stream per 24 hours. For example, you reach the limit if you call StartDeliveryStreamEncryption 13 times and StopDeliveryStreamEncryption 12 times for the same delivery stream in a 24-hour period."},{"ref":"AWS.Firehose.html#stop_delivery_stream_encryption/3","title":"AWS.Firehose.stop_delivery_stream_encryption/3","type":"function","doc":"Disables server-side encryption (SSE) for the delivery stream. This operation is asynchronous. It returns immediately. When you invoke it, Kinesis Data Firehose first sets the encryption status of the stream to DISABLING, and then to DISABLED. You can continue to read and write data to your stream while its status is DISABLING. It can take up to 5 seconds after the encryption status changes to DISABLED before all records written to the delivery stream are no longer subject to encryption. To find out whether a record or a batch of records was encrypted, check the response elements PutRecordOutput$Encrypted and PutRecordBatchOutput$Encrypted, respectively. To check the encryption state of a delivery stream, use DescribeDeliveryStream. If SSE is enabled using a customer managed CMK and then you invoke StopDeliveryStreamEncryption, Kinesis Data Firehose schedules the related KMS grant for retirement and then retires it after it ensures that it is finished delivering records to the destination. The StartDeliveryStreamEncryption and StopDeliveryStreamEncryption operations have a combined limit of 25 calls per delivery stream per 24 hours. For example, you reach the limit if you call StartDeliveryStreamEncryption 13 times and StopDeliveryStreamEncryption 12 times for the same delivery stream in a 24-hour period."},{"ref":"AWS.Firehose.html#tag_delivery_stream/3","title":"AWS.Firehose.tag_delivery_stream/3","type":"function","doc":"Adds or updates tags for the specified delivery stream. A tag is a key-value pair that you can define and assign to AWS resources. If you specify a tag that already exists, the tag value is replaced with the value that you specify in the request. Tags are metadata. For example, you can add friendly names and descriptions or other types of information that can help you distinguish the delivery stream. For more information about tags, see Using Cost Allocation Tags in the AWS Billing and Cost Management User Guide. Each delivery stream can have up to 50 tags. This operation has a limit of five transactions per second per account."},{"ref":"AWS.Firehose.html#untag_delivery_stream/3","title":"AWS.Firehose.untag_delivery_stream/3","type":"function","doc":"Removes tags from the specified delivery stream. Removed tags are deleted, and you can&#39;t recover them after this operation successfully completes. If you specify a tag that doesn&#39;t exist, the operation ignores it. This operation has a limit of five transactions per second per account."},{"ref":"AWS.Firehose.html#update_destination/3","title":"AWS.Firehose.update_destination/3","type":"function","doc":"Updates the specified destination of the specified delivery stream. Use this operation to change the destination type (for example, to replace the Amazon S3 destination with Amazon Redshift) or change the parameters associated with a destination (for example, to change the bucket name of the Amazon S3 destination). The update might not occur immediately. The target delivery stream remains active while the configurations are updated, so data writes to the delivery stream can continue during this process. The updated configurations are usually effective within a few minutes. Switching between Amazon ES and other services is not supported. For an Amazon ES destination, you can only update to another Amazon ES destination. If the destination type is the same, Kinesis Data Firehose merges the configuration parameters specified with the destination configuration that already exists on the delivery stream. If any of the parameters are not specified in the call, the existing values are retained. For example, in the Amazon S3 destination, if EncryptionConfiguration is not specified, then the existing EncryptionConfiguration is maintained on the destination. If the destination type is not the same, for example, changing the destination from Amazon S3 to Amazon Redshift, Kinesis Data Firehose does not merge any parameters. In this case, all parameters must be specified. Kinesis Data Firehose uses CurrentDeliveryStreamVersionId to avoid race conditions and conflicting merges. This is a required field, and the service updates the configuration only if the existing configuration has a version ID that matches. After the update is applied successfully, the version ID is updated, and can be retrieved using DescribeDeliveryStream. Use the new version ID to set CurrentDeliveryStreamVersionId in the next call."},{"ref":"AWS.Forecast.html","title":"AWS.Forecast","type":"module","doc":"Provides APIs for creating and managing Amazon Forecast resources."},{"ref":"AWS.Forecast.html#create_dataset/3","title":"AWS.Forecast.create_dataset/3","type":"function","doc":"Creates an Amazon Forecast dataset. The information about the dataset that you provide helps Forecast understand how to consume the data for model training. This includes the following: DataFrequency * - How frequently your historical time-series data is collected. Domain and DatasetType * - Each dataset has an associated dataset domain and a type within the domain. Amazon Forecast provides a list of predefined domains and types within each domain. For each unique dataset domain and type within the domain, Amazon Forecast requires your data to include a minimum set of predefined fields. Schema * - A schema specifies the fields in the dataset, including the field name and data type. After creating a dataset, you import your training data into it and add the dataset to a dataset group. You use the dataset group to create a predictor. For more information, see howitworks-datasets-groups. To get a list of all your datasets, use the ListDatasets operation. For example Forecast datasets, see the Amazon Forecast Sample GitHub repository. The Status of a dataset must be ACTIVE before you can import training data. Use the DescribeDataset operation to get the status."},{"ref":"AWS.Forecast.html#create_dataset_group/3","title":"AWS.Forecast.create_dataset_group/3","type":"function","doc":"Creates a dataset group, which holds a collection of related datasets. You can add datasets to the dataset group when you create the dataset group, or later by using the UpdateDatasetGroup operation. After creating a dataset group and adding datasets, you use the dataset group when you create a predictor. For more information, see howitworks-datasets-groups. To get a list of all your datasets groups, use the ListDatasetGroups operation. The Status of a dataset group must be ACTIVE before you can create use the dataset group to create a predictor. To get the status, use the DescribeDatasetGroup operation."},{"ref":"AWS.Forecast.html#create_dataset_import_job/3","title":"AWS.Forecast.create_dataset_import_job/3","type":"function","doc":"Imports your training data to an Amazon Forecast dataset. You provide the location of your training data in an Amazon Simple Storage Service (Amazon S3) bucket and the Amazon Resource Name (ARN) of the dataset that you want to import the data to. You must specify a DataSource object that includes an AWS Identity and Access Management (IAM) role that Amazon Forecast can assume to access the data, as Amazon Forecast makes a copy of your data and processes it in an internal AWS system. For more information, see aws-forecast-iam-roles. The training data must be in CSV format. The delimiter must be a comma (,). You can specify the path to a specific CSV file, the S3 bucket, or to a folder in the S3 bucket. For the latter two cases, Amazon Forecast imports all files up to the limit of 10,000 files. Because dataset imports are not aggregated, your most recent dataset import is the one that is used when training a predictor or generating a forecast. Make sure that your most recent dataset import contains all of the data you want to model off of, and not just the new data collected since the previous import. To get a list of all your dataset import jobs, filtered by specified criteria, use the ListDatasetImportJobs operation."},{"ref":"AWS.Forecast.html#create_forecast/3","title":"AWS.Forecast.create_forecast/3","type":"function","doc":"Creates a forecast for each item in the TARGET_TIME_SERIES dataset that was used to train the predictor. This is known as inference. To retrieve the forecast for a single item at low latency, use the operation. To export the complete forecast into your Amazon Simple Storage Service (Amazon S3) bucket, use the CreateForecastExportJob operation. The range of the forecast is determined by the ForecastHorizon value, which you specify in the CreatePredictor request. When you query a forecast, you can request a specific date range within the forecast. To get a list of all your forecasts, use the ListForecasts operation. The forecasts generated by Amazon Forecast are in the same time zone as the dataset that was used to create the predictor. For more information, see howitworks-forecast. The Status of the forecast must be ACTIVE before you can query or export the forecast. Use the DescribeForecast operation to get the status."},{"ref":"AWS.Forecast.html#create_forecast_export_job/3","title":"AWS.Forecast.create_forecast_export_job/3","type":"function","doc":"Exports a forecast created by the CreateForecast operation to your Amazon Simple Storage Service (Amazon S3) bucket. The forecast file name will match the following conventions: __ where the component is in Java SimpleDateFormat (yyyy-MM-ddTHH-mm-ssZ). You must specify a `DataDestination` object that includes an AWS Identity and Access Management (IAM) role that Amazon Forecast can assume to access the Amazon S3 bucket. For more information, see `aws-forecast-iam-roles`. For more information, see `howitworks-forecast`. To get a list of all your forecast export jobs, use the `ListForecastExportJobs` operation. The `Status` of the forecast export job must be `ACTIVE` before you can access the forecast in your Amazon S3 bucket. To get the status, use the `DescribeForecastExportJob` operation."},{"ref":"AWS.Forecast.html#create_predictor/3","title":"AWS.Forecast.create_predictor/3","type":"function","doc":"Creates an Amazon Forecast predictor. In the request, you provide a dataset group and either specify an algorithm or let Amazon Forecast choose the algorithm for you using AutoML. If you specify an algorithm, you also can override algorithm-specific hyperparameters. Amazon Forecast uses the chosen algorithm to train a model using the latest version of the datasets in the specified dataset group. The result is called a predictor. You then generate a forecast using the CreateForecast operation. After training a model, the CreatePredictor operation also evaluates it. To see the evaluation metrics, use the GetAccuracyMetrics operation. Always review the evaluation metrics before deciding to use the predictor to generate a forecast. Optionally, you can specify a featurization configuration to fill and aggregate the data fields in the TARGET_TIME_SERIES dataset to improve model training. For more information, see FeaturizationConfig. For RELATED_TIME_SERIES datasets, CreatePredictor verifies that the DataFrequency specified when the dataset was created matches the ForecastFrequency. TARGET_TIME_SERIES datasets don&#39;t have this restriction. Amazon Forecast also verifies the delimiter and timestamp format. For more information, see howitworks-datasets-groups. AutoML If you want Amazon Forecast to evaluate each algorithm and choose the one that minimizes the objective function, set PerformAutoML to true. The objective function is defined as the mean of the weighted p10, p50, and p90 quantile losses. For more information, see EvaluationResult. When AutoML is enabled, the following properties are disallowed: AlgorithmArn HPOConfig PerformHPO TrainingParameters To get a list of all of your predictors, use the ListPredictors operation. Before you can use the predictor to create a forecast, the Status of the predictor must be ACTIVE, signifying that training has completed. To get the status, use the DescribePredictor operation."},{"ref":"AWS.Forecast.html#delete_dataset/3","title":"AWS.Forecast.delete_dataset/3","type":"function","doc":"Deletes an Amazon Forecast dataset that was created using the CreateDataset operation. You can only delete datasets that have a status of ACTIVE or CREATE_FAILED. To get the status use the DescribeDataset operation. Forecast does not automatically update any dataset groups that contain the deleted dataset. In order to update the dataset group, use the operation, omitting the deleted dataset&#39;s ARN."},{"ref":"AWS.Forecast.html#delete_dataset_group/3","title":"AWS.Forecast.delete_dataset_group/3","type":"function","doc":"Deletes a dataset group created using the CreateDatasetGroup operation. You can only delete dataset groups that have a status of ACTIVE, CREATE_FAILED, or UPDATE_FAILED. To get the status, use the DescribeDatasetGroup operation. This operation deletes only the dataset group, not the datasets in the group."},{"ref":"AWS.Forecast.html#delete_dataset_import_job/3","title":"AWS.Forecast.delete_dataset_import_job/3","type":"function","doc":"Deletes a dataset import job created using the CreateDatasetImportJob operation. You can delete only dataset import jobs that have a status of ACTIVE or CREATE_FAILED. To get the status, use the DescribeDatasetImportJob operation."},{"ref":"AWS.Forecast.html#delete_forecast/3","title":"AWS.Forecast.delete_forecast/3","type":"function","doc":"Deletes a forecast created using the CreateForecast operation. You can delete only forecasts that have a status of ACTIVE or CREATE_FAILED. To get the status, use the DescribeForecast operation. You can&#39;t delete a forecast while it is being exported. After a forecast is deleted, you can no longer query the forecast."},{"ref":"AWS.Forecast.html#delete_forecast_export_job/3","title":"AWS.Forecast.delete_forecast_export_job/3","type":"function","doc":"Deletes a forecast export job created using the CreateForecastExportJob operation. You can delete only export jobs that have a status of ACTIVE or CREATE_FAILED. To get the status, use the DescribeForecastExportJob operation."},{"ref":"AWS.Forecast.html#delete_predictor/3","title":"AWS.Forecast.delete_predictor/3","type":"function","doc":"Deletes a predictor created using the CreatePredictor operation. You can delete only predictor that have a status of ACTIVE or CREATE_FAILED. To get the status, use the DescribePredictor operation."},{"ref":"AWS.Forecast.html#describe_dataset/3","title":"AWS.Forecast.describe_dataset/3","type":"function","doc":"Describes an Amazon Forecast dataset created using the CreateDataset operation. In addition to listing the parameters specified in the CreateDataset request, this operation includes the following dataset properties: CreationTime LastModificationTime Status"},{"ref":"AWS.Forecast.html#describe_dataset_group/3","title":"AWS.Forecast.describe_dataset_group/3","type":"function","doc":"Describes a dataset group created using the CreateDatasetGroup operation. In addition to listing the parameters provided in the CreateDatasetGroup request, this operation includes the following properties: DatasetArns - The datasets belonging to the group. CreationTime LastModificationTime Status"},{"ref":"AWS.Forecast.html#describe_dataset_import_job/3","title":"AWS.Forecast.describe_dataset_import_job/3","type":"function","doc":"Describes a dataset import job created using the CreateDatasetImportJob operation. In addition to listing the parameters provided in the CreateDatasetImportJob request, this operation includes the following properties: CreationTime LastModificationTime DataSize FieldStatistics Status Message - If an error occurred, information about the error."},{"ref":"AWS.Forecast.html#describe_forecast/3","title":"AWS.Forecast.describe_forecast/3","type":"function","doc":"Describes a forecast created using the CreateForecast operation. In addition to listing the properties provided in the CreateForecast request, this operation lists the following properties: DatasetGroupArn - The dataset group that provided the training data. CreationTime LastModificationTime Status Message - If an error occurred, information about the error."},{"ref":"AWS.Forecast.html#describe_forecast_export_job/3","title":"AWS.Forecast.describe_forecast_export_job/3","type":"function","doc":"Describes a forecast export job created using the CreateForecastExportJob operation. In addition to listing the properties provided by the user in the CreateForecastExportJob request, this operation lists the following properties: CreationTime LastModificationTime Status Message - If an error occurred, information about the error."},{"ref":"AWS.Forecast.html#describe_predictor/3","title":"AWS.Forecast.describe_predictor/3","type":"function","doc":"Describes a predictor created using the CreatePredictor operation. In addition to listing the properties provided in the CreatePredictor request, this operation lists the following properties: DatasetImportJobArns - The dataset import jobs used to import training data. AutoMLAlgorithmArns - If AutoML is performed, the algorithms that were evaluated. CreationTime LastModificationTime Status Message - If an error occurred, information about the error."},{"ref":"AWS.Forecast.html#get_accuracy_metrics/3","title":"AWS.Forecast.get_accuracy_metrics/3","type":"function","doc":"Provides metrics on the accuracy of the models that were trained by the CreatePredictor operation. Use metrics to see how well the model performed and to decide whether to use the predictor to generate a forecast. For more information, see metrics. This operation generates metrics for each backtest window that was evaluated. The number of backtest windows (NumberOfBacktestWindows) is specified using the EvaluationParameters object, which is optionally included in the CreatePredictor request. If NumberOfBacktestWindows isn&#39;t specified, the number defaults to one. The parameters of the filling method determine which items contribute to the metrics. If you want all items to contribute, specify zero. If you want only those items that have complete data in the range being evaluated to contribute, specify nan. For more information, see FeaturizationMethod. Before you can get accuracy metrics, the Status of the predictor must be ACTIVE, signifying that training has completed. To get the status, use the DescribePredictor operation."},{"ref":"AWS.Forecast.html#list_dataset_groups/3","title":"AWS.Forecast.list_dataset_groups/3","type":"function","doc":"Returns a list of dataset groups created using the CreateDatasetGroup operation. For each dataset group, this operation returns a summary of its properties, including its Amazon Resource Name (ARN). You can retrieve the complete set of properties by using the dataset group ARN with the DescribeDatasetGroup operation."},{"ref":"AWS.Forecast.html#list_dataset_import_jobs/3","title":"AWS.Forecast.list_dataset_import_jobs/3","type":"function","doc":"Returns a list of dataset import jobs created using the CreateDatasetImportJob operation. For each import job, this operation returns a summary of its properties, including its Amazon Resource Name (ARN). You can retrieve the complete set of properties by using the ARN with the DescribeDatasetImportJob operation. You can filter the list by providing an array of Filter objects."},{"ref":"AWS.Forecast.html#list_datasets/3","title":"AWS.Forecast.list_datasets/3","type":"function","doc":"Returns a list of datasets created using the CreateDataset operation. For each dataset, a summary of its properties, including its Amazon Resource Name (ARN), is returned. To retrieve the complete set of properties, use the ARN with the DescribeDataset operation."},{"ref":"AWS.Forecast.html#list_forecast_export_jobs/3","title":"AWS.Forecast.list_forecast_export_jobs/3","type":"function","doc":"Returns a list of forecast export jobs created using the CreateForecastExportJob operation. For each forecast export job, this operation returns a summary of its properties, including its Amazon Resource Name (ARN). To retrieve the complete set of properties, use the ARN with the DescribeForecastExportJob operation. You can filter the list using an array of Filter objects."},{"ref":"AWS.Forecast.html#list_forecasts/3","title":"AWS.Forecast.list_forecasts/3","type":"function","doc":"Returns a list of forecasts created using the CreateForecast operation. For each forecast, this operation returns a summary of its properties, including its Amazon Resource Name (ARN). To retrieve the complete set of properties, specify the ARN with the DescribeForecast operation. You can filter the list using an array of Filter objects."},{"ref":"AWS.Forecast.html#list_predictors/3","title":"AWS.Forecast.list_predictors/3","type":"function","doc":"Returns a list of predictors created using the CreatePredictor operation. For each predictor, this operation returns a summary of its properties, including its Amazon Resource Name (ARN). You can retrieve the complete set of properties by using the ARN with the DescribePredictor operation. You can filter the list using an array of Filter objects."},{"ref":"AWS.Forecast.html#list_tags_for_resource/3","title":"AWS.Forecast.list_tags_for_resource/3","type":"function","doc":"Lists the tags for an Amazon Forecast resource."},{"ref":"AWS.Forecast.html#tag_resource/3","title":"AWS.Forecast.tag_resource/3","type":"function","doc":"Associates the specified tags to a resource with the specified resourceArn. If existing tags on a resource are not specified in the request parameters, they are not changed. When a resource is deleted, the tags associated with that resource are also deleted."},{"ref":"AWS.Forecast.html#untag_resource/3","title":"AWS.Forecast.untag_resource/3","type":"function","doc":"Deletes the specified tags from a resource."},{"ref":"AWS.Forecast.html#update_dataset_group/3","title":"AWS.Forecast.update_dataset_group/3","type":"function","doc":"Replaces the datasets in a dataset group with the specified datasets. The Status of the dataset group must be ACTIVE before you can use the dataset group to create a predictor. Use the DescribeDatasetGroup operation to get the status."},{"ref":"AWS.Forecastquery.html","title":"AWS.Forecastquery","type":"module","doc":"Provides APIs for creating and managing Amazon Forecast resources."},{"ref":"AWS.Forecastquery.html#query_forecast/3","title":"AWS.Forecastquery.query_forecast/3","type":"function","doc":"Retrieves a forecast for a single item, filtered by the supplied criteria. The criteria is a key-value pair. The key is either item_id (or the equivalent non-timestamp, non-target field) from the TARGET_TIME_SERIES dataset, or one of the forecast dimensions specified as part of the FeaturizationConfig object. By default, QueryForecast returns the complete date range for the filtered forecast. You can request a specific date range. To get the full forecast, use the CreateForecastExportJob operation. The forecasts generated by Amazon Forecast are in the same timezone as the dataset that was used to create the predictor."},{"ref":"AWS.FraudDetector.html","title":"AWS.FraudDetector","type":"module","doc":"This is the Amazon Fraud Detector API Reference. This guide is for developers who need detailed information about Amazon Fraud Detector API actions, data types, and errors. For more information about Amazon Fraud Detector features, see the Amazon Fraud Detector User Guide."},{"ref":"AWS.FraudDetector.html#batch_create_variable/3","title":"AWS.FraudDetector.batch_create_variable/3","type":"function","doc":"Creates a batch of variables."},{"ref":"AWS.FraudDetector.html#batch_get_variable/3","title":"AWS.FraudDetector.batch_get_variable/3","type":"function","doc":"Gets a batch of variables."},{"ref":"AWS.FraudDetector.html#create_detector_version/3","title":"AWS.FraudDetector.create_detector_version/3","type":"function","doc":"Creates a detector version. The detector version starts in a DRAFT status."},{"ref":"AWS.FraudDetector.html#create_model/3","title":"AWS.FraudDetector.create_model/3","type":"function","doc":"Creates a model using the specified model type."},{"ref":"AWS.FraudDetector.html#create_model_version/3","title":"AWS.FraudDetector.create_model_version/3","type":"function","doc":"Creates a version of the model using the specified model type and model id."},{"ref":"AWS.FraudDetector.html#create_rule/3","title":"AWS.FraudDetector.create_rule/3","type":"function","doc":"Creates a rule for use with the specified detector."},{"ref":"AWS.FraudDetector.html#create_variable/3","title":"AWS.FraudDetector.create_variable/3","type":"function","doc":"Creates a variable."},{"ref":"AWS.FraudDetector.html#delete_detector/3","title":"AWS.FraudDetector.delete_detector/3","type":"function","doc":"Deletes the detector. Before deleting a detector, you must first delete all detector versions and rule versions associated with the detector."},{"ref":"AWS.FraudDetector.html#delete_detector_version/3","title":"AWS.FraudDetector.delete_detector_version/3","type":"function","doc":"Deletes the detector version. You cannot delete detector versions that are in ACTIVE status."},{"ref":"AWS.FraudDetector.html#delete_event/3","title":"AWS.FraudDetector.delete_event/3","type":"function","doc":"Deletes the specified event."},{"ref":"AWS.FraudDetector.html#delete_rule/3","title":"AWS.FraudDetector.delete_rule/3","type":"function","doc":"Deletes the rule. You cannot delete a rule if it is used by an ACTIVE or INACTIVE detector version."},{"ref":"AWS.FraudDetector.html#describe_detector/3","title":"AWS.FraudDetector.describe_detector/3","type":"function","doc":"Gets all versions for a specified detector."},{"ref":"AWS.FraudDetector.html#describe_model_versions/3","title":"AWS.FraudDetector.describe_model_versions/3","type":"function","doc":"Gets all of the model versions for the specified model type or for the specified model type and model ID. You can also get details for a single, specified model version."},{"ref":"AWS.FraudDetector.html#get_detector_version/3","title":"AWS.FraudDetector.get_detector_version/3","type":"function","doc":"Gets a particular detector version."},{"ref":"AWS.FraudDetector.html#get_detectors/3","title":"AWS.FraudDetector.get_detectors/3","type":"function","doc":"Gets all detectors or a single detector if a detectorId is specified. This is a paginated API. If you provide a null maxResults, this action retrieves a maximum of 10 records per page. If you provide a maxResults, the value must be between 5 and 10. To get the next page results, provide the pagination token from the GetDetectorsResponse as part of your request. A null pagination token fetches the records from the beginning."},{"ref":"AWS.FraudDetector.html#get_entity_types/3","title":"AWS.FraudDetector.get_entity_types/3","type":"function","doc":"Gets all entity types or a specific entity type if a name is specified. This is a paginated API. If you provide a null maxResults, this action retrieves a maximum of 10 records per page. If you provide a maxResults, the value must be between 5 and 10. To get the next page results, provide the pagination token from the GetEntityTypesResponse as part of your request. A null pagination token fetches the records from the beginning."},{"ref":"AWS.FraudDetector.html#get_event_prediction/3","title":"AWS.FraudDetector.get_event_prediction/3","type":"function","doc":"Evaluates an event against a detector version. If a version ID is not provided, the detectors (ACTIVE) version is used."},{"ref":"AWS.FraudDetector.html#get_event_types/3","title":"AWS.FraudDetector.get_event_types/3","type":"function","doc":"Gets all event types or a specific event type if name is provided. This is a paginated API. If you provide a null maxResults, this action retrieves a maximum of 10 records per page. If you provide a maxResults, the value must be between 5 and 10. To get the next page results, provide the pagination token from the GetEventTypesResponse as part of your request. A null pagination token fetches the records from the beginning."},{"ref":"AWS.FraudDetector.html#get_external_models/3","title":"AWS.FraudDetector.get_external_models/3","type":"function","doc":"Gets the details for one or more Amazon SageMaker models that have been imported into the service. This is a paginated API. If you provide a null maxResults, this actions retrieves a maximum of 10 records per page. If you provide a maxResults, the value must be between 5 and 10. To get the next page results, provide the pagination token from the GetExternalModelsResult as part of your request. A null pagination token fetches the records from the beginning."},{"ref":"AWS.FraudDetector.html#get_k_m_s_encryption_key/3","title":"AWS.FraudDetector.get_k_m_s_encryption_key/3","type":"function","doc":"Gets the encryption key if a Key Management Service (KMS) customer master key (CMK) has been specified to be used to encrypt content in Amazon Fraud Detector."},{"ref":"AWS.FraudDetector.html#get_labels/3","title":"AWS.FraudDetector.get_labels/3","type":"function","doc":"Gets all labels or a specific label if name is provided. This is a paginated API. If you provide a null maxResults, this action retrieves a maximum of 50 records per page. If you provide a maxResults, the value must be between 10 and 50. To get the next page results, provide the pagination token from the GetGetLabelsResponse as part of your request. A null pagination token fetches the records from the beginning."},{"ref":"AWS.FraudDetector.html#get_model_version/3","title":"AWS.FraudDetector.get_model_version/3","type":"function","doc":"Gets the details of the specified model version."},{"ref":"AWS.FraudDetector.html#get_models/3","title":"AWS.FraudDetector.get_models/3","type":"function","doc":"Gets one or more models. Gets all models for the AWS account if no model type and no model id provided. Gets all models for the AWS account and model type, if the model type is specified but model id is not provided. Gets a specific model if (model type, model id) tuple is specified. This is a paginated API. If you provide a null maxResults, this action retrieves a maximum of 10 records per page. If you provide a maxResults, the value must be between 1 and 10. To get the next page results, provide the pagination token from the response as part of your request. A null pagination token fetches the records from the beginning."},{"ref":"AWS.FraudDetector.html#get_outcomes/3","title":"AWS.FraudDetector.get_outcomes/3","type":"function","doc":"Gets one or more outcomes. This is a paginated API. If you provide a null maxResults, this actions retrieves a maximum of 100 records per page. If you provide a maxResults, the value must be between 50 and 100. To get the next page results, provide the pagination token from the GetOutcomesResult as part of your request. A null pagination token fetches the records from the beginning."},{"ref":"AWS.FraudDetector.html#get_rules/3","title":"AWS.FraudDetector.get_rules/3","type":"function","doc":"Get all rules for a detector (paginated) if ruleId and ruleVersion are not specified. Gets all rules for the detector and the ruleId if present (paginated). Gets a specific rule if both the ruleId and the ruleVersion are specified. This is a paginated API. Providing null maxResults results in retrieving maximum of 100 records per page. If you provide maxResults the value must be between 50 and 100. To get the next page result, a provide a pagination token from GetRulesResult as part of your request. Null pagination token fetches the records from the beginning."},{"ref":"AWS.FraudDetector.html#get_variables/3","title":"AWS.FraudDetector.get_variables/3","type":"function","doc":"Gets all of the variables or the specific variable. This is a paginated API. Providing null maxSizePerPage results in retrieving maximum of 100 records per page. If you provide maxSizePerPage the value must be between 50 and 100. To get the next page result, a provide a pagination token from GetVariablesResult as part of your request. Null pagination token fetches the records from the beginning."},{"ref":"AWS.FraudDetector.html#list_tags_for_resource/3","title":"AWS.FraudDetector.list_tags_for_resource/3","type":"function","doc":"Lists all tags associated with the resource. This is a paginated API. To get the next page results, provide the pagination token from the response as part of your request. A null pagination token fetches the records from the beginning."},{"ref":"AWS.FraudDetector.html#put_detector/3","title":"AWS.FraudDetector.put_detector/3","type":"function","doc":"Creates or updates a detector."},{"ref":"AWS.FraudDetector.html#put_entity_type/3","title":"AWS.FraudDetector.put_entity_type/3","type":"function","doc":"Creates or updates an entity type. An entity represents who is performing the event. As part of a fraud prediction, you pass the entity ID to indicate the specific entity who performed the event. An entity type classifies the entity. Example classifications include customer, merchant, or account."},{"ref":"AWS.FraudDetector.html#put_event_type/3","title":"AWS.FraudDetector.put_event_type/3","type":"function","doc":"Creates or updates an event type. An event is a business activity that is evaluated for fraud risk. With Amazon Fraud Detector, you generate fraud predictions for events. An event type defines the structure for an event sent to Amazon Fraud Detector. This includes the variables sent as part of the event, the entity performing the event (such as a customer), and the labels that classify the event. Example event types include online payment transactions, account registrations, and authentications."},{"ref":"AWS.FraudDetector.html#put_external_model/3","title":"AWS.FraudDetector.put_external_model/3","type":"function","doc":"Creates or updates an Amazon SageMaker model endpoint. You can also use this action to update the configuration of the model endpoint, including the IAM role and/or the mapped variables."},{"ref":"AWS.FraudDetector.html#put_k_m_s_encryption_key/3","title":"AWS.FraudDetector.put_k_m_s_encryption_key/3","type":"function","doc":"Specifies the Key Management Service (KMS) customer master key (CMK) to be used to encrypt content in Amazon Fraud Detector."},{"ref":"AWS.FraudDetector.html#put_label/3","title":"AWS.FraudDetector.put_label/3","type":"function","doc":"Creates or updates label. A label classifies an event as fraudulent or legitimate. Labels are associated with event types and used to train supervised machine learning models in Amazon Fraud Detector."},{"ref":"AWS.FraudDetector.html#put_outcome/3","title":"AWS.FraudDetector.put_outcome/3","type":"function","doc":"Creates or updates an outcome."},{"ref":"AWS.FraudDetector.html#tag_resource/3","title":"AWS.FraudDetector.tag_resource/3","type":"function","doc":"Assigns tags to a resource."},{"ref":"AWS.FraudDetector.html#untag_resource/3","title":"AWS.FraudDetector.untag_resource/3","type":"function","doc":"Removes tags from a resource."},{"ref":"AWS.FraudDetector.html#update_detector_version/3","title":"AWS.FraudDetector.update_detector_version/3","type":"function","doc":"Updates a detector version. The detector version attributes that you can update include models, external model endpoints, rules, rule execution mode, and description. You can only update a DRAFT detector version."},{"ref":"AWS.FraudDetector.html#update_detector_version_metadata/3","title":"AWS.FraudDetector.update_detector_version_metadata/3","type":"function","doc":"Updates the detector version&#39;s description. You can update the metadata for any detector version (DRAFT, ACTIVE, or INACTIVE)."},{"ref":"AWS.FraudDetector.html#update_detector_version_status/3","title":"AWS.FraudDetector.update_detector_version_status/3","type":"function","doc":"Updates the detector versions status. You can perform the following promotions or demotions using UpdateDetectorVersionStatus: DRAFT to ACTIVE, ACTIVE to INACTIVE, and INACTIVE to ACTIVE."},{"ref":"AWS.FraudDetector.html#update_model/3","title":"AWS.FraudDetector.update_model/3","type":"function","doc":"Updates a model. You can update the description attribute using this action."},{"ref":"AWS.FraudDetector.html#update_model_version/3","title":"AWS.FraudDetector.update_model_version/3","type":"function","doc":"Updates a model version. Updating a model version retrains an existing model version using updated training data and produces a new minor version of the model. You can update the training data set location and data access role attributes using this action. This action creates and trains a new minor version of the model, for example version 1.01, 1.02, 1.03."},{"ref":"AWS.FraudDetector.html#update_model_version_status/3","title":"AWS.FraudDetector.update_model_version_status/3","type":"function","doc":"Updates the status of a model version. You can perform the following status updates: Change the TRAINING_COMPLETE status to ACTIVE. Change ACTIVEto INACTIVE."},{"ref":"AWS.FraudDetector.html#update_rule_metadata/3","title":"AWS.FraudDetector.update_rule_metadata/3","type":"function","doc":"Updates a rule&#39;s metadata. The description attribute can be updated."},{"ref":"AWS.FraudDetector.html#update_rule_version/3","title":"AWS.FraudDetector.update_rule_version/3","type":"function","doc":"Updates a rule version resulting in a new rule version. Updates a rule version resulting in a new rule version (version 1, 2, 3 ...)."},{"ref":"AWS.FraudDetector.html#update_variable/3","title":"AWS.FraudDetector.update_variable/3","type":"function","doc":"Updates a variable."},{"ref":"AWS.GameLift.html","title":"AWS.GameLift","type":"module","doc":"Amazon GameLift Service GameLift provides solutions for hosting session-based multiplayer game servers in the cloud, including tools for deploying, operating, and scaling game servers. Built on AWS global computing infrastructure, GameLift helps you deliver high-performance, high-reliability, low-cost game servers while dynamically scaling your resource usage to meet player demand. About GameLift solutions Get more information on these GameLift solutions in the Amazon GameLift Developer Guide. Managed GameLift -- GameLift offers a fully managed service to set up and maintain computing machines for hosting, manage game session and player session life cycle, and handle security, storage, and performance tracking. You can use automatic scaling tools to balance hosting costs against meeting player demand., configure your game session management to minimize player latency, or add FlexMatch for matchmaking. Managed GameLift with Realtime Servers  With GameLift Realtime Servers, you can quickly configure and set up game servers for your game. Realtime Servers provides a game server framework with core Amazon GameLift infrastructure already built in. GameLift FleetIQ  Use GameLift FleetIQ as a standalone feature while managing your own EC2 instances and Auto Scaling groups for game hosting. GameLift FleetIQ provides optimizations that make low-cost Spot Instances viable for game hosting. About this API Reference This reference guide describes the low-level service API for Amazon GameLift. You can find links to language-specific SDK guides and the AWS CLI reference with each operation and data type topic. Useful links: GameLift API operations listed by tasks GameLift tools and resources"},{"ref":"AWS.GameLift.html#accept_match/3","title":"AWS.GameLift.accept_match/3","type":"function","doc":"Registers a player&#39;s acceptance or rejection of a proposed FlexMatch match. A matchmaking configuration may require player acceptance; if so, then matches built with that configuration cannot be completed unless all players accept the proposed match within a specified time limit. When FlexMatch builds a match, all the matchmaking tickets involved in the proposed match are placed into status REQUIRES_ACCEPTANCE. This is a trigger for your game to get acceptance from all players in the ticket. Acceptances are only valid for tickets when they are in this status; all other acceptances result in an error. To register acceptance, specify the ticket ID, a response, and one or more players. Once all players have registered acceptance, the matchmaking tickets advance to status PLACING, where a new game session is created for the match. If any player rejects the match, or if acceptances are not received before a specified timeout, the proposed match is dropped. The matchmaking tickets are then handled in one of two ways: For tickets where one or more players rejected the match, the ticket status is returned to SEARCHING to find a new match. For tickets where one or more players failed to respond, the ticket status is set to CANCELLED, and processing is terminated. A new matchmaking request for these players can be submitted as needed. Learn more Add FlexMatch to a Game Client FlexMatch Events Reference Related operations StartMatchmaking DescribeMatchmaking StopMatchmaking AcceptMatch StartMatchBackfill"},{"ref":"AWS.GameLift.html#claim_game_server/3","title":"AWS.GameLift.claim_game_server/3","type":"function","doc":"This operation is used with the Amazon GameLift FleetIQ solution and game server groups. Locates an available game server and temporarily reserves it to host gameplay and players. This operation is called from a game client or client service (such as a matchmaker) to request hosting resources for a new game session. In response, GameLift FleetIQ locates an available game server, places it in CLAIMED status for 60 seconds, and returns connection information that players can use to connect to the game server. To claim a game server, identify a game server group. You can also specify a game server ID, although this approach bypasses GameLift FleetIQ placement optimization. Optionally, include game data to pass to the game server at the start of a game session, such as a game map or player information. When a game server is successfully claimed, connection information is returned. A claimed game server&#39;s utilization status remains AVAILABLE while the claim status is set to CLAIMED for up to 60 seconds. This time period gives the game server time to update its status to UTILIZED (using UpdateGameServer) once players join. If the game server&#39;s status is not updated within 60 seconds, the game server reverts to unclaimed status and is available to be claimed by another request. The claim time period is a fixed value and is not configurable. If you try to claim a specific game server, this request will fail in the following cases: If the game server utilization status is UTILIZED. If the game server claim status is CLAIMED. When claiming a specific game server, this request will succeed even if the game server is running on an instance in DRAINING status. To avoid this, first check the instance status by calling DescribeGameServerInstances. Learn more GameLift FleetIQ Guide Related operations RegisterGameServer ListGameServers ClaimGameServer DescribeGameServer UpdateGameServer DeregisterGameServer"},{"ref":"AWS.GameLift.html#create_alias/3","title":"AWS.GameLift.create_alias/3","type":"function","doc":"Creates an alias for a fleet. In most situations, you can use an alias ID in place of a fleet ID. An alias provides a level of abstraction for a fleet that is useful when redirecting player traffic from one fleet to another, such as when updating your game build. Amazon GameLift supports two types of routing strategies for aliases: simple and terminal. A simple alias points to an active fleet. A terminal alias is used to display messaging or link to a URL instead of routing players to an active fleet. For example, you might use a terminal alias when a game version is no longer supported and you want to direct players to an upgrade site. To create a fleet alias, specify an alias name, routing strategy, and optional description. Each simple alias can point to only one fleet, but a fleet can have multiple aliases. If successful, a new alias record is returned, including an alias ID and an ARN. You can reassign an alias to another fleet by calling UpdateAlias. CreateAlias ListAliases DescribeAlias UpdateAlias DeleteAlias ResolveAlias"},{"ref":"AWS.GameLift.html#create_build/3","title":"AWS.GameLift.create_build/3","type":"function","doc":"Creates a new Amazon GameLift build resource for your game server binary files. Game server binaries must be combined into a zip file for use with Amazon GameLift. When setting up a new game build for GameLift, we recommend using the AWS CLI command upload-build . This helper command combines two tasks: (1) it uploads your build files from a file directory to a GameLift Amazon S3 location, and (2) it creates a new build resource. The CreateBuild operation can used in the following scenarios: To create a new game build with build files that are in an S3 location under an AWS account that you control. To use this option, you must first give Amazon GameLift access to the S3 bucket. With permissions in place, call CreateBuild and specify a build name, operating system, and the S3 storage location of your game build. To directly upload your build files to a GameLift S3 location. To use this option, first call CreateBuild and specify a build name and operating system. This operation creates a new build resource and also returns an S3 location with temporary access credentials. Use the credentials to manually upload your build files to the specified S3 location. For more information, see Uploading Objects in the Amazon S3 Developer Guide. Build files can be uploaded to the GameLift S3 location once only; that can&#39;t be updated. If successful, this operation creates a new build resource with a unique build ID and places it in INITIALIZED status. A build must be in READY status before you can create fleets with it. Learn more Uploading Your Game Create a Build with Files in Amazon S3 Related operations CreateBuild ListBuilds DescribeBuild UpdateBuild DeleteBuild"},{"ref":"AWS.GameLift.html#create_fleet/3","title":"AWS.GameLift.create_fleet/3","type":"function","doc":"Creates a new fleet to run your game servers. whether they are custom game builds or Realtime Servers with game-specific script. A fleet is a set of Amazon Elastic Compute Cloud (Amazon EC2) instances, each of which can host multiple game sessions. When creating a fleet, you choose the hardware specifications, set some configuration options, and specify the game server to deploy on the new fleet. To create a new fleet, provide the following: (1) a fleet name, (2) an EC2 instance type and fleet type (spot or on-demand), (3) the build ID for your game build or script ID if using Realtime Servers, and (4) a runtime configuration, which determines how game servers will run on each instance in the fleet. If the CreateFleet call is successful, Amazon GameLift performs the following tasks. You can track the process of a fleet by checking the fleet status or by monitoring fleet creation events: Creates a fleet resource. Status: NEW. Begins writing events to the fleet event log, which can be accessed in the Amazon GameLift console. Sets the fleet&#39;s target capacity to 1 (desired instances), which triggers Amazon GameLift to start one new EC2 instance. Downloads the game build or Realtime script to the new instance and installs it. Statuses: DOWNLOADING, VALIDATING, BUILDING. Starts launching server processes on the instance. If the fleet is configured to run multiple server processes per instance, Amazon GameLift staggers each process launch by a few seconds. Status: ACTIVATING. Sets the fleet&#39;s status to ACTIVE as soon as one server process is ready to host a game session. Learn more Setting Up FleetsDebug Fleet Creation Issues Related operations CreateFleet ListFleets DeleteFleet DescribeFleetAttributes UpdateFleetAttributes StartFleetActions or StopFleetActions"},{"ref":"AWS.GameLift.html#create_game_server_group/3","title":"AWS.GameLift.create_game_server_group/3","type":"function","doc":"This operation is used with the Amazon GameLift FleetIQ solution and game server groups. Creates a GameLift FleetIQ game server group for managing game hosting on a collection of Amazon EC2 instances for game hosting. This operation creates the game server group, creates an Auto Scaling group in your AWS account, and establishes a link between the two groups. You can view the status of your game server groups in the GameLift console. Game server group metrics and events are emitted to Amazon CloudWatch. Before creating a new game server group, you must have the following: An Amazon EC2 launch template that specifies how to launch Amazon EC2 instances with your game server build. For more information, see Launching an Instance from a Launch Template in the Amazon EC2 User Guide. An IAM role that extends limited access to your AWS account to allow GameLift FleetIQ to create and interact with the Auto Scaling group. For more information, see Create IAM roles for cross-service interaction in the GameLift FleetIQ Developer Guide. To create a new game server group, specify a unique group name, IAM role and Amazon EC2 launch template, and provide a list of instance types that can be used in the group. You must also set initial maximum and minimum limits on the group&#39;s instance count. You can optionally set an Auto Scaling policy with target tracking based on a GameLift FleetIQ metric. Once the game server group and corresponding Auto Scaling group are created, you have full access to change the Auto Scaling group&#39;s configuration as needed. Several properties that are set when creating a game server group, including maximum/minimum size and auto-scaling policy settings, must be updated directly in the Auto Scaling group. Keep in mind that some Auto Scaling group properties are periodically updated by GameLift FleetIQ as part of its balancing activities to optimize for availability and cost. Learn more GameLift FleetIQ Guide Related operations CreateGameServerGroup ListGameServerGroups DescribeGameServerGroup UpdateGameServerGroup DeleteGameServerGroup ResumeGameServerGroup SuspendGameServerGroup DescribeGameServerInstances"},{"ref":"AWS.GameLift.html#create_game_session/3","title":"AWS.GameLift.create_game_session/3","type":"function","doc":"Creates a multiplayer game session for players. This operation creates a game session record and assigns an available server process in the specified fleet to host the game session. A fleet must have an ACTIVE status before a game session can be created in it. To create a game session, specify either fleet ID or alias ID and indicate a maximum number of players to allow in the game session. You can also provide a name and game-specific properties for this game session. If successful, a GameSession object is returned containing the game session properties and other settings you specified. Idempotency tokens. You can add a token that uniquely identifies game session requests. This is useful for ensuring that game session requests are idempotent. Multiple requests with the same idempotency token are processed only once; subsequent requests return the original result. All response values are the same with the exception of game session status, which may change. Resource creation limits. If you are creating a game session on a fleet with a resource creation limit policy in force, then you must specify a creator ID. Without this ID, Amazon GameLift has no way to evaluate the policy for this new game session request. Player acceptance policy. By default, newly created game sessions are open to new players. You can restrict new player access by using UpdateGameSession to change the game session&#39;s player session creation policy. Game session logs. Logs are retained for all active game sessions for 14 days. To access the logs, call GetGameSessionLogUrl to download the log files. Available in Amazon GameLift Local. CreateGameSession DescribeGameSessions DescribeGameSessionDetails SearchGameSessions UpdateGameSession GetGameSessionLogUrl Game session placements StartGameSessionPlacement DescribeGameSessionPlacement StopGameSessionPlacement"},{"ref":"AWS.GameLift.html#create_game_session_queue/3","title":"AWS.GameLift.create_game_session_queue/3","type":"function","doc":"Establishes a new queue for processing requests to place new game sessions. A queue identifies where new game sessions can be hosted -- by specifying a list of destinations (fleets or aliases) -- and how long requests can wait in the queue before timing out. You can set up a queue to try to place game sessions on fleets in multiple Regions. To add placement requests to a queue, call StartGameSessionPlacement and reference the queue name. Destination order. When processing a request for a game session, Amazon GameLift tries each destination in order until it finds one with available resources to host the new game session. A queue&#39;s default order is determined by how destinations are listed. The default order is overridden when a game session placement request provides player latency information. Player latency information enables Amazon GameLift to prioritize destinations where players report the lowest average latency, as a result placing the new game session where the majority of players will have the best possible gameplay experience. Player latency policies. For placement requests containing player latency information, use player latency policies to protect individual players from very high latencies. With a latency cap, even when a destination can deliver a low latency for most players, the game is not placed where any individual player is reporting latency higher than a policy&#39;s maximum. A queue can have multiple latency policies, which are enforced consecutively starting with the policy with the lowest latency cap. Use multiple policies to gradually relax latency controls; for example, you might set a policy with a low latency cap for the first 60 seconds, a second policy with a higher cap for the next 60 seconds, etc. To create a new queue, provide a name, timeout value, a list of destinations and, if desired, a set of latency policies. If successful, a new queue object is returned. Learn more Design a Game Session Queue Create a Game Session Queue Related operations CreateGameSessionQueue DescribeGameSessionQueues UpdateGameSessionQueue DeleteGameSessionQueue"},{"ref":"AWS.GameLift.html#create_matchmaking_configuration/3","title":"AWS.GameLift.create_matchmaking_configuration/3","type":"function","doc":"Defines a new matchmaking configuration for use with FlexMatch. A matchmaking configuration sets out guidelines for matching players and getting the matches into games. You can set up multiple matchmaking configurations to handle the scenarios needed for your game. Each matchmaking ticket (StartMatchmaking or StartMatchBackfill) specifies a configuration for the match and provides player attributes to support the configuration being used. To create a matchmaking configuration, at a minimum you must specify the following: configuration name; a rule set that governs how to evaluate players and find acceptable matches; a game session queue to use when placing a new game session for the match; and the maximum time allowed for a matchmaking attempt. To track the progress of matchmaking tickets, set up an Amazon Simple Notification Service (SNS) to receive notifications, and provide the topic ARN in the matchmaking configuration. An alternative method, continuously poling ticket status with DescribeMatchmaking, should only be used for games in development with low matchmaking usage. Learn more Design a FlexMatch Matchmaker Set Up FlexMatch Event Notification Related operations CreateMatchmakingConfiguration DescribeMatchmakingConfigurations UpdateMatchmakingConfiguration DeleteMatchmakingConfiguration CreateMatchmakingRuleSet DescribeMatchmakingRuleSets ValidateMatchmakingRuleSet DeleteMatchmakingRuleSet"},{"ref":"AWS.GameLift.html#create_matchmaking_rule_set/3","title":"AWS.GameLift.create_matchmaking_rule_set/3","type":"function","doc":"Creates a new rule set for FlexMatch matchmaking. A rule set describes the type of match to create, such as the number and size of teams. It also sets the parameters for acceptable player matches, such as minimum skill level or character type. A rule set is used by a MatchmakingConfiguration. To create a matchmaking rule set, provide unique rule set name and the rule set body in JSON format. Rule sets must be defined in the same Region as the matchmaking configuration they are used with. Since matchmaking rule sets cannot be edited, it is a good idea to check the rule set syntax using ValidateMatchmakingRuleSet before creating a new rule set. Learn more Build a Rule Set Design a Matchmaker Matchmaking with FlexMatch Related operations CreateMatchmakingConfiguration DescribeMatchmakingConfigurations UpdateMatchmakingConfiguration DeleteMatchmakingConfiguration CreateMatchmakingRuleSet DescribeMatchmakingRuleSets ValidateMatchmakingRuleSet DeleteMatchmakingRuleSet"},{"ref":"AWS.GameLift.html#create_player_session/3","title":"AWS.GameLift.create_player_session/3","type":"function","doc":"Reserves an open player slot in an active game session. Before a player can be added, a game session must have an ACTIVE status, have a creation policy of ALLOW_ALL, and have an open player slot. To add a group of players to a game session, use CreatePlayerSessions. When the player connects to the game server and references a player session ID, the game server contacts the Amazon GameLift service to validate the player reservation and accept the player. To create a player session, specify a game session ID, player ID, and optionally a string of player data. If successful, a slot is reserved in the game session for the player and a new PlayerSession object is returned. Player sessions cannot be updated. Available in Amazon GameLift Local. CreatePlayerSession CreatePlayerSessions DescribePlayerSessions Game session placements StartGameSessionPlacement DescribeGameSessionPlacement StopGameSessionPlacement"},{"ref":"AWS.GameLift.html#create_player_sessions/3","title":"AWS.GameLift.create_player_sessions/3","type":"function","doc":"Reserves open slots in a game session for a group of players. Before players can be added, a game session must have an ACTIVE status, have a creation policy of ALLOW_ALL, and have an open player slot. To add a single player to a game session, use CreatePlayerSession. When a player connects to the game server and references a player session ID, the game server contacts the Amazon GameLift service to validate the player reservation and accept the player. To create player sessions, specify a game session ID, a list of player IDs, and optionally a set of player data strings. If successful, a slot is reserved in the game session for each player and a set of new PlayerSession objects is returned. Player sessions cannot be updated. Available in Amazon GameLift Local. CreatePlayerSession CreatePlayerSessions DescribePlayerSessions Game session placements StartGameSessionPlacement DescribeGameSessionPlacement StopGameSessionPlacement"},{"ref":"AWS.GameLift.html#create_script/3","title":"AWS.GameLift.create_script/3","type":"function","doc":"Creates a new script record for your Realtime Servers script. Realtime scripts are JavaScript that provide configuration settings and optional custom game logic for your game. The script is deployed when you create a Realtime Servers fleet to host your game sessions. Script logic is executed during an active game session. To create a new script record, specify a script name and provide the script file(s). The script files and all dependencies must be zipped into a single file. You can pull the zip file from either of these locations: A locally available directory. Use the ZipFile parameter for this option. An Amazon Simple Storage Service (Amazon S3) bucket under your AWS account. Use the StorageLocation parameter for this option. You&#39;ll need to have an Identity Access Management (IAM) role that allows the Amazon GameLift service to access your S3 bucket. If the call is successful, a new script record is created with a unique script ID. If the script file is provided as a local file, the file is uploaded to an Amazon GameLift-owned S3 bucket and the script record&#39;s storage location reflects this location. If the script file is provided as an S3 bucket, Amazon GameLift accesses the file at this storage location as needed for deployment. Learn more Amazon GameLift Realtime Servers Set Up a Role for Amazon GameLift Access Related operations CreateScript ListScripts DescribeScript UpdateScript DeleteScript"},{"ref":"AWS.GameLift.html#create_vpc_peering_authorization/3","title":"AWS.GameLift.create_vpc_peering_authorization/3","type":"function","doc":"Requests authorization to create or delete a peer connection between the VPC for your Amazon GameLift fleet and a virtual private cloud (VPC) in your AWS account. VPC peering enables the game servers on your fleet to communicate directly with other AWS resources. Once you&#39;ve received authorization, call CreateVpcPeeringConnection to establish the peering connection. For more information, see VPC Peering with Amazon GameLift Fleets. You can peer with VPCs that are owned by any AWS account you have access to, including the account that you use to manage your Amazon GameLift fleets. You cannot peer with VPCs that are in different Regions. To request authorization to create a connection, call this operation from the AWS account with the VPC that you want to peer to your Amazon GameLift fleet. For example, to enable your game servers to retrieve data from a DynamoDB table, use the account that manages that DynamoDB resource. Identify the following values: (1) The ID of the VPC that you want to peer with, and (2) the ID of the AWS account that you use to manage Amazon GameLift. If successful, VPC peering is authorized for the specified VPC. To request authorization to delete a connection, call this operation from the AWS account with the VPC that is peered with your Amazon GameLift fleet. Identify the following values: (1) VPC ID that you want to delete the peering connection for, and (2) ID of the AWS account that you use to manage Amazon GameLift. The authorization remains valid for 24 hours unless it is canceled by a call to DeleteVpcPeeringAuthorization. You must create or delete the peering connection while the authorization is valid. CreateVpcPeeringAuthorization DescribeVpcPeeringAuthorizations DeleteVpcPeeringAuthorization CreateVpcPeeringConnection DescribeVpcPeeringConnections DeleteVpcPeeringConnection"},{"ref":"AWS.GameLift.html#create_vpc_peering_connection/3","title":"AWS.GameLift.create_vpc_peering_connection/3","type":"function","doc":"Establishes a VPC peering connection between a virtual private cloud (VPC) in an AWS account with the VPC for your Amazon GameLift fleet. VPC peering enables the game servers on your fleet to communicate directly with other AWS resources. You can peer with VPCs in any AWS account that you have access to, including the account that you use to manage your Amazon GameLift fleets. You cannot peer with VPCs that are in different Regions. For more information, see VPC Peering with Amazon GameLift Fleets. Before calling this operation to establish the peering connection, you first need to call CreateVpcPeeringAuthorization and identify the VPC you want to peer with. Once the authorization for the specified VPC is issued, you have 24 hours to establish the connection. These two operations handle all tasks necessary to peer the two VPCs, including acceptance, updating routing tables, etc. To establish the connection, call this operation from the AWS account that is used to manage the Amazon GameLift fleets. Identify the following values: (1) The ID of the fleet you want to be enable a VPC peering connection for; (2) The AWS account with the VPC that you want to peer with; and (3) The ID of the VPC you want to peer with. This operation is asynchronous. If successful, a VpcPeeringConnection request is created. You can use continuous polling to track the request&#39;s status using DescribeVpcPeeringConnections, or by monitoring fleet events for success or failure using DescribeFleetEvents. CreateVpcPeeringAuthorization DescribeVpcPeeringAuthorizations DeleteVpcPeeringAuthorization CreateVpcPeeringConnection DescribeVpcPeeringConnections DeleteVpcPeeringConnection"},{"ref":"AWS.GameLift.html#delete_alias/3","title":"AWS.GameLift.delete_alias/3","type":"function","doc":"Deletes an alias. This operation removes all record of the alias. Game clients attempting to access a server process using the deleted alias receive an error. To delete an alias, specify the alias ID to be deleted. CreateAlias ListAliases DescribeAlias UpdateAlias DeleteAlias ResolveAlias"},{"ref":"AWS.GameLift.html#delete_build/3","title":"AWS.GameLift.delete_build/3","type":"function","doc":"Deletes a build. This operation permanently deletes the build resource and any uploaded build files. Deleting a build does not affect the status of any active fleets using the build, but you can no longer create new fleets with the deleted build. To delete a build, specify the build ID. Learn more Upload a Custom Server Build Related operations CreateBuild ListBuilds DescribeBuild UpdateBuild DeleteBuild"},{"ref":"AWS.GameLift.html#delete_fleet/3","title":"AWS.GameLift.delete_fleet/3","type":"function","doc":"Deletes everything related to a fleet. Before deleting a fleet, you must set the fleet&#39;s desired capacity to zero. See UpdateFleetCapacity. If the fleet being deleted has a VPC peering connection, you first need to get a valid authorization (good for 24 hours) by calling CreateVpcPeeringAuthorization. You do not need to explicitly delete the VPC peering connection--this is done as part of the delete fleet process. This operation removes the fleet and its resources. Once a fleet is deleted, you can no longer use any of the resource in that fleet. Learn more Setting up GameLift Fleets Related operations CreateFleet ListFleets DeleteFleet DescribeFleetAttributes UpdateFleetAttributes StartFleetActions or StopFleetActions"},{"ref":"AWS.GameLift.html#delete_game_server_group/3","title":"AWS.GameLift.delete_game_server_group/3","type":"function","doc":"This operation is used with the Amazon GameLift FleetIQ solution and game server groups. Terminates a game server group and permanently deletes the game server group record. You have several options for how these resources are impacted when deleting the game server group. Depending on the type of delete operation selected, this operation might affect these resources: The game server group The corresponding Auto Scaling group All game servers that are currently running in the group To delete a game server group, identify the game server group to delete and specify the type of delete operation to initiate. Game server groups can only be deleted if they are in ACTIVE or ERROR status. If the delete request is successful, a series of operations are kicked off. The game server group status is changed to DELETE_SCHEDULED, which prevents new game servers from being registered and stops automatic scaling activity. Once all game servers in the game server group are deregistered, GameLift FleetIQ can begin deleting resources. If any of the delete operations fail, the game server group is placed in ERROR status. GameLift FleetIQ emits delete events to Amazon CloudWatch. Learn more GameLift FleetIQ Guide Related operations CreateGameServerGroup ListGameServerGroups DescribeGameServerGroup UpdateGameServerGroup DeleteGameServerGroup ResumeGameServerGroup SuspendGameServerGroup DescribeGameServerInstances"},{"ref":"AWS.GameLift.html#delete_game_session_queue/3","title":"AWS.GameLift.delete_game_session_queue/3","type":"function","doc":"Deletes a game session queue. Once a queue is successfully deleted, unfulfilled StartGameSessionPlacement requests that reference the queue will fail. To delete a queue, specify the queue name. Learn more Using Multi-Region Queues Related operations CreateGameSessionQueue DescribeGameSessionQueues UpdateGameSessionQueue DeleteGameSessionQueue"},{"ref":"AWS.GameLift.html#delete_matchmaking_configuration/3","title":"AWS.GameLift.delete_matchmaking_configuration/3","type":"function","doc":"Permanently removes a FlexMatch matchmaking configuration. To delete, specify the configuration name. A matchmaking configuration cannot be deleted if it is being used in any active matchmaking tickets. Related operations CreateMatchmakingConfiguration DescribeMatchmakingConfigurations UpdateMatchmakingConfiguration DeleteMatchmakingConfiguration CreateMatchmakingRuleSet DescribeMatchmakingRuleSets ValidateMatchmakingRuleSet DeleteMatchmakingRuleSet"},{"ref":"AWS.GameLift.html#delete_matchmaking_rule_set/3","title":"AWS.GameLift.delete_matchmaking_rule_set/3","type":"function","doc":"Deletes an existing matchmaking rule set. To delete the rule set, provide the rule set name. Rule sets cannot be deleted if they are currently being used by a matchmaking configuration. Learn more Build a Rule Set Related operations CreateMatchmakingConfiguration DescribeMatchmakingConfigurations UpdateMatchmakingConfiguration DeleteMatchmakingConfiguration CreateMatchmakingRuleSet DescribeMatchmakingRuleSets ValidateMatchmakingRuleSet DeleteMatchmakingRuleSet"},{"ref":"AWS.GameLift.html#delete_scaling_policy/3","title":"AWS.GameLift.delete_scaling_policy/3","type":"function","doc":"Deletes a fleet scaling policy. Once deleted, the policy is no longer in force and GameLift removes all record of it. To delete a scaling policy, specify both the scaling policy name and the fleet ID it is associated with. To temporarily suspend scaling policies, call StopFleetActions. This operation suspends all policies for the fleet. DescribeFleetCapacity UpdateFleetCapacity DescribeEC2InstanceLimits Manage scaling policies: PutScalingPolicy (auto-scaling) DescribeScalingPolicies (auto-scaling) DeleteScalingPolicy (auto-scaling) Manage fleet actions: StartFleetActions StopFleetActions"},{"ref":"AWS.GameLift.html#delete_script/3","title":"AWS.GameLift.delete_script/3","type":"function","doc":"Deletes a Realtime script. This operation permanently deletes the script record. If script files were uploaded, they are also deleted (files stored in an S3 bucket are not deleted). To delete a script, specify the script ID. Before deleting a script, be sure to terminate all fleets that are deployed with the script being deleted. Fleet instances periodically check for script updates, and if the script record no longer exists, the instance will go into an error state and be unable to host game sessions. Learn more Amazon GameLift Realtime Servers Related operations CreateScript ListScripts DescribeScript UpdateScript DeleteScript"},{"ref":"AWS.GameLift.html#delete_vpc_peering_authorization/3","title":"AWS.GameLift.delete_vpc_peering_authorization/3","type":"function","doc":"Cancels a pending VPC peering authorization for the specified VPC. If you need to delete an existing VPC peering connection, call DeleteVpcPeeringConnection. CreateVpcPeeringAuthorization DescribeVpcPeeringAuthorizations DeleteVpcPeeringAuthorization CreateVpcPeeringConnection DescribeVpcPeeringConnections DeleteVpcPeeringConnection"},{"ref":"AWS.GameLift.html#delete_vpc_peering_connection/3","title":"AWS.GameLift.delete_vpc_peering_connection/3","type":"function","doc":"Removes a VPC peering connection. To delete the connection, you must have a valid authorization for the VPC peering connection that you want to delete. You can check for an authorization by calling DescribeVpcPeeringAuthorizations or request a new one using CreateVpcPeeringAuthorization. Once a valid authorization exists, call this operation from the AWS account that is used to manage the Amazon GameLift fleets. Identify the connection to delete by the connection ID and fleet ID. If successful, the connection is removed. CreateVpcPeeringAuthorization DescribeVpcPeeringAuthorizations DeleteVpcPeeringAuthorization CreateVpcPeeringConnection DescribeVpcPeeringConnections DeleteVpcPeeringConnection"},{"ref":"AWS.GameLift.html#deregister_game_server/3","title":"AWS.GameLift.deregister_game_server/3","type":"function","doc":"This operation is used with the Amazon GameLift FleetIQ solution and game server groups. Removes the game server from a game server group. As a result of this operation, the deregistered game server can no longer be claimed and will not be returned in a list of active game servers. To deregister a game server, specify the game server group and game server ID. If successful, this operation emits a CloudWatch event with termination timestamp and reason. Learn more GameLift FleetIQ Guide Related operations RegisterGameServer ListGameServers ClaimGameServer DescribeGameServer UpdateGameServer DeregisterGameServer"},{"ref":"AWS.GameLift.html#describe_alias/3","title":"AWS.GameLift.describe_alias/3","type":"function","doc":"Retrieves properties for an alias. This operation returns all alias metadata and settings. To get an alias&#39;s target fleet ID only, use ResolveAlias. To get alias properties, specify the alias ID. If successful, the requested alias record is returned. CreateAlias ListAliases DescribeAlias UpdateAlias DeleteAlias ResolveAlias"},{"ref":"AWS.GameLift.html#describe_build/3","title":"AWS.GameLift.describe_build/3","type":"function","doc":"Retrieves properties for a custom game build. To request a build resource, specify a build ID. If successful, an object containing the build properties is returned. Learn more Upload a Custom Server Build Related operations CreateBuild ListBuilds DescribeBuild UpdateBuild DeleteBuild"},{"ref":"AWS.GameLift.html#describe_e_c2_instance_limits/3","title":"AWS.GameLift.describe_e_c2_instance_limits/3","type":"function","doc":"Retrieves the following information for the specified EC2 instance type: Maximum number of instances allowed per AWS account (service limit). Current usage for the AWS account. To learn more about the capabilities of each instance type, see Amazon EC2 Instance Types. Note that the instance types offered may vary depending on the region. Learn more Setting up GameLift Fleets Related operations CreateFleet ListFleets DeleteFleet DescribeFleetAttributes UpdateFleetAttributes StartFleetActions or StopFleetActions"},{"ref":"AWS.GameLift.html#describe_fleet_attributes/3","title":"AWS.GameLift.describe_fleet_attributes/3","type":"function","doc":"Retrieves core properties, including configuration, status, and metadata, for a fleet. To get attributes for one or more fleets, provide a list of fleet IDs or fleet ARNs. To get attributes for all fleets, do not specify a fleet identifier. When requesting attributes for multiple fleets, use the pagination parameters to retrieve results as a set of sequential pages. If successful, a FleetAttributes object is returned for each fleet requested, unless the fleet identifier is not found. Some API operations may limit the number of fleet IDs allowed in one request. If a request exceeds this limit, the request fails and the error message includes the maximum allowed number. Learn more Setting up GameLift Fleets Related operations CreateFleet ListFleets DeleteFleet Describe fleets: DescribeFleetAttributes DescribeFleetCapacity DescribeFleetPortSettings DescribeFleetUtilization DescribeRuntimeConfiguration DescribeEC2InstanceLimits DescribeFleetEvents UpdateFleetAttributes StartFleetActions or StopFleetActions"},{"ref":"AWS.GameLift.html#describe_fleet_capacity/3","title":"AWS.GameLift.describe_fleet_capacity/3","type":"function","doc":"Retrieves the current capacity statistics for one or more fleets. These statistics present a snapshot of the fleet&#39;s instances and provide insight on current or imminent scaling activity. To get statistics on game hosting activity in the fleet, see DescribeFleetUtilization. You can request capacity for all fleets or specify a list of one or more fleet identifiers. When requesting multiple fleets, use the pagination parameters to retrieve results as a set of sequential pages. If successful, a FleetCapacity object is returned for each requested fleet ID. When a list of fleet IDs is provided, attribute objects are returned only for fleets that currently exist. Some API operations may limit the number of fleet IDs allowed in one request. If a request exceeds this limit, the request fails and the error message includes the maximum allowed. Learn more Setting up GameLift Fleets GameLift Metrics for Fleets Related operations CreateFleet ListFleets DeleteFleet Describe fleets: DescribeFleetAttributes DescribeFleetCapacity DescribeFleetPortSettings DescribeFleetUtilization DescribeRuntimeConfiguration DescribeEC2InstanceLimits DescribeFleetEvents UpdateFleetAttributes StartFleetActions or StopFleetActions"},{"ref":"AWS.GameLift.html#describe_fleet_events/3","title":"AWS.GameLift.describe_fleet_events/3","type":"function","doc":"Retrieves entries from the specified fleet&#39;s event log. You can specify a time range to limit the result set. Use the pagination parameters to retrieve results as a set of sequential pages. If successful, a collection of event log entries matching the request are returned. Learn more Setting up GameLift Fleets Related operations CreateFleet ListFleets DeleteFleet Describe fleets: DescribeFleetAttributes DescribeFleetCapacity DescribeFleetPortSettings DescribeFleetUtilization DescribeRuntimeConfiguration DescribeEC2InstanceLimits DescribeFleetEvents UpdateFleetAttributes StartFleetActions or StopFleetActions"},{"ref":"AWS.GameLift.html#describe_fleet_port_settings/3","title":"AWS.GameLift.describe_fleet_port_settings/3","type":"function","doc":"Retrieves a fleet&#39;s inbound connection permissions. Connection permissions specify the range of IP addresses and port settings that incoming traffic can use to access server processes in the fleet. Game sessions that are running on instances in the fleet use connections that fall in this range. To get a fleet&#39;s inbound connection permissions, specify the fleet&#39;s unique identifier. If successful, a collection of IpPermission objects is returned for the requested fleet ID. If the requested fleet has been deleted, the result set is empty. Learn more Setting up GameLift Fleets Related operations CreateFleet ListFleets DeleteFleet Describe fleets: DescribeFleetAttributes DescribeFleetCapacity DescribeFleetPortSettings DescribeFleetUtilization DescribeRuntimeConfiguration DescribeEC2InstanceLimits DescribeFleetEvents UpdateFleetAttributes StartFleetActions or StopFleetActions"},{"ref":"AWS.GameLift.html#describe_fleet_utilization/3","title":"AWS.GameLift.describe_fleet_utilization/3","type":"function","doc":"Retrieves utilization statistics for one or more fleets. These statistics provide insight into how available hosting resources are currently being used. To get statistics on available hosting resources, see DescribeFleetCapacity. You can request utilization data for all fleets, or specify a list of one or more fleet IDs. When requesting multiple fleets, use the pagination parameters to retrieve results as a set of sequential pages. If successful, a FleetUtilization object is returned for each requested fleet ID, unless the fleet identifier is not found. Some API operations may limit the number of fleet IDs allowed in one request. If a request exceeds this limit, the request fails and the error message includes the maximum allowed. Learn more Setting up GameLift Fleets GameLift Metrics for Fleets Related operations CreateFleet ListFleets DeleteFleet Describe fleets: DescribeFleetAttributes DescribeFleetCapacity DescribeFleetPortSettings DescribeFleetUtilization DescribeRuntimeConfiguration DescribeEC2InstanceLimits DescribeFleetEvents UpdateFleetAttributes StartFleetActions or StopFleetActions"},{"ref":"AWS.GameLift.html#describe_game_server/3","title":"AWS.GameLift.describe_game_server/3","type":"function","doc":"This operation is used with the Amazon GameLift FleetIQ solution and game server groups. Retrieves information for a registered game server. Information includes game server status, health check info, and the instance that the game server is running on. To retrieve game server information, specify the game server ID. If successful, the requested game server object is returned. Learn more GameLift FleetIQ Guide Related operations RegisterGameServer ListGameServers ClaimGameServer DescribeGameServer UpdateGameServer DeregisterGameServer"},{"ref":"AWS.GameLift.html#describe_game_server_group/3","title":"AWS.GameLift.describe_game_server_group/3","type":"function","doc":"This operation is used with the Amazon GameLift FleetIQ solution and game server groups. Retrieves information on a game server group. This operation returns only properties related to GameLift FleetIQ. To view or update properties for the corresponding Auto Scaling group, such as launch template, auto scaling policies, and maximum/minimum group size, access the Auto Scaling group directly. To get attributes for a game server group, provide a group name or ARN value. If successful, a GameServerGroup object is returned. Learn more GameLift FleetIQ Guide Related operations CreateGameServerGroup ListGameServerGroups DescribeGameServerGroup UpdateGameServerGroup DeleteGameServerGroup ResumeGameServerGroup SuspendGameServerGroup DescribeGameServerInstances"},{"ref":"AWS.GameLift.html#describe_game_server_instances/3","title":"AWS.GameLift.describe_game_server_instances/3","type":"function","doc":"This operation is used with the Amazon GameLift FleetIQ solution and game server groups. Retrieves status information about the Amazon EC2 instances associated with a GameLift FleetIQ game server group. Use this operation to detect when instances are active or not available to host new game servers. If you are looking for instance configuration information, call DescribeGameServerGroup or access the corresponding Auto Scaling group properties. To request status for all instances in the game server group, provide a game server group ID only. To request status for specific instances, provide the game server group ID and one or more instance IDs. Use the pagination parameters to retrieve results in sequential segments. If successful, a collection of GameServerInstance objects is returned. This operation is not designed to be called with every game server claim request; this practice can cause you to exceed your API limit, which results in errors. Instead, as a best practice, cache the results and refresh your cache no more than once every 10 seconds. Learn more GameLift FleetIQ Guide Related operations CreateGameServerGroup ListGameServerGroups DescribeGameServerGroup UpdateGameServerGroup DeleteGameServerGroup ResumeGameServerGroup SuspendGameServerGroup DescribeGameServerInstances"},{"ref":"AWS.GameLift.html#describe_game_session_details/3","title":"AWS.GameLift.describe_game_session_details/3","type":"function","doc":"Retrieves properties, including the protection policy in force, for one or more game sessions. This operation can be used in several ways: (1) provide a GameSessionId or GameSessionArn to request details for a specific game session; (2) provide either a FleetId or an AliasId to request properties for all game sessions running on a fleet. To get game session record(s), specify just one of the following: game session ID, fleet ID, or alias ID. You can filter this request by game session status. Use the pagination parameters to retrieve results as a set of sequential pages. If successful, a GameSessionDetail object is returned for each session matching the request. CreateGameSession DescribeGameSessions DescribeGameSessionDetails SearchGameSessions UpdateGameSession GetGameSessionLogUrl Game session placements StartGameSessionPlacement DescribeGameSessionPlacement StopGameSessionPlacement"},{"ref":"AWS.GameLift.html#describe_game_session_placement/3","title":"AWS.GameLift.describe_game_session_placement/3","type":"function","doc":"Retrieves properties and current status of a game session placement request. To get game session placement details, specify the placement ID. If successful, a GameSessionPlacement object is returned. CreateGameSession DescribeGameSessions DescribeGameSessionDetails SearchGameSessions UpdateGameSession GetGameSessionLogUrl Game session placements StartGameSessionPlacement DescribeGameSessionPlacement StopGameSessionPlacement"},{"ref":"AWS.GameLift.html#describe_game_session_queues/3","title":"AWS.GameLift.describe_game_session_queues/3","type":"function","doc":"Retrieves the properties for one or more game session queues. When requesting multiple queues, use the pagination parameters to retrieve results as a set of sequential pages. If successful, a GameSessionQueue object is returned for each requested queue. When specifying a list of queues, objects are returned only for queues that currently exist in the Region. Learn more View Your Queues Related operations CreateGameSessionQueue DescribeGameSessionQueues UpdateGameSessionQueue DeleteGameSessionQueue"},{"ref":"AWS.GameLift.html#describe_game_sessions/3","title":"AWS.GameLift.describe_game_sessions/3","type":"function","doc":"Retrieves a set of one or more game sessions. Request a specific game session or request all game sessions on a fleet. Alternatively, use SearchGameSessions to request a set of active game sessions that are filtered by certain criteria. To retrieve protection policy settings for game sessions, use DescribeGameSessionDetails. To get game sessions, specify one of the following: game session ID, fleet ID, or alias ID. You can filter this request by game session status. Use the pagination parameters to retrieve results as a set of sequential pages. If successful, a GameSession object is returned for each game session matching the request. Available in Amazon GameLift Local. CreateGameSession DescribeGameSessions DescribeGameSessionDetails SearchGameSessions UpdateGameSession GetGameSessionLogUrl Game session placements StartGameSessionPlacement DescribeGameSessionPlacement StopGameSessionPlacement"},{"ref":"AWS.GameLift.html#describe_instances/3","title":"AWS.GameLift.describe_instances/3","type":"function","doc":"Retrieves information about a fleet&#39;s instances, including instance IDs. Use this operation to get details on all instances in the fleet or get details on one specific instance. To get a specific instance, specify fleet ID and instance ID. To get all instances in a fleet, specify a fleet ID only. Use the pagination parameters to retrieve results as a set of sequential pages. If successful, an Instance object is returned for each result. Learn more Remotely Access Fleet Instances Debug Fleet Issues Related operations DescribeInstances GetInstanceAccess"},{"ref":"AWS.GameLift.html#describe_matchmaking/3","title":"AWS.GameLift.describe_matchmaking/3","type":"function","doc":"Retrieves one or more matchmaking tickets. Use this operation to retrieve ticket information, including--after a successful match is made--connection information for the resulting new game session. To request matchmaking tickets, provide a list of up to 10 ticket IDs. If the request is successful, a ticket object is returned for each requested ID that currently exists. This operation is not designed to be continually called to track matchmaking ticket status. This practice can cause you to exceed your API limit, which results in errors. Instead, as a best practice, set up an Amazon Simple Notification Service (SNS) to receive notifications, and provide the topic ARN in the matchmaking configuration. Continuously poling ticket status with DescribeMatchmaking should only be used for games in development with low matchmaking usage. Learn more Add FlexMatch to a Game Client Set Up FlexMatch Event Notification Related operations StartMatchmaking DescribeMatchmaking StopMatchmaking AcceptMatch StartMatchBackfill"},{"ref":"AWS.GameLift.html#describe_matchmaking_configurations/3","title":"AWS.GameLift.describe_matchmaking_configurations/3","type":"function","doc":"Retrieves the details of FlexMatch matchmaking configurations. This operation offers the following options: (1) retrieve all matchmaking configurations, (2) retrieve configurations for a specified list, or (3) retrieve all configurations that use a specified rule set name. When requesting multiple items, use the pagination parameters to retrieve results as a set of sequential pages. If successful, a configuration is returned for each requested name. When specifying a list of names, only configurations that currently exist are returned. Learn more Setting Up FlexMatch Matchmakers Related operations CreateMatchmakingConfiguration DescribeMatchmakingConfigurations UpdateMatchmakingConfiguration DeleteMatchmakingConfiguration CreateMatchmakingRuleSet DescribeMatchmakingRuleSets ValidateMatchmakingRuleSet DeleteMatchmakingRuleSet"},{"ref":"AWS.GameLift.html#describe_matchmaking_rule_sets/3","title":"AWS.GameLift.describe_matchmaking_rule_sets/3","type":"function","doc":"Retrieves the details for FlexMatch matchmaking rule sets. You can request all existing rule sets for the Region, or provide a list of one or more rule set names. When requesting multiple items, use the pagination parameters to retrieve results as a set of sequential pages. If successful, a rule set is returned for each requested name. Learn more Build a Rule Set Related operations CreateMatchmakingConfiguration DescribeMatchmakingConfigurations UpdateMatchmakingConfiguration DeleteMatchmakingConfiguration CreateMatchmakingRuleSet DescribeMatchmakingRuleSets ValidateMatchmakingRuleSet DeleteMatchmakingRuleSet"},{"ref":"AWS.GameLift.html#describe_player_sessions/3","title":"AWS.GameLift.describe_player_sessions/3","type":"function","doc":"Retrieves properties for one or more player sessions. This operation can be used in several ways: (1) provide a PlayerSessionId to request properties for a specific player session; (2) provide a GameSessionId to request properties for all player sessions in the specified game session; (3) provide a PlayerId to request properties for all player sessions of a specified player. To get game session record(s), specify only one of the following: a player session ID, a game session ID, or a player ID. You can filter this request by player session status. Use the pagination parameters to retrieve results as a set of sequential pages. If successful, a PlayerSession object is returned for each session matching the request. Available in Amazon GameLift Local. CreatePlayerSession CreatePlayerSessions DescribePlayerSessions Game session placements StartGameSessionPlacement DescribeGameSessionPlacement StopGameSessionPlacement"},{"ref":"AWS.GameLift.html#describe_runtime_configuration/3","title":"AWS.GameLift.describe_runtime_configuration/3","type":"function","doc":"Retrieves a fleet&#39;s runtime configuration settings. The runtime configuration tells Amazon GameLift which server processes to run (and how) on each instance in the fleet. To get a runtime configuration, specify the fleet&#39;s unique identifier. If successful, a RuntimeConfiguration object is returned for the requested fleet. If the requested fleet has been deleted, the result set is empty. Learn more Setting up GameLift Fleets Running Multiple Processes on a Fleet Related operations CreateFleet ListFleets DeleteFleet Describe fleets: DescribeFleetAttributes DescribeFleetCapacity DescribeFleetPortSettings DescribeFleetUtilization DescribeRuntimeConfiguration DescribeEC2InstanceLimits DescribeFleetEvents UpdateFleetAttributes StartFleetActions or StopFleetActions"},{"ref":"AWS.GameLift.html#describe_scaling_policies/3","title":"AWS.GameLift.describe_scaling_policies/3","type":"function","doc":"Retrieves all scaling policies applied to a fleet. To get a fleet&#39;s scaling policies, specify the fleet ID. You can filter this request by policy status, such as to retrieve only active scaling policies. Use the pagination parameters to retrieve results as a set of sequential pages. If successful, set of ScalingPolicy objects is returned for the fleet. A fleet may have all of its scaling policies suspended (StopFleetActions). This operation does not affect the status of the scaling policies, which remains ACTIVE. To see whether a fleet&#39;s scaling policies are in force or suspended, call DescribeFleetAttributes and check the stopped actions. DescribeFleetCapacity UpdateFleetCapacity DescribeEC2InstanceLimits Manage scaling policies: PutScalingPolicy (auto-scaling) DescribeScalingPolicies (auto-scaling) DeleteScalingPolicy (auto-scaling) Manage fleet actions: StartFleetActions StopFleetActions"},{"ref":"AWS.GameLift.html#describe_script/3","title":"AWS.GameLift.describe_script/3","type":"function","doc":"Retrieves properties for a Realtime script. To request a script record, specify the script ID. If successful, an object containing the script properties is returned. Learn more Amazon GameLift Realtime Servers Related operations CreateScript ListScripts DescribeScript UpdateScript DeleteScript"},{"ref":"AWS.GameLift.html#describe_vpc_peering_authorizations/3","title":"AWS.GameLift.describe_vpc_peering_authorizations/3","type":"function","doc":"Retrieves valid VPC peering authorizations that are pending for the AWS account. This operation returns all VPC peering authorizations and requests for peering. This includes those initiated and received by this account. CreateVpcPeeringAuthorization DescribeVpcPeeringAuthorizations DeleteVpcPeeringAuthorization CreateVpcPeeringConnection DescribeVpcPeeringConnections DeleteVpcPeeringConnection"},{"ref":"AWS.GameLift.html#describe_vpc_peering_connections/3","title":"AWS.GameLift.describe_vpc_peering_connections/3","type":"function","doc":"Retrieves information on VPC peering connections. Use this operation to get peering information for all fleets or for one specific fleet ID. To retrieve connection information, call this operation from the AWS account that is used to manage the Amazon GameLift fleets. Specify a fleet ID or leave the parameter empty to retrieve all connection records. If successful, the retrieved information includes both active and pending connections. Active connections identify the IpV4 CIDR block that the VPC uses to connect. CreateVpcPeeringAuthorization DescribeVpcPeeringAuthorizations DeleteVpcPeeringAuthorization CreateVpcPeeringConnection DescribeVpcPeeringConnections DeleteVpcPeeringConnection"},{"ref":"AWS.GameLift.html#get_game_session_log_url/3","title":"AWS.GameLift.get_game_session_log_url/3","type":"function","doc":"Retrieves the location of stored game session logs for a specified game session. When a game session is terminated, Amazon GameLift automatically stores the logs in Amazon S3 and retains them for 14 days. Use this URL to download the logs. See the AWS Service Limits page for maximum log file sizes. Log files that exceed this limit are not saved. CreateGameSession DescribeGameSessions DescribeGameSessionDetails SearchGameSessions UpdateGameSession GetGameSessionLogUrl Game session placements StartGameSessionPlacement DescribeGameSessionPlacement StopGameSessionPlacement"},{"ref":"AWS.GameLift.html#get_instance_access/3","title":"AWS.GameLift.get_instance_access/3","type":"function","doc":"Requests remote access to a fleet instance. Remote access is useful for debugging, gathering benchmarking data, or observing activity in real time. To remotely access an instance, you need credentials that match the operating system of the instance. For a Windows instance, Amazon GameLift returns a user name and password as strings for use with a Windows Remote Desktop client. For a Linux instance, Amazon GameLift returns a user name and RSA private key, also as strings, for use with an SSH client. The private key must be saved in the proper format to a .pem file before using. If you&#39;re making this request using the AWS CLI, saving the secret can be handled as part of the GetInstanceAccess request, as shown in one of the examples for this operation. To request access to a specific instance, specify the IDs of both the instance and the fleet it belongs to. You can retrieve a fleet&#39;s instance IDs by calling DescribeInstances. If successful, an InstanceAccess object is returned that contains the instance&#39;s IP address and a set of credentials. Learn more Remotely Access Fleet Instances Debug Fleet Issues Related operations DescribeInstances GetInstanceAccess"},{"ref":"AWS.GameLift.html#list_aliases/3","title":"AWS.GameLift.list_aliases/3","type":"function","doc":"Retrieves all aliases for this AWS account. You can filter the result set by alias name and/or routing strategy type. Use the pagination parameters to retrieve results in sequential pages. Returned aliases are not listed in any particular order. CreateAlias ListAliases DescribeAlias UpdateAlias DeleteAlias ResolveAlias"},{"ref":"AWS.GameLift.html#list_builds/3","title":"AWS.GameLift.list_builds/3","type":"function","doc":"Retrieves build resources for all builds associated with the AWS account in use. You can limit results to builds that are in a specific status by using the Status parameter. Use the pagination parameters to retrieve results in a set of sequential pages. Build resources are not listed in any particular order. Learn more Upload a Custom Server Build Related operations CreateBuild ListBuilds DescribeBuild UpdateBuild DeleteBuild"},{"ref":"AWS.GameLift.html#list_fleets/3","title":"AWS.GameLift.list_fleets/3","type":"function","doc":"Retrieves a collection of fleet resources for this AWS account. You can filter the result set to find only those fleets that are deployed with a specific build or script. Use the pagination parameters to retrieve results in sequential pages. Fleet resources are not listed in a particular order. Learn more Setting up GameLift Fleets Related operations CreateFleet ListFleets DeleteFleet DescribeFleetAttributes UpdateFleetAttributes StartFleetActions or StopFleetActions"},{"ref":"AWS.GameLift.html#list_game_server_groups/3","title":"AWS.GameLift.list_game_server_groups/3","type":"function","doc":"This operation is used with the Amazon GameLift FleetIQ solution and game server groups. Retrieves information on all game servers groups that exist in the current AWS account for the selected Region. Use the pagination parameters to retrieve results in a set of sequential segments. Learn more GameLift FleetIQ Guide Related operations CreateGameServerGroup ListGameServerGroups DescribeGameServerGroup UpdateGameServerGroup DeleteGameServerGroup ResumeGameServerGroup SuspendGameServerGroup DescribeGameServerInstances"},{"ref":"AWS.GameLift.html#list_game_servers/3","title":"AWS.GameLift.list_game_servers/3","type":"function","doc":"This operation is used with the Amazon GameLift FleetIQ solution and game server groups. Retrieves information on all game servers that are currently active in a specified game server group. You can opt to sort the list by game server age. Use the pagination parameters to retrieve results in a set of sequential segments. Learn more GameLift FleetIQ Guide Related operations RegisterGameServer ListGameServers ClaimGameServer DescribeGameServer UpdateGameServer DeregisterGameServer"},{"ref":"AWS.GameLift.html#list_scripts/3","title":"AWS.GameLift.list_scripts/3","type":"function","doc":"Retrieves script records for all Realtime scripts that are associated with the AWS account in use. Learn more Amazon GameLift Realtime Servers Related operations CreateScript ListScripts DescribeScript UpdateScript DeleteScript"},{"ref":"AWS.GameLift.html#list_tags_for_resource/3","title":"AWS.GameLift.list_tags_for_resource/3","type":"function","doc":"Retrieves all tags that are assigned to a GameLift resource. Resource tags are used to organize AWS resources for a range of purposes. This operation handles the permissions necessary to manage tags for the following GameLift resource types: Build Script Fleet Alias GameSessionQueue MatchmakingConfiguration MatchmakingRuleSet To list tags for a resource, specify the unique ARN value for the resource. Learn more Tagging AWS Resources in the AWS General Reference AWS Tagging Strategies Related operations TagResource UntagResource ListTagsForResource"},{"ref":"AWS.GameLift.html#put_scaling_policy/3","title":"AWS.GameLift.put_scaling_policy/3","type":"function","doc":"Creates or updates a scaling policy for a fleet. Scaling policies are used to automatically scale a fleet&#39;s hosting capacity to meet player demand. An active scaling policy instructs Amazon GameLift to track a fleet metric and automatically change the fleet&#39;s capacity when a certain threshold is reached. There are two types of scaling policies: target-based and rule-based. Use a target-based policy to quickly and efficiently manage fleet scaling; this option is the most commonly used. Use rule-based policies when you need to exert fine-grained control over auto-scaling. Fleets can have multiple scaling policies of each type in force at the same time; you can have one target-based policy, one or multiple rule-based scaling policies, or both. We recommend caution, however, because multiple auto-scaling policies can have unintended consequences. You can temporarily suspend all scaling policies for a fleet by calling StopFleetActions with the fleet action AUTO_SCALING. To resume scaling policies, call StartFleetActions with the same fleet action. To stop just one scaling policy--or to permanently remove it, you must delete the policy with DeleteScalingPolicy. Learn more about how to work with auto-scaling in Set Up Fleet Automatic Scaling. Target-based policy A target-based policy tracks a single metric: PercentAvailableGameSessions. This metric tells us how much of a fleet&#39;s hosting capacity is ready to host game sessions but is not currently in use. This is the fleet&#39;s buffer; it measures the additional player demand that the fleet could handle at current capacity. With a target-based policy, you set your ideal buffer size and leave it to Amazon GameLift to take whatever action is needed to maintain that target. For example, you might choose to maintain a 10% buffer for a fleet that has the capacity to host 100 simultaneous game sessions. This policy tells Amazon GameLift to take action whenever the fleet&#39;s available capacity falls below or rises above 10 game sessions. Amazon GameLift will start new instances or stop unused instances in order to return to the 10% buffer. To create or update a target-based policy, specify a fleet ID and name, and set the policy type to &quot;TargetBased&quot;. Specify the metric to track (PercentAvailableGameSessions) and reference a TargetConfiguration object with your desired buffer value. Exclude all other parameters. On a successful request, the policy name is returned. The scaling policy is automatically in force as soon as it&#39;s successfully created. If the fleet&#39;s auto-scaling actions are temporarily suspended, the new policy will be in force once the fleet actions are restarted. Rule-based policy A rule-based policy tracks specified fleet metric, sets a threshold value, and specifies the type of action to initiate when triggered. With a rule-based policy, you can select from several available fleet metrics. Each policy specifies whether to scale up or scale down (and by how much), so you need one policy for each type of action. For example, a policy may make the following statement: &quot;If the percentage of idle instances is greater than 20% for more than 15 minutes, then reduce the fleet capacity by 10%.&quot; A policy&#39;s rule statement has the following structure: If [MetricName] is [ComparisonOperator] [Threshold] for [EvaluationPeriods] minutes, then [ScalingAdjustmentType] to/by [ScalingAdjustment]. To implement the example, the rule statement would look like this: If [PercentIdleInstances] is [GreaterThanThreshold] [20] for [15] minutes, then [PercentChangeInCapacity] to/by [10]. To create or update a scaling policy, specify a unique combination of name and fleet ID, and set the policy type to &quot;RuleBased&quot;. Specify the parameter values for a policy rule statement. On a successful request, the policy name is returned. Scaling policies are automatically in force as soon as they&#39;re successfully created. If the fleet&#39;s auto-scaling actions are temporarily suspended, the new policy will be in force once the fleet actions are restarted. DescribeFleetCapacity UpdateFleetCapacity DescribeEC2InstanceLimits Manage scaling policies: PutScalingPolicy (auto-scaling) DescribeScalingPolicies (auto-scaling) DeleteScalingPolicy (auto-scaling) Manage fleet actions: StartFleetActions StopFleetActions"},{"ref":"AWS.GameLift.html#register_game_server/3","title":"AWS.GameLift.register_game_server/3","type":"function","doc":"This operation is used with the Amazon GameLift FleetIQ solution and game server groups. Creates a new game server resource and notifies GameLift FleetIQ that the game server is ready to host gameplay and players. This operation is called by a game server process that is running on an instance in a game server group. Registering game servers enables GameLift FleetIQ to track available game servers and enables game clients and services to claim a game server for a new game session. To register a game server, identify the game server group and instance where the game server is running, and provide a unique identifier for the game server. You can also include connection and game server data. When a game client or service requests a game server by calling ClaimGameServer, this information is returned in the response. Once a game server is successfully registered, it is put in status AVAILABLE. A request to register a game server may fail if the instance it is running on is in the process of shutting down as part of instance balancing or scale-down activity. Learn more GameLift FleetIQ Guide Related operations RegisterGameServer ListGameServers ClaimGameServer DescribeGameServer UpdateGameServer DeregisterGameServer"},{"ref":"AWS.GameLift.html#request_upload_credentials/3","title":"AWS.GameLift.request_upload_credentials/3","type":"function","doc":"Retrieves a fresh set of credentials for use when uploading a new set of game build files to Amazon GameLift&#39;s Amazon S3. This is done as part of the build creation process; see CreateBuild. To request new credentials, specify the build ID as returned with an initial CreateBuild request. If successful, a new set of credentials are returned, along with the S3 storage location associated with the build ID. Learn more Create a Build with Files in S3 Related operations CreateBuild ListBuilds DescribeBuild UpdateBuild DeleteBuild"},{"ref":"AWS.GameLift.html#resolve_alias/3","title":"AWS.GameLift.resolve_alias/3","type":"function","doc":"Retrieves the fleet ID that an alias is currently pointing to. CreateAlias ListAliases DescribeAlias UpdateAlias DeleteAlias ResolveAlias"},{"ref":"AWS.GameLift.html#resume_game_server_group/3","title":"AWS.GameLift.resume_game_server_group/3","type":"function","doc":"This operation is used with the Amazon GameLift FleetIQ solution and game server groups. Reinstates activity on a game server group after it has been suspended. A game server group might be suspended by theSuspendGameServerGroup operation, or it might be suspended involuntarily due to a configuration problem. In the second case, you can manually resume activity on the group once the configuration problem has been resolved. Refer to the game server group status and status reason for more information on why group activity is suspended. To resume activity, specify a game server group ARN and the type of activity to be resumed. If successful, a GameServerGroup object is returned showing that the resumed activity is no longer listed in SuspendedActions. Learn more GameLift FleetIQ Guide Related operations CreateGameServerGroup ListGameServerGroups DescribeGameServerGroup UpdateGameServerGroup DeleteGameServerGroup ResumeGameServerGroup SuspendGameServerGroup DescribeGameServerInstances"},{"ref":"AWS.GameLift.html#search_game_sessions/3","title":"AWS.GameLift.search_game_sessions/3","type":"function","doc":"Retrieves all active game sessions that match a set of search criteria and sorts them in a specified order. You can search or sort by the following game session attributes: gameSessionId -- A unique identifier for the game session. You can use either a GameSessionId or GameSessionArn value. gameSessionName -- Name assigned to a game session. This value is set when requesting a new game session with CreateGameSession or updating with UpdateGameSession. Game session names do not need to be unique to a game session. gameSessionProperties -- Custom data defined in a game session&#39;s GameProperty parameter. GameProperty values are stored as key:value pairs; the filter expression must indicate the key and a string to search the data values for. For example, to search for game sessions with custom data containing the key:value pair &quot;gameMode:brawl&quot;, specify the following: gameSessionProperties.gameMode = &quot;brawl&quot;. All custom data values are searched as strings. maximumSessions -- Maximum number of player sessions allowed for a game session. This value is set when requesting a new game session with CreateGameSession or updating with UpdateGameSession. creationTimeMillis -- Value indicating when a game session was created. It is expressed in Unix time as milliseconds. playerSessionCount -- Number of players currently connected to a game session. This value changes rapidly as players join the session or drop out. hasAvailablePlayerSessions -- Boolean value indicating whether a game session has reached its maximum number of players. It is highly recommended that all search requests include this filter attribute to optimize search performance and return only sessions that players can join. Returned values for playerSessionCount and hasAvailablePlayerSessions change quickly as players join sessions and others drop out. Results should be considered a snapshot in time. Be sure to refresh search results often, and handle sessions that fill up before a player can join. To search or sort, specify either a fleet ID or an alias ID, and provide a search filter expression, a sort expression, or both. If successful, a collection of GameSession objects matching the request is returned. Use the pagination parameters to retrieve results as a set of sequential pages. You can search for game sessions one fleet at a time only. To find game sessions across multiple fleets, you must search each fleet separately and combine the results. This search feature finds only game sessions that are in ACTIVE status. To locate games in statuses other than active, use DescribeGameSessionDetails. CreateGameSession DescribeGameSessions DescribeGameSessionDetails SearchGameSessions UpdateGameSession GetGameSessionLogUrl Game session placements StartGameSessionPlacement DescribeGameSessionPlacement StopGameSessionPlacement"},{"ref":"AWS.GameLift.html#start_fleet_actions/3","title":"AWS.GameLift.start_fleet_actions/3","type":"function","doc":"Resumes activity on a fleet that was suspended with StopFleetActions. Currently, this operation is used to restart a fleet&#39;s auto-scaling activity. To start fleet actions, specify the fleet ID and the type of actions to restart. When auto-scaling fleet actions are restarted, Amazon GameLift once again initiates scaling events as triggered by the fleet&#39;s scaling policies. If actions on the fleet were never stopped, this operation will have no effect. You can view a fleet&#39;s stopped actions using DescribeFleetAttributes. Learn more Setting up GameLift Fleets Related operations CreateFleet ListFleets DeleteFleet DescribeFleetAttributes UpdateFleetAttributes StartFleetActions or StopFleetActions"},{"ref":"AWS.GameLift.html#start_game_session_placement/3","title":"AWS.GameLift.start_game_session_placement/3","type":"function","doc":"Places a request for a new game session in a queue (see CreateGameSessionQueue). When processing a placement request, Amazon GameLift searches for available resources on the queue&#39;s destinations, scanning each until it finds resources or the placement request times out. A game session placement request can also request player sessions. When a new game session is successfully created, Amazon GameLift creates a player session for each player included in the request. When placing a game session, by default Amazon GameLift tries each fleet in the order they are listed in the queue configuration. Ideally, a queue&#39;s destinations are listed in preference order. Alternatively, when requesting a game session with players, you can also provide latency data for each player in relevant Regions. Latency data indicates the performance lag a player experiences when connected to a fleet in the Region. Amazon GameLift uses latency data to reorder the list of destinations to place the game session in a Region with minimal lag. If latency data is provided for multiple players, Amazon GameLift calculates each Region&#39;s average lag for all players and reorders to get the best game play across all players. To place a new game session request, specify the following: The queue name and a set of game session properties and settings A unique ID (such as a UUID) for the placement. You use this ID to track the status of the placement request (Optional) A set of player data and a unique player ID for each player that you are joining to the new game session (player data is optional, but if you include it, you must also provide a unique ID for each player) Latency data for all players (if you want to optimize game play for the players) If successful, a new game session placement is created. To track the status of a placement request, call DescribeGameSessionPlacement and check the request&#39;s status. If the status is FULFILLED, a new game session has been created and a game session ARN and Region are referenced. If the placement request times out, you can resubmit the request or retry it with a different queue. CreateGameSession DescribeGameSessions DescribeGameSessionDetails SearchGameSessions UpdateGameSession GetGameSessionLogUrl Game session placements StartGameSessionPlacement DescribeGameSessionPlacement StopGameSessionPlacement"},{"ref":"AWS.GameLift.html#start_match_backfill/3","title":"AWS.GameLift.start_match_backfill/3","type":"function","doc":"Finds new players to fill open slots in an existing game session. This operation can be used to add players to matched games that start with fewer than the maximum number of players or to replace players when they drop out. By backfilling with the same matchmaker used to create the original match, you ensure that new players meet the match criteria and maintain a consistent experience throughout the game session. You can backfill a match anytime after a game session has been created. To request a match backfill, specify a unique ticket ID, the existing game session&#39;s ARN, a matchmaking configuration, and a set of data that describes all current players in the game session. If successful, a match backfill ticket is created and returned with status set to QUEUED. The ticket is placed in the matchmaker&#39;s ticket pool and processed. Track the status of the ticket to respond as needed. The process of finding backfill matches is essentially identical to the initial matchmaking process. The matchmaker searches the pool and groups tickets together to form potential matches, allowing only one backfill ticket per potential match. Once the a match is formed, the matchmaker creates player sessions for the new players. All tickets in the match are updated with the game session&#39;s connection information, and the GameSession object is updated to include matchmaker data on the new players. For more detail on how match backfill requests are processed, see How Amazon GameLift FlexMatch Works. Learn more Backfill Existing Games with FlexMatch How GameLift FlexMatch Works Related operations StartMatchmaking DescribeMatchmaking StopMatchmaking AcceptMatch StartMatchBackfill"},{"ref":"AWS.GameLift.html#start_matchmaking/3","title":"AWS.GameLift.start_matchmaking/3","type":"function","doc":"Uses FlexMatch to create a game match for a group of players based on custom matchmaking rules, and starts a new game for the matched players. Each matchmaking request specifies the type of match to build (team configuration, rules for an acceptable match, etc.). The request also specifies the players to find a match for and where to host the new game session for optimal performance. A matchmaking request might start with a single player or a group of players who want to play together. FlexMatch finds additional players as needed to fill the match. Match type, rules, and the queue used to place a new game session are defined in a MatchmakingConfiguration. To start matchmaking, provide a unique ticket ID, specify a matchmaking configuration, and include the players to be matched. You must also include a set of player attributes relevant for the matchmaking configuration. If successful, a matchmaking ticket is returned with status set to QUEUED. Track the status of the ticket to respond as needed and acquire game session connection information for successfully completed matches. Ticket status updates are tracked using event notification through Amazon Simple Notification Service (SNS), which is defined in the matchmaking configuration. Processing a matchmaking request -- FlexMatch handles a matchmaking request as follows: Your client code submits a StartMatchmaking request for one or more players and tracks the status of the request ticket. FlexMatch uses this ticket and others in process to build an acceptable match. When a potential match is identified, all tickets in the proposed match are advanced to the next status. If the match requires player acceptance (set in the matchmaking configuration), the tickets move into status REQUIRES_ACCEPTANCE. This status triggers your client code to solicit acceptance from all players in every ticket involved in the match, and then call AcceptMatch for each player. If any player rejects or fails to accept the match before a specified timeout, the proposed match is dropped (see AcceptMatch for more details). Once a match is proposed and accepted, the matchmaking tickets move into status PLACING. FlexMatch locates resources for a new game session using the game session queue (set in the matchmaking configuration) and creates the game session based on the match data. When the match is successfully placed, the matchmaking tickets move into COMPLETED status. Connection information (including game session endpoint and player session) is added to the matchmaking tickets. Matched players can use the connection information to join the game. Learn more Add FlexMatch to a Game Client Set Up FlexMatch Event Notification FlexMatch Integration Roadmap How GameLift FlexMatch Works Related operations StartMatchmaking DescribeMatchmaking StopMatchmaking AcceptMatch StartMatchBackfill"},{"ref":"AWS.GameLift.html#stop_fleet_actions/3","title":"AWS.GameLift.stop_fleet_actions/3","type":"function","doc":"Suspends activity on a fleet. Currently, this operation is used to stop a fleet&#39;s auto-scaling activity. It is used to temporarily stop triggering scaling events. The policies can be retained and auto-scaling activity can be restarted using StartFleetActions. You can view a fleet&#39;s stopped actions using DescribeFleetAttributes. To stop fleet actions, specify the fleet ID and the type of actions to suspend. When auto-scaling fleet actions are stopped, Amazon GameLift no longer initiates scaling events except in response to manual changes using UpdateFleetCapacity. Learn more Setting up GameLift Fleets Related operations CreateFleet ListFleets DeleteFleet DescribeFleetAttributes UpdateFleetAttributes StartFleetActions or StopFleetActions"},{"ref":"AWS.GameLift.html#stop_game_session_placement/3","title":"AWS.GameLift.stop_game_session_placement/3","type":"function","doc":"Cancels a game session placement that is in PENDING status. To stop a placement, provide the placement ID values. If successful, the placement is moved to CANCELLED status. CreateGameSession DescribeGameSessions DescribeGameSessionDetails SearchGameSessions UpdateGameSession GetGameSessionLogUrl Game session placements StartGameSessionPlacement DescribeGameSessionPlacement StopGameSessionPlacement"},{"ref":"AWS.GameLift.html#stop_matchmaking/3","title":"AWS.GameLift.stop_matchmaking/3","type":"function","doc":"Cancels a matchmaking ticket or match backfill ticket that is currently being processed. To stop the matchmaking operation, specify the ticket ID. If successful, work on the ticket is stopped, and the ticket status is changed to CANCELLED. This call is also used to turn off automatic backfill for an individual game session. This is for game sessions that are created with a matchmaking configuration that has automatic backfill enabled. The ticket ID is included in the MatchmakerData of an updated game session object, which is provided to the game server. If the operation is successful, the service sends back an empty JSON struct with the HTTP 200 response (not an empty HTTP body). Learn more Add FlexMatch to a Game Client Related operations StartMatchmaking DescribeMatchmaking StopMatchmaking AcceptMatch StartMatchBackfill"},{"ref":"AWS.GameLift.html#suspend_game_server_group/3","title":"AWS.GameLift.suspend_game_server_group/3","type":"function","doc":"This operation is used with the Amazon GameLift FleetIQ solution and game server groups. Temporarily stops activity on a game server group without terminating instances or the game server group. You can restart activity by calling ResumeGameServerGroup. You can suspend the following activity: Instance type replacement - This activity evaluates the current game hosting viability of all Spot instance types that are defined for the game server group. It updates the Auto Scaling group to remove nonviable Spot Instance types, which have a higher chance of game server interruptions. It then balances capacity across the remaining viable Spot Instance types. When this activity is suspended, the Auto Scaling group continues with its current balance, regardless of viability. Instance protection, utilization metrics, and capacity scaling activities continue to be active. To suspend activity, specify a game server group ARN and the type of activity to be suspended. If successful, a GameServerGroup object is returned showing that the activity is listed in SuspendedActions. Learn more GameLift FleetIQ Guide Related operations CreateGameServerGroup ListGameServerGroups DescribeGameServerGroup UpdateGameServerGroup DeleteGameServerGroup ResumeGameServerGroup SuspendGameServerGroup DescribeGameServerInstances"},{"ref":"AWS.GameLift.html#tag_resource/3","title":"AWS.GameLift.tag_resource/3","type":"function","doc":"Assigns a tag to a GameLift resource. AWS resource tags provide an additional management tool set. You can use tags to organize resources, create IAM permissions policies to manage access to groups of resources, customize AWS cost breakdowns, etc. This operation handles the permissions necessary to manage tags for the following GameLift resource types: Build Script Fleet Alias GameSessionQueue MatchmakingConfiguration MatchmakingRuleSet To add a tag to a resource, specify the unique ARN value for the resource and provide a tag list containing one or more tags. The operation succeeds even if the list includes tags that are already assigned to the specified resource. Learn more Tagging AWS Resources in the AWS General Reference AWS Tagging Strategies Related operations TagResource UntagResource ListTagsForResource"},{"ref":"AWS.GameLift.html#untag_resource/3","title":"AWS.GameLift.untag_resource/3","type":"function","doc":"Removes a tag that is assigned to a GameLift resource. Resource tags are used to organize AWS resources for a range of purposes. This operation handles the permissions necessary to manage tags for the following GameLift resource types: Build Script Fleet Alias GameSessionQueue MatchmakingConfiguration MatchmakingRuleSet To remove a tag from a resource, specify the unique ARN value for the resource and provide a string list containing one or more tags to be removed. This operation succeeds even if the list includes tags that are not currently assigned to the specified resource. Learn more Tagging AWS Resources in the AWS General Reference AWS Tagging Strategies Related operations TagResource UntagResource ListTagsForResource"},{"ref":"AWS.GameLift.html#update_alias/3","title":"AWS.GameLift.update_alias/3","type":"function","doc":"Updates properties for an alias. To update properties, specify the alias ID to be updated and provide the information to be changed. To reassign an alias to another fleet, provide an updated routing strategy. If successful, the updated alias record is returned. CreateAlias ListAliases DescribeAlias UpdateAlias DeleteAlias ResolveAlias"},{"ref":"AWS.GameLift.html#update_build/3","title":"AWS.GameLift.update_build/3","type":"function","doc":"Updates metadata in a build resource, including the build name and version. To update the metadata, specify the build ID to update and provide the new values. If successful, a build object containing the updated metadata is returned. Learn more Upload a Custom Server Build Related operations CreateBuild ListBuilds DescribeBuild UpdateBuild DeleteBuild"},{"ref":"AWS.GameLift.html#update_fleet_attributes/3","title":"AWS.GameLift.update_fleet_attributes/3","type":"function","doc":"Updates fleet properties, including name and description, for a fleet. To update metadata, specify the fleet ID and the property values that you want to change. If successful, the fleet ID for the updated fleet is returned. Learn more Setting up GameLift Fleets Related operations CreateFleet ListFleets DeleteFleet DescribeFleetAttributes Update fleets: UpdateFleetAttributes UpdateFleetCapacity UpdateFleetPortSettings UpdateRuntimeConfiguration StartFleetActions or StopFleetActions"},{"ref":"AWS.GameLift.html#update_fleet_capacity/3","title":"AWS.GameLift.update_fleet_capacity/3","type":"function","doc":"Updates capacity settings for a fleet. Use this operation to specify the number of EC2 instances (hosts) that you want this fleet to contain. Before calling this operation, you may want to call DescribeEC2InstanceLimits to get the maximum capacity based on the fleet&#39;s EC2 instance type. Specify minimum and maximum number of instances. Amazon GameLift will not change fleet capacity to values fall outside of this range. This is particularly important when using auto-scaling (see PutScalingPolicy) to allow capacity to adjust based on player demand while imposing limits on automatic adjustments. To update fleet capacity, specify the fleet ID and the number of instances you want the fleet to host. If successful, Amazon GameLift starts or terminates instances so that the fleet&#39;s active instance count matches the desired instance count. You can view a fleet&#39;s current capacity information by calling DescribeFleetCapacity. If the desired instance count is higher than the instance type&#39;s limit, the &quot;Limit Exceeded&quot; exception occurs. Learn more Setting up GameLift Fleets Related operations CreateFleet ListFleets DeleteFleet DescribeFleetAttributes Update fleets: UpdateFleetAttributes UpdateFleetCapacity UpdateFleetPortSettings UpdateRuntimeConfiguration StartFleetActions or StopFleetActions"},{"ref":"AWS.GameLift.html#update_fleet_port_settings/3","title":"AWS.GameLift.update_fleet_port_settings/3","type":"function","doc":"Updates port settings for a fleet. To update settings, specify the fleet ID to be updated and list the permissions you want to update. List the permissions you want to add in InboundPermissionAuthorizations, and permissions you want to remove in InboundPermissionRevocations. Permissions to be removed must match existing fleet permissions. If successful, the fleet ID for the updated fleet is returned. Learn more Setting up GameLift Fleets Related operations CreateFleet ListFleets DeleteFleet DescribeFleetAttributes Update fleets: UpdateFleetAttributes UpdateFleetCapacity UpdateFleetPortSettings UpdateRuntimeConfiguration StartFleetActions or StopFleetActions"},{"ref":"AWS.GameLift.html#update_game_server/3","title":"AWS.GameLift.update_game_server/3","type":"function","doc":"This operation is used with the Amazon GameLift FleetIQ solution and game server groups. Updates information about a registered game server to help GameLift FleetIQ to track game server availability. This operation is called by a game server process that is running on an instance in a game server group. Use this operation to update the following types of game server information. You can make all three types of updates in the same request: To update the game server&#39;s utilization status, identify the game server and game server group and specify the current utilization status. Use this status to identify when game servers are currently hosting games and when they are available to be claimed. To report health status, identify the game server and game server group and set health check to HEALTHY. If a game server does not report health status for a certain length of time, the game server is no longer considered healthy. As a result, it will be eventually deregistered from the game server group to avoid affecting utilization metrics. The best practice is to report health every 60 seconds. To change game server metadata, provide updated game server data. Once a game server is successfully updated, the relevant statuses and timestamps are updated. Learn more GameLift FleetIQ Guide Related operations RegisterGameServer ListGameServers ClaimGameServer DescribeGameServer UpdateGameServer DeregisterGameServer"},{"ref":"AWS.GameLift.html#update_game_server_group/3","title":"AWS.GameLift.update_game_server_group/3","type":"function","doc":"This operation is used with the Amazon GameLift FleetIQ solution and game server groups. Updates GameLift FleetIQ-specific properties for a game server group. Many Auto Scaling group properties are updated on the Auto Scaling group directly, including the launch template, Auto Scaling policies, and maximum/minimum/desired instance counts. To update the game server group, specify the game server group ID and provide the updated values. Before applying the updates, the new values are validated to ensure that GameLift FleetIQ can continue to perform instance balancing activity. If successful, a GameServerGroup object is returned. Learn more GameLift FleetIQ Guide Related operations CreateGameServerGroup ListGameServerGroups DescribeGameServerGroup UpdateGameServerGroup DeleteGameServerGroup ResumeGameServerGroup SuspendGameServerGroup DescribeGameServerInstances"},{"ref":"AWS.GameLift.html#update_game_session/3","title":"AWS.GameLift.update_game_session/3","type":"function","doc":"Updates game session properties. This includes the session name, maximum player count, protection policy, which controls whether or not an active game session can be terminated during a scale-down event, and the player session creation policy, which controls whether or not new players can join the session. To update a game session, specify the game session ID and the values you want to change. If successful, an updated GameSession object is returned. CreateGameSession DescribeGameSessions DescribeGameSessionDetails SearchGameSessions UpdateGameSession GetGameSessionLogUrl Game session placements StartGameSessionPlacement DescribeGameSessionPlacement StopGameSessionPlacement"},{"ref":"AWS.GameLift.html#update_game_session_queue/3","title":"AWS.GameLift.update_game_session_queue/3","type":"function","doc":"Updates settings for a game session queue, which determines how new game session requests in the queue are processed. To update settings, specify the queue name to be updated and provide the new settings. When updating destinations, provide a complete list of destinations. Learn more Using Multi-Region Queues Related operations CreateGameSessionQueue DescribeGameSessionQueues UpdateGameSessionQueue DeleteGameSessionQueue"},{"ref":"AWS.GameLift.html#update_matchmaking_configuration/3","title":"AWS.GameLift.update_matchmaking_configuration/3","type":"function","doc":"Updates settings for a FlexMatch matchmaking configuration. These changes affect all matches and game sessions that are created after the update. To update settings, specify the configuration name to be updated and provide the new settings. Learn more Design a FlexMatch Matchmaker Related operations CreateMatchmakingConfiguration DescribeMatchmakingConfigurations UpdateMatchmakingConfiguration DeleteMatchmakingConfiguration CreateMatchmakingRuleSet DescribeMatchmakingRuleSets ValidateMatchmakingRuleSet DeleteMatchmakingRuleSet"},{"ref":"AWS.GameLift.html#update_runtime_configuration/3","title":"AWS.GameLift.update_runtime_configuration/3","type":"function","doc":"Updates the current runtime configuration for the specified fleet, which tells Amazon GameLift how to launch server processes on instances in the fleet. You can update a fleet&#39;s runtime configuration at any time after the fleet is created; it does not need to be in an ACTIVE status. To update runtime configuration, specify the fleet ID and provide a RuntimeConfiguration object with an updated set of server process configurations. Each instance in a Amazon GameLift fleet checks regularly for an updated runtime configuration and changes how it launches server processes to comply with the latest version. Existing server processes are not affected by the update; runtime configuration changes are applied gradually as existing processes shut down and new processes are launched during Amazon GameLift&#39;s normal process recycling activity. Learn more Setting up GameLift Fleets Related operations CreateFleet ListFleets DeleteFleet DescribeFleetAttributes Update fleets: UpdateFleetAttributes UpdateFleetCapacity UpdateFleetPortSettings UpdateRuntimeConfiguration StartFleetActions or StopFleetActions"},{"ref":"AWS.GameLift.html#update_script/3","title":"AWS.GameLift.update_script/3","type":"function","doc":"Updates Realtime script metadata and content. To update script metadata, specify the script ID and provide updated name and/or version values. To update script content, provide an updated zip file by pointing to either a local file or an Amazon S3 bucket location. You can use either method regardless of how the original script was uploaded. Use the Version parameter to track updates to the script. If the call is successful, the updated metadata is stored in the script record and a revised script is uploaded to the Amazon GameLift service. Once the script is updated and acquired by a fleet instance, the new version is used for all new game sessions. Learn more Amazon GameLift Realtime Servers Related operations CreateScript ListScripts DescribeScript UpdateScript DeleteScript"},{"ref":"AWS.GameLift.html#validate_matchmaking_rule_set/3","title":"AWS.GameLift.validate_matchmaking_rule_set/3","type":"function","doc":"Validates the syntax of a matchmaking rule or rule set. This operation checks that the rule set is using syntactically correct JSON and that it conforms to allowed property expressions. To validate syntax, provide a rule set JSON string. Learn more Build a Rule Set Related operations CreateMatchmakingConfiguration DescribeMatchmakingConfigurations UpdateMatchmakingConfiguration DeleteMatchmakingConfiguration CreateMatchmakingRuleSet DescribeMatchmakingRuleSets ValidateMatchmakingRuleSet DeleteMatchmakingRuleSet"},{"ref":"AWS.Glacier.html","title":"AWS.Glacier","type":"module","doc":"Amazon S3 Glacier (Glacier) is a storage solution for &quot;cold data.&quot; Glacier is an extremely low-cost storage service that provides secure, durable, and easy-to-use storage for data backup and archival. With Glacier, customers can store their data cost effectively for months, years, or decades. Glacier also enables customers to offload the administrative burdens of operating and scaling storage to AWS, so they don&#39;t have to worry about capacity planning, hardware provisioning, data replication, hardware failure and recovery, or time-consuming hardware migrations. Glacier is a great storage choice when low storage cost is paramount and your data is rarely retrieved. If your application requires fast or frequent access to your data, consider using Amazon S3. For more information, see Amazon Simple Storage Service (Amazon S3). You can store any kind of data in any format. There is no maximum limit on the total amount of data you can store in Glacier. If you are a first-time user of Glacier, we recommend that you begin by reading the following sections in the Amazon S3 Glacier Developer Guide: What is Amazon S3 Glacier - This section of the Developer Guide describes the underlying data model, the operations it supports, and the AWS SDKs that you can use to interact with the service. Getting Started with Amazon S3 Glacier The Getting Started section walks you through the process of creating a vault, uploading archives, creating jobs to download archives, retrieving the job output, and deleting archives."},{"ref":"AWS.Glacier.html#abort_multipart_upload/6","title":"AWS.Glacier.abort_multipart_upload/6","type":"function","doc":"This operation aborts a multipart upload identified by the upload ID. After the Abort Multipart Upload request succeeds, you cannot upload any more parts to the multipart upload or complete the multipart upload. Aborting a completed upload fails. However, aborting an already-aborted upload will succeed, for a short time. For more information about uploading a part and completing a multipart upload, see UploadMultipartPart and CompleteMultipartUpload. This operation is idempotent. An AWS account has full permission to perform all operations (actions). However, AWS Identity and Access Management (IAM) users don&#39;t have any permissions by default. You must grant them explicit permission to perform specific actions. For more information, see Access Control Using AWS Identity and Access Management (IAM). For conceptual information and underlying REST API, see Working with Archives in Amazon S3 Glacier and Abort Multipart Upload in the Amazon Glacier Developer Guide."},{"ref":"AWS.Glacier.html#abort_vault_lock/5","title":"AWS.Glacier.abort_vault_lock/5","type":"function","doc":"This operation aborts the vault locking process if the vault lock is not in the Locked state. If the vault lock is in the Locked state when this operation is requested, the operation returns an AccessDeniedException error. Aborting the vault locking process removes the vault lock policy from the specified vault. A vault lock is put into the InProgress state by calling InitiateVaultLock. A vault lock is put into the Locked state by calling CompleteVaultLock. You can get the state of a vault lock by calling GetVaultLock. For more information about the vault locking process, see Amazon Glacier Vault Lock. For more information about vault lock policies, see Amazon Glacier Access Control with Vault Lock Policies. This operation is idempotent. You can successfully invoke this operation multiple times, if the vault lock is in the InProgress state or if there is no policy associated with the vault."},{"ref":"AWS.Glacier.html#add_tags_to_vault/5","title":"AWS.Glacier.add_tags_to_vault/5","type":"function","doc":"This operation adds the specified tags to a vault. Each tag is composed of a key and a value. Each vault can have up to 10 tags. If your request would cause the tag limit for the vault to be exceeded, the operation throws the LimitExceededException error. If a tag already exists on the vault under a specified key, the existing key value will be overwritten. For more information about tags, see Tagging Amazon S3 Glacier Resources."},{"ref":"AWS.Glacier.html#complete_multipart_upload/6","title":"AWS.Glacier.complete_multipart_upload/6","type":"function","doc":"You call this operation to inform Amazon S3 Glacier (Glacier) that all the archive parts have been uploaded and that Glacier can now assemble the archive from the uploaded parts. After assembling and saving the archive to the vault, Glacier returns the URI path of the newly created archive resource. Using the URI path, you can then access the archive. After you upload an archive, you should save the archive ID returned to retrieve the archive at a later point. You can also get the vault inventory to obtain a list of archive IDs in a vault. For more information, see InitiateJob. In the request, you must include the computed SHA256 tree hash of the entire archive you have uploaded. For information about computing a SHA256 tree hash, see Computing Checksums. On the server side, Glacier also constructs the SHA256 tree hash of the assembled archive. If the values match, Glacier saves the archive to the vault; otherwise, it returns an error, and the operation fails. The ListParts operation returns a list of parts uploaded for a specific multipart upload. It includes checksum information for each uploaded part that can be used to debug a bad checksum issue. Additionally, Glacier also checks for any missing content ranges when assembling the archive, if missing content ranges are found, Glacier returns an error and the operation fails. Complete Multipart Upload is an idempotent operation. After your first successful complete multipart upload, if you call the operation again within a short period, the operation will succeed and return the same archive ID. This is useful in the event you experience a network issue that causes an aborted connection or receive a 500 server error, in which case you can repeat your Complete Multipart Upload request and get the same archive ID without creating duplicate archives. Note, however, that after the multipart upload completes, you cannot call the List Parts operation and the multipart upload will not appear in List Multipart Uploads response, even if idempotent complete is possible. An AWS account has full permission to perform all operations (actions). However, AWS Identity and Access Management (IAM) users don&#39;t have any permissions by default. You must grant them explicit permission to perform specific actions. For more information, see Access Control Using AWS Identity and Access Management (IAM). For conceptual information and underlying REST API, see Uploading Large Archives in Parts (Multipart Upload) and Complete Multipart Upload in the Amazon Glacier Developer Guide."},{"ref":"AWS.Glacier.html#complete_vault_lock/6","title":"AWS.Glacier.complete_vault_lock/6","type":"function","doc":"This operation completes the vault locking process by transitioning the vault lock from the InProgress state to the Locked state, which causes the vault lock policy to become unchangeable. A vault lock is put into the InProgress state by calling InitiateVaultLock. You can obtain the state of the vault lock by calling GetVaultLock. For more information about the vault locking process, Amazon Glacier Vault Lock. This operation is idempotent. This request is always successful if the vault lock is in the Locked state and the provided lock ID matches the lock ID originally used to lock the vault. If an invalid lock ID is passed in the request when the vault lock is in the Locked state, the operation returns an AccessDeniedException error. If an invalid lock ID is passed in the request when the vault lock is in the InProgress state, the operation throws an InvalidParameter error."},{"ref":"AWS.Glacier.html#create_vault/5","title":"AWS.Glacier.create_vault/5","type":"function","doc":"This operation creates a new vault with the specified name. The name of the vault must be unique within a region for an AWS account. You can create up to 1,000 vaults per account. If you need to create more vaults, contact Amazon S3 Glacier. You must use the following guidelines when naming a vault. Names can be between 1 and 255 characters long. Allowed characters are a-z, A-Z, 0-9, &#39;_&#39; (underscore), &#39;-&#39; (hyphen), and &#39;.&#39; (period). This operation is idempotent. An AWS account has full permission to perform all operations (actions). However, AWS Identity and Access Management (IAM) users don&#39;t have any permissions by default. You must grant them explicit permission to perform specific actions. For more information, see Access Control Using AWS Identity and Access Management (IAM). For conceptual information and underlying REST API, see Creating a Vault in Amazon Glacier and Create Vault in the Amazon Glacier Developer Guide."},{"ref":"AWS.Glacier.html#delete_archive/6","title":"AWS.Glacier.delete_archive/6","type":"function","doc":"This operation deletes an archive from a vault. Subsequent requests to initiate a retrieval of this archive will fail. Archive retrievals that are in progress for this archive ID may or may not succeed according to the following scenarios: If the archive retrieval job is actively preparing the data for download when Amazon S3 Glacier receives the delete archive request, the archival retrieval operation might fail. If the archive retrieval job has successfully prepared the archive for download when Amazon S3 Glacier receives the delete archive request, you will be able to download the output. This operation is idempotent. Attempting to delete an already-deleted archive does not result in an error. An AWS account has full permission to perform all operations (actions). However, AWS Identity and Access Management (IAM) users don&#39;t have any permissions by default. You must grant them explicit permission to perform specific actions. For more information, see Access Control Using AWS Identity and Access Management (IAM). For conceptual information and underlying REST API, see Deleting an Archive in Amazon Glacier and Delete Archive in the Amazon Glacier Developer Guide."},{"ref":"AWS.Glacier.html#delete_vault/5","title":"AWS.Glacier.delete_vault/5","type":"function","doc":"This operation deletes a vault. Amazon S3 Glacier will delete a vault only if there are no archives in the vault as of the last inventory and there have been no writes to the vault since the last inventory. If either of these conditions is not satisfied, the vault deletion fails (that is, the vault is not removed) and Amazon S3 Glacier returns an error. You can use DescribeVault to return the number of archives in a vault, and you can use Initiate a Job (POST jobs) to initiate a new inventory retrieval for a vault. The inventory contains the archive IDs you use to delete archives using Delete Archive (DELETE archive). This operation is idempotent. An AWS account has full permission to perform all operations (actions). However, AWS Identity and Access Management (IAM) users don&#39;t have any permissions by default. You must grant them explicit permission to perform specific actions. For more information, see Access Control Using AWS Identity and Access Management (IAM). For conceptual information and underlying REST API, see Deleting a Vault in Amazon Glacier and Delete Vault in the Amazon S3 Glacier Developer Guide."},{"ref":"AWS.Glacier.html#delete_vault_access_policy/5","title":"AWS.Glacier.delete_vault_access_policy/5","type":"function","doc":"This operation deletes the access policy associated with the specified vault. The operation is eventually consistent; that is, it might take some time for Amazon S3 Glacier to completely remove the access policy, and you might still see the effect of the policy for a short time after you send the delete request. This operation is idempotent. You can invoke delete multiple times, even if there is no policy associated with the vault. For more information about vault access policies, see Amazon Glacier Access Control with Vault Access Policies."},{"ref":"AWS.Glacier.html#delete_vault_notifications/5","title":"AWS.Glacier.delete_vault_notifications/5","type":"function","doc":"This operation deletes the notification configuration set for a vault. The operation is eventually consistent; that is, it might take some time for Amazon S3 Glacier to completely disable the notifications and you might still receive some notifications for a short time after you send the delete request. An AWS account has full permission to perform all operations (actions). However, AWS Identity and Access Management (IAM) users don&#39;t have any permissions by default. You must grant them explicit permission to perform specific actions. For more information, see Access Control Using AWS Identity and Access Management (IAM). For conceptual information and underlying REST API, see Configuring Vault Notifications in Amazon S3 Glacier and Delete Vault Notification Configuration in the Amazon S3 Glacier Developer Guide."},{"ref":"AWS.Glacier.html#describe_job/5","title":"AWS.Glacier.describe_job/5","type":"function","doc":"This operation returns information about a job you previously initiated, including the job initiation date, the user who initiated the job, the job status code/message and the Amazon SNS topic to notify after Amazon S3 Glacier (Glacier) completes the job. For more information about initiating a job, see InitiateJob. This operation enables you to check the status of your job. However, it is strongly recommended that you set up an Amazon SNS topic and specify it in your initiate job request so that Glacier can notify the topic after it completes the job. A job ID will not expire for at least 24 hours after Glacier completes the job. An AWS account has full permission to perform all operations (actions). However, AWS Identity and Access Management (IAM) users don&#39;t have any permissions by default. You must grant them explicit permission to perform specific actions. For more information, see Access Control Using AWS Identity and Access Management (IAM). For more information about using this operation, see the documentation for the underlying REST API Describe Job in the Amazon Glacier Developer Guide."},{"ref":"AWS.Glacier.html#describe_vault/4","title":"AWS.Glacier.describe_vault/4","type":"function","doc":"This operation returns information about a vault, including the vault&#39;s Amazon Resource Name (ARN), the date the vault was created, the number of archives it contains, and the total size of all the archives in the vault. The number of archives and their total size are as of the last inventory generation. This means that if you add or remove an archive from a vault, and then immediately use Describe Vault, the change in contents will not be immediately reflected. If you want to retrieve the latest inventory of the vault, use InitiateJob. Amazon S3 Glacier generates vault inventories approximately daily. For more information, see Downloading a Vault Inventory in Amazon S3 Glacier. An AWS account has full permission to perform all operations (actions). However, AWS Identity and Access Management (IAM) users don&#39;t have any permissions by default. You must grant them explicit permission to perform specific actions. For more information, see Access Control Using AWS Identity and Access Management (IAM). For conceptual information and underlying REST API, see Retrieving Vault Metadata in Amazon S3 Glacier and Describe Vault in the Amazon Glacier Developer Guide."},{"ref":"AWS.Glacier.html#get_data_retrieval_policy/3","title":"AWS.Glacier.get_data_retrieval_policy/3","type":"function","doc":"This operation returns the current data retrieval policy for the account and region specified in the GET request. For more information about data retrieval policies, see Amazon Glacier Data Retrieval Policies."},{"ref":"AWS.Glacier.html#get_job_output/6","title":"AWS.Glacier.get_job_output/6","type":"function","doc":"This operation downloads the output of the job you initiated using InitiateJob. Depending on the job type you specified when you initiated the job, the output will be either the content of an archive or a vault inventory. You can download all the job output or download a portion of the output by specifying a byte range. In the case of an archive retrieval job, depending on the byte range you specify, Amazon S3 Glacier (Glacier) returns the checksum for the portion of the data. You can compute the checksum on the client and verify that the values match to ensure the portion you downloaded is the correct data. A job ID will not expire for at least 24 hours after Glacier completes the job. That a byte range. For both archive and inventory retrieval jobs, you should verify the downloaded size against the size returned in the headers from the Get Job Output response. For archive retrieval jobs, you should also verify that the size is what you expected. If you download a portion of the output, the expected size is based on the range of bytes you specified. For example, if you specify a range of bytes=0-1048575, you should verify your download size is 1,048,576 bytes. If you download an entire archive, the expected size is the size of the archive when you uploaded it to Amazon S3 Glacier The expected size is also returned in the headers from the Get Job Output response. In the case of an archive retrieval job, depending on the byte range you specify, Glacier returns the checksum for the portion of the data. To ensure the portion you downloaded is the correct data, compute the checksum on the client, verify that the values match, and verify that the size is what you expected. A job ID does not expire for at least 24 hours after Glacier completes the job. That is, you can download the job output within the 24 hours period after Amazon Glacier completes the job. An AWS account has full permission to perform all operations (actions). However, AWS Identity and Access Management (IAM) users don&#39;t have any permissions by default. You must grant them explicit permission to perform specific actions. For more information, see Access Control Using AWS Identity and Access Management (IAM). For conceptual information and the underlying REST API, see Downloading a Vault Inventory, Downloading an Archive, and Get Job Output"},{"ref":"AWS.Glacier.html#get_vault_access_policy/4","title":"AWS.Glacier.get_vault_access_policy/4","type":"function","doc":"This operation retrieves the access-policy subresource set on the vault; for more information on setting this subresource, see Set Vault Access Policy (PUT access-policy). If there is no access policy set on the vault, the operation returns a 404 Not found error. For more information about vault access policies, see Amazon Glacier Access Control with Vault Access Policies."},{"ref":"AWS.Glacier.html#get_vault_lock/4","title":"AWS.Glacier.get_vault_lock/4","type":"function","doc":"This operation retrieves the following attributes from the lock-policy subresource set on the specified vault: The vault lock policy set on the vault. The state of the vault lock, which is either InProgess or Locked. When the lock ID expires. The lock ID is used to complete the vault locking process. When the vault lock was initiated and put into the InProgress state. A vault lock is put into the InProgress state by calling InitiateVaultLock. A vault lock is put into the Locked state by calling CompleteVaultLock. You can abort the vault locking process by calling AbortVaultLock. For more information about the vault locking process, Amazon Glacier Vault Lock. If there is no vault lock policy set on the vault, the operation returns a 404 Not found error. For more information about vault lock policies, Amazon Glacier Access Control with Vault Lock Policies."},{"ref":"AWS.Glacier.html#get_vault_notifications/4","title":"AWS.Glacier.get_vault_notifications/4","type":"function","doc":"This operation retrieves the notification-configuration subresource of the specified vault. For information about setting a notification configuration on a vault, see SetVaultNotifications. If a notification configuration for a vault is not set, the operation returns a 404 Not Found error. For more information about vault notifications, see Configuring Vault Notifications in Amazon S3 Glacier. An AWS account has full permission to perform all operations (actions). However, AWS Identity and Access Management (IAM) users don&#39;t have any permissions by default. You must grant them explicit permission to perform specific actions. For more information, see Access Control Using AWS Identity and Access Management (IAM). For conceptual information and underlying REST API, see Configuring Vault Notifications in Amazon S3 Glacier and Get Vault Notification Configuration in the Amazon Glacier Developer Guide."},{"ref":"AWS.Glacier.html#initiate_job/5","title":"AWS.Glacier.initiate_job/5","type":"function","doc":"This operation initiates a job of the specified type, which can be a select, an archival retrieval, or a vault retrieval. For more information about using this operation, see the documentation for the underlying REST API Initiate a Job."},{"ref":"AWS.Glacier.html#initiate_multipart_upload/5","title":"AWS.Glacier.initiate_multipart_upload/5","type":"function","doc":"This operation initiates a multipart upload. Amazon S3 Glacier creates a multipart upload resource and returns its ID in the response. The multipart upload ID is used in subsequent requests to upload parts of an archive (see UploadMultipartPart). When you initiate a multipart upload, you specify the part size in number of bytes. The part size must be a megabyte (1024 KB) multiplied by a power of 2-for example, 1048576 (1 MB), 2097152 (2 MB), 4194304 (4 MB), 8388608 (8 MB), and so on. The minimum allowable part size is 1 MB, and the maximum is 4 GB. Every part you upload to this resource (see UploadMultipartPart), except the last one, must have the same size. The last one can be the same size or smaller. For example, suppose you want to upload a 16.2 MB file. If you initiate the multipart upload with a part size of 4 MB, you will upload four parts of 4 MB each and one part of 0.2 MB. You don&#39;t need to know the size of the archive when you start a multipart upload because Amazon S3 Glacier does not require you to specify the overall archive size. After you complete the multipart upload, Amazon S3 Glacier (Glacier) removes the multipart upload resource referenced by the ID. Glacier also removes the multipart upload resource if you cancel the multipart upload or it may be removed if there is no activity for a period of 24 hours. An AWS account has full permission to perform all operations (actions). However, AWS Identity and Access Management (IAM) users don&#39;t have any permissions by default. You must grant them explicit permission to perform specific actions. For more information, see Access Control Using AWS Identity and Access Management (IAM). For conceptual information and underlying REST API, see Uploading Large Archives in Parts (Multipart Upload) and Initiate Multipart Upload in the Amazon Glacier Developer Guide."},{"ref":"AWS.Glacier.html#initiate_vault_lock/5","title":"AWS.Glacier.initiate_vault_lock/5","type":"function","doc":"This operation initiates the vault locking process by doing the following: Installing a vault lock policy on the specified vault. Setting the lock state of vault lock to InProgress. Returning a lock ID, which is used to complete the vault locking process. You can set one vault lock policy for each vault and this policy can be up to 20 KB in size. For more information about vault lock policies, see Amazon Glacier Access Control with Vault Lock Policies. You must complete the vault locking process within 24 hours after the vault lock enters the InProgress state. After the 24 hour window ends, the lock ID expires, the vault automatically exits the InProgress state, and the vault lock policy is removed from the vault. You call CompleteVaultLock to complete the vault locking process by setting the state of the vault lock to Locked. After a vault lock is in the Locked state, you cannot initiate a new vault lock for the vault. You can abort the vault locking process by calling AbortVaultLock. You can get the state of the vault lock by calling GetVaultLock. For more information about the vault locking process, Amazon Glacier Vault Lock. If this operation is called when the vault lock is in the InProgress state, the operation returns an AccessDeniedException error. When the vault lock is in the InProgress state you must call AbortVaultLock before you can initiate a new vault lock policy."},{"ref":"AWS.Glacier.html#list_jobs/8","title":"AWS.Glacier.list_jobs/8","type":"function","doc":"This operation lists jobs for a vault, including jobs that are in-progress and jobs that have recently finished. The List Job operation returns a list of these jobs sorted by job initiation time. Amazon Glacier retains recently completed jobs for a period before deleting them; however, it eventually removes completed jobs. The output of completed jobs can be retrieved. Retaining completed jobs for a period of time after they have completed enables you to get a job output in the event you miss the job completion notification or your first attempt to download it fails. For example, suppose you start an archive retrieval job to download an archive. After the job completes, you start to download the archive but encounter a network error. In this scenario, you can retry and download the archive while the job exists. The List Jobs operation supports pagination. You should always check the response Marker field. If there are no more jobs to list, the Marker field is set to null. If there are more jobs to list, the Marker field is set to a non-null value, which you can use to continue the pagination of the list. To return a list of jobs that begins at a specific job, set the marker request parameter to the Marker value for that job that you obtained from a previous List Jobs request. You can set a maximum limit for the number of jobs returned in the response by specifying the limit parameter in the request. The default limit is 50. The number of jobs returned might be fewer than the limit, but the number of returned jobs never exceeds the limit. Additionally, you can filter the jobs list returned by specifying the optional statuscode parameter or completed parameter, or both. Using the statuscode parameter, you can specify to return only jobs that match either the InProgress, Succeeded, or Failed status. Using the completed parameter, you can specify to return only jobs that were completed (true) or jobs that were not completed (false). For more information about using this operation, see the documentation for the underlying REST API List Jobs."},{"ref":"AWS.Glacier.html#list_multipart_uploads/6","title":"AWS.Glacier.list_multipart_uploads/6","type":"function","doc":"This operation lists in-progress multipart uploads for the specified vault. An in-progress multipart upload is a multipart upload that has been initiated by an InitiateMultipartUpload request, but has not yet been completed or aborted. The list returned in the List Multipart Upload response has no guaranteed order. The List Multipart Uploads operation supports pagination. By default, this operation returns up to 50 multipart uploads in the response. You should always check the response for a marker at which to continue the list; if there are no more items the marker is null. To return a list of multipart uploads that begins at a specific upload, set the marker request parameter to the value you obtained from a previous List Multipart Upload request. You can also limit the number of uploads returned in the response by specifying the limit parameter in the request. Note the difference between this operation and listing parts (ListParts). The List Multipart Uploads operation lists all multipart uploads for a vault and does not require a multipart upload ID. The List Parts operation requires a multipart upload ID since parts are associated with a single upload. An AWS account has full permission to perform all operations (actions). However, AWS Identity and Access Management (IAM) users don&#39;t have any permissions by default. You must grant them explicit permission to perform specific actions. For more information, see Access Control Using AWS Identity and Access Management (IAM). For conceptual information and the underlying REST API, see Working with Archives in Amazon S3 Glacier and List Multipart Uploads in the Amazon Glacier Developer Guide."},{"ref":"AWS.Glacier.html#list_parts/7","title":"AWS.Glacier.list_parts/7","type":"function","doc":"This operation lists the parts of an archive that have been uploaded in a specific multipart upload. You can make this request at any time during an in-progress multipart upload before you complete the upload (see CompleteMultipartUpload. List Parts returns an error for completed uploads. The list returned in the List Parts response is sorted by part range. The List Parts operation supports pagination. By default, this operation returns up to 50 uploaded parts in the response. You should always check the response for a marker at which to continue the list; if there are no more items the marker is null. To return a list of parts that begins at a specific part, set the marker request parameter to the value you obtained from a previous List Parts request. You can also limit the number of parts returned in the response by specifying the limit parameter in the request. An AWS account has full permission to perform all operations (actions). However, AWS Identity and Access Management (IAM) users don&#39;t have any permissions by default. You must grant them explicit permission to perform specific actions. For more information, see Access Control Using AWS Identity and Access Management (IAM). For conceptual information and the underlying REST API, see Working with Archives in Amazon S3 Glacier and List Parts in the Amazon Glacier Developer Guide."},{"ref":"AWS.Glacier.html#list_provisioned_capacity/3","title":"AWS.Glacier.list_provisioned_capacity/3","type":"function","doc":"This operation lists the provisioned capacity units for the specified AWS account."},{"ref":"AWS.Glacier.html#list_tags_for_vault/4","title":"AWS.Glacier.list_tags_for_vault/4","type":"function","doc":"This operation lists all the tags attached to a vault. The operation returns an empty map if there are no tags. For more information about tags, see Tagging Amazon S3 Glacier Resources."},{"ref":"AWS.Glacier.html#list_vaults/5","title":"AWS.Glacier.list_vaults/5","type":"function","doc":"This operation lists all vaults owned by the calling user&#39;s account. The list returned in the response is ASCII-sorted by vault name. By default, this operation returns up to 10 items. If there are more vaults to list, the response marker field contains the vault Amazon Resource Name (ARN) at which to continue the list with a new List Vaults request; otherwise, the marker field is null. To return a list of vaults that begins at a specific vault, set the marker request parameter to the vault ARN you obtained from a previous List Vaults request. You can also limit the number of vaults returned in the response by specifying the limit parameter in the request. An AWS account has full permission to perform all operations (actions). However, AWS Identity and Access Management (IAM) users don&#39;t have any permissions by default. You must grant them explicit permission to perform specific actions. For more information, see Access Control Using AWS Identity and Access Management (IAM). For conceptual information and underlying REST API, see Retrieving Vault Metadata in Amazon S3 Glacier and List Vaults in the Amazon Glacier Developer Guide."},{"ref":"AWS.Glacier.html#purchase_provisioned_capacity/4","title":"AWS.Glacier.purchase_provisioned_capacity/4","type":"function","doc":"This operation purchases a provisioned capacity unit for an AWS account."},{"ref":"AWS.Glacier.html#remove_tags_from_vault/5","title":"AWS.Glacier.remove_tags_from_vault/5","type":"function","doc":"This operation removes one or more tags from the set of tags attached to a vault. For more information about tags, see Tagging Amazon S3 Glacier Resources. This operation is idempotent. The operation will be successful, even if there are no tags attached to the vault."},{"ref":"AWS.Glacier.html#set_data_retrieval_policy/4","title":"AWS.Glacier.set_data_retrieval_policy/4","type":"function","doc":"This operation sets and then enacts a data retrieval policy in the region specified in the PUT request. You can set one policy per region for an AWS account. The policy is enacted within a few minutes of a successful PUT operation. The set policy operation does not affect retrieval jobs that were in progress before the policy was enacted. For more information about data retrieval policies, see Amazon Glacier Data Retrieval Policies."},{"ref":"AWS.Glacier.html#set_vault_access_policy/5","title":"AWS.Glacier.set_vault_access_policy/5","type":"function","doc":"This operation configures an access policy for a vault and will overwrite an existing policy. To configure a vault access policy, send a PUT request to the access-policy subresource of the vault. An access policy is specific to a vault and is also called a vault subresource. You can set one access policy per vault and the policy can be up to 20 KB in size. For more information about vault access policies, see Amazon Glacier Access Control with Vault Access Policies."},{"ref":"AWS.Glacier.html#set_vault_notifications/5","title":"AWS.Glacier.set_vault_notifications/5","type":"function","doc":"This operation configures notifications that will be sent when specific events happen to a vault. By default, you don&#39;t get any notifications. To configure vault notifications, send a PUT request to the notification-configuration subresource of the vault. The request should include a JSON document that provides an Amazon SNS topic and specific events for which you want Amazon S3 Glacier to send notifications to the topic. Amazon SNS topics must grant permission to the vault to be allowed to publish notifications to the topic. You can configure a vault to publish a notification for the following vault events: ArchiveRetrievalCompleted This event occurs when a job that was initiated for an archive retrieval is completed (InitiateJob). The status of the completed job can be &quot;Succeeded&quot; or &quot;Failed&quot;. The notification sent to the SNS topic is the same output as returned from DescribeJob. InventoryRetrievalCompleted This event occurs when a job that was initiated for an inventory retrieval is completed (InitiateJob). The status of the completed job can be &quot;Succeeded&quot; or &quot;Failed&quot;. The notification sent to the SNS topic is the same output as returned from DescribeJob. An AWS account has full permission to perform all operations (actions). However, AWS Identity and Access Management (IAM) users don&#39;t have any permissions by default. You must grant them explicit permission to perform specific actions. For more information, see Access Control Using AWS Identity and Access Management (IAM). For conceptual information and underlying REST API, see Configuring Vault Notifications in Amazon S3 Glacier and Set Vault Notification Configuration in the Amazon Glacier Developer Guide."},{"ref":"AWS.Glacier.html#upload_archive/5","title":"AWS.Glacier.upload_archive/5","type":"function","doc":"This operation adds an archive to a vault. This is a synchronous operation, and for a successful upload, your data is durably persisted. Amazon S3 Glacier returns the archive ID in the x-amz-archive-id header of the response. You must use the archive ID to access your data in Amazon S3 Glacier. After you upload an archive, you should save the archive ID returned so that you can retrieve or delete the archive later. Besides saving the archive ID, you can also index it and give it a friendly name to allow for better searching. You can also use the optional archive description field to specify how the archive is referred to in an external index of archives, such as you might create in Amazon DynamoDB. You can also get the vault inventory to obtain a list of archive IDs in a vault. For more information, see InitiateJob. You must provide a SHA256 tree hash of the data you are uploading. For information about computing a SHA256 tree hash, see Computing Checksums. You can optionally specify an archive description of up to 1,024 printable ASCII characters. You can get the archive description when you either retrieve the archive or get the vault inventory. For more information, see InitiateJob. Amazon Glacier does not interpret the description in any way. An archive description does not need to be unique. You cannot use the description to retrieve or sort the archive list. Archives are immutable. After you upload an archive, you cannot edit the archive or its description. An AWS account has full permission to perform all operations (actions). However, AWS Identity and Access Management (IAM) users don&#39;t have any permissions by default. You must grant them explicit permission to perform specific actions. For more information, see Access Control Using AWS Identity and Access Management (IAM). For conceptual information and underlying REST API, see Uploading an Archive in Amazon Glacier and Upload Archive in the Amazon Glacier Developer Guide."},{"ref":"AWS.Glacier.html#upload_multipart_part/6","title":"AWS.Glacier.upload_multipart_part/6","type":"function","doc":"This operation uploads a part of an archive. You can upload archive parts in any order. You can also upload them in parallel. You can upload up to 10,000 parts for a multipart upload. Amazon Glacier rejects your upload part request if any of the following conditions is true: SHA256 tree hash does not matchTo ensure that part data is not corrupted in transmission, you compute a SHA256 tree hash of the part and include it in your request. Upon receiving the part data, Amazon S3 Glacier also computes a SHA256 tree hash. If these hash values don&#39;t match, the operation fails. For information about computing a SHA256 tree hash, see Computing Checksums. Part size does not matchThe size of each part except the last must match the size specified in the corresponding InitiateMultipartUpload request. The size of the last part must be the same size as, or smaller than, the specified size. If you upload a part whose size is smaller than the part size you specified in your initiate multipart upload request and that part is not the last part, then the upload part request will succeed. However, the subsequent Complete Multipart Upload request will fail. Range does not alignThe byte range value in the request does not align with the part size specified in the corresponding initiate request. For example, if you specify a part size of 4194304 bytes (4 MB), then 0 to 4194303 bytes (4 MB - 1) and 4194304 (4 MB) to 8388607 (8 MB - 1) are valid part ranges. However, if you set a range value of 2 MB to 6 MB, the range does not align with the part size and the upload will fail. This operation is idempotent. If you upload the same part multiple times, the data included in the most recent request overwrites the previously uploaded data. An AWS account has full permission to perform all operations (actions). However, AWS Identity and Access Management (IAM) users don&#39;t have any permissions by default. You must grant them explicit permission to perform specific actions. For more information, see Access Control Using AWS Identity and Access Management (IAM). For conceptual information and underlying REST API, see Uploading Large Archives in Parts (Multipart Upload) and Upload Part in the Amazon Glacier Developer Guide."},{"ref":"AWS.GlobalAccelerator.html","title":"AWS.GlobalAccelerator","type":"module","doc":"AWS Global Accelerator This is the AWS Global Accelerator API Reference. This guide is for developers who need detailed information about AWS Global Accelerator API actions, data types, and errors. For more information about Global Accelerator features, see the AWS Global Accelerator Developer Guide. AWS Global Accelerator is a service in which you create accelerators to improve availability and performance of your applications for local and global users. You must specify the US West (Oregon) Region to create or update accelerators. By default, Global Accelerator provides you with static IP addresses that you associate with your accelerator. (Instead of using the IP addresses that Global Accelerator provides, you can configure these entry points to be IPv4 addresses from your own IP address ranges that you bring to Global Accelerator.) The static IP addresses are anycast from the AWS edge network and distribute incoming application traffic across multiple endpoint resources in multiple AWS Regions, which increases the availability of your applications. Endpoints can be Network Load Balancers, Application Load Balancers, EC2 instances, or Elastic IP addresses that are located in one AWS Region or multiple Regions. Global Accelerator uses the AWS global network to route traffic to the optimal regional endpoint based on health, client location, and policies that you configure. The service reacts instantly to changes in health or configuration to ensure that internet traffic from clients is directed to only healthy endpoints. Global Accelerator includes components that work together to help you improve performance and availability for your applications: Definitions Static IP address By default, AWS Global Accelerator provides you with a set of static IP addresses that are anycast from the AWS edge network and serve as the single fixed entry points for your clients. Or you can configure these entry points to be IPv4 addresses from your own IP address ranges that you bring to Global Accelerator (BYOIP). For more information, see Bring Your Own IP Addresses (BYOIP) in the AWS Global Accelerator Developer Guide. If you already have load balancers, EC2 instances, or Elastic IP addresses set up for your applications, you can easily add those to Global Accelerator to allow the resources to be accessed by the static IP addresses. The static IP addresses remain assigned to your accelerator for as long as it exists, even if you disable the accelerator and it no longer accepts or routes traffic. However, when you delete an accelerator, you lose the static IP addresses that are assigned to it, so you can no longer route traffic by using them. You can use IAM policies with Global Accelerator to limit the users who have permissions to delete an accelerator. For more information, see Authentication and Access Control in the AWS Global Accelerator Developer Guide. Accelerator An accelerator directs traffic to optimal endpoints over the AWS global network to improve availability and performance for your internet applications that have a global audience. Each accelerator includes one or more listeners. DNS name Global Accelerator assigns each accelerator a default Domain Name System (DNS) name, similar to a1234567890abcdef.awsglobalaccelerator.com, that points to your Global Accelerator static IP addresses. Depending on the use case, you can use your accelerator&#39;s static IP addresses or DNS name to route traffic to your accelerator, or set up DNS records to route traffic using your own custom domain name. Network zone A network zone services the static IP addresses for your accelerator from a unique IP subnet. Similar to an AWS Availability Zone, a network zone is an isolated unit with its own set of physical infrastructure. When you configure an accelerator, by default, Global Accelerator allocates two IPv4 addresses for it. If one IP address from a network zone becomes unavailable due to IP address blocking by certain client networks, or network disruptions, then client applications can retry on the healthy static IP address from the other isolated network zone. Listener A listener processes inbound connections from clients to Global Accelerator, based on the protocol and port that you configure. Each listener has one or more endpoint groups associated with it, and traffic is forwarded to endpoints in one of the groups. You associate endpoint groups with listeners by specifying the Regions that you want to distribute traffic to. Traffic is distributed to optimal endpoints within the endpoint groups associated with a listener. Endpoint group Each endpoint group is associated with a specific AWS Region. Endpoint groups include one or more endpoints in the Region. You can increase or reduce the percentage of traffic that would be otherwise directed to an endpoint group by adjusting a setting called a traffic dial. The traffic dial lets you easily do performance testing or blue/green deployment testing for new releases across different AWS Regions, for example. Endpoint An endpoint is a Network Load Balancer, Application Load Balancer, EC2 instance, or Elastic IP address. Traffic is routed to endpoints based on several factors, including the geo-proximity to the user, the health of the endpoint, and the configuration options that you choose, such as endpoint weights. For each endpoint, you can configure weights, which are numbers that you can use to specify the proportion of traffic to route to each one. This can be useful, for example, to do performance testing within a Region."},{"ref":"AWS.GlobalAccelerator.html#advertise_byoip_cidr/3","title":"AWS.GlobalAccelerator.advertise_byoip_cidr/3","type":"function","doc":"Advertises an IPv4 address range that is provisioned for use with your AWS resources through bring your own IP addresses (BYOIP). It can take a few minutes before traffic to the specified addresses starts routing to AWS because of propagation delays. To see an AWS CLI example of advertising an address range, scroll down to Example. To stop advertising the BYOIP address range, use WithdrawByoipCidr. For more information, see Bring Your Own IP Addresses (BYOIP) in the AWS Global Accelerator Developer Guide."},{"ref":"AWS.GlobalAccelerator.html#create_accelerator/3","title":"AWS.GlobalAccelerator.create_accelerator/3","type":"function","doc":"Create an accelerator. An accelerator includes one or more listeners that process inbound connections and direct traffic to one or more endpoint groups, each of which includes endpoints, such as Network Load Balancers. To see an AWS CLI example of creating an accelerator, scroll down to Example. If you bring your own IP address ranges to AWS Global Accelerator (BYOIP), you can assign IP addresses from your own pool to your accelerator as the static IP address entry points. Only one IP address from each of your IP address ranges can be used for each accelerator. You must specify the US West (Oregon) Region to create or update accelerators."},{"ref":"AWS.GlobalAccelerator.html#create_endpoint_group/3","title":"AWS.GlobalAccelerator.create_endpoint_group/3","type":"function","doc":"Create an endpoint group for the specified listener. An endpoint group is a collection of endpoints in one AWS Region. To see an AWS CLI example of creating an endpoint group, scroll down to Example."},{"ref":"AWS.GlobalAccelerator.html#create_listener/3","title":"AWS.GlobalAccelerator.create_listener/3","type":"function","doc":"Create a listener to process inbound connections from clients to an accelerator. Connections arrive to assigned static IP addresses on a port, port range, or list of port ranges that you specify. To see an AWS CLI example of creating a listener, scroll down to Example."},{"ref":"AWS.GlobalAccelerator.html#delete_accelerator/3","title":"AWS.GlobalAccelerator.delete_accelerator/3","type":"function","doc":"Delete an accelerator. Before you can delete an accelerator, you must disable it and remove all dependent resources (listeners and endpoint groups). To disable the accelerator, update the accelerator to set Enabled to false. When you create an accelerator, by default, Global Accelerator provides you with a set of two static IP addresses. Alternatively, you can bring your own IP address ranges to Global Accelerator and assign IP addresses from those ranges. The IP addresses are assigned to your accelerator for as long as it exists, even if you disable the accelerator and it no longer accepts or routes traffic. However, when you delete an accelerator, you lose the static IP addresses that are assigned to the accelerator, so you can no longer route traffic by using them. As a best practice, ensure that you have permissions in place to avoid inadvertently deleting accelerators. You can use IAM policies with Global Accelerator to limit the users who have permissions to delete an accelerator. For more information, see Authentication and Access Control in the AWS Global Accelerator Developer Guide."},{"ref":"AWS.GlobalAccelerator.html#delete_endpoint_group/3","title":"AWS.GlobalAccelerator.delete_endpoint_group/3","type":"function","doc":"Delete an endpoint group from a listener."},{"ref":"AWS.GlobalAccelerator.html#delete_listener/3","title":"AWS.GlobalAccelerator.delete_listener/3","type":"function","doc":"Delete a listener from an accelerator."},{"ref":"AWS.GlobalAccelerator.html#deprovision_byoip_cidr/3","title":"AWS.GlobalAccelerator.deprovision_byoip_cidr/3","type":"function","doc":"Releases the specified address range that you provisioned to use with your AWS resources through bring your own IP addresses (BYOIP) and deletes the corresponding address pool. To see an AWS CLI example of deprovisioning an address range, scroll down to Example. Before you can release an address range, you must stop advertising it by using WithdrawByoipCidr and you must not have any accelerators that are using static IP addresses allocated from its address range. For more information, see Bring Your Own IP Addresses (BYOIP) in the AWS Global Accelerator Developer Guide."},{"ref":"AWS.GlobalAccelerator.html#describe_accelerator/3","title":"AWS.GlobalAccelerator.describe_accelerator/3","type":"function","doc":"Describe an accelerator. To see an AWS CLI example of describing an accelerator, scroll down to Example."},{"ref":"AWS.GlobalAccelerator.html#describe_accelerator_attributes/3","title":"AWS.GlobalAccelerator.describe_accelerator_attributes/3","type":"function","doc":"Describe the attributes of an accelerator. To see an AWS CLI example of describing the attributes of an accelerator, scroll down to Example."},{"ref":"AWS.GlobalAccelerator.html#describe_endpoint_group/3","title":"AWS.GlobalAccelerator.describe_endpoint_group/3","type":"function","doc":"Describe an endpoint group. To see an AWS CLI example of describing an endpoint group, scroll down to Example."},{"ref":"AWS.GlobalAccelerator.html#describe_listener/3","title":"AWS.GlobalAccelerator.describe_listener/3","type":"function","doc":"Describe a listener. To see an AWS CLI example of describing a listener, scroll down to Example."},{"ref":"AWS.GlobalAccelerator.html#list_accelerators/3","title":"AWS.GlobalAccelerator.list_accelerators/3","type":"function","doc":"List the accelerators for an AWS account. To see an AWS CLI example of listing the accelerators for an AWS account, scroll down to Example."},{"ref":"AWS.GlobalAccelerator.html#list_byoip_cidrs/3","title":"AWS.GlobalAccelerator.list_byoip_cidrs/3","type":"function","doc":"Lists the IP address ranges that were specified in calls to ProvisionByoipCidr, including the current state and a history of state changes. To see an AWS CLI example of listing BYOIP CIDR addresses, scroll down to Example."},{"ref":"AWS.GlobalAccelerator.html#list_endpoint_groups/3","title":"AWS.GlobalAccelerator.list_endpoint_groups/3","type":"function","doc":"List the endpoint groups that are associated with a listener. To see an AWS CLI example of listing the endpoint groups for listener, scroll down to Example."},{"ref":"AWS.GlobalAccelerator.html#list_listeners/3","title":"AWS.GlobalAccelerator.list_listeners/3","type":"function","doc":"List the listeners for an accelerator. To see an AWS CLI example of listing the listeners for an accelerator, scroll down to Example."},{"ref":"AWS.GlobalAccelerator.html#list_tags_for_resource/3","title":"AWS.GlobalAccelerator.list_tags_for_resource/3","type":"function","doc":"List all tags for an accelerator. To see an AWS CLI example of listing tags for an accelerator, scroll down to Example. For more information, see Tagging in AWS Global Accelerator in the AWS Global Accelerator Developer Guide."},{"ref":"AWS.GlobalAccelerator.html#provision_byoip_cidr/3","title":"AWS.GlobalAccelerator.provision_byoip_cidr/3","type":"function","doc":"Provisions an IP address range to use with your AWS resources through bring your own IP addresses (BYOIP) and creates a corresponding address pool. After the address range is provisioned, it is ready to be advertised using AdvertiseByoipCidr. To see an AWS CLI example of provisioning an address range for BYOIP, scroll down to Example. For more information, see Bring Your Own IP Addresses (BYOIP) in the AWS Global Accelerator Developer Guide."},{"ref":"AWS.GlobalAccelerator.html#tag_resource/3","title":"AWS.GlobalAccelerator.tag_resource/3","type":"function","doc":"Add tags to an accelerator resource. To see an AWS CLI example of adding tags to an accelerator, scroll down to Example. For more information, see Tagging in AWS Global Accelerator in the AWS Global Accelerator Developer Guide."},{"ref":"AWS.GlobalAccelerator.html#untag_resource/3","title":"AWS.GlobalAccelerator.untag_resource/3","type":"function","doc":"Remove tags from a Global Accelerator resource. When you specify a tag key, the action removes both that key and its associated value. To see an AWS CLI example of removing tags from an accelerator, scroll down to Example. The operation succeeds even if you attempt to remove tags from an accelerator that was already removed. For more information, see Tagging in AWS Global Accelerator in the AWS Global Accelerator Developer Guide."},{"ref":"AWS.GlobalAccelerator.html#update_accelerator/3","title":"AWS.GlobalAccelerator.update_accelerator/3","type":"function","doc":"Update an accelerator. To see an AWS CLI example of updating an accelerator, scroll down to Example. You must specify the US West (Oregon) Region to create or update accelerators."},{"ref":"AWS.GlobalAccelerator.html#update_accelerator_attributes/3","title":"AWS.GlobalAccelerator.update_accelerator_attributes/3","type":"function","doc":"Update the attributes for an accelerator. To see an AWS CLI example of updating an accelerator to enable flow logs, scroll down to Example."},{"ref":"AWS.GlobalAccelerator.html#update_endpoint_group/3","title":"AWS.GlobalAccelerator.update_endpoint_group/3","type":"function","doc":"Update an endpoint group. To see an AWS CLI example of updating an endpoint group, scroll down to Example."},{"ref":"AWS.GlobalAccelerator.html#update_listener/3","title":"AWS.GlobalAccelerator.update_listener/3","type":"function","doc":"Update a listener. To see an AWS CLI example of updating listener, scroll down to Example."},{"ref":"AWS.GlobalAccelerator.html#withdraw_byoip_cidr/3","title":"AWS.GlobalAccelerator.withdraw_byoip_cidr/3","type":"function","doc":"Stops advertising an address range that is provisioned as an address pool. You can perform this operation at most once every 10 seconds, even if you specify different address ranges each time. To see an AWS CLI example of withdrawing an address range for BYOIP so it will no longer be advertised by AWS, scroll down to Example. It can take a few minutes before traffic to the specified addresses stops routing to AWS because of propagation delays. For more information, see Bring Your Own IP Addresses (BYOIP) in the AWS Global Accelerator Developer Guide."},{"ref":"AWS.Glue.html","title":"AWS.Glue","type":"module","doc":"AWS Glue Defines the public endpoint for the AWS Glue service."},{"ref":"AWS.Glue.html#batch_create_partition/3","title":"AWS.Glue.batch_create_partition/3","type":"function","doc":"Creates one or more partitions in a batch operation."},{"ref":"AWS.Glue.html#batch_delete_connection/3","title":"AWS.Glue.batch_delete_connection/3","type":"function","doc":"Deletes a list of connection definitions from the Data Catalog."},{"ref":"AWS.Glue.html#batch_delete_partition/3","title":"AWS.Glue.batch_delete_partition/3","type":"function","doc":"Deletes one or more partitions in a batch operation."},{"ref":"AWS.Glue.html#batch_delete_table/3","title":"AWS.Glue.batch_delete_table/3","type":"function","doc":"Deletes multiple tables at once. After completing this operation, you no longer have access to the table versions and partitions that belong to the deleted table. AWS Glue deletes these &quot;orphaned&quot; resources asynchronously in a timely manner, at the discretion of the service. To ensure the immediate deletion of all related resources, before calling BatchDeleteTable, use DeleteTableVersion or BatchDeleteTableVersion, and DeletePartition or BatchDeletePartition, to delete any resources that belong to the table."},{"ref":"AWS.Glue.html#batch_delete_table_version/3","title":"AWS.Glue.batch_delete_table_version/3","type":"function","doc":"Deletes a specified batch of versions of a table."},{"ref":"AWS.Glue.html#batch_get_crawlers/3","title":"AWS.Glue.batch_get_crawlers/3","type":"function","doc":"Returns a list of resource metadata for a given list of crawler names. After calling the ListCrawlers operation, you can call this operation to access the data to which you have been granted permissions. This operation supports all IAM permissions, including permission conditions that uses tags."},{"ref":"AWS.Glue.html#batch_get_dev_endpoints/3","title":"AWS.Glue.batch_get_dev_endpoints/3","type":"function","doc":"Returns a list of resource metadata for a given list of development endpoint names. After calling the ListDevEndpoints operation, you can call this operation to access the data to which you have been granted permissions. This operation supports all IAM permissions, including permission conditions that uses tags."},{"ref":"AWS.Glue.html#batch_get_jobs/3","title":"AWS.Glue.batch_get_jobs/3","type":"function","doc":"Returns a list of resource metadata for a given list of job names. After calling the ListJobs operation, you can call this operation to access the data to which you have been granted permissions. This operation supports all IAM permissions, including permission conditions that uses tags."},{"ref":"AWS.Glue.html#batch_get_partition/3","title":"AWS.Glue.batch_get_partition/3","type":"function","doc":"Retrieves partitions in a batch request."},{"ref":"AWS.Glue.html#batch_get_triggers/3","title":"AWS.Glue.batch_get_triggers/3","type":"function","doc":"Returns a list of resource metadata for a given list of trigger names. After calling the ListTriggers operation, you can call this operation to access the data to which you have been granted permissions. This operation supports all IAM permissions, including permission conditions that uses tags."},{"ref":"AWS.Glue.html#batch_get_workflows/3","title":"AWS.Glue.batch_get_workflows/3","type":"function","doc":"Returns a list of resource metadata for a given list of workflow names. After calling the ListWorkflows operation, you can call this operation to access the data to which you have been granted permissions. This operation supports all IAM permissions, including permission conditions that uses tags."},{"ref":"AWS.Glue.html#batch_stop_job_run/3","title":"AWS.Glue.batch_stop_job_run/3","type":"function","doc":"Stops one or more job runs for a specified job definition."},{"ref":"AWS.Glue.html#batch_update_partition/3","title":"AWS.Glue.batch_update_partition/3","type":"function","doc":"Updates one or more partitions in a batch operation."},{"ref":"AWS.Glue.html#cancel_m_l_task_run/3","title":"AWS.Glue.cancel_m_l_task_run/3","type":"function","doc":"Cancels (stops) a task run. Machine learning task runs are asynchronous tasks that AWS Glue runs on your behalf as part of various machine learning workflows. You can cancel a machine learning task run at any time by calling CancelMLTaskRun with a task run&#39;s parent transform&#39;s TransformID and the task run&#39;s TaskRunId."},{"ref":"AWS.Glue.html#create_classifier/3","title":"AWS.Glue.create_classifier/3","type":"function","doc":"Creates a classifier in the user&#39;s account. This can be a GrokClassifier, an XMLClassifier, a JsonClassifier, or a CsvClassifier, depending on which field of the request is present."},{"ref":"AWS.Glue.html#create_connection/3","title":"AWS.Glue.create_connection/3","type":"function","doc":"Creates a connection definition in the Data Catalog."},{"ref":"AWS.Glue.html#create_crawler/3","title":"AWS.Glue.create_crawler/3","type":"function","doc":"Creates a new crawler with specified targets, role, configuration, and optional schedule. At least one crawl target must be specified, in the s3Targets field, the jdbcTargets field, or the DynamoDBTargets field."},{"ref":"AWS.Glue.html#create_database/3","title":"AWS.Glue.create_database/3","type":"function","doc":"Creates a new database in a Data Catalog."},{"ref":"AWS.Glue.html#create_dev_endpoint/3","title":"AWS.Glue.create_dev_endpoint/3","type":"function","doc":"Creates a new development endpoint."},{"ref":"AWS.Glue.html#create_job/3","title":"AWS.Glue.create_job/3","type":"function","doc":"Creates a new job definition."},{"ref":"AWS.Glue.html#create_m_l_transform/3","title":"AWS.Glue.create_m_l_transform/3","type":"function","doc":"Creates an AWS Glue machine learning transform. This operation creates the transform and all the necessary parameters to train it. Call this operation as the first step in the process of using a machine learning transform (such as the FindMatches transform) for deduplicating data. You can provide an optional Description, in addition to the parameters that you want to use for your algorithm. You must also specify certain parameters for the tasks that AWS Glue runs on your behalf as part of learning from your data and creating a high-quality machine learning transform. These parameters include Role, and optionally, AllocatedCapacity, Timeout, and MaxRetries. For more information, see Jobs."},{"ref":"AWS.Glue.html#create_partition/3","title":"AWS.Glue.create_partition/3","type":"function","doc":"Creates a new partition."},{"ref":"AWS.Glue.html#create_script/3","title":"AWS.Glue.create_script/3","type":"function","doc":"Transforms a directed acyclic graph (DAG) into code."},{"ref":"AWS.Glue.html#create_security_configuration/3","title":"AWS.Glue.create_security_configuration/3","type":"function","doc":"Creates a new security configuration. A security configuration is a set of security properties that can be used by AWS Glue. You can use a security configuration to encrypt data at rest. For information about using security configurations in AWS Glue, see Encrypting Data Written by Crawlers, Jobs, and Development Endpoints."},{"ref":"AWS.Glue.html#create_table/3","title":"AWS.Glue.create_table/3","type":"function","doc":"Creates a new table definition in the Data Catalog."},{"ref":"AWS.Glue.html#create_trigger/3","title":"AWS.Glue.create_trigger/3","type":"function","doc":"Creates a new trigger."},{"ref":"AWS.Glue.html#create_user_defined_function/3","title":"AWS.Glue.create_user_defined_function/3","type":"function","doc":"Creates a new function definition in the Data Catalog."},{"ref":"AWS.Glue.html#create_workflow/3","title":"AWS.Glue.create_workflow/3","type":"function","doc":"Creates a new workflow."},{"ref":"AWS.Glue.html#delete_classifier/3","title":"AWS.Glue.delete_classifier/3","type":"function","doc":"Removes a classifier from the Data Catalog."},{"ref":"AWS.Glue.html#delete_column_statistics_for_partition/3","title":"AWS.Glue.delete_column_statistics_for_partition/3","type":"function","doc":"Delete the partition column statistics of a column."},{"ref":"AWS.Glue.html#delete_column_statistics_for_table/3","title":"AWS.Glue.delete_column_statistics_for_table/3","type":"function","doc":"Retrieves table statistics of columns."},{"ref":"AWS.Glue.html#delete_connection/3","title":"AWS.Glue.delete_connection/3","type":"function","doc":"Deletes a connection from the Data Catalog."},{"ref":"AWS.Glue.html#delete_crawler/3","title":"AWS.Glue.delete_crawler/3","type":"function","doc":"Removes a specified crawler from the AWS Glue Data Catalog, unless the crawler state is RUNNING."},{"ref":"AWS.Glue.html#delete_database/3","title":"AWS.Glue.delete_database/3","type":"function","doc":"Removes a specified database from a Data Catalog. After completing this operation, you no longer have access to the tables (and all table versions and partitions that might belong to the tables) and the user-defined functions in the deleted database. AWS Glue deletes these &quot;orphaned&quot; resources asynchronously in a timely manner, at the discretion of the service. To ensure the immediate deletion of all related resources, before calling DeleteDatabase, use DeleteTableVersion or BatchDeleteTableVersion, DeletePartition or BatchDeletePartition, DeleteUserDefinedFunction, and DeleteTable or BatchDeleteTable, to delete any resources that belong to the database."},{"ref":"AWS.Glue.html#delete_dev_endpoint/3","title":"AWS.Glue.delete_dev_endpoint/3","type":"function","doc":"Deletes a specified development endpoint."},{"ref":"AWS.Glue.html#delete_job/3","title":"AWS.Glue.delete_job/3","type":"function","doc":"Deletes a specified job definition. If the job definition is not found, no exception is thrown."},{"ref":"AWS.Glue.html#delete_m_l_transform/3","title":"AWS.Glue.delete_m_l_transform/3","type":"function","doc":"Deletes an AWS Glue machine learning transform. Machine learning transforms are a special type of transform that use machine learning to learn the details of the transformation to be performed by learning from examples provided by humans. These transformations are then saved by AWS Glue. If you no longer need a transform, you can delete it by calling DeleteMLTransforms. However, any AWS Glue jobs that still reference the deleted transform will no longer succeed."},{"ref":"AWS.Glue.html#delete_partition/3","title":"AWS.Glue.delete_partition/3","type":"function","doc":"Deletes a specified partition."},{"ref":"AWS.Glue.html#delete_resource_policy/3","title":"AWS.Glue.delete_resource_policy/3","type":"function","doc":"Deletes a specified policy."},{"ref":"AWS.Glue.html#delete_security_configuration/3","title":"AWS.Glue.delete_security_configuration/3","type":"function","doc":"Deletes a specified security configuration."},{"ref":"AWS.Glue.html#delete_table/3","title":"AWS.Glue.delete_table/3","type":"function","doc":"Removes a table definition from the Data Catalog. After completing this operation, you no longer have access to the table versions and partitions that belong to the deleted table. AWS Glue deletes these &quot;orphaned&quot; resources asynchronously in a timely manner, at the discretion of the service. To ensure the immediate deletion of all related resources, before calling DeleteTable, use DeleteTableVersion or BatchDeleteTableVersion, and DeletePartition or BatchDeletePartition, to delete any resources that belong to the table."},{"ref":"AWS.Glue.html#delete_table_version/3","title":"AWS.Glue.delete_table_version/3","type":"function","doc":"Deletes a specified version of a table."},{"ref":"AWS.Glue.html#delete_trigger/3","title":"AWS.Glue.delete_trigger/3","type":"function","doc":"Deletes a specified trigger. If the trigger is not found, no exception is thrown."},{"ref":"AWS.Glue.html#delete_user_defined_function/3","title":"AWS.Glue.delete_user_defined_function/3","type":"function","doc":"Deletes an existing function definition from the Data Catalog."},{"ref":"AWS.Glue.html#delete_workflow/3","title":"AWS.Glue.delete_workflow/3","type":"function","doc":"Deletes a workflow."},{"ref":"AWS.Glue.html#get_catalog_import_status/3","title":"AWS.Glue.get_catalog_import_status/3","type":"function","doc":"Retrieves the status of a migration operation."},{"ref":"AWS.Glue.html#get_classifier/3","title":"AWS.Glue.get_classifier/3","type":"function","doc":"Retrieve a classifier by name."},{"ref":"AWS.Glue.html#get_classifiers/3","title":"AWS.Glue.get_classifiers/3","type":"function","doc":"Lists all classifier objects in the Data Catalog."},{"ref":"AWS.Glue.html#get_column_statistics_for_partition/3","title":"AWS.Glue.get_column_statistics_for_partition/3","type":"function","doc":"Retrieves partition statistics of columns."},{"ref":"AWS.Glue.html#get_column_statistics_for_table/3","title":"AWS.Glue.get_column_statistics_for_table/3","type":"function","doc":"Retrieves table statistics of columns."},{"ref":"AWS.Glue.html#get_connection/3","title":"AWS.Glue.get_connection/3","type":"function","doc":"Retrieves a connection definition from the Data Catalog."},{"ref":"AWS.Glue.html#get_connections/3","title":"AWS.Glue.get_connections/3","type":"function","doc":"Retrieves a list of connection definitions from the Data Catalog."},{"ref":"AWS.Glue.html#get_crawler/3","title":"AWS.Glue.get_crawler/3","type":"function","doc":"Retrieves metadata for a specified crawler."},{"ref":"AWS.Glue.html#get_crawler_metrics/3","title":"AWS.Glue.get_crawler_metrics/3","type":"function","doc":"Retrieves metrics about specified crawlers."},{"ref":"AWS.Glue.html#get_crawlers/3","title":"AWS.Glue.get_crawlers/3","type":"function","doc":"Retrieves metadata for all crawlers defined in the customer account."},{"ref":"AWS.Glue.html#get_data_catalog_encryption_settings/3","title":"AWS.Glue.get_data_catalog_encryption_settings/3","type":"function","doc":"Retrieves the security configuration for a specified catalog."},{"ref":"AWS.Glue.html#get_database/3","title":"AWS.Glue.get_database/3","type":"function","doc":"Retrieves the definition of a specified database."},{"ref":"AWS.Glue.html#get_databases/3","title":"AWS.Glue.get_databases/3","type":"function","doc":"Retrieves all databases defined in a given Data Catalog."},{"ref":"AWS.Glue.html#get_dataflow_graph/3","title":"AWS.Glue.get_dataflow_graph/3","type":"function","doc":"Transforms a Python script into a directed acyclic graph (DAG)."},{"ref":"AWS.Glue.html#get_dev_endpoint/3","title":"AWS.Glue.get_dev_endpoint/3","type":"function","doc":"Retrieves information about a specified development endpoint. When you create a development endpoint in a virtual private cloud (VPC), AWS Glue returns only a private IP address, and the public IP address field is not populated. When you create a non-VPC development endpoint, AWS Glue returns only a public IP address."},{"ref":"AWS.Glue.html#get_dev_endpoints/3","title":"AWS.Glue.get_dev_endpoints/3","type":"function","doc":"Retrieves all the development endpoints in this AWS account. When you create a development endpoint in a virtual private cloud (VPC), AWS Glue returns only a private IP address and the public IP address field is not populated. When you create a non-VPC development endpoint, AWS Glue returns only a public IP address."},{"ref":"AWS.Glue.html#get_job/3","title":"AWS.Glue.get_job/3","type":"function","doc":"Retrieves an existing job definition."},{"ref":"AWS.Glue.html#get_job_bookmark/3","title":"AWS.Glue.get_job_bookmark/3","type":"function","doc":"Returns information on a job bookmark entry."},{"ref":"AWS.Glue.html#get_job_run/3","title":"AWS.Glue.get_job_run/3","type":"function","doc":"Retrieves the metadata for a given job run."},{"ref":"AWS.Glue.html#get_job_runs/3","title":"AWS.Glue.get_job_runs/3","type":"function","doc":"Retrieves metadata for all runs of a given job definition."},{"ref":"AWS.Glue.html#get_jobs/3","title":"AWS.Glue.get_jobs/3","type":"function","doc":"Retrieves all current job definitions."},{"ref":"AWS.Glue.html#get_m_l_task_run/3","title":"AWS.Glue.get_m_l_task_run/3","type":"function","doc":"Gets details for a specific task run on a machine learning transform. Machine learning task runs are asynchronous tasks that AWS Glue runs on your behalf as part of various machine learning workflows. You can check the stats of any task run by calling GetMLTaskRun with the TaskRunID and its parent transform&#39;s TransformID."},{"ref":"AWS.Glue.html#get_m_l_task_runs/3","title":"AWS.Glue.get_m_l_task_runs/3","type":"function","doc":"Gets a list of runs for a machine learning transform. Machine learning task runs are asynchronous tasks that AWS Glue runs on your behalf as part of various machine learning workflows. You can get a sortable, filterable list of machine learning task runs by calling GetMLTaskRuns with their parent transform&#39;s TransformID and other optional parameters as documented in this section. This operation returns a list of historic runs and must be paginated."},{"ref":"AWS.Glue.html#get_m_l_transform/3","title":"AWS.Glue.get_m_l_transform/3","type":"function","doc":"Gets an AWS Glue machine learning transform artifact and all its corresponding metadata. Machine learning transforms are a special type of transform that use machine learning to learn the details of the transformation to be performed by learning from examples provided by humans. These transformations are then saved by AWS Glue. You can retrieve their metadata by calling GetMLTransform."},{"ref":"AWS.Glue.html#get_m_l_transforms/3","title":"AWS.Glue.get_m_l_transforms/3","type":"function","doc":"Gets a sortable, filterable list of existing AWS Glue machine learning transforms. Machine learning transforms are a special type of transform that use machine learning to learn the details of the transformation to be performed by learning from examples provided by humans. These transformations are then saved by AWS Glue, and you can retrieve their metadata by calling GetMLTransforms."},{"ref":"AWS.Glue.html#get_mapping/3","title":"AWS.Glue.get_mapping/3","type":"function","doc":"Creates mappings."},{"ref":"AWS.Glue.html#get_partition/3","title":"AWS.Glue.get_partition/3","type":"function","doc":"Retrieves information about a specified partition."},{"ref":"AWS.Glue.html#get_partition_indexes/3","title":"AWS.Glue.get_partition_indexes/3","type":"function","doc":"Retrieves the partition indexes associated with a table."},{"ref":"AWS.Glue.html#get_partitions/3","title":"AWS.Glue.get_partitions/3","type":"function","doc":"Retrieves information about the partitions in a table."},{"ref":"AWS.Glue.html#get_plan/3","title":"AWS.Glue.get_plan/3","type":"function","doc":"Gets code to perform a specified mapping."},{"ref":"AWS.Glue.html#get_resource_policies/3","title":"AWS.Glue.get_resource_policies/3","type":"function","doc":"Retrieves the security configurations for the resource policies set on individual resources, and also the account-level policy. This operation also returns the Data Catalog resource policy. However, if you enabled metadata encryption in Data Catalog settings, and you do not have permission on the AWS KMS key, the operation can&#39;t return the Data Catalog resource policy."},{"ref":"AWS.Glue.html#get_resource_policy/3","title":"AWS.Glue.get_resource_policy/3","type":"function","doc":"Retrieves a specified resource policy."},{"ref":"AWS.Glue.html#get_security_configuration/3","title":"AWS.Glue.get_security_configuration/3","type":"function","doc":"Retrieves a specified security configuration."},{"ref":"AWS.Glue.html#get_security_configurations/3","title":"AWS.Glue.get_security_configurations/3","type":"function","doc":"Retrieves a list of all security configurations."},{"ref":"AWS.Glue.html#get_table/3","title":"AWS.Glue.get_table/3","type":"function","doc":"Retrieves the Table definition in a Data Catalog for a specified table."},{"ref":"AWS.Glue.html#get_table_version/3","title":"AWS.Glue.get_table_version/3","type":"function","doc":"Retrieves a specified version of a table."},{"ref":"AWS.Glue.html#get_table_versions/3","title":"AWS.Glue.get_table_versions/3","type":"function","doc":"Retrieves a list of strings that identify available versions of a specified table."},{"ref":"AWS.Glue.html#get_tables/3","title":"AWS.Glue.get_tables/3","type":"function","doc":"Retrieves the definitions of some or all of the tables in a given Database."},{"ref":"AWS.Glue.html#get_tags/3","title":"AWS.Glue.get_tags/3","type":"function","doc":"Retrieves a list of tags associated with a resource."},{"ref":"AWS.Glue.html#get_trigger/3","title":"AWS.Glue.get_trigger/3","type":"function","doc":"Retrieves the definition of a trigger."},{"ref":"AWS.Glue.html#get_triggers/3","title":"AWS.Glue.get_triggers/3","type":"function","doc":"Gets all the triggers associated with a job."},{"ref":"AWS.Glue.html#get_user_defined_function/3","title":"AWS.Glue.get_user_defined_function/3","type":"function","doc":"Retrieves a specified function definition from the Data Catalog."},{"ref":"AWS.Glue.html#get_user_defined_functions/3","title":"AWS.Glue.get_user_defined_functions/3","type":"function","doc":"Retrieves multiple function definitions from the Data Catalog."},{"ref":"AWS.Glue.html#get_workflow/3","title":"AWS.Glue.get_workflow/3","type":"function","doc":"Retrieves resource metadata for a workflow."},{"ref":"AWS.Glue.html#get_workflow_run/3","title":"AWS.Glue.get_workflow_run/3","type":"function","doc":"Retrieves the metadata for a given workflow run."},{"ref":"AWS.Glue.html#get_workflow_run_properties/3","title":"AWS.Glue.get_workflow_run_properties/3","type":"function","doc":"Retrieves the workflow run properties which were set during the run."},{"ref":"AWS.Glue.html#get_workflow_runs/3","title":"AWS.Glue.get_workflow_runs/3","type":"function","doc":"Retrieves metadata for all runs of a given workflow."},{"ref":"AWS.Glue.html#import_catalog_to_glue/3","title":"AWS.Glue.import_catalog_to_glue/3","type":"function","doc":"Imports an existing Amazon Athena Data Catalog to AWS Glue"},{"ref":"AWS.Glue.html#list_crawlers/3","title":"AWS.Glue.list_crawlers/3","type":"function","doc":"Retrieves the names of all crawler resources in this AWS account, or the resources with the specified tag. This operation allows you to see which resources are available in your account, and their names. This operation takes the optional Tags field, which you can use as a filter on the response so that tagged resources can be retrieved as a group. If you choose to use tags filtering, only resources with the tag are retrieved."},{"ref":"AWS.Glue.html#list_dev_endpoints/3","title":"AWS.Glue.list_dev_endpoints/3","type":"function","doc":"Retrieves the names of all DevEndpoint resources in this AWS account, or the resources with the specified tag. This operation allows you to see which resources are available in your account, and their names. This operation takes the optional Tags field, which you can use as a filter on the response so that tagged resources can be retrieved as a group. If you choose to use tags filtering, only resources with the tag are retrieved."},{"ref":"AWS.Glue.html#list_jobs/3","title":"AWS.Glue.list_jobs/3","type":"function","doc":"Retrieves the names of all job resources in this AWS account, or the resources with the specified tag. This operation allows you to see which resources are available in your account, and their names. This operation takes the optional Tags field, which you can use as a filter on the response so that tagged resources can be retrieved as a group. If you choose to use tags filtering, only resources with the tag are retrieved."},{"ref":"AWS.Glue.html#list_m_l_transforms/3","title":"AWS.Glue.list_m_l_transforms/3","type":"function","doc":"Retrieves a sortable, filterable list of existing AWS Glue machine learning transforms in this AWS account, or the resources with the specified tag. This operation takes the optional Tags field, which you can use as a filter of the responses so that tagged resources can be retrieved as a group. If you choose to use tag filtering, only resources with the tags are retrieved."},{"ref":"AWS.Glue.html#list_triggers/3","title":"AWS.Glue.list_triggers/3","type":"function","doc":"Retrieves the names of all trigger resources in this AWS account, or the resources with the specified tag. This operation allows you to see which resources are available in your account, and their names. This operation takes the optional Tags field, which you can use as a filter on the response so that tagged resources can be retrieved as a group. If you choose to use tags filtering, only resources with the tag are retrieved."},{"ref":"AWS.Glue.html#list_workflows/3","title":"AWS.Glue.list_workflows/3","type":"function","doc":"Lists names of workflows created in the account."},{"ref":"AWS.Glue.html#put_data_catalog_encryption_settings/3","title":"AWS.Glue.put_data_catalog_encryption_settings/3","type":"function","doc":"Sets the security configuration for a specified catalog. After the configuration has been set, the specified encryption is applied to every catalog write thereafter."},{"ref":"AWS.Glue.html#put_resource_policy/3","title":"AWS.Glue.put_resource_policy/3","type":"function","doc":"Sets the Data Catalog resource policy for access control."},{"ref":"AWS.Glue.html#put_workflow_run_properties/3","title":"AWS.Glue.put_workflow_run_properties/3","type":"function","doc":"Puts the specified workflow run properties for the given workflow run. If a property already exists for the specified run, then it overrides the value otherwise adds the property to existing properties."},{"ref":"AWS.Glue.html#reset_job_bookmark/3","title":"AWS.Glue.reset_job_bookmark/3","type":"function","doc":"Resets a bookmark entry."},{"ref":"AWS.Glue.html#resume_workflow_run/3","title":"AWS.Glue.resume_workflow_run/3","type":"function","doc":"Restarts selected nodes of a previous partially completed workflow run and resumes the workflow run. The selected nodes and all nodes that are downstream from the selected nodes are run."},{"ref":"AWS.Glue.html#search_tables/3","title":"AWS.Glue.search_tables/3","type":"function","doc":"Searches a set of tables based on properties in the table metadata as well as on the parent database. You can search against text or filter conditions. You can only get tables that you have access to based on the security policies defined in Lake Formation. You need at least a read-only access to the table for it to be returned. If you do not have access to all the columns in the table, these columns will not be searched against when returning the list of tables back to you. If you have access to the columns but not the data in the columns, those columns and the associated metadata for those columns will be included in the search."},{"ref":"AWS.Glue.html#start_crawler/3","title":"AWS.Glue.start_crawler/3","type":"function","doc":"Starts a crawl using the specified crawler, regardless of what is scheduled. If the crawler is already running, returns a CrawlerRunningException."},{"ref":"AWS.Glue.html#start_crawler_schedule/3","title":"AWS.Glue.start_crawler_schedule/3","type":"function","doc":"Changes the schedule state of the specified crawler to SCHEDULED, unless the crawler is already running or the schedule state is already SCHEDULED."},{"ref":"AWS.Glue.html#start_export_labels_task_run/3","title":"AWS.Glue.start_export_labels_task_run/3","type":"function","doc":"Begins an asynchronous task to export all labeled data for a particular transform. This task is the only label-related API call that is not part of the typical active learning workflow. You typically use StartExportLabelsTaskRun when you want to work with all of your existing labels at the same time, such as when you want to remove or change labels that were previously submitted as truth. This API operation accepts the TransformId whose labels you want to export and an Amazon Simple Storage Service (Amazon S3) path to export the labels to. The operation returns a TaskRunId. You can check on the status of your task run by calling the GetMLTaskRun API."},{"ref":"AWS.Glue.html#start_import_labels_task_run/3","title":"AWS.Glue.start_import_labels_task_run/3","type":"function","doc":"Enables you to provide additional labels (examples of truth) to be used to teach the machine learning transform and improve its quality. This API operation is generally used as part of the active learning workflow that starts with the StartMLLabelingSetGenerationTaskRun call and that ultimately results in improving the quality of your machine learning transform. After the StartMLLabelingSetGenerationTaskRun finishes, AWS Glue machine learning will have generated a series of questions for humans to answer. (Answering these questions is often called &#39;labeling&#39; in the machine learning workflows). In the case of the FindMatches transform, these questions are of the form, What is the correct way to group these rows together into groups composed entirely of matching records? After the labeling process is finished, users upload their answers/labels with a call to StartImportLabelsTaskRun. After StartImportLabelsTaskRun finishes, all future runs of the machine learning transform use the new and improved labels and perform a higher-quality transformation. By default, StartMLLabelingSetGenerationTaskRun continually learns from and combines all labels that you upload unless you set Replace to true. If you set Replace to true, StartImportLabelsTaskRun deletes and forgets all previously uploaded labels and learns only from the exact set that you upload. Replacing labels can be helpful if you realize that you previously uploaded incorrect labels, and you believe that they are having a negative effect on your transform quality. You can check on the status of your task run by calling the GetMLTaskRun operation."},{"ref":"AWS.Glue.html#start_job_run/3","title":"AWS.Glue.start_job_run/3","type":"function","doc":"Starts a job run using a job definition."},{"ref":"AWS.Glue.html#start_m_l_evaluation_task_run/3","title":"AWS.Glue.start_m_l_evaluation_task_run/3","type":"function","doc":"Starts a task to estimate the quality of the transform. When you provide label sets as examples of truth, AWS Glue machine learning uses some of those examples to learn from them. The rest of the labels are used as a test to estimate quality. Returns a unique identifier for the run. You can call GetMLTaskRun to get more information about the stats of the EvaluationTaskRun."},{"ref":"AWS.Glue.html#start_m_l_labeling_set_generation_task_run/3","title":"AWS.Glue.start_m_l_labeling_set_generation_task_run/3","type":"function","doc":"Starts the active learning workflow for your machine learning transform to improve the transform&#39;s quality by generating label sets and adding labels. When the StartMLLabelingSetGenerationTaskRun finishes, AWS Glue will have generated a &quot;labeling set&quot; or a set of questions for humans to answer. In the case of the FindMatches transform, these questions are of the form, What is the correct way to group these rows together into groups composed entirely of matching records? After the labeling process is finished, you can upload your labels with a call to StartImportLabelsTaskRun. After StartImportLabelsTaskRun finishes, all future runs of the machine learning transform will use the new and improved labels and perform a higher-quality transformation."},{"ref":"AWS.Glue.html#start_trigger/3","title":"AWS.Glue.start_trigger/3","type":"function","doc":"Starts an existing trigger. See Triggering Jobs for information about how different types of trigger are started."},{"ref":"AWS.Glue.html#start_workflow_run/3","title":"AWS.Glue.start_workflow_run/3","type":"function","doc":"Starts a new run of the specified workflow."},{"ref":"AWS.Glue.html#stop_crawler/3","title":"AWS.Glue.stop_crawler/3","type":"function","doc":"If the specified crawler is running, stops the crawl."},{"ref":"AWS.Glue.html#stop_crawler_schedule/3","title":"AWS.Glue.stop_crawler_schedule/3","type":"function","doc":"Sets the schedule state of the specified crawler to NOT_SCHEDULED, but does not stop the crawler if it is already running."},{"ref":"AWS.Glue.html#stop_trigger/3","title":"AWS.Glue.stop_trigger/3","type":"function","doc":"Stops a specified trigger."},{"ref":"AWS.Glue.html#stop_workflow_run/3","title":"AWS.Glue.stop_workflow_run/3","type":"function","doc":"Stops the execution of the specified workflow run."},{"ref":"AWS.Glue.html#tag_resource/3","title":"AWS.Glue.tag_resource/3","type":"function","doc":"Adds tags to a resource. A tag is a label you can assign to an AWS resource. In AWS Glue, you can tag only certain resources. For information about what resources you can tag, see AWS Tags in AWS Glue."},{"ref":"AWS.Glue.html#untag_resource/3","title":"AWS.Glue.untag_resource/3","type":"function","doc":"Removes tags from a resource."},{"ref":"AWS.Glue.html#update_classifier/3","title":"AWS.Glue.update_classifier/3","type":"function","doc":"Modifies an existing classifier (a GrokClassifier, an XMLClassifier, a JsonClassifier, or a CsvClassifier, depending on which field is present)."},{"ref":"AWS.Glue.html#update_column_statistics_for_partition/3","title":"AWS.Glue.update_column_statistics_for_partition/3","type":"function","doc":"Creates or updates partition statistics of columns."},{"ref":"AWS.Glue.html#update_column_statistics_for_table/3","title":"AWS.Glue.update_column_statistics_for_table/3","type":"function","doc":"Creates or updates table statistics of columns."},{"ref":"AWS.Glue.html#update_connection/3","title":"AWS.Glue.update_connection/3","type":"function","doc":"Updates a connection definition in the Data Catalog."},{"ref":"AWS.Glue.html#update_crawler/3","title":"AWS.Glue.update_crawler/3","type":"function","doc":"Updates a crawler. If a crawler is running, you must stop it using StopCrawler before updating it."},{"ref":"AWS.Glue.html#update_crawler_schedule/3","title":"AWS.Glue.update_crawler_schedule/3","type":"function","doc":"Updates the schedule of a crawler using a cron expression."},{"ref":"AWS.Glue.html#update_database/3","title":"AWS.Glue.update_database/3","type":"function","doc":"Updates an existing database definition in a Data Catalog."},{"ref":"AWS.Glue.html#update_dev_endpoint/3","title":"AWS.Glue.update_dev_endpoint/3","type":"function","doc":"Updates a specified development endpoint."},{"ref":"AWS.Glue.html#update_job/3","title":"AWS.Glue.update_job/3","type":"function","doc":"Updates an existing job definition."},{"ref":"AWS.Glue.html#update_m_l_transform/3","title":"AWS.Glue.update_m_l_transform/3","type":"function","doc":"Updates an existing machine learning transform. Call this operation to tune the algorithm parameters to achieve better results. After calling this operation, you can call the StartMLEvaluationTaskRun operation to assess how well your new parameters achieved your goals (such as improving the quality of your machine learning transform, or making it more cost-effective)."},{"ref":"AWS.Glue.html#update_partition/3","title":"AWS.Glue.update_partition/3","type":"function","doc":"Updates a partition."},{"ref":"AWS.Glue.html#update_table/3","title":"AWS.Glue.update_table/3","type":"function","doc":"Updates a metadata table in the Data Catalog."},{"ref":"AWS.Glue.html#update_trigger/3","title":"AWS.Glue.update_trigger/3","type":"function","doc":"Updates a trigger definition."},{"ref":"AWS.Glue.html#update_user_defined_function/3","title":"AWS.Glue.update_user_defined_function/3","type":"function","doc":"Updates an existing function definition in the Data Catalog."},{"ref":"AWS.Glue.html#update_workflow/3","title":"AWS.Glue.update_workflow/3","type":"function","doc":"Updates an existing workflow."},{"ref":"AWS.Greengrass.html","title":"AWS.Greengrass","type":"module","doc":"AWS IoT Greengrass seamlessly extends AWS onto physical devices so they can act locally on the data they generate, while still using the cloud for management, analytics, and durable storage. AWS IoT Greengrass ensures your devices can respond quickly to local events and operate with intermittent connectivity. AWS IoT Greengrass minimizes the cost of transmitting data to the cloud by allowing you to author AWS Lambda functions that execute locally."},{"ref":"AWS.Greengrass.html#associate_role_to_group/4","title":"AWS.Greengrass.associate_role_to_group/4","type":"function","doc":"Associates a role with a group. Your Greengrass core will use the role to access AWS cloud services. The role&#39;s permissions should allow Greengrass core Lambda functions to perform actions against the cloud."},{"ref":"AWS.Greengrass.html#associate_service_role_to_account/3","title":"AWS.Greengrass.associate_service_role_to_account/3","type":"function","doc":"Associates a role with your account. AWS IoT Greengrass will use the role to access your Lambda functions and AWS IoT resources. This is necessary for deployments to succeed. The role must have at least minimum permissions in the policy &#39;&#39;AWSGreengrassResourceAccessRolePolicy&#39;&#39;."},{"ref":"AWS.Greengrass.html#create_connector_definition/3","title":"AWS.Greengrass.create_connector_definition/3","type":"function","doc":"Creates a connector definition. You may provide the initial version of the connector definition now or use &#39;&#39;CreateConnectorDefinitionVersion&#39;&#39; at a later time."},{"ref":"AWS.Greengrass.html#create_connector_definition_version/4","title":"AWS.Greengrass.create_connector_definition_version/4","type":"function","doc":"Creates a version of a connector definition which has already been defined."},{"ref":"AWS.Greengrass.html#create_core_definition/3","title":"AWS.Greengrass.create_core_definition/3","type":"function","doc":"Creates a core definition. You may provide the initial version of the core definition now or use &#39;&#39;CreateCoreDefinitionVersion&#39;&#39; at a later time. Greengrass groups must each contain exactly one Greengrass core."},{"ref":"AWS.Greengrass.html#create_core_definition_version/4","title":"AWS.Greengrass.create_core_definition_version/4","type":"function","doc":"Creates a version of a core definition that has already been defined. Greengrass groups must each contain exactly one Greengrass core."},{"ref":"AWS.Greengrass.html#create_deployment/4","title":"AWS.Greengrass.create_deployment/4","type":"function","doc":"Creates a deployment. &#39;&#39;CreateDeployment&#39;&#39; requests are idempotent with respect to the &#39;&#39;X-Amzn-Client-Token&#39;&#39; token and the request parameters."},{"ref":"AWS.Greengrass.html#create_device_definition/3","title":"AWS.Greengrass.create_device_definition/3","type":"function","doc":"Creates a device definition. You may provide the initial version of the device definition now or use &#39;&#39;CreateDeviceDefinitionVersion&#39;&#39; at a later time."},{"ref":"AWS.Greengrass.html#create_device_definition_version/4","title":"AWS.Greengrass.create_device_definition_version/4","type":"function","doc":"Creates a version of a device definition that has already been defined."},{"ref":"AWS.Greengrass.html#create_function_definition/3","title":"AWS.Greengrass.create_function_definition/3","type":"function","doc":"Creates a Lambda function definition which contains a list of Lambda functions and their configurations to be used in a group. You can create an initial version of the definition by providing a list of Lambda functions and their configurations now, or use &#39;&#39;CreateFunctionDefinitionVersion&#39;&#39; later."},{"ref":"AWS.Greengrass.html#create_function_definition_version/4","title":"AWS.Greengrass.create_function_definition_version/4","type":"function","doc":"Creates a version of a Lambda function definition that has already been defined."},{"ref":"AWS.Greengrass.html#create_group/3","title":"AWS.Greengrass.create_group/3","type":"function","doc":"Creates a group. You may provide the initial version of the group or use &#39;&#39;CreateGroupVersion&#39;&#39; at a later time. Tip: You can use the &#39;&#39;gg_group_setup&#39;&#39; package (https://github.com/awslabs/aws-greengrass-group-setup) as a library or command-line application to create and deploy Greengrass groups."},{"ref":"AWS.Greengrass.html#create_group_certificate_authority/4","title":"AWS.Greengrass.create_group_certificate_authority/4","type":"function","doc":"Creates a CA for the group. If a CA already exists, it will rotate the existing CA."},{"ref":"AWS.Greengrass.html#create_group_version/4","title":"AWS.Greengrass.create_group_version/4","type":"function","doc":"Creates a version of a group which has already been defined."},{"ref":"AWS.Greengrass.html#create_logger_definition/3","title":"AWS.Greengrass.create_logger_definition/3","type":"function","doc":"Creates a logger definition. You may provide the initial version of the logger definition now or use &#39;&#39;CreateLoggerDefinitionVersion&#39;&#39; at a later time."},{"ref":"AWS.Greengrass.html#create_logger_definition_version/4","title":"AWS.Greengrass.create_logger_definition_version/4","type":"function","doc":"Creates a version of a logger definition that has already been defined."},{"ref":"AWS.Greengrass.html#create_resource_definition/3","title":"AWS.Greengrass.create_resource_definition/3","type":"function","doc":"Creates a resource definition which contains a list of resources to be used in a group. You can create an initial version of the definition by providing a list of resources now, or use &#39;&#39;CreateResourceDefinitionVersion&#39;&#39; later."},{"ref":"AWS.Greengrass.html#create_resource_definition_version/4","title":"AWS.Greengrass.create_resource_definition_version/4","type":"function","doc":"Creates a version of a resource definition that has already been defined."},{"ref":"AWS.Greengrass.html#create_software_update_job/3","title":"AWS.Greengrass.create_software_update_job/3","type":"function","doc":"Creates a software update for a core or group of cores (specified as an IoT thing group.) Use this to update the OTA Agent as well as the Greengrass core software. It makes use of the IoT Jobs feature which provides additional commands to manage a Greengrass core software update job."},{"ref":"AWS.Greengrass.html#create_subscription_definition/3","title":"AWS.Greengrass.create_subscription_definition/3","type":"function","doc":"Creates a subscription definition. You may provide the initial version of the subscription definition now or use &#39;&#39;CreateSubscriptionDefinitionVersion&#39;&#39; at a later time."},{"ref":"AWS.Greengrass.html#create_subscription_definition_version/4","title":"AWS.Greengrass.create_subscription_definition_version/4","type":"function","doc":"Creates a version of a subscription definition which has already been defined."},{"ref":"AWS.Greengrass.html#delete_connector_definition/4","title":"AWS.Greengrass.delete_connector_definition/4","type":"function","doc":"Deletes a connector definition."},{"ref":"AWS.Greengrass.html#delete_core_definition/4","title":"AWS.Greengrass.delete_core_definition/4","type":"function","doc":"Deletes a core definition."},{"ref":"AWS.Greengrass.html#delete_device_definition/4","title":"AWS.Greengrass.delete_device_definition/4","type":"function","doc":"Deletes a device definition."},{"ref":"AWS.Greengrass.html#delete_function_definition/4","title":"AWS.Greengrass.delete_function_definition/4","type":"function","doc":"Deletes a Lambda function definition."},{"ref":"AWS.Greengrass.html#delete_group/4","title":"AWS.Greengrass.delete_group/4","type":"function","doc":"Deletes a group."},{"ref":"AWS.Greengrass.html#delete_logger_definition/4","title":"AWS.Greengrass.delete_logger_definition/4","type":"function","doc":"Deletes a logger definition."},{"ref":"AWS.Greengrass.html#delete_resource_definition/4","title":"AWS.Greengrass.delete_resource_definition/4","type":"function","doc":"Deletes a resource definition."},{"ref":"AWS.Greengrass.html#delete_subscription_definition/4","title":"AWS.Greengrass.delete_subscription_definition/4","type":"function","doc":"Deletes a subscription definition."},{"ref":"AWS.Greengrass.html#disassociate_role_from_group/4","title":"AWS.Greengrass.disassociate_role_from_group/4","type":"function","doc":"Disassociates the role from a group."},{"ref":"AWS.Greengrass.html#disassociate_service_role_from_account/3","title":"AWS.Greengrass.disassociate_service_role_from_account/3","type":"function","doc":"Disassociates the service role from your account. Without a service role, deployments will not work."},{"ref":"AWS.Greengrass.html#get_associated_role/3","title":"AWS.Greengrass.get_associated_role/3","type":"function","doc":"Retrieves the role associated with a particular group."},{"ref":"AWS.Greengrass.html#get_bulk_deployment_status/3","title":"AWS.Greengrass.get_bulk_deployment_status/3","type":"function","doc":"Returns the status of a bulk deployment."},{"ref":"AWS.Greengrass.html#get_connectivity_info/3","title":"AWS.Greengrass.get_connectivity_info/3","type":"function","doc":"Retrieves the connectivity information for a core."},{"ref":"AWS.Greengrass.html#get_connector_definition/3","title":"AWS.Greengrass.get_connector_definition/3","type":"function","doc":"Retrieves information about a connector definition."},{"ref":"AWS.Greengrass.html#get_connector_definition_version/5","title":"AWS.Greengrass.get_connector_definition_version/5","type":"function","doc":"Retrieves information about a connector definition version, including the connectors that the version contains. Connectors are prebuilt modules that interact with local infrastructure, device protocols, AWS, and other cloud services."},{"ref":"AWS.Greengrass.html#get_core_definition/3","title":"AWS.Greengrass.get_core_definition/3","type":"function","doc":"Retrieves information about a core definition version."},{"ref":"AWS.Greengrass.html#get_core_definition_version/4","title":"AWS.Greengrass.get_core_definition_version/4","type":"function","doc":"Retrieves information about a core definition version."},{"ref":"AWS.Greengrass.html#get_deployment_status/4","title":"AWS.Greengrass.get_deployment_status/4","type":"function","doc":"Returns the status of a deployment."},{"ref":"AWS.Greengrass.html#get_device_definition/3","title":"AWS.Greengrass.get_device_definition/3","type":"function","doc":"Retrieves information about a device definition."},{"ref":"AWS.Greengrass.html#get_device_definition_version/5","title":"AWS.Greengrass.get_device_definition_version/5","type":"function","doc":"Retrieves information about a device definition version."},{"ref":"AWS.Greengrass.html#get_function_definition/3","title":"AWS.Greengrass.get_function_definition/3","type":"function","doc":"Retrieves information about a Lambda function definition, including its creation time and latest version."},{"ref":"AWS.Greengrass.html#get_function_definition_version/5","title":"AWS.Greengrass.get_function_definition_version/5","type":"function","doc":"Retrieves information about a Lambda function definition version, including which Lambda functions are included in the version and their configurations."},{"ref":"AWS.Greengrass.html#get_group/3","title":"AWS.Greengrass.get_group/3","type":"function","doc":"Retrieves information about a group."},{"ref":"AWS.Greengrass.html#get_group_certificate_authority/4","title":"AWS.Greengrass.get_group_certificate_authority/4","type":"function","doc":"Retreives the CA associated with a group. Returns the public key of the CA."},{"ref":"AWS.Greengrass.html#get_group_certificate_configuration/3","title":"AWS.Greengrass.get_group_certificate_configuration/3","type":"function","doc":"Retrieves the current configuration for the CA used by the group."},{"ref":"AWS.Greengrass.html#get_group_version/4","title":"AWS.Greengrass.get_group_version/4","type":"function","doc":"Retrieves information about a group version."},{"ref":"AWS.Greengrass.html#get_logger_definition/3","title":"AWS.Greengrass.get_logger_definition/3","type":"function","doc":"Retrieves information about a logger definition."},{"ref":"AWS.Greengrass.html#get_logger_definition_version/5","title":"AWS.Greengrass.get_logger_definition_version/5","type":"function","doc":"Retrieves information about a logger definition version."},{"ref":"AWS.Greengrass.html#get_resource_definition/3","title":"AWS.Greengrass.get_resource_definition/3","type":"function","doc":"Retrieves information about a resource definition, including its creation time and latest version."},{"ref":"AWS.Greengrass.html#get_resource_definition_version/4","title":"AWS.Greengrass.get_resource_definition_version/4","type":"function","doc":"Retrieves information about a resource definition version, including which resources are included in the version."},{"ref":"AWS.Greengrass.html#get_service_role_for_account/2","title":"AWS.Greengrass.get_service_role_for_account/2","type":"function","doc":"Retrieves the service role that is attached to your account."},{"ref":"AWS.Greengrass.html#get_subscription_definition/3","title":"AWS.Greengrass.get_subscription_definition/3","type":"function","doc":"Retrieves information about a subscription definition."},{"ref":"AWS.Greengrass.html#get_subscription_definition_version/5","title":"AWS.Greengrass.get_subscription_definition_version/5","type":"function","doc":"Retrieves information about a subscription definition version."},{"ref":"AWS.Greengrass.html#get_thing_runtime_configuration/3","title":"AWS.Greengrass.get_thing_runtime_configuration/3","type":"function","doc":"Get the runtime configuration of a thing."},{"ref":"AWS.Greengrass.html#list_bulk_deployment_detailed_reports/5","title":"AWS.Greengrass.list_bulk_deployment_detailed_reports/5","type":"function","doc":"Gets a paginated list of the deployments that have been started in a bulk deployment operation, and their current deployment status."},{"ref":"AWS.Greengrass.html#list_bulk_deployments/4","title":"AWS.Greengrass.list_bulk_deployments/4","type":"function","doc":"Returns a list of bulk deployments."},{"ref":"AWS.Greengrass.html#list_connector_definition_versions/5","title":"AWS.Greengrass.list_connector_definition_versions/5","type":"function","doc":"Lists the versions of a connector definition, which are containers for connectors. Connectors run on the Greengrass core and contain built-in integration with local infrastructure, device protocols, AWS, and other cloud services."},{"ref":"AWS.Greengrass.html#list_connector_definitions/4","title":"AWS.Greengrass.list_connector_definitions/4","type":"function","doc":"Retrieves a list of connector definitions."},{"ref":"AWS.Greengrass.html#list_core_definition_versions/5","title":"AWS.Greengrass.list_core_definition_versions/5","type":"function","doc":"Lists the versions of a core definition."},{"ref":"AWS.Greengrass.html#list_core_definitions/4","title":"AWS.Greengrass.list_core_definitions/4","type":"function","doc":"Retrieves a list of core definitions."},{"ref":"AWS.Greengrass.html#list_deployments/5","title":"AWS.Greengrass.list_deployments/5","type":"function","doc":"Returns a history of deployments for the group."},{"ref":"AWS.Greengrass.html#list_device_definition_versions/5","title":"AWS.Greengrass.list_device_definition_versions/5","type":"function","doc":"Lists the versions of a device definition."},{"ref":"AWS.Greengrass.html#list_device_definitions/4","title":"AWS.Greengrass.list_device_definitions/4","type":"function","doc":"Retrieves a list of device definitions."},{"ref":"AWS.Greengrass.html#list_function_definition_versions/5","title":"AWS.Greengrass.list_function_definition_versions/5","type":"function","doc":"Lists the versions of a Lambda function definition."},{"ref":"AWS.Greengrass.html#list_function_definitions/4","title":"AWS.Greengrass.list_function_definitions/4","type":"function","doc":"Retrieves a list of Lambda function definitions."},{"ref":"AWS.Greengrass.html#list_group_certificate_authorities/3","title":"AWS.Greengrass.list_group_certificate_authorities/3","type":"function","doc":"Retrieves the current CAs for a group."},{"ref":"AWS.Greengrass.html#list_group_versions/5","title":"AWS.Greengrass.list_group_versions/5","type":"function","doc":"Lists the versions of a group."},{"ref":"AWS.Greengrass.html#list_groups/4","title":"AWS.Greengrass.list_groups/4","type":"function","doc":"Retrieves a list of groups."},{"ref":"AWS.Greengrass.html#list_logger_definition_versions/5","title":"AWS.Greengrass.list_logger_definition_versions/5","type":"function","doc":"Lists the versions of a logger definition."},{"ref":"AWS.Greengrass.html#list_logger_definitions/4","title":"AWS.Greengrass.list_logger_definitions/4","type":"function","doc":"Retrieves a list of logger definitions."},{"ref":"AWS.Greengrass.html#list_resource_definition_versions/5","title":"AWS.Greengrass.list_resource_definition_versions/5","type":"function","doc":"Lists the versions of a resource definition."},{"ref":"AWS.Greengrass.html#list_resource_definitions/4","title":"AWS.Greengrass.list_resource_definitions/4","type":"function","doc":"Retrieves a list of resource definitions."},{"ref":"AWS.Greengrass.html#list_subscription_definition_versions/5","title":"AWS.Greengrass.list_subscription_definition_versions/5","type":"function","doc":"Lists the versions of a subscription definition."},{"ref":"AWS.Greengrass.html#list_subscription_definitions/4","title":"AWS.Greengrass.list_subscription_definitions/4","type":"function","doc":"Retrieves a list of subscription definitions."},{"ref":"AWS.Greengrass.html#list_tags_for_resource/3","title":"AWS.Greengrass.list_tags_for_resource/3","type":"function","doc":"Retrieves a list of resource tags for a resource arn."},{"ref":"AWS.Greengrass.html#reset_deployments/4","title":"AWS.Greengrass.reset_deployments/4","type":"function","doc":"Resets a group&#39;s deployments."},{"ref":"AWS.Greengrass.html#start_bulk_deployment/3","title":"AWS.Greengrass.start_bulk_deployment/3","type":"function","doc":"Deploys multiple groups in one operation. This action starts the bulk deployment of a specified set of group versions. Each group version deployment will be triggered with an adaptive rate that has a fixed upper limit. We recommend that you include an &#39;&#39;X-Amzn-Client-Token&#39;&#39; token in every &#39;&#39;StartBulkDeployment&#39;&#39; request. These requests are idempotent with respect to the token and the request parameters."},{"ref":"AWS.Greengrass.html#stop_bulk_deployment/4","title":"AWS.Greengrass.stop_bulk_deployment/4","type":"function","doc":"Stops the execution of a bulk deployment. This action returns a status of &#39;&#39;Stopping&#39;&#39; until the deployment is stopped. You cannot start a new bulk deployment while a previous deployment is in the &#39;&#39;Stopping&#39;&#39; state. This action doesn&#39;t rollback completed deployments or cancel pending deployments."},{"ref":"AWS.Greengrass.html#tag_resource/4","title":"AWS.Greengrass.tag_resource/4","type":"function","doc":"Adds tags to a Greengrass resource. Valid resources are &#39;Group&#39;, &#39;ConnectorDefinition&#39;, &#39;CoreDefinition&#39;, &#39;DeviceDefinition&#39;, &#39;FunctionDefinition&#39;, &#39;LoggerDefinition&#39;, &#39;SubscriptionDefinition&#39;, &#39;ResourceDefinition&#39;, and &#39;BulkDeployment&#39;."},{"ref":"AWS.Greengrass.html#untag_resource/4","title":"AWS.Greengrass.untag_resource/4","type":"function","doc":"Remove resource tags from a Greengrass Resource."},{"ref":"AWS.Greengrass.html#update_connectivity_info/4","title":"AWS.Greengrass.update_connectivity_info/4","type":"function","doc":"Updates the connectivity information for the core. Any devices that belong to the group which has this core will receive this information in order to find the location of the core and connect to it."},{"ref":"AWS.Greengrass.html#update_connector_definition/4","title":"AWS.Greengrass.update_connector_definition/4","type":"function","doc":"Updates a connector definition."},{"ref":"AWS.Greengrass.html#update_core_definition/4","title":"AWS.Greengrass.update_core_definition/4","type":"function","doc":"Updates a core definition."},{"ref":"AWS.Greengrass.html#update_device_definition/4","title":"AWS.Greengrass.update_device_definition/4","type":"function","doc":"Updates a device definition."},{"ref":"AWS.Greengrass.html#update_function_definition/4","title":"AWS.Greengrass.update_function_definition/4","type":"function","doc":"Updates a Lambda function definition."},{"ref":"AWS.Greengrass.html#update_group/4","title":"AWS.Greengrass.update_group/4","type":"function","doc":"Updates a group."},{"ref":"AWS.Greengrass.html#update_group_certificate_configuration/4","title":"AWS.Greengrass.update_group_certificate_configuration/4","type":"function","doc":"Updates the Certificate expiry time for a group."},{"ref":"AWS.Greengrass.html#update_logger_definition/4","title":"AWS.Greengrass.update_logger_definition/4","type":"function","doc":"Updates a logger definition."},{"ref":"AWS.Greengrass.html#update_resource_definition/4","title":"AWS.Greengrass.update_resource_definition/4","type":"function","doc":"Updates a resource definition."},{"ref":"AWS.Greengrass.html#update_subscription_definition/4","title":"AWS.Greengrass.update_subscription_definition/4","type":"function","doc":"Updates a subscription definition."},{"ref":"AWS.Greengrass.html#update_thing_runtime_configuration/4","title":"AWS.Greengrass.update_thing_runtime_configuration/4","type":"function","doc":"Updates the runtime configuration of a thing."},{"ref":"AWS.GroundStation.html","title":"AWS.GroundStation","type":"module","doc":"Welcome to the AWS Ground Station API Reference. AWS Ground Station is a fully managed service that enables you to control satellite communications, downlink and process satellite data, and scale your satellite operations efficiently and cost-effectively without having to build or manage your own ground station infrastructure."},{"ref":"AWS.GroundStation.html#cancel_contact/4","title":"AWS.GroundStation.cancel_contact/4","type":"function","doc":"Cancels a contact with a specified contact ID."},{"ref":"AWS.GroundStation.html#create_config/3","title":"AWS.GroundStation.create_config/3","type":"function","doc":"Creates a Config with the specified configData parameters. Only one type of configData can be specified."},{"ref":"AWS.GroundStation.html#create_dataflow_endpoint_group/3","title":"AWS.GroundStation.create_dataflow_endpoint_group/3","type":"function","doc":"Creates a DataflowEndpoint group containing the specified list of DataflowEndpoint objects. The name field in each endpoint is used in your mission profile DataflowEndpointConfig to specify which endpoints to use during a contact. When a contact uses multiple DataflowEndpointConfig objects, each Config must match a DataflowEndpoint in the same group."},{"ref":"AWS.GroundStation.html#create_mission_profile/3","title":"AWS.GroundStation.create_mission_profile/3","type":"function","doc":"Creates a mission profile. dataflowEdges is a list of lists of strings. Each lower level list of strings has two elements: a from ARN and a to ARN."},{"ref":"AWS.GroundStation.html#delete_config/5","title":"AWS.GroundStation.delete_config/5","type":"function","doc":"Deletes a Config."},{"ref":"AWS.GroundStation.html#delete_dataflow_endpoint_group/4","title":"AWS.GroundStation.delete_dataflow_endpoint_group/4","type":"function","doc":"Deletes a dataflow endpoint group."},{"ref":"AWS.GroundStation.html#delete_mission_profile/4","title":"AWS.GroundStation.delete_mission_profile/4","type":"function","doc":"Deletes a mission profile."},{"ref":"AWS.GroundStation.html#describe_contact/3","title":"AWS.GroundStation.describe_contact/3","type":"function","doc":"Describes an existing contact."},{"ref":"AWS.GroundStation.html#get_config/4","title":"AWS.GroundStation.get_config/4","type":"function","doc":"Returns Config information. Only one Config response can be returned."},{"ref":"AWS.GroundStation.html#get_dataflow_endpoint_group/3","title":"AWS.GroundStation.get_dataflow_endpoint_group/3","type":"function","doc":"Returns the dataflow endpoint group."},{"ref":"AWS.GroundStation.html#get_minute_usage/3","title":"AWS.GroundStation.get_minute_usage/3","type":"function","doc":"Returns the number of minutes used by account."},{"ref":"AWS.GroundStation.html#get_mission_profile/3","title":"AWS.GroundStation.get_mission_profile/3","type":"function","doc":"Returns a mission profile."},{"ref":"AWS.GroundStation.html#get_satellite/3","title":"AWS.GroundStation.get_satellite/3","type":"function","doc":"Returns a satellite."},{"ref":"AWS.GroundStation.html#list_configs/4","title":"AWS.GroundStation.list_configs/4","type":"function","doc":"Returns a list of Config objects."},{"ref":"AWS.GroundStation.html#list_contacts/3","title":"AWS.GroundStation.list_contacts/3","type":"function","doc":"Returns a list of contacts. If statusList contains AVAILABLE, the request must include groundStation, missionprofileArn, and satelliteArn."},{"ref":"AWS.GroundStation.html#list_dataflow_endpoint_groups/4","title":"AWS.GroundStation.list_dataflow_endpoint_groups/4","type":"function","doc":"Returns a list of DataflowEndpoint groups."},{"ref":"AWS.GroundStation.html#list_ground_stations/5","title":"AWS.GroundStation.list_ground_stations/5","type":"function","doc":"Returns a list of ground stations."},{"ref":"AWS.GroundStation.html#list_mission_profiles/4","title":"AWS.GroundStation.list_mission_profiles/4","type":"function","doc":"Returns a list of mission profiles."},{"ref":"AWS.GroundStation.html#list_satellites/4","title":"AWS.GroundStation.list_satellites/4","type":"function","doc":"Returns a list of satellites."},{"ref":"AWS.GroundStation.html#list_tags_for_resource/3","title":"AWS.GroundStation.list_tags_for_resource/3","type":"function","doc":"Returns a list of tags for a specified resource."},{"ref":"AWS.GroundStation.html#reserve_contact/3","title":"AWS.GroundStation.reserve_contact/3","type":"function","doc":"Reserves a contact using specified parameters."},{"ref":"AWS.GroundStation.html#tag_resource/4","title":"AWS.GroundStation.tag_resource/4","type":"function","doc":"Assigns a tag to a resource."},{"ref":"AWS.GroundStation.html#untag_resource/4","title":"AWS.GroundStation.untag_resource/4","type":"function","doc":"Deassigns a resource tag."},{"ref":"AWS.GroundStation.html#update_config/5","title":"AWS.GroundStation.update_config/5","type":"function","doc":"Updates the Config used when scheduling contacts. Updating a Config will not update the execution parameters for existing future contacts scheduled with this Config."},{"ref":"AWS.GroundStation.html#update_mission_profile/4","title":"AWS.GroundStation.update_mission_profile/4","type":"function","doc":"Updates a mission profile. Updating a mission profile will not update the execution parameters for existing future contacts."},{"ref":"AWS.GuardDuty.html","title":"AWS.GuardDuty","type":"module","doc":"Amazon GuardDuty is a continuous security monitoring service that analyzes and processes the following data sources: VPC Flow Logs, AWS CloudTrail event logs, and DNS logs. It uses threat intelligence feeds (such as lists of malicious IPs and domains) and machine learning to identify unexpected, potentially unauthorized, and malicious activity within your AWS environment. This can include issues like escalations of privileges, uses of exposed credentials, or communication with malicious IPs, URLs, or domains. For example, GuardDuty can detect compromised EC2 instances that serve malware or mine bitcoin. GuardDuty also monitors AWS account access behavior for signs of compromise. Some examples of this are unauthorized infrastructure deployments such as EC2 instances deployed in a Region that has never been used, or unusual API calls like a password policy change to reduce password strength. GuardDuty informs you of the status of your AWS environment by producing security findings that you can view in the GuardDuty console or through Amazon CloudWatch events. For more information, see the Amazon GuardDuty User Guide ."},{"ref":"AWS.GuardDuty.html#accept_invitation/4","title":"AWS.GuardDuty.accept_invitation/4","type":"function","doc":"Accepts the invitation to be monitored by a master GuardDuty account."},{"ref":"AWS.GuardDuty.html#archive_findings/4","title":"AWS.GuardDuty.archive_findings/4","type":"function","doc":"Archives GuardDuty findings that are specified by the list of finding IDs. Only the master account can archive findings. Member accounts don&#39;t have permission to archive findings from their accounts."},{"ref":"AWS.GuardDuty.html#create_detector/3","title":"AWS.GuardDuty.create_detector/3","type":"function","doc":"Creates a single Amazon GuardDuty detector. A detector is a resource that represents the GuardDuty service. To start using GuardDuty, you must create a detector in each Region where you enable the service. You can have only one detector per account per Region. All data sources are enabled in a new detector by default."},{"ref":"AWS.GuardDuty.html#create_filter/4","title":"AWS.GuardDuty.create_filter/4","type":"function","doc":"Creates a filter using the specified finding criteria."},{"ref":"AWS.GuardDuty.html#create_i_p_set/4","title":"AWS.GuardDuty.create_i_p_set/4","type":"function","doc":"Creates a new IPSet, which is called a trusted IP list in the console user interface. An IPSet is a list of IP addresses that are trusted for secure communication with AWS infrastructure and applications. GuardDuty doesn&#39;t generate findings for IP addresses that are included in IPSets. Only users from the master account can use this operation."},{"ref":"AWS.GuardDuty.html#create_members/4","title":"AWS.GuardDuty.create_members/4","type":"function","doc":"Creates member accounts of the current AWS account by specifying a list of AWS account IDs. This step is a prerequisite for managing the associated member accounts either by invitation or through an organization. When using Create Members as an organizations delegated administrator this action will enable GuardDuty in the added member accounts, with the exception of the organization master account, which must enable GuardDuty prior to being added as a member. If you are adding accounts by invitation use this action after GuardDuty has been enabled in potential member accounts and before using Invite Members ."},{"ref":"AWS.GuardDuty.html#create_publishing_destination/4","title":"AWS.GuardDuty.create_publishing_destination/4","type":"function","doc":"Creates a publishing destination to export findings to. The resource to export findings to must exist before you use this operation."},{"ref":"AWS.GuardDuty.html#create_sample_findings/4","title":"AWS.GuardDuty.create_sample_findings/4","type":"function","doc":"Generates example findings of types specified by the list of finding types. If &#39;NULL&#39; is specified for findingTypes, the API generates example findings of all supported finding types."},{"ref":"AWS.GuardDuty.html#create_threat_intel_set/4","title":"AWS.GuardDuty.create_threat_intel_set/4","type":"function","doc":"Creates a new ThreatIntelSet. ThreatIntelSets consist of known malicious IP addresses. GuardDuty generates findings based on ThreatIntelSets. Only users of the master account can use this operation."},{"ref":"AWS.GuardDuty.html#decline_invitations/3","title":"AWS.GuardDuty.decline_invitations/3","type":"function","doc":"Declines invitations sent to the current member account by AWS accounts specified by their account IDs."},{"ref":"AWS.GuardDuty.html#delete_detector/4","title":"AWS.GuardDuty.delete_detector/4","type":"function","doc":"Deletes an Amazon GuardDuty detector that is specified by the detector ID."},{"ref":"AWS.GuardDuty.html#delete_filter/5","title":"AWS.GuardDuty.delete_filter/5","type":"function","doc":"Deletes the filter specified by the filter name."},{"ref":"AWS.GuardDuty.html#delete_i_p_set/5","title":"AWS.GuardDuty.delete_i_p_set/5","type":"function","doc":"Deletes the IPSet specified by the ipSetId. IPSets are called trusted IP lists in the console user interface."},{"ref":"AWS.GuardDuty.html#delete_invitations/3","title":"AWS.GuardDuty.delete_invitations/3","type":"function","doc":"Deletes invitations sent to the current member account by AWS accounts specified by their account IDs."},{"ref":"AWS.GuardDuty.html#delete_members/4","title":"AWS.GuardDuty.delete_members/4","type":"function","doc":"Deletes GuardDuty member accounts (to the current GuardDuty master account) specified by the account IDs."},{"ref":"AWS.GuardDuty.html#delete_publishing_destination/5","title":"AWS.GuardDuty.delete_publishing_destination/5","type":"function","doc":"Deletes the publishing definition with the specified destinationId."},{"ref":"AWS.GuardDuty.html#delete_threat_intel_set/5","title":"AWS.GuardDuty.delete_threat_intel_set/5","type":"function","doc":"Deletes the ThreatIntelSet specified by the ThreatIntelSet ID."},{"ref":"AWS.GuardDuty.html#describe_organization_configuration/3","title":"AWS.GuardDuty.describe_organization_configuration/3","type":"function","doc":"Returns information about the account selected as the delegated administrator for GuardDuty."},{"ref":"AWS.GuardDuty.html#describe_publishing_destination/4","title":"AWS.GuardDuty.describe_publishing_destination/4","type":"function","doc":"Returns information about the publishing destination specified by the provided destinationId."},{"ref":"AWS.GuardDuty.html#disable_organization_admin_account/3","title":"AWS.GuardDuty.disable_organization_admin_account/3","type":"function","doc":"Disables an AWS account within the Organization as the GuardDuty delegated administrator."},{"ref":"AWS.GuardDuty.html#disassociate_from_master_account/4","title":"AWS.GuardDuty.disassociate_from_master_account/4","type":"function","doc":"Disassociates the current GuardDuty member account from its master account."},{"ref":"AWS.GuardDuty.html#disassociate_members/4","title":"AWS.GuardDuty.disassociate_members/4","type":"function","doc":"Disassociates GuardDuty member accounts (to the current GuardDuty master account) specified by the account IDs."},{"ref":"AWS.GuardDuty.html#enable_organization_admin_account/3","title":"AWS.GuardDuty.enable_organization_admin_account/3","type":"function","doc":"Enables an AWS account within the organization as the GuardDuty delegated administrator."},{"ref":"AWS.GuardDuty.html#get_detector/3","title":"AWS.GuardDuty.get_detector/3","type":"function","doc":"Retrieves an Amazon GuardDuty detector specified by the detectorId."},{"ref":"AWS.GuardDuty.html#get_filter/4","title":"AWS.GuardDuty.get_filter/4","type":"function","doc":"Returns the details of the filter specified by the filter name."},{"ref":"AWS.GuardDuty.html#get_findings/4","title":"AWS.GuardDuty.get_findings/4","type":"function","doc":"Describes Amazon GuardDuty findings specified by finding IDs."},{"ref":"AWS.GuardDuty.html#get_findings_statistics/4","title":"AWS.GuardDuty.get_findings_statistics/4","type":"function","doc":"Lists Amazon GuardDuty findings statistics for the specified detector ID."},{"ref":"AWS.GuardDuty.html#get_i_p_set/4","title":"AWS.GuardDuty.get_i_p_set/4","type":"function","doc":"Retrieves the IPSet specified by the ipSetId."},{"ref":"AWS.GuardDuty.html#get_invitations_count/2","title":"AWS.GuardDuty.get_invitations_count/2","type":"function","doc":"Returns the count of all GuardDuty membership invitations that were sent to the current member account except the currently accepted invitation."},{"ref":"AWS.GuardDuty.html#get_master_account/3","title":"AWS.GuardDuty.get_master_account/3","type":"function","doc":"Provides the details for the GuardDuty master account associated with the current GuardDuty member account."},{"ref":"AWS.GuardDuty.html#get_member_detectors/4","title":"AWS.GuardDuty.get_member_detectors/4","type":"function","doc":"Describes which data sources are enabled for the member account&#39;s detector."},{"ref":"AWS.GuardDuty.html#get_members/4","title":"AWS.GuardDuty.get_members/4","type":"function","doc":"Retrieves GuardDuty member accounts (to the current GuardDuty master account) specified by the account IDs."},{"ref":"AWS.GuardDuty.html#get_threat_intel_set/4","title":"AWS.GuardDuty.get_threat_intel_set/4","type":"function","doc":"Retrieves the ThreatIntelSet that is specified by the ThreatIntelSet ID."},{"ref":"AWS.GuardDuty.html#get_usage_statistics/4","title":"AWS.GuardDuty.get_usage_statistics/4","type":"function","doc":"Lists Amazon GuardDuty usage statistics over the last 30 days for the specified detector ID. For newly enabled detectors or data sources the cost returned will include only the usage so far under 30 days, this may differ from the cost metrics in the console, which projects usage over 30 days to provide a monthly cost estimate. For more information see Understanding How Usage Costs are Calculated."},{"ref":"AWS.GuardDuty.html#invite_members/4","title":"AWS.GuardDuty.invite_members/4","type":"function","doc":"Invites other AWS accounts (created as members of the current AWS account by CreateMembers) to enable GuardDuty, and allow the current AWS account to view and manage these accounts&#39; GuardDuty findings on their behalf as the master account."},{"ref":"AWS.GuardDuty.html#list_detectors/4","title":"AWS.GuardDuty.list_detectors/4","type":"function","doc":"Lists detectorIds of all the existing Amazon GuardDuty detector resources."},{"ref":"AWS.GuardDuty.html#list_filters/5","title":"AWS.GuardDuty.list_filters/5","type":"function","doc":"Returns a paginated list of the current filters."},{"ref":"AWS.GuardDuty.html#list_findings/4","title":"AWS.GuardDuty.list_findings/4","type":"function","doc":"Lists Amazon GuardDuty findings for the specified detector ID."},{"ref":"AWS.GuardDuty.html#list_i_p_sets/5","title":"AWS.GuardDuty.list_i_p_sets/5","type":"function","doc":"Lists the IPSets of the GuardDuty service specified by the detector ID. If you use this operation from a member account, the IPSets returned are the IPSets from the associated master account."},{"ref":"AWS.GuardDuty.html#list_invitations/4","title":"AWS.GuardDuty.list_invitations/4","type":"function","doc":"Lists all GuardDuty membership invitations that were sent to the current AWS account."},{"ref":"AWS.GuardDuty.html#list_members/6","title":"AWS.GuardDuty.list_members/6","type":"function","doc":"Lists details about all member accounts for the current GuardDuty master account."},{"ref":"AWS.GuardDuty.html#list_organization_admin_accounts/4","title":"AWS.GuardDuty.list_organization_admin_accounts/4","type":"function","doc":"Lists the accounts configured as GuardDuty delegated administrators."},{"ref":"AWS.GuardDuty.html#list_publishing_destinations/5","title":"AWS.GuardDuty.list_publishing_destinations/5","type":"function","doc":"Returns a list of publishing destinations associated with the specified dectectorId."},{"ref":"AWS.GuardDuty.html#list_tags_for_resource/3","title":"AWS.GuardDuty.list_tags_for_resource/3","type":"function","doc":"Lists tags for a resource. Tagging is currently supported for detectors, finding filters, IP sets, and threat intel sets, with a limit of 50 tags per resource. When invoked, this operation returns all assigned tags for a given resource."},{"ref":"AWS.GuardDuty.html#list_threat_intel_sets/5","title":"AWS.GuardDuty.list_threat_intel_sets/5","type":"function","doc":"Lists the ThreatIntelSets of the GuardDuty service specified by the detector ID. If you use this operation from a member account, the ThreatIntelSets associated with the master account are returned."},{"ref":"AWS.GuardDuty.html#start_monitoring_members/4","title":"AWS.GuardDuty.start_monitoring_members/4","type":"function","doc":"Turns on GuardDuty monitoring of the specified member accounts. Use this operation to restart monitoring of accounts that you stopped monitoring with the StopMonitoringMembers operation."},{"ref":"AWS.GuardDuty.html#stop_monitoring_members/4","title":"AWS.GuardDuty.stop_monitoring_members/4","type":"function","doc":"Stops GuardDuty monitoring for the specified member accounts. Use the StartMonitoringMembers operation to restart monitoring for those accounts."},{"ref":"AWS.GuardDuty.html#tag_resource/4","title":"AWS.GuardDuty.tag_resource/4","type":"function","doc":"Adds tags to a resource."},{"ref":"AWS.GuardDuty.html#unarchive_findings/4","title":"AWS.GuardDuty.unarchive_findings/4","type":"function","doc":"Unarchives GuardDuty findings specified by the findingIds."},{"ref":"AWS.GuardDuty.html#untag_resource/4","title":"AWS.GuardDuty.untag_resource/4","type":"function","doc":"Removes tags from a resource."},{"ref":"AWS.GuardDuty.html#update_detector/4","title":"AWS.GuardDuty.update_detector/4","type":"function","doc":"Updates the Amazon GuardDuty detector specified by the detectorId."},{"ref":"AWS.GuardDuty.html#update_filter/5","title":"AWS.GuardDuty.update_filter/5","type":"function","doc":"Updates the filter specified by the filter name."},{"ref":"AWS.GuardDuty.html#update_findings_feedback/4","title":"AWS.GuardDuty.update_findings_feedback/4","type":"function","doc":"Marks the specified GuardDuty findings as useful or not useful."},{"ref":"AWS.GuardDuty.html#update_i_p_set/5","title":"AWS.GuardDuty.update_i_p_set/5","type":"function","doc":"Updates the IPSet specified by the IPSet ID."},{"ref":"AWS.GuardDuty.html#update_member_detectors/4","title":"AWS.GuardDuty.update_member_detectors/4","type":"function","doc":"Contains information on member accounts to be updated."},{"ref":"AWS.GuardDuty.html#update_organization_configuration/4","title":"AWS.GuardDuty.update_organization_configuration/4","type":"function","doc":"Updates the delegated administrator account with the values provided."},{"ref":"AWS.GuardDuty.html#update_publishing_destination/5","title":"AWS.GuardDuty.update_publishing_destination/5","type":"function","doc":"Updates information about the publishing destination specified by the destinationId."},{"ref":"AWS.GuardDuty.html#update_threat_intel_set/5","title":"AWS.GuardDuty.update_threat_intel_set/5","type":"function","doc":"Updates the ThreatIntelSet specified by the ThreatIntelSet ID."},{"ref":"AWS.Health.html","title":"AWS.Health","type":"module","doc":"AWS Health The AWS Health API provides programmatic access to the AWS Health information that appears in the AWS Personal Health Dashboard. You can use the API operations to get information about AWS Health events that affect your AWS services and resources. You must have a Business or Enterprise support plan from AWS Support to use the AWS Health API. If you call the AWS Health API from an AWS account that doesn&#39;t have a Business or Enterprise support plan, you receive a SubscriptionRequiredException error. AWS Health has a single endpoint: health.us-east-1.amazonaws.com (HTTPS). Use this endpoint to call the AWS Health API operations. For authentication of requests, AWS Health uses the Signature Version 4 Signing Process. If your AWS account is part of AWS Organizations, you can use the AWS Health organizational view feature. This feature provides a centralized view of AWS Health events across all accounts in your organization. You can aggregate AWS Health events in real time to identify accounts in your organization that are affected by an operational event or get notified of security vulnerabilities. Use the organizational view API operations to enable this feature and return event information. For more information, see Aggregating AWS Health events in the AWS Health User Guide. When you use the AWS Health API operations to return AWS Health events, see the following recommendations: Use the eventScopeCode parameter to specify whether to return AWS Health events that are public or account-specific. Use pagination to view all events from the response. For example, if you call the DescribeEventsForOrganization operation to get all events in your organization, you might receive several page results. Specify the nextToken in the next request to return more results."},{"ref":"AWS.Health.html#describe_affected_accounts_for_organization/3","title":"AWS.Health.describe_affected_accounts_for_organization/3","type":"function","doc":"Returns a list of accounts in the organization from AWS Organizations that are affected by the provided event. For more information about the different types of AWS Health events, see Event. Before you can call this operation, you must first enable AWS Health to work with AWS Organizations. To do this, call the EnableHealthServiceAccessForOrganization operation from your organization&#39;s master account. This API operation uses pagination. Specify the nextToken parameter in the next request to return more results."},{"ref":"AWS.Health.html#describe_affected_entities/3","title":"AWS.Health.describe_affected_entities/3","type":"function","doc":"Returns a list of entities that have been affected by the specified events, based on the specified filter criteria. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. Events that have impact beyond that of the affected entities, or where the extent of impact is unknown, include at least one entity indicating this. At least one event ARN is required. Results are sorted by the lastUpdatedTime of the entity, starting with the most recent. This API operation uses pagination. Specify the nextToken parameter in the next request to return more results."},{"ref":"AWS.Health.html#describe_affected_entities_for_organization/3","title":"AWS.Health.describe_affected_entities_for_organization/3","type":"function","doc":"Returns a list of entities that have been affected by one or more events for one or more accounts in your organization in AWS Organizations, based on the filter criteria. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. At least one event Amazon Resource Name (ARN) and account ID are required. Results are sorted by the lastUpdatedTime of the entity, starting with the most recent. Before you can call this operation, you must first enable AWS Health to work with AWS Organizations. To do this, call the EnableHealthServiceAccessForOrganization operation from your organization&#39;s master account. This API operation uses pagination. Specify the nextToken parameter in the next request to return more results."},{"ref":"AWS.Health.html#describe_entity_aggregates/3","title":"AWS.Health.describe_entity_aggregates/3","type":"function","doc":"Returns the number of entities that are affected by each of the specified events. If no events are specified, the counts of all affected entities are returned."},{"ref":"AWS.Health.html#describe_event_aggregates/3","title":"AWS.Health.describe_event_aggregates/3","type":"function","doc":"Returns the number of events of each event type (issue, scheduled change, and account notification). If no filter is specified, the counts of all events in each category are returned. This API operation uses pagination. Specify the nextToken parameter in the next request to return more results."},{"ref":"AWS.Health.html#describe_event_details/3","title":"AWS.Health.describe_event_details/3","type":"function","doc":"Returns detailed information about one or more specified events. Information includes standard event data (Region, service, and so on, as returned by DescribeEvents), a detailed event description, and possible additional metadata that depends upon the nature of the event. Affected entities are not included. To retrieve those, use the DescribeAffectedEntities operation. If a specified event cannot be retrieved, an error message is returned for that event."},{"ref":"AWS.Health.html#describe_event_details_for_organization/3","title":"AWS.Health.describe_event_details_for_organization/3","type":"function","doc":"Returns detailed information about one or more specified events for one or more accounts in your organization. Information includes standard event data (Region, service, and so on, as returned by DescribeEventsForOrganization), a detailed event description, and possible additional metadata that depends upon the nature of the event. Affected entities are not included; to retrieve those, use the DescribeAffectedEntitiesForOrganization operation. Before you can call this operation, you must first enable AWS Health to work with AWS Organizations. To do this, call the EnableHealthServiceAccessForOrganization operation from your organization&#39;s master account. When you call the DescribeEventDetailsForOrganization operation, you specify the organizationEventDetailFilters object in the request. Depending on the AWS Health event type, note the following differences: If the event is public, the awsAccountId parameter must be empty. If you specify an account ID for a public event, then an error message is returned. That&#39;s because the event might apply to all AWS accounts and isn&#39;t specific to an account in your organization. If the event is specific to an account, then you must specify the awsAccountId parameter in the request. If you don&#39;t specify an account ID, an error message returns because the event is specific to an AWS account in your organization. For more information, see Event."},{"ref":"AWS.Health.html#describe_event_types/3","title":"AWS.Health.describe_event_types/3","type":"function","doc":"Returns the event types that meet the specified filter criteria. If no filter criteria are specified, all event types are returned, in no particular order. This API operation uses pagination. Specify the nextToken parameter in the next request to return more results."},{"ref":"AWS.Health.html#describe_events/3","title":"AWS.Health.describe_events/3","type":"function","doc":"Returns information about events that meet the specified filter criteria. Events are returned in a summary form and do not include the detailed description, any additional metadata that depends on the event type, or any affected resources. To retrieve that information, use the DescribeEventDetails and DescribeAffectedEntities operations. If no filter criteria are specified, all events are returned. Results are sorted by lastModifiedTime, starting with the most recent event. When you call the DescribeEvents operation and specify an entity for the entityValues parameter, AWS Health might return public events that aren&#39;t specific to that resource. For example, if you call DescribeEvents and specify an ID for an Amazon Elastic Compute Cloud (Amazon EC2) instance, AWS Health might return events that aren&#39;t specific to that resource or service. To get events that are specific to a service, use the services parameter in the filter object. For more information, see Event. This API operation uses pagination. Specify the nextToken parameter in the next request to return more results."},{"ref":"AWS.Health.html#describe_events_for_organization/3","title":"AWS.Health.describe_events_for_organization/3","type":"function","doc":"Returns information about events across your organization in AWS Organizations. You can use thefilters parameter to specify the events that you want to return. Events are returned in a summary form and don&#39;t include the affected accounts, detailed description, any additional metadata that depends on the event type, or any affected resources. To retrieve that information, use the following operations: DescribeAffectedAccountsForOrganization DescribeEventDetailsForOrganization * DescribeAffectedEntitiesForOrganization If you don&#39;t specify a filter, the DescribeEventsForOrganizations returns all events across your organization. Results are sorted by lastModifiedTime, starting with the most recent event. For more information about the different types of AWS Health events, see Event. Before you can call this operation, you must first enable AWS Health to work with AWS Organizations. To do this, call the EnableHealthServiceAccessForOrganization operation from your organization&#39;s master AWS account. This API operation uses pagination. Specify the nextToken parameter in the next request to return more results."},{"ref":"AWS.Health.html#describe_health_service_status_for_organization/3","title":"AWS.Health.describe_health_service_status_for_organization/3","type":"function","doc":"This operation provides status information on enabling or disabling AWS Health to work with your organization. To call this operation, you must sign in as an IAM user, assume an IAM role, or sign in as the root user (not recommended) in the organization&#39;s master account."},{"ref":"AWS.Health.html#disable_health_service_access_for_organization/3","title":"AWS.Health.disable_health_service_access_for_organization/3","type":"function","doc":"Disables AWS Health from working with AWS Organizations. To call this operation, you must sign in as an AWS Identity and Access Management (IAM) user, assume an IAM role, or sign in as the root user (not recommended) in the organization&#39;s master AWS account. For more information, see Aggregating AWS Health events in the AWS Health User Guide. This operation doesn&#39;t remove the service-linked role (SLR) from the AWS master account in your organization. You must use the IAM console, API, or AWS Command Line Interface (AWS CLI) to remove the SLR. For more information, see Deleting a Service-Linked Role in the IAM User Guide. You can also disable the organizational feature by using the Organizations DisableAWSServiceAccess API operation. After you call this operation, AWS Health stops aggregating events for all other AWS accounts in your organization. If you call the AWS Health API operations for organizational view, AWS Health returns an error. AWS Health continues to aggregate health events for your AWS account."},{"ref":"AWS.Health.html#enable_health_service_access_for_organization/3","title":"AWS.Health.enable_health_service_access_for_organization/3","type":"function","doc":"Calling this operation enables AWS Health to work with AWS Organizations. This applies a service-linked role (SLR) to the master account in the organization. To call this operation, you must sign in as an IAM user, assume an IAM role, or sign in as the root user (not recommended) in the organization&#39;s master account. For more information, see Aggregating AWS Health events in the AWS Health User Guide."},{"ref":"AWS.Honeycode.html","title":"AWS.Honeycode","type":"module","doc":"Amazon Honeycode is a fully managed service that allows you to quickly build mobile and web apps for teamswithout programming. Build Honeycode apps for managing almost anything, like projects, customers, operations, approvals, resources, and even your team."},{"ref":"AWS.Honeycode.html#get_screen_data/3","title":"AWS.Honeycode.get_screen_data/3","type":"function","doc":"The GetScreenData API allows retrieval of data from a screen in a Honeycode app. The API allows setting local variables in the screen to filter, sort or otherwise affect what will be displayed on the screen."},{"ref":"AWS.Honeycode.html#invoke_screen_automation/7","title":"AWS.Honeycode.invoke_screen_automation/7","type":"function","doc":"The InvokeScreenAutomation API allows invoking an action defined in a screen in a Honeycode app. The API allows setting local variables, which can then be used in the automation being invoked. This allows automating the Honeycode app interactions to write, update or delete data in the workbook."},{"ref":"AWS.IAM.html","title":"AWS.IAM","type":"module","doc":"AWS Identity and Access Management AWS Identity and Access Management (IAM) is a web service for securely controlling access to AWS services. With IAM, you can centrally manage users, security credentials such as access keys, and permissions that control which AWS resources users and applications can access. For more information about IAM, see AWS Identity and Access Management (IAM) and the AWS Identity and Access Management User Guide."},{"ref":"AWS.IAM.html#add_client_i_d_to_open_i_d_connect_provider/3","title":"AWS.IAM.add_client_i_d_to_open_i_d_connect_provider/3","type":"function","doc":"Adds a new client ID (also known as audience) to the list of client IDs already registered for the specified IAM OpenID Connect (OIDC) provider resource. This operation is idempotent; it does not fail or return an error if you add an existing client ID to the provider."},{"ref":"AWS.IAM.html#add_role_to_instance_profile/3","title":"AWS.IAM.add_role_to_instance_profile/3","type":"function","doc":"Adds the specified IAM role to the specified instance profile. An instance profile can contain only one role. (The number and size of IAM resources in an AWS account are limited. For more information, see IAM and STS Quotas in the IAM User Guide.) You can remove the existing role and then add a different role to an instance profile. You must then wait for the change to appear across all of AWS because of eventual consistency. To force the change, you must disassociate the instance profile and then associate the instance profile, or you can stop your instance and then restart it. The caller of this API must be granted the PassRole permission on the IAM role by a permissions policy. For more information about roles, go to Working with Roles. For more information about instance profiles, go to About Instance Profiles."},{"ref":"AWS.IAM.html#add_user_to_group/3","title":"AWS.IAM.add_user_to_group/3","type":"function","doc":"Adds the specified user to the specified group."},{"ref":"AWS.IAM.html#attach_group_policy/3","title":"AWS.IAM.attach_group_policy/3","type":"function","doc":"Attaches the specified managed policy to the specified IAM group. You use this API to attach a managed policy to a group. To embed an inline policy in a group, use PutGroupPolicy. For more information about policies, see Managed Policies and Inline Policies in the IAM User Guide."},{"ref":"AWS.IAM.html#attach_role_policy/3","title":"AWS.IAM.attach_role_policy/3","type":"function","doc":"Attaches the specified managed policy to the specified IAM role. When you attach a managed policy to a role, the managed policy becomes part of the role&#39;s permission (access) policy. You cannot use a managed policy as the role&#39;s trust policy. The role&#39;s trust policy is created at the same time as the role, using CreateRole. You can update a role&#39;s trust policy using UpdateAssumeRolePolicy. Use this API to attach a managed policy to a role. To embed an inline policy in a role, use PutRolePolicy. For more information about policies, see Managed Policies and Inline Policies in the IAM User Guide."},{"ref":"AWS.IAM.html#attach_user_policy/3","title":"AWS.IAM.attach_user_policy/3","type":"function","doc":"Attaches the specified managed policy to the specified user. You use this API to attach a managed policy to a user. To embed an inline policy in a user, use PutUserPolicy. For more information about policies, see Managed Policies and Inline Policies in the IAM User Guide."},{"ref":"AWS.IAM.html#change_password/3","title":"AWS.IAM.change_password/3","type":"function","doc":"Changes the password of the IAM user who is calling this operation. The AWS account root user password is not affected by this operation. To change the password for a different user, see UpdateLoginProfile. For more information about modifying passwords, see Managing Passwords in the IAM User Guide."},{"ref":"AWS.IAM.html#create_access_key/3","title":"AWS.IAM.create_access_key/3","type":"function","doc":"Creates a new AWS secret access key and corresponding AWS access key ID for the specified user. The default status for new keys is Active. If you do not specify a user name, IAM determines the user name implicitly based on the AWS access key ID signing the request. This operation works for access keys under the AWS account. Consequently, you can use this operation to manage AWS account root user credentials. This is true even if the AWS account has no associated users. The number and size of IAM resources in an AWS account are limited. For more information, see IAM and STS Quotas in the IAM User Guide. To ensure the security of your AWS account, the secret access key is accessible only during key and user creation. You must save the key (for example, in a text file) if you want to be able to access it again. If a secret key is lost, you can delete the access keys for the associated user and then create new keys."},{"ref":"AWS.IAM.html#create_account_alias/3","title":"AWS.IAM.create_account_alias/3","type":"function","doc":"Creates an alias for your AWS account. For information about using an AWS account alias, see Using an Alias for Your AWS Account ID in the IAM User Guide."},{"ref":"AWS.IAM.html#create_group/3","title":"AWS.IAM.create_group/3","type":"function","doc":"Creates a new group. The number and size of IAM resources in an AWS account are limited. For more information, see IAM and STS Quotas in the IAM User Guide."},{"ref":"AWS.IAM.html#create_instance_profile/3","title":"AWS.IAM.create_instance_profile/3","type":"function","doc":"Creates a new instance profile. For information about instance profiles, go to About Instance Profiles. The number and size of IAM resources in an AWS account are limited. For more information, see IAM and STS Quotas in the IAM User Guide."},{"ref":"AWS.IAM.html#create_login_profile/3","title":"AWS.IAM.create_login_profile/3","type":"function","doc":"Creates a password for the specified user, giving the user the ability to access AWS services through the AWS Management Console. For more information about managing passwords, see Managing Passwords in the IAM User Guide."},{"ref":"AWS.IAM.html#create_open_i_d_connect_provider/3","title":"AWS.IAM.create_open_i_d_connect_provider/3","type":"function","doc":"Creates an IAM entity to describe an identity provider (IdP) that supports OpenID Connect (OIDC). The OIDC provider that you create with this operation can be used as a principal in a role&#39;s trust policy. Such a policy establishes a trust relationship between AWS and the OIDC provider. When you create the IAM OIDC provider, you specify the following: The URL of the OIDC identity provider (IdP) to trust A list of client IDs (also known as audiences) that identify the application or applications that are allowed to authenticate using the OIDC provider A list of thumbprints of one or more server certificates that the IdP uses You get all of this information from the OIDC IdP that you want to use to access AWS. The trust for the OIDC provider is derived from the IAM provider that this operation creates. Therefore, it is best to limit access to the CreateOpenIDConnectProvider operation to highly privileged users."},{"ref":"AWS.IAM.html#create_policy/3","title":"AWS.IAM.create_policy/3","type":"function","doc":"Creates a new managed policy for your AWS account. This operation creates a policy version with a version identifier of v1 and sets v1 as the policy&#39;s default version. For more information about policy versions, see Versioning for Managed Policies in the IAM User Guide. For more information about managed policies in general, see Managed Policies and Inline Policies in the IAM User Guide."},{"ref":"AWS.IAM.html#create_policy_version/3","title":"AWS.IAM.create_policy_version/3","type":"function","doc":"Creates a new version of the specified managed policy. To update a managed policy, you create a new policy version. A managed policy can have up to five versions. If the policy has five versions, you must delete an existing version using DeletePolicyVersion before you create a new version. Optionally, you can set the new version as the policy&#39;s default version. The default version is the version that is in effect for the IAM users, groups, and roles to which the policy is attached. For more information about managed policy versions, see Versioning for Managed Policies in the IAM User Guide."},{"ref":"AWS.IAM.html#create_role/3","title":"AWS.IAM.create_role/3","type":"function","doc":"Creates a new role for your AWS account. For more information about roles, go to IAM Roles. The number and size of IAM resources in an AWS account are limited. For more information, see IAM and STS Quotas in the IAM User Guide."},{"ref":"AWS.IAM.html#create_s_a_m_l_provider/3","title":"AWS.IAM.create_s_a_m_l_provider/3","type":"function","doc":"Creates an IAM resource that describes an identity provider (IdP) that supports SAML 2.0. The SAML provider resource that you create with this operation can be used as a principal in an IAM role&#39;s trust policy. Such a policy can enable federated users who sign in using the SAML IdP to assume the role. You can create an IAM role that supports Web-based single sign-on (SSO) to the AWS Management Console or one that supports API access to AWS. When you create the SAML provider resource, you upload a SAML metadata document that you get from your IdP. That document includes the issuer&#39;s name, expiration information, and keys that can be used to validate the SAML authentication response (assertions) that the IdP sends. You must generate the metadata document using the identity management software that is used as your organization&#39;s IdP. This operation requires Signature Version 4. For more information, see Enabling SAML 2.0 Federated Users to Access the AWS Management Console and About SAML 2.0-based Federation in the IAM User Guide."},{"ref":"AWS.IAM.html#create_service_linked_role/3","title":"AWS.IAM.create_service_linked_role/3","type":"function","doc":"Creates an IAM role that is linked to a specific AWS service. The service controls the attached policies and when the role can be deleted. This helps ensure that the service is not broken by an unexpectedly changed or deleted role, which could put your AWS resources into an unknown state. Allowing the service to control the role helps improve service stability and proper cleanup when a service and its role are no longer needed. For more information, see Using Service-Linked Roles in the IAM User Guide. To attach a policy to this service-linked role, you must make the request using the AWS service that depends on this role."},{"ref":"AWS.IAM.html#create_service_specific_credential/3","title":"AWS.IAM.create_service_specific_credential/3","type":"function","doc":"Generates a set of credentials consisting of a user name and password that can be used to access the service specified in the request. These credentials are generated by IAM, and can be used only for the specified service. You can have a maximum of two sets of service-specific credentials for each supported service per user. The only supported service at this time is AWS CodeCommit. You can reset the password to a new service-generated value by calling ResetServiceSpecificCredential. For more information about service-specific credentials, see Using IAM with AWS CodeCommit: Git Credentials, SSH Keys, and AWS Access Keys in the IAM User Guide."},{"ref":"AWS.IAM.html#create_user/3","title":"AWS.IAM.create_user/3","type":"function","doc":"Creates a new IAM user for your AWS account. The number and size of IAM resources in an AWS account are limited. For more information, see IAM and STS Quotas in the IAM User Guide."},{"ref":"AWS.IAM.html#create_virtual_m_f_a_device/3","title":"AWS.IAM.create_virtual_m_f_a_device/3","type":"function","doc":"Creates a new virtual MFA device for the AWS account. After creating the virtual MFA, use EnableMFADevice to attach the MFA device to an IAM user. For more information about creating and working with virtual MFA devices, go to Using a Virtual MFA Device in the IAM User Guide. The number and size of IAM resources in an AWS account are limited. For more information, see IAM and STS Quotas in the IAM User Guide. The seed information contained in the QR code and the Base32 string should be treated like any other secret access information. In other words, protect the seed information as you would your AWS access keys or your passwords. After you provision your virtual device, you should ensure that the information is destroyed following secure procedures."},{"ref":"AWS.IAM.html#deactivate_m_f_a_device/3","title":"AWS.IAM.deactivate_m_f_a_device/3","type":"function","doc":"Deactivates the specified MFA device and removes it from association with the user name for which it was originally enabled. For more information about creating and working with virtual MFA devices, go to Enabling a Virtual Multi-factor Authentication (MFA) Device in the IAM User Guide."},{"ref":"AWS.IAM.html#delete_access_key/3","title":"AWS.IAM.delete_access_key/3","type":"function","doc":"Deletes the access key pair associated with the specified IAM user. If you do not specify a user name, IAM determines the user name implicitly based on the AWS access key ID signing the request. This operation works for access keys under the AWS account. Consequently, you can use this operation to manage AWS account root user credentials even if the AWS account has no associated users."},{"ref":"AWS.IAM.html#delete_account_alias/3","title":"AWS.IAM.delete_account_alias/3","type":"function","doc":"Deletes the specified AWS account alias. For information about using an AWS account alias, see Using an Alias for Your AWS Account ID in the IAM User Guide."},{"ref":"AWS.IAM.html#delete_account_password_policy/3","title":"AWS.IAM.delete_account_password_policy/3","type":"function","doc":"Deletes the password policy for the AWS account. There are no parameters."},{"ref":"AWS.IAM.html#delete_group/3","title":"AWS.IAM.delete_group/3","type":"function","doc":"Deletes the specified IAM group. The group must not contain any users or have any attached policies."},{"ref":"AWS.IAM.html#delete_group_policy/3","title":"AWS.IAM.delete_group_policy/3","type":"function","doc":"Deletes the specified inline policy that is embedded in the specified IAM group. A group can also have managed policies attached to it. To detach a managed policy from a group, use DetachGroupPolicy. For more information about policies, refer to Managed Policies and Inline Policies in the IAM User Guide."},{"ref":"AWS.IAM.html#delete_instance_profile/3","title":"AWS.IAM.delete_instance_profile/3","type":"function","doc":"Deletes the specified instance profile. The instance profile must not have an associated role. Make sure that you do not have any Amazon EC2 instances running with the instance profile you are about to delete. Deleting a role or instance profile that is associated with a running instance will break any applications running on the instance. For more information about instance profiles, go to About Instance Profiles."},{"ref":"AWS.IAM.html#delete_login_profile/3","title":"AWS.IAM.delete_login_profile/3","type":"function","doc":"Deletes the password for the specified IAM user, which terminates the user&#39;s ability to access AWS services through the AWS Management Console. Deleting a user&#39;s password does not prevent a user from accessing AWS through the command line interface or the API. To prevent all user access, you must also either make any access keys inactive or delete them. For more information about making keys inactive or deleting them, see UpdateAccessKey and DeleteAccessKey."},{"ref":"AWS.IAM.html#delete_open_i_d_connect_provider/3","title":"AWS.IAM.delete_open_i_d_connect_provider/3","type":"function","doc":"Deletes an OpenID Connect identity provider (IdP) resource object in IAM. Deleting an IAM OIDC provider resource does not update any roles that reference the provider as a principal in their trust policies. Any attempt to assume a role that references a deleted provider fails. This operation is idempotent; it does not fail or return an error if you call the operation for a provider that does not exist."},{"ref":"AWS.IAM.html#delete_policy/3","title":"AWS.IAM.delete_policy/3","type":"function","doc":"Deletes the specified managed policy. Before you can delete a managed policy, you must first detach the policy from all users, groups, and roles that it is attached to. In addition, you must delete all the policy&#39;s versions. The following steps describe the process for deleting a managed policy: Detach the policy from all users, groups, and roles that the policy is attached to, using the DetachUserPolicy, DetachGroupPolicy, or DetachRolePolicy API operations. To list all the users, groups, and roles that a policy is attached to, use ListEntitiesForPolicy. Delete all versions of the policy using DeletePolicyVersion. To list the policy&#39;s versions, use ListPolicyVersions. You cannot use DeletePolicyVersion to delete the version that is marked as the default version. You delete the policy&#39;s default version in the next step of the process. Delete the policy (this automatically deletes the policy&#39;s default version) using this API. For information about managed policies, see Managed Policies and Inline Policies in the IAM User Guide."},{"ref":"AWS.IAM.html#delete_policy_version/3","title":"AWS.IAM.delete_policy_version/3","type":"function","doc":"Deletes the specified version from the specified managed policy. You cannot delete the default version from a policy using this API. To delete the default version from a policy, use DeletePolicy. To find out which version of a policy is marked as the default version, use ListPolicyVersions. For information about versions for managed policies, see Versioning for Managed Policies in the IAM User Guide."},{"ref":"AWS.IAM.html#delete_role/3","title":"AWS.IAM.delete_role/3","type":"function","doc":"Deletes the specified role. The role must not have any policies attached. For more information about roles, go to Working with Roles. Make sure that you do not have any Amazon EC2 instances running with the role you are about to delete. Deleting a role or instance profile that is associated with a running instance will break any applications running on the instance."},{"ref":"AWS.IAM.html#delete_role_permissions_boundary/3","title":"AWS.IAM.delete_role_permissions_boundary/3","type":"function","doc":"Deletes the permissions boundary for the specified IAM role. Deleting the permissions boundary for a role might increase its permissions. For example, it might allow anyone who assumes the role to perform all the actions granted in its permissions policies."},{"ref":"AWS.IAM.html#delete_role_policy/3","title":"AWS.IAM.delete_role_policy/3","type":"function","doc":"Deletes the specified inline policy that is embedded in the specified IAM role. A role can also have managed policies attached to it. To detach a managed policy from a role, use DetachRolePolicy. For more information about policies, refer to Managed Policies and Inline Policies in the IAM User Guide."},{"ref":"AWS.IAM.html#delete_s_a_m_l_provider/3","title":"AWS.IAM.delete_s_a_m_l_provider/3","type":"function","doc":"Deletes a SAML provider resource in IAM. Deleting the provider resource from IAM does not update any roles that reference the SAML provider resource&#39;s ARN as a principal in their trust policies. Any attempt to assume a role that references a non-existent provider resource ARN fails. This operation requires Signature Version 4."},{"ref":"AWS.IAM.html#delete_s_s_h_public_key/3","title":"AWS.IAM.delete_s_s_h_public_key/3","type":"function","doc":"Deletes the specified SSH public key. The SSH public key deleted by this operation is used only for authenticating the associated IAM user to an AWS CodeCommit repository. For more information about using SSH keys to authenticate to an AWS CodeCommit repository, see Set up AWS CodeCommit for SSH Connections in the AWS CodeCommit User Guide."},{"ref":"AWS.IAM.html#delete_server_certificate/3","title":"AWS.IAM.delete_server_certificate/3","type":"function","doc":"Deletes the specified server certificate. For more information about working with server certificates, see Working with Server Certificates in the IAM User Guide. This topic also includes a list of AWS services that can use the server certificates that you manage with IAM. If you are using a server certificate with Elastic Load Balancing, deleting the certificate could have implications for your application. If Elastic Load Balancing doesn&#39;t detect the deletion of bound certificates, it may continue to use the certificates. This could cause Elastic Load Balancing to stop accepting traffic. We recommend that you remove the reference to the certificate from Elastic Load Balancing before using this command to delete the certificate. For more information, go to DeleteLoadBalancerListeners in the Elastic Load Balancing API Reference."},{"ref":"AWS.IAM.html#delete_service_linked_role/3","title":"AWS.IAM.delete_service_linked_role/3","type":"function","doc":"Submits a service-linked role deletion request and returns a DeletionTaskId, which you can use to check the status of the deletion. Before you call this operation, confirm that the role has no active sessions and that any resources used by the role in the linked service are deleted. If you call this operation more than once for the same service-linked role and an earlier deletion task is not complete, then the DeletionTaskId of the earlier request is returned. If you submit a deletion request for a service-linked role whose linked service is still accessing a resource, then the deletion task fails. If it fails, the GetServiceLinkedRoleDeletionStatus API operation returns the reason for the failure, usually including the resources that must be deleted. To delete the service-linked role, you must first remove those resources from the linked service and then submit the deletion request again. Resources are specific to the service that is linked to the role. For more information about removing resources from a service, see the AWS documentation for your service. For more information about service-linked roles, see Roles Terms and Concepts: AWS Service-Linked Role in the IAM User Guide."},{"ref":"AWS.IAM.html#delete_service_specific_credential/3","title":"AWS.IAM.delete_service_specific_credential/3","type":"function","doc":"Deletes the specified service-specific credential."},{"ref":"AWS.IAM.html#delete_signing_certificate/3","title":"AWS.IAM.delete_signing_certificate/3","type":"function","doc":"Deletes a signing certificate associated with the specified IAM user. If you do not specify a user name, IAM determines the user name implicitly based on the AWS access key ID signing the request. This operation works for access keys under the AWS account. Consequently, you can use this operation to manage AWS account root user credentials even if the AWS account has no associated IAM users."},{"ref":"AWS.IAM.html#delete_user/3","title":"AWS.IAM.delete_user/3","type":"function","doc":"Deletes the specified IAM user. Unlike the AWS Management Console, when you delete a user programmatically, you must delete the items attached to the user manually, or the deletion fails. For more information, see Deleting an IAM User. Before attempting to delete a user, remove the following items: Password (DeleteLoginProfile) Access keys (DeleteAccessKey) Signing certificate (DeleteSigningCertificate) SSH public key (DeleteSSHPublicKey) Git credentials (DeleteServiceSpecificCredential) Multi-factor authentication (MFA) device (DeactivateMFADevice, DeleteVirtualMFADevice) Inline policies (DeleteUserPolicy) Attached managed policies (DetachUserPolicy) Group memberships (RemoveUserFromGroup)"},{"ref":"AWS.IAM.html#delete_user_permissions_boundary/3","title":"AWS.IAM.delete_user_permissions_boundary/3","type":"function","doc":"Deletes the permissions boundary for the specified IAM user. Deleting the permissions boundary for a user might increase its permissions by allowing the user to perform all the actions granted in its permissions policies."},{"ref":"AWS.IAM.html#delete_user_policy/3","title":"AWS.IAM.delete_user_policy/3","type":"function","doc":"Deletes the specified inline policy that is embedded in the specified IAM user. A user can also have managed policies attached to it. To detach a managed policy from a user, use DetachUserPolicy. For more information about policies, refer to Managed Policies and Inline Policies in the IAM User Guide."},{"ref":"AWS.IAM.html#delete_virtual_m_f_a_device/3","title":"AWS.IAM.delete_virtual_m_f_a_device/3","type":"function","doc":"Deletes a virtual MFA device. You must deactivate a user&#39;s virtual MFA device before you can delete it. For information about deactivating MFA devices, see DeactivateMFADevice."},{"ref":"AWS.IAM.html#detach_group_policy/3","title":"AWS.IAM.detach_group_policy/3","type":"function","doc":"Removes the specified managed policy from the specified IAM group. A group can also have inline policies embedded with it. To delete an inline policy, use the DeleteGroupPolicy API. For information about policies, see Managed Policies and Inline Policies in the IAM User Guide."},{"ref":"AWS.IAM.html#detach_role_policy/3","title":"AWS.IAM.detach_role_policy/3","type":"function","doc":"Removes the specified managed policy from the specified role. A role can also have inline policies embedded with it. To delete an inline policy, use the DeleteRolePolicy API. For information about policies, see Managed Policies and Inline Policies in the IAM User Guide."},{"ref":"AWS.IAM.html#detach_user_policy/3","title":"AWS.IAM.detach_user_policy/3","type":"function","doc":"Removes the specified managed policy from the specified user. A user can also have inline policies embedded with it. To delete an inline policy, use the DeleteUserPolicy API. For information about policies, see Managed Policies and Inline Policies in the IAM User Guide."},{"ref":"AWS.IAM.html#enable_m_f_a_device/3","title":"AWS.IAM.enable_m_f_a_device/3","type":"function","doc":"Enables the specified MFA device and associates it with the specified IAM user. When enabled, the MFA device is required for every subsequent login by the IAM user associated with the device."},{"ref":"AWS.IAM.html#generate_credential_report/3","title":"AWS.IAM.generate_credential_report/3","type":"function","doc":"Generates a credential report for the AWS account. For more information about the credential report, see Getting Credential Reports in the IAM User Guide."},{"ref":"AWS.IAM.html#generate_organizations_access_report/3","title":"AWS.IAM.generate_organizations_access_report/3","type":"function","doc":"Generates a report for service last accessed data for AWS Organizations. You can generate a report for any entities (organization root, organizational unit, or account) or policies in your organization. To call this operation, you must be signed in using your AWS Organizations master account credentials. You can use your long-term IAM user or root user credentials, or temporary credentials from assuming an IAM role. SCPs must be enabled for your organization root. You must have the required IAM and AWS Organizations permissions. For more information, see Refining Permissions Using Service Last Accessed Data in the IAM User Guide. You can generate a service last accessed data report for entities by specifying only the entity&#39;s path. This data includes a list of services that are allowed by any service control policies (SCPs) that apply to the entity. You can generate a service last accessed data report for a policy by specifying an entity&#39;s path and an optional AWS Organizations policy ID. This data includes a list of services that are allowed by the specified SCP. For each service in both report types, the data includes the most recent account activity that the policy allows to account principals in the entity or the entity&#39;s children. For important information about the data, reporting period, permissions required, troubleshooting, and supported Regions see Reducing Permissions Using Service Last Accessed Data in the IAM User Guide. The data includesallattempts to access AWS, not just the successful ones. This includes all attempts that were made using the AWS Management Console, the AWS API through any of the SDKs, or any of the command line tools. An unexpected entry in the service last accessed data does not mean that an account has been compromised, because the request might have been denied. Refer to your CloudTrail logs as the authoritative source for information about all API calls and whether they were successful or denied access. For more information, seeLogging IAM Events with CloudTrail in the IAM User Guide. This operation returns a JobId. Use this parameter in the GetOrganizationsAccessReport operation to check the status of the report generation. To check the status of this request, use the JobId parameter in the GetOrganizationsAccessReport operation and test the JobStatus response parameter. When the job is complete, you can retrieve the report. To generate a service last accessed data report for entities, specify an entity path without specifying the optional AWS Organizations policy ID. The type of entity that you specify determines the data returned in the report. Root  When you specify the organizations root as the entity, the resulting report lists all of the services allowed by SCPs that are attached to your root. For each service, the report includes data for all accounts in your organization except the master account, because the master account is not limited by SCPs. OU  When you specify an organizational unit (OU) as the entity, the resulting report lists all of the services allowed by SCPs that are attached to the OU and its parents. For each service, the report includes data for all accounts in the OU or its children. This data excludes the master account, because the master account is not limited by SCPs. Master account  When you specify the master account, the resulting report lists all AWS services, because the master account is not limited by SCPs. For each service, the report includes data for only the master account. Account  When you specify another account as the entity, the resulting report lists all of the services allowed by SCPs that are attached to the account and its parents. For each service, the report includes data for only the specified account. To generate a service last accessed data report for policies, specify an entity path and the optional AWS Organizations policy ID. The type of entity that you specify determines the data returned for each service. Root  When you specify the root entity and a policy ID, the resulting report lists all of the services that are allowed by the specified SCP. For each service, the report includes data for all accounts in your organization to which the SCP applies. This data excludes the master account, because the master account is not limited by SCPs. If the SCP is not attached to any entities in the organization, then the report will return a list of services with no data. OU  When you specify an OU entity and a policy ID, the resulting report lists all of the services that are allowed by the specified SCP. For each service, the report includes data for all accounts in the OU or its children to which the SCP applies. This means that other accounts outside the OU that are affected by the SCP might not be included in the data. This data excludes the master account, because the master account is not limited by SCPs. If the SCP is not attached to the OU or one of its children, the report will return a list of services with no data. Master account  When you specify the master account, the resulting report lists all AWS services, because the master account is not limited by SCPs. If you specify a policy ID in the CLI or API, the policy is ignored. For each service, the report includes data for only the master account. Account  When you specify another account entity and a policy ID, the resulting report lists all of the services that are allowed by the specified SCP. For each service, the report includes data for only the specified account. This means that other accounts in the organization that are affected by the SCP might not be included in the data. If the SCP is not attached to the account, the report will return a list of services with no data. Service last accessed data does not use other policy types when determining whether a principal could access a service. These other policy types include identity-based policies, resource-based policies, access control lists, IAM permissions boundaries, and STS assume role policies. It only applies SCP logic. For more about the evaluation of policy types, see Evaluating Policies in the IAM User Guide. For more information about service last accessed data, see Reducing Policy Scope by Viewing User Activity in the IAM User Guide."},{"ref":"AWS.IAM.html#generate_service_last_accessed_details/3","title":"AWS.IAM.generate_service_last_accessed_details/3","type":"function","doc":"Generates a report that includes details about when an IAM resource (user, group, role, or policy) was last used in an attempt to access AWS services. Recent activity usually appears within four hours. IAM reports activity for the last 365 days, or less if your Region began supporting this feature within the last year. For more information, see Regions Where Data Is Tracked. The service last accessed data includesallattempts to access an AWS API, not just the successful ones. This includes all attempts that were made using the AWS Management Console, the AWS API through any of the SDKs, or any of the command line tools. An unexpected entry in the service last accessed data does not mean that your account has been compromised, because the request might have been denied. Refer to your CloudTrail logs as the authoritative source for information about all API calls and whether they were successful or denied access. For more information, seeLogging IAM Events with CloudTrail in the IAM User Guide. The GenerateServiceLastAccessedDetails operation returns a JobId. Use this parameter in the following operations to retrieve the following details from your report: GetServiceLastAccessedDetails  Use this operation for users, groups, roles, or policies to list every AWS service that the resource could access using permissions policies. For each service, the response includes information about the most recent access attempt. The JobId returned by GenerateServiceLastAccessedDetail must be used by the same role within a session, or by the same user when used to call GetServiceLastAccessedDetail. GetServiceLastAccessedDetailsWithEntities  Use this operation for groups and policies to list information about the associated entities (users or roles) that attempted to access a specific AWS service. To check the status of the GenerateServiceLastAccessedDetails request, use the JobId parameter in the same operations and test the JobStatus response parameter. For additional information about the permissions policies that allow an identity (user, group, or role) to access specific services, use the ListPoliciesGrantingServiceAccess operation. Service last accessed data does not use other policy types when determining whether a resource could access a service. These other policy types include resource-based policies, access control lists, AWS Organizations policies, IAM permissions boundaries, and AWS STS assume role policies. It only applies permissions policy logic. For more about the evaluation of policy types, see Evaluating Policies in the IAM User Guide. For more information about service and action last accessed data, see Reducing Permissions Using Service Last Accessed Data in the IAM User Guide."},{"ref":"AWS.IAM.html#get_access_key_last_used/3","title":"AWS.IAM.get_access_key_last_used/3","type":"function","doc":"Retrieves information about when the specified access key was last used. The information includes the date and time of last use, along with the AWS service and Region that were specified in the last request made with that key."},{"ref":"AWS.IAM.html#get_account_authorization_details/3","title":"AWS.IAM.get_account_authorization_details/3","type":"function","doc":"Retrieves information about all IAM users, groups, roles, and policies in your AWS account, including their relationships to one another. Use this API to obtain a snapshot of the configuration of IAM permissions (users, groups, roles, and policies) in your account. Policies returned by this API are URL-encoded compliant with RFC 3986. You can use a URL decoding method to convert the policy back to plain JSON text. For example, if you use Java, you can use the decode method of the java.net.URLDecoder utility class in the Java SDK. Other languages and SDKs provide similar functionality. You can optionally filter the results using the Filter parameter. You can paginate the results using the MaxItems and Marker parameters."},{"ref":"AWS.IAM.html#get_account_password_policy/3","title":"AWS.IAM.get_account_password_policy/3","type":"function","doc":"Retrieves the password policy for the AWS account. For more information about using a password policy, go to Managing an IAM Password Policy."},{"ref":"AWS.IAM.html#get_account_summary/3","title":"AWS.IAM.get_account_summary/3","type":"function","doc":"Retrieves information about IAM entity usage and IAM quotas in the AWS account. The number and size of IAM resources in an AWS account are limited. For more information, see IAM and STS Quotas in the IAM User Guide."},{"ref":"AWS.IAM.html#get_context_keys_for_custom_policy/3","title":"AWS.IAM.get_context_keys_for_custom_policy/3","type":"function","doc":"Gets a list of all of the context keys referenced in the input policies. The policies are supplied as a list of one or more strings. To get the context keys from policies associated with an IAM user, group, or role, use GetContextKeysForPrincipalPolicy. Context keys are variables maintained by AWS and its services that provide details about the context of an API query request. Context keys can be evaluated by testing against a value specified in an IAM policy. Use GetContextKeysForCustomPolicy to understand what key names and values you must supply when you call SimulateCustomPolicy. Note that all parameters are shown in unencoded form here for clarity but must be URL encoded to be included as a part of a real HTML request."},{"ref":"AWS.IAM.html#get_context_keys_for_principal_policy/3","title":"AWS.IAM.get_context_keys_for_principal_policy/3","type":"function","doc":"Gets a list of all of the context keys referenced in all the IAM policies that are attached to the specified IAM entity. The entity can be an IAM user, group, or role. If you specify a user, then the request also includes all of the policies attached to groups that the user is a member of. You can optionally include a list of one or more additional policies, specified as strings. If you want to include only a list of policies by string, use GetContextKeysForCustomPolicy instead. Note: This API discloses information about the permissions granted to other users. If you do not want users to see other user&#39;s permissions, then consider allowing them to use GetContextKeysForCustomPolicy instead. Context keys are variables maintained by AWS and its services that provide details about the context of an API query request. Context keys can be evaluated by testing against a value in an IAM policy. Use GetContextKeysForPrincipalPolicy to understand what key names and values you must supply when you call SimulatePrincipalPolicy."},{"ref":"AWS.IAM.html#get_credential_report/3","title":"AWS.IAM.get_credential_report/3","type":"function","doc":"Retrieves a credential report for the AWS account. For more information about the credential report, see Getting Credential Reports in the IAM User Guide."},{"ref":"AWS.IAM.html#get_group/3","title":"AWS.IAM.get_group/3","type":"function","doc":"Returns a list of IAM users that are in the specified IAM group. You can paginate the results using the MaxItems and Marker parameters."},{"ref":"AWS.IAM.html#get_group_policy/3","title":"AWS.IAM.get_group_policy/3","type":"function","doc":"Retrieves the specified inline policy document that is embedded in the specified IAM group. Policies returned by this API are URL-encoded compliant with RFC 3986. You can use a URL decoding method to convert the policy back to plain JSON text. For example, if you use Java, you can use the decode method of the java.net.URLDecoder utility class in the Java SDK. Other languages and SDKs provide similar functionality. An IAM group can also have managed policies attached to it. To retrieve a managed policy document that is attached to a group, use GetPolicy to determine the policy&#39;s default version, then use GetPolicyVersion to retrieve the policy document. For more information about policies, see Managed Policies and Inline Policies in the IAM User Guide."},{"ref":"AWS.IAM.html#get_instance_profile/3","title":"AWS.IAM.get_instance_profile/3","type":"function","doc":"Retrieves information about the specified instance profile, including the instance profile&#39;s path, GUID, ARN, and role. For more information about instance profiles, see About Instance Profiles in the IAM User Guide."},{"ref":"AWS.IAM.html#get_login_profile/3","title":"AWS.IAM.get_login_profile/3","type":"function","doc":"Retrieves the user name and password-creation date for the specified IAM user. If the user has not been assigned a password, the operation returns a 404 (NoSuchEntity) error."},{"ref":"AWS.IAM.html#get_open_i_d_connect_provider/3","title":"AWS.IAM.get_open_i_d_connect_provider/3","type":"function","doc":"Returns information about the specified OpenID Connect (OIDC) provider resource object in IAM."},{"ref":"AWS.IAM.html#get_organizations_access_report/3","title":"AWS.IAM.get_organizations_access_report/3","type":"function","doc":"Retrieves the service last accessed data report for AWS Organizations that was previously generated using the GenerateOrganizationsAccessReport operation. This operation retrieves the status of your report job and the report contents. Depending on the parameters that you passed when you generated the report, the data returned could include different information. For details, see GenerateOrganizationsAccessReport. To call this operation, you must be signed in to the master account in your organization. SCPs must be enabled for your organization root. You must have permissions to perform this operation. For more information, see Refining Permissions Using Service Last Accessed Data in the IAM User Guide. For each service that principals in an account (root users, IAM users, or IAM roles) could access using SCPs, the operation returns details about the most recent access attempt. If there was no attempt, the service is listed without details about the most recent attempt to access the service. If the operation fails, it returns the reason that it failed. By default, the list is sorted by service namespace."},{"ref":"AWS.IAM.html#get_policy/3","title":"AWS.IAM.get_policy/3","type":"function","doc":"Retrieves information about the specified managed policy, including the policy&#39;s default version and the total number of IAM users, groups, and roles to which the policy is attached. To retrieve the list of the specific users, groups, and roles that the policy is attached to, use the ListEntitiesForPolicy API. This API returns metadata about the policy. To retrieve the actual policy document for a specific version of the policy, use GetPolicyVersion. This API retrieves information about managed policies. To retrieve information about an inline policy that is embedded with an IAM user, group, or role, use the GetUserPolicy, GetGroupPolicy, or GetRolePolicy API. For more information about policies, see Managed Policies and Inline Policies in the IAM User Guide."},{"ref":"AWS.IAM.html#get_policy_version/3","title":"AWS.IAM.get_policy_version/3","type":"function","doc":"Retrieves information about the specified version of the specified managed policy, including the policy document. Policies returned by this API are URL-encoded compliant with RFC 3986. You can use a URL decoding method to convert the policy back to plain JSON text. For example, if you use Java, you can use the decode method of the java.net.URLDecoder utility class in the Java SDK. Other languages and SDKs provide similar functionality. To list the available versions for a policy, use ListPolicyVersions. This API retrieves information about managed policies. To retrieve information about an inline policy that is embedded in a user, group, or role, use the GetUserPolicy, GetGroupPolicy, or GetRolePolicy API. For more information about the types of policies, see Managed Policies and Inline Policies in the IAM User Guide. For more information about managed policy versions, see Versioning for Managed Policies in the IAM User Guide."},{"ref":"AWS.IAM.html#get_role/3","title":"AWS.IAM.get_role/3","type":"function","doc":"Retrieves information about the specified role, including the role&#39;s path, GUID, ARN, and the role&#39;s trust policy that grants permission to assume the role. For more information about roles, see Working with Roles. Policies returned by this API are URL-encoded compliant with RFC 3986. You can use a URL decoding method to convert the policy back to plain JSON text. For example, if you use Java, you can use the decode method of the java.net.URLDecoder utility class in the Java SDK. Other languages and SDKs provide similar functionality."},{"ref":"AWS.IAM.html#get_role_policy/3","title":"AWS.IAM.get_role_policy/3","type":"function","doc":"Retrieves the specified inline policy document that is embedded with the specified IAM role. Policies returned by this API are URL-encoded compliant with RFC 3986. You can use a URL decoding method to convert the policy back to plain JSON text. For example, if you use Java, you can use the decode method of the java.net.URLDecoder utility class in the Java SDK. Other languages and SDKs provide similar functionality. An IAM role can also have managed policies attached to it. To retrieve a managed policy document that is attached to a role, use GetPolicy to determine the policy&#39;s default version, then use GetPolicyVersion to retrieve the policy document. For more information about policies, see Managed Policies and Inline Policies in the IAM User Guide. For more information about roles, see Using Roles to Delegate Permissions and Federate Identities."},{"ref":"AWS.IAM.html#get_s_a_m_l_provider/3","title":"AWS.IAM.get_s_a_m_l_provider/3","type":"function","doc":"Returns the SAML provider metadocument that was uploaded when the IAM SAML provider resource object was created or updated. This operation requires Signature Version 4."},{"ref":"AWS.IAM.html#get_s_s_h_public_key/3","title":"AWS.IAM.get_s_s_h_public_key/3","type":"function","doc":"Retrieves the specified SSH public key, including metadata about the key. The SSH public key retrieved by this operation is used only for authenticating the associated IAM user to an AWS CodeCommit repository. For more information about using SSH keys to authenticate to an AWS CodeCommit repository, see Set up AWS CodeCommit for SSH Connections in the AWS CodeCommit User Guide."},{"ref":"AWS.IAM.html#get_server_certificate/3","title":"AWS.IAM.get_server_certificate/3","type":"function","doc":"Retrieves information about the specified server certificate stored in IAM. For more information about working with server certificates, see Working with Server Certificates in the IAM User Guide. This topic includes a list of AWS services that can use the server certificates that you manage with IAM."},{"ref":"AWS.IAM.html#get_service_last_accessed_details/3","title":"AWS.IAM.get_service_last_accessed_details/3","type":"function","doc":"Retrieves a service last accessed report that was created using the GenerateServiceLastAccessedDetails operation. You can use the JobId parameter in GetServiceLastAccessedDetails to retrieve the status of your report job. When the report is complete, you can retrieve the generated report. The report includes a list of AWS services that the resource (user, group, role, or managed policy) can access. Service last accessed data does not use other policy types when determining whether a resource could access a service. These other policy types include resource-based policies, access control lists, AWS Organizations policies, IAM permissions boundaries, and AWS STS assume role policies. It only applies permissions policy logic. For more about the evaluation of policy types, see Evaluating Policies in the IAM User Guide. For each service that the resource could access using permissions policies, the operation returns details about the most recent access attempt. If there was no attempt, the service is listed without details about the most recent attempt to access the service. If the operation fails, the GetServiceLastAccessedDetails operation returns the reason that it failed. The GetServiceLastAccessedDetails operation returns a list of services. This list includes the number of entities that have attempted to access the service and the date and time of the last attempt. It also returns the ARN of the following entity, depending on the resource ARN that you used to generate the report: User  Returns the user ARN that you used to generate the report Group  Returns the ARN of the group member (user) that last attempted to access the service Role  Returns the role ARN that you used to generate the report Policy  Returns the ARN of the user or role that last used the policy to attempt to access the service By default, the list is sorted by service namespace. If you specified ACTION_LEVEL granularity when you generated the report, this operation returns service and action last accessed data. This includes the most recent access attempt for each tracked action within a service. Otherwise, this operation returns only service data. For more information about service and action last accessed data, see Reducing Permissions Using Service Last Accessed Data in the IAM User Guide."},{"ref":"AWS.IAM.html#get_service_last_accessed_details_with_entities/3","title":"AWS.IAM.get_service_last_accessed_details_with_entities/3","type":"function","doc":"After you generate a group or policy report using the GenerateServiceLastAccessedDetails operation, you can use the JobId parameter in GetServiceLastAccessedDetailsWithEntities. This operation retrieves the status of your report job and a list of entities that could have used group or policy permissions to access the specified service. Group  For a group report, this operation returns a list of users in the group that could have used the groups policies in an attempt to access the service. Policy  For a policy report, this operation returns a list of entities (users or roles) that could have used the policy in an attempt to access the service. You can also use this operation for user or role reports to retrieve details about those entities. If the operation fails, the GetServiceLastAccessedDetailsWithEntities operation returns the reason that it failed. By default, the list of associated entities is sorted by date, with the most recent access listed first."},{"ref":"AWS.IAM.html#get_service_linked_role_deletion_status/3","title":"AWS.IAM.get_service_linked_role_deletion_status/3","type":"function","doc":"Retrieves the status of your service-linked role deletion. After you use the DeleteServiceLinkedRole API operation to submit a service-linked role for deletion, you can use the DeletionTaskId parameter in GetServiceLinkedRoleDeletionStatus to check the status of the deletion. If the deletion fails, this operation returns the reason that it failed, if that information is returned by the service."},{"ref":"AWS.IAM.html#get_user/3","title":"AWS.IAM.get_user/3","type":"function","doc":"Retrieves information about the specified IAM user, including the user&#39;s creation date, path, unique ID, and ARN. If you do not specify a user name, IAM determines the user name implicitly based on the AWS access key ID used to sign the request to this API."},{"ref":"AWS.IAM.html#get_user_policy/3","title":"AWS.IAM.get_user_policy/3","type":"function","doc":"Retrieves the specified inline policy document that is embedded in the specified IAM user. Policies returned by this API are URL-encoded compliant with RFC 3986. You can use a URL decoding method to convert the policy back to plain JSON text. For example, if you use Java, you can use the decode method of the java.net.URLDecoder utility class in the Java SDK. Other languages and SDKs provide similar functionality. An IAM user can also have managed policies attached to it. To retrieve a managed policy document that is attached to a user, use GetPolicy to determine the policy&#39;s default version. Then use GetPolicyVersion to retrieve the policy document. For more information about policies, see Managed Policies and Inline Policies in the IAM User Guide."},{"ref":"AWS.IAM.html#list_access_keys/3","title":"AWS.IAM.list_access_keys/3","type":"function","doc":"Returns information about the access key IDs associated with the specified IAM user. If there is none, the operation returns an empty list. Although each user is limited to a small number of keys, you can still paginate the results using the MaxItems and Marker parameters. If the UserName field is not specified, the user name is determined implicitly based on the AWS access key ID used to sign the request. This operation works for access keys under the AWS account. Consequently, you can use this operation to manage AWS account root user credentials even if the AWS account has no associated users. To ensure the security of your AWS account, the secret access key is accessible only during key and user creation."},{"ref":"AWS.IAM.html#list_account_aliases/3","title":"AWS.IAM.list_account_aliases/3","type":"function","doc":"Lists the account alias associated with the AWS account (Note: you can have only one). For information about using an AWS account alias, see Using an Alias for Your AWS Account ID in the IAM User Guide."},{"ref":"AWS.IAM.html#list_attached_group_policies/3","title":"AWS.IAM.list_attached_group_policies/3","type":"function","doc":"Lists all managed policies that are attached to the specified IAM group. An IAM group can also have inline policies embedded with it. To list the inline policies for a group, use the ListGroupPolicies API. For information about policies, see Managed Policies and Inline Policies in the IAM User Guide. You can paginate the results using the MaxItems and Marker parameters. You can use the PathPrefix parameter to limit the list of policies to only those matching the specified path prefix. If there are no policies attached to the specified group (or none that match the specified path prefix), the operation returns an empty list."},{"ref":"AWS.IAM.html#list_attached_role_policies/3","title":"AWS.IAM.list_attached_role_policies/3","type":"function","doc":"Lists all managed policies that are attached to the specified IAM role. An IAM role can also have inline policies embedded with it. To list the inline policies for a role, use the ListRolePolicies API. For information about policies, see Managed Policies and Inline Policies in the IAM User Guide. You can paginate the results using the MaxItems and Marker parameters. You can use the PathPrefix parameter to limit the list of policies to only those matching the specified path prefix. If there are no policies attached to the specified role (or none that match the specified path prefix), the operation returns an empty list."},{"ref":"AWS.IAM.html#list_attached_user_policies/3","title":"AWS.IAM.list_attached_user_policies/3","type":"function","doc":"Lists all managed policies that are attached to the specified IAM user. An IAM user can also have inline policies embedded with it. To list the inline policies for a user, use the ListUserPolicies API. For information about policies, see Managed Policies and Inline Policies in the IAM User Guide. You can paginate the results using the MaxItems and Marker parameters. You can use the PathPrefix parameter to limit the list of policies to only those matching the specified path prefix. If there are no policies attached to the specified group (or none that match the specified path prefix), the operation returns an empty list."},{"ref":"AWS.IAM.html#list_entities_for_policy/3","title":"AWS.IAM.list_entities_for_policy/3","type":"function","doc":"Lists all IAM users, groups, and roles that the specified managed policy is attached to. You can use the optional EntityFilter parameter to limit the results to a particular type of entity (users, groups, or roles). For example, to list only the roles that are attached to the specified policy, set EntityFilter to Role. You can paginate the results using the MaxItems and Marker parameters."},{"ref":"AWS.IAM.html#list_group_policies/3","title":"AWS.IAM.list_group_policies/3","type":"function","doc":"Lists the names of the inline policies that are embedded in the specified IAM group. An IAM group can also have managed policies attached to it. To list the managed policies that are attached to a group, use ListAttachedGroupPolicies. For more information about policies, see Managed Policies and Inline Policies in the IAM User Guide. You can paginate the results using the MaxItems and Marker parameters. If there are no inline policies embedded with the specified group, the operation returns an empty list."},{"ref":"AWS.IAM.html#list_groups/3","title":"AWS.IAM.list_groups/3","type":"function","doc":"Lists the IAM groups that have the specified path prefix. You can paginate the results using the MaxItems and Marker parameters."},{"ref":"AWS.IAM.html#list_groups_for_user/3","title":"AWS.IAM.list_groups_for_user/3","type":"function","doc":"Lists the IAM groups that the specified IAM user belongs to. You can paginate the results using the MaxItems and Marker parameters."},{"ref":"AWS.IAM.html#list_instance_profiles/3","title":"AWS.IAM.list_instance_profiles/3","type":"function","doc":"Lists the instance profiles that have the specified path prefix. If there are none, the operation returns an empty list. For more information about instance profiles, go to About Instance Profiles. You can paginate the results using the MaxItems and Marker parameters."},{"ref":"AWS.IAM.html#list_instance_profiles_for_role/3","title":"AWS.IAM.list_instance_profiles_for_role/3","type":"function","doc":"Lists the instance profiles that have the specified associated IAM role. If there are none, the operation returns an empty list. For more information about instance profiles, go to About Instance Profiles. You can paginate the results using the MaxItems and Marker parameters."},{"ref":"AWS.IAM.html#list_m_f_a_devices/3","title":"AWS.IAM.list_m_f_a_devices/3","type":"function","doc":"Lists the MFA devices for an IAM user. If the request includes a IAM user name, then this operation lists all the MFA devices associated with the specified user. If you do not specify a user name, IAM determines the user name implicitly based on the AWS access key ID signing the request for this API. You can paginate the results using the MaxItems and Marker parameters."},{"ref":"AWS.IAM.html#list_open_i_d_connect_providers/3","title":"AWS.IAM.list_open_i_d_connect_providers/3","type":"function","doc":"Lists information about the IAM OpenID Connect (OIDC) provider resource objects defined in the AWS account."},{"ref":"AWS.IAM.html#list_policies/3","title":"AWS.IAM.list_policies/3","type":"function","doc":"Lists all the managed policies that are available in your AWS account, including your own customer-defined managed policies and all AWS managed policies. You can filter the list of policies that is returned using the optional OnlyAttached, Scope, and PathPrefix parameters. For example, to list only the customer managed policies in your AWS account, set Scope to Local. To list only AWS managed policies, set Scope to AWS. You can paginate the results using the MaxItems and Marker parameters. For more information about managed policies, see Managed Policies and Inline Policies in the IAM User Guide."},{"ref":"AWS.IAM.html#list_policies_granting_service_access/3","title":"AWS.IAM.list_policies_granting_service_access/3","type":"function","doc":"Retrieves a list of policies that the IAM identity (user, group, or role) can use to access each specified service. This operation does not use other policy types when determining whether a resource could access a service. These other policy types include resource-based policies, access control lists, AWS Organizations policies, IAM permissions boundaries, and AWS STS assume role policies. It only applies permissions policy logic. For more about the evaluation of policy types, see Evaluating Policies in the IAM User Guide. The list of policies returned by the operation depends on the ARN of the identity that you provide. User  The list of policies includes the managed and inline policies that are attached to the user directly. The list also includes any additional managed and inline policies that are attached to the group to which the user belongs. Group  The list of policies includes only the managed and inline policies that are attached to the group directly. Policies that are attached to the groups user are not included. Role  The list of policies includes only the managed and inline policies that are attached to the role. For each managed policy, this operation returns the ARN and policy name. For each inline policy, it returns the policy name and the entity to which it is attached. Inline policies do not have an ARN. For more information about these policy types, see Managed Policies and Inline Policies in the IAM User Guide. Policies that are attached to users and roles as permissions boundaries are not returned. To view which managed policy is currently used to set the permissions boundary for a user or role, use the GetUser or GetRole operations."},{"ref":"AWS.IAM.html#list_policy_versions/3","title":"AWS.IAM.list_policy_versions/3","type":"function","doc":"Lists information about the versions of the specified managed policy, including the version that is currently set as the policy&#39;s default version. For more information about managed policies, see Managed Policies and Inline Policies in the IAM User Guide."},{"ref":"AWS.IAM.html#list_role_policies/3","title":"AWS.IAM.list_role_policies/3","type":"function","doc":"Lists the names of the inline policies that are embedded in the specified IAM role. An IAM role can also have managed policies attached to it. To list the managed policies that are attached to a role, use ListAttachedRolePolicies. For more information about policies, see Managed Policies and Inline Policies in the IAM User Guide. You can paginate the results using the MaxItems and Marker parameters. If there are no inline policies embedded with the specified role, the operation returns an empty list."},{"ref":"AWS.IAM.html#list_role_tags/3","title":"AWS.IAM.list_role_tags/3","type":"function","doc":"Lists the tags that are attached to the specified role. The returned list of tags is sorted by tag key. For more information about tagging, see Tagging IAM Identities in the IAM User Guide."},{"ref":"AWS.IAM.html#list_roles/3","title":"AWS.IAM.list_roles/3","type":"function","doc":"Lists the IAM roles that have the specified path prefix. If there are none, the operation returns an empty list. For more information about roles, go to Working with Roles. You can paginate the results using the MaxItems and Marker parameters."},{"ref":"AWS.IAM.html#list_s_a_m_l_providers/3","title":"AWS.IAM.list_s_a_m_l_providers/3","type":"function","doc":"Lists the SAML provider resource objects defined in IAM in the account. This operation requires Signature Version 4."},{"ref":"AWS.IAM.html#list_s_s_h_public_keys/3","title":"AWS.IAM.list_s_s_h_public_keys/3","type":"function","doc":"Returns information about the SSH public keys associated with the specified IAM user. If none exists, the operation returns an empty list. The SSH public keys returned by this operation are used only for authenticating the IAM user to an AWS CodeCommit repository. For more information about using SSH keys to authenticate to an AWS CodeCommit repository, see Set up AWS CodeCommit for SSH Connections in the AWS CodeCommit User Guide. Although each user is limited to a small number of keys, you can still paginate the results using the MaxItems and Marker parameters."},{"ref":"AWS.IAM.html#list_server_certificates/3","title":"AWS.IAM.list_server_certificates/3","type":"function","doc":"Lists the server certificates stored in IAM that have the specified path prefix. If none exist, the operation returns an empty list. You can paginate the results using the MaxItems and Marker parameters. For more information about working with server certificates, see Working with Server Certificates in the IAM User Guide. This topic also includes a list of AWS services that can use the server certificates that you manage with IAM."},{"ref":"AWS.IAM.html#list_service_specific_credentials/3","title":"AWS.IAM.list_service_specific_credentials/3","type":"function","doc":"Returns information about the service-specific credentials associated with the specified IAM user. If none exists, the operation returns an empty list. The service-specific credentials returned by this operation are used only for authenticating the IAM user to a specific service. For more information about using service-specific credentials to authenticate to an AWS service, see Set Up service-specific credentials in the AWS CodeCommit User Guide."},{"ref":"AWS.IAM.html#list_signing_certificates/3","title":"AWS.IAM.list_signing_certificates/3","type":"function","doc":"Returns information about the signing certificates associated with the specified IAM user. If none exists, the operation returns an empty list. Although each user is limited to a small number of signing certificates, you can still paginate the results using the MaxItems and Marker parameters. If the UserName field is not specified, the user name is determined implicitly based on the AWS access key ID used to sign the request for this API. This operation works for access keys under the AWS account. Consequently, you can use this operation to manage AWS account root user credentials even if the AWS account has no associated users."},{"ref":"AWS.IAM.html#list_user_policies/3","title":"AWS.IAM.list_user_policies/3","type":"function","doc":"Lists the names of the inline policies embedded in the specified IAM user. An IAM user can also have managed policies attached to it. To list the managed policies that are attached to a user, use ListAttachedUserPolicies. For more information about policies, see Managed Policies and Inline Policies in the IAM User Guide. You can paginate the results using the MaxItems and Marker parameters. If there are no inline policies embedded with the specified user, the operation returns an empty list."},{"ref":"AWS.IAM.html#list_user_tags/3","title":"AWS.IAM.list_user_tags/3","type":"function","doc":"Lists the tags that are attached to the specified user. The returned list of tags is sorted by tag key. For more information about tagging, see Tagging IAM Identities in the IAM User Guide."},{"ref":"AWS.IAM.html#list_users/3","title":"AWS.IAM.list_users/3","type":"function","doc":"Lists the IAM users that have the specified path prefix. If no path prefix is specified, the operation returns all users in the AWS account. If there are none, the operation returns an empty list. You can paginate the results using the MaxItems and Marker parameters."},{"ref":"AWS.IAM.html#list_virtual_m_f_a_devices/3","title":"AWS.IAM.list_virtual_m_f_a_devices/3","type":"function","doc":"Lists the virtual MFA devices defined in the AWS account by assignment status. If you do not specify an assignment status, the operation returns a list of all virtual MFA devices. Assignment status can be Assigned, Unassigned, or Any. You can paginate the results using the MaxItems and Marker parameters."},{"ref":"AWS.IAM.html#put_group_policy/3","title":"AWS.IAM.put_group_policy/3","type":"function","doc":"Adds or updates an inline policy document that is embedded in the specified IAM group. A user can also have managed policies attached to it. To attach a managed policy to a group, use AttachGroupPolicy. To create a new managed policy, use CreatePolicy. For information about policies, see Managed Policies and Inline Policies in the IAM User Guide. For information about limits on the number of inline policies that you can embed in a group, see Limitations on IAM Entities in the IAM User Guide. Because policy documents can be large, you should use POST rather than GET when calling PutGroupPolicy. For general information about using the Query API with IAM, go to Making Query Requests in the IAM User Guide."},{"ref":"AWS.IAM.html#put_role_permissions_boundary/3","title":"AWS.IAM.put_role_permissions_boundary/3","type":"function","doc":"Adds or updates the policy that is specified as the IAM role&#39;s permissions boundary. You can use an AWS managed policy or a customer managed policy to set the boundary for a role. Use the boundary to control the maximum permissions that the role can have. Setting a permissions boundary is an advanced feature that can affect the permissions for the role. You cannot set the boundary for a service-linked role. Policies used as permissions boundaries do not provide permissions. You must also attach a permissions policy to the role. To learn how the effective permissions for a role are evaluated, see IAM JSON Policy Evaluation Logic in the IAM User Guide."},{"ref":"AWS.IAM.html#put_role_policy/3","title":"AWS.IAM.put_role_policy/3","type":"function","doc":"Adds or updates an inline policy document that is embedded in the specified IAM role. When you embed an inline policy in a role, the inline policy is used as part of the role&#39;s access (permissions) policy. The role&#39;s trust policy is created at the same time as the role, using CreateRole. You can update a role&#39;s trust policy using UpdateAssumeRolePolicy. For more information about IAM roles, go to Using Roles to Delegate Permissions and Federate Identities. A role can also have a managed policy attached to it. To attach a managed policy to a role, use AttachRolePolicy. To create a new managed policy, use CreatePolicy. For information about policies, see Managed Policies and Inline Policies in the IAM User Guide. For information about limits on the number of inline policies that you can embed with a role, see Limitations on IAM Entities in the IAM User Guide. Because policy documents can be large, you should use POST rather than GET when calling PutRolePolicy. For general information about using the Query API with IAM, go to Making Query Requests in the IAM User Guide."},{"ref":"AWS.IAM.html#put_user_permissions_boundary/3","title":"AWS.IAM.put_user_permissions_boundary/3","type":"function","doc":"Adds or updates the policy that is specified as the IAM user&#39;s permissions boundary. You can use an AWS managed policy or a customer managed policy to set the boundary for a user. Use the boundary to control the maximum permissions that the user can have. Setting a permissions boundary is an advanced feature that can affect the permissions for the user. Policies that are used as permissions boundaries do not provide permissions. You must also attach a permissions policy to the user. To learn how the effective permissions for a user are evaluated, see IAM JSON Policy Evaluation Logic in the IAM User Guide."},{"ref":"AWS.IAM.html#put_user_policy/3","title":"AWS.IAM.put_user_policy/3","type":"function","doc":"Adds or updates an inline policy document that is embedded in the specified IAM user. An IAM user can also have a managed policy attached to it. To attach a managed policy to a user, use AttachUserPolicy. To create a new managed policy, use CreatePolicy. For information about policies, see Managed Policies and Inline Policies in the IAM User Guide. For information about limits on the number of inline policies that you can embed in a user, see Limitations on IAM Entities in the IAM User Guide. Because policy documents can be large, you should use POST rather than GET when calling PutUserPolicy. For general information about using the Query API with IAM, go to Making Query Requests in the IAM User Guide."},{"ref":"AWS.IAM.html#remove_client_i_d_from_open_i_d_connect_provider/3","title":"AWS.IAM.remove_client_i_d_from_open_i_d_connect_provider/3","type":"function","doc":"Removes the specified client ID (also known as audience) from the list of client IDs registered for the specified IAM OpenID Connect (OIDC) provider resource object. This operation is idempotent; it does not fail or return an error if you try to remove a client ID that does not exist."},{"ref":"AWS.IAM.html#remove_role_from_instance_profile/3","title":"AWS.IAM.remove_role_from_instance_profile/3","type":"function","doc":"Removes the specified IAM role from the specified EC2 instance profile. Make sure that you do not have any Amazon EC2 instances running with the role you are about to remove from the instance profile. Removing a role from an instance profile that is associated with a running instance might break any applications running on the instance. For more information about IAM roles, go to Working with Roles. For more information about instance profiles, go to About Instance Profiles."},{"ref":"AWS.IAM.html#remove_user_from_group/3","title":"AWS.IAM.remove_user_from_group/3","type":"function","doc":"Removes the specified user from the specified group."},{"ref":"AWS.IAM.html#reset_service_specific_credential/3","title":"AWS.IAM.reset_service_specific_credential/3","type":"function","doc":"Resets the password for a service-specific credential. The new password is AWS generated and cryptographically strong. It cannot be configured by the user. Resetting the password immediately invalidates the previous password associated with this user."},{"ref":"AWS.IAM.html#resync_m_f_a_device/3","title":"AWS.IAM.resync_m_f_a_device/3","type":"function","doc":"Synchronizes the specified MFA device with its IAM resource object on the AWS servers. For more information about creating and working with virtual MFA devices, go to Using a Virtual MFA Device in the IAM User Guide."},{"ref":"AWS.IAM.html#set_default_policy_version/3","title":"AWS.IAM.set_default_policy_version/3","type":"function","doc":"Sets the specified version of the specified policy as the policy&#39;s default (operative) version. This operation affects all users, groups, and roles that the policy is attached to. To list the users, groups, and roles that the policy is attached to, use the ListEntitiesForPolicy API. For information about managed policies, see Managed Policies and Inline Policies in the IAM User Guide."},{"ref":"AWS.IAM.html#set_security_token_service_preferences/3","title":"AWS.IAM.set_security_token_service_preferences/3","type":"function","doc":"Sets the specified version of the global endpoint token as the token version used for the AWS account. By default, AWS Security Token Service (STS) is available as a global service, and all STS requests go to a single endpoint at https://sts.amazonaws.com. AWS recommends using Regional STS endpoints to reduce latency, build in redundancy, and increase session token availability. For information about Regional endpoints for STS, see AWS Regions and Endpoints in the AWS General Reference. If you make an STS call to the global endpoint, the resulting session tokens might be valid in some Regions but not others. It depends on the version that is set in this operation. Version 1 tokens are valid only in AWS Regions that are available by default. These tokens do not work in manually enabled Regions, such as Asia Pacific (Hong Kong). Version 2 tokens are valid in all Regions. However, version 2 tokens are longer and might affect systems where you temporarily store tokens. For information, see Activating and Deactivating STS in an AWS Region in the IAM User Guide. To view the current session token version, see the GlobalEndpointTokenVersion entry in the response of the GetAccountSummary operation."},{"ref":"AWS.IAM.html#simulate_custom_policy/3","title":"AWS.IAM.simulate_custom_policy/3","type":"function","doc":"Simulate how a set of IAM policies and optionally a resource-based policy works with a list of API operations and AWS resources to determine the policies&#39; effective permissions. The policies are provided as strings. The simulation does not perform the API operations; it only checks the authorization to determine if the simulated policies allow or deny the operations. If you want to simulate existing policies that are attached to an IAM user, group, or role, use SimulatePrincipalPolicy instead. Context keys are variables that are maintained by AWS and its services and which provide details about the context of an API query request. You can use the Condition element of an IAM policy to evaluate context keys. To get the list of context keys that the policies require for correct simulation, use GetContextKeysForCustomPolicy. If the output is long, you can use MaxItems and Marker parameters to paginate the results."},{"ref":"AWS.IAM.html#simulate_principal_policy/3","title":"AWS.IAM.simulate_principal_policy/3","type":"function","doc":"Simulate how a set of IAM policies attached to an IAM entity works with a list of API operations and AWS resources to determine the policies&#39; effective permissions. The entity can be an IAM user, group, or role. If you specify a user, then the simulation also includes all of the policies that are attached to groups that the user belongs to. You can optionally include a list of one or more additional policies specified as strings to include in the simulation. If you want to simulate only policies specified as strings, use SimulateCustomPolicy instead. You can also optionally include one resource-based policy to be evaluated with each of the resources included in the simulation. The simulation does not perform the API operations; it only checks the authorization to determine if the simulated policies allow or deny the operations. Note: This API discloses information about the permissions granted to other users. If you do not want users to see other user&#39;s permissions, then consider allowing them to use SimulateCustomPolicy instead. Context keys are variables maintained by AWS and its services that provide details about the context of an API query request. You can use the Condition element of an IAM policy to evaluate context keys. To get the list of context keys that the policies require for correct simulation, use GetContextKeysForPrincipalPolicy. If the output is long, you can use the MaxItems and Marker parameters to paginate the results."},{"ref":"AWS.IAM.html#tag_role/3","title":"AWS.IAM.tag_role/3","type":"function","doc":"Adds one or more tags to an IAM role. The role can be a regular role or a service-linked role. If a tag with the same key name already exists, then that tag is overwritten with the new value. A tag consists of a key name and an associated value. By assigning tags to your resources, you can do the following: Administrative grouping and discovery - Attach tags to resources to aid in organization and search. For example, you could search for all resources with the key name Project and the value MyImportantProject. Or search for all resources with the key name Cost Center and the value 41200. Access control - Reference tags in IAM user-based and resource-based policies. You can use tags to restrict access to only an IAM user or role that has a specified tag attached. You can also restrict access to only those resources that have a certain tag attached. For examples of policies that show how to use tags to control access, see Control Access Using IAM Tags in the IAM User Guide. Cost allocation - Use tags to help track which individuals and teams are using which AWS resources. Make sure that you have no invalid tags and that you do not exceed the allowed number of tags per role. In either case, the entire request fails and no tags are added to the role. AWS always interprets the tag Value as a single string. If you need to store an array, you can store comma-separated values in the string. However, you must interpret the value in your code. For more information about tagging, see Tagging IAM Identities in the IAM User Guide."},{"ref":"AWS.IAM.html#tag_user/3","title":"AWS.IAM.tag_user/3","type":"function","doc":"Adds one or more tags to an IAM user. If a tag with the same key name already exists, then that tag is overwritten with the new value. A tag consists of a key name and an associated value. By assigning tags to your resources, you can do the following: Administrative grouping and discovery - Attach tags to resources to aid in organization and search. For example, you could search for all resources with the key name Project and the value MyImportantProject. Or search for all resources with the key name Cost Center and the value 41200. Access control - Reference tags in IAM user-based and resource-based policies. You can use tags to restrict access to only an IAM requesting user or to a role that has a specified tag attached. You can also restrict access to only those resources that have a certain tag attached. For examples of policies that show how to use tags to control access, see Control Access Using IAM Tags in the IAM User Guide. Cost allocation - Use tags to help track which individuals and teams are using which AWS resources. Make sure that you have no invalid tags and that you do not exceed the allowed number of tags per role. In either case, the entire request fails and no tags are added to the role. AWS always interprets the tag Value as a single string. If you need to store an array, you can store comma-separated values in the string. However, you must interpret the value in your code. For more information about tagging, see Tagging IAM Identities in the IAM User Guide."},{"ref":"AWS.IAM.html#untag_role/3","title":"AWS.IAM.untag_role/3","type":"function","doc":"Removes the specified tags from the role. For more information about tagging, see Tagging IAM Identities in the IAM User Guide."},{"ref":"AWS.IAM.html#untag_user/3","title":"AWS.IAM.untag_user/3","type":"function","doc":"Removes the specified tags from the user. For more information about tagging, see Tagging IAM Identities in the IAM User Guide."},{"ref":"AWS.IAM.html#update_access_key/3","title":"AWS.IAM.update_access_key/3","type":"function","doc":"Changes the status of the specified access key from Active to Inactive, or vice versa. This operation can be used to disable a user&#39;s key as part of a key rotation workflow. If the UserName is not specified, the user name is determined implicitly based on the AWS access key ID used to sign the request. This operation works for access keys under the AWS account. Consequently, you can use this operation to manage AWS account root user credentials even if the AWS account has no associated users. For information about rotating keys, see Managing Keys and Certificates in the IAM User Guide."},{"ref":"AWS.IAM.html#update_account_password_policy/3","title":"AWS.IAM.update_account_password_policy/3","type":"function","doc":"Updates the password policy settings for the AWS account. This operation does not support partial updates. No parameters are required, but if you do not specify a parameter, that parameter&#39;s value reverts to its default value. See the Request Parameters section for each parameter&#39;s default value. Also note that some parameters do not allow the default parameter to be explicitly set. Instead, to invoke the default value, do not include that parameter when you invoke the operation. For more information about using a password policy, see Managing an IAM Password Policy in the IAM User Guide."},{"ref":"AWS.IAM.html#update_assume_role_policy/3","title":"AWS.IAM.update_assume_role_policy/3","type":"function","doc":"Updates the policy that grants an IAM entity permission to assume a role. This is typically referred to as the &quot;role trust policy&quot;. For more information about roles, go to Using Roles to Delegate Permissions and Federate Identities."},{"ref":"AWS.IAM.html#update_group/3","title":"AWS.IAM.update_group/3","type":"function","doc":"Updates the name and/or the path of the specified IAM group. You should understand the implications of changing a group&#39;s path or name. For more information, see Renaming Users and Groups in the IAM User Guide. The person making the request (the principal), must have permission to change the role group with the old name and the new name. For example, to change the group named Managers to MGRs, the principal must have a policy that allows them to update both groups. If the principal has permission to update the Managers group, but not the MGRs group, then the update fails. For more information about permissions, see Access Management."},{"ref":"AWS.IAM.html#update_login_profile/3","title":"AWS.IAM.update_login_profile/3","type":"function","doc":"Changes the password for the specified IAM user. IAM users can change their own passwords by calling ChangePassword. For more information about modifying passwords, see Managing Passwords in the IAM User Guide."},{"ref":"AWS.IAM.html#update_open_i_d_connect_provider_thumbprint/3","title":"AWS.IAM.update_open_i_d_connect_provider_thumbprint/3","type":"function","doc":"Replaces the existing list of server certificate thumbprints associated with an OpenID Connect (OIDC) provider resource object with a new list of thumbprints. The list that you pass with this operation completely replaces the existing list of thumbprints. (The lists are not merged.) Typically, you need to update a thumbprint only when the identity provider&#39;s certificate changes, which occurs rarely. However, if the provider&#39;s certificate does change, any attempt to assume an IAM role that specifies the OIDC provider as a principal fails until the certificate thumbprint is updated. Trust for the OIDC provider is derived from the provider&#39;s certificate and is validated by the thumbprint. Therefore, it is best to limit access to the UpdateOpenIDConnectProviderThumbprint operation to highly privileged users."},{"ref":"AWS.IAM.html#update_role/3","title":"AWS.IAM.update_role/3","type":"function","doc":"Updates the description or maximum session duration setting of a role."},{"ref":"AWS.IAM.html#update_role_description/3","title":"AWS.IAM.update_role_description/3","type":"function","doc":"Use UpdateRole instead. Modifies only the description of a role. This operation performs the same function as the Description parameter in the UpdateRole operation."},{"ref":"AWS.IAM.html#update_s_a_m_l_provider/3","title":"AWS.IAM.update_s_a_m_l_provider/3","type":"function","doc":"Updates the metadata document for an existing SAML provider resource object. This operation requires Signature Version 4."},{"ref":"AWS.IAM.html#update_s_s_h_public_key/3","title":"AWS.IAM.update_s_s_h_public_key/3","type":"function","doc":"Sets the status of an IAM user&#39;s SSH public key to active or inactive. SSH public keys that are inactive cannot be used for authentication. This operation can be used to disable a user&#39;s SSH public key as part of a key rotation work flow. The SSH public key affected by this operation is used only for authenticating the associated IAM user to an AWS CodeCommit repository. For more information about using SSH keys to authenticate to an AWS CodeCommit repository, see Set up AWS CodeCommit for SSH Connections in the AWS CodeCommit User Guide."},{"ref":"AWS.IAM.html#update_server_certificate/3","title":"AWS.IAM.update_server_certificate/3","type":"function","doc":"Updates the name and/or the path of the specified server certificate stored in IAM. For more information about working with server certificates, see Working with Server Certificates in the IAM User Guide. This topic also includes a list of AWS services that can use the server certificates that you manage with IAM. You should understand the implications of changing a server certificate&#39;s path or name. For more information, see Renaming a Server Certificate in the IAM User Guide. The person making the request (the principal), must have permission to change the server certificate with the old name and the new name. For example, to change the certificate named ProductionCert to ProdCert, the principal must have a policy that allows them to update both certificates. If the principal has permission to update the ProductionCert group, but not the ProdCert certificate, then the update fails. For more information about permissions, see Access Management in the IAM User Guide."},{"ref":"AWS.IAM.html#update_service_specific_credential/3","title":"AWS.IAM.update_service_specific_credential/3","type":"function","doc":"Sets the status of a service-specific credential to Active or Inactive. Service-specific credentials that are inactive cannot be used for authentication to the service. This operation can be used to disable a user&#39;s service-specific credential as part of a credential rotation work flow."},{"ref":"AWS.IAM.html#update_signing_certificate/3","title":"AWS.IAM.update_signing_certificate/3","type":"function","doc":"Changes the status of the specified user signing certificate from active to disabled, or vice versa. This operation can be used to disable an IAM user&#39;s signing certificate as part of a certificate rotation work flow. If the UserName field is not specified, the user name is determined implicitly based on the AWS access key ID used to sign the request. This operation works for access keys under the AWS account. Consequently, you can use this operation to manage AWS account root user credentials even if the AWS account has no associated users."},{"ref":"AWS.IAM.html#update_user/3","title":"AWS.IAM.update_user/3","type":"function","doc":"Updates the name and/or the path of the specified IAM user. You should understand the implications of changing an IAM user&#39;s path or name. For more information, see Renaming an IAM User and Renaming an IAM Group in the IAM User Guide. To change a user name, the requester must have appropriate permissions on both the source object and the target object. For example, to change Bob to Robert, the entity making the request must have permission on Bob and Robert, or must have permission on all (*). For more information about permissions, see Permissions and Policies."},{"ref":"AWS.IAM.html#upload_s_s_h_public_key/3","title":"AWS.IAM.upload_s_s_h_public_key/3","type":"function","doc":"Uploads an SSH public key and associates it with the specified IAM user. The SSH public key uploaded by this operation can be used only for authenticating the associated IAM user to an AWS CodeCommit repository. For more information about using SSH keys to authenticate to an AWS CodeCommit repository, see Set up AWS CodeCommit for SSH Connections in the AWS CodeCommit User Guide."},{"ref":"AWS.IAM.html#upload_server_certificate/3","title":"AWS.IAM.upload_server_certificate/3","type":"function","doc":"Uploads a server certificate entity for the AWS account. The server certificate entity includes a public key certificate, a private key, and an optional certificate chain, which should all be PEM-encoded. We recommend that you use AWS Certificate Manager to provision, manage, and deploy your server certificates. With ACM you can request a certificate, deploy it to AWS resources, and let ACM handle certificate renewals for you. Certificates provided by ACM are free. For more information about using ACM, see the AWS Certificate Manager User Guide. For more information about working with server certificates, see Working with Server Certificates in the IAM User Guide. This topic includes a list of AWS services that can use the server certificates that you manage with IAM. For information about the number of server certificates you can upload, see Limitations on IAM Entities and Objects in the IAM User Guide. Because the body of the public key certificate, private key, and the certificate chain can be large, you should use POST rather than GET when calling UploadServerCertificate. For information about setting up signatures and authorization through the API, go to Signing AWS API Requests in the AWS General Reference. For general information about using the Query API with IAM, go to Calling the API by Making HTTP Query Requests in the IAM User Guide."},{"ref":"AWS.IAM.html#upload_signing_certificate/3","title":"AWS.IAM.upload_signing_certificate/3","type":"function","doc":"Uploads an X.509 signing certificate and associates it with the specified IAM user. Some AWS services use X.509 signing certificates to validate requests that are signed with a corresponding private key. When you upload the certificate, its default status is Active. If the UserName is not specified, the IAM user name is determined implicitly based on the AWS access key ID used to sign the request. This operation works for access keys under the AWS account. Consequently, you can use this operation to manage AWS account root user credentials even if the AWS account has no associated users. Because the body of an X.509 certificate can be large, you should use POST rather than GET when calling UploadSigningCertificate. For information about setting up signatures and authorization through the API, go to Signing AWS API Requests in the AWS General Reference. For general information about using the Query API with IAM, go to Making Query Requests in the IAM User Guide."},{"ref":"AWS.Identitystore.html","title":"AWS.Identitystore","type":"module","doc":""},{"ref":"AWS.Identitystore.html#describe_group/3","title":"AWS.Identitystore.describe_group/3","type":"function","doc":"Retrieves the group metadata and attributes from GroupId in an identity store."},{"ref":"AWS.Identitystore.html#describe_user/3","title":"AWS.Identitystore.describe_user/3","type":"function","doc":"Retrieves the user metadata and attributes from UserId in an identity store."},{"ref":"AWS.Identitystore.html#list_groups/3","title":"AWS.Identitystore.list_groups/3","type":"function","doc":"Lists the attribute name and value of the group that you specified in the search. We only support DisplayName as a valid filter attribute path currently, and filter is required. This API returns minimum attributes, including GroupId and group DisplayName in the response."},{"ref":"AWS.Identitystore.html#list_users/3","title":"AWS.Identitystore.list_users/3","type":"function","doc":"Lists the attribute name and value of the user that you specified in the search. We only support UserName as a valid filter attribute path currently, and filter is required. This API returns minimum attributes, including UserId and UserName in the response."},{"ref":"AWS.Imagebuilder.html","title":"AWS.Imagebuilder","type":"module","doc":"EC2 Image Builder is a fully managed AWS service that makes it easier to automate the creation, management, and deployment of customized, secure, and up-to-date golden server images that are pre-installed and pre-configured with software and settings to meet specific IT standards."},{"ref":"AWS.Imagebuilder.html#cancel_image_creation/3","title":"AWS.Imagebuilder.cancel_image_creation/3","type":"function","doc":"CancelImageCreation cancels the creation of Image. This operation can only be used on images in a non-terminal state."},{"ref":"AWS.Imagebuilder.html#create_component/3","title":"AWS.Imagebuilder.create_component/3","type":"function","doc":"Creates a new component that can be used to build, validate, test, and assess your image."},{"ref":"AWS.Imagebuilder.html#create_distribution_configuration/3","title":"AWS.Imagebuilder.create_distribution_configuration/3","type":"function","doc":"Creates a new distribution configuration. Distribution configurations define and configure the outputs of your pipeline."},{"ref":"AWS.Imagebuilder.html#create_image/3","title":"AWS.Imagebuilder.create_image/3","type":"function","doc":"Creates a new image. This request will create a new image along with all of the configured output resources defined in the distribution configuration."},{"ref":"AWS.Imagebuilder.html#create_image_pipeline/3","title":"AWS.Imagebuilder.create_image_pipeline/3","type":"function","doc":"Creates a new image pipeline. Image pipelines enable you to automate the creation and distribution of images."},{"ref":"AWS.Imagebuilder.html#create_image_recipe/3","title":"AWS.Imagebuilder.create_image_recipe/3","type":"function","doc":"Creates a new image recipe. Image recipes define how images are configured, tested, and assessed."},{"ref":"AWS.Imagebuilder.html#create_infrastructure_configuration/3","title":"AWS.Imagebuilder.create_infrastructure_configuration/3","type":"function","doc":"Creates a new infrastructure configuration. An infrastructure configuration defines the environment in which your image will be built and tested."},{"ref":"AWS.Imagebuilder.html#delete_component/3","title":"AWS.Imagebuilder.delete_component/3","type":"function","doc":"Deletes a component build version."},{"ref":"AWS.Imagebuilder.html#delete_distribution_configuration/3","title":"AWS.Imagebuilder.delete_distribution_configuration/3","type":"function","doc":"Deletes a distribution configuration."},{"ref":"AWS.Imagebuilder.html#delete_image/3","title":"AWS.Imagebuilder.delete_image/3","type":"function","doc":"Deletes an image."},{"ref":"AWS.Imagebuilder.html#delete_image_pipeline/3","title":"AWS.Imagebuilder.delete_image_pipeline/3","type":"function","doc":"Deletes an image pipeline."},{"ref":"AWS.Imagebuilder.html#delete_image_recipe/3","title":"AWS.Imagebuilder.delete_image_recipe/3","type":"function","doc":"Deletes an image recipe."},{"ref":"AWS.Imagebuilder.html#delete_infrastructure_configuration/3","title":"AWS.Imagebuilder.delete_infrastructure_configuration/3","type":"function","doc":"Deletes an infrastructure configuration."},{"ref":"AWS.Imagebuilder.html#get_component/3","title":"AWS.Imagebuilder.get_component/3","type":"function","doc":"Gets a component object."},{"ref":"AWS.Imagebuilder.html#get_component_policy/3","title":"AWS.Imagebuilder.get_component_policy/3","type":"function","doc":"Gets a component policy."},{"ref":"AWS.Imagebuilder.html#get_distribution_configuration/3","title":"AWS.Imagebuilder.get_distribution_configuration/3","type":"function","doc":"Gets a distribution configuration."},{"ref":"AWS.Imagebuilder.html#get_image/3","title":"AWS.Imagebuilder.get_image/3","type":"function","doc":"Gets an image."},{"ref":"AWS.Imagebuilder.html#get_image_pipeline/3","title":"AWS.Imagebuilder.get_image_pipeline/3","type":"function","doc":"Gets an image pipeline."},{"ref":"AWS.Imagebuilder.html#get_image_policy/3","title":"AWS.Imagebuilder.get_image_policy/3","type":"function","doc":"Gets an image policy."},{"ref":"AWS.Imagebuilder.html#get_image_recipe/3","title":"AWS.Imagebuilder.get_image_recipe/3","type":"function","doc":"Gets an image recipe."},{"ref":"AWS.Imagebuilder.html#get_image_recipe_policy/3","title":"AWS.Imagebuilder.get_image_recipe_policy/3","type":"function","doc":"Gets an image recipe policy."},{"ref":"AWS.Imagebuilder.html#get_infrastructure_configuration/3","title":"AWS.Imagebuilder.get_infrastructure_configuration/3","type":"function","doc":"Gets an infrastructure configuration."},{"ref":"AWS.Imagebuilder.html#import_component/3","title":"AWS.Imagebuilder.import_component/3","type":"function","doc":"Imports a component and transforms its data into a component document."},{"ref":"AWS.Imagebuilder.html#list_component_build_versions/3","title":"AWS.Imagebuilder.list_component_build_versions/3","type":"function","doc":"Returns the list of component build versions for the specified semantic version."},{"ref":"AWS.Imagebuilder.html#list_components/3","title":"AWS.Imagebuilder.list_components/3","type":"function","doc":"Returns the list of component build versions for the specified semantic version."},{"ref":"AWS.Imagebuilder.html#list_distribution_configurations/3","title":"AWS.Imagebuilder.list_distribution_configurations/3","type":"function","doc":"Returns a list of distribution configurations."},{"ref":"AWS.Imagebuilder.html#list_image_build_versions/3","title":"AWS.Imagebuilder.list_image_build_versions/3","type":"function","doc":"Returns a list of image build versions."},{"ref":"AWS.Imagebuilder.html#list_image_pipeline_images/3","title":"AWS.Imagebuilder.list_image_pipeline_images/3","type":"function","doc":"Returns a list of images created by the specified pipeline."},{"ref":"AWS.Imagebuilder.html#list_image_pipelines/3","title":"AWS.Imagebuilder.list_image_pipelines/3","type":"function","doc":"Returns a list of image pipelines."},{"ref":"AWS.Imagebuilder.html#list_image_recipes/3","title":"AWS.Imagebuilder.list_image_recipes/3","type":"function","doc":"Returns a list of image recipes."},{"ref":"AWS.Imagebuilder.html#list_images/3","title":"AWS.Imagebuilder.list_images/3","type":"function","doc":"Returns the list of images that you have access to."},{"ref":"AWS.Imagebuilder.html#list_infrastructure_configurations/3","title":"AWS.Imagebuilder.list_infrastructure_configurations/3","type":"function","doc":"Returns a list of infrastructure configurations."},{"ref":"AWS.Imagebuilder.html#list_tags_for_resource/3","title":"AWS.Imagebuilder.list_tags_for_resource/3","type":"function","doc":"Returns the list of tags for the specified resource."},{"ref":"AWS.Imagebuilder.html#put_component_policy/3","title":"AWS.Imagebuilder.put_component_policy/3","type":"function","doc":"Applies a policy to a component. We recommend that you call the RAM API CreateResourceShare to share resources. If you call the Image Builder API PutComponentPolicy, you must also call the RAM API PromoteResourceShareCreatedFromPolicy in order for the resource to be visible to all principals with whom the resource is shared."},{"ref":"AWS.Imagebuilder.html#put_image_policy/3","title":"AWS.Imagebuilder.put_image_policy/3","type":"function","doc":"Applies a policy to an image. We recommend that you call the RAM API CreateResourceShare to share resources. If you call the Image Builder API PutImagePolicy, you must also call the RAM API PromoteResourceShareCreatedFromPolicy in order for the resource to be visible to all principals with whom the resource is shared."},{"ref":"AWS.Imagebuilder.html#put_image_recipe_policy/3","title":"AWS.Imagebuilder.put_image_recipe_policy/3","type":"function","doc":"Applies a policy to an image recipe. We recommend that you call the RAM API CreateResourceShare to share resources. If you call the Image Builder API PutImageRecipePolicy, you must also call the RAM API PromoteResourceShareCreatedFromPolicy in order for the resource to be visible to all principals with whom the resource is shared."},{"ref":"AWS.Imagebuilder.html#start_image_pipeline_execution/3","title":"AWS.Imagebuilder.start_image_pipeline_execution/3","type":"function","doc":"Manually triggers a pipeline to create an image."},{"ref":"AWS.Imagebuilder.html#tag_resource/4","title":"AWS.Imagebuilder.tag_resource/4","type":"function","doc":"Adds a tag to a resource."},{"ref":"AWS.Imagebuilder.html#untag_resource/4","title":"AWS.Imagebuilder.untag_resource/4","type":"function","doc":"Removes a tag from a resource."},{"ref":"AWS.Imagebuilder.html#update_distribution_configuration/3","title":"AWS.Imagebuilder.update_distribution_configuration/3","type":"function","doc":"Updates a new distribution configuration. Distribution configurations define and configure the outputs of your pipeline."},{"ref":"AWS.Imagebuilder.html#update_image_pipeline/3","title":"AWS.Imagebuilder.update_image_pipeline/3","type":"function","doc":"Updates a new image pipeline. Image pipelines enable you to automate the creation and distribution of images."},{"ref":"AWS.Imagebuilder.html#update_infrastructure_configuration/3","title":"AWS.Imagebuilder.update_infrastructure_configuration/3","type":"function","doc":"Updates a new infrastructure configuration. An infrastructure configuration defines the environment in which your image will be built and tested."},{"ref":"AWS.Importexport.html","title":"AWS.Importexport","type":"module","doc":"AWS Import/Export Service AWS Import/Export accelerates transferring large amounts of data between the AWS cloud and portable storage devices that you mail to us. AWS Import/Export transfers data directly onto and off of your storage devices using Amazon&#39;s high-speed internal network and bypassing the Internet. For large data sets, AWS Import/Export is often faster than Internet transfer and more cost effective than upgrading your connectivity."},{"ref":"AWS.Importexport.html#cancel_job/3","title":"AWS.Importexport.cancel_job/3","type":"function","doc":"This operation cancels a specified job. Only the job owner can cancel it. The operation fails if the job has already started or is complete."},{"ref":"AWS.Importexport.html#create_job/3","title":"AWS.Importexport.create_job/3","type":"function","doc":"This operation initiates the process of scheduling an upload or download of your data. You include in the request a manifest that describes the data transfer specifics. The response to the request includes a job ID, which you can use in other operations, a signature that you use to identify your storage device, and the address where you should ship your storage device."},{"ref":"AWS.Importexport.html#get_shipping_label/3","title":"AWS.Importexport.get_shipping_label/3","type":"function","doc":"This operation generates a pre-paid UPS shipping label that you will use to ship your device to AWS for processing."},{"ref":"AWS.Importexport.html#get_status/3","title":"AWS.Importexport.get_status/3","type":"function","doc":"This operation returns information about a job, including where the job is in the processing pipeline, the status of the results, and the signature value associated with the job. You can only return information about jobs you own."},{"ref":"AWS.Importexport.html#list_jobs/3","title":"AWS.Importexport.list_jobs/3","type":"function","doc":"This operation returns the jobs associated with the requester. AWS Import/Export lists the jobs in reverse chronological order based on the date of creation. For example if Job Test1 was created 2009Dec30 and Test2 was created 2010Feb05, the ListJobs operation would return Test2 followed by Test1."},{"ref":"AWS.Importexport.html#update_job/3","title":"AWS.Importexport.update_job/3","type":"function","doc":"You use this operation to change the parameters specified in the original manifest file by supplying a new manifest file. The manifest file attached to this request replaces the original manifest file. You can only use the operation after a CreateJob request but before the data transfer starts and you can only use it on jobs you own."},{"ref":"AWS.Inspector.html","title":"AWS.Inspector","type":"module","doc":"Amazon Inspector Amazon Inspector enables you to analyze the behavior of your AWS resources and to identify potential security issues. For more information, see Amazon Inspector User Guide."},{"ref":"AWS.Inspector.html#add_attributes_to_findings/3","title":"AWS.Inspector.add_attributes_to_findings/3","type":"function","doc":"Assigns attributes (key and value pairs) to the findings that are specified by the ARNs of the findings."},{"ref":"AWS.Inspector.html#create_assessment_target/3","title":"AWS.Inspector.create_assessment_target/3","type":"function","doc":"Creates a new assessment target using the ARN of the resource group that is generated by CreateResourceGroup. If resourceGroupArn is not specified, all EC2 instances in the current AWS account and region are included in the assessment target. If the service-linked role isnt already registered, this action also creates and registers a service-linked role to grant Amazon Inspector access to AWS Services needed to perform security assessments. You can create up to 50 assessment targets per AWS account. You can run up to 500 concurrent agents per AWS account. For more information, see Amazon Inspector Assessment Targets."},{"ref":"AWS.Inspector.html#create_assessment_template/3","title":"AWS.Inspector.create_assessment_template/3","type":"function","doc":"Creates an assessment template for the assessment target that is specified by the ARN of the assessment target. If the service-linked role isnt already registered, this action also creates and registers a service-linked role to grant Amazon Inspector access to AWS Services needed to perform security assessments."},{"ref":"AWS.Inspector.html#create_exclusions_preview/3","title":"AWS.Inspector.create_exclusions_preview/3","type":"function","doc":"Starts the generation of an exclusions preview for the specified assessment template. The exclusions preview lists the potential exclusions (ExclusionPreview) that Inspector can detect before it runs the assessment."},{"ref":"AWS.Inspector.html#create_resource_group/3","title":"AWS.Inspector.create_resource_group/3","type":"function","doc":"Creates a resource group using the specified set of tags (key and value pairs) that are used to select the EC2 instances to be included in an Amazon Inspector assessment target. The created resource group is then used to create an Amazon Inspector assessment target. For more information, see CreateAssessmentTarget."},{"ref":"AWS.Inspector.html#delete_assessment_run/3","title":"AWS.Inspector.delete_assessment_run/3","type":"function","doc":"Deletes the assessment run that is specified by the ARN of the assessment run."},{"ref":"AWS.Inspector.html#delete_assessment_target/3","title":"AWS.Inspector.delete_assessment_target/3","type":"function","doc":"Deletes the assessment target that is specified by the ARN of the assessment target."},{"ref":"AWS.Inspector.html#delete_assessment_template/3","title":"AWS.Inspector.delete_assessment_template/3","type":"function","doc":"Deletes the assessment template that is specified by the ARN of the assessment template."},{"ref":"AWS.Inspector.html#describe_assessment_runs/3","title":"AWS.Inspector.describe_assessment_runs/3","type":"function","doc":"Describes the assessment runs that are specified by the ARNs of the assessment runs."},{"ref":"AWS.Inspector.html#describe_assessment_targets/3","title":"AWS.Inspector.describe_assessment_targets/3","type":"function","doc":"Describes the assessment targets that are specified by the ARNs of the assessment targets."},{"ref":"AWS.Inspector.html#describe_assessment_templates/3","title":"AWS.Inspector.describe_assessment_templates/3","type":"function","doc":"Describes the assessment templates that are specified by the ARNs of the assessment templates."},{"ref":"AWS.Inspector.html#describe_cross_account_access_role/3","title":"AWS.Inspector.describe_cross_account_access_role/3","type":"function","doc":"Describes the IAM role that enables Amazon Inspector to access your AWS account."},{"ref":"AWS.Inspector.html#describe_exclusions/3","title":"AWS.Inspector.describe_exclusions/3","type":"function","doc":"Describes the exclusions that are specified by the exclusions&#39; ARNs."},{"ref":"AWS.Inspector.html#describe_findings/3","title":"AWS.Inspector.describe_findings/3","type":"function","doc":"Describes the findings that are specified by the ARNs of the findings."},{"ref":"AWS.Inspector.html#describe_resource_groups/3","title":"AWS.Inspector.describe_resource_groups/3","type":"function","doc":"Describes the resource groups that are specified by the ARNs of the resource groups."},{"ref":"AWS.Inspector.html#describe_rules_packages/3","title":"AWS.Inspector.describe_rules_packages/3","type":"function","doc":"Describes the rules packages that are specified by the ARNs of the rules packages."},{"ref":"AWS.Inspector.html#get_assessment_report/3","title":"AWS.Inspector.get_assessment_report/3","type":"function","doc":"Produces an assessment report that includes detailed and comprehensive results of a specified assessment run."},{"ref":"AWS.Inspector.html#get_exclusions_preview/3","title":"AWS.Inspector.get_exclusions_preview/3","type":"function","doc":"Retrieves the exclusions preview (a list of ExclusionPreview objects) specified by the preview token. You can obtain the preview token by running the CreateExclusionsPreview API."},{"ref":"AWS.Inspector.html#get_telemetry_metadata/3","title":"AWS.Inspector.get_telemetry_metadata/3","type":"function","doc":"Information about the data that is collected for the specified assessment run."},{"ref":"AWS.Inspector.html#list_assessment_run_agents/3","title":"AWS.Inspector.list_assessment_run_agents/3","type":"function","doc":"Lists the agents of the assessment runs that are specified by the ARNs of the assessment runs."},{"ref":"AWS.Inspector.html#list_assessment_runs/3","title":"AWS.Inspector.list_assessment_runs/3","type":"function","doc":"Lists the assessment runs that correspond to the assessment templates that are specified by the ARNs of the assessment templates."},{"ref":"AWS.Inspector.html#list_assessment_targets/3","title":"AWS.Inspector.list_assessment_targets/3","type":"function","doc":"Lists the ARNs of the assessment targets within this AWS account. For more information about assessment targets, see Amazon Inspector Assessment Targets."},{"ref":"AWS.Inspector.html#list_assessment_templates/3","title":"AWS.Inspector.list_assessment_templates/3","type":"function","doc":"Lists the assessment templates that correspond to the assessment targets that are specified by the ARNs of the assessment targets."},{"ref":"AWS.Inspector.html#list_event_subscriptions/3","title":"AWS.Inspector.list_event_subscriptions/3","type":"function","doc":"Lists all the event subscriptions for the assessment template that is specified by the ARN of the assessment template. For more information, see SubscribeToEvent and UnsubscribeFromEvent."},{"ref":"AWS.Inspector.html#list_exclusions/3","title":"AWS.Inspector.list_exclusions/3","type":"function","doc":"List exclusions that are generated by the assessment run."},{"ref":"AWS.Inspector.html#list_findings/3","title":"AWS.Inspector.list_findings/3","type":"function","doc":"Lists findings that are generated by the assessment runs that are specified by the ARNs of the assessment runs."},{"ref":"AWS.Inspector.html#list_rules_packages/3","title":"AWS.Inspector.list_rules_packages/3","type":"function","doc":"Lists all available Amazon Inspector rules packages."},{"ref":"AWS.Inspector.html#list_tags_for_resource/3","title":"AWS.Inspector.list_tags_for_resource/3","type":"function","doc":"Lists all tags associated with an assessment template."},{"ref":"AWS.Inspector.html#preview_agents/3","title":"AWS.Inspector.preview_agents/3","type":"function","doc":"Previews the agents installed on the EC2 instances that are part of the specified assessment target."},{"ref":"AWS.Inspector.html#register_cross_account_access_role/3","title":"AWS.Inspector.register_cross_account_access_role/3","type":"function","doc":"Registers the IAM role that grants Amazon Inspector access to AWS Services needed to perform security assessments."},{"ref":"AWS.Inspector.html#remove_attributes_from_findings/3","title":"AWS.Inspector.remove_attributes_from_findings/3","type":"function","doc":"Removes entire attributes (key and value pairs) from the findings that are specified by the ARNs of the findings where an attribute with the specified key exists."},{"ref":"AWS.Inspector.html#set_tags_for_resource/3","title":"AWS.Inspector.set_tags_for_resource/3","type":"function","doc":"Sets tags (key and value pairs) to the assessment template that is specified by the ARN of the assessment template."},{"ref":"AWS.Inspector.html#start_assessment_run/3","title":"AWS.Inspector.start_assessment_run/3","type":"function","doc":"Starts the assessment run specified by the ARN of the assessment template. For this API to function properly, you must not exceed the limit of running up to 500 concurrent agents per AWS account."},{"ref":"AWS.Inspector.html#stop_assessment_run/3","title":"AWS.Inspector.stop_assessment_run/3","type":"function","doc":"Stops the assessment run that is specified by the ARN of the assessment run."},{"ref":"AWS.Inspector.html#subscribe_to_event/3","title":"AWS.Inspector.subscribe_to_event/3","type":"function","doc":"Enables the process of sending Amazon Simple Notification Service (SNS) notifications about a specified event to a specified SNS topic."},{"ref":"AWS.Inspector.html#unsubscribe_from_event/3","title":"AWS.Inspector.unsubscribe_from_event/3","type":"function","doc":"Disables the process of sending Amazon Simple Notification Service (SNS) notifications about a specified event to a specified SNS topic."},{"ref":"AWS.Inspector.html#update_assessment_target/3","title":"AWS.Inspector.update_assessment_target/3","type":"function","doc":"Updates the assessment target that is specified by the ARN of the assessment target. If resourceGroupArn is not specified, all EC2 instances in the current AWS account and region are included in the assessment target."},{"ref":"AWS.IoT.html","title":"AWS.IoT","type":"module","doc":"AWS IoT AWS IoT provides secure, bi-directional communication between Internet-connected devices (such as sensors, actuators, embedded devices, or smart appliances) and the AWS cloud. You can discover your custom IoT-Data endpoint to communicate with, configure rules for data processing and integration with other services, organize resources associated with each device (Registry), configure logging, and create and manage policies and credentials to authenticate devices. The service endpoints that expose this API are listed in AWS IoT Core Endpoints and Quotas. You must use the endpoint for the region that has the resources you want to access. The service name used by AWS Signature Version 4 to sign the request is: execute-api. For more information about how AWS IoT works, see the Developer Guide. For information about how to use the credentials provider for AWS IoT, see Authorizing Direct Calls to AWS Services."},{"ref":"AWS.IoT.html#accept_certificate_transfer/4","title":"AWS.IoT.accept_certificate_transfer/4","type":"function","doc":"Accepts a pending certificate transfer. The default state of the certificate is INACTIVE. To check for pending certificate transfers, call ListCertificates to enumerate your certificates."},{"ref":"AWS.IoT.html#add_thing_to_billing_group/3","title":"AWS.IoT.add_thing_to_billing_group/3","type":"function","doc":"Adds a thing to a billing group."},{"ref":"AWS.IoT.html#add_thing_to_thing_group/3","title":"AWS.IoT.add_thing_to_thing_group/3","type":"function","doc":"Adds a thing to a thing group."},{"ref":"AWS.IoT.html#associate_targets_with_job/4","title":"AWS.IoT.associate_targets_with_job/4","type":"function","doc":"Associates a group with a continuous job. The following criteria must be met: The job must have been created with the targetSelection field set to &quot;CONTINUOUS&quot;. The job status must currently be &quot;IN_PROGRESS&quot;. The total number of targets associated with a job must not exceed 100."},{"ref":"AWS.IoT.html#attach_policy/4","title":"AWS.IoT.attach_policy/4","type":"function","doc":"Attaches a policy to the specified target."},{"ref":"AWS.IoT.html#attach_principal_policy/4","title":"AWS.IoT.attach_principal_policy/4","type":"function","doc":"Attaches the specified policy to the specified principal (certificate or other credential). Note: This API is deprecated. Please use AttachPolicy instead."},{"ref":"AWS.IoT.html#attach_security_profile/4","title":"AWS.IoT.attach_security_profile/4","type":"function","doc":"Associates a Device Defender security profile with a thing group or this account. Each thing group or account can have up to five security profiles associated with it."},{"ref":"AWS.IoT.html#attach_thing_principal/4","title":"AWS.IoT.attach_thing_principal/4","type":"function","doc":"Attaches the specified principal to the specified thing. A principal can be X.509 certificates, IAM users, groups, and roles, Amazon Cognito identities or federated identities."},{"ref":"AWS.IoT.html#cancel_audit_mitigation_actions_task/4","title":"AWS.IoT.cancel_audit_mitigation_actions_task/4","type":"function","doc":"Cancels a mitigation action task that is in progress. If the task is not in progress, an InvalidRequestException occurs."},{"ref":"AWS.IoT.html#cancel_audit_task/4","title":"AWS.IoT.cancel_audit_task/4","type":"function","doc":"Cancels an audit that is in progress. The audit can be either scheduled or on-demand. If the audit is not in progress, an &quot;InvalidRequestException&quot; occurs."},{"ref":"AWS.IoT.html#cancel_certificate_transfer/4","title":"AWS.IoT.cancel_certificate_transfer/4","type":"function","doc":"Cancels a pending transfer for the specified certificate. Note Only the transfer source account can use this operation to cancel a transfer. (Transfer destinations can use RejectCertificateTransfer instead.) After transfer, AWS IoT returns the certificate to the source account in the INACTIVE state. After the destination account has accepted the transfer, the transfer cannot be cancelled. After a certificate transfer is cancelled, the status of the certificate changes from PENDING_TRANSFER to INACTIVE."},{"ref":"AWS.IoT.html#cancel_job/4","title":"AWS.IoT.cancel_job/4","type":"function","doc":"Cancels a job."},{"ref":"AWS.IoT.html#cancel_job_execution/5","title":"AWS.IoT.cancel_job_execution/5","type":"function","doc":"Cancels the execution of a job for a given thing."},{"ref":"AWS.IoT.html#clear_default_authorizer/3","title":"AWS.IoT.clear_default_authorizer/3","type":"function","doc":"Clears the default authorizer."},{"ref":"AWS.IoT.html#confirm_topic_rule_destination/3","title":"AWS.IoT.confirm_topic_rule_destination/3","type":"function","doc":"Confirms a topic rule destination. When you create a rule requiring a destination, AWS IoT sends a confirmation message to the endpoint or base address you specify. The message includes a token which you pass back when calling ConfirmTopicRuleDestination to confirm that you own or have access to the endpoint."},{"ref":"AWS.IoT.html#create_audit_suppression/3","title":"AWS.IoT.create_audit_suppression/3","type":"function","doc":"Creates a Device Defender audit suppression."},{"ref":"AWS.IoT.html#create_authorizer/4","title":"AWS.IoT.create_authorizer/4","type":"function","doc":"Creates an authorizer."},{"ref":"AWS.IoT.html#create_billing_group/4","title":"AWS.IoT.create_billing_group/4","type":"function","doc":"Creates a billing group."},{"ref":"AWS.IoT.html#create_certificate_from_csr/3","title":"AWS.IoT.create_certificate_from_csr/3","type":"function","doc":"Creates an X.509 certificate using the specified certificate signing request. Note: The CSR must include a public key that is either an RSA key with a length of at least 2048 bits or an ECC key from NIST P-256 or NIST P-384 curves. Note: Reusing the same certificate signing request (CSR) results in a distinct certificate. You can create multiple certificates in a batch by creating a directory, copying multiple .csr files into that directory, and then specifying that directory on the command line. The following commands show how to create a batch of certificates given a batch of CSRs. Assuming a set of CSRs are located inside of the directory my-csr-directory: On Linux and OS X, the command is: $ ls my-csr-directory/ | xargs -I {} aws iot create-certificate-from-csr --certificate-signing-request file://my-csr-directory/{} This command lists all of the CSRs in my-csr-directory and pipes each CSR file name to the aws iot create-certificate-from-csr AWS CLI command to create a certificate for the corresponding CSR. The aws iot create-certificate-from-csr part of the command can also be run in parallel to speed up the certificate creation process: $ ls my-csr-directory/ | xargs -P 10 -I {} aws iot create-certificate-from-csr --certificate-signing-request file://my-csr-directory/{} On Windows PowerShell, the command to create certificates for all CSRs in my-csr-directory is: ls -Name my-csr-directory | %{aws iot create-certificate-from-csr --certificate-signing-request file://my-csr-directory/$_} On a Windows command prompt, the command to create certificates for all CSRs in my-csr-directory is: forfiles /p my-csr-directory /c &quot;cmd /c aws iot create-certificate-from-csr --certificate-signing-request file://@path&quot;"},{"ref":"AWS.IoT.html#create_dimension/4","title":"AWS.IoT.create_dimension/4","type":"function","doc":"Create a dimension that you can use to limit the scope of a metric used in a security profile for AWS IoT Device Defender. For example, using a TOPIC_FILTER dimension, you can narrow down the scope of the metric only to MQTT topics whose name match the pattern specified in the dimension."},{"ref":"AWS.IoT.html#create_domain_configuration/4","title":"AWS.IoT.create_domain_configuration/4","type":"function","doc":"Creates a domain configuration. The domain configuration feature is in public preview and is subject to change."},{"ref":"AWS.IoT.html#create_dynamic_thing_group/4","title":"AWS.IoT.create_dynamic_thing_group/4","type":"function","doc":"Creates a dynamic thing group."},{"ref":"AWS.IoT.html#create_job/4","title":"AWS.IoT.create_job/4","type":"function","doc":"Creates a job."},{"ref":"AWS.IoT.html#create_keys_and_certificate/3","title":"AWS.IoT.create_keys_and_certificate/3","type":"function","doc":"Creates a 2048-bit RSA key pair and issues an X.509 certificate using the issued public key. You can also call CreateKeysAndCertificate over MQTT from a device, for more information, see Provisioning MQTT API. Note This is the only time AWS IoT issues the private key for this certificate, so it is important to keep it in a secure location."},{"ref":"AWS.IoT.html#create_mitigation_action/4","title":"AWS.IoT.create_mitigation_action/4","type":"function","doc":"Defines an action that can be applied to audit findings by using StartAuditMitigationActionsTask. Only certain types of mitigation actions can be applied to specific check names. For more information, see Mitigation actions. Each mitigation action can apply only one type of change."},{"ref":"AWS.IoT.html#create_o_t_a_update/4","title":"AWS.IoT.create_o_t_a_update/4","type":"function","doc":"Creates an AWS IoT OTAUpdate on a target group of things or groups."},{"ref":"AWS.IoT.html#create_policy/4","title":"AWS.IoT.create_policy/4","type":"function","doc":"Creates an AWS IoT policy. The created policy is the default version for the policy. This operation creates a policy version with a version identifier of 1 and sets 1 as the policy&#39;s default version."},{"ref":"AWS.IoT.html#create_policy_version/4","title":"AWS.IoT.create_policy_version/4","type":"function","doc":"Creates a new version of the specified AWS IoT policy. To update a policy, create a new policy version. A managed policy can have up to five versions. If the policy has five versions, you must use DeletePolicyVersion to delete an existing version before you create a new one. Optionally, you can set the new version as the policy&#39;s default version. The default version is the operative version (that is, the version that is in effect for the certificates to which the policy is attached)."},{"ref":"AWS.IoT.html#create_provisioning_claim/4","title":"AWS.IoT.create_provisioning_claim/4","type":"function","doc":"Creates a provisioning claim."},{"ref":"AWS.IoT.html#create_provisioning_template/3","title":"AWS.IoT.create_provisioning_template/3","type":"function","doc":"Creates a fleet provisioning template."},{"ref":"AWS.IoT.html#create_provisioning_template_version/4","title":"AWS.IoT.create_provisioning_template_version/4","type":"function","doc":"Creates a new version of a fleet provisioning template."},{"ref":"AWS.IoT.html#create_role_alias/4","title":"AWS.IoT.create_role_alias/4","type":"function","doc":"Creates a role alias."},{"ref":"AWS.IoT.html#create_scheduled_audit/4","title":"AWS.IoT.create_scheduled_audit/4","type":"function","doc":"Creates a scheduled audit that is run at a specified time interval."},{"ref":"AWS.IoT.html#create_security_profile/4","title":"AWS.IoT.create_security_profile/4","type":"function","doc":"Creates a Device Defender security profile."},{"ref":"AWS.IoT.html#create_stream/4","title":"AWS.IoT.create_stream/4","type":"function","doc":"Creates a stream for delivering one or more large files in chunks over MQTT. A stream transports data bytes in chunks or blocks packaged as MQTT messages from a source like S3. You can have one or more files associated with a stream."},{"ref":"AWS.IoT.html#create_thing/4","title":"AWS.IoT.create_thing/4","type":"function","doc":"Creates a thing record in the registry. If this call is made multiple times using the same thing name and configuration, the call will succeed. If this call is made with the same thing name but different configuration a ResourceAlreadyExistsException is thrown. This is a control plane operation. See Authorization for information about authorizing control plane actions."},{"ref":"AWS.IoT.html#create_thing_group/4","title":"AWS.IoT.create_thing_group/4","type":"function","doc":"Create a thing group. This is a control plane operation. See Authorization for information about authorizing control plane actions."},{"ref":"AWS.IoT.html#create_thing_type/4","title":"AWS.IoT.create_thing_type/4","type":"function","doc":"Creates a new thing type."},{"ref":"AWS.IoT.html#create_topic_rule/4","title":"AWS.IoT.create_topic_rule/4","type":"function","doc":"Creates a rule. Creating rules is an administrator-level action. Any user who has permission to create rules will be able to access data processed by the rule."},{"ref":"AWS.IoT.html#create_topic_rule_destination/3","title":"AWS.IoT.create_topic_rule_destination/3","type":"function","doc":"Creates a topic rule destination. The destination must be confirmed prior to use."},{"ref":"AWS.IoT.html#delete_account_audit_configuration/3","title":"AWS.IoT.delete_account_audit_configuration/3","type":"function","doc":"Restores the default settings for Device Defender audits for this account. Any configuration data you entered is deleted and all audit checks are reset to disabled."},{"ref":"AWS.IoT.html#delete_audit_suppression/3","title":"AWS.IoT.delete_audit_suppression/3","type":"function","doc":"Deletes a Device Defender audit suppression."},{"ref":"AWS.IoT.html#delete_authorizer/4","title":"AWS.IoT.delete_authorizer/4","type":"function","doc":"Deletes an authorizer."},{"ref":"AWS.IoT.html#delete_billing_group/4","title":"AWS.IoT.delete_billing_group/4","type":"function","doc":"Deletes the billing group."},{"ref":"AWS.IoT.html#delete_c_a_certificate/4","title":"AWS.IoT.delete_c_a_certificate/4","type":"function","doc":"Deletes a registered CA certificate."},{"ref":"AWS.IoT.html#delete_certificate/4","title":"AWS.IoT.delete_certificate/4","type":"function","doc":"Deletes the specified certificate. A certificate cannot be deleted if it has a policy or IoT thing attached to it or if its status is set to ACTIVE. To delete a certificate, first use the DetachPrincipalPolicy API to detach all policies. Next, use the UpdateCertificate API to set the certificate to the INACTIVE status."},{"ref":"AWS.IoT.html#delete_dimension/4","title":"AWS.IoT.delete_dimension/4","type":"function","doc":"Removes the specified dimension from your AWS account."},{"ref":"AWS.IoT.html#delete_domain_configuration/4","title":"AWS.IoT.delete_domain_configuration/4","type":"function","doc":"Deletes the specified domain configuration. The domain configuration feature is in public preview and is subject to change."},{"ref":"AWS.IoT.html#delete_dynamic_thing_group/4","title":"AWS.IoT.delete_dynamic_thing_group/4","type":"function","doc":"Deletes a dynamic thing group."},{"ref":"AWS.IoT.html#delete_job/4","title":"AWS.IoT.delete_job/4","type":"function","doc":"Deletes a job and its related job executions. Deleting a job may take time, depending on the number of job executions created for the job and various other factors. While the job is being deleted, the status of the job will be shown as &quot;DELETION_IN_PROGRESS&quot;. Attempting to delete or cancel a job whose status is already &quot;DELETION_IN_PROGRESS&quot; will result in an error. Only 10 jobs may have status &quot;DELETION_IN_PROGRESS&quot; at the same time, or a LimitExceededException will occur."},{"ref":"AWS.IoT.html#delete_job_execution/6","title":"AWS.IoT.delete_job_execution/6","type":"function","doc":"Deletes a job execution."},{"ref":"AWS.IoT.html#delete_mitigation_action/4","title":"AWS.IoT.delete_mitigation_action/4","type":"function","doc":"Deletes a defined mitigation action from your AWS account."},{"ref":"AWS.IoT.html#delete_o_t_a_update/4","title":"AWS.IoT.delete_o_t_a_update/4","type":"function","doc":"Delete an OTA update."},{"ref":"AWS.IoT.html#delete_policy/4","title":"AWS.IoT.delete_policy/4","type":"function","doc":"Deletes the specified policy. A policy cannot be deleted if it has non-default versions or it is attached to any certificate. To delete a policy, use the DeletePolicyVersion API to delete all non-default versions of the policy; use the DetachPrincipalPolicy API to detach the policy from any certificate; and then use the DeletePolicy API to delete the policy. When a policy is deleted using DeletePolicy, its default version is deleted with it."},{"ref":"AWS.IoT.html#delete_policy_version/5","title":"AWS.IoT.delete_policy_version/5","type":"function","doc":"Deletes the specified version of the specified policy. You cannot delete the default version of a policy using this API. To delete the default version of a policy, use DeletePolicy. To find out which version of a policy is marked as the default version, use ListPolicyVersions."},{"ref":"AWS.IoT.html#delete_provisioning_template/4","title":"AWS.IoT.delete_provisioning_template/4","type":"function","doc":"Deletes a fleet provisioning template."},{"ref":"AWS.IoT.html#delete_provisioning_template_version/5","title":"AWS.IoT.delete_provisioning_template_version/5","type":"function","doc":"Deletes a fleet provisioning template version."},{"ref":"AWS.IoT.html#delete_registration_code/3","title":"AWS.IoT.delete_registration_code/3","type":"function","doc":"Deletes a CA certificate registration code."},{"ref":"AWS.IoT.html#delete_role_alias/4","title":"AWS.IoT.delete_role_alias/4","type":"function","doc":"Deletes a role alias"},{"ref":"AWS.IoT.html#delete_scheduled_audit/4","title":"AWS.IoT.delete_scheduled_audit/4","type":"function","doc":"Deletes a scheduled audit."},{"ref":"AWS.IoT.html#delete_security_profile/4","title":"AWS.IoT.delete_security_profile/4","type":"function","doc":"Deletes a Device Defender security profile."},{"ref":"AWS.IoT.html#delete_stream/4","title":"AWS.IoT.delete_stream/4","type":"function","doc":"Deletes a stream."},{"ref":"AWS.IoT.html#delete_thing/4","title":"AWS.IoT.delete_thing/4","type":"function","doc":"Deletes the specified thing. Returns successfully with no error if the deletion is successful or you specify a thing that doesn&#39;t exist."},{"ref":"AWS.IoT.html#delete_thing_group/4","title":"AWS.IoT.delete_thing_group/4","type":"function","doc":"Deletes a thing group."},{"ref":"AWS.IoT.html#delete_thing_type/4","title":"AWS.IoT.delete_thing_type/4","type":"function","doc":"Deletes the specified thing type. You cannot delete a thing type if it has things associated with it. To delete a thing type, first mark it as deprecated by calling DeprecateThingType, then remove any associated things by calling UpdateThing to change the thing type on any associated thing, and finally use DeleteThingType to delete the thing type."},{"ref":"AWS.IoT.html#delete_topic_rule/4","title":"AWS.IoT.delete_topic_rule/4","type":"function","doc":"Deletes the rule."},{"ref":"AWS.IoT.html#delete_topic_rule_destination/4","title":"AWS.IoT.delete_topic_rule_destination/4","type":"function","doc":"Deletes a topic rule destination."},{"ref":"AWS.IoT.html#delete_v2_logging_level/3","title":"AWS.IoT.delete_v2_logging_level/3","type":"function","doc":"Deletes a logging level."},{"ref":"AWS.IoT.html#deprecate_thing_type/4","title":"AWS.IoT.deprecate_thing_type/4","type":"function","doc":"Deprecates a thing type. You can not associate new things with deprecated thing type."},{"ref":"AWS.IoT.html#describe_account_audit_configuration/2","title":"AWS.IoT.describe_account_audit_configuration/2","type":"function","doc":"Gets information about the Device Defender audit settings for this account. Settings include how audit notifications are sent and which audit checks are enabled or disabled."},{"ref":"AWS.IoT.html#describe_audit_finding/3","title":"AWS.IoT.describe_audit_finding/3","type":"function","doc":"Gets information about a single audit finding. Properties include the reason for noncompliance, the severity of the issue, and when the audit that returned the finding was started."},{"ref":"AWS.IoT.html#describe_audit_mitigation_actions_task/3","title":"AWS.IoT.describe_audit_mitigation_actions_task/3","type":"function","doc":"Gets information about an audit mitigation task that is used to apply mitigation actions to a set of audit findings. Properties include the actions being applied, the audit checks to which they&#39;re being applied, the task status, and aggregated task statistics."},{"ref":"AWS.IoT.html#describe_audit_suppression/3","title":"AWS.IoT.describe_audit_suppression/3","type":"function","doc":"Gets information about a Device Defender audit suppression."},{"ref":"AWS.IoT.html#describe_audit_task/3","title":"AWS.IoT.describe_audit_task/3","type":"function","doc":"Gets information about a Device Defender audit."},{"ref":"AWS.IoT.html#describe_authorizer/3","title":"AWS.IoT.describe_authorizer/3","type":"function","doc":"Describes an authorizer."},{"ref":"AWS.IoT.html#describe_billing_group/3","title":"AWS.IoT.describe_billing_group/3","type":"function","doc":"Returns information about a billing group."},{"ref":"AWS.IoT.html#describe_c_a_certificate/3","title":"AWS.IoT.describe_c_a_certificate/3","type":"function","doc":"Describes a registered CA certificate."},{"ref":"AWS.IoT.html#describe_certificate/3","title":"AWS.IoT.describe_certificate/3","type":"function","doc":"Gets information about the specified certificate."},{"ref":"AWS.IoT.html#describe_default_authorizer/2","title":"AWS.IoT.describe_default_authorizer/2","type":"function","doc":"Describes the default authorizer."},{"ref":"AWS.IoT.html#describe_dimension/3","title":"AWS.IoT.describe_dimension/3","type":"function","doc":"Provides details about a dimension that is defined in your AWS account."},{"ref":"AWS.IoT.html#describe_domain_configuration/3","title":"AWS.IoT.describe_domain_configuration/3","type":"function","doc":"Gets summary information about a domain configuration. The domain configuration feature is in public preview and is subject to change."},{"ref":"AWS.IoT.html#describe_endpoint/3","title":"AWS.IoT.describe_endpoint/3","type":"function","doc":"Returns a unique endpoint specific to the AWS account making the call."},{"ref":"AWS.IoT.html#describe_event_configurations/2","title":"AWS.IoT.describe_event_configurations/2","type":"function","doc":"Describes event configurations."},{"ref":"AWS.IoT.html#describe_index/3","title":"AWS.IoT.describe_index/3","type":"function","doc":"Describes a search index."},{"ref":"AWS.IoT.html#describe_job/3","title":"AWS.IoT.describe_job/3","type":"function","doc":"Describes a job."},{"ref":"AWS.IoT.html#describe_job_execution/5","title":"AWS.IoT.describe_job_execution/5","type":"function","doc":"Describes a job execution."},{"ref":"AWS.IoT.html#describe_mitigation_action/3","title":"AWS.IoT.describe_mitigation_action/3","type":"function","doc":"Gets information about a mitigation action."},{"ref":"AWS.IoT.html#describe_provisioning_template/3","title":"AWS.IoT.describe_provisioning_template/3","type":"function","doc":"Returns information about a fleet provisioning template."},{"ref":"AWS.IoT.html#describe_provisioning_template_version/4","title":"AWS.IoT.describe_provisioning_template_version/4","type":"function","doc":"Returns information about a fleet provisioning template version."},{"ref":"AWS.IoT.html#describe_role_alias/3","title":"AWS.IoT.describe_role_alias/3","type":"function","doc":"Describes a role alias."},{"ref":"AWS.IoT.html#describe_scheduled_audit/3","title":"AWS.IoT.describe_scheduled_audit/3","type":"function","doc":"Gets information about a scheduled audit."},{"ref":"AWS.IoT.html#describe_security_profile/3","title":"AWS.IoT.describe_security_profile/3","type":"function","doc":"Gets information about a Device Defender security profile."},{"ref":"AWS.IoT.html#describe_stream/3","title":"AWS.IoT.describe_stream/3","type":"function","doc":"Gets information about a stream."},{"ref":"AWS.IoT.html#describe_thing/3","title":"AWS.IoT.describe_thing/3","type":"function","doc":"Gets information about the specified thing."},{"ref":"AWS.IoT.html#describe_thing_group/3","title":"AWS.IoT.describe_thing_group/3","type":"function","doc":"Describe a thing group."},{"ref":"AWS.IoT.html#describe_thing_registration_task/3","title":"AWS.IoT.describe_thing_registration_task/3","type":"function","doc":"Describes a bulk thing provisioning task."},{"ref":"AWS.IoT.html#describe_thing_type/3","title":"AWS.IoT.describe_thing_type/3","type":"function","doc":"Gets information about the specified thing type."},{"ref":"AWS.IoT.html#detach_policy/4","title":"AWS.IoT.detach_policy/4","type":"function","doc":"Detaches a policy from the specified target."},{"ref":"AWS.IoT.html#detach_principal_policy/4","title":"AWS.IoT.detach_principal_policy/4","type":"function","doc":"Removes the specified policy from the specified certificate. Note: This API is deprecated. Please use DetachPolicy instead."},{"ref":"AWS.IoT.html#detach_security_profile/4","title":"AWS.IoT.detach_security_profile/4","type":"function","doc":"Disassociates a Device Defender security profile from a thing group or from this account."},{"ref":"AWS.IoT.html#detach_thing_principal/4","title":"AWS.IoT.detach_thing_principal/4","type":"function","doc":"Detaches the specified principal from the specified thing. A principal can be X.509 certificates, IAM users, groups, and roles, Amazon Cognito identities or federated identities. This call is asynchronous. It might take several seconds for the detachment to propagate."},{"ref":"AWS.IoT.html#disable_topic_rule/4","title":"AWS.IoT.disable_topic_rule/4","type":"function","doc":"Disables the rule."},{"ref":"AWS.IoT.html#enable_topic_rule/4","title":"AWS.IoT.enable_topic_rule/4","type":"function","doc":"Enables the rule."},{"ref":"AWS.IoT.html#get_cardinality/3","title":"AWS.IoT.get_cardinality/3","type":"function","doc":"Returns the approximate count of unique values that match the query."},{"ref":"AWS.IoT.html#get_effective_policies/3","title":"AWS.IoT.get_effective_policies/3","type":"function","doc":"Gets a list of the policies that have an effect on the authorization behavior of the specified device when it connects to the AWS IoT device gateway."},{"ref":"AWS.IoT.html#get_indexing_configuration/2","title":"AWS.IoT.get_indexing_configuration/2","type":"function","doc":"Gets the indexing configuration."},{"ref":"AWS.IoT.html#get_job_document/3","title":"AWS.IoT.get_job_document/3","type":"function","doc":"Gets a job document."},{"ref":"AWS.IoT.html#get_logging_options/2","title":"AWS.IoT.get_logging_options/2","type":"function","doc":"Gets the logging options. NOTE: use of this command is not recommended. Use GetV2LoggingOptions instead."},{"ref":"AWS.IoT.html#get_o_t_a_update/3","title":"AWS.IoT.get_o_t_a_update/3","type":"function","doc":"Gets an OTA update."},{"ref":"AWS.IoT.html#get_percentiles/3","title":"AWS.IoT.get_percentiles/3","type":"function","doc":"Groups the aggregated values that match the query into percentile groupings. The default percentile groupings are: 1,5,25,50,75,95,99, although you can specify your own when you call GetPercentiles. This function returns a value for each percentile group specified (or the default percentile groupings). The percentile group &quot;1&quot; contains the aggregated field value that occurs in approximately one percent of the values that match the query. The percentile group &quot;5&quot; contains the aggregated field value that occurs in approximately five percent of the values that match the query, and so on. The result is an approximation, the more values that match the query, the more accurate the percentile values."},{"ref":"AWS.IoT.html#get_policy/3","title":"AWS.IoT.get_policy/3","type":"function","doc":"Gets information about the specified policy with the policy document of the default version."},{"ref":"AWS.IoT.html#get_policy_version/4","title":"AWS.IoT.get_policy_version/4","type":"function","doc":"Gets information about the specified policy version."},{"ref":"AWS.IoT.html#get_registration_code/2","title":"AWS.IoT.get_registration_code/2","type":"function","doc":"Gets a registration code used to register a CA certificate with AWS IoT."},{"ref":"AWS.IoT.html#get_statistics/3","title":"AWS.IoT.get_statistics/3","type":"function","doc":"Returns the count, average, sum, minimum, maximum, sum of squares, variance, and standard deviation for the specified aggregated field. If the aggregation field is of type String, only the count statistic is returned."},{"ref":"AWS.IoT.html#get_topic_rule/3","title":"AWS.IoT.get_topic_rule/3","type":"function","doc":"Gets information about the rule."},{"ref":"AWS.IoT.html#get_topic_rule_destination/3","title":"AWS.IoT.get_topic_rule_destination/3","type":"function","doc":"Gets information about a topic rule destination."},{"ref":"AWS.IoT.html#get_v2_logging_options/2","title":"AWS.IoT.get_v2_logging_options/2","type":"function","doc":"Gets the fine grained logging options."},{"ref":"AWS.IoT.html#list_active_violations/6","title":"AWS.IoT.list_active_violations/6","type":"function","doc":"Lists the active violations for a given Device Defender security profile."},{"ref":"AWS.IoT.html#list_attached_policies/4","title":"AWS.IoT.list_attached_policies/4","type":"function","doc":"Lists the policies attached to the specified thing group."},{"ref":"AWS.IoT.html#list_audit_findings/3","title":"AWS.IoT.list_audit_findings/3","type":"function","doc":"Lists the findings (results) of a Device Defender audit or of the audits performed during a specified time period. (Findings are retained for 90 days.)"},{"ref":"AWS.IoT.html#list_audit_mitigation_actions_executions/7","title":"AWS.IoT.list_audit_mitigation_actions_executions/7","type":"function","doc":"Gets the status of audit mitigation action tasks that were executed."},{"ref":"AWS.IoT.html#list_audit_mitigation_actions_tasks/9","title":"AWS.IoT.list_audit_mitigation_actions_tasks/9","type":"function","doc":"Gets a list of audit mitigation action tasks that match the specified filters."},{"ref":"AWS.IoT.html#list_audit_suppressions/3","title":"AWS.IoT.list_audit_suppressions/3","type":"function","doc":"Lists your Device Defender audit listings."},{"ref":"AWS.IoT.html#list_audit_tasks/8","title":"AWS.IoT.list_audit_tasks/8","type":"function","doc":"Lists the Device Defender audits that have been performed during a given time period."},{"ref":"AWS.IoT.html#list_authorizers/6","title":"AWS.IoT.list_authorizers/6","type":"function","doc":"Lists the authorizers registered in your account."},{"ref":"AWS.IoT.html#list_billing_groups/5","title":"AWS.IoT.list_billing_groups/5","type":"function","doc":"Lists the billing groups you have created."},{"ref":"AWS.IoT.html#list_c_a_certificates/5","title":"AWS.IoT.list_c_a_certificates/5","type":"function","doc":"Lists the CA certificates registered for your AWS account. The results are paginated with a default page size of 25. You can use the returned marker to retrieve additional results."},{"ref":"AWS.IoT.html#list_certificates/5","title":"AWS.IoT.list_certificates/5","type":"function","doc":"Lists the certificates registered in your AWS account. The results are paginated with a default page size of 25. You can use the returned marker to retrieve additional results."},{"ref":"AWS.IoT.html#list_certificates_by_c_a/6","title":"AWS.IoT.list_certificates_by_c_a/6","type":"function","doc":"List the device certificates signed by the specified CA certificate."},{"ref":"AWS.IoT.html#list_dimensions/4","title":"AWS.IoT.list_dimensions/4","type":"function","doc":"List the set of dimensions that are defined for your AWS account."},{"ref":"AWS.IoT.html#list_domain_configurations/5","title":"AWS.IoT.list_domain_configurations/5","type":"function","doc":"Gets a list of domain configurations for the user. This list is sorted alphabetically by domain configuration name. The domain configuration feature is in public preview and is subject to change."},{"ref":"AWS.IoT.html#list_indices/4","title":"AWS.IoT.list_indices/4","type":"function","doc":"Lists the search indices."},{"ref":"AWS.IoT.html#list_job_executions_for_job/6","title":"AWS.IoT.list_job_executions_for_job/6","type":"function","doc":"Lists the job executions for a job."},{"ref":"AWS.IoT.html#list_job_executions_for_thing/6","title":"AWS.IoT.list_job_executions_for_thing/6","type":"function","doc":"Lists the job executions for the specified thing."},{"ref":"AWS.IoT.html#list_jobs/8","title":"AWS.IoT.list_jobs/8","type":"function","doc":"Lists jobs."},{"ref":"AWS.IoT.html#list_mitigation_actions/5","title":"AWS.IoT.list_mitigation_actions/5","type":"function","doc":"Gets a list of all mitigation actions that match the specified filter criteria."},{"ref":"AWS.IoT.html#list_o_t_a_updates/5","title":"AWS.IoT.list_o_t_a_updates/5","type":"function","doc":"Lists OTA updates."},{"ref":"AWS.IoT.html#list_outgoing_certificates/5","title":"AWS.IoT.list_outgoing_certificates/5","type":"function","doc":"Lists certificates that are being transferred but not yet accepted."},{"ref":"AWS.IoT.html#list_policies/5","title":"AWS.IoT.list_policies/5","type":"function","doc":"Lists your policies."},{"ref":"AWS.IoT.html#list_policy_principals/6","title":"AWS.IoT.list_policy_principals/6","type":"function","doc":"Lists the principals associated with the specified policy. Note: This API is deprecated. Please use ListTargetsForPolicy instead."},{"ref":"AWS.IoT.html#list_policy_versions/3","title":"AWS.IoT.list_policy_versions/3","type":"function","doc":"Lists the versions of the specified policy and identifies the default version."},{"ref":"AWS.IoT.html#list_principal_policies/6","title":"AWS.IoT.list_principal_policies/6","type":"function","doc":"Lists the policies attached to the specified principal. If you use an Cognito identity, the ID must be in AmazonCognito Identity format. Note: This API is deprecated. Please use ListAttachedPolicies instead."},{"ref":"AWS.IoT.html#list_principal_things/5","title":"AWS.IoT.list_principal_things/5","type":"function","doc":"Lists the things associated with the specified principal. A principal can be X.509 certificates, IAM users, groups, and roles, Amazon Cognito identities or federated identities."},{"ref":"AWS.IoT.html#list_provisioning_template_versions/5","title":"AWS.IoT.list_provisioning_template_versions/5","type":"function","doc":"A list of fleet provisioning template versions."},{"ref":"AWS.IoT.html#list_provisioning_templates/4","title":"AWS.IoT.list_provisioning_templates/4","type":"function","doc":"Lists the fleet provisioning templates in your AWS account."},{"ref":"AWS.IoT.html#list_role_aliases/5","title":"AWS.IoT.list_role_aliases/5","type":"function","doc":"Lists the role aliases registered in your account."},{"ref":"AWS.IoT.html#list_scheduled_audits/4","title":"AWS.IoT.list_scheduled_audits/4","type":"function","doc":"Lists all of your scheduled audits."},{"ref":"AWS.IoT.html#list_security_profiles/5","title":"AWS.IoT.list_security_profiles/5","type":"function","doc":"Lists the Device Defender security profiles you have created. You can use filters to list only those security profiles associated with a thing group or only those associated with your account."},{"ref":"AWS.IoT.html#list_security_profiles_for_target/6","title":"AWS.IoT.list_security_profiles_for_target/6","type":"function","doc":"Lists the Device Defender security profiles attached to a target (thing group)."},{"ref":"AWS.IoT.html#list_streams/5","title":"AWS.IoT.list_streams/5","type":"function","doc":"Lists all of the streams in your AWS account."},{"ref":"AWS.IoT.html#list_tags_for_resource/4","title":"AWS.IoT.list_tags_for_resource/4","type":"function","doc":"Lists the tags (metadata) you have assigned to the resource."},{"ref":"AWS.IoT.html#list_targets_for_policy/4","title":"AWS.IoT.list_targets_for_policy/4","type":"function","doc":"List targets for the specified policy."},{"ref":"AWS.IoT.html#list_targets_for_security_profile/5","title":"AWS.IoT.list_targets_for_security_profile/5","type":"function","doc":"Lists the targets (thing groups) associated with a given Device Defender security profile."},{"ref":"AWS.IoT.html#list_thing_groups/7","title":"AWS.IoT.list_thing_groups/7","type":"function","doc":"List the thing groups in your account."},{"ref":"AWS.IoT.html#list_thing_groups_for_thing/5","title":"AWS.IoT.list_thing_groups_for_thing/5","type":"function","doc":"List the thing groups to which the specified thing belongs."},{"ref":"AWS.IoT.html#list_thing_principals/3","title":"AWS.IoT.list_thing_principals/3","type":"function","doc":"Lists the principals associated with the specified thing. A principal can be X.509 certificates, IAM users, groups, and roles, Amazon Cognito identities or federated identities."},{"ref":"AWS.IoT.html#list_thing_registration_task_reports/6","title":"AWS.IoT.list_thing_registration_task_reports/6","type":"function","doc":"Information about the thing registration tasks."},{"ref":"AWS.IoT.html#list_thing_registration_tasks/5","title":"AWS.IoT.list_thing_registration_tasks/5","type":"function","doc":"List bulk thing provisioning tasks."},{"ref":"AWS.IoT.html#list_thing_types/5","title":"AWS.IoT.list_thing_types/5","type":"function","doc":"Lists the existing thing types."},{"ref":"AWS.IoT.html#list_things/7","title":"AWS.IoT.list_things/7","type":"function","doc":"Lists your things. Use the attributeName and attributeValue parameters to filter your things. For example, calling ListThings with attributeName=Color and attributeValue=Red retrieves all things in the registry that contain an attribute Color with the value Red. You will not be charged for calling this API if an Access denied error is returned. You will also not be charged if no attributes or pagination token was provided in request and no pagination token and no results were returned."},{"ref":"AWS.IoT.html#list_things_in_billing_group/5","title":"AWS.IoT.list_things_in_billing_group/5","type":"function","doc":"Lists the things you have added to the given billing group."},{"ref":"AWS.IoT.html#list_things_in_thing_group/6","title":"AWS.IoT.list_things_in_thing_group/6","type":"function","doc":"Lists the things in the specified group."},{"ref":"AWS.IoT.html#list_topic_rule_destinations/4","title":"AWS.IoT.list_topic_rule_destinations/4","type":"function","doc":"Lists all the topic rule destinations in your AWS account."},{"ref":"AWS.IoT.html#list_topic_rules/6","title":"AWS.IoT.list_topic_rules/6","type":"function","doc":"Lists the rules for the specific topic."},{"ref":"AWS.IoT.html#list_v2_logging_levels/5","title":"AWS.IoT.list_v2_logging_levels/5","type":"function","doc":"Lists logging levels."},{"ref":"AWS.IoT.html#list_violation_events/8","title":"AWS.IoT.list_violation_events/8","type":"function","doc":"Lists the Device Defender security profile violations discovered during the given time period. You can use filters to limit the results to those alerts issued for a particular security profile, behavior, or thing (device)."},{"ref":"AWS.IoT.html#register_c_a_certificate/3","title":"AWS.IoT.register_c_a_certificate/3","type":"function","doc":"Registers a CA certificate with AWS IoT. This CA certificate can then be used to sign device certificates, which can be then registered with AWS IoT. You can register up to 10 CA certificates per AWS account that have the same subject field. This enables you to have up to 10 certificate authorities sign your device certificates. If you have more than one CA certificate registered, make sure you pass the CA certificate when you register your device certificates with the RegisterCertificate API."},{"ref":"AWS.IoT.html#register_certificate/3","title":"AWS.IoT.register_certificate/3","type":"function","doc":"Registers a device certificate with AWS IoT. If you have more than one CA certificate that has the same subject field, you must specify the CA certificate that was used to sign the device certificate being registered."},{"ref":"AWS.IoT.html#register_certificate_without_c_a/3","title":"AWS.IoT.register_certificate_without_c_a/3","type":"function","doc":"Register a certificate that does not have a certificate authority (CA)."},{"ref":"AWS.IoT.html#register_thing/3","title":"AWS.IoT.register_thing/3","type":"function","doc":"Provisions a thing in the device registry. RegisterThing calls other AWS IoT control plane APIs. These calls might exceed your account level AWS IoT Throttling Limits and cause throttle errors. Please contact AWS Customer Support to raise your throttling limits if necessary."},{"ref":"AWS.IoT.html#reject_certificate_transfer/4","title":"AWS.IoT.reject_certificate_transfer/4","type":"function","doc":"Rejects a pending certificate transfer. After AWS IoT rejects a certificate transfer, the certificate status changes from PENDING_TRANSFER to INACTIVE. To check for pending certificate transfers, call ListCertificates to enumerate your certificates. This operation can only be called by the transfer destination. After it is called, the certificate will be returned to the source&#39;s account in the INACTIVE state."},{"ref":"AWS.IoT.html#remove_thing_from_billing_group/3","title":"AWS.IoT.remove_thing_from_billing_group/3","type":"function","doc":"Removes the given thing from the billing group."},{"ref":"AWS.IoT.html#remove_thing_from_thing_group/3","title":"AWS.IoT.remove_thing_from_thing_group/3","type":"function","doc":"Remove the specified thing from the specified group. You must specify either a thingGroupArn or a thingGroupName to identify the thing group and either a thingArn or a thingName to identify the thing to remove from the thing group."},{"ref":"AWS.IoT.html#replace_topic_rule/4","title":"AWS.IoT.replace_topic_rule/4","type":"function","doc":"Replaces the rule. You must specify all parameters for the new rule. Creating rules is an administrator-level action. Any user who has permission to create rules will be able to access data processed by the rule."},{"ref":"AWS.IoT.html#search_index/3","title":"AWS.IoT.search_index/3","type":"function","doc":"The query search index."},{"ref":"AWS.IoT.html#set_default_authorizer/3","title":"AWS.IoT.set_default_authorizer/3","type":"function","doc":"Sets the default authorizer. This will be used if a websocket connection is made without specifying an authorizer."},{"ref":"AWS.IoT.html#set_default_policy_version/5","title":"AWS.IoT.set_default_policy_version/5","type":"function","doc":"Sets the specified version of the specified policy as the policy&#39;s default (operative) version. This action affects all certificates to which the policy is attached. To list the principals the policy is attached to, use the ListPrincipalPolicy API."},{"ref":"AWS.IoT.html#set_logging_options/3","title":"AWS.IoT.set_logging_options/3","type":"function","doc":"Sets the logging options. NOTE: use of this command is not recommended. Use SetV2LoggingOptions instead."},{"ref":"AWS.IoT.html#set_v2_logging_level/3","title":"AWS.IoT.set_v2_logging_level/3","type":"function","doc":"Sets the logging level."},{"ref":"AWS.IoT.html#set_v2_logging_options/3","title":"AWS.IoT.set_v2_logging_options/3","type":"function","doc":"Sets the logging options for the V2 logging service."},{"ref":"AWS.IoT.html#start_audit_mitigation_actions_task/4","title":"AWS.IoT.start_audit_mitigation_actions_task/4","type":"function","doc":"Starts a task that applies a set of mitigation actions to the specified target."},{"ref":"AWS.IoT.html#start_on_demand_audit_task/3","title":"AWS.IoT.start_on_demand_audit_task/3","type":"function","doc":"Starts an on-demand Device Defender audit."},{"ref":"AWS.IoT.html#start_thing_registration_task/3","title":"AWS.IoT.start_thing_registration_task/3","type":"function","doc":"Creates a bulk thing provisioning task."},{"ref":"AWS.IoT.html#stop_thing_registration_task/4","title":"AWS.IoT.stop_thing_registration_task/4","type":"function","doc":"Cancels a bulk thing provisioning task."},{"ref":"AWS.IoT.html#tag_resource/3","title":"AWS.IoT.tag_resource/3","type":"function","doc":"Adds to or modifies the tags of the given resource. Tags are metadata which can be used to manage a resource."},{"ref":"AWS.IoT.html#test_authorization/3","title":"AWS.IoT.test_authorization/3","type":"function","doc":"Tests if a specified principal is authorized to perform an AWS IoT action on a specified resource. Use this to test and debug the authorization behavior of devices that connect to the AWS IoT device gateway."},{"ref":"AWS.IoT.html#test_invoke_authorizer/4","title":"AWS.IoT.test_invoke_authorizer/4","type":"function","doc":"Tests a custom authorization behavior by invoking a specified custom authorizer. Use this to test and debug the custom authorization behavior of devices that connect to the AWS IoT device gateway."},{"ref":"AWS.IoT.html#transfer_certificate/4","title":"AWS.IoT.transfer_certificate/4","type":"function","doc":"Transfers the specified certificate to the specified AWS account. You can cancel the transfer until it is acknowledged by the recipient. No notification is sent to the transfer destination&#39;s account. It is up to the caller to notify the transfer target. The certificate being transferred must not be in the ACTIVE state. You can use the UpdateCertificate API to deactivate it. The certificate must not have any policies attached to it. You can use the DetachPrincipalPolicy API to detach them."},{"ref":"AWS.IoT.html#untag_resource/3","title":"AWS.IoT.untag_resource/3","type":"function","doc":"Removes the given tags (metadata) from the resource."},{"ref":"AWS.IoT.html#update_account_audit_configuration/3","title":"AWS.IoT.update_account_audit_configuration/3","type":"function","doc":"Configures or reconfigures the Device Defender audit settings for this account. Settings include how audit notifications are sent and which audit checks are enabled or disabled."},{"ref":"AWS.IoT.html#update_audit_suppression/3","title":"AWS.IoT.update_audit_suppression/3","type":"function","doc":"Updates a Device Defender audit suppression."},{"ref":"AWS.IoT.html#update_authorizer/4","title":"AWS.IoT.update_authorizer/4","type":"function","doc":"Updates an authorizer."},{"ref":"AWS.IoT.html#update_billing_group/4","title":"AWS.IoT.update_billing_group/4","type":"function","doc":"Updates information about the billing group."},{"ref":"AWS.IoT.html#update_c_a_certificate/4","title":"AWS.IoT.update_c_a_certificate/4","type":"function","doc":"Updates a registered CA certificate."},{"ref":"AWS.IoT.html#update_certificate/4","title":"AWS.IoT.update_certificate/4","type":"function","doc":"Updates the status of the specified certificate. This operation is idempotent. Certificates must be in the ACTIVE state to authenticate devices that use a certificate to connect to AWS IoT. Within a few minutes of updating a certificate from the ACTIVE state to any other state, AWS IoT disconnects all devices that used that certificate to connect. Devices cannot use a certificate that is not in the ACTIVE state to reconnect."},{"ref":"AWS.IoT.html#update_dimension/4","title":"AWS.IoT.update_dimension/4","type":"function","doc":"Updates the definition for a dimension. You cannot change the type of a dimension after it is created (you can delete it and re-create it)."},{"ref":"AWS.IoT.html#update_domain_configuration/4","title":"AWS.IoT.update_domain_configuration/4","type":"function","doc":"Updates values stored in the domain configuration. Domain configurations for default endpoints can&#39;t be updated. The domain configuration feature is in public preview and is subject to change."},{"ref":"AWS.IoT.html#update_dynamic_thing_group/4","title":"AWS.IoT.update_dynamic_thing_group/4","type":"function","doc":"Updates a dynamic thing group."},{"ref":"AWS.IoT.html#update_event_configurations/3","title":"AWS.IoT.update_event_configurations/3","type":"function","doc":"Updates the event configurations."},{"ref":"AWS.IoT.html#update_indexing_configuration/3","title":"AWS.IoT.update_indexing_configuration/3","type":"function","doc":"Updates the search configuration."},{"ref":"AWS.IoT.html#update_job/4","title":"AWS.IoT.update_job/4","type":"function","doc":"Updates supported fields of the specified job."},{"ref":"AWS.IoT.html#update_mitigation_action/4","title":"AWS.IoT.update_mitigation_action/4","type":"function","doc":"Updates the definition for the specified mitigation action."},{"ref":"AWS.IoT.html#update_provisioning_template/4","title":"AWS.IoT.update_provisioning_template/4","type":"function","doc":"Updates a fleet provisioning template."},{"ref":"AWS.IoT.html#update_role_alias/4","title":"AWS.IoT.update_role_alias/4","type":"function","doc":"Updates a role alias."},{"ref":"AWS.IoT.html#update_scheduled_audit/4","title":"AWS.IoT.update_scheduled_audit/4","type":"function","doc":"Updates a scheduled audit, including which checks are performed and how often the audit takes place."},{"ref":"AWS.IoT.html#update_security_profile/4","title":"AWS.IoT.update_security_profile/4","type":"function","doc":"Updates a Device Defender security profile."},{"ref":"AWS.IoT.html#update_stream/4","title":"AWS.IoT.update_stream/4","type":"function","doc":"Updates an existing stream. The stream version will be incremented by one."},{"ref":"AWS.IoT.html#update_thing/4","title":"AWS.IoT.update_thing/4","type":"function","doc":"Updates the data for a thing."},{"ref":"AWS.IoT.html#update_thing_group/4","title":"AWS.IoT.update_thing_group/4","type":"function","doc":"Update a thing group."},{"ref":"AWS.IoT.html#update_thing_groups_for_thing/3","title":"AWS.IoT.update_thing_groups_for_thing/3","type":"function","doc":"Updates the groups to which the thing belongs."},{"ref":"AWS.IoT.html#update_topic_rule_destination/3","title":"AWS.IoT.update_topic_rule_destination/3","type":"function","doc":"Updates a topic rule destination. You use this to change the status, endpoint URL, or confirmation URL of the destination."},{"ref":"AWS.IoT.html#validate_security_profile_behaviors/3","title":"AWS.IoT.validate_security_profile_behaviors/3","type":"function","doc":"Validates a Device Defender security profile behaviors specification."},{"ref":"AWS.IoT1ClickDevices.html","title":"AWS.IoT1ClickDevices","type":"module","doc":"Describes all of the AWS IoT 1-Click device-related API operations for the service. Also provides sample requests, responses, and errors for the supported web services protocols."},{"ref":"AWS.IoT1ClickDevices.html#claim_devices_by_claim_code/4","title":"AWS.IoT1ClickDevices.claim_devices_by_claim_code/4","type":"function","doc":"Adds device(s) to your account (i.e., claim one or more devices) if and only if you received a claim code with the device(s)."},{"ref":"AWS.IoT1ClickDevices.html#describe_device/3","title":"AWS.IoT1ClickDevices.describe_device/3","type":"function","doc":"Given a device ID, returns a DescribeDeviceResponse object describing the details of the device."},{"ref":"AWS.IoT1ClickDevices.html#finalize_device_claim/4","title":"AWS.IoT1ClickDevices.finalize_device_claim/4","type":"function","doc":"Given a device ID, finalizes the claim request for the associated device. Claiming a device consists of initiating a claim, then publishing a device event, and finalizing the claim. For a device of type button, a device event can be published by simply clicking the device."},{"ref":"AWS.IoT1ClickDevices.html#get_device_methods/3","title":"AWS.IoT1ClickDevices.get_device_methods/3","type":"function","doc":"Given a device ID, returns the invokable methods associated with the device."},{"ref":"AWS.IoT1ClickDevices.html#initiate_device_claim/4","title":"AWS.IoT1ClickDevices.initiate_device_claim/4","type":"function","doc":"Given a device ID, initiates a claim request for the associated device. Claiming a device consists of initiating a claim, then publishing a device event, and finalizing the claim. For a device of type button, a device event can be published by simply clicking the device."},{"ref":"AWS.IoT1ClickDevices.html#invoke_device_method/4","title":"AWS.IoT1ClickDevices.invoke_device_method/4","type":"function","doc":"Given a device ID, issues a request to invoke a named device method (with possible parameters). See the &quot;Example POST&quot; code snippet below."},{"ref":"AWS.IoT1ClickDevices.html#list_device_events/7","title":"AWS.IoT1ClickDevices.list_device_events/7","type":"function","doc":"Using a device ID, returns a DeviceEventsResponse object containing an array of events for the device."},{"ref":"AWS.IoT1ClickDevices.html#list_devices/5","title":"AWS.IoT1ClickDevices.list_devices/5","type":"function","doc":"Lists the 1-Click compatible devices associated with your AWS account."},{"ref":"AWS.IoT1ClickDevices.html#list_tags_for_resource/3","title":"AWS.IoT1ClickDevices.list_tags_for_resource/3","type":"function","doc":"Lists the tags associated with the specified resource ARN."},{"ref":"AWS.IoT1ClickDevices.html#tag_resource/4","title":"AWS.IoT1ClickDevices.tag_resource/4","type":"function","doc":"Adds or updates the tags associated with the resource ARN. See AWS IoT 1-Click Service Limits for the maximum number of tags allowed per resource."},{"ref":"AWS.IoT1ClickDevices.html#unclaim_device/4","title":"AWS.IoT1ClickDevices.unclaim_device/4","type":"function","doc":"Disassociates a device from your AWS account using its device ID."},{"ref":"AWS.IoT1ClickDevices.html#untag_resource/4","title":"AWS.IoT1ClickDevices.untag_resource/4","type":"function","doc":"Using tag keys, deletes the tags (key/value pairs) associated with the specified resource ARN."},{"ref":"AWS.IoT1ClickDevices.html#update_device_state/4","title":"AWS.IoT1ClickDevices.update_device_state/4","type":"function","doc":"Using a Boolean value (true or false), this operation enables or disables the device given a device ID."},{"ref":"AWS.IoT1ClickProjects.html","title":"AWS.IoT1ClickProjects","type":"module","doc":"The AWS IoT 1-Click Projects API Reference"},{"ref":"AWS.IoT1ClickProjects.html#associate_device_with_placement/6","title":"AWS.IoT1ClickProjects.associate_device_with_placement/6","type":"function","doc":"Associates a physical device with a placement."},{"ref":"AWS.IoT1ClickProjects.html#create_placement/4","title":"AWS.IoT1ClickProjects.create_placement/4","type":"function","doc":"Creates an empty placement."},{"ref":"AWS.IoT1ClickProjects.html#create_project/3","title":"AWS.IoT1ClickProjects.create_project/3","type":"function","doc":"Creates an empty project with a placement template. A project contains zero or more placements that adhere to the placement template defined in the project."},{"ref":"AWS.IoT1ClickProjects.html#delete_placement/5","title":"AWS.IoT1ClickProjects.delete_placement/5","type":"function","doc":"Deletes a placement. To delete a placement, it must not have any devices associated with it. When you delete a placement, all associated data becomes irretrievable."},{"ref":"AWS.IoT1ClickProjects.html#delete_project/4","title":"AWS.IoT1ClickProjects.delete_project/4","type":"function","doc":"Deletes a project. To delete a project, it must not have any placements associated with it. When you delete a project, all associated data becomes irretrievable."},{"ref":"AWS.IoT1ClickProjects.html#describe_placement/4","title":"AWS.IoT1ClickProjects.describe_placement/4","type":"function","doc":"Describes a placement in a project."},{"ref":"AWS.IoT1ClickProjects.html#describe_project/3","title":"AWS.IoT1ClickProjects.describe_project/3","type":"function","doc":"Returns an object describing a project."},{"ref":"AWS.IoT1ClickProjects.html#disassociate_device_from_placement/6","title":"AWS.IoT1ClickProjects.disassociate_device_from_placement/6","type":"function","doc":"Removes a physical device from a placement."},{"ref":"AWS.IoT1ClickProjects.html#get_devices_in_placement/4","title":"AWS.IoT1ClickProjects.get_devices_in_placement/4","type":"function","doc":"Returns an object enumerating the devices in a placement."},{"ref":"AWS.IoT1ClickProjects.html#list_placements/5","title":"AWS.IoT1ClickProjects.list_placements/5","type":"function","doc":"Lists the placement(s) of a project."},{"ref":"AWS.IoT1ClickProjects.html#list_projects/4","title":"AWS.IoT1ClickProjects.list_projects/4","type":"function","doc":"Lists the AWS IoT 1-Click project(s) associated with your AWS account and region."},{"ref":"AWS.IoT1ClickProjects.html#list_tags_for_resource/3","title":"AWS.IoT1ClickProjects.list_tags_for_resource/3","type":"function","doc":"Lists the tags (metadata key/value pairs) which you have assigned to the resource."},{"ref":"AWS.IoT1ClickProjects.html#tag_resource/4","title":"AWS.IoT1ClickProjects.tag_resource/4","type":"function","doc":"Creates or modifies tags for a resource. Tags are key/value pairs (metadata) that can be used to manage a resource. For more information, see AWS Tagging Strategies."},{"ref":"AWS.IoT1ClickProjects.html#untag_resource/4","title":"AWS.IoT1ClickProjects.untag_resource/4","type":"function","doc":"Removes one or more tags (metadata key/value pairs) from a resource."},{"ref":"AWS.IoT1ClickProjects.html#update_placement/5","title":"AWS.IoT1ClickProjects.update_placement/5","type":"function","doc":"Updates a placement with the given attributes. To clear an attribute, pass an empty value (i.e., &quot;&quot;)."},{"ref":"AWS.IoT1ClickProjects.html#update_project/4","title":"AWS.IoT1ClickProjects.update_project/4","type":"function","doc":"Updates a project associated with your AWS account and region. With the exception of device template names, you can pass just the values that need to be updated because the update request will change only the values that are provided. To clear a value, pass the empty string (i.e., &quot;&quot;)."},{"ref":"AWS.IoTAnalytics.html","title":"AWS.IoTAnalytics","type":"module","doc":"AWS IoT Analytics allows you to collect large amounts of device data, process messages, and store them. You can then query the data and run sophisticated analytics on it. AWS IoT Analytics enables advanced data exploration through integration with Jupyter Notebooks and data visualization through integration with Amazon QuickSight. Traditional analytics and business intelligence tools are designed to process structured data. IoT data often comes from devices that record noisy processes (such as temperature, motion, or sound). As a result the data from these devices can have significant gaps, corrupted messages, and false readings that must be cleaned up before analysis can occur. Also, IoT data is often only meaningful in the context of other data from external sources. AWS IoT Analytics automates the steps required to analyze data from IoT devices. AWS IoT Analytics filters, transforms, and enriches IoT data before storing it in a time-series data store for analysis. You can set up the service to collect only the data you need from your devices, apply mathematical transforms to process the data, and enrich the data with device-specific metadata such as device type and location before storing it. Then, you can analyze your data by running queries using the built-in SQL query engine, or perform more complex analytics and machine learning inference. AWS IoT Analytics includes pre-built models for common IoT use cases so you can answer questions like which devices are about to fail or which customers are at risk of abandoning their wearable devices."},{"ref":"AWS.IoTAnalytics.html#batch_put_message/3","title":"AWS.IoTAnalytics.batch_put_message/3","type":"function","doc":"Sends messages to a channel."},{"ref":"AWS.IoTAnalytics.html#cancel_pipeline_reprocessing/5","title":"AWS.IoTAnalytics.cancel_pipeline_reprocessing/5","type":"function","doc":"Cancels the reprocessing of data through the pipeline."},{"ref":"AWS.IoTAnalytics.html#create_channel/3","title":"AWS.IoTAnalytics.create_channel/3","type":"function","doc":"Creates a channel. A channel collects data from an MQTT topic and archives the raw, unprocessed messages before publishing the data to a pipeline."},{"ref":"AWS.IoTAnalytics.html#create_dataset/3","title":"AWS.IoTAnalytics.create_dataset/3","type":"function","doc":"Creates a data set. A data set stores data retrieved from a data store by applying a &quot;queryAction&quot; (a SQL query) or a &quot;containerAction&quot; (executing a containerized application). This operation creates the skeleton of a data set. The data set can be populated manually by calling &quot;CreateDatasetContent&quot; or automatically according to a &quot;trigger&quot; you specify."},{"ref":"AWS.IoTAnalytics.html#create_dataset_content/4","title":"AWS.IoTAnalytics.create_dataset_content/4","type":"function","doc":"Creates the content of a data set by applying a &quot;queryAction&quot; (a SQL query) or a &quot;containerAction&quot; (executing a containerized application)."},{"ref":"AWS.IoTAnalytics.html#create_datastore/3","title":"AWS.IoTAnalytics.create_datastore/3","type":"function","doc":"Creates a data store, which is a repository for messages."},{"ref":"AWS.IoTAnalytics.html#create_pipeline/3","title":"AWS.IoTAnalytics.create_pipeline/3","type":"function","doc":"Creates a pipeline. A pipeline consumes messages from a channel and allows you to process the messages before storing them in a data store. You must specify both a channel and a datastore activity and, optionally, as many as 23 additional activities in the pipelineActivities array."},{"ref":"AWS.IoTAnalytics.html#delete_channel/4","title":"AWS.IoTAnalytics.delete_channel/4","type":"function","doc":"Deletes the specified channel."},{"ref":"AWS.IoTAnalytics.html#delete_dataset/4","title":"AWS.IoTAnalytics.delete_dataset/4","type":"function","doc":"Deletes the specified data set. You do not have to delete the content of the data set before you perform this operation."},{"ref":"AWS.IoTAnalytics.html#delete_dataset_content/4","title":"AWS.IoTAnalytics.delete_dataset_content/4","type":"function","doc":"Deletes the content of the specified data set."},{"ref":"AWS.IoTAnalytics.html#delete_datastore/4","title":"AWS.IoTAnalytics.delete_datastore/4","type":"function","doc":"Deletes the specified data store."},{"ref":"AWS.IoTAnalytics.html#delete_pipeline/4","title":"AWS.IoTAnalytics.delete_pipeline/4","type":"function","doc":"Deletes the specified pipeline."},{"ref":"AWS.IoTAnalytics.html#describe_channel/4","title":"AWS.IoTAnalytics.describe_channel/4","type":"function","doc":"Retrieves information about a channel."},{"ref":"AWS.IoTAnalytics.html#describe_dataset/3","title":"AWS.IoTAnalytics.describe_dataset/3","type":"function","doc":"Retrieves information about a data set."},{"ref":"AWS.IoTAnalytics.html#describe_datastore/4","title":"AWS.IoTAnalytics.describe_datastore/4","type":"function","doc":"Retrieves information about a data store."},{"ref":"AWS.IoTAnalytics.html#describe_logging_options/2","title":"AWS.IoTAnalytics.describe_logging_options/2","type":"function","doc":"Retrieves the current settings of the AWS IoT Analytics logging options."},{"ref":"AWS.IoTAnalytics.html#describe_pipeline/3","title":"AWS.IoTAnalytics.describe_pipeline/3","type":"function","doc":"Retrieves information about a pipeline."},{"ref":"AWS.IoTAnalytics.html#get_dataset_content/4","title":"AWS.IoTAnalytics.get_dataset_content/4","type":"function","doc":"Retrieves the contents of a data set as pre-signed URIs."},{"ref":"AWS.IoTAnalytics.html#list_channels/4","title":"AWS.IoTAnalytics.list_channels/4","type":"function","doc":"Retrieves a list of channels."},{"ref":"AWS.IoTAnalytics.html#list_dataset_contents/7","title":"AWS.IoTAnalytics.list_dataset_contents/7","type":"function","doc":"Lists information about data set contents that have been created."},{"ref":"AWS.IoTAnalytics.html#list_datasets/4","title":"AWS.IoTAnalytics.list_datasets/4","type":"function","doc":"Retrieves information about data sets."},{"ref":"AWS.IoTAnalytics.html#list_datastores/4","title":"AWS.IoTAnalytics.list_datastores/4","type":"function","doc":"Retrieves a list of data stores."},{"ref":"AWS.IoTAnalytics.html#list_pipelines/4","title":"AWS.IoTAnalytics.list_pipelines/4","type":"function","doc":"Retrieves a list of pipelines."},{"ref":"AWS.IoTAnalytics.html#list_tags_for_resource/3","title":"AWS.IoTAnalytics.list_tags_for_resource/3","type":"function","doc":"Lists the tags (metadata) which you have assigned to the resource."},{"ref":"AWS.IoTAnalytics.html#put_logging_options/3","title":"AWS.IoTAnalytics.put_logging_options/3","type":"function","doc":"Sets or updates the AWS IoT Analytics logging options. Note that if you update the value of any loggingOptions field, it takes up to one minute for the change to take effect. Also, if you change the policy attached to the role you specified in the roleArn field (for example, to correct an invalid policy) it takes up to 5 minutes for that change to take effect."},{"ref":"AWS.IoTAnalytics.html#run_pipeline_activity/3","title":"AWS.IoTAnalytics.run_pipeline_activity/3","type":"function","doc":"Simulates the results of running a pipeline activity on a message payload."},{"ref":"AWS.IoTAnalytics.html#sample_channel_data/6","title":"AWS.IoTAnalytics.sample_channel_data/6","type":"function","doc":"Retrieves a sample of messages from the specified channel ingested during the specified timeframe. Up to 10 messages can be retrieved."},{"ref":"AWS.IoTAnalytics.html#start_pipeline_reprocessing/4","title":"AWS.IoTAnalytics.start_pipeline_reprocessing/4","type":"function","doc":"Starts the reprocessing of raw message data through the pipeline."},{"ref":"AWS.IoTAnalytics.html#tag_resource/3","title":"AWS.IoTAnalytics.tag_resource/3","type":"function","doc":"Adds to or modifies the tags of the given resource. Tags are metadata which can be used to manage a resource."},{"ref":"AWS.IoTAnalytics.html#untag_resource/3","title":"AWS.IoTAnalytics.untag_resource/3","type":"function","doc":"Removes the given tags (metadata) from the resource."},{"ref":"AWS.IoTAnalytics.html#update_channel/4","title":"AWS.IoTAnalytics.update_channel/4","type":"function","doc":"Updates the settings of a channel."},{"ref":"AWS.IoTAnalytics.html#update_dataset/4","title":"AWS.IoTAnalytics.update_dataset/4","type":"function","doc":"Updates the settings of a data set."},{"ref":"AWS.IoTAnalytics.html#update_datastore/4","title":"AWS.IoTAnalytics.update_datastore/4","type":"function","doc":"Updates the settings of a data store."},{"ref":"AWS.IoTAnalytics.html#update_pipeline/4","title":"AWS.IoTAnalytics.update_pipeline/4","type":"function","doc":"Updates the settings of a pipeline. You must specify both a channel and a datastore activity and, optionally, as many as 23 additional activities in the pipelineActivities array."},{"ref":"AWS.IoTDataPlane.html","title":"AWS.IoTDataPlane","type":"module","doc":"AWS IoT AWS IoT-Data enables secure, bi-directional communication between Internet-connected things (such as sensors, actuators, embedded devices, or smart appliances) and the AWS cloud. It implements a broker for applications and things to publish messages over HTTP (Publish) and retrieve, update, and delete shadows. A shadow is a persistent representation of your things and their state in the AWS cloud. Find the endpoint address for actions in the AWS IoT data plane by running this CLI command: aws iot describe-endpoint --endpoint-type iot:Data-ATS The service name used by AWS Signature Version 4 to sign requests is: iotdevicegateway."},{"ref":"AWS.IoTDataPlane.html#delete_thing_shadow/4","title":"AWS.IoTDataPlane.delete_thing_shadow/4","type":"function","doc":"Deletes the shadow for the specified thing. For more information, see DeleteThingShadow in the AWS IoT Developer Guide."},{"ref":"AWS.IoTDataPlane.html#get_thing_shadow/4","title":"AWS.IoTDataPlane.get_thing_shadow/4","type":"function","doc":"Gets the shadow for the specified thing. For more information, see GetThingShadow in the AWS IoT Developer Guide."},{"ref":"AWS.IoTDataPlane.html#list_named_shadows_for_thing/5","title":"AWS.IoTDataPlane.list_named_shadows_for_thing/5","type":"function","doc":"Lists the shadows for the specified thing."},{"ref":"AWS.IoTDataPlane.html#publish/4","title":"AWS.IoTDataPlane.publish/4","type":"function","doc":"Publishes state information. For more information, see HTTP Protocol in the AWS IoT Developer Guide."},{"ref":"AWS.IoTDataPlane.html#update_thing_shadow/4","title":"AWS.IoTDataPlane.update_thing_shadow/4","type":"function","doc":"Updates the shadow for the specified thing. For more information, see UpdateThingShadow in the AWS IoT Developer Guide."},{"ref":"AWS.IoTEvents.html","title":"AWS.IoTEvents","type":"module","doc":"AWS IoT Events monitors your equipment or device fleets for failures or changes in operation, and triggers actions when such events occur. You can use AWS IoT Events API operations to create, read, update, and delete inputs and detector models, and to list their versions."},{"ref":"AWS.IoTEvents.html#create_detector_model/3","title":"AWS.IoTEvents.create_detector_model/3","type":"function","doc":"Creates a detector model."},{"ref":"AWS.IoTEvents.html#create_input/3","title":"AWS.IoTEvents.create_input/3","type":"function","doc":"Creates an input."},{"ref":"AWS.IoTEvents.html#delete_detector_model/4","title":"AWS.IoTEvents.delete_detector_model/4","type":"function","doc":"Deletes a detector model. Any active instances of the detector model are also deleted."},{"ref":"AWS.IoTEvents.html#delete_input/4","title":"AWS.IoTEvents.delete_input/4","type":"function","doc":"Deletes an input."},{"ref":"AWS.IoTEvents.html#describe_detector_model/4","title":"AWS.IoTEvents.describe_detector_model/4","type":"function","doc":"Describes a detector model. If the version parameter is not specified, information about the latest version is returned."},{"ref":"AWS.IoTEvents.html#describe_input/3","title":"AWS.IoTEvents.describe_input/3","type":"function","doc":"Describes an input."},{"ref":"AWS.IoTEvents.html#describe_logging_options/2","title":"AWS.IoTEvents.describe_logging_options/2","type":"function","doc":"Retrieves the current settings of the AWS IoT Events logging options."},{"ref":"AWS.IoTEvents.html#list_detector_model_versions/5","title":"AWS.IoTEvents.list_detector_model_versions/5","type":"function","doc":"Lists all the versions of a detector model. Only the metadata associated with each detector model version is returned."},{"ref":"AWS.IoTEvents.html#list_detector_models/4","title":"AWS.IoTEvents.list_detector_models/4","type":"function","doc":"Lists the detector models you have created. Only the metadata associated with each detector model is returned."},{"ref":"AWS.IoTEvents.html#list_inputs/4","title":"AWS.IoTEvents.list_inputs/4","type":"function","doc":"Lists the inputs you have created."},{"ref":"AWS.IoTEvents.html#list_tags_for_resource/3","title":"AWS.IoTEvents.list_tags_for_resource/3","type":"function","doc":"Lists the tags (metadata) you have assigned to the resource."},{"ref":"AWS.IoTEvents.html#put_logging_options/3","title":"AWS.IoTEvents.put_logging_options/3","type":"function","doc":"Sets or updates the AWS IoT Events logging options. If you update the value of any loggingOptions field, it takes up to one minute for the change to take effect. If you change the policy attached to the role you specified in the roleArn field (for example, to correct an invalid policy), it takes up to five minutes for that change to take effect."},{"ref":"AWS.IoTEvents.html#tag_resource/3","title":"AWS.IoTEvents.tag_resource/3","type":"function","doc":"Adds to or modifies the tags of the given resource. Tags are metadata that can be used to manage a resource."},{"ref":"AWS.IoTEvents.html#untag_resource/3","title":"AWS.IoTEvents.untag_resource/3","type":"function","doc":"Removes the given tags (metadata) from the resource."},{"ref":"AWS.IoTEvents.html#update_detector_model/4","title":"AWS.IoTEvents.update_detector_model/4","type":"function","doc":"Updates a detector model. Detectors (instances) spawned by the previous version are deleted and then re-created as new inputs arrive."},{"ref":"AWS.IoTEvents.html#update_input/4","title":"AWS.IoTEvents.update_input/4","type":"function","doc":"Updates an input."},{"ref":"AWS.IoTEventsData.html","title":"AWS.IoTEventsData","type":"module","doc":"AWS IoT Events monitors your equipment or device fleets for failures or changes in operation, and triggers actions when such events occur. AWS IoT Events Data API commands enable you to send inputs to detectors, list detectors, and view or update a detector&#39;s status."},{"ref":"AWS.IoTEventsData.html#batch_put_message/3","title":"AWS.IoTEventsData.batch_put_message/3","type":"function","doc":"Sends a set of messages to the AWS IoT Events system. Each message payload is transformed into the input you specify (&quot;inputName&quot;) and ingested into any detectors that monitor that input. If multiple messages are sent, the order in which the messages are processed isn&#39;t guaranteed. To guarantee ordering, you must send messages one at a time and wait for a successful response."},{"ref":"AWS.IoTEventsData.html#batch_update_detector/3","title":"AWS.IoTEventsData.batch_update_detector/3","type":"function","doc":"Updates the state, variable values, and timer settings of one or more detectors (instances) of a specified detector model."},{"ref":"AWS.IoTEventsData.html#describe_detector/4","title":"AWS.IoTEventsData.describe_detector/4","type":"function","doc":"Returns information about the specified detector (instance)."},{"ref":"AWS.IoTEventsData.html#list_detectors/6","title":"AWS.IoTEventsData.list_detectors/6","type":"function","doc":"Lists detectors (the instances of a detector model)."},{"ref":"AWS.IoTJobsDataPlane.html","title":"AWS.IoTJobsDataPlane","type":"module","doc":"AWS IoT Jobs is a service that allows you to define a set of jobs  remote operations that are sent to and executed on one or more devices connected to AWS IoT. For example, you can define a job that instructs a set of devices to download and install application or firmware updates, reboot, rotate certificates, or perform remote troubleshooting operations. To create a job, you make a job document which is a description of the remote operations to be performed, and you specify a list of targets that should perform the operations. The targets can be individual things, thing groups or both. AWS IoT Jobs sends a message to inform the targets that a job is available. The target starts the execution of the job by downloading the job document, performing the operations it specifies, and reporting its progress to AWS IoT. The Jobs service provides commands to track the progress of a job on a specific target and for all the targets of the job"},{"ref":"AWS.IoTJobsDataPlane.html#describe_job_execution/6","title":"AWS.IoTJobsDataPlane.describe_job_execution/6","type":"function","doc":"Gets details of a job execution."},{"ref":"AWS.IoTJobsDataPlane.html#get_pending_job_executions/3","title":"AWS.IoTJobsDataPlane.get_pending_job_executions/3","type":"function","doc":"Gets the list of all jobs for a thing that are not in a terminal status."},{"ref":"AWS.IoTJobsDataPlane.html#start_next_pending_job_execution/4","title":"AWS.IoTJobsDataPlane.start_next_pending_job_execution/4","type":"function","doc":"Gets and starts the next pending (status IN_PROGRESS or QUEUED) job execution for a thing."},{"ref":"AWS.IoTJobsDataPlane.html#update_job_execution/5","title":"AWS.IoTJobsDataPlane.update_job_execution/5","type":"function","doc":"Updates the status of a job execution."},{"ref":"AWS.IoTSecureTunneling.html","title":"AWS.IoTSecureTunneling","type":"module","doc":"AWS IoT Secure Tunneling AWS IoT Secure Tunnling enables you to create remote connections to devices deployed in the field. For more information about how AWS IoT Secure Tunneling works, see the User Guide."},{"ref":"AWS.IoTSecureTunneling.html#close_tunnel/3","title":"AWS.IoTSecureTunneling.close_tunnel/3","type":"function","doc":"Closes a tunnel identified by the unique tunnel id. When a CloseTunnel request is received, we close the WebSocket connections between the client and proxy server so no data can be transmitted."},{"ref":"AWS.IoTSecureTunneling.html#describe_tunnel/3","title":"AWS.IoTSecureTunneling.describe_tunnel/3","type":"function","doc":"Gets information about a tunnel identified by the unique tunnel id."},{"ref":"AWS.IoTSecureTunneling.html#list_tags_for_resource/3","title":"AWS.IoTSecureTunneling.list_tags_for_resource/3","type":"function","doc":"Lists the tags for the specified resource."},{"ref":"AWS.IoTSecureTunneling.html#list_tunnels/3","title":"AWS.IoTSecureTunneling.list_tunnels/3","type":"function","doc":"List all tunnels for an AWS account. Tunnels are listed by creation time in descending order, newer tunnels will be listed before older tunnels."},{"ref":"AWS.IoTSecureTunneling.html#open_tunnel/3","title":"AWS.IoTSecureTunneling.open_tunnel/3","type":"function","doc":"Creates a new tunnel, and returns two client access tokens for clients to use to connect to the AWS IoT Secure Tunneling proxy server. ."},{"ref":"AWS.IoTSecureTunneling.html#tag_resource/3","title":"AWS.IoTSecureTunneling.tag_resource/3","type":"function","doc":"A resource tag."},{"ref":"AWS.IoTSecureTunneling.html#untag_resource/3","title":"AWS.IoTSecureTunneling.untag_resource/3","type":"function","doc":"Removes a tag from a resource."},{"ref":"AWS.IoTSiteWise.html","title":"AWS.IoTSiteWise","type":"module","doc":"Welcome to the AWS IoT SiteWise API Reference. AWS IoT SiteWise is an AWS service that connects Industrial Internet of Things (IIoT) devices to the power of the AWS Cloud. For more information, see the AWS IoT SiteWise User Guide. For information about AWS IoT SiteWise quotas, see Quotas in the AWS IoT SiteWise User Guide."},{"ref":"AWS.IoTSiteWise.html#associate_assets/4","title":"AWS.IoTSiteWise.associate_assets/4","type":"function","doc":"Associates a child asset with the given parent asset through a hierarchy defined in the parent asset&#39;s model. For more information, see Associating assets in the AWS IoT SiteWise User Guide."},{"ref":"AWS.IoTSiteWise.html#batch_associate_project_assets/4","title":"AWS.IoTSiteWise.batch_associate_project_assets/4","type":"function","doc":"Associates a group (batch) of assets with an AWS IoT SiteWise Monitor project."},{"ref":"AWS.IoTSiteWise.html#batch_disassociate_project_assets/4","title":"AWS.IoTSiteWise.batch_disassociate_project_assets/4","type":"function","doc":"Disassociates a group (batch) of assets from an AWS IoT SiteWise Monitor project."},{"ref":"AWS.IoTSiteWise.html#batch_put_asset_property_value/3","title":"AWS.IoTSiteWise.batch_put_asset_property_value/3","type":"function","doc":"Sends a list of asset property values to AWS IoT SiteWise. Each value is a timestamp-quality-value (TQV) data point. For more information, see Ingesting data using the API in the AWS IoT SiteWise User Guide. To identify an asset property, you must specify one of the following: The assetId and propertyId of an asset property. A propertyAlias, which is a data stream alias (for example, /company/windfarm/3/turbine/7/temperature). To define an asset property&#39;s alias, see UpdateAssetProperty. With respect to Unix epoch time, AWS IoT SiteWise accepts only TQVs that have a timestamp of no more than 15 minutes in the past and no more than 5 minutes in the future. AWS IoT SiteWise rejects timestamps outside of the inclusive range of [-15, +5] minutes and returns a TimestampOutOfRangeException error. For each asset property, AWS IoT SiteWise overwrites TQVs with duplicate timestamps unless the newer TQV has a different quality. For example, if you store a TQV {T1, GOOD, V1}, then storing {T1, GOOD, V2} replaces the existing TQV. AWS IoT SiteWise authorizes access to each BatchPutAssetPropertyValue entry individually. For more information, see BatchPutAssetPropertyValue authorization in the AWS IoT SiteWise User Guide."},{"ref":"AWS.IoTSiteWise.html#create_access_policy/3","title":"AWS.IoTSiteWise.create_access_policy/3","type":"function","doc":"Creates an access policy that grants the specified identity (AWS SSO user, AWS SSO group, or IAM user) access to the specified AWS IoT SiteWise Monitor portal or project resource."},{"ref":"AWS.IoTSiteWise.html#create_asset/3","title":"AWS.IoTSiteWise.create_asset/3","type":"function","doc":"Creates an asset from an existing asset model. For more information, see Creating assets in the AWS IoT SiteWise User Guide."},{"ref":"AWS.IoTSiteWise.html#create_asset_model/3","title":"AWS.IoTSiteWise.create_asset_model/3","type":"function","doc":"Creates an asset model from specified property and hierarchy definitions. You create assets from asset models. With asset models, you can easily create assets of the same type that have standardized definitions. Each asset created from a model inherits the asset model&#39;s property and hierarchy definitions. For more information, see Defining asset models in the AWS IoT SiteWise User Guide."},{"ref":"AWS.IoTSiteWise.html#create_dashboard/3","title":"AWS.IoTSiteWise.create_dashboard/3","type":"function","doc":"Creates a dashboard in an AWS IoT SiteWise Monitor project."},{"ref":"AWS.IoTSiteWise.html#create_gateway/3","title":"AWS.IoTSiteWise.create_gateway/3","type":"function","doc":"Creates a gateway, which is a virtual or edge device that delivers industrial data streams from local servers to AWS IoT SiteWise. For more information, see Ingesting data using a gateway in the AWS IoT SiteWise User Guide."},{"ref":"AWS.IoTSiteWise.html#create_portal/3","title":"AWS.IoTSiteWise.create_portal/3","type":"function","doc":"Creates a portal, which can contain projects and dashboards. AWS IoT SiteWise Monitor uses AWS SSO or IAM to authenticate portal users and manage user permissions. Before you can sign in to a new portal, you must add at least one identity to that portal. For more information, see Adding or removing portal administrators in the AWS IoT SiteWise User Guide."},{"ref":"AWS.IoTSiteWise.html#create_presigned_portal_url/4","title":"AWS.IoTSiteWise.create_presigned_portal_url/4","type":"function","doc":"Creates a pre-signed URL to a portal. Use this operation to create URLs to portals that use AWS Identity and Access Management (IAM) to authenticate users. An IAM user with access to a portal can call this API to get a URL to that portal. The URL contains a session token that lets the IAM user access the portal."},{"ref":"AWS.IoTSiteWise.html#create_project/3","title":"AWS.IoTSiteWise.create_project/3","type":"function","doc":"Creates a project in the specified portal."},{"ref":"AWS.IoTSiteWise.html#delete_access_policy/4","title":"AWS.IoTSiteWise.delete_access_policy/4","type":"function","doc":"Deletes an access policy that grants the specified identity access to the specified AWS IoT SiteWise Monitor resource. You can use this operation to revoke access to an AWS IoT SiteWise Monitor resource."},{"ref":"AWS.IoTSiteWise.html#delete_asset/4","title":"AWS.IoTSiteWise.delete_asset/4","type":"function","doc":"Deletes an asset. This action can&#39;t be undone. For more information, see Deleting assets and models in the AWS IoT SiteWise User Guide. You can&#39;t delete an asset that&#39;s associated to another asset. For more information, see DisassociateAssets."},{"ref":"AWS.IoTSiteWise.html#delete_asset_model/4","title":"AWS.IoTSiteWise.delete_asset_model/4","type":"function","doc":"Deletes an asset model. This action can&#39;t be undone. You must delete all assets created from an asset model before you can delete the model. Also, you can&#39;t delete an asset model if a parent asset model exists that contains a property formula expression that depends on the asset model that you want to delete. For more information, see Deleting assets and models in the AWS IoT SiteWise User Guide."},{"ref":"AWS.IoTSiteWise.html#delete_dashboard/4","title":"AWS.IoTSiteWise.delete_dashboard/4","type":"function","doc":"Deletes a dashboard from AWS IoT SiteWise Monitor."},{"ref":"AWS.IoTSiteWise.html#delete_gateway/4","title":"AWS.IoTSiteWise.delete_gateway/4","type":"function","doc":"Deletes a gateway from AWS IoT SiteWise. When you delete a gateway, some of the gateway&#39;s files remain in your gateway&#39;s file system."},{"ref":"AWS.IoTSiteWise.html#delete_portal/4","title":"AWS.IoTSiteWise.delete_portal/4","type":"function","doc":"Deletes a portal from AWS IoT SiteWise Monitor."},{"ref":"AWS.IoTSiteWise.html#delete_project/4","title":"AWS.IoTSiteWise.delete_project/4","type":"function","doc":"Deletes a project from AWS IoT SiteWise Monitor."},{"ref":"AWS.IoTSiteWise.html#describe_access_policy/3","title":"AWS.IoTSiteWise.describe_access_policy/3","type":"function","doc":"Describes an access policy, which specifies an identity&#39;s access to an AWS IoT SiteWise Monitor portal or project."},{"ref":"AWS.IoTSiteWise.html#describe_asset/3","title":"AWS.IoTSiteWise.describe_asset/3","type":"function","doc":"Retrieves information about an asset."},{"ref":"AWS.IoTSiteWise.html#describe_asset_model/3","title":"AWS.IoTSiteWise.describe_asset_model/3","type":"function","doc":"Retrieves information about an asset model."},{"ref":"AWS.IoTSiteWise.html#describe_asset_property/4","title":"AWS.IoTSiteWise.describe_asset_property/4","type":"function","doc":"Retrieves information about an asset property. When you call this operation for an attribute property, this response includes the default attribute value that you define in the asset model. If you update the default value in the model, this operation&#39;s response includes the new default value. This operation doesn&#39;t return the value of the asset property. To get the value of an asset property, use GetAssetPropertyValue."},{"ref":"AWS.IoTSiteWise.html#describe_dashboard/3","title":"AWS.IoTSiteWise.describe_dashboard/3","type":"function","doc":"Retrieves information about a dashboard."},{"ref":"AWS.IoTSiteWise.html#describe_gateway/3","title":"AWS.IoTSiteWise.describe_gateway/3","type":"function","doc":"Retrieves information about a gateway."},{"ref":"AWS.IoTSiteWise.html#describe_gateway_capability_configuration/4","title":"AWS.IoTSiteWise.describe_gateway_capability_configuration/4","type":"function","doc":"Retrieves information about a gateway capability configuration. Each gateway capability defines data sources for a gateway. A capability configuration can contain multiple data source configurations. If you define OPC-UA sources for a gateway in the AWS IoT SiteWise console, all of your OPC-UA sources are stored in one capability configuration. To list all capability configurations for a gateway, use DescribeGateway."},{"ref":"AWS.IoTSiteWise.html#describe_logging_options/2","title":"AWS.IoTSiteWise.describe_logging_options/2","type":"function","doc":"Retrieves the current AWS IoT SiteWise logging options."},{"ref":"AWS.IoTSiteWise.html#describe_portal/3","title":"AWS.IoTSiteWise.describe_portal/3","type":"function","doc":"Retrieves information about a portal."},{"ref":"AWS.IoTSiteWise.html#describe_project/3","title":"AWS.IoTSiteWise.describe_project/3","type":"function","doc":"Retrieves information about a project."},{"ref":"AWS.IoTSiteWise.html#disassociate_assets/4","title":"AWS.IoTSiteWise.disassociate_assets/4","type":"function","doc":"Disassociates a child asset from the given parent asset through a hierarchy defined in the parent asset&#39;s model."},{"ref":"AWS.IoTSiteWise.html#get_asset_property_aggregates/13","title":"AWS.IoTSiteWise.get_asset_property_aggregates/13","type":"function","doc":"Gets aggregated values for an asset property. For more information, see Querying aggregates in the AWS IoT SiteWise User Guide. To identify an asset property, you must specify one of the following: The assetId and propertyId of an asset property. A propertyAlias, which is a data stream alias (for example, /company/windfarm/3/turbine/7/temperature). To define an asset property&#39;s alias, see UpdateAssetProperty."},{"ref":"AWS.IoTSiteWise.html#get_asset_property_value/5","title":"AWS.IoTSiteWise.get_asset_property_value/5","type":"function","doc":"Gets an asset property&#39;s current value. For more information, see Querying current values in the AWS IoT SiteWise User Guide. To identify an asset property, you must specify one of the following: The assetId and propertyId of an asset property. A propertyAlias, which is a data stream alias (for example, /company/windfarm/3/turbine/7/temperature). To define an asset property&#39;s alias, see UpdateAssetProperty."},{"ref":"AWS.IoTSiteWise.html#get_asset_property_value_history/11","title":"AWS.IoTSiteWise.get_asset_property_value_history/11","type":"function","doc":"Gets the history of an asset property&#39;s values. For more information, see Querying historical values in the AWS IoT SiteWise User Guide. To identify an asset property, you must specify one of the following: The assetId and propertyId of an asset property. A propertyAlias, which is a data stream alias (for example, /company/windfarm/3/turbine/7/temperature). To define an asset property&#39;s alias, see UpdateAssetProperty."},{"ref":"AWS.IoTSiteWise.html#list_access_policies/9","title":"AWS.IoTSiteWise.list_access_policies/9","type":"function","doc":"Retrieves a paginated list of access policies for an identity (an AWS SSO user, an AWS SSO group, or an IAM user) or an AWS IoT SiteWise Monitor resource (a portal or project)."},{"ref":"AWS.IoTSiteWise.html#list_asset_models/4","title":"AWS.IoTSiteWise.list_asset_models/4","type":"function","doc":"Retrieves a paginated list of summaries of all asset models."},{"ref":"AWS.IoTSiteWise.html#list_assets/6","title":"AWS.IoTSiteWise.list_assets/6","type":"function","doc":"Retrieves a paginated list of asset summaries. You can use this operation to do the following: List assets based on a specific asset model. List top-level assets. You can&#39;t use this operation to list all assets. To retrieve summaries for all of your assets, use ListAssetModels to get all of your asset model IDs. Then, use ListAssets to get all assets for each asset model."},{"ref":"AWS.IoTSiteWise.html#list_associated_assets/7","title":"AWS.IoTSiteWise.list_associated_assets/7","type":"function","doc":"Retrieves a paginated list of associated assets. You can use this operation to do the following: List child assets associated to a parent asset by a hierarchy that you specify. List an asset&#39;s parent asset."},{"ref":"AWS.IoTSiteWise.html#list_dashboards/5","title":"AWS.IoTSiteWise.list_dashboards/5","type":"function","doc":"Retrieves a paginated list of dashboards for an AWS IoT SiteWise Monitor project."},{"ref":"AWS.IoTSiteWise.html#list_gateways/4","title":"AWS.IoTSiteWise.list_gateways/4","type":"function","doc":"Retrieves a paginated list of gateways."},{"ref":"AWS.IoTSiteWise.html#list_portals/4","title":"AWS.IoTSiteWise.list_portals/4","type":"function","doc":"Retrieves a paginated list of AWS IoT SiteWise Monitor portals."},{"ref":"AWS.IoTSiteWise.html#list_project_assets/5","title":"AWS.IoTSiteWise.list_project_assets/5","type":"function","doc":"Retrieves a paginated list of assets associated with an AWS IoT SiteWise Monitor project."},{"ref":"AWS.IoTSiteWise.html#list_projects/5","title":"AWS.IoTSiteWise.list_projects/5","type":"function","doc":"Retrieves a paginated list of projects for an AWS IoT SiteWise Monitor portal."},{"ref":"AWS.IoTSiteWise.html#list_tags_for_resource/3","title":"AWS.IoTSiteWise.list_tags_for_resource/3","type":"function","doc":"Retrieves the list of tags for an AWS IoT SiteWise resource."},{"ref":"AWS.IoTSiteWise.html#put_logging_options/3","title":"AWS.IoTSiteWise.put_logging_options/3","type":"function","doc":"Sets logging options for AWS IoT SiteWise."},{"ref":"AWS.IoTSiteWise.html#tag_resource/3","title":"AWS.IoTSiteWise.tag_resource/3","type":"function","doc":"Adds tags to an AWS IoT SiteWise resource. If a tag already exists for the resource, this operation updates the tag&#39;s value."},{"ref":"AWS.IoTSiteWise.html#untag_resource/3","title":"AWS.IoTSiteWise.untag_resource/3","type":"function","doc":"Removes a tag from an AWS IoT SiteWise resource."},{"ref":"AWS.IoTSiteWise.html#update_access_policy/4","title":"AWS.IoTSiteWise.update_access_policy/4","type":"function","doc":"Updates an existing access policy that specifies an identity&#39;s access to an AWS IoT SiteWise Monitor portal or project resource."},{"ref":"AWS.IoTSiteWise.html#update_asset/4","title":"AWS.IoTSiteWise.update_asset/4","type":"function","doc":"Updates an asset&#39;s name. For more information, see Updating assets and models in the AWS IoT SiteWise User Guide."},{"ref":"AWS.IoTSiteWise.html#update_asset_model/4","title":"AWS.IoTSiteWise.update_asset_model/4","type":"function","doc":"Updates an asset model and all of the assets that were created from the model. Each asset created from the model inherits the updated asset model&#39;s property and hierarchy definitions. For more information, see Updating assets and models in the AWS IoT SiteWise User Guide. This operation overwrites the existing model with the provided model. To avoid deleting your asset model&#39;s properties or hierarchies, you must include their IDs and definitions in the updated asset model payload. For more information, see DescribeAssetModel. If you remove a property from an asset model, AWS IoT SiteWise deletes all previous data for that property. If you remove a hierarchy definition from an asset model, AWS IoT SiteWise disassociates every asset associated with that hierarchy. You can&#39;t change the type or data type of an existing property."},{"ref":"AWS.IoTSiteWise.html#update_asset_property/5","title":"AWS.IoTSiteWise.update_asset_property/5","type":"function","doc":"Updates an asset property&#39;s alias and notification state. This operation overwrites the property&#39;s existing alias and notification state. To keep your existing property&#39;s alias or notification state, you must include the existing values in the UpdateAssetProperty request. For more information, see DescribeAssetProperty."},{"ref":"AWS.IoTSiteWise.html#update_dashboard/4","title":"AWS.IoTSiteWise.update_dashboard/4","type":"function","doc":"Updates an AWS IoT SiteWise Monitor dashboard."},{"ref":"AWS.IoTSiteWise.html#update_gateway/4","title":"AWS.IoTSiteWise.update_gateway/4","type":"function","doc":"Updates a gateway&#39;s name."},{"ref":"AWS.IoTSiteWise.html#update_gateway_capability_configuration/4","title":"AWS.IoTSiteWise.update_gateway_capability_configuration/4","type":"function","doc":"Updates a gateway capability configuration or defines a new capability configuration. Each gateway capability defines data sources for a gateway. A capability configuration can contain multiple data source configurations. If you define OPC-UA sources for a gateway in the AWS IoT SiteWise console, all of your OPC-UA sources are stored in one capability configuration. To list all capability configurations for a gateway, use DescribeGateway."},{"ref":"AWS.IoTSiteWise.html#update_portal/4","title":"AWS.IoTSiteWise.update_portal/4","type":"function","doc":"Updates an AWS IoT SiteWise Monitor portal."},{"ref":"AWS.IoTSiteWise.html#update_project/4","title":"AWS.IoTSiteWise.update_project/4","type":"function","doc":"Updates an AWS IoT SiteWise Monitor project."},{"ref":"AWS.IoTThingsGraph.html","title":"AWS.IoTThingsGraph","type":"module","doc":"AWS IoT Things Graph AWS IoT Things Graph provides an integrated set of tools that enable developers to connect devices and services that use different standards, such as units of measure and communication protocols. AWS IoT Things Graph makes it possible to build IoT applications with little to no code by connecting devices and services and defining how they interact at an abstract level. For more information about how AWS IoT Things Graph works, see the User Guide."},{"ref":"AWS.IoTThingsGraph.html#associate_entity_to_thing/3","title":"AWS.IoTThingsGraph.associate_entity_to_thing/3","type":"function","doc":"Associates a device with a concrete thing that is in the user&#39;s registry. A thing can be associated with only one device at a time. If you associate a thing with a new device id, its previous association will be removed."},{"ref":"AWS.IoTThingsGraph.html#create_flow_template/3","title":"AWS.IoTThingsGraph.create_flow_template/3","type":"function","doc":"Creates a workflow template. Workflows can be created only in the user&#39;s namespace. (The public namespace contains only entities.) The workflow can contain only entities in the specified namespace. The workflow is validated against the entities in the latest version of the user&#39;s namespace unless another namespace version is specified in the request."},{"ref":"AWS.IoTThingsGraph.html#create_system_instance/3","title":"AWS.IoTThingsGraph.create_system_instance/3","type":"function","doc":"Creates a system instance. This action validates the system instance, prepares the deployment-related resources. For Greengrass deployments, it updates the Greengrass group that is specified by the greengrassGroupName parameter. It also adds a file to the S3 bucket specified by the s3BucketName parameter. You need to call DeploySystemInstance after running this action. For Greengrass deployments, since this action modifies and adds resources to a Greengrass group and an S3 bucket on the caller&#39;s behalf, the calling identity must have write permissions to both the specified Greengrass group and S3 bucket. Otherwise, the call will fail with an authorization error. For cloud deployments, this action requires a flowActionsRoleArn value. This is an IAM role that has permissions to access AWS services, such as AWS Lambda and AWS IoT, that the flow uses when it executes. If the definition document doesn&#39;t specify a version of the user&#39;s namespace, the latest version will be used by default."},{"ref":"AWS.IoTThingsGraph.html#create_system_template/3","title":"AWS.IoTThingsGraph.create_system_template/3","type":"function","doc":"Creates a system. The system is validated against the entities in the latest version of the user&#39;s namespace unless another namespace version is specified in the request."},{"ref":"AWS.IoTThingsGraph.html#delete_flow_template/3","title":"AWS.IoTThingsGraph.delete_flow_template/3","type":"function","doc":"Deletes a workflow. Any new system or deployment that contains this workflow will fail to update or deploy. Existing deployments that contain the workflow will continue to run (since they use a snapshot of the workflow taken at the time of deployment)."},{"ref":"AWS.IoTThingsGraph.html#delete_namespace/3","title":"AWS.IoTThingsGraph.delete_namespace/3","type":"function","doc":"Deletes the specified namespace. This action deletes all of the entities in the namespace. Delete the systems and flows that use entities in the namespace before performing this action."},{"ref":"AWS.IoTThingsGraph.html#delete_system_instance/3","title":"AWS.IoTThingsGraph.delete_system_instance/3","type":"function","doc":"Deletes a system instance. Only system instances that have never been deployed, or that have been undeployed can be deleted. Users can create a new system instance that has the same ID as a deleted system instance."},{"ref":"AWS.IoTThingsGraph.html#delete_system_template/3","title":"AWS.IoTThingsGraph.delete_system_template/3","type":"function","doc":"Deletes a system. New deployments can&#39;t contain the system after its deletion. Existing deployments that contain the system will continue to work because they use a snapshot of the system that is taken when it is deployed."},{"ref":"AWS.IoTThingsGraph.html#deploy_system_instance/3","title":"AWS.IoTThingsGraph.deploy_system_instance/3","type":"function","doc":"Greengrass and Cloud Deployments Deploys the system instance to the target specified in CreateSystemInstance. Greengrass Deployments If the system or any workflows and entities have been updated before this action is called, then the deployment will create a new Amazon Simple Storage Service resource file and then deploy it. Since this action creates a Greengrass deployment on the caller&#39;s behalf, the calling identity must have write permissions to the specified Greengrass group. Otherwise, the call will fail with an authorization error. For information about the artifacts that get added to your Greengrass core device when you use this API, see AWS IoT Things Graph and AWS IoT Greengrass."},{"ref":"AWS.IoTThingsGraph.html#deprecate_flow_template/3","title":"AWS.IoTThingsGraph.deprecate_flow_template/3","type":"function","doc":"Deprecates the specified workflow. This action marks the workflow for deletion. Deprecated flows can&#39;t be deployed, but existing deployments will continue to run."},{"ref":"AWS.IoTThingsGraph.html#deprecate_system_template/3","title":"AWS.IoTThingsGraph.deprecate_system_template/3","type":"function","doc":"Deprecates the specified system."},{"ref":"AWS.IoTThingsGraph.html#describe_namespace/3","title":"AWS.IoTThingsGraph.describe_namespace/3","type":"function","doc":"Gets the latest version of the user&#39;s namespace and the public version that it is tracking."},{"ref":"AWS.IoTThingsGraph.html#dissociate_entity_from_thing/3","title":"AWS.IoTThingsGraph.dissociate_entity_from_thing/3","type":"function","doc":"Dissociates a device entity from a concrete thing. The action takes only the type of the entity that you need to dissociate because only one entity of a particular type can be associated with a thing."},{"ref":"AWS.IoTThingsGraph.html#get_entities/3","title":"AWS.IoTThingsGraph.get_entities/3","type":"function","doc":"Gets definitions of the specified entities. Uses the latest version of the user&#39;s namespace by default. This API returns the following TDM entities. Properties States Events Actions Capabilities Mappings Devices Device Models Services This action doesn&#39;t return definitions for systems, flows, and deployments."},{"ref":"AWS.IoTThingsGraph.html#get_flow_template/3","title":"AWS.IoTThingsGraph.get_flow_template/3","type":"function","doc":"Gets the latest version of the DefinitionDocument and FlowTemplateSummary for the specified workflow."},{"ref":"AWS.IoTThingsGraph.html#get_flow_template_revisions/3","title":"AWS.IoTThingsGraph.get_flow_template_revisions/3","type":"function","doc":"Gets revisions of the specified workflow. Only the last 100 revisions are stored. If the workflow has been deprecated, this action will return revisions that occurred before the deprecation. This action won&#39;t work for workflows that have been deleted."},{"ref":"AWS.IoTThingsGraph.html#get_namespace_deletion_status/3","title":"AWS.IoTThingsGraph.get_namespace_deletion_status/3","type":"function","doc":"Gets the status of a namespace deletion task."},{"ref":"AWS.IoTThingsGraph.html#get_system_instance/3","title":"AWS.IoTThingsGraph.get_system_instance/3","type":"function","doc":"Gets a system instance."},{"ref":"AWS.IoTThingsGraph.html#get_system_template/3","title":"AWS.IoTThingsGraph.get_system_template/3","type":"function","doc":"Gets a system."},{"ref":"AWS.IoTThingsGraph.html#get_system_template_revisions/3","title":"AWS.IoTThingsGraph.get_system_template_revisions/3","type":"function","doc":"Gets revisions made to the specified system template. Only the previous 100 revisions are stored. If the system has been deprecated, this action will return the revisions that occurred before its deprecation. This action won&#39;t work with systems that have been deleted."},{"ref":"AWS.IoTThingsGraph.html#get_upload_status/3","title":"AWS.IoTThingsGraph.get_upload_status/3","type":"function","doc":"Gets the status of the specified upload."},{"ref":"AWS.IoTThingsGraph.html#list_flow_execution_messages/3","title":"AWS.IoTThingsGraph.list_flow_execution_messages/3","type":"function","doc":"Returns a list of objects that contain information about events in a flow execution."},{"ref":"AWS.IoTThingsGraph.html#list_tags_for_resource/3","title":"AWS.IoTThingsGraph.list_tags_for_resource/3","type":"function","doc":"Lists all tags on an AWS IoT Things Graph resource."},{"ref":"AWS.IoTThingsGraph.html#search_entities/3","title":"AWS.IoTThingsGraph.search_entities/3","type":"function","doc":"Searches for entities of the specified type. You can search for entities in your namespace and the public namespace that you&#39;re tracking."},{"ref":"AWS.IoTThingsGraph.html#search_flow_executions/3","title":"AWS.IoTThingsGraph.search_flow_executions/3","type":"function","doc":"Searches for AWS IoT Things Graph workflow execution instances."},{"ref":"AWS.IoTThingsGraph.html#search_flow_templates/3","title":"AWS.IoTThingsGraph.search_flow_templates/3","type":"function","doc":"Searches for summary information about workflows."},{"ref":"AWS.IoTThingsGraph.html#search_system_instances/3","title":"AWS.IoTThingsGraph.search_system_instances/3","type":"function","doc":"Searches for system instances in the user&#39;s account."},{"ref":"AWS.IoTThingsGraph.html#search_system_templates/3","title":"AWS.IoTThingsGraph.search_system_templates/3","type":"function","doc":"Searches for summary information about systems in the user&#39;s account. You can filter by the ID of a workflow to return only systems that use the specified workflow."},{"ref":"AWS.IoTThingsGraph.html#search_things/3","title":"AWS.IoTThingsGraph.search_things/3","type":"function","doc":"Searches for things associated with the specified entity. You can search by both device and device model. For example, if two different devices, camera1 and camera2, implement the camera device model, the user can associate thing1 to camera1 and thing2 to camera2. SearchThings(camera2) will return only thing2, but SearchThings(camera) will return both thing1 and thing2. This action searches for exact matches and doesn&#39;t perform partial text matching."},{"ref":"AWS.IoTThingsGraph.html#tag_resource/3","title":"AWS.IoTThingsGraph.tag_resource/3","type":"function","doc":"Creates a tag for the specified resource."},{"ref":"AWS.IoTThingsGraph.html#undeploy_system_instance/3","title":"AWS.IoTThingsGraph.undeploy_system_instance/3","type":"function","doc":"Removes a system instance from its target (Cloud or Greengrass)."},{"ref":"AWS.IoTThingsGraph.html#untag_resource/3","title":"AWS.IoTThingsGraph.untag_resource/3","type":"function","doc":"Removes a tag from the specified resource."},{"ref":"AWS.IoTThingsGraph.html#update_flow_template/3","title":"AWS.IoTThingsGraph.update_flow_template/3","type":"function","doc":"Updates the specified workflow. All deployed systems and system instances that use the workflow will see the changes in the flow when it is redeployed. If you don&#39;t want this behavior, copy the workflow (creating a new workflow with a different ID), and update the copy. The workflow can contain only entities in the specified namespace."},{"ref":"AWS.IoTThingsGraph.html#update_system_template/3","title":"AWS.IoTThingsGraph.update_system_template/3","type":"function","doc":"Updates the specified system. You don&#39;t need to run this action after updating a workflow. Any deployment that uses the system will see the changes in the system when it is redeployed."},{"ref":"AWS.IoTThingsGraph.html#upload_entity_definitions/3","title":"AWS.IoTThingsGraph.upload_entity_definitions/3","type":"function","doc":"Asynchronously uploads one or more entity definitions to the user&#39;s namespace. The document parameter is required if syncWithPublicNamespace and deleteExistingEntites are false. If the syncWithPublicNamespace parameter is set to true, the user&#39;s namespace will synchronize with the latest version of the public namespace. If deprecateExistingEntities is set to true, all entities in the latest version will be deleted before the new DefinitionDocument is uploaded. When a user uploads entity definitions for the first time, the service creates a new namespace for the user. The new namespace tracks the public namespace. Currently users can have only one namespace. The namespace version increments whenever a user uploads entity definitions that are backwards-incompatible and whenever a user sets the syncWithPublicNamespace parameter or the deprecateExistingEntities parameter to true. The IDs for all of the entities should be in URN format. Each entity must be in the user&#39;s namespace. Users can&#39;t create entities in the public namespace, but entity definitions can refer to entities in the public namespace. Valid entities are Device, DeviceModel, Service, Capability, State, Action, Event, Property, Mapping, Enum."},{"ref":"AWS.Ivs.html","title":"AWS.Ivs","type":"module","doc":"Introduction The Amazon Interactive Video Service (IVS) API is REST compatible, using a standard HTTP API and an AWS SNS event stream for responses. JSON is used for both requests and responses, including errors. The API is an AWS regional service, currently in these regions: us-west-2, us-east-1, and eu-west-1. All API request parameters and URLs are case sensitive. * For a summary of notable documentation changes in each release, see Document History. Service Endpoints The following are the Amazon IVS service endpoints (all HTTPS): Region name: US West (Oregon) Region: us-west-2 Endpoint: ivs.us-west-2.amazonaws.com Region name: US East (Virginia) Region: us-east-1 Endpoint: ivs.us-east-1.amazonaws.com Region name: EU West (Dublin) Region: eu-west-1 Endpoint: ivs.eu-west-1.amazonaws.com Allowed Header Values **Accept:** application/json **Accept-Encoding:** gzip, deflate **Content-Type:**application/json Resources The following resources contain information about your IVS live stream (see Getting Started with Amazon IVS): Channel  Stores configuration data related to your live stream. You first create a channel and then use the channels stream key to start your live stream. See the Channel endpoints for more information. Stream key  An identifier assigned by Amazon IVS when you create a channel, which is then used to authorize streaming. See the StreamKey endpoints for more information. Treat the stream key like a secret, since it allows anyone to stream to the channel. Playback key pair  Video playback may be restricted using playback-authorization tokens, which use public-key encryption. A playback key pair is the public-private pair of keys used to sign and validate the playback-authorization token. See the PlaybackKeyPair endpoints for more information. Tagging A tag is a metadata label that you assign to an AWS resource. A tag comprises a key and a value, both set by you. For example, you might set a tag as topic:nature to label a particular video category. See Tagging AWS Resources for more information, including restrictions that apply to tags. Tags can help you identify and organize your AWS resources. For example, you can use the same tag for different resources to indicate that they are related. You can also use tags to manage access (see Access Tags). The Amazon IVS API has these tag-related endpoints: TagResource, UntagResource, and ListTagsForResource. The following resources support tagging: Channels, Stream Keys, and Playback Key Pairs. Channel Endpoints CreateChannel  Creates a new channel and an associated stream key to start streaming. GetChannel  Gets the channel configuration for the specified channel ARN (Amazon Resource Name). BatchGetChannel  Performs GetChannel on multiple ARNs simultaneously. ListChannels  Gets summary information about all channels in your account, in the AWS region where the API request is processed. This list can be filtered to match a specified string. UpdateChannel  Updates a channel&#39;s configuration. This does not affect an ongoing stream of this channel. You must stop and restart the stream for the changes to take effect. DeleteChannel  Deletes the specified channel. StreamKey Endpoints CreateStreamKey  Creates a stream key, used to initiate a stream, for the specified channel ARN. GetStreamKey  Gets stream key information for the specified ARN. BatchGetStreamKey  Performs GetStreamKey on multiple ARNs simultaneously. ListStreamKeys  Gets summary information about stream keys for the specified channel. DeleteStreamKey  Deletes the stream key for the specified ARN, so it can no longer be used to stream. Stream Endpoints GetStream  Gets information about the active (live) stream on a specified channel. ListStreams  Gets summary information about live streams in your account, in the AWS region where the API request is processed. StopStream  Disconnects the incoming RTMPS stream for the specified channel. Can be used in conjunction with DeleteStreamKey to prevent further streaming to a channel. PutMetadata  Inserts metadata into an RTMPS stream for the specified channel. A maximum of 5 requests per second per channel is allowed, each with a maximum 1KB payload. PlaybackKeyPair Endpoints ImportPlaybackKeyPair  Imports the public portion of a new key pair and returns its arn and fingerprint. The privateKey can then be used to generate viewer authorization tokens, to grant viewers access to authorized channels. GetPlaybackKeyPair  Gets a specified playback authorization key pair and returns the arn and fingerprint. The privateKey held by the caller can be used to generate viewer authorization tokens, to grant viewers access to authorized channels. ListPlaybackKeyPairs  Gets summary information about playback key pairs. DeletePlaybackKeyPair  Deletes a specified authorization key pair. This invalidates future viewer tokens generated using the key pairs privateKey. AWS Tags Endpoints TagResource  Adds or updates tags for the AWS resource with the specified ARN. UntagResource  Removes tags from the resource with the specified ARN. ListTagsForResource  Gets information about AWS tags for the specified ARN."},{"ref":"AWS.Ivs.html#batch_get_channel/3","title":"AWS.Ivs.batch_get_channel/3","type":"function","doc":"Performs GetChannel on multiple ARNs simultaneously."},{"ref":"AWS.Ivs.html#batch_get_stream_key/3","title":"AWS.Ivs.batch_get_stream_key/3","type":"function","doc":"Performs GetStreamKey on multiple ARNs simultaneously."},{"ref":"AWS.Ivs.html#create_channel/3","title":"AWS.Ivs.create_channel/3","type":"function","doc":"Creates a new channel and an associated stream key to start streaming."},{"ref":"AWS.Ivs.html#create_stream_key/3","title":"AWS.Ivs.create_stream_key/3","type":"function","doc":"Creates a stream key, used to initiate a stream, for the specified channel ARN. Note that CreateChannel creates a stream key. If you subsequently use CreateStreamKey on the same channel, it will fail because a stream key already exists and there is a limit of 1 stream key per channel. To reset the stream key on a channel, use DeleteStreamKey and then CreateStreamKey."},{"ref":"AWS.Ivs.html#delete_channel/3","title":"AWS.Ivs.delete_channel/3","type":"function","doc":"Deletes the specified channel and its associated stream keys."},{"ref":"AWS.Ivs.html#delete_playback_key_pair/3","title":"AWS.Ivs.delete_playback_key_pair/3","type":"function","doc":"Deletes a specified authorization key pair. This invalidates future viewer tokens generated using the key pairs privateKey."},{"ref":"AWS.Ivs.html#delete_stream_key/3","title":"AWS.Ivs.delete_stream_key/3","type":"function","doc":"Deletes the stream key for the specified ARN, so it can no longer be used to stream."},{"ref":"AWS.Ivs.html#get_channel/3","title":"AWS.Ivs.get_channel/3","type":"function","doc":"Gets the channel configuration for the specified channel ARN. See also BatchGetChannel."},{"ref":"AWS.Ivs.html#get_playback_key_pair/3","title":"AWS.Ivs.get_playback_key_pair/3","type":"function","doc":"Gets a specified playback authorization key pair and returns the arn and fingerprint. The privateKey held by the caller can be used to generate viewer authorization tokens, to grant viewers access to authorized channels."},{"ref":"AWS.Ivs.html#get_stream/3","title":"AWS.Ivs.get_stream/3","type":"function","doc":"Gets information about the active (live) stream on a specified channel."},{"ref":"AWS.Ivs.html#get_stream_key/3","title":"AWS.Ivs.get_stream_key/3","type":"function","doc":"Gets stream-key information for a specified ARN."},{"ref":"AWS.Ivs.html#import_playback_key_pair/3","title":"AWS.Ivs.import_playback_key_pair/3","type":"function","doc":"Imports the public portion of a new key pair and returns its arn and fingerprint. The privateKey can then be used to generate viewer authorization tokens, to grant viewers access to authorized channels."},{"ref":"AWS.Ivs.html#list_channels/3","title":"AWS.Ivs.list_channels/3","type":"function","doc":"Gets summary information about all channels in your account, in the AWS region where the API request is processed. This list can be filtered to match a specified string."},{"ref":"AWS.Ivs.html#list_playback_key_pairs/3","title":"AWS.Ivs.list_playback_key_pairs/3","type":"function","doc":"Gets summary information about playback key pairs."},{"ref":"AWS.Ivs.html#list_stream_keys/3","title":"AWS.Ivs.list_stream_keys/3","type":"function","doc":"Gets summary information about stream keys for the specified channel."},{"ref":"AWS.Ivs.html#list_streams/3","title":"AWS.Ivs.list_streams/3","type":"function","doc":"Gets summary information about live streams in your account, in the AWS region where the API request is processed."},{"ref":"AWS.Ivs.html#list_tags_for_resource/3","title":"AWS.Ivs.list_tags_for_resource/3","type":"function","doc":"Gets information about AWS tags for the specified ARN."},{"ref":"AWS.Ivs.html#put_metadata/3","title":"AWS.Ivs.put_metadata/3","type":"function","doc":"Inserts metadata into an RTMPS stream for the specified channel. A maximum of 5 requests per second per channel is allowed, each with a maximum 1KB payload."},{"ref":"AWS.Ivs.html#stop_stream/3","title":"AWS.Ivs.stop_stream/3","type":"function","doc":"Disconnects the incoming RTMPS stream for the specified channel. Can be used in conjunction with DeleteStreamKey to prevent further streaming to a channel. Many streaming client-software libraries automatically reconnect a dropped RTMPS session, so to stop the stream permanently, you may want to first revoke the streamKey attached to the channel."},{"ref":"AWS.Ivs.html#tag_resource/4","title":"AWS.Ivs.tag_resource/4","type":"function","doc":"Adds or updates tags for the AWS resource with the specified ARN."},{"ref":"AWS.Ivs.html#untag_resource/4","title":"AWS.Ivs.untag_resource/4","type":"function","doc":"Removes tags from the resource with the specified ARN."},{"ref":"AWS.Ivs.html#update_channel/3","title":"AWS.Ivs.update_channel/3","type":"function","doc":"Updates a channel&#39;s configuration. This does not affect an ongoing stream of this channel. You must stop and restart the stream for the changes to take effect."},{"ref":"AWS.KMS.html","title":"AWS.KMS","type":"module","doc":"AWS Key Management Service AWS Key Management Service (AWS KMS) is an encryption and key management web service. This guide describes the AWS KMS operations that you can call programmatically. For general information about AWS KMS, see the AWS Key Management Service Developer Guide . AWS provides SDKs that consist of libraries and sample code for various programming languages and platforms (Java, Ruby, .Net, macOS, Android, etc.). The SDKs provide a convenient way to create programmatic access to AWS KMS and other AWS services. For example, the SDKs take care of tasks such as signing requests (see below), managing errors, and retrying requests automatically. For more information about the AWS SDKs, including how to download and install them, see Tools for Amazon Web Services. We recommend that you use the AWS SDKs to make programmatic API calls to AWS KMS. Clients must support TLS (Transport Layer Security) 1.0. We recommend TLS 1.2. Clients must also support cipher suites with Perfect Forward Secrecy (PFS) such as Ephemeral Diffie-Hellman (DHE) or Elliptic Curve Ephemeral Diffie-Hellman (ECDHE). Most modern systems such as Java 7 and later support these modes. Signing Requests Requests must be signed by using an access key ID and a secret access key. We strongly recommend that you do not use your AWS account (root) access key ID and secret key for everyday work with AWS KMS. Instead, use the access key ID and secret access key for an IAM user. You can also use the AWS Security Token Service to generate temporary security credentials that you can use to sign requests. All AWS KMS operations require Signature Version 4. Logging API Requests AWS KMS supports AWS CloudTrail, a service that logs AWS API calls and related events for your AWS account and delivers them to an Amazon S3 bucket that you specify. By using the information collected by CloudTrail, you can determine what requests were made to AWS KMS, who made the request, when it was made, and so on. To learn more about CloudTrail, including how to turn it on and find your log files, see the AWS CloudTrail User Guide. Additional Resources For more information about credentials and request signing, see the following: AWS Security Credentials - This topic provides general information about the types of credentials used for accessing AWS. Temporary Security Credentials - This section of the IAM User Guide describes how to create and use temporary security credentials. Signature Version 4 Signing Process - This set of topics walks you through the process of signing a request using an access key ID and a secret access key. Commonly Used API Operations Of the API operations discussed in this guide, the following will prove the most useful for most applications. You will likely perform operations other than these, such as creating keys and assigning policies, by using the console. Encrypt Decrypt GenerateDataKey GenerateDataKeyWithoutPlaintext"},{"ref":"AWS.KMS.html#cancel_key_deletion/3","title":"AWS.KMS.cancel_key_deletion/3","type":"function","doc":"Cancels the deletion of a customer master key (CMK). When this operation succeeds, the key state of the CMK is Disabled. To enable the CMK, use EnableKey. You cannot perform this operation on a CMK in a different AWS account. For more information about scheduling and canceling deletion of a CMK, see Deleting Customer Master Keys in the AWS Key Management Service Developer Guide. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#connect_custom_key_store/3","title":"AWS.KMS.connect_custom_key_store/3","type":"function","doc":"Connects or reconnects a custom key store to its associated AWS CloudHSM cluster. The custom key store must be connected before you can create customer master keys (CMKs) in the key store or use the CMKs it contains. You can disconnect and reconnect a custom key store at any time. To connect a custom key store, its associated AWS CloudHSM cluster must have at least one active HSM. To get the number of active HSMs in a cluster, use the DescribeClusters operation. To add HSMs to the cluster, use the CreateHsm operation. Also, the kmsuser crypto user (CU) must not be logged into the cluster. This prevents AWS KMS from using this account to log in. The connection process can take an extended amount of time to complete; up to 20 minutes. This operation starts the connection process, but it does not wait for it to complete. When it succeeds, this operation quickly returns an HTTP 200 response and a JSON object with no properties. However, this response does not indicate that the custom key store is connected. To get the connection state of the custom key store, use the DescribeCustomKeyStores operation. During the connection process, AWS KMS finds the AWS CloudHSM cluster that is associated with the custom key store, creates the connection infrastructure, connects to the cluster, logs into the AWS CloudHSM client as the kmsuser CU, and rotates its password. The ConnectCustomKeyStore operation might fail for various reasons. To find the reason, use the DescribeCustomKeyStores operation and see the ConnectionErrorCode in the response. For help interpreting the ConnectionErrorCode, see CustomKeyStoresListEntry. To fix the failure, use the DisconnectCustomKeyStore operation to disconnect the custom key store, correct the error, use the UpdateCustomKeyStore operation if necessary, and then use ConnectCustomKeyStore again. If you are having trouble connecting or disconnecting a custom key store, see Troubleshooting a Custom Key Store in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#create_alias/3","title":"AWS.KMS.create_alias/3","type":"function","doc":"Creates a display name for a customer managed customer master key (CMK). You can use an alias to identify a CMK in cryptographic operations, such as Encrypt and GenerateDataKey. You can change the CMK associated with the alias at any time. Aliases are easier to remember than key IDs. They can also help to simplify your applications. For example, if you use an alias in your code, you can change the CMK your code uses by associating a given alias with a different CMK. To run the same code in multiple AWS regions, use an alias in your code, such as alias/ApplicationKey. Then, in each AWS Region, create an alias/ApplicationKey alias that is associated with a CMK in that Region. When you run your code, it uses the alias/ApplicationKey CMK for that AWS Region without any Region-specific code. This operation does not return a response. To get the alias that you created, use the ListAliases operation. To use aliases successfully, be aware of the following information. Each alias points to only one CMK at a time, although a single CMK can have multiple aliases. The alias and its associated CMK must be in the same AWS account and Region. You can associate an alias with any customer managed CMK in the same AWS account and Region. However, you do not have permission to associate an alias with an AWS managed CMK or an AWS owned CMK. To change the CMK associated with an alias, use the UpdateAlias operation. The current CMK and the new CMK must be the same type (both symmetric or both asymmetric) and they must have the same key usage (ENCRYPT_DECRYPT or SIGN_VERIFY). This restriction prevents cryptographic errors in code that uses aliases. The alias name must begin with alias/ followed by a name, such as alias/ExampleAlias. It can contain only alphanumeric characters, forward slashes (/), underscores (_), and dashes (-). The alias name cannot begin with alias/aws/. The alias/aws/ prefix is reserved for AWS managed CMKs. The alias name must be unique within an AWS Region. However, you can use the same alias name in multiple Regions of the same AWS account. Each instance of the alias is associated with a CMK in its Region. After you create an alias, you cannot change its alias name. However, you can use the DeleteAlias operation to delete the alias and then create a new alias with the desired name. You can use an alias name or alias ARN to identify a CMK in AWS KMS cryptographic operations and in the DescribeKey operation. However, you cannot use alias names or alias ARNs in API operations that manage CMKs, such as DisableKey or GetKeyPolicy. For information about the valid CMK identifiers for each AWS KMS API operation, see the descriptions of the KeyId parameter in the API operation documentation. Because an alias is not a property of a CMK, you can delete and change the aliases of a CMK without affecting the CMK. Also, aliases do not appear in the response from the DescribeKey operation. To get the aliases and alias ARNs of CMKs in each AWS account and Region, use the ListAliases operation. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#create_custom_key_store/3","title":"AWS.KMS.create_custom_key_store/3","type":"function","doc":"Creates a custom key store that is associated with an AWS CloudHSM cluster that you own and manage. This operation is part of the Custom Key Store feature feature in AWS KMS, which combines the convenience and extensive integration of AWS KMS with the isolation and control of a single-tenant key store. Before you create the custom key store, you must assemble the required elements, including an AWS CloudHSM cluster that fulfills the requirements for a custom key store. For details about the required elements, see Assemble the Prerequisites in the AWS Key Management Service Developer Guide. When the operation completes successfully, it returns the ID of the new custom key store. Before you can use your new custom key store, you need to use the ConnectCustomKeyStore operation to connect the new key store to its AWS CloudHSM cluster. Even if you are not going to use your custom key store immediately, you might want to connect it to verify that all settings are correct and then disconnect it until you are ready to use it. For help with failures, see Troubleshooting a Custom Key Store in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#create_grant/3","title":"AWS.KMS.create_grant/3","type":"function","doc":"Adds a grant to a customer master key (CMK). The grant allows the grantee principal to use the CMK when the conditions specified in the grant are met. When setting permissions, grants are an alternative to key policies. To create a grant that allows a cryptographic operation only when the request includes a particular encryption context, use the Constraints parameter. For details, see GrantConstraints. You can create grants on symmetric and asymmetric CMKs. However, if the grant allows an operation that the CMK does not support, CreateGrant fails with a ValidationException. Grants for symmetric CMKs cannot allow operations that are not supported for symmetric CMKs, including Sign, Verify, and GetPublicKey. (There are limited exceptions to this rule for legacy operations, but you should not create a grant for an operation that AWS KMS does not support.) Grants for asymmetric CMKs cannot allow operations that are not supported for asymmetric CMKs, including operations that generate data keys or data key pairs, or operations related to automatic key rotation, imported key material, or CMKs in custom key stores. Grants for asymmetric CMKs with a KeyUsage of ENCRYPT_DECRYPT cannot allow the Sign or Verify operations. Grants for asymmetric CMKs with a KeyUsage of SIGN_VERIFY cannot allow the Encrypt or Decrypt operations. Grants for asymmetric CMKs cannot include an encryption context grant constraint. An encryption context is not supported on asymmetric CMKs. For information about symmetric and asymmetric CMKs, see Using Symmetric and Asymmetric CMKs in the AWS Key Management Service Developer Guide. To perform this operation on a CMK in a different AWS account, specify the key ARN in the value of the KeyId parameter. For more information about grants, see Grants in the AWS Key Management Service Developer Guide . The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#create_key/3","title":"AWS.KMS.create_key/3","type":"function","doc":"Creates a unique customer managed customer master key (CMK) in your AWS account and Region. You cannot use this operation to create a CMK in a different AWS account. You can use the CreateKey operation to create symmetric or asymmetric CMKs. Symmetric CMKs contain a 256-bit symmetric key that never leaves AWS KMS unencrypted. To use the CMK, you must call AWS KMS. You can use a symmetric CMK to encrypt and decrypt small amounts of data, but they are typically used to generate data keys and data keys pairs. For details, see GenerateDataKey and GenerateDataKeyPair. Asymmetric CMKs can contain an RSA key pair or an Elliptic Curve (ECC) key pair. The private key in an asymmetric CMK never leaves AWS KMS unencrypted. However, you can use the GetPublicKey operation to download the public key so it can be used outside of AWS KMS. CMKs with RSA key pairs can be used to encrypt or decrypt data or sign and verify messages (but not both). CMKs with ECC key pairs can be used only to sign and verify messages. For information about symmetric and asymmetric CMKs, see Using Symmetric and Asymmetric CMKs in the AWS Key Management Service Developer Guide. To create different types of CMKs, use the following guidance: Definitions Asymmetric CMKs To create an asymmetric CMK, use the CustomerMasterKeySpec parameter to specify the type of key material in the CMK. Then, use the KeyUsage parameter to determine whether the CMK will be used to encrypt and decrypt or sign and verify. You can&#39;t change these properties after the CMK is created. Symmetric CMKs When creating a symmetric CMK, you don&#39;t need to specify the CustomerMasterKeySpec or KeyUsage parameters. The default value for CustomerMasterKeySpec, SYMMETRIC_DEFAULT, and the default value for KeyUsage, ENCRYPT_DECRYPT, are the only valid values for symmetric CMKs. Imported Key Material To import your own key material, begin by creating a symmetric CMK with no key material. To do this, use the Origin parameter of CreateKey with a value of EXTERNAL. Next, use GetParametersForImport operation to get a public key and import token, and use the public key to encrypt your key material. Then, use ImportKeyMaterial with your import token to import the key material. For step-by-step instructions, see Importing Key Material in the AWS Key Management Service Developer Guide . You cannot import the key material into an asymmetric CMK. Custom Key Stores To create a symmetric CMK in a custom key store, use the CustomKeyStoreId parameter to specify the custom key store. You must also use the Origin parameter with a value of AWS_CLOUDHSM. The AWS CloudHSM cluster that is associated with the custom key store must have at least two active HSMs in different Availability Zones in the AWS Region. You cannot create an asymmetric CMK in a custom key store. For information about custom key stores in AWS KMS see Using Custom Key Stores in the AWS Key Management Service Developer Guide ."},{"ref":"AWS.KMS.html#decrypt/3","title":"AWS.KMS.decrypt/3","type":"function","doc":"Decrypts ciphertext that was encrypted by a AWS KMS customer master key (CMK) using any of the following operations: Encrypt GenerateDataKey GenerateDataKeyPair GenerateDataKeyWithoutPlaintext GenerateDataKeyPairWithoutPlaintext You can use this operation to decrypt ciphertext that was encrypted under a symmetric or asymmetric CMK. When the CMK is asymmetric, you must specify the CMK and the encryption algorithm that was used to encrypt the ciphertext. For information about symmetric and asymmetric CMKs, see Using Symmetric and Asymmetric CMKs in the AWS Key Management Service Developer Guide. The Decrypt operation also decrypts ciphertext that was encrypted outside of AWS KMS by the public key in an AWS KMS asymmetric CMK. However, it cannot decrypt ciphertext produced by other libraries, such as the AWS Encryption SDK or Amazon S3 client-side encryption. These libraries return a ciphertext format that is incompatible with AWS KMS. If the ciphertext was encrypted under a symmetric CMK, you do not need to specify the CMK or the encryption algorithm. AWS KMS can get this information from metadata that it adds to the symmetric ciphertext blob. However, if you prefer, you can specify the KeyId to ensure that a particular CMK is used to decrypt the ciphertext. If you specify a different CMK than the one used to encrypt the ciphertext, the Decrypt operation fails. Whenever possible, use key policies to give users permission to call the Decrypt operation on a particular CMK, instead of using IAM policies. Otherwise, you might create an IAM user policy that gives the user Decrypt permission on all CMKs. This user could decrypt ciphertext that was encrypted by CMKs in other accounts if the key policy for the cross-account CMK permits it. If you must use an IAM policy for Decrypt permissions, limit the user to particular CMKs or particular trusted accounts. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#delete_alias/3","title":"AWS.KMS.delete_alias/3","type":"function","doc":"Deletes the specified alias. You cannot perform this operation on an alias in a different AWS account. Because an alias is not a property of a CMK, you can delete and change the aliases of a CMK without affecting the CMK. Also, aliases do not appear in the response from the DescribeKey operation. To get the aliases of all CMKs, use the ListAliases operation. Each CMK can have multiple aliases. To change the alias of a CMK, use DeleteAlias to delete the current alias and CreateAlias to create a new alias. To associate an existing alias with a different customer master key (CMK), call UpdateAlias."},{"ref":"AWS.KMS.html#delete_custom_key_store/3","title":"AWS.KMS.delete_custom_key_store/3","type":"function","doc":"Deletes a custom key store. This operation does not delete the AWS CloudHSM cluster that is associated with the custom key store, or affect any users or keys in the cluster. The custom key store that you delete cannot contain any AWS KMS customer master keys (CMKs). Before deleting the key store, verify that you will never need to use any of the CMKs in the key store for any cryptographic operations. Then, use ScheduleKeyDeletion to delete the AWS KMS customer master keys (CMKs) from the key store. When the scheduled waiting period expires, the ScheduleKeyDeletion operation deletes the CMKs. Then it makes a best effort to delete the key material from the associated cluster. However, you might need to manually delete the orphaned key material from the cluster and its backups. After all CMKs are deleted from AWS KMS, use DisconnectCustomKeyStore to disconnect the key store from AWS KMS. Then, you can delete the custom key store. Instead of deleting the custom key store, consider using DisconnectCustomKeyStore to disconnect it from AWS KMS. While the key store is disconnected, you cannot create or use the CMKs in the key store. But, you do not need to delete CMKs and you can reconnect a disconnected custom key store at any time. If the operation succeeds, it returns a JSON object with no properties. This operation is part of the Custom Key Store feature feature in AWS KMS, which combines the convenience and extensive integration of AWS KMS with the isolation and control of a single-tenant key store."},{"ref":"AWS.KMS.html#delete_imported_key_material/3","title":"AWS.KMS.delete_imported_key_material/3","type":"function","doc":"Deletes key material that you previously imported. This operation makes the specified customer master key (CMK) unusable. For more information about importing key material into AWS KMS, see Importing Key Material in the AWS Key Management Service Developer Guide. You cannot perform this operation on a CMK in a different AWS account. When the specified CMK is in the PendingDeletion state, this operation does not change the CMK&#39;s state. Otherwise, it changes the CMK&#39;s state to PendingImport. After you delete key material, you can use ImportKeyMaterial to reimport the same key material into the CMK. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#describe_custom_key_stores/3","title":"AWS.KMS.describe_custom_key_stores/3","type":"function","doc":"Gets information about custom key stores in the account and region. This operation is part of the Custom Key Store feature feature in AWS KMS, which combines the convenience and extensive integration of AWS KMS with the isolation and control of a single-tenant key store. By default, this operation returns information about all custom key stores in the account and region. To get only information about a particular custom key store, use either the CustomKeyStoreName or CustomKeyStoreId parameter (but not both). To determine whether the custom key store is connected to its AWS CloudHSM cluster, use the ConnectionState element in the response. If an attempt to connect the custom key store failed, the ConnectionState value is FAILED and the ConnectionErrorCode element in the response indicates the cause of the failure. For help interpreting the ConnectionErrorCode, see CustomKeyStoresListEntry. Custom key stores have a DISCONNECTED connection state if the key store has never been connected or you use the DisconnectCustomKeyStore operation to disconnect it. If your custom key store state is CONNECTED but you are having trouble using it, make sure that its associated AWS CloudHSM cluster is active and contains the minimum number of HSMs required for the operation, if any. For help repairing your custom key store, see the Troubleshooting Custom Key Stores topic in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#describe_key/3","title":"AWS.KMS.describe_key/3","type":"function","doc":"Provides detailed information about a customer master key (CMK). You can run DescribeKey on a customer managed CMK or an AWS managed CMK. This detailed information includes the key ARN, creation date (and deletion date, if applicable), the key state, and the origin and expiration date (if any) of the key material. For CMKs in custom key stores, it includes information about the custom key store, such as the key store ID and the AWS CloudHSM cluster ID. It includes fields, like KeySpec, that help you distinguish symmetric from asymmetric CMKs. It also provides information that is particularly important to asymmetric CMKs, such as the key usage (encryption or signing) and the encryption algorithms or signing algorithms that the CMK supports. DescribeKey does not return the following information: Aliases associated with the CMK. To get this information, use ListAliases. Whether automatic key rotation is enabled on the CMK. To get this information, use GetKeyRotationStatus. Also, some key states prevent a CMK from being automatically rotated. For details, see How Automatic Key Rotation Works in AWS Key Management Service Developer Guide. Tags on the CMK. To get this information, use ListResourceTags. Key policies and grants on the CMK. To get this information, use GetKeyPolicy and ListGrants. If you call the DescribeKey operation on a predefined AWS alias, that is, an AWS alias with no key ID, AWS KMS creates an AWS managed CMK. Then, it associates the alias with the new CMK, and returns the KeyId and Arn of the new CMK in the response. To perform this operation on a CMK in a different AWS account, specify the key ARN or alias ARN in the value of the KeyId parameter."},{"ref":"AWS.KMS.html#disable_key/3","title":"AWS.KMS.disable_key/3","type":"function","doc":"Sets the state of a customer master key (CMK) to disabled, thereby preventing its use for cryptographic operations. You cannot perform this operation on a CMK in a different AWS account. For more information about how key state affects the use of a CMK, see How Key State Affects the Use of a Customer Master Key in the AWS Key Management Service Developer Guide . The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#disable_key_rotation/3","title":"AWS.KMS.disable_key_rotation/3","type":"function","doc":"Disables automatic rotation of the key material for the specified symmetric customer master key (CMK). You cannot enable automatic rotation of asymmetric CMKs, CMKs with imported key material, or CMKs in a custom key store. You cannot perform this operation on a CMK in a different AWS account. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#disconnect_custom_key_store/3","title":"AWS.KMS.disconnect_custom_key_store/3","type":"function","doc":"Disconnects the custom key store from its associated AWS CloudHSM cluster. While a custom key store is disconnected, you can manage the custom key store and its customer master keys (CMKs), but you cannot create or use CMKs in the custom key store. You can reconnect the custom key store at any time. While a custom key store is disconnected, all attempts to create customer master keys (CMKs) in the custom key store or to use existing CMKs in cryptographic operations will fail. This action can prevent users from storing and accessing sensitive data. To find the connection state of a custom key store, use the DescribeCustomKeyStores operation. To reconnect a custom key store, use the ConnectCustomKeyStore operation. If the operation succeeds, it returns a JSON object with no properties. This operation is part of the Custom Key Store feature feature in AWS KMS, which combines the convenience and extensive integration of AWS KMS with the isolation and control of a single-tenant key store."},{"ref":"AWS.KMS.html#enable_key/3","title":"AWS.KMS.enable_key/3","type":"function","doc":"Sets the key state of a customer master key (CMK) to enabled. This allows you to use the CMK for cryptographic operations. You cannot perform this operation on a CMK in a different AWS account. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#enable_key_rotation/3","title":"AWS.KMS.enable_key_rotation/3","type":"function","doc":"Enables automatic rotation of the key material for the specified symmetric customer master key (CMK). You cannot perform this operation on a CMK in a different AWS account. You cannot enable automatic rotation of asymmetric CMKs, CMKs with imported key material, or CMKs in a custom key store. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#encrypt/3","title":"AWS.KMS.encrypt/3","type":"function","doc":"Encrypts plaintext into ciphertext by using a customer master key (CMK). The Encrypt operation has two primary use cases: You can encrypt small amounts of arbitrary data, such as a personal identifier or database password, or other sensitive information. You can use the Encrypt operation to move encrypted data from one AWS Region to another. For example, in Region A, generate a data key and use the plaintext key to encrypt your data. Then, in Region A, use the Encrypt operation to encrypt the plaintext data key under a CMK in Region B. Now, you can move the encrypted data and the encrypted data key to Region B. When necessary, you can decrypt the encrypted data key and the encrypted data entirely within in Region B. You don&#39;t need to use the Encrypt operation to encrypt a data key. The GenerateDataKey and GenerateDataKeyPair operations return a plaintext data key and an encrypted copy of that data key. When you encrypt data, you must specify a symmetric or asymmetric CMK to use in the encryption operation. The CMK must have a KeyUsage value of ENCRYPT_DECRYPT. To find the KeyUsage of a CMK, use the DescribeKey operation. If you use a symmetric CMK, you can use an encryption context to add additional security to your encryption operation. If you specify an EncryptionContext when encrypting data, you must specify the same encryption context (a case-sensitive exact match) when decrypting the data. Otherwise, the request to decrypt fails with an InvalidCiphertextException. For more information, see Encryption Context in the AWS Key Management Service Developer Guide. If you specify an asymmetric CMK, you must also specify the encryption algorithm. The algorithm must be compatible with the CMK type. When you use an asymmetric CMK to encrypt or reencrypt data, be sure to record the CMK and encryption algorithm that you choose. You will be required to provide the same CMK and encryption algorithm when you decrypt the data. If the CMK and algorithm do not match the values used to encrypt the data, the decrypt operation fails. You are not required to supply the CMK ID and encryption algorithm when you decrypt with symmetric CMKs because AWS KMS stores this information in the ciphertext blob. AWS KMS cannot store metadata in ciphertext generated with asymmetric keys. The standard format for asymmetric key ciphertext does not include configurable fields. The maximum size of the data that you can encrypt varies with the type of CMK and the encryption algorithm that you choose. Symmetric CMKs SYMMETRIC_DEFAULT: 4096 bytes RSA_2048 RSAES_OAEP_SHA_1: 214 bytes RSAES_OAEP_SHA_256: 190 bytes RSA_3072 RSAES_OAEP_SHA_1: 342 bytes RSAES_OAEP_SHA_256: 318 bytes RSA_4096 RSAES_OAEP_SHA_1: 470 bytes RSAES_OAEP_SHA_256: 446 bytes The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide. To perform this operation on a CMK in a different AWS account, specify the key ARN or alias ARN in the value of the KeyId parameter."},{"ref":"AWS.KMS.html#generate_data_key/3","title":"AWS.KMS.generate_data_key/3","type":"function","doc":"Generates a unique symmetric data key for client-side encryption. This operation returns a plaintext copy of the data key and a copy that is encrypted under a customer master key (CMK) that you specify. You can use the plaintext key to encrypt your data outside of AWS KMS and store the encrypted data key with the encrypted data. GenerateDataKey returns a unique data key for each request. The bytes in the plaintext key are not related to the caller or the CMK. To generate a data key, specify the symmetric CMK that will be used to encrypt the data key. You cannot use an asymmetric CMK to generate data keys. To get the type of your CMK, use the DescribeKey operation. You must also specify the length of the data key. Use either the KeySpec or NumberOfBytes parameters (but not both). For 128-bit and 256-bit data keys, use the KeySpec parameter. To get only an encrypted copy of the data key, use GenerateDataKeyWithoutPlaintext. To generate an asymmetric data key pair, use the GenerateDataKeyPair or GenerateDataKeyPairWithoutPlaintext operation. To get a cryptographically secure random byte string, use GenerateRandom. You can use the optional encryption context to add additional security to the encryption operation. If you specify an EncryptionContext, you must specify the same encryption context (a case-sensitive exact match) when decrypting the encrypted data key. Otherwise, the request to decrypt fails with an InvalidCiphertextException. For more information, see Encryption Context in the AWS Key Management Service Developer Guide. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide. How to use your data key We recommend that you use the following pattern to encrypt data locally in your application. You can write your own code or use a client-side encryption library, such as the AWS Encryption SDK, the Amazon DynamoDB Encryption Client, or Amazon S3 client-side encryption to do these tasks for you. To encrypt data outside of AWS KMS: Use the GenerateDataKey operation to get a data key. Use the plaintext data key (in the Plaintext field of the response) to encrypt your data outside of AWS KMS. Then erase the plaintext data key from memory. Store the encrypted data key (in the CiphertextBlob field of the response) with the encrypted data. To decrypt data outside of AWS KMS: Use the Decrypt operation to decrypt the encrypted data key. The operation returns a plaintext copy of the data key. Use the plaintext data key to decrypt data outside of AWS KMS, then erase the plaintext data key from memory."},{"ref":"AWS.KMS.html#generate_data_key_pair/3","title":"AWS.KMS.generate_data_key_pair/3","type":"function","doc":"Generates a unique asymmetric data key pair. The GenerateDataKeyPair operation returns a plaintext public key, a plaintext private key, and a copy of the private key that is encrypted under the symmetric CMK you specify. You can use the data key pair to perform asymmetric cryptography outside of AWS KMS. GenerateDataKeyPair returns a unique data key pair for each request. The bytes in the keys are not related to the caller or the CMK that is used to encrypt the private key. You can use the public key that GenerateDataKeyPair returns to encrypt data or verify a signature outside of AWS KMS. Then, store the encrypted private key with the data. When you are ready to decrypt data or sign a message, you can use the Decrypt operation to decrypt the encrypted private key. To generate a data key pair, you must specify a symmetric customer master key (CMK) to encrypt the private key in a data key pair. You cannot use an asymmetric CMK or a CMK in a custom key store. To get the type and origin of your CMK, use the DescribeKey operation. If you are using the data key pair to encrypt data, or for any operation where you don&#39;t immediately need a private key, consider using the GenerateDataKeyPairWithoutPlaintext operation. GenerateDataKeyPairWithoutPlaintext returns a plaintext public key and an encrypted private key, but omits the plaintext private key that you need only to decrypt ciphertext or sign a message. Later, when you need to decrypt the data or sign a message, use the Decrypt operation to decrypt the encrypted private key in the data key pair. You can use the optional encryption context to add additional security to the encryption operation. If you specify an EncryptionContext, you must specify the same encryption context (a case-sensitive exact match) when decrypting the encrypted data key. Otherwise, the request to decrypt fails with an InvalidCiphertextException. For more information, see Encryption Context in the AWS Key Management Service Developer Guide. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#generate_data_key_pair_without_plaintext/3","title":"AWS.KMS.generate_data_key_pair_without_plaintext/3","type":"function","doc":"Generates a unique asymmetric data key pair. The GenerateDataKeyPairWithoutPlaintext operation returns a plaintext public key and a copy of the private key that is encrypted under the symmetric CMK you specify. Unlike GenerateDataKeyPair, this operation does not return a plaintext private key. To generate a data key pair, you must specify a symmetric customer master key (CMK) to encrypt the private key in the data key pair. You cannot use an asymmetric CMK or a CMK in a custom key store. To get the type and origin of your CMK, use the KeySpec field in the DescribeKey response. You can use the public key that GenerateDataKeyPairWithoutPlaintext returns to encrypt data or verify a signature outside of AWS KMS. Then, store the encrypted private key with the data. When you are ready to decrypt data or sign a message, you can use the Decrypt operation to decrypt the encrypted private key. GenerateDataKeyPairWithoutPlaintext returns a unique data key pair for each request. The bytes in the key are not related to the caller or CMK that is used to encrypt the private key. You can use the optional encryption context to add additional security to the encryption operation. If you specify an EncryptionContext, you must specify the same encryption context (a case-sensitive exact match) when decrypting the encrypted data key. Otherwise, the request to decrypt fails with an InvalidCiphertextException. For more information, see Encryption Context in the AWS Key Management Service Developer Guide. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#generate_data_key_without_plaintext/3","title":"AWS.KMS.generate_data_key_without_plaintext/3","type":"function","doc":"Generates a unique symmetric data key. This operation returns a data key that is encrypted under a customer master key (CMK) that you specify. To request an asymmetric data key pair, use the GenerateDataKeyPair or GenerateDataKeyPairWithoutPlaintext operations. GenerateDataKeyWithoutPlaintext is identical to the GenerateDataKey operation except that returns only the encrypted copy of the data key. This operation is useful for systems that need to encrypt data at some point, but not immediately. When you need to encrypt the data, you call the Decrypt operation on the encrypted copy of the key. It&#39;s also useful in distributed systems with different levels of trust. For example, you might store encrypted data in containers. One component of your system creates new containers and stores an encrypted data key with each container. Then, a different component puts the data into the containers. That component first decrypts the data key, uses the plaintext data key to encrypt data, puts the encrypted data into the container, and then destroys the plaintext data key. In this system, the component that creates the containers never sees the plaintext data key. GenerateDataKeyWithoutPlaintext returns a unique data key for each request. The bytes in the keys are not related to the caller or CMK that is used to encrypt the private key. To generate a data key, you must specify the symmetric customer master key (CMK) that is used to encrypt the data key. You cannot use an asymmetric CMK to generate a data key. To get the type of your CMK, use the DescribeKey operation. If the operation succeeds, you will find the encrypted copy of the data key in the CiphertextBlob field. You can use the optional encryption context to add additional security to the encryption operation. If you specify an EncryptionContext, you must specify the same encryption context (a case-sensitive exact match) when decrypting the encrypted data key. Otherwise, the request to decrypt fails with an InvalidCiphertextException. For more information, see Encryption Context in the AWS Key Management Service Developer Guide. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#generate_random/3","title":"AWS.KMS.generate_random/3","type":"function","doc":"Returns a random byte string that is cryptographically secure. By default, the random byte string is generated in AWS KMS. To generate the byte string in the AWS CloudHSM cluster that is associated with a custom key store, specify the custom key store ID. For more information about entropy and random number generation, see the AWS Key Management Service Cryptographic Details whitepaper."},{"ref":"AWS.KMS.html#get_key_policy/3","title":"AWS.KMS.get_key_policy/3","type":"function","doc":"Gets a key policy attached to the specified customer master key (CMK). You cannot perform this operation on a CMK in a different AWS account."},{"ref":"AWS.KMS.html#get_key_rotation_status/3","title":"AWS.KMS.get_key_rotation_status/3","type":"function","doc":"Gets a Boolean value that indicates whether automatic rotation of the key material is enabled for the specified customer master key (CMK). You cannot enable automatic rotation of asymmetric CMKs, CMKs with imported key material, or CMKs in a custom key store. The key rotation status for these CMKs is always false. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide. Disabled: The key rotation status does not change when you disable a CMK. However, while the CMK is disabled, AWS KMS does not rotate the backing key. Pending deletion: While a CMK is pending deletion, its key rotation status is false and AWS KMS does not rotate the backing key. If you cancel the deletion, the original key rotation status is restored. To perform this operation on a CMK in a different AWS account, specify the key ARN in the value of the KeyId parameter."},{"ref":"AWS.KMS.html#get_parameters_for_import/3","title":"AWS.KMS.get_parameters_for_import/3","type":"function","doc":"Returns the items you need to import key material into a symmetric, customer managed customer master key (CMK). For more information about importing key material into AWS KMS, see Importing Key Material in the AWS Key Management Service Developer Guide. This operation returns a public key and an import token. Use the public key to encrypt the symmetric key material. Store the import token to send with a subsequent ImportKeyMaterial request. You must specify the key ID of the symmetric CMK into which you will import key material. This CMK&#39;s Origin must be EXTERNAL. You must also specify the wrapping algorithm and type of wrapping key (public key) that you will use to encrypt the key material. You cannot perform this operation on an asymmetric CMK or on any CMK in a different AWS account. To import key material, you must use the public key and import token from the same response. These items are valid for 24 hours. The expiration date and time appear in the GetParametersForImport response. You cannot use an expired token in an ImportKeyMaterial request. If your key and token expire, send another GetParametersForImport request. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#get_public_key/3","title":"AWS.KMS.get_public_key/3","type":"function","doc":"Returns the public key of an asymmetric CMK. Unlike the private key of a asymmetric CMK, which never leaves AWS KMS unencrypted, callers with kms:GetPublicKey permission can download the public key of an asymmetric CMK. You can share the public key to allow others to encrypt messages and verify signatures outside of AWS KMS. For information about symmetric and asymmetric CMKs, see Using Symmetric and Asymmetric CMKs in the AWS Key Management Service Developer Guide. You do not need to download the public key. Instead, you can use the public key within AWS KMS by calling the Encrypt, ReEncrypt, or Verify operations with the identifier of an asymmetric CMK. When you use the public key within AWS KMS, you benefit from the authentication, authorization, and logging that are part of every AWS KMS operation. You also reduce of risk of encrypting data that cannot be decrypted. These features are not effective outside of AWS KMS. For details, see Special Considerations for Downloading Public Keys. To help you use the public key safely outside of AWS KMS, GetPublicKey returns important information about the public key in the response, including: * CustomerMasterKeySpec: The type of key material in the public key, such as RSA_4096 or ECC_NIST_P521. * KeyUsage: Whether the key is used for encryption or signing. * EncryptionAlgorithms or SigningAlgorithms: A list of the encryption algorithms or the signing algorithms for the key. Although AWS KMS cannot enforce these restrictions on external operations, it is crucial that you use this information to prevent the public key from being used improperly. For example, you can prevent a public signing key from being used encrypt data, or prevent a public key from being used with an encryption algorithm that is not supported by AWS KMS. You can also avoid errors, such as using the wrong signing algorithm in a verification operation. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#import_key_material/3","title":"AWS.KMS.import_key_material/3","type":"function","doc":"Imports key material into an existing symmetric AWS KMS customer master key (CMK) that was created without key material. After you successfully import key material into a CMK, you can reimport the same key material into that CMK, but you cannot import different key material. You cannot perform this operation on an asymmetric CMK or on any CMK in a different AWS account. For more information about creating CMKs with no key material and then importing key material, see Importing Key Material in the AWS Key Management Service Developer Guide. Before using this operation, call GetParametersForImport. Its response includes a public key and an import token. Use the public key to encrypt the key material. Then, submit the import token from the same GetParametersForImport response. When calling this operation, you must specify the following values: The key ID or key ARN of a CMK with no key material. Its Origin must be EXTERNAL. To create a CMK with no key material, call CreateKey and set the value of its Origin parameter to EXTERNAL. To get the Origin of a CMK, call DescribeKey.) The encrypted key material. To get the public key to encrypt the key material, call GetParametersForImport. The import token that GetParametersForImport returned. You must use a public key and token from the same GetParametersForImport response. Whether the key material expires and if so, when. If you set an expiration date, AWS KMS deletes the key material from the CMK on the specified date, and the CMK becomes unusable. To use the CMK again, you must reimport the same key material. The only way to change an expiration date is by reimporting the same key material and specifying a new expiration date. When this operation is successful, the key state of the CMK changes from PendingImport to Enabled, and you can use the CMK. If this operation fails, use the exception to help determine the problem. If the error is related to the key material, the import token, or wrapping key, use GetParametersForImport to get a new public key and import token for the CMK and repeat the import procedure. For help, see How To Import Key Material in the AWS Key Management Service Developer Guide. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#list_aliases/3","title":"AWS.KMS.list_aliases/3","type":"function","doc":"Gets a list of aliases in the caller&#39;s AWS account and region. You cannot list aliases in other accounts. For more information about aliases, see CreateAlias. By default, the ListAliases command returns all aliases in the account and region. To get only the aliases that point to a particular customer master key (CMK), use the KeyId parameter. The ListAliases response can include aliases that you created and associated with your customer managed CMKs, and aliases that AWS created and associated with AWS managed CMKs in your account. You can recognize AWS aliases because their names have the format aws/&lt;service-name&gt;, such as aws/dynamodb. The response might also include aliases that have no TargetKeyId field. These are predefined aliases that AWS has created but has not yet associated with a CMK. Aliases that AWS creates in your account, including predefined aliases, do not count against your AWS KMS aliases quota."},{"ref":"AWS.KMS.html#list_grants/3","title":"AWS.KMS.list_grants/3","type":"function","doc":"Gets a list of all grants for the specified customer master key (CMK). To perform this operation on a CMK in a different AWS account, specify the key ARN in the value of the KeyId parameter. The GranteePrincipal field in the ListGrants response usually contains the user or role designated as the grantee principal in the grant. However, when the grantee principal in the grant is an AWS service, the GranteePrincipal field contains the service principal, which might represent several different grantee principals."},{"ref":"AWS.KMS.html#list_key_policies/3","title":"AWS.KMS.list_key_policies/3","type":"function","doc":"Gets the names of the key policies that are attached to a customer master key (CMK). This operation is designed to get policy names that you can use in a GetKeyPolicy operation. However, the only valid policy name is default. You cannot perform this operation on a CMK in a different AWS account."},{"ref":"AWS.KMS.html#list_keys/3","title":"AWS.KMS.list_keys/3","type":"function","doc":"Gets a list of all customer master keys (CMKs) in the caller&#39;s AWS account and Region."},{"ref":"AWS.KMS.html#list_resource_tags/3","title":"AWS.KMS.list_resource_tags/3","type":"function","doc":"Returns a list of all tags for the specified customer master key (CMK). You cannot perform this operation on a CMK in a different AWS account."},{"ref":"AWS.KMS.html#list_retirable_grants/3","title":"AWS.KMS.list_retirable_grants/3","type":"function","doc":"Returns a list of all grants for which the grant&#39;s RetiringPrincipal matches the one specified. A typical use is to list all grants that you are able to retire. To retire a grant, use RetireGrant."},{"ref":"AWS.KMS.html#put_key_policy/3","title":"AWS.KMS.put_key_policy/3","type":"function","doc":"Attaches a key policy to the specified customer master key (CMK). You cannot perform this operation on a CMK in a different AWS account. For more information about key policies, see Key Policies in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#re_encrypt/3","title":"AWS.KMS.re_encrypt/3","type":"function","doc":"Decrypts ciphertext and then reencrypts it entirely within AWS KMS. You can use this operation to change the customer master key (CMK) under which data is encrypted, such as when you manually rotate a CMK or change the CMK that protects a ciphertext. You can also use it to reencrypt ciphertext under the same CMK, such as to change the encryption context of a ciphertext. The ReEncrypt operation can decrypt ciphertext that was encrypted by using an AWS KMS CMK in an AWS KMS operation, such as Encrypt or GenerateDataKey. It can also decrypt ciphertext that was encrypted by using the public key of an asymmetric CMK outside of AWS KMS. However, it cannot decrypt ciphertext produced by other libraries, such as the AWS Encryption SDK or Amazon S3 client-side encryption. These libraries return a ciphertext format that is incompatible with AWS KMS. When you use the ReEncrypt operation, you need to provide information for the decrypt operation and the subsequent encrypt operation. If your ciphertext was encrypted under an asymmetric CMK, you must identify the source CMK, that is, the CMK that encrypted the ciphertext. You must also supply the encryption algorithm that was used. This information is required to decrypt the data. It is optional, but you can specify a source CMK even when the ciphertext was encrypted under a symmetric CMK. This ensures that the ciphertext is decrypted only by using a particular CMK. If the CMK that you specify cannot decrypt the ciphertext, the ReEncrypt operation fails. To reencrypt the data, you must specify the destination CMK, that is, the CMK that re-encrypts the data after it is decrypted. You can select a symmetric or asymmetric CMK. If the destination CMK is an asymmetric CMK, you must also provide the encryption algorithm. The algorithm that you choose must be compatible with the CMK. When you use an asymmetric CMK to encrypt or reencrypt data, be sure to record the CMK and encryption algorithm that you choose. You will be required to provide the same CMK and encryption algorithm when you decrypt the data. If the CMK and algorithm do not match the values used to encrypt the data, the decrypt operation fails. You are not required to supply the CMK ID and encryption algorithm when you decrypt with symmetric CMKs because AWS KMS stores this information in the ciphertext blob. AWS KMS cannot store metadata in ciphertext generated with asymmetric keys. The standard format for asymmetric key ciphertext does not include configurable fields. Unlike other AWS KMS API operations, ReEncrypt callers must have two permissions: kms:ReEncryptFrom permission on the source CMK kms:ReEncryptTo permission on the destination CMK To permit reencryption from or to a CMK, include the &quot;kms:ReEncrypt*&quot; permission in your key policy. This permission is automatically included in the key policy when you use the console to create a CMK. But you must include it manually when you create a CMK programmatically or when you use the PutKeyPolicy operation to set a key policy. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#retire_grant/3","title":"AWS.KMS.retire_grant/3","type":"function","doc":"Retires a grant. To clean up, you can retire a grant when you&#39;re done using it. You should revoke a grant when you intend to actively deny operations that depend on it. The following are permitted to call this API: The AWS account (root user) under which the grant was created The RetiringPrincipal, if present in the grant The GranteePrincipal, if RetireGrant is an operation specified in the grant You must identify the grant to retire by its grant token or by a combination of the grant ID and the Amazon Resource Name (ARN) of the customer master key (CMK). A grant token is a unique variable-length base64-encoded string. A grant ID is a 64 character unique identifier of a grant. The CreateGrant operation returns both."},{"ref":"AWS.KMS.html#revoke_grant/3","title":"AWS.KMS.revoke_grant/3","type":"function","doc":"Revokes the specified grant for the specified customer master key (CMK). You can revoke a grant to actively deny operations that depend on it. To perform this operation on a CMK in a different AWS account, specify the key ARN in the value of the KeyId parameter."},{"ref":"AWS.KMS.html#schedule_key_deletion/3","title":"AWS.KMS.schedule_key_deletion/3","type":"function","doc":"Schedules the deletion of a customer master key (CMK). You may provide a waiting period, specified in days, before deletion occurs. If you do not provide a waiting period, the default period of 30 days is used. When this operation is successful, the key state of the CMK changes to PendingDeletion. Before the waiting period ends, you can use CancelKeyDeletion to cancel the deletion of the CMK. After the waiting period ends, AWS KMS deletes the CMK and all AWS KMS data associated with it, including all aliases that refer to it. Deleting a CMK is a destructive and potentially dangerous operation. When a CMK is deleted, all data that was encrypted under the CMK is unrecoverable. To prevent the use of a CMK without deleting it, use DisableKey. If you schedule deletion of a CMK from a custom key store, when the waiting period expires, ScheduleKeyDeletion deletes the CMK from AWS KMS. Then AWS KMS makes a best effort to delete the key material from the associated AWS CloudHSM cluster. However, you might need to manually delete the orphaned key material from the cluster and its backups. You cannot perform this operation on a CMK in a different AWS account. For more information about scheduling a CMK for deletion, see Deleting Customer Master Keys in the AWS Key Management Service Developer Guide. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#sign/3","title":"AWS.KMS.sign/3","type":"function","doc":"Creates a digital signature for a message or message digest by using the private key in an asymmetric CMK. To verify the signature, use the Verify operation, or use the public key in the same asymmetric CMK outside of AWS KMS. For information about symmetric and asymmetric CMKs, see Using Symmetric and Asymmetric CMKs in the AWS Key Management Service Developer Guide. Digital signatures are generated and verified by using asymmetric key pair, such as an RSA or ECC pair that is represented by an asymmetric customer master key (CMK). The key owner (or an authorized user) uses their private key to sign a message. Anyone with the public key can verify that the message was signed with that particular private key and that the message hasn&#39;t changed since it was signed. To use the Sign operation, provide the following information: Use the KeyId parameter to identify an asymmetric CMK with a KeyUsage value of SIGN_VERIFY. To get the KeyUsage value of a CMK, use the DescribeKey operation. The caller must have kms:Sign permission on the CMK. Use the Message parameter to specify the message or message digest to sign. You can submit messages of up to 4096 bytes. To sign a larger message, generate a hash digest of the message, and then provide the hash digest in the Message parameter. To indicate whether the message is a full message or a digest, use the MessageType parameter. Choose a signing algorithm that is compatible with the CMK. When signing a message, be sure to record the CMK and the signing algorithm. This information is required to verify the signature. To verify the signature that this operation generates, use the Verify operation. Or use the GetPublicKey operation to download the public key and then use the public key to verify the signature outside of AWS KMS. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#tag_resource/3","title":"AWS.KMS.tag_resource/3","type":"function","doc":"Adds or edits tags for a customer master key (CMK). You cannot perform this operation on a CMK in a different AWS account. Each tag consists of a tag key and a tag value. Tag keys and tag values are both required, but tag values can be empty (null) strings. You can only use a tag key once for each CMK. If you use the tag key again, AWS KMS replaces the current tag value with the specified value. For information about the rules that apply to tag keys and tag values, see User-Defined Tag Restrictions in the AWS Billing and Cost Management User Guide. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#untag_resource/3","title":"AWS.KMS.untag_resource/3","type":"function","doc":"Removes the specified tags from the specified customer master key (CMK). You cannot perform this operation on a CMK in a different AWS account. To remove a tag, specify the tag key. To change the tag value of an existing tag key, use TagResource. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#update_alias/3","title":"AWS.KMS.update_alias/3","type":"function","doc":"Associates an existing AWS KMS alias with a different customer master key (CMK). Each alias is associated with only one CMK at a time, although a CMK can have multiple aliases. The alias and the CMK must be in the same AWS account and region. You cannot perform this operation on an alias in a different AWS account. The current and new CMK must be the same type (both symmetric or both asymmetric), and they must have the same key usage (ENCRYPT_DECRYPT or SIGN_VERIFY). This restriction prevents errors in code that uses aliases. If you must assign an alias to a different type of CMK, use DeleteAlias to delete the old alias and CreateAlias to create a new alias. You cannot use UpdateAlias to change an alias name. To change an alias name, use DeleteAlias to delete the old alias and CreateAlias to create a new alias. Because an alias is not a property of a CMK, you can create, update, and delete the aliases of a CMK without affecting the CMK. Also, aliases do not appear in the response from the DescribeKey operation. To get the aliases of all CMKs in the account, use the ListAliases operation. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#update_custom_key_store/3","title":"AWS.KMS.update_custom_key_store/3","type":"function","doc":"Changes the properties of a custom key store. Use the CustomKeyStoreId parameter to identify the custom key store you want to edit. Use the remaining parameters to change the properties of the custom key store. You can only update a custom key store that is disconnected. To disconnect the custom key store, use DisconnectCustomKeyStore. To reconnect the custom key store after the update completes, use ConnectCustomKeyStore. To find the connection state of a custom key store, use the DescribeCustomKeyStores operation. Use the parameters of UpdateCustomKeyStore to edit your keystore settings. Use the NewCustomKeyStoreName parameter to change the friendly name of the custom key store to the value that you specify. Use the KeyStorePassword parameter tell AWS KMS the current password of the kmsuser crypto user (CU) in the associated AWS CloudHSM cluster. You can use this parameter to fix connection failures that occur when AWS KMS cannot log into the associated cluster because the kmsuser password has changed. This value does not change the password in the AWS CloudHSM cluster. Use the CloudHsmClusterId parameter to associate the custom key store with a different, but related, AWS CloudHSM cluster. You can use this parameter to repair a custom key store if its AWS CloudHSM cluster becomes corrupted or is deleted, or when you need to create or restore a cluster from a backup. If the operation succeeds, it returns a JSON object with no properties. This operation is part of the Custom Key Store feature feature in AWS KMS, which combines the convenience and extensive integration of AWS KMS with the isolation and control of a single-tenant key store."},{"ref":"AWS.KMS.html#update_key_description/3","title":"AWS.KMS.update_key_description/3","type":"function","doc":"Updates the description of a customer master key (CMK). To see the description of a CMK, use DescribeKey. You cannot perform this operation on a CMK in a different AWS account. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.KMS.html#verify/3","title":"AWS.KMS.verify/3","type":"function","doc":"Verifies a digital signature that was generated by the Sign operation. Verification confirms that an authorized user signed the message with the specified CMK and signing algorithm, and the message hasn&#39;t changed since it was signed. If the signature is verified, the value of the SignatureValid field in the response is True. If the signature verification fails, the Verify operation fails with an KMSInvalidSignatureException exception. A digital signature is generated by using the private key in an asymmetric CMK. The signature is verified by using the public key in the same asymmetric CMK. For information about symmetric and asymmetric CMKs, see Using Symmetric and Asymmetric CMKs in the AWS Key Management Service Developer Guide. To verify a digital signature, you can use the Verify operation. Specify the same asymmetric CMK, message, and signing algorithm that were used to produce the signature. You can also verify the digital signature by using the public key of the CMK outside of AWS KMS. Use the GetPublicKey operation to download the public key in the asymmetric CMK and then use the public key to verify the signature outside of AWS KMS. The advantage of using the Verify operation is that it is performed within AWS KMS. As a result, it&#39;s easy to call, the operation is performed within the FIPS boundary, it is logged in AWS CloudTrail, and you can use key policy and IAM policy to determine who is authorized to use the CMK to verify signatures. The CMK that you use for this operation must be in a compatible key state. For details, see How Key State Affects Use of a Customer Master Key in the AWS Key Management Service Developer Guide."},{"ref":"AWS.Kafka.html","title":"AWS.Kafka","type":"module","doc":"The operations for managing an Amazon MSK cluster."},{"ref":"AWS.Kafka.html#batch_associate_scram_secret/4","title":"AWS.Kafka.batch_associate_scram_secret/4","type":"function","doc":"Associates one or more Scram Secrets with an Amazon MSK cluster."},{"ref":"AWS.Kafka.html#batch_disassociate_scram_secret/4","title":"AWS.Kafka.batch_disassociate_scram_secret/4","type":"function","doc":"Disassociates one or more Scram Secrets from an Amazon MSK cluster."},{"ref":"AWS.Kafka.html#create_cluster/3","title":"AWS.Kafka.create_cluster/3","type":"function","doc":"Creates a new MSK cluster."},{"ref":"AWS.Kafka.html#create_configuration/3","title":"AWS.Kafka.create_configuration/3","type":"function","doc":"Creates a new MSK configuration."},{"ref":"AWS.Kafka.html#delete_cluster/4","title":"AWS.Kafka.delete_cluster/4","type":"function","doc":"Deletes the MSK cluster specified by the Amazon Resource Name (ARN) in the request."},{"ref":"AWS.Kafka.html#delete_configuration/4","title":"AWS.Kafka.delete_configuration/4","type":"function","doc":"Deletes the specified MSK configuration. The configuration must be in the ACTIVE or DELETE_FAILED state."},{"ref":"AWS.Kafka.html#describe_cluster/3","title":"AWS.Kafka.describe_cluster/3","type":"function","doc":"Returns a description of the MSK cluster whose Amazon Resource Name (ARN) is specified in the request."},{"ref":"AWS.Kafka.html#describe_cluster_operation/3","title":"AWS.Kafka.describe_cluster_operation/3","type":"function","doc":"Returns a description of the cluster operation specified by the ARN."},{"ref":"AWS.Kafka.html#describe_configuration/3","title":"AWS.Kafka.describe_configuration/3","type":"function","doc":"Returns a description of this MSK configuration."},{"ref":"AWS.Kafka.html#describe_configuration_revision/4","title":"AWS.Kafka.describe_configuration_revision/4","type":"function","doc":"Returns a description of this revision of the configuration."},{"ref":"AWS.Kafka.html#get_bootstrap_brokers/3","title":"AWS.Kafka.get_bootstrap_brokers/3","type":"function","doc":"A list of brokers that a client application can use to bootstrap."},{"ref":"AWS.Kafka.html#get_compatible_kafka_versions/3","title":"AWS.Kafka.get_compatible_kafka_versions/3","type":"function","doc":"Gets the Apache Kafka versions to which you can update the MSK cluster."},{"ref":"AWS.Kafka.html#list_cluster_operations/5","title":"AWS.Kafka.list_cluster_operations/5","type":"function","doc":"Returns a list of all the operations that have been performed on the specified MSK cluster."},{"ref":"AWS.Kafka.html#list_clusters/5","title":"AWS.Kafka.list_clusters/5","type":"function","doc":"Returns a list of all the MSK clusters in the current Region."},{"ref":"AWS.Kafka.html#list_configuration_revisions/5","title":"AWS.Kafka.list_configuration_revisions/5","type":"function","doc":"Returns a list of all the revisions of an MSK configuration."},{"ref":"AWS.Kafka.html#list_configurations/4","title":"AWS.Kafka.list_configurations/4","type":"function","doc":"Returns a list of all the MSK configurations in this Region."},{"ref":"AWS.Kafka.html#list_kafka_versions/4","title":"AWS.Kafka.list_kafka_versions/4","type":"function","doc":"Returns a list of Kafka versions."},{"ref":"AWS.Kafka.html#list_nodes/5","title":"AWS.Kafka.list_nodes/5","type":"function","doc":"Returns a list of the broker nodes in the cluster."},{"ref":"AWS.Kafka.html#list_scram_secrets/5","title":"AWS.Kafka.list_scram_secrets/5","type":"function","doc":"Returns a list of the Scram Secrets associated with an Amazon MSK cluster."},{"ref":"AWS.Kafka.html#list_tags_for_resource/3","title":"AWS.Kafka.list_tags_for_resource/3","type":"function","doc":"Returns a list of the tags associated with the specified resource."},{"ref":"AWS.Kafka.html#reboot_broker/4","title":"AWS.Kafka.reboot_broker/4","type":"function","doc":"Executes a reboot on a broker."},{"ref":"AWS.Kafka.html#tag_resource/4","title":"AWS.Kafka.tag_resource/4","type":"function","doc":"Adds tags to the specified MSK resource."},{"ref":"AWS.Kafka.html#untag_resource/4","title":"AWS.Kafka.untag_resource/4","type":"function","doc":"Removes the tags associated with the keys that are provided in the query."},{"ref":"AWS.Kafka.html#update_broker_count/4","title":"AWS.Kafka.update_broker_count/4","type":"function","doc":"Updates the number of broker nodes in the cluster. You can use this operation to increase the number of brokers in an existing cluster. You can&#39;t decrease the number of brokers."},{"ref":"AWS.Kafka.html#update_broker_storage/4","title":"AWS.Kafka.update_broker_storage/4","type":"function","doc":"Updates the EBS storage associated with MSK brokers."},{"ref":"AWS.Kafka.html#update_cluster_configuration/4","title":"AWS.Kafka.update_cluster_configuration/4","type":"function","doc":"Updates the cluster with the configuration that is specified in the request body."},{"ref":"AWS.Kafka.html#update_cluster_kafka_version/4","title":"AWS.Kafka.update_cluster_kafka_version/4","type":"function","doc":"Updates the Apache Kafka version for the cluster."},{"ref":"AWS.Kafka.html#update_configuration/4","title":"AWS.Kafka.update_configuration/4","type":"function","doc":"Updates an existing MSK configuration. The configuration must be in the Active state."},{"ref":"AWS.Kafka.html#update_monitoring/4","title":"AWS.Kafka.update_monitoring/4","type":"function","doc":"Updates the monitoring settings for the cluster. You can use this operation to specify which Apache Kafka metrics you want Amazon MSK to send to Amazon CloudWatch. You can also specify settings for open monitoring with Prometheus."},{"ref":"AWS.Kendra.html","title":"AWS.Kendra","type":"module","doc":"Amazon Kendra is a service for indexing large document sets."},{"ref":"AWS.Kendra.html#batch_delete_document/3","title":"AWS.Kendra.batch_delete_document/3","type":"function","doc":"Removes one or more documents from an index. The documents must have been added with the BatchPutDocument operation. The documents are deleted asynchronously. You can see the progress of the deletion by using AWS CloudWatch. Any error messages releated to the processing of the batch are sent to you CloudWatch log."},{"ref":"AWS.Kendra.html#batch_put_document/3","title":"AWS.Kendra.batch_put_document/3","type":"function","doc":"Adds one or more documents to an index. The BatchPutDocument operation enables you to ingest inline documents or a set of documents stored in an Amazon S3 bucket. Use this operation to ingest your text and unstructured text into an index, add custom attributes to the documents, and to attach an access control list to the documents added to the index. The documents are indexed asynchronously. You can see the progress of the batch using AWS CloudWatch. Any error messages related to processing the batch are sent to your AWS CloudWatch log."},{"ref":"AWS.Kendra.html#create_data_source/3","title":"AWS.Kendra.create_data_source/3","type":"function","doc":"Creates a data source that you use to with an Amazon Kendra index. You specify a name, data source connector type and description for your data source. You also specify configuration information such as document metadata (author, source URI, and so on) and user context information. CreateDataSource is a synchronous operation. The operation returns 200 if the data source was successfully created. Otherwise, an exception is raised."},{"ref":"AWS.Kendra.html#create_faq/3","title":"AWS.Kendra.create_faq/3","type":"function","doc":"Creates an new set of frequently asked question (FAQ) questions and answers."},{"ref":"AWS.Kendra.html#create_index/3","title":"AWS.Kendra.create_index/3","type":"function","doc":"Creates a new Amazon Kendra index. Index creation is an asynchronous operation. To determine if index creation has completed, check the Status field returned from a call to . The Status field is set to ACTIVE when the index is ready to use. Once the index is active you can index your documents using the operation or using one of the supported data sources."},{"ref":"AWS.Kendra.html#delete_data_source/3","title":"AWS.Kendra.delete_data_source/3","type":"function","doc":"Deletes an Amazon Kendra data source. An exception is not thrown if the data source is already being deleted. While the data source is being deleted, the Status field returned by a call to the operation is set to DELETING. For more information, see Deleting Data Sources."},{"ref":"AWS.Kendra.html#delete_faq/3","title":"AWS.Kendra.delete_faq/3","type":"function","doc":"Removes an FAQ from an index."},{"ref":"AWS.Kendra.html#delete_index/3","title":"AWS.Kendra.delete_index/3","type":"function","doc":"Deletes an existing Amazon Kendra index. An exception is not thrown if the index is already being deleted. While the index is being deleted, the Status field returned by a call to the DescribeIndex operation is set to DELETING."},{"ref":"AWS.Kendra.html#describe_data_source/3","title":"AWS.Kendra.describe_data_source/3","type":"function","doc":"Gets information about a Amazon Kendra data source."},{"ref":"AWS.Kendra.html#describe_faq/3","title":"AWS.Kendra.describe_faq/3","type":"function","doc":"Gets information about an FAQ list."},{"ref":"AWS.Kendra.html#describe_index/3","title":"AWS.Kendra.describe_index/3","type":"function","doc":"Describes an existing Amazon Kendra index"},{"ref":"AWS.Kendra.html#list_data_source_sync_jobs/3","title":"AWS.Kendra.list_data_source_sync_jobs/3","type":"function","doc":"Gets statistics about synchronizing Amazon Kendra with a data source."},{"ref":"AWS.Kendra.html#list_data_sources/3","title":"AWS.Kendra.list_data_sources/3","type":"function","doc":"Lists the data sources that you have created."},{"ref":"AWS.Kendra.html#list_faqs/3","title":"AWS.Kendra.list_faqs/3","type":"function","doc":"Gets a list of FAQ lists associated with an index."},{"ref":"AWS.Kendra.html#list_indices/3","title":"AWS.Kendra.list_indices/3","type":"function","doc":"Lists the Amazon Kendra indexes that you have created."},{"ref":"AWS.Kendra.html#list_tags_for_resource/3","title":"AWS.Kendra.list_tags_for_resource/3","type":"function","doc":"Gets a list of tags associated with a specified resource. Indexes, FAQs, and data sources can have tags associated with them."},{"ref":"AWS.Kendra.html#query/3","title":"AWS.Kendra.query/3","type":"function","doc":"Searches an active index. Use this API to search your documents using query. The Query operation enables to do faceted search and to filter results based on document attributes. It also enables you to provide user context that Amazon Kendra uses to enforce document access control in the search results. Amazon Kendra searches your index for text content and question and answer (FAQ) content. By default the response contains three types of results. Relevant passages Matching FAQs Relevant documents You can specify that the query return only one type of result using the QueryResultTypeConfig parameter. Each query returns the 100 most relevant results."},{"ref":"AWS.Kendra.html#start_data_source_sync_job/3","title":"AWS.Kendra.start_data_source_sync_job/3","type":"function","doc":"Starts a synchronization job for a data source. If a synchronization job is already in progress, Amazon Kendra returns a ResourceInUseException exception."},{"ref":"AWS.Kendra.html#stop_data_source_sync_job/3","title":"AWS.Kendra.stop_data_source_sync_job/3","type":"function","doc":"Stops a running synchronization job. You can&#39;t stop a scheduled synchronization job."},{"ref":"AWS.Kendra.html#submit_feedback/3","title":"AWS.Kendra.submit_feedback/3","type":"function","doc":"Enables you to provide feedback to Amazon Kendra to improve the performance of the service."},{"ref":"AWS.Kendra.html#tag_resource/3","title":"AWS.Kendra.tag_resource/3","type":"function","doc":"Adds the specified tag to the specified index, FAQ, or data source resource. If the tag already exists, the existing value is replaced with the new value."},{"ref":"AWS.Kendra.html#untag_resource/3","title":"AWS.Kendra.untag_resource/3","type":"function","doc":"Removes a tag from an index, FAQ, or a data source."},{"ref":"AWS.Kendra.html#update_data_source/3","title":"AWS.Kendra.update_data_source/3","type":"function","doc":"Updates an existing Amazon Kendra data source."},{"ref":"AWS.Kendra.html#update_index/3","title":"AWS.Kendra.update_index/3","type":"function","doc":"Updates an existing Amazon Kendra index."},{"ref":"AWS.Kinesis.html","title":"AWS.Kinesis","type":"module","doc":"Amazon Kinesis Data Streams Service API Reference Amazon Kinesis Data Streams is a managed service that scales elastically for real-time processing of streaming big data."},{"ref":"AWS.Kinesis.html#add_tags_to_stream/3","title":"AWS.Kinesis.add_tags_to_stream/3","type":"function","doc":"Adds or updates tags for the specified Kinesis data stream. Each time you invoke this operation, you can specify up to 10 tags. If you want to add more than 10 tags to your stream, you can invoke this operation multiple times. In total, each stream can have up to 50 tags. If tags have already been assigned to the stream, AddTagsToStream overwrites any existing tags that correspond to the specified tag keys. AddTagsToStream has a limit of five transactions per second per account."},{"ref":"AWS.Kinesis.html#create_stream/3","title":"AWS.Kinesis.create_stream/3","type":"function","doc":"Creates a Kinesis data stream. A stream captures and transports data records that are continuously emitted from different data sources or producers. Scale-out within a stream is explicitly supported by means of shards, which are uniquely identified groups of data records in a stream. You specify and control the number of shards that a stream is composed of. Each shard can support reads up to five transactions per second, up to a maximum data read total of 2 MiB per second. Each shard can support writes up to 1,000 records per second, up to a maximum data write total of 1 MiB per second. If the amount of data input increases or decreases, you can add or remove shards. The stream name identifies the stream. The name is scoped to the AWS account used by the application. It is also scoped by AWS Region. That is, two streams in two different accounts can have the same name, and two streams in the same account, but in two different Regions, can have the same name. CreateStream is an asynchronous operation. Upon receiving a CreateStream request, Kinesis Data Streams immediately returns and sets the stream status to CREATING. After the stream is created, Kinesis Data Streams sets the stream status to ACTIVE. You should perform read and write operations only on an ACTIVE stream. You receive a LimitExceededException when making a CreateStream request when you try to do one of the following: Have more than five streams in the CREATING state at any point in time. Create more shards than are authorized for your account. For the default shard limit for an AWS account, see Amazon Kinesis Data Streams Limits in the Amazon Kinesis Data Streams Developer Guide. To increase this limit, contact AWS Support. You can use DescribeStream to check the stream status, which is returned in StreamStatus. CreateStream has a limit of five transactions per second per account."},{"ref":"AWS.Kinesis.html#decrease_stream_retention_period/3","title":"AWS.Kinesis.decrease_stream_retention_period/3","type":"function","doc":"Decreases the Kinesis data stream&#39;s retention period, which is the length of time data records are accessible after they are added to the stream. The minimum value of a stream&#39;s retention period is 24 hours. This operation may result in lost data. For example, if the stream&#39;s retention period is 48 hours and is decreased to 24 hours, any data already in the stream that is older than 24 hours is inaccessible."},{"ref":"AWS.Kinesis.html#delete_stream/3","title":"AWS.Kinesis.delete_stream/3","type":"function","doc":"Deletes a Kinesis data stream and all its shards and data. You must shut down any applications that are operating on the stream before you delete the stream. If an application attempts to operate on a deleted stream, it receives the exception ResourceNotFoundException. If the stream is in the ACTIVE state, you can delete it. After a DeleteStream request, the specified stream is in the DELETING state until Kinesis Data Streams completes the deletion. Note: Kinesis Data Streams might continue to accept data read and write operations, such as PutRecord, PutRecords, and GetRecords, on a stream in the DELETING state until the stream deletion is complete. When you delete a stream, any shards in that stream are also deleted, and any tags are dissociated from the stream. You can use the DescribeStream operation to check the state of the stream, which is returned in StreamStatus. DeleteStream has a limit of five transactions per second per account."},{"ref":"AWS.Kinesis.html#deregister_stream_consumer/3","title":"AWS.Kinesis.deregister_stream_consumer/3","type":"function","doc":"To deregister a consumer, provide its ARN. Alternatively, you can provide the ARN of the data stream and the name you gave the consumer when you registered it. You may also provide all three parameters, as long as they don&#39;t conflict with each other. If you don&#39;t know the name or ARN of the consumer that you want to deregister, you can use the ListStreamConsumers operation to get a list of the descriptions of all the consumers that are currently registered with a given data stream. The description of a consumer contains its name and ARN. This operation has a limit of five transactions per second per stream."},{"ref":"AWS.Kinesis.html#describe_limits/3","title":"AWS.Kinesis.describe_limits/3","type":"function","doc":"Describes the shard limits and usage for the account. If you update your account limits, the old limits might be returned for a few minutes. This operation has a limit of one transaction per second per account."},{"ref":"AWS.Kinesis.html#describe_stream/3","title":"AWS.Kinesis.describe_stream/3","type":"function","doc":"Describes the specified Kinesis data stream. The information returned includes the stream name, Amazon Resource Name (ARN), creation time, enhanced metric configuration, and shard map. The shard map is an array of shard objects. For each shard object, there is the hash key and sequence number ranges that the shard spans, and the IDs of any earlier shards that played in a role in creating the shard. Every record ingested in the stream is identified by a sequence number, which is assigned when the record is put into the stream. You can limit the number of shards returned by each call. For more information, see Retrieving Shards from a Stream in the Amazon Kinesis Data Streams Developer Guide. There are no guarantees about the chronological order shards returned. To process shards in chronological order, use the ID of the parent shard to track the lineage to the oldest shard. This operation has a limit of 10 transactions per second per account."},{"ref":"AWS.Kinesis.html#describe_stream_consumer/3","title":"AWS.Kinesis.describe_stream_consumer/3","type":"function","doc":"To get the description of a registered consumer, provide the ARN of the consumer. Alternatively, you can provide the ARN of the data stream and the name you gave the consumer when you registered it. You may also provide all three parameters, as long as they don&#39;t conflict with each other. If you don&#39;t know the name or ARN of the consumer that you want to describe, you can use the ListStreamConsumers operation to get a list of the descriptions of all the consumers that are currently registered with a given data stream. This operation has a limit of 20 transactions per second per stream."},{"ref":"AWS.Kinesis.html#describe_stream_summary/3","title":"AWS.Kinesis.describe_stream_summary/3","type":"function","doc":"Provides a summarized description of the specified Kinesis data stream without the shard list. The information returned includes the stream name, Amazon Resource Name (ARN), status, record retention period, approximate creation time, monitoring, encryption details, and open shard count. DescribeStreamSummary has a limit of 20 transactions per second per account."},{"ref":"AWS.Kinesis.html#disable_enhanced_monitoring/3","title":"AWS.Kinesis.disable_enhanced_monitoring/3","type":"function","doc":"Disables enhanced monitoring."},{"ref":"AWS.Kinesis.html#enable_enhanced_monitoring/3","title":"AWS.Kinesis.enable_enhanced_monitoring/3","type":"function","doc":"Enables enhanced Kinesis data stream monitoring for shard-level metrics."},{"ref":"AWS.Kinesis.html#get_records/3","title":"AWS.Kinesis.get_records/3","type":"function","doc":"Gets data records from a Kinesis data stream&#39;s shard. Specify a shard iterator using the ShardIterator parameter. The shard iterator specifies the position in the shard from which you want to start reading data records sequentially. If there are no records available in the portion of the shard that the iterator points to, GetRecords returns an empty list. It might take multiple calls to get to a portion of the shard that contains records. You can scale by provisioning multiple shards per stream while considering service limits (for more information, see Amazon Kinesis Data Streams Limits in the Amazon Kinesis Data Streams Developer Guide). Your application should have one thread per shard, each reading continuously from its stream. To read from a stream continually, call GetRecords in a loop. Use GetShardIterator to get the shard iterator to specify in the first GetRecords call. GetRecords returns a new shard iterator in NextShardIterator. Specify the shard iterator returned in NextShardIterator in subsequent calls to GetRecords. If the shard has been closed, the shard iterator can&#39;t return more data and GetRecords returns null in NextShardIterator. You can terminate the loop when the shard is closed, or when the shard iterator reaches the record with the sequence number or other attribute that marks it as the last record to process. Each data record can be up to 1 MiB in size, and each shard can read up to 2 MiB per second. You can ensure that your calls don&#39;t exceed the maximum supported size or throughput by using the Limit parameter to specify the maximum number of records that GetRecords can return. Consider your average record size when determining this limit. The maximum number of records that can be returned per call is 10,000. The size of the data returned by GetRecords varies depending on the utilization of the shard. The maximum size of data that GetRecords can return is 10 MiB. If a call returns this amount of data, subsequent calls made within the next 5 seconds throw ProvisionedThroughputExceededException. If there is insufficient provisioned throughput on the stream, subsequent calls made within the next 1 second throw ProvisionedThroughputExceededException. GetRecords doesn&#39;t return any data when it throws an exception. For this reason, we recommend that you wait 1 second between calls to GetRecords. However, it&#39;s possible that the application will get exceptions for longer than 1 second. To detect whether the application is falling behind in processing, you can use the MillisBehindLatest response attribute. You can also monitor the stream using CloudWatch metrics and other mechanisms (see Monitoring in the Amazon Kinesis Data Streams Developer Guide). Each Amazon Kinesis record includes a value, ApproximateArrivalTimestamp, that is set when a stream successfully receives and stores a record. This is commonly referred to as a server-side time stamp, whereas a client-side time stamp is set when a data producer creates or sends the record to a stream (a data producer is any data source putting data records into a stream, for example with PutRecords). The time stamp has millisecond precision. There are no guarantees about the time stamp accuracy, or that the time stamp is always increasing. For example, records in a shard or across a stream might have time stamps that are out of order. This operation has a limit of five transactions per second per shard."},{"ref":"AWS.Kinesis.html#get_shard_iterator/3","title":"AWS.Kinesis.get_shard_iterator/3","type":"function","doc":"Gets an Amazon Kinesis shard iterator. A shard iterator expires 5 minutes after it is returned to the requester. A shard iterator specifies the shard position from which to start reading data records sequentially. The position is specified using the sequence number of a data record in a shard. A sequence number is the identifier associated with every record ingested in the stream, and is assigned when a record is put into the stream. Each stream has one or more shards. You must specify the shard iterator type. For example, you can set the ShardIteratorType parameter to read exactly from the position denoted by a specific sequence number by using the AT_SEQUENCE_NUMBER shard iterator type. Alternatively, the parameter can read right after the sequence number by using the AFTER_SEQUENCE_NUMBER shard iterator type, using sequence numbers returned by earlier calls to PutRecord, PutRecords, GetRecords, or DescribeStream. In the request, you can specify the shard iterator type AT_TIMESTAMP to read records from an arbitrary point in time, TRIM_HORIZON to cause ShardIterator to point to the last untrimmed record in the shard in the system (the oldest data record in the shard), or LATEST so that you always read the most recent data in the shard. When you read repeatedly from a stream, use a GetShardIterator request to get the first shard iterator for use in your first GetRecords request and for subsequent reads use the shard iterator returned by the GetRecords request in NextShardIterator. A new shard iterator is returned by every GetRecords request in NextShardIterator, which you use in the ShardIterator parameter of the next GetRecords request. If a GetShardIterator request is made too often, you receive a ProvisionedThroughputExceededException. For more information about throughput limits, see GetRecords, and Streams Limits in the Amazon Kinesis Data Streams Developer Guide. If the shard is closed, GetShardIterator returns a valid iterator for the last sequence number of the shard. A shard can be closed as a result of using SplitShard or MergeShards. GetShardIterator has a limit of five transactions per second per account per open shard."},{"ref":"AWS.Kinesis.html#increase_stream_retention_period/3","title":"AWS.Kinesis.increase_stream_retention_period/3","type":"function","doc":"Increases the Kinesis data stream&#39;s retention period, which is the length of time data records are accessible after they are added to the stream. The maximum value of a stream&#39;s retention period is 168 hours (7 days). If you choose a longer stream retention period, this operation increases the time period during which records that have not yet expired are accessible. However, it does not make previous, expired data (older than the stream&#39;s previous retention period) accessible after the operation has been called. For example, if a stream&#39;s retention period is set to 24 hours and is increased to 168 hours, any data that is older than 24 hours remains inaccessible to consumer applications."},{"ref":"AWS.Kinesis.html#list_shards/3","title":"AWS.Kinesis.list_shards/3","type":"function","doc":"Lists the shards in a stream and provides information about each shard. This operation has a limit of 100 transactions per second per data stream. This API is a new operation that is used by the Amazon Kinesis Client Library (KCL). If you have a fine-grained IAM policy that only allows specific operations, you must update your policy to allow calls to this API. For more information, see Controlling Access to Amazon Kinesis Data Streams Resources Using IAM."},{"ref":"AWS.Kinesis.html#list_stream_consumers/3","title":"AWS.Kinesis.list_stream_consumers/3","type":"function","doc":"Lists the consumers registered to receive data from a stream using enhanced fan-out, and provides information about each consumer. This operation has a limit of 5 transactions per second per stream."},{"ref":"AWS.Kinesis.html#list_streams/3","title":"AWS.Kinesis.list_streams/3","type":"function","doc":"Lists your Kinesis data streams. The number of streams may be too large to return from a single call to ListStreams. You can limit the number of returned streams using the Limit parameter. If you do not specify a value for the Limit parameter, Kinesis Data Streams uses the default limit, which is currently 10. You can detect if there are more streams available to list by using the HasMoreStreams flag from the returned output. If there are more streams available, you can request more streams by using the name of the last stream returned by the ListStreams request in the ExclusiveStartStreamName parameter in a subsequent request to ListStreams. The group of stream names returned by the subsequent request is then added to the list. You can continue this process until all the stream names have been collected in the list. ListStreams has a limit of five transactions per second per account."},{"ref":"AWS.Kinesis.html#list_tags_for_stream/3","title":"AWS.Kinesis.list_tags_for_stream/3","type":"function","doc":"Lists the tags for the specified Kinesis data stream. This operation has a limit of five transactions per second per account."},{"ref":"AWS.Kinesis.html#merge_shards/3","title":"AWS.Kinesis.merge_shards/3","type":"function","doc":"Merges two adjacent shards in a Kinesis data stream and combines them into a single shard to reduce the stream&#39;s capacity to ingest and transport data. Two shards are considered adjacent if the union of the hash key ranges for the two shards form a contiguous set with no gaps. For example, if you have two shards, one with a hash key range of 276...381 and the other with a hash key range of 382...454, then you could merge these two shards into a single shard that would have a hash key range of 276...454. After the merge, the single child shard receives data for all hash key values covered by the two parent shards. MergeShards is called when there is a need to reduce the overall capacity of a stream because of excess capacity that is not being used. You must specify the shard to be merged and the adjacent shard for a stream. For more information about merging shards, see Merge Two Shards in the Amazon Kinesis Data Streams Developer Guide. If the stream is in the ACTIVE state, you can call MergeShards. If a stream is in the CREATING, UPDATING, or DELETING state, MergeShards returns a ResourceInUseException. If the specified stream does not exist, MergeShards returns a ResourceNotFoundException. You can use DescribeStream to check the state of the stream, which is returned in StreamStatus. MergeShards is an asynchronous operation. Upon receiving a MergeShards request, Amazon Kinesis Data Streams immediately returns a response and sets the StreamStatus to UPDATING. After the operation is completed, Kinesis Data Streams sets the StreamStatus to ACTIVE. Read and write operations continue to work while the stream is in the UPDATING state. You use DescribeStream to determine the shard IDs that are specified in the MergeShards request. If you try to operate on too many streams in parallel using CreateStream, DeleteStream, MergeShards, or SplitShard, you receive a LimitExceededException. MergeShards has a limit of five transactions per second per account."},{"ref":"AWS.Kinesis.html#put_record/3","title":"AWS.Kinesis.put_record/3","type":"function","doc":"Writes a single data record into an Amazon Kinesis data stream. Call PutRecord to send data into the stream for real-time ingestion and subsequent processing, one record at a time. Each shard can support writes up to 1,000 records per second, up to a maximum data write total of 1 MiB per second. You must specify the name of the stream that captures, stores, and transports the data; a partition key; and the data blob itself. The data blob can be any type of data; for example, a segment from a log file, geographic/location data, website clickstream data, and so on. The partition key is used by Kinesis Data Streams to distribute data across shards. Kinesis Data Streams segregates the data records that belong to a stream into multiple shards, using the partition key associated with each data record to determine the shard to which a given data record belongs. Partition keys are Unicode strings, with a maximum length limit of 256 characters for each key. An MD5 hash function is used to map partition keys to 128-bit integer values and to map associated data records to shards using the hash key ranges of the shards. You can override hashing the partition key to determine the shard by explicitly specifying a hash value using the ExplicitHashKey parameter. For more information, see Adding Data to a Stream in the Amazon Kinesis Data Streams Developer Guide. PutRecord returns the shard ID of where the data record was placed and the sequence number that was assigned to the data record. Sequence numbers increase over time and are specific to a shard within a stream, not across all shards within a stream. To guarantee strictly increasing ordering, write serially to a shard and use the SequenceNumberForOrdering parameter. For more information, see Adding Data to a Stream in the Amazon Kinesis Data Streams Developer Guide. After you write a record to a stream, you cannot modify that record or its order within the stream. If a PutRecord request cannot be processed because of insufficient provisioned throughput on the shard involved in the request, PutRecord throws ProvisionedThroughputExceededException. By default, data records are accessible for 24 hours from the time that they are added to a stream. You can use IncreaseStreamRetentionPeriod or DecreaseStreamRetentionPeriod to modify this retention period."},{"ref":"AWS.Kinesis.html#put_records/3","title":"AWS.Kinesis.put_records/3","type":"function","doc":"Writes multiple data records into a Kinesis data stream in a single call (also referred to as a PutRecords request). Use this operation to send data into the stream for data ingestion and processing. Each PutRecords request can support up to 500 records. Each record in the request can be as large as 1 MiB, up to a limit of 5 MiB for the entire request, including partition keys. Each shard can support writes up to 1,000 records per second, up to a maximum data write total of 1 MiB per second. You must specify the name of the stream that captures, stores, and transports the data; and an array of request Records, with each record in the array requiring a partition key and data blob. The record size limit applies to the total size of the partition key and data blob. The data blob can be any type of data; for example, a segment from a log file, geographic/location data, website clickstream data, and so on. The partition key is used by Kinesis Data Streams as input to a hash function that maps the partition key and associated data to a specific shard. An MD5 hash function is used to map partition keys to 128-bit integer values and to map associated data records to shards. As a result of this hashing mechanism, all data records with the same partition key map to the same shard within the stream. For more information, see Adding Data to a Stream in the Amazon Kinesis Data Streams Developer Guide. Each record in the Records array may include an optional parameter, ExplicitHashKey, which overrides the partition key to shard mapping. This parameter allows a data producer to determine explicitly the shard where the record is stored. For more information, see Adding Multiple Records with PutRecords in the Amazon Kinesis Data Streams Developer Guide. The PutRecords response includes an array of response Records. Each record in the response array directly correlates with a record in the request array using natural ordering, from the top to the bottom of the request and response. The response Records array always includes the same number of records as the request array. The response Records array includes both successfully and unsuccessfully processed records. Kinesis Data Streams attempts to process all records in each PutRecords request. A single record failure does not stop the processing of subsequent records. As a result, PutRecords doesn&#39;t guarantee the ordering of records. If you need to read records in the same order they are written to the stream, use PutRecord instead of PutRecords, and write to the same shard. A successfully processed record includes ShardId and SequenceNumber values. The ShardId parameter identifies the shard in the stream where the record is stored. The SequenceNumber parameter is an identifier assigned to the put record, unique to all records in the stream. An unsuccessfully processed record includes ErrorCode and ErrorMessage values. ErrorCode reflects the type of error and can be one of the following values: ProvisionedThroughputExceededException or InternalFailure. ErrorMessage provides more detailed information about the ProvisionedThroughputExceededException exception including the account ID, stream name, and shard ID of the record that was throttled. For more information about partially successful responses, see Adding Multiple Records with PutRecords in the Amazon Kinesis Data Streams Developer Guide. After you write a record to a stream, you cannot modify that record or its order within the stream. By default, data records are accessible for 24 hours from the time that they are added to a stream. You can use IncreaseStreamRetentionPeriod or DecreaseStreamRetentionPeriod to modify this retention period."},{"ref":"AWS.Kinesis.html#register_stream_consumer/3","title":"AWS.Kinesis.register_stream_consumer/3","type":"function","doc":"Registers a consumer with a Kinesis data stream. When you use this operation, the consumer you register can then call SubscribeToShard to receive data from the stream using enhanced fan-out, at a rate of up to 2 MiB per second for every shard you subscribe to. This rate is unaffected by the total number of consumers that read from the same stream. You can register up to 20 consumers per stream. A given consumer can only be registered with one stream at a time. For an example of how to use this operations, see Enhanced Fan-Out Using the Kinesis Data Streams API. The use of this operation has a limit of five transactions per second per account. Also, only 5 consumers can be created simultaneously. In other words, you cannot have more than 5 consumers in a CREATING status at the same time. Registering a 6th consumer while there are 5 in a CREATING status results in a LimitExceededException."},{"ref":"AWS.Kinesis.html#remove_tags_from_stream/3","title":"AWS.Kinesis.remove_tags_from_stream/3","type":"function","doc":"Removes tags from the specified Kinesis data stream. Removed tags are deleted and cannot be recovered after this operation successfully completes. If you specify a tag that does not exist, it is ignored. RemoveTagsFromStream has a limit of five transactions per second per account."},{"ref":"AWS.Kinesis.html#split_shard/3","title":"AWS.Kinesis.split_shard/3","type":"function","doc":"Splits a shard into two new shards in the Kinesis data stream, to increase the stream&#39;s capacity to ingest and transport data. SplitShard is called when there is a need to increase the overall capacity of a stream because of an expected increase in the volume of data records being ingested. You can also use SplitShard when a shard appears to be approaching its maximum utilization; for example, the producers sending data into the specific shard are suddenly sending more than previously anticipated. You can also call SplitShard to increase stream capacity, so that more Kinesis Data Streams applications can simultaneously read data from the stream for real-time processing. You must specify the shard to be split and the new hash key, which is the position in the shard where the shard gets split in two. In many cases, the new hash key might be the average of the beginning and ending hash key, but it can be any hash key value in the range being mapped into the shard. For more information, see Split a Shard in the Amazon Kinesis Data Streams Developer Guide. You can use DescribeStream to determine the shard ID and hash key values for the ShardToSplit and NewStartingHashKey parameters that are specified in the SplitShard request. SplitShard is an asynchronous operation. Upon receiving a SplitShard request, Kinesis Data Streams immediately returns a response and sets the stream status to UPDATING. After the operation is completed, Kinesis Data Streams sets the stream status to ACTIVE. Read and write operations continue to work while the stream is in the UPDATING state. You can use DescribeStream to check the status of the stream, which is returned in StreamStatus. If the stream is in the ACTIVE state, you can call SplitShard. If a stream is in CREATING or UPDATING or DELETING states, DescribeStream returns a ResourceInUseException. If the specified stream does not exist, DescribeStream returns a ResourceNotFoundException. If you try to create more shards than are authorized for your account, you receive a LimitExceededException. For the default shard limit for an AWS account, see Kinesis Data Streams Limits in the Amazon Kinesis Data Streams Developer Guide. To increase this limit, contact AWS Support. If you try to operate on too many streams simultaneously using CreateStream, DeleteStream, MergeShards, and/or SplitShard, you receive a LimitExceededException. SplitShard has a limit of five transactions per second per account."},{"ref":"AWS.Kinesis.html#start_stream_encryption/3","title":"AWS.Kinesis.start_stream_encryption/3","type":"function","doc":"Enables or updates server-side encryption using an AWS KMS key for a specified stream. Starting encryption is an asynchronous operation. Upon receiving the request, Kinesis Data Streams returns immediately and sets the status of the stream to UPDATING. After the update is complete, Kinesis Data Streams sets the status of the stream back to ACTIVE. Updating or applying encryption normally takes a few seconds to complete, but it can take minutes. You can continue to read and write data to your stream while its status is UPDATING. Once the status of the stream is ACTIVE, encryption begins for records written to the stream. API Limits: You can successfully apply a new AWS KMS key for server-side encryption 25 times in a rolling 24-hour period. Note: It can take up to 5 seconds after the stream is in an ACTIVE status before all records written to the stream are encrypted. After you enable encryption, you can verify that encryption is applied by inspecting the API response from PutRecord or PutRecords."},{"ref":"AWS.Kinesis.html#stop_stream_encryption/3","title":"AWS.Kinesis.stop_stream_encryption/3","type":"function","doc":"Disables server-side encryption for a specified stream. Stopping encryption is an asynchronous operation. Upon receiving the request, Kinesis Data Streams returns immediately and sets the status of the stream to UPDATING. After the update is complete, Kinesis Data Streams sets the status of the stream back to ACTIVE. Stopping encryption normally takes a few seconds to complete, but it can take minutes. You can continue to read and write data to your stream while its status is UPDATING. Once the status of the stream is ACTIVE, records written to the stream are no longer encrypted by Kinesis Data Streams. API Limits: You can successfully disable server-side encryption 25 times in a rolling 24-hour period. Note: It can take up to 5 seconds after the stream is in an ACTIVE status before all records written to the stream are no longer subject to encryption. After you disabled encryption, you can verify that encryption is not applied by inspecting the API response from PutRecord or PutRecords."},{"ref":"AWS.Kinesis.html#subscribe_to_shard/3","title":"AWS.Kinesis.subscribe_to_shard/3","type":"function","doc":"This operation establishes an HTTP/2 connection between the consumer you specify in the ConsumerARN parameter and the shard you specify in the ShardId parameter. After the connection is successfully established, Kinesis Data Streams pushes records from the shard to the consumer over this connection. Before you call this operation, call RegisterStreamConsumer to register the consumer with Kinesis Data Streams. When the SubscribeToShard call succeeds, your consumer starts receiving events of type SubscribeToShardEvent over the HTTP/2 connection for up to 5 minutes, after which time you need to call SubscribeToShard again to renew the subscription if you want to continue to receive records. You can make one call to SubscribeToShard per second per registered consumer per shard. For example, if you have a 4000 shard stream and two registered stream consumers, you can make one SubscribeToShard request per second for each combination of shard and registered consumer, allowing you to subscribe both consumers to all 4000 shards in one second. If you call SubscribeToShard again with the same ConsumerARN and ShardId within 5 seconds of a successful call, you&#39;ll get a ResourceInUseException. If you call SubscribeToShard 5 seconds or more after a successful call, the first connection will expire and the second call will take over the subscription. For an example of how to use this operations, see Enhanced Fan-Out Using the Kinesis Data Streams API."},{"ref":"AWS.Kinesis.html#update_shard_count/3","title":"AWS.Kinesis.update_shard_count/3","type":"function","doc":"Updates the shard count of the specified stream to the specified number of shards. Updating the shard count is an asynchronous operation. Upon receiving the request, Kinesis Data Streams returns immediately and sets the status of the stream to UPDATING. After the update is complete, Kinesis Data Streams sets the status of the stream back to ACTIVE. Depending on the size of the stream, the scaling action could take a few minutes to complete. You can continue to read and write data to your stream while its status is UPDATING. To update the shard count, Kinesis Data Streams performs splits or merges on individual shards. This can cause short-lived shards to be created, in addition to the final shards. These short-lived shards count towards your total shard limit for your account in the Region. When using this operation, we recommend that you specify a target shard count that is a multiple of 25% (25%, 50%, 75%, 100%). You can specify any target value within your shard limit. However, if you specify a target that isn&#39;t a multiple of 25%, the scaling action might take longer to complete. This operation has the following default limits. By default, you cannot do the following: Scale more than ten times per rolling 24-hour period per stream Scale up to more than double your current shard count for a stream Scale down below half your current shard count for a stream Scale up to more than 500 shards in a stream Scale a stream with more than 500 shards down unless the result is less than 500 shards Scale up to more than the shard limit for your account For the default limits for an AWS account, see Streams Limits in the Amazon Kinesis Data Streams Developer Guide. To request an increase in the call rate limit, the shard limit for this API, or your overall shard limit, use the limits form."},{"ref":"AWS.KinesisAnalytics.html","title":"AWS.KinesisAnalytics","type":"module","doc":"Amazon Kinesis Analytics Overview This documentation is for version 1 of the Amazon Kinesis Data Analytics API, which only supports SQL applications. Version 2 of the API supports SQL and Java applications. For more information about version 2, see Amazon Kinesis Data Analytics API V2 Documentation. This is the Amazon Kinesis Analytics v1 API Reference. The Amazon Kinesis Analytics Developer Guide provides additional information."},{"ref":"AWS.KinesisAnalytics.html#add_application_cloud_watch_logging_option/3","title":"AWS.KinesisAnalytics.add_application_cloud_watch_logging_option/3","type":"function","doc":"This documentation is for version 1 of the Amazon Kinesis Data Analytics API, which only supports SQL applications. Version 2 of the API supports SQL and Java applications. For more information about version 2, see Amazon Kinesis Data Analytics API V2 Documentation. Adds a CloudWatch log stream to monitor application configuration errors. For more information about using CloudWatch log streams with Amazon Kinesis Analytics applications, see Working with Amazon CloudWatch Logs."},{"ref":"AWS.KinesisAnalytics.html#add_application_input/3","title":"AWS.KinesisAnalytics.add_application_input/3","type":"function","doc":"This documentation is for version 1 of the Amazon Kinesis Data Analytics API, which only supports SQL applications. Version 2 of the API supports SQL and Java applications. For more information about version 2, see Amazon Kinesis Data Analytics API V2 Documentation. Adds a streaming source to your Amazon Kinesis application. For conceptual information, see Configuring Application Input. You can add a streaming source either when you create an application or you can use this operation to add a streaming source after you create an application. For more information, see CreateApplication. Any configuration update, including adding a streaming source using this operation, results in a new version of the application. You can use the DescribeApplication operation to find the current application version. This operation requires permissions to perform the kinesisanalytics:AddApplicationInput action."},{"ref":"AWS.KinesisAnalytics.html#add_application_input_processing_configuration/3","title":"AWS.KinesisAnalytics.add_application_input_processing_configuration/3","type":"function","doc":"This documentation is for version 1 of the Amazon Kinesis Data Analytics API, which only supports SQL applications. Version 2 of the API supports SQL and Java applications. For more information about version 2, see Amazon Kinesis Data Analytics API V2 Documentation. Adds an InputProcessingConfiguration to an application. An input processor preprocesses records on the input stream before the application&#39;s SQL code executes. Currently, the only input processor available is AWS Lambda."},{"ref":"AWS.KinesisAnalytics.html#add_application_output/3","title":"AWS.KinesisAnalytics.add_application_output/3","type":"function","doc":"This documentation is for version 1 of the Amazon Kinesis Data Analytics API, which only supports SQL applications. Version 2 of the API supports SQL and Java applications. For more information about version 2, see Amazon Kinesis Data Analytics API V2 Documentation. Adds an external destination to your Amazon Kinesis Analytics application. If you want Amazon Kinesis Analytics to deliver data from an in-application stream within your application to an external destination (such as an Amazon Kinesis stream, an Amazon Kinesis Firehose delivery stream, or an AWS Lambda function), you add the relevant configuration to your application using this operation. You can configure one or more outputs for your application. Each output configuration maps an in-application stream and an external destination. You can use one of the output configurations to deliver data from your in-application error stream to an external destination so that you can analyze the errors. For more information, see Understanding Application Output (Destination). Any configuration update, including adding a streaming source using this operation, results in a new version of the application. You can use the DescribeApplication operation to find the current application version. For the limits on the number of application inputs and outputs you can configure, see Limits. This operation requires permissions to perform the kinesisanalytics:AddApplicationOutput action."},{"ref":"AWS.KinesisAnalytics.html#add_application_reference_data_source/3","title":"AWS.KinesisAnalytics.add_application_reference_data_source/3","type":"function","doc":"This documentation is for version 1 of the Amazon Kinesis Data Analytics API, which only supports SQL applications. Version 2 of the API supports SQL and Java applications. For more information about version 2, see Amazon Kinesis Data Analytics API V2 Documentation. Adds a reference data source to an existing application. Amazon Kinesis Analytics reads reference data (that is, an Amazon S3 object) and creates an in-application table within your application. In the request, you provide the source (S3 bucket name and object key name), name of the in-application table to create, and the necessary mapping information that describes how data in Amazon S3 object maps to columns in the resulting in-application table. For conceptual information, see Configuring Application Input. For the limits on data sources you can add to your application, see Limits. This operation requires permissions to perform the kinesisanalytics:AddApplicationOutput action."},{"ref":"AWS.KinesisAnalytics.html#create_application/3","title":"AWS.KinesisAnalytics.create_application/3","type":"function","doc":"This documentation is for version 1 of the Amazon Kinesis Data Analytics API, which only supports SQL applications. Version 2 of the API supports SQL and Java applications. For more information about version 2, see Amazon Kinesis Data Analytics API V2 Documentation. Creates an Amazon Kinesis Analytics application. You can configure each application with one streaming source as input, application code to process the input, and up to three destinations where you want Amazon Kinesis Analytics to write the output data from your application. For an overview, see How it Works. In the input configuration, you map the streaming source to an in-application stream, which you can think of as a constantly updating table. In the mapping, you must provide a schema for the in-application stream and map each data column in the in-application stream to a data element in the streaming source. Your application code is one or more SQL statements that read input data, transform it, and generate output. Your application code can create one or more SQL artifacts like SQL streams or pumps. In the output configuration, you can configure the application to write data from in-application streams created in your applications to up to three destinations. To read data from your source stream or write data to destination streams, Amazon Kinesis Analytics needs your permissions. You grant these permissions by creating IAM roles. This operation requires permissions to perform the kinesisanalytics:CreateApplication action. For introductory exercises to create an Amazon Kinesis Analytics application, see Getting Started."},{"ref":"AWS.KinesisAnalytics.html#delete_application/3","title":"AWS.KinesisAnalytics.delete_application/3","type":"function","doc":"This documentation is for version 1 of the Amazon Kinesis Data Analytics API, which only supports SQL applications. Version 2 of the API supports SQL and Java applications. For more information about version 2, see Amazon Kinesis Data Analytics API V2 Documentation. Deletes the specified application. Amazon Kinesis Analytics halts application execution and deletes the application, including any application artifacts (such as in-application streams, reference table, and application code). This operation requires permissions to perform the kinesisanalytics:DeleteApplication action."},{"ref":"AWS.KinesisAnalytics.html#delete_application_cloud_watch_logging_option/3","title":"AWS.KinesisAnalytics.delete_application_cloud_watch_logging_option/3","type":"function","doc":"This documentation is for version 1 of the Amazon Kinesis Data Analytics API, which only supports SQL applications. Version 2 of the API supports SQL and Java applications. For more information about version 2, see Amazon Kinesis Data Analytics API V2 Documentation. Deletes a CloudWatch log stream from an application. For more information about using CloudWatch log streams with Amazon Kinesis Analytics applications, see Working with Amazon CloudWatch Logs."},{"ref":"AWS.KinesisAnalytics.html#delete_application_input_processing_configuration/3","title":"AWS.KinesisAnalytics.delete_application_input_processing_configuration/3","type":"function","doc":"This documentation is for version 1 of the Amazon Kinesis Data Analytics API, which only supports SQL applications. Version 2 of the API supports SQL and Java applications. For more information about version 2, see Amazon Kinesis Data Analytics API V2 Documentation. Deletes an InputProcessingConfiguration from an input."},{"ref":"AWS.KinesisAnalytics.html#delete_application_output/3","title":"AWS.KinesisAnalytics.delete_application_output/3","type":"function","doc":"This documentation is for version 1 of the Amazon Kinesis Data Analytics API, which only supports SQL applications. Version 2 of the API supports SQL and Java applications. For more information about version 2, see Amazon Kinesis Data Analytics API V2 Documentation. Deletes output destination configuration from your application configuration. Amazon Kinesis Analytics will no longer write data from the corresponding in-application stream to the external output destination. This operation requires permissions to perform the kinesisanalytics:DeleteApplicationOutput action."},{"ref":"AWS.KinesisAnalytics.html#delete_application_reference_data_source/3","title":"AWS.KinesisAnalytics.delete_application_reference_data_source/3","type":"function","doc":"This documentation is for version 1 of the Amazon Kinesis Data Analytics API, which only supports SQL applications. Version 2 of the API supports SQL and Java applications. For more information about version 2, see Amazon Kinesis Data Analytics API V2 Documentation. Deletes a reference data source configuration from the specified application configuration. If the application is running, Amazon Kinesis Analytics immediately removes the in-application table that you created using the AddApplicationReferenceDataSource operation. This operation requires permissions to perform the kinesisanalytics.DeleteApplicationReferenceDataSource action."},{"ref":"AWS.KinesisAnalytics.html#describe_application/3","title":"AWS.KinesisAnalytics.describe_application/3","type":"function","doc":"This documentation is for version 1 of the Amazon Kinesis Data Analytics API, which only supports SQL applications. Version 2 of the API supports SQL and Java applications. For more information about version 2, see Amazon Kinesis Data Analytics API V2 Documentation. Returns information about a specific Amazon Kinesis Analytics application. If you want to retrieve a list of all applications in your account, use the ListApplications operation. This operation requires permissions to perform the kinesisanalytics:DescribeApplication action. You can use DescribeApplication to get the current application versionId, which you need to call other operations such as Update."},{"ref":"AWS.KinesisAnalytics.html#discover_input_schema/3","title":"AWS.KinesisAnalytics.discover_input_schema/3","type":"function","doc":"This documentation is for version 1 of the Amazon Kinesis Data Analytics API, which only supports SQL applications. Version 2 of the API supports SQL and Java applications. For more information about version 2, see Amazon Kinesis Data Analytics API V2 Documentation. Infers a schema by evaluating sample records on the specified streaming source (Amazon Kinesis stream or Amazon Kinesis Firehose delivery stream) or S3 object. In the response, the operation returns the inferred schema and also the sample records that the operation used to infer the schema. You can use the inferred schema when configuring a streaming source for your application. For conceptual information, see Configuring Application Input. Note that when you create an application using the Amazon Kinesis Analytics console, the console uses this operation to infer a schema and show it in the console user interface. This operation requires permissions to perform the kinesisanalytics:DiscoverInputSchema action."},{"ref":"AWS.KinesisAnalytics.html#list_applications/3","title":"AWS.KinesisAnalytics.list_applications/3","type":"function","doc":"This documentation is for version 1 of the Amazon Kinesis Data Analytics API, which only supports SQL applications. Version 2 of the API supports SQL and Java applications. For more information about version 2, see Amazon Kinesis Data Analytics API V2 Documentation. Returns a list of Amazon Kinesis Analytics applications in your account. For each application, the response includes the application name, Amazon Resource Name (ARN), and status. If the response returns the HasMoreApplications value as true, you can send another request by adding the ExclusiveStartApplicationName in the request body, and set the value of this to the last application name from the previous response. If you want detailed information about a specific application, use DescribeApplication. This operation requires permissions to perform the kinesisanalytics:ListApplications action."},{"ref":"AWS.KinesisAnalytics.html#list_tags_for_resource/3","title":"AWS.KinesisAnalytics.list_tags_for_resource/3","type":"function","doc":"Retrieves the list of key-value tags assigned to the application. For more information, see Using Tagging."},{"ref":"AWS.KinesisAnalytics.html#start_application/3","title":"AWS.KinesisAnalytics.start_application/3","type":"function","doc":"This documentation is for version 1 of the Amazon Kinesis Data Analytics API, which only supports SQL applications. Version 2 of the API supports SQL and Java applications. For more information about version 2, see Amazon Kinesis Data Analytics API V2 Documentation. Starts the specified Amazon Kinesis Analytics application. After creating an application, you must exclusively call this operation to start your application. After the application starts, it begins consuming the input data, processes it, and writes the output to the configured destination. The application status must be READY for you to start an application. You can get the application status in the console or using the DescribeApplication operation. After you start the application, you can stop the application from processing the input by calling the StopApplication operation. This operation requires permissions to perform the kinesisanalytics:StartApplication action."},{"ref":"AWS.KinesisAnalytics.html#stop_application/3","title":"AWS.KinesisAnalytics.stop_application/3","type":"function","doc":"This documentation is for version 1 of the Amazon Kinesis Data Analytics API, which only supports SQL applications. Version 2 of the API supports SQL and Java applications. For more information about version 2, see Amazon Kinesis Data Analytics API V2 Documentation. Stops the application from processing input data. You can stop an application only if it is in the running state. You can use the DescribeApplication operation to find the application state. After the application is stopped, Amazon Kinesis Analytics stops reading data from the input, the application stops processing data, and there is no output written to the destination. This operation requires permissions to perform the kinesisanalytics:StopApplication action."},{"ref":"AWS.KinesisAnalytics.html#tag_resource/3","title":"AWS.KinesisAnalytics.tag_resource/3","type":"function","doc":"Adds one or more key-value tags to a Kinesis Analytics application. Note that the maximum number of application tags includes system tags. The maximum number of user-defined application tags is 50. For more information, see Using Tagging."},{"ref":"AWS.KinesisAnalytics.html#untag_resource/3","title":"AWS.KinesisAnalytics.untag_resource/3","type":"function","doc":"Removes one or more tags from a Kinesis Analytics application. For more information, see Using Tagging."},{"ref":"AWS.KinesisAnalytics.html#update_application/3","title":"AWS.KinesisAnalytics.update_application/3","type":"function","doc":"This documentation is for version 1 of the Amazon Kinesis Data Analytics API, which only supports SQL applications. Version 2 of the API supports SQL and Java applications. For more information about version 2, see Amazon Kinesis Data Analytics API V2 Documentation. Updates an existing Amazon Kinesis Analytics application. Using this API, you can update application code, input configuration, and output configuration. Note that Amazon Kinesis Analytics updates the CurrentApplicationVersionId each time you update your application. This operation requires permission for the kinesisanalytics:UpdateApplication action."},{"ref":"AWS.KinesisAnalyticsV2.html","title":"AWS.KinesisAnalyticsV2","type":"module","doc":"Amazon Kinesis Data Analytics is a fully managed service that you can use to process and analyze streaming data using Java, SQL, or Scala. The service enables you to quickly author and run Java, SQL, or Scala code against streaming sources to perform time series analytics, feed real-time dashboards, and create real-time metrics."},{"ref":"AWS.KinesisAnalyticsV2.html#add_application_cloud_watch_logging_option/3","title":"AWS.KinesisAnalyticsV2.add_application_cloud_watch_logging_option/3","type":"function","doc":"Adds an Amazon CloudWatch log stream to monitor application configuration errors."},{"ref":"AWS.KinesisAnalyticsV2.html#add_application_input/3","title":"AWS.KinesisAnalyticsV2.add_application_input/3","type":"function","doc":"Adds a streaming source to your SQL-based Kinesis Data Analytics application. You can add a streaming source when you create an application, or you can use this operation to add a streaming source after you create an application. For more information, see CreateApplication. Any configuration update, including adding a streaming source using this operation, results in a new version of the application. You can use the DescribeApplication operation to find the current application version."},{"ref":"AWS.KinesisAnalyticsV2.html#add_application_input_processing_configuration/3","title":"AWS.KinesisAnalyticsV2.add_application_input_processing_configuration/3","type":"function","doc":"Adds an InputProcessingConfiguration to a SQL-based Kinesis Data Analytics application. An input processor pre-processes records on the input stream before the application&#39;s SQL code executes. Currently, the only input processor available is AWS Lambda."},{"ref":"AWS.KinesisAnalyticsV2.html#add_application_output/3","title":"AWS.KinesisAnalyticsV2.add_application_output/3","type":"function","doc":"Adds an external destination to your SQL-based Kinesis Data Analytics application. If you want Kinesis Data Analytics to deliver data from an in-application stream within your application to an external destination (such as an Kinesis data stream, a Kinesis Data Firehose delivery stream, or an AWS Lambda function), you add the relevant configuration to your application using this operation. You can configure one or more outputs for your application. Each output configuration maps an in-application stream and an external destination. You can use one of the output configurations to deliver data from your in-application error stream to an external destination so that you can analyze the errors. Any configuration update, including adding a streaming source using this operation, results in a new version of the application. You can use the DescribeApplication operation to find the current application version."},{"ref":"AWS.KinesisAnalyticsV2.html#add_application_reference_data_source/3","title":"AWS.KinesisAnalyticsV2.add_application_reference_data_source/3","type":"function","doc":"Adds a reference data source to an existing SQL-based Kinesis Data Analytics application. Kinesis Data Analytics reads reference data (that is, an Amazon S3 object) and creates an in-application table within your application. In the request, you provide the source (S3 bucket name and object key name), name of the in-application table to create, and the necessary mapping information that describes how data in an Amazon S3 object maps to columns in the resulting in-application table."},{"ref":"AWS.KinesisAnalyticsV2.html#add_application_vpc_configuration/3","title":"AWS.KinesisAnalyticsV2.add_application_vpc_configuration/3","type":"function","doc":"Adds a Virtual Private Cloud (VPC) configuration to the application. Applications can use VPCs to store and access resources securely. Note the following about VPC configurations for Kinesis Data Analytics applications: VPC configurations are not supported for SQL applications. When a VPC is added to a Kinesis Data Analytics application, the application can no longer be accessed from the Internet directly. To enable Internet access to the application, add an Internet gateway to your VPC."},{"ref":"AWS.KinesisAnalyticsV2.html#create_application/3","title":"AWS.KinesisAnalyticsV2.create_application/3","type":"function","doc":"Creates a Kinesis Data Analytics application. For information about creating a Kinesis Data Analytics application, see Creating an Application."},{"ref":"AWS.KinesisAnalyticsV2.html#create_application_snapshot/3","title":"AWS.KinesisAnalyticsV2.create_application_snapshot/3","type":"function","doc":"Creates a snapshot of the application&#39;s state data."},{"ref":"AWS.KinesisAnalyticsV2.html#delete_application/3","title":"AWS.KinesisAnalyticsV2.delete_application/3","type":"function","doc":"Deletes the specified application. Kinesis Data Analytics halts application execution and deletes the application."},{"ref":"AWS.KinesisAnalyticsV2.html#delete_application_cloud_watch_logging_option/3","title":"AWS.KinesisAnalyticsV2.delete_application_cloud_watch_logging_option/3","type":"function","doc":"Deletes an Amazon CloudWatch log stream from an Kinesis Data Analytics application."},{"ref":"AWS.KinesisAnalyticsV2.html#delete_application_input_processing_configuration/3","title":"AWS.KinesisAnalyticsV2.delete_application_input_processing_configuration/3","type":"function","doc":"Deletes an InputProcessingConfiguration from an input."},{"ref":"AWS.KinesisAnalyticsV2.html#delete_application_output/3","title":"AWS.KinesisAnalyticsV2.delete_application_output/3","type":"function","doc":"Deletes the output destination configuration from your SQL-based Kinesis Data Analytics application&#39;s configuration. Kinesis Data Analytics will no longer write data from the corresponding in-application stream to the external output destination."},{"ref":"AWS.KinesisAnalyticsV2.html#delete_application_reference_data_source/3","title":"AWS.KinesisAnalyticsV2.delete_application_reference_data_source/3","type":"function","doc":"Deletes a reference data source configuration from the specified SQL-based Kinesis Data Analytics application&#39;s configuration. If the application is running, Kinesis Data Analytics immediately removes the in-application table that you created using the AddApplicationReferenceDataSource operation."},{"ref":"AWS.KinesisAnalyticsV2.html#delete_application_snapshot/3","title":"AWS.KinesisAnalyticsV2.delete_application_snapshot/3","type":"function","doc":"Deletes a snapshot of application state."},{"ref":"AWS.KinesisAnalyticsV2.html#delete_application_vpc_configuration/3","title":"AWS.KinesisAnalyticsV2.delete_application_vpc_configuration/3","type":"function","doc":"Removes a VPC configuration from a Kinesis Data Analytics application."},{"ref":"AWS.KinesisAnalyticsV2.html#describe_application/3","title":"AWS.KinesisAnalyticsV2.describe_application/3","type":"function","doc":"Returns information about a specific Kinesis Data Analytics application. If you want to retrieve a list of all applications in your account, use the ListApplications operation."},{"ref":"AWS.KinesisAnalyticsV2.html#describe_application_snapshot/3","title":"AWS.KinesisAnalyticsV2.describe_application_snapshot/3","type":"function","doc":"Returns information about a snapshot of application state data."},{"ref":"AWS.KinesisAnalyticsV2.html#discover_input_schema/3","title":"AWS.KinesisAnalyticsV2.discover_input_schema/3","type":"function","doc":"Infers a schema for a SQL-based Kinesis Data Analytics application by evaluating sample records on the specified streaming source (Kinesis data stream or Kinesis Data Firehose delivery stream) or Amazon S3 object. In the response, the operation returns the inferred schema and also the sample records that the operation used to infer the schema. You can use the inferred schema when configuring a streaming source for your application. When you create an application using the Kinesis Data Analytics console, the console uses this operation to infer a schema and show it in the console user interface."},{"ref":"AWS.KinesisAnalyticsV2.html#list_application_snapshots/3","title":"AWS.KinesisAnalyticsV2.list_application_snapshots/3","type":"function","doc":"Lists information about the current application snapshots."},{"ref":"AWS.KinesisAnalyticsV2.html#list_applications/3","title":"AWS.KinesisAnalyticsV2.list_applications/3","type":"function","doc":"Returns a list of Kinesis Data Analytics applications in your account. For each application, the response includes the application name, Amazon Resource Name (ARN), and status. If you want detailed information about a specific application, use DescribeApplication."},{"ref":"AWS.KinesisAnalyticsV2.html#list_tags_for_resource/3","title":"AWS.KinesisAnalyticsV2.list_tags_for_resource/3","type":"function","doc":"Retrieves the list of key-value tags assigned to the application. For more information, see Using Tagging."},{"ref":"AWS.KinesisAnalyticsV2.html#start_application/3","title":"AWS.KinesisAnalyticsV2.start_application/3","type":"function","doc":"Starts the specified Kinesis Data Analytics application. After creating an application, you must exclusively call this operation to start your application."},{"ref":"AWS.KinesisAnalyticsV2.html#stop_application/3","title":"AWS.KinesisAnalyticsV2.stop_application/3","type":"function","doc":"Stops the application from processing data. You can stop an application only if it is in the running state. You can use the DescribeApplication operation to find the application state."},{"ref":"AWS.KinesisAnalyticsV2.html#tag_resource/3","title":"AWS.KinesisAnalyticsV2.tag_resource/3","type":"function","doc":"Adds one or more key-value tags to a Kinesis Data Analytics application. Note that the maximum number of application tags includes system tags. The maximum number of user-defined application tags is 50. For more information, see Using Tagging."},{"ref":"AWS.KinesisAnalyticsV2.html#untag_resource/3","title":"AWS.KinesisAnalyticsV2.untag_resource/3","type":"function","doc":"Removes one or more tags from a Kinesis Data Analytics application. For more information, see Using Tagging."},{"ref":"AWS.KinesisAnalyticsV2.html#update_application/3","title":"AWS.KinesisAnalyticsV2.update_application/3","type":"function","doc":"Updates an existing Kinesis Data Analytics application. Using this operation, you can update application code, input configuration, and output configuration. Kinesis Data Analytics updates the ApplicationVersionId each time you update your application. You cannot update the RuntimeEnvironment of an existing application. If you need to update an application&#39;s RuntimeEnvironment, you must delete the application and create it again."},{"ref":"AWS.KinesisVideo.html","title":"AWS.KinesisVideo","type":"module","doc":""},{"ref":"AWS.KinesisVideo.html#create_signaling_channel/3","title":"AWS.KinesisVideo.create_signaling_channel/3","type":"function","doc":"Creates a signaling channel. CreateSignalingChannel is an asynchronous operation."},{"ref":"AWS.KinesisVideo.html#create_stream/3","title":"AWS.KinesisVideo.create_stream/3","type":"function","doc":"Creates a new Kinesis video stream. When you create a new stream, Kinesis Video Streams assigns it a version number. When you change the stream&#39;s metadata, Kinesis Video Streams updates the version. CreateStream is an asynchronous operation. For information about how the service works, see How it Works. You must have permissions for the KinesisVideo:CreateStream action."},{"ref":"AWS.KinesisVideo.html#delete_signaling_channel/3","title":"AWS.KinesisVideo.delete_signaling_channel/3","type":"function","doc":"Deletes a specified signaling channel. DeleteSignalingChannel is an asynchronous operation. If you don&#39;t specify the channel&#39;s current version, the most recent version is deleted."},{"ref":"AWS.KinesisVideo.html#delete_stream/3","title":"AWS.KinesisVideo.delete_stream/3","type":"function","doc":"Deletes a Kinesis video stream and the data contained in the stream. This method marks the stream for deletion, and makes the data in the stream inaccessible immediately. To ensure that you have the latest version of the stream before deleting it, you can specify the stream version. Kinesis Video Streams assigns a version to each stream. When you update a stream, Kinesis Video Streams assigns a new version number. To get the latest stream version, use the DescribeStream API. This operation requires permission for the KinesisVideo:DeleteStream action."},{"ref":"AWS.KinesisVideo.html#describe_signaling_channel/3","title":"AWS.KinesisVideo.describe_signaling_channel/3","type":"function","doc":"Returns the most current information about the signaling channel. You must specify either the name or the Amazon Resource Name (ARN) of the channel that you want to describe."},{"ref":"AWS.KinesisVideo.html#describe_stream/3","title":"AWS.KinesisVideo.describe_stream/3","type":"function","doc":"Returns the most current information about the specified stream. You must specify either the StreamName or the StreamARN."},{"ref":"AWS.KinesisVideo.html#get_data_endpoint/3","title":"AWS.KinesisVideo.get_data_endpoint/3","type":"function","doc":"Gets an endpoint for a specified stream for either reading or writing. Use this endpoint in your application to read from the specified stream (using the GetMedia or GetMediaForFragmentList operations) or write to it (using the PutMedia operation). The returned endpoint does not have the API name appended. The client needs to add the API name to the returned endpoint. In the request, specify the stream either by StreamName or StreamARN."},{"ref":"AWS.KinesisVideo.html#get_signaling_channel_endpoint/3","title":"AWS.KinesisVideo.get_signaling_channel_endpoint/3","type":"function","doc":"Provides an endpoint for the specified signaling channel to send and receive messages. This API uses the SingleMasterChannelEndpointConfiguration input parameter, which consists of the Protocols and Role properties. Protocols is used to determine the communication mechanism. For example, if you specify WSS as the protocol, this API produces a secure websocket endpoint. If you specify HTTPS as the protocol, this API generates an HTTPS endpoint. Role determines the messaging permissions. A MASTER role results in this API generating an endpoint that a client can use to communicate with any of the viewers on the channel. A VIEWER role results in this API generating an endpoint that a client can use to communicate only with a MASTER."},{"ref":"AWS.KinesisVideo.html#list_signaling_channels/3","title":"AWS.KinesisVideo.list_signaling_channels/3","type":"function","doc":"Returns an array of ChannelInfo objects. Each object describes a signaling channel. To retrieve only those channels that satisfy a specific condition, you can specify a ChannelNameCondition."},{"ref":"AWS.KinesisVideo.html#list_streams/3","title":"AWS.KinesisVideo.list_streams/3","type":"function","doc":"Returns an array of StreamInfo objects. Each object describes a stream. To retrieve only streams that satisfy a specific condition, you can specify a StreamNameCondition."},{"ref":"AWS.KinesisVideo.html#list_tags_for_resource/3","title":"AWS.KinesisVideo.list_tags_for_resource/3","type":"function","doc":"Returns a list of tags associated with the specified signaling channel."},{"ref":"AWS.KinesisVideo.html#list_tags_for_stream/3","title":"AWS.KinesisVideo.list_tags_for_stream/3","type":"function","doc":"Returns a list of tags associated with the specified stream. In the request, you must specify either the StreamName or the StreamARN."},{"ref":"AWS.KinesisVideo.html#tag_resource/3","title":"AWS.KinesisVideo.tag_resource/3","type":"function","doc":"Adds one or more tags to a signaling channel. A tag is a key-value pair (the value is optional) that you can define and assign to AWS resources. If you specify a tag that already exists, the tag value is replaced with the value that you specify in the request. For more information, see Using Cost Allocation Tags in the AWS Billing and Cost Management User Guide."},{"ref":"AWS.KinesisVideo.html#tag_stream/3","title":"AWS.KinesisVideo.tag_stream/3","type":"function","doc":"Adds one or more tags to a stream. A tag is a key-value pair (the value is optional) that you can define and assign to AWS resources. If you specify a tag that already exists, the tag value is replaced with the value that you specify in the request. For more information, see Using Cost Allocation Tags in the AWS Billing and Cost Management User Guide. You must provide either the StreamName or the StreamARN. This operation requires permission for the KinesisVideo:TagStream action. Kinesis video streams support up to 50 tags."},{"ref":"AWS.KinesisVideo.html#untag_resource/3","title":"AWS.KinesisVideo.untag_resource/3","type":"function","doc":"Removes one or more tags from a signaling channel. In the request, specify only a tag key or keys; don&#39;t specify the value. If you specify a tag key that does not exist, it&#39;s ignored."},{"ref":"AWS.KinesisVideo.html#untag_stream/3","title":"AWS.KinesisVideo.untag_stream/3","type":"function","doc":"Removes one or more tags from a stream. In the request, specify only a tag key or keys; don&#39;t specify the value. If you specify a tag key that does not exist, it&#39;s ignored. In the request, you must provide the StreamName or StreamARN."},{"ref":"AWS.KinesisVideo.html#update_data_retention/3","title":"AWS.KinesisVideo.update_data_retention/3","type":"function","doc":"Increases or decreases the stream&#39;s data retention period by the value that you specify. To indicate whether you want to increase or decrease the data retention period, specify the Operation parameter in the request body. In the request, you must specify either the StreamName or the StreamARN. The retention period that you specify replaces the current value. This operation requires permission for the KinesisVideo:UpdateDataRetention action. Changing the data retention period affects the data in the stream as follows: If the data retention period is increased, existing data is retained for the new retention period. For example, if the data retention period is increased from one hour to seven hours, all existing data is retained for seven hours. If the data retention period is decreased, existing data is retained for the new retention period. For example, if the data retention period is decreased from seven hours to one hour, all existing data is retained for one hour, and any data older than one hour is deleted immediately."},{"ref":"AWS.KinesisVideo.html#update_signaling_channel/3","title":"AWS.KinesisVideo.update_signaling_channel/3","type":"function","doc":"Updates the existing signaling channel. This is an asynchronous operation and takes time to complete. If the MessageTtlSeconds value is updated (either increased or reduced), it only applies to new messages sent via this channel after it&#39;s been updated. Existing messages are still expired as per the previous MessageTtlSeconds value."},{"ref":"AWS.KinesisVideo.html#update_stream/3","title":"AWS.KinesisVideo.update_stream/3","type":"function","doc":"Updates stream metadata, such as the device name and media type. You must provide the stream name or the Amazon Resource Name (ARN) of the stream. To make sure that you have the latest version of the stream before updating it, you can specify the stream version. Kinesis Video Streams assigns a version to each stream. When you update a stream, Kinesis Video Streams assigns a new version number. To get the latest stream version, use the DescribeStream API. UpdateStream is an asynchronous operation, and takes time to complete."},{"ref":"AWS.KinesisVideoArchivedMedia.html","title":"AWS.KinesisVideoArchivedMedia","type":"module","doc":""},{"ref":"AWS.KinesisVideoArchivedMedia.html#get_clip/3","title":"AWS.KinesisVideoArchivedMedia.get_clip/3","type":"function","doc":"Downloads an MP4 file (clip) containing the archived, on-demand media from the specified video stream over the specified time range. Both the StreamName and the StreamARN parameters are optional, but you must specify either the StreamName or the StreamARN when invoking this API operation. As a prerequsite to using GetCLip API, you must obtain an endpoint using GetDataEndpoint, specifying GET_CLIP fortheAPINameparameter. An Amazon Kinesis video stream has the following requirements for providing data through MP4: The media must contain h.264 or h.265 encoded video and, optionally, AAC or G.711 encoded audio. Specifically, the codec ID of track 1 should be `V_MPEG/ISO/AVC` (for h.264) or V_MPEGH/ISO/HEVC (for H.265). Optionally, the codec ID of track 2 should be `A_AAC` (for AAC) or A_MS/ACM (for G.711). Data retention must be greater than 0. The video track of each fragment must contain codec private data in the Advanced Video Coding (AVC) for H.264 format and HEVC for H.265 format. For more information, see [MPEG-4 specification ISO/IEC 14496-15](https://www.iso.org/standard/55980.html). For information about adapting stream data to a given format, see [NAL Adaptation Flags](http://docs.aws.amazon.com/kinesisvideostreams/latest/dg/producer-reference-nal.html). The audio track (if present) of each fragment must contain codec private data in the AAC format ([AAC specification ISO/IEC 13818-7](https://www.iso.org/standard/43345.html)) or the [MS Wave format](http://www-mmsp.ece.mcgill.ca/Documents/AudioFormats/WAVE/WAVE.html). You can monitor the amount of outgoing data by monitoring the `GetClip.OutgoingBytes` Amazon CloudWatch metric. For information about using CloudWatch to monitor Kinesis Video Streams, see [Monitoring Kinesis Video Streams](http://docs.aws.amazon.com/kinesisvideostreams/latest/dg/monitoring.html). For pricing information, see [Amazon Kinesis Video Streams Pricing](https://aws.amazon.com/kinesis/video-streams/pricing/) and [AWS Pricing](https://aws.amazon.com/pricing/). Charges for outgoing AWS data apply."},{"ref":"AWS.KinesisVideoArchivedMedia.html#get_d_a_s_h_streaming_session_u_r_l/3","title":"AWS.KinesisVideoArchivedMedia.get_d_a_s_h_streaming_session_u_r_l/3","type":"function","doc":"Retrieves an MPEG Dynamic Adaptive Streaming over HTTP (DASH) URL for the stream. You can then open the URL in a media player to view the stream contents. Both the StreamName and the StreamARN parameters are optional, but you must specify either the StreamName or the StreamARN when invoking this API operation. An Amazon Kinesis video stream has the following requirements for providing data through MPEG-DASH: The media must contain h.264 or h.265 encoded video and, optionally, AAC or G.711 encoded audio. Specifically, the codec ID of track 1 should be V_MPEG/ISO/AVC (for h.264) or V_MPEGH/ISO/HEVC (for H.265). Optionally, the codec ID of track 2 should be A_AAC (for AAC) or A_MS/ACM (for G.711). Data retention must be greater than 0. The video track of each fragment must contain codec private data in the Advanced Video Coding (AVC) for H.264 format and HEVC for H.265 format. For more information, see MPEG-4 specification ISO/IEC 14496-15. For information about adapting stream data to a given format, see NAL Adaptation Flags. The audio track (if present) of each fragment must contain codec private data in the AAC format (AAC specification ISO/IEC 13818-7) or the MS Wave format. The following procedure shows how to use MPEG-DASH with Kinesis Video Streams: Get an endpoint using GetDataEndpoint, specifying GET_DASH_STREAMING_SESSION_URL for the APIName parameter. Retrieve the MPEG-DASH URL using GetDASHStreamingSessionURL. Kinesis Video Streams creates an MPEG-DASH streaming session to be used for accessing content in a stream using the MPEG-DASH protocol. GetDASHStreamingSessionURL returns an authenticated URL (that includes an encrypted session token) for the session&#39;s MPEG-DASH manifest (the root resource needed for streaming with MPEG-DASH). Don&#39;t share or store this token where an unauthorized entity could access it. The token provides access to the content of the stream. Safeguard the token with the same measures that you would use with your AWS credentials. The media that is made available through the manifest consists only of the requested stream, time range, and format. No other media data (such as frames outside the requested window or alternate bitrates) is made available. Provide the URL (containing the encrypted session token) for the MPEG-DASH manifest to a media player that supports the MPEG-DASH protocol. Kinesis Video Streams makes the initialization fragment and media fragments available through the manifest URL. The initialization fragment contains the codec private data for the stream, and other data needed to set up the video or audio decoder and renderer. The media fragments contain encoded video frames or encoded audio samples. The media player receives the authenticated URL and requests stream metadata and media data normally. When the media player requests data, it calls the following actions: GetDASHManifest: Retrieves an MPEG DASH manifest, which contains the metadata for the media that you want to playback. GetMP4InitFragment: Retrieves the MP4 initialization fragment. The media player typically loads the initialization fragment before loading any media fragments. This fragment contains the &quot;fytp&quot; and &quot;moov&quot; MP4 atoms, and the child atoms that are needed to initialize the media player decoder. The initialization fragment does not correspond to a fragment in a Kinesis video stream. It contains only the codec private data for the stream and respective track, which the media player needs to decode the media frames. * **GetMP4MediaFragment:** Retrieves MP4 media fragments. These fragments contain the &quot;moof&quot; and &quot;mdat&quot; MP4 atoms and their child atoms, containing the encoded fragment&#39;s media frames and their timestamps. After the first media fragment is made available in a streaming session, any fragments that don&#39;t contain the same codec private data cause an error to be returned when those different media fragments are loaded. Therefore, the codec private data should not change between fragments in a session. This also means that the session fails if the fragments in a stream change from having only video to having both audio and video. Data retrieved with this action is billable. See Pricing for details. The following restrictions apply to MPEG-DASH sessions: A streaming session URL should not be shared between players. The service might throttle a session if multiple media players are sharing it. For connection limits, see Kinesis Video Streams Limits. A Kinesis video stream can have a maximum of ten active MPEG-DASH streaming sessions. If a new session is created when the maximum number of sessions is already active, the oldest (earliest created) session is closed. The number of active GetMedia connections on a Kinesis video stream does not count against this limit, and the number of active MPEG-DASH sessions does not count against the active GetMedia connection limit. The maximum limits for active HLS and MPEG-DASH streaming sessions are independent of each other. You can monitor the amount of data that the media player consumes by monitoring the GetMP4MediaFragment.OutgoingBytes Amazon CloudWatch metric. For information about using CloudWatch to monitor Kinesis Video Streams, see Monitoring Kinesis Video Streams. For pricing information, see Amazon Kinesis Video Streams Pricing and AWS Pricing. Charges for both HLS sessions and outgoing AWS data apply. For more information about HLS, see HTTP Live Streaming on the Apple Developer site. If an error is thrown after invoking a Kinesis Video Streams archived media API, in addition to the HTTP status code and the response body, it includes the following pieces of information: x-amz-ErrorType HTTP header  contains a more specific error type in addition to what the HTTP status code provides. x-amz-RequestId HTTP header  if you want to report an issue to AWS, the support team can better diagnose the problem if given the Request Id. Both the HTTP status code and the ErrorType header can be utilized to make programmatic decisions about whether errors are retry-able and under what conditions, as well as provide information on what actions the client programmer might need to take in order to successfully try again. For more information, see the Errors section at the bottom of this topic, as well as Common Errors."},{"ref":"AWS.KinesisVideoArchivedMedia.html#get_h_l_s_streaming_session_u_r_l/3","title":"AWS.KinesisVideoArchivedMedia.get_h_l_s_streaming_session_u_r_l/3","type":"function","doc":"Retrieves an HTTP Live Streaming (HLS) URL for the stream. You can then open the URL in a browser or media player to view the stream contents. Both the StreamName and the StreamARN parameters are optional, but you must specify either the StreamName or the StreamARN when invoking this API operation. An Amazon Kinesis video stream has the following requirements for providing data through HLS: The media must contain h.264 or h.265 encoded video and, optionally, AAC encoded audio. Specifically, the codec ID of track 1 should be V_MPEG/ISO/AVC (for h.264) or V_MPEG/ISO/HEVC (for h.265). Optionally, the codec ID of track 2 should be A_AAC. Data retention must be greater than 0. The video track of each fragment must contain codec private data in the Advanced Video Coding (AVC) for H.264 format or HEVC for H.265 format (MPEG-4 specification ISO/IEC 14496-15). For information about adapting stream data to a given format, see NAL Adaptation Flags. The audio track (if present) of each fragment must contain codec private data in the AAC format (AAC specification ISO/IEC 13818-7). Kinesis Video Streams HLS sessions contain fragments in the fragmented MPEG-4 form (also called fMP4 or CMAF) or the MPEG-2 form (also called TS chunks, which the HLS specification also supports). For more information about HLS fragment types, see the HLS specification. The following procedure shows how to use HLS with Kinesis Video Streams: Get an endpoint using GetDataEndpoint, specifying GET_HLS_STREAMING_SESSION_URL for the APIName parameter. Retrieve the HLS URL using GetHLSStreamingSessionURL. Kinesis Video Streams creates an HLS streaming session to be used for accessing content in a stream using the HLS protocol. GetHLSStreamingSessionURL returns an authenticated URL (that includes an encrypted session token) for the session&#39;s HLS master playlist (the root resource needed for streaming with HLS). Don&#39;t share or store this token where an unauthorized entity could access it. The token provides access to the content of the stream. Safeguard the token with the same measures that you would use with your AWS credentials. The media that is made available through the playlist consists only of the requested stream, time range, and format. No other media data (such as frames outside the requested window or alternate bitrates) is made available. Provide the URL (containing the encrypted session token) for the HLS master playlist to a media player that supports the HLS protocol. Kinesis Video Streams makes the HLS media playlist, initialization fragment, and media fragments available through the master playlist URL. The initialization fragment contains the codec private data for the stream, and other data needed to set up the video or audio decoder and renderer. The media fragments contain H.264-encoded video frames or AAC-encoded audio samples. The media player receives the authenticated URL and requests stream metadata and media data normally. When the media player requests data, it calls the following actions: GetHLSMasterPlaylist: Retrieves an HLS master playlist, which contains a URL for the GetHLSMediaPlaylist action for each track, and additional metadata for the media player, including estimated bitrate and resolution. GetHLSMediaPlaylist: Retrieves an HLS media playlist, which contains a URL to access the MP4 initialization fragment with the GetMP4InitFragment action, and URLs to access the MP4 media fragments with the GetMP4MediaFragment actions. The HLS media playlist also contains metadata about the stream that the player needs to play it, such as whether the PlaybackMode is LIVE or ON_DEMAND. The HLS media playlist is typically static for sessions with a PlaybackType of ON_DEMAND. The HLS media playlist is continually updated with new fragments for sessions with a PlaybackType of LIVE. There is a distinct HLS media playlist for the video track and the audio track (if applicable) that contains MP4 media URLs for the specific track. GetMP4InitFragment: Retrieves the MP4 initialization fragment. The media player typically loads the initialization fragment before loading any media fragments. This fragment contains the &quot;fytp&quot; and &quot;moov&quot; MP4 atoms, and the child atoms that are needed to initialize the media player decoder. The initialization fragment does not correspond to a fragment in a Kinesis video stream. It contains only the codec private data for the stream and respective track, which the media player needs to decode the media frames. * **GetMP4MediaFragment:** Retrieves MP4 media fragments. These fragments contain the &quot;moof&quot; and &quot;mdat&quot; MP4 atoms and their child atoms, containing the encoded fragment&#39;s media frames and their timestamps. After the first media fragment is made available in a streaming session, any fragments that don&#39;t contain the same codec private data cause an error to be returned when those different media fragments are loaded. Therefore, the codec private data should not change between fragments in a session. This also means that the session fails if the fragments in a stream change from having only video to having both audio and video. Data retrieved with this action is billable. See Pricing for details. * **GetTSFragment:** Retrieves MPEG TS fragments containing both initialization and media data for all tracks in the stream. If the ContainerFormat is MPEG_TS, this API is used instead of GetMP4InitFragment and GetMP4MediaFragment to retrieve stream media. Data retrieved with this action is billable. For more information, see Kinesis Video Streams pricing. The following restrictions apply to HLS sessions: A streaming session URL should not be shared between players. The service might throttle a session if multiple media players are sharing it. For connection limits, see Kinesis Video Streams Limits. A Kinesis video stream can have a maximum of ten active HLS streaming sessions. If a new session is created when the maximum number of sessions is already active, the oldest (earliest created) session is closed. The number of active GetMedia connections on a Kinesis video stream does not count against this limit, and the number of active HLS sessions does not count against the active GetMedia connection limit. The maximum limits for active HLS and MPEG-DASH streaming sessions are independent of each other. You can monitor the amount of data that the media player consumes by monitoring the GetMP4MediaFragment.OutgoingBytes Amazon CloudWatch metric. For information about using CloudWatch to monitor Kinesis Video Streams, see Monitoring Kinesis Video Streams. For pricing information, see Amazon Kinesis Video Streams Pricing and AWS Pricing. Charges for both HLS sessions and outgoing AWS data apply. For more information about HLS, see HTTP Live Streaming on the Apple Developer site. If an error is thrown after invoking a Kinesis Video Streams archived media API, in addition to the HTTP status code and the response body, it includes the following pieces of information: x-amz-ErrorType HTTP header  contains a more specific error type in addition to what the HTTP status code provides. x-amz-RequestId HTTP header  if you want to report an issue to AWS, the support team can better diagnose the problem if given the Request Id. Both the HTTP status code and the ErrorType header can be utilized to make programmatic decisions about whether errors are retry-able and under what conditions, as well as provide information on what actions the client programmer might need to take in order to successfully try again. For more information, see the Errors section at the bottom of this topic, as well as Common Errors."},{"ref":"AWS.KinesisVideoArchivedMedia.html#get_media_for_fragment_list/3","title":"AWS.KinesisVideoArchivedMedia.get_media_for_fragment_list/3","type":"function","doc":"Gets media for a list of fragments (specified by fragment number) from the archived data in an Amazon Kinesis video stream. You must first call the GetDataEndpoint API to get an endpoint. Then send the GetMediaForFragmentList requests to this endpoint using the --endpoint-url parameter. The following limits apply when using the GetMediaForFragmentList API: A client can call GetMediaForFragmentList up to five times per second per stream. Kinesis Video Streams sends media data at a rate of up to 25 megabytes per second (or 200 megabits per second) during a GetMediaForFragmentList session. If an error is thrown after invoking a Kinesis Video Streams archived media API, in addition to the HTTP status code and the response body, it includes the following pieces of information: x-amz-ErrorType HTTP header  contains a more specific error type in addition to what the HTTP status code provides. x-amz-RequestId HTTP header  if you want to report an issue to AWS, the support team can better diagnose the problem if given the Request Id. Both the HTTP status code and the ErrorType header can be utilized to make programmatic decisions about whether errors are retry-able and under what conditions, as well as provide information on what actions the client programmer might need to take in order to successfully try again. For more information, see the Errors section at the bottom of this topic, as well as Common Errors."},{"ref":"AWS.KinesisVideoArchivedMedia.html#list_fragments/3","title":"AWS.KinesisVideoArchivedMedia.list_fragments/3","type":"function","doc":"Returns a list of Fragment objects from the specified stream and timestamp range within the archived data. Listing fragments is eventually consistent. This means that even if the producer receives an acknowledgment that a fragment is persisted, the result might not be returned immediately from a request to ListFragments. However, results are typically available in less than one second. You must first call the GetDataEndpoint API to get an endpoint. Then send the ListFragments requests to this endpoint using the --endpoint-url parameter. If an error is thrown after invoking a Kinesis Video Streams archived media API, in addition to the HTTP status code and the response body, it includes the following pieces of information: x-amz-ErrorType HTTP header  contains a more specific error type in addition to what the HTTP status code provides. x-amz-RequestId HTTP header  if you want to report an issue to AWS, the support team can better diagnose the problem if given the Request Id. Both the HTTP status code and the ErrorType header can be utilized to make programmatic decisions about whether errors are retry-able and under what conditions, as well as provide information on what actions the client programmer might need to take in order to successfully try again. For more information, see the Errors section at the bottom of this topic, as well as Common Errors."},{"ref":"AWS.KinesisVideoMedia.html","title":"AWS.KinesisVideoMedia","type":"module","doc":""},{"ref":"AWS.KinesisVideoMedia.html#get_media/3","title":"AWS.KinesisVideoMedia.get_media/3","type":"function","doc":"Use this API to retrieve media content from a Kinesis video stream. In the request, you identify the stream name or stream Amazon Resource Name (ARN), and the starting chunk. Kinesis Video Streams then returns a stream of chunks in order by fragment number. You must first call the GetDataEndpoint API to get an endpoint. Then send the GetMedia requests to this endpoint using the --endpoint-url parameter. When you put media data (fragments) on a stream, Kinesis Video Streams stores each incoming fragment and related metadata in what is called a &quot;chunk.&quot; For more information, see PutMedia. The GetMedia API returns a stream of these chunks starting from the chunk that you specify in the request. The following limits apply when using the GetMedia API: A client can call GetMedia up to five times per second per stream. Kinesis Video Streams sends media data at a rate of up to 25 megabytes per second (or 200 megabits per second) during a GetMedia session. If an error is thrown after invoking a Kinesis Video Streams media API, in addition to the HTTP status code and the response body, it includes the following pieces of information: x-amz-ErrorType HTTP header  contains a more specific error type in addition to what the HTTP status code provides. x-amz-RequestId HTTP header  if you want to report an issue to AWS, the support team can better diagnose the problem if given the Request Id. Both the HTTP status code and the ErrorType header can be utilized to make programmatic decisions about whether errors are retry-able and under what conditions, as well as provide information on what actions the client programmer might need to take in order to successfully try again. For more information, see the Errors section at the bottom of this topic, as well as Common Errors."},{"ref":"AWS.KinesisVideoSignaling.html","title":"AWS.KinesisVideoSignaling","type":"module","doc":"Kinesis Video Streams Signaling Service is a intermediate service that establishes a communication channel for discovering peers, transmitting offers and answers in order to establish peer-to-peer connection in webRTC technology."},{"ref":"AWS.KinesisVideoSignaling.html#get_ice_server_config/3","title":"AWS.KinesisVideoSignaling.get_ice_server_config/3","type":"function","doc":"Gets the Interactive Connectivity Establishment (ICE) server configuration information, including URIs, username, and password which can be used to configure the WebRTC connection. The ICE component uses this configuration information to setup the WebRTC connection, including authenticating with the Traversal Using Relays around NAT (TURN) relay server. TURN is a protocol that is used to improve the connectivity of peer-to-peer applications. By providing a cloud-based relay service, TURN ensures that a connection can be established even when one or more peers are incapable of a direct peer-to-peer connection. For more information, see A REST API For Access To TURN Services. You can invoke this API to establish a fallback mechanism in case either of the peers is unable to establish a direct peer-to-peer connection over a signaling channel. You must specify either a signaling channel ARN or the client ID in order to invoke this API."},{"ref":"AWS.KinesisVideoSignaling.html#send_alexa_offer_to_master/3","title":"AWS.KinesisVideoSignaling.send_alexa_offer_to_master/3","type":"function","doc":"This API allows you to connect WebRTC-enabled devices with Alexa display devices. When invoked, it sends the Alexa Session Description Protocol (SDP) offer to the master peer. The offer is delivered as soon as the master is connected to the specified signaling channel. This API returns the SDP answer from the connected master. If the master is not connected to the signaling channel, redelivery requests are made until the message expires."},{"ref":"AWS.LakeFormation.html","title":"AWS.LakeFormation","type":"module","doc":"AWS Lake Formation Defines the public endpoint for the AWS Lake Formation service."},{"ref":"AWS.LakeFormation.html#batch_grant_permissions/3","title":"AWS.LakeFormation.batch_grant_permissions/3","type":"function","doc":"Batch operation to grant permissions to the principal."},{"ref":"AWS.LakeFormation.html#batch_revoke_permissions/3","title":"AWS.LakeFormation.batch_revoke_permissions/3","type":"function","doc":"Batch operation to revoke permissions from the principal."},{"ref":"AWS.LakeFormation.html#deregister_resource/3","title":"AWS.LakeFormation.deregister_resource/3","type":"function","doc":"Deregisters the resource as managed by the Data Catalog. When you deregister a path, Lake Formation removes the path from the inline policy attached to your service-linked role."},{"ref":"AWS.LakeFormation.html#describe_resource/3","title":"AWS.LakeFormation.describe_resource/3","type":"function","doc":"Retrieves the current data access role for the given resource registered in AWS Lake Formation."},{"ref":"AWS.LakeFormation.html#get_data_lake_settings/3","title":"AWS.LakeFormation.get_data_lake_settings/3","type":"function","doc":"Retrieves the list of the data lake administrators of a Lake Formation-managed data lake."},{"ref":"AWS.LakeFormation.html#get_effective_permissions_for_path/3","title":"AWS.LakeFormation.get_effective_permissions_for_path/3","type":"function","doc":"Returns the Lake Formation permissions for a specified table or database resource located at a path in Amazon S3. GetEffectivePermissionsForPath will not return databases and tables if the catalog is encrypted."},{"ref":"AWS.LakeFormation.html#grant_permissions/3","title":"AWS.LakeFormation.grant_permissions/3","type":"function","doc":"Grants permissions to the principal to access metadata in the Data Catalog and data organized in underlying data storage such as Amazon S3. For information about permissions, see Security and Access Control to Metadata and Data."},{"ref":"AWS.LakeFormation.html#list_permissions/3","title":"AWS.LakeFormation.list_permissions/3","type":"function","doc":"Returns a list of the principal permissions on the resource, filtered by the permissions of the caller. For example, if you are granted an ALTER permission, you are able to see only the principal permissions for ALTER. This operation returns only those permissions that have been explicitly granted. For information about permissions, see Security and Access Control to Metadata and Data."},{"ref":"AWS.LakeFormation.html#list_resources/3","title":"AWS.LakeFormation.list_resources/3","type":"function","doc":"Lists the resources registered to be managed by the Data Catalog."},{"ref":"AWS.LakeFormation.html#put_data_lake_settings/3","title":"AWS.LakeFormation.put_data_lake_settings/3","type":"function","doc":"Sets the list of data lake administrators who have admin privileges on all resources managed by Lake Formation. For more information on admin privileges, see Granting Lake Formation Permissions. This API replaces the current list of data lake admins with the new list being passed. To add an admin, fetch the current list and add the new admin to that list and pass that list in this API."},{"ref":"AWS.LakeFormation.html#register_resource/3","title":"AWS.LakeFormation.register_resource/3","type":"function","doc":"Registers the resource as managed by the Data Catalog. To add or update data, Lake Formation needs read/write access to the chosen Amazon S3 path. Choose a role that you know has permission to do this, or choose the AWSServiceRoleForLakeFormationDataAccess service-linked role. When you register the first Amazon S3 path, the service-linked role and a new inline policy are created on your behalf. Lake Formation adds the first path to the inline policy and attaches it to the service-linked role. When you register subsequent paths, Lake Formation adds the path to the existing policy. The following request registers a new location and gives AWS Lake Formation permission to use the service-linked role to access that location. ResourceArn = arn:aws:s3:::my-bucket UseServiceLinkedRole = true If UseServiceLinkedRole is not set to true, you must provide or set the RoleArn: arn:aws:iam::12345:role/my-data-access-role"},{"ref":"AWS.LakeFormation.html#revoke_permissions/3","title":"AWS.LakeFormation.revoke_permissions/3","type":"function","doc":"Revokes permissions to the principal to access metadata in the Data Catalog and data organized in underlying data storage such as Amazon S3."},{"ref":"AWS.LakeFormation.html#update_resource/3","title":"AWS.LakeFormation.update_resource/3","type":"function","doc":"Updates the data access role used for vending access to the given (registered) resource in AWS Lake Formation."},{"ref":"AWS.Lambda.html","title":"AWS.Lambda","type":"module","doc":"AWS Lambda Overview This is the AWS Lambda API Reference. The AWS Lambda Developer Guide provides additional information. For the service overview, see What is AWS Lambda, and for information about how the service works, see AWS Lambda: How it Works in the AWS Lambda Developer Guide."},{"ref":"AWS.Lambda.html#add_layer_version_permission/5","title":"AWS.Lambda.add_layer_version_permission/5","type":"function","doc":"Adds permissions to the resource-based policy of a version of an AWS Lambda layer. Use this action to grant layer usage permission to other accounts. You can grant permission to a single account, all AWS accounts, or all accounts in an organization. To revoke permission, call RemoveLayerVersionPermission with the statement ID that you specified when you added it."},{"ref":"AWS.Lambda.html#add_permission/4","title":"AWS.Lambda.add_permission/4","type":"function","doc":"Grants an AWS service or another account permission to use a function. You can apply the policy at the function level, or specify a qualifier to restrict access to a single version or alias. If you use a qualifier, the invoker must use the full Amazon Resource Name (ARN) of that version or alias to invoke the function. To grant permission to another account, specify the account ID as the Principal. For AWS services, the principal is a domain-style identifier defined by the service, like s3.amazonaws.com or sns.amazonaws.com. For AWS services, you can also specify the ARN of the associated resource as the SourceArn. If you grant permission to a service principal without specifying the source, other accounts could potentially configure resources in their account to invoke your Lambda function. This action adds a statement to a resource-based permissions policy for the function. For more information about function policies, see Lambda Function Policies."},{"ref":"AWS.Lambda.html#create_alias/4","title":"AWS.Lambda.create_alias/4","type":"function","doc":"Creates an alias for a Lambda function version. Use aliases to provide clients with a function identifier that you can update to invoke a different version. You can also map an alias to split invocation requests between two versions. Use the RoutingConfig parameter to specify a second version and the percentage of invocation requests that it receives."},{"ref":"AWS.Lambda.html#create_event_source_mapping/3","title":"AWS.Lambda.create_event_source_mapping/3","type":"function","doc":"Creates a mapping between an event source and an AWS Lambda function. Lambda reads items from the event source and triggers the function. For details about each event source type, see the following topics. Using AWS Lambda with Amazon DynamoDB Using AWS Lambda with Amazon Kinesis Using AWS Lambda with Amazon SQS Using AWS Lambda with Amazon MSK The following error handling options are only available for stream sources (DynamoDB and Kinesis): BisectBatchOnFunctionError - If the function returns an error, split the batch in two and retry. DestinationConfig - Send discarded records to an Amazon SQS queue or Amazon SNS topic. MaximumRecordAgeInSeconds - Discard records older than the specified age. Default -1 (infinite). Minimum 60. Maximum 604800. MaximumRetryAttempts - Discard records after the specified number of retries. Default -1 (infinite). Minimum 0. Maximum 10000. When infinite, failed records will be retried until the record expires. ParallelizationFactor - Process multiple batches from each shard concurrently."},{"ref":"AWS.Lambda.html#create_function/3","title":"AWS.Lambda.create_function/3","type":"function","doc":"Creates a Lambda function. To create a function, you need a deployment package and an execution role. The deployment package contains your function code. The execution role grants the function permission to use AWS services, such as Amazon CloudWatch Logs for log streaming and AWS X-Ray for request tracing. When you create a function, Lambda provisions an instance of the function and its supporting resources. If your function connects to a VPC, this process can take a minute or so. During this time, you can&#39;t invoke or modify the function. The State, StateReason, and StateReasonCode fields in the response from GetFunctionConfiguration indicate when the function is ready to invoke. For more information, see Function States. A function has an unpublished version, and can have published versions and aliases. The unpublished version changes when you update your function&#39;s code and configuration. A published version is a snapshot of your function code and configuration that can&#39;t be changed. An alias is a named resource that maps to a version, and can be changed to map to a different version. Use the Publish parameter to create version 1 of your function from its initial configuration. The other parameters let you configure version-specific and function-level settings. You can modify version-specific settings later with UpdateFunctionConfiguration. Function-level settings apply to both the unpublished and published versions of the function, and include tags (TagResource) and per-function concurrency limits (PutFunctionConcurrency). If another account or an AWS service invokes your function, use AddPermission to grant permission by creating a resource-based IAM policy. You can grant permissions at the function level, on a version, or on an alias. To invoke your function directly, use Invoke. To invoke your function in response to events in other AWS services, create an event source mapping (CreateEventSourceMapping), or configure a function trigger in the other service. For more information, see Invoking Functions."},{"ref":"AWS.Lambda.html#delete_alias/5","title":"AWS.Lambda.delete_alias/5","type":"function","doc":"Deletes a Lambda function alias."},{"ref":"AWS.Lambda.html#delete_event_source_mapping/4","title":"AWS.Lambda.delete_event_source_mapping/4","type":"function","doc":"Deletes an event source mapping. You can get the identifier of a mapping from the output of ListEventSourceMappings. When you delete an event source mapping, it enters a Deleting state and might not be completely deleted for several seconds."},{"ref":"AWS.Lambda.html#delete_function/4","title":"AWS.Lambda.delete_function/4","type":"function","doc":"Deletes a Lambda function. To delete a specific function version, use the Qualifier parameter. Otherwise, all versions and aliases are deleted. To delete Lambda event source mappings that invoke a function, use DeleteEventSourceMapping. For AWS services and resources that invoke your function directly, delete the trigger in the service where you originally configured it."},{"ref":"AWS.Lambda.html#delete_function_concurrency/4","title":"AWS.Lambda.delete_function_concurrency/4","type":"function","doc":"Removes a concurrent execution limit from a function."},{"ref":"AWS.Lambda.html#delete_function_event_invoke_config/4","title":"AWS.Lambda.delete_function_event_invoke_config/4","type":"function","doc":"Deletes the configuration for asynchronous invocation for a function, version, or alias. To configure options for asynchronous invocation, use PutFunctionEventInvokeConfig."},{"ref":"AWS.Lambda.html#delete_layer_version/5","title":"AWS.Lambda.delete_layer_version/5","type":"function","doc":"Deletes a version of an AWS Lambda layer. Deleted versions can no longer be viewed or added to functions. To avoid breaking functions, a copy of the version remains in Lambda until no functions refer to it."},{"ref":"AWS.Lambda.html#delete_provisioned_concurrency_config/4","title":"AWS.Lambda.delete_provisioned_concurrency_config/4","type":"function","doc":"Deletes the provisioned concurrency configuration for a function."},{"ref":"AWS.Lambda.html#get_account_settings/2","title":"AWS.Lambda.get_account_settings/2","type":"function","doc":"Retrieves details about your account&#39;s limits and usage in an AWS Region."},{"ref":"AWS.Lambda.html#get_alias/4","title":"AWS.Lambda.get_alias/4","type":"function","doc":"Returns details about a Lambda function alias."},{"ref":"AWS.Lambda.html#get_event_source_mapping/3","title":"AWS.Lambda.get_event_source_mapping/3","type":"function","doc":"Returns details about an event source mapping. You can get the identifier of a mapping from the output of ListEventSourceMappings."},{"ref":"AWS.Lambda.html#get_function/4","title":"AWS.Lambda.get_function/4","type":"function","doc":"Returns information about the function or function version, with a link to download the deployment package that&#39;s valid for 10 minutes. If you specify a function version, only details that are specific to that version are returned."},{"ref":"AWS.Lambda.html#get_function_concurrency/3","title":"AWS.Lambda.get_function_concurrency/3","type":"function","doc":"Returns details about the reserved concurrency configuration for a function. To set a concurrency limit for a function, use PutFunctionConcurrency."},{"ref":"AWS.Lambda.html#get_function_configuration/4","title":"AWS.Lambda.get_function_configuration/4","type":"function","doc":"Returns the version-specific settings of a Lambda function or version. The output includes only options that can vary between versions of a function. To modify these settings, use UpdateFunctionConfiguration. To get all of a function&#39;s details, including function-level settings, use GetFunction."},{"ref":"AWS.Lambda.html#get_function_event_invoke_config/4","title":"AWS.Lambda.get_function_event_invoke_config/4","type":"function","doc":"Retrieves the configuration for asynchronous invocation for a function, version, or alias. To configure options for asynchronous invocation, use PutFunctionEventInvokeConfig."},{"ref":"AWS.Lambda.html#get_layer_version/4","title":"AWS.Lambda.get_layer_version/4","type":"function","doc":"Returns information about a version of an AWS Lambda layer, with a link to download the layer archive that&#39;s valid for 10 minutes."},{"ref":"AWS.Lambda.html#get_layer_version_by_arn/3","title":"AWS.Lambda.get_layer_version_by_arn/3","type":"function","doc":"Returns information about a version of an AWS Lambda layer, with a link to download the layer archive that&#39;s valid for 10 minutes."},{"ref":"AWS.Lambda.html#get_layer_version_policy/4","title":"AWS.Lambda.get_layer_version_policy/4","type":"function","doc":"Returns the permission policy for a version of an AWS Lambda layer. For more information, see AddLayerVersionPermission."},{"ref":"AWS.Lambda.html#get_policy/4","title":"AWS.Lambda.get_policy/4","type":"function","doc":"Returns the resource-based IAM policy for a function, version, or alias."},{"ref":"AWS.Lambda.html#get_provisioned_concurrency_config/4","title":"AWS.Lambda.get_provisioned_concurrency_config/4","type":"function","doc":"Retrieves the provisioned concurrency configuration for a function&#39;s alias or version."},{"ref":"AWS.Lambda.html#invoke/4","title":"AWS.Lambda.invoke/4","type":"function","doc":"Invokes a Lambda function. You can invoke a function synchronously (and wait for the response), or asynchronously. To invoke a function asynchronously, set InvocationType to Event. For synchronous invocation, details about the function response, including errors, are included in the response body and headers. For either invocation type, you can find more information in the execution log and trace. When an error occurs, your function may be invoked multiple times. Retry behavior varies by error type, client, event source, and invocation type. For example, if you invoke a function asynchronously and it returns an error, Lambda executes the function up to two more times. For more information, see Retry Behavior. For asynchronous invocation, Lambda adds events to a queue before sending them to your function. If your function does not have enough capacity to keep up with the queue, events may be lost. Occasionally, your function may receive the same event multiple times, even if no error occurs. To retain events that were not processed, configure your function with a dead-letter queue. The status code in the API response doesn&#39;t reflect function errors. Error codes are reserved for errors that prevent your function from executing, such as permissions errors, limit errors, or issues with your function&#39;s code and configuration. For example, Lambda returns TooManyRequestsException if executing the function would cause you to exceed a concurrency limit at either the account level (ConcurrentInvocationLimitExceeded) or function level (ReservedFunctionConcurrentInvocationLimitExceeded). For functions with a long timeout, your client might be disconnected during synchronous invocation while it waits for a response. Configure your HTTP client, SDK, firewall, proxy, or operating system to allow for long connections with timeout or keep-alive settings. This operation requires permission for the lambda:InvokeFunction action."},{"ref":"AWS.Lambda.html#invoke_async/4","title":"AWS.Lambda.invoke_async/4","type":"function","doc":"For asynchronous function invocation, use Invoke. Invokes a function asynchronously."},{"ref":"AWS.Lambda.html#list_aliases/6","title":"AWS.Lambda.list_aliases/6","type":"function","doc":"Returns a list of aliases for a Lambda function."},{"ref":"AWS.Lambda.html#list_event_source_mappings/6","title":"AWS.Lambda.list_event_source_mappings/6","type":"function","doc":"Lists event source mappings. Specify an EventSourceArn to only show event source mappings for a single event source."},{"ref":"AWS.Lambda.html#list_function_event_invoke_configs/5","title":"AWS.Lambda.list_function_event_invoke_configs/5","type":"function","doc":"Retrieves a list of configurations for asynchronous invocation for a function. To configure options for asynchronous invocation, use PutFunctionEventInvokeConfig."},{"ref":"AWS.Lambda.html#list_functions/6","title":"AWS.Lambda.list_functions/6","type":"function","doc":"Returns a list of Lambda functions, with the version-specific configuration of each. Lambda returns up to 50 functions per call. Set FunctionVersion to ALL to include all published versions of each function in addition to the unpublished version. To get more information about a function or version, use GetFunction."},{"ref":"AWS.Lambda.html#list_layer_versions/6","title":"AWS.Lambda.list_layer_versions/6","type":"function","doc":"Lists the versions of an AWS Lambda layer. Versions that have been deleted aren&#39;t listed. Specify a runtime identifier to list only versions that indicate that they&#39;re compatible with that runtime."},{"ref":"AWS.Lambda.html#list_layers/5","title":"AWS.Lambda.list_layers/5","type":"function","doc":"Lists AWS Lambda layers and shows information about the latest version of each. Specify a runtime identifier to list only layers that indicate that they&#39;re compatible with that runtime."},{"ref":"AWS.Lambda.html#list_provisioned_concurrency_configs/5","title":"AWS.Lambda.list_provisioned_concurrency_configs/5","type":"function","doc":"Retrieves a list of provisioned concurrency configurations for a function."},{"ref":"AWS.Lambda.html#list_tags/3","title":"AWS.Lambda.list_tags/3","type":"function","doc":"Returns a function&#39;s tags. You can also view tags with GetFunction."},{"ref":"AWS.Lambda.html#list_versions_by_function/5","title":"AWS.Lambda.list_versions_by_function/5","type":"function","doc":"Returns a list of versions, with the version-specific configuration of each. Lambda returns up to 50 versions per call."},{"ref":"AWS.Lambda.html#publish_layer_version/4","title":"AWS.Lambda.publish_layer_version/4","type":"function","doc":"Creates an AWS Lambda layer from a ZIP archive. Each time you call PublishLayerVersion with the same layer name, a new version is created. Add layers to your function with CreateFunction or UpdateFunctionConfiguration."},{"ref":"AWS.Lambda.html#publish_version/4","title":"AWS.Lambda.publish_version/4","type":"function","doc":"Creates a version from the current code and configuration of a function. Use versions to create a snapshot of your function code and configuration that doesn&#39;t change. AWS Lambda doesn&#39;t publish a version if the function&#39;s configuration and code haven&#39;t changed since the last version. Use UpdateFunctionCode or UpdateFunctionConfiguration to update the function before publishing a version. Clients can invoke versions directly or with an alias. To create an alias, use CreateAlias."},{"ref":"AWS.Lambda.html#put_function_concurrency/4","title":"AWS.Lambda.put_function_concurrency/4","type":"function","doc":"Sets the maximum number of simultaneous executions for a function, and reserves capacity for that concurrency level. Concurrency settings apply to the function as a whole, including all published versions and the unpublished version. Reserving concurrency both ensures that your function has capacity to process the specified number of events simultaneously, and prevents it from scaling beyond that level. Use GetFunction to see the current setting for a function. Use GetAccountSettings to see your Regional concurrency limit. You can reserve concurrency for as many functions as you like, as long as you leave at least 100 simultaneous executions unreserved for functions that aren&#39;t configured with a per-function limit. For more information, see Managing Concurrency."},{"ref":"AWS.Lambda.html#put_function_event_invoke_config/4","title":"AWS.Lambda.put_function_event_invoke_config/4","type":"function","doc":"Configures options for asynchronous invocation on a function, version, or alias. If a configuration already exists for a function, version, or alias, this operation overwrites it. If you exclude any settings, they are removed. To set one option without affecting existing settings for other options, use UpdateFunctionEventInvokeConfig. By default, Lambda retries an asynchronous invocation twice if the function returns an error. It retains events in a queue for up to six hours. When an event fails all processing attempts or stays in the asynchronous invocation queue for too long, Lambda discards it. To retain discarded events, configure a dead-letter queue with UpdateFunctionConfiguration. To send an invocation record to a queue, topic, function, or event bus, specify a destination. You can configure separate destinations for successful invocations (on-success) and events that fail all processing attempts (on-failure). You can configure destinations in addition to or instead of a dead-letter queue."},{"ref":"AWS.Lambda.html#put_provisioned_concurrency_config/4","title":"AWS.Lambda.put_provisioned_concurrency_config/4","type":"function","doc":"Adds a provisioned concurrency configuration to a function&#39;s alias or version."},{"ref":"AWS.Lambda.html#remove_layer_version_permission/6","title":"AWS.Lambda.remove_layer_version_permission/6","type":"function","doc":"Removes a statement from the permissions policy for a version of an AWS Lambda layer. For more information, see AddLayerVersionPermission."},{"ref":"AWS.Lambda.html#remove_permission/5","title":"AWS.Lambda.remove_permission/5","type":"function","doc":"Revokes function-use permission from an AWS service or another account. You can get the ID of the statement from the output of GetPolicy."},{"ref":"AWS.Lambda.html#tag_resource/4","title":"AWS.Lambda.tag_resource/4","type":"function","doc":"Adds tags to a function."},{"ref":"AWS.Lambda.html#untag_resource/4","title":"AWS.Lambda.untag_resource/4","type":"function","doc":"Removes tags from a function."},{"ref":"AWS.Lambda.html#update_alias/5","title":"AWS.Lambda.update_alias/5","type":"function","doc":"Updates the configuration of a Lambda function alias."},{"ref":"AWS.Lambda.html#update_event_source_mapping/4","title":"AWS.Lambda.update_event_source_mapping/4","type":"function","doc":"Updates an event source mapping. You can change the function that AWS Lambda invokes, or pause invocation and resume later from the same location. The following error handling options are only available for stream sources (DynamoDB and Kinesis): BisectBatchOnFunctionError - If the function returns an error, split the batch in two and retry. DestinationConfig - Send discarded records to an Amazon SQS queue or Amazon SNS topic. MaximumRecordAgeInSeconds - Discard records older than the specified age. Default -1 (infinite). Minimum 60. Maximum 604800. MaximumRetryAttempts - Discard records after the specified number of retries. Default -1 (infinite). Minimum 0. Maximum 10000. When infinite, failed records will be retried until the record expires. ParallelizationFactor - Process multiple batches from each shard concurrently."},{"ref":"AWS.Lambda.html#update_function_code/4","title":"AWS.Lambda.update_function_code/4","type":"function","doc":"Updates a Lambda function&#39;s code. The function&#39;s code is locked when you publish a version. You can&#39;t modify the code of a published version, only the unpublished version."},{"ref":"AWS.Lambda.html#update_function_configuration/4","title":"AWS.Lambda.update_function_configuration/4","type":"function","doc":"Modify the version-specific settings of a Lambda function. When you update a function, Lambda provisions an instance of the function and its supporting resources. If your function connects to a VPC, this process can take a minute. During this time, you can&#39;t modify the function, but you can still invoke it. The LastUpdateStatus, LastUpdateStatusReason, and LastUpdateStatusReasonCode fields in the response from GetFunctionConfiguration indicate when the update is complete and the function is processing events with the new configuration. For more information, see Function States. These settings can vary between versions of a function and are locked when you publish a version. You can&#39;t modify the configuration of a published version, only the unpublished version. To configure function concurrency, use PutFunctionConcurrency. To grant invoke permissions to an account or AWS service, use AddPermission."},{"ref":"AWS.Lambda.html#update_function_event_invoke_config/4","title":"AWS.Lambda.update_function_event_invoke_config/4","type":"function","doc":"Updates the configuration for asynchronous invocation for a function, version, or alias. To configure options for asynchronous invocation, use PutFunctionEventInvokeConfig."},{"ref":"AWS.LexModelBuilding.html","title":"AWS.LexModelBuilding","type":"module","doc":"Amazon Lex Build-Time Actions Amazon Lex is an AWS service for building conversational voice and text interfaces. Use these actions to create, update, and delete conversational bots for new and existing client applications."},{"ref":"AWS.LexModelBuilding.html#create_bot_version/4","title":"AWS.LexModelBuilding.create_bot_version/4","type":"function","doc":"Creates a new version of the bot based on the $LATEST version. If the $LATEST version of this resource hasn&#39;t changed since you created the last version, Amazon Lex doesn&#39;t create a new version. It returns the last created version. You can update only the $LATEST version of the bot. You can&#39;t update the numbered versions that you create with the CreateBotVersion operation. When you create the first version of a bot, Amazon Lex sets the version to 1. Subsequent versions increment by 1. For more information, see versioning-intro. This operation requires permission for the lex:CreateBotVersion action."},{"ref":"AWS.LexModelBuilding.html#create_intent_version/4","title":"AWS.LexModelBuilding.create_intent_version/4","type":"function","doc":"Creates a new version of an intent based on the $LATEST version of the intent. If the $LATEST version of this intent hasn&#39;t changed since you last updated it, Amazon Lex doesn&#39;t create a new version. It returns the last version you created. You can update only the $LATEST version of the intent. You can&#39;t update the numbered versions that you create with the CreateIntentVersion operation. When you create a version of an intent, Amazon Lex sets the version to 1. Subsequent versions increment by 1. For more information, see versioning-intro. This operation requires permissions to perform the lex:CreateIntentVersion action."},{"ref":"AWS.LexModelBuilding.html#create_slot_type_version/4","title":"AWS.LexModelBuilding.create_slot_type_version/4","type":"function","doc":"Creates a new version of a slot type based on the $LATEST version of the specified slot type. If the $LATEST version of this resource has not changed since the last version that you created, Amazon Lex doesn&#39;t create a new version. It returns the last version that you created. You can update only the $LATEST version of a slot type. You can&#39;t update the numbered versions that you create with the CreateSlotTypeVersion operation. When you create a version of a slot type, Amazon Lex sets the version to 1. Subsequent versions increment by 1. For more information, see versioning-intro. This operation requires permissions for the lex:CreateSlotTypeVersion action."},{"ref":"AWS.LexModelBuilding.html#delete_bot/4","title":"AWS.LexModelBuilding.delete_bot/4","type":"function","doc":"Deletes all versions of the bot, including the $LATEST version. To delete a specific version of the bot, use the DeleteBotVersion operation. The DeleteBot operation doesn&#39;t immediately remove the bot schema. Instead, it is marked for deletion and removed later. Amazon Lex stores utterances indefinitely for improving the ability of your bot to respond to user inputs. These utterances are not removed when the bot is deleted. To remove the utterances, use the DeleteUtterances operation. If a bot has an alias, you can&#39;t delete it. Instead, the DeleteBot operation returns a ResourceInUseException exception that includes a reference to the alias that refers to the bot. To remove the reference to the bot, delete the alias. If you get the same exception again, delete the referring alias until the DeleteBot operation is successful. This operation requires permissions for the lex:DeleteBot action."},{"ref":"AWS.LexModelBuilding.html#delete_bot_alias/5","title":"AWS.LexModelBuilding.delete_bot_alias/5","type":"function","doc":"Deletes an alias for the specified bot. You can&#39;t delete an alias that is used in the association between a bot and a messaging channel. If an alias is used in a channel association, the DeleteBot operation returns a ResourceInUseException exception that includes a reference to the channel association that refers to the bot. You can remove the reference to the alias by deleting the channel association. If you get the same exception again, delete the referring association until the DeleteBotAlias operation is successful."},{"ref":"AWS.LexModelBuilding.html#delete_bot_channel_association/6","title":"AWS.LexModelBuilding.delete_bot_channel_association/6","type":"function","doc":"Deletes the association between an Amazon Lex bot and a messaging platform. This operation requires permission for the lex:DeleteBotChannelAssociation action."},{"ref":"AWS.LexModelBuilding.html#delete_bot_version/5","title":"AWS.LexModelBuilding.delete_bot_version/5","type":"function","doc":"Deletes a specific version of a bot. To delete all versions of a bot, use the DeleteBot operation. This operation requires permissions for the lex:DeleteBotVersion action."},{"ref":"AWS.LexModelBuilding.html#delete_intent/4","title":"AWS.LexModelBuilding.delete_intent/4","type":"function","doc":"Deletes all versions of the intent, including the $LATEST version. To delete a specific version of the intent, use the DeleteIntentVersion operation. You can delete a version of an intent only if it is not referenced. To delete an intent that is referred to in one or more bots (see how-it-works), you must remove those references first. If you get the ResourceInUseException exception, it provides an example reference that shows where the intent is referenced. To remove the reference to the intent, either update the bot or delete it. If you get the same exception when you attempt to delete the intent again, repeat until the intent has no references and the call to DeleteIntent is successful. This operation requires permission for the lex:DeleteIntent action."},{"ref":"AWS.LexModelBuilding.html#delete_intent_version/5","title":"AWS.LexModelBuilding.delete_intent_version/5","type":"function","doc":"Deletes a specific version of an intent. To delete all versions of a intent, use the DeleteIntent operation. This operation requires permissions for the lex:DeleteIntentVersion action."},{"ref":"AWS.LexModelBuilding.html#delete_slot_type/4","title":"AWS.LexModelBuilding.delete_slot_type/4","type":"function","doc":"Deletes all versions of the slot type, including the $LATEST version. To delete a specific version of the slot type, use the DeleteSlotTypeVersion operation. You can delete a version of a slot type only if it is not referenced. To delete a slot type that is referred to in one or more intents, you must remove those references first. If you get the ResourceInUseException exception, the exception provides an example reference that shows the intent where the slot type is referenced. To remove the reference to the slot type, either update the intent or delete it. If you get the same exception when you attempt to delete the slot type again, repeat until the slot type has no references and the DeleteSlotType call is successful. This operation requires permission for the lex:DeleteSlotType action."},{"ref":"AWS.LexModelBuilding.html#delete_slot_type_version/5","title":"AWS.LexModelBuilding.delete_slot_type_version/5","type":"function","doc":"Deletes a specific version of a slot type. To delete all versions of a slot type, use the DeleteSlotType operation. This operation requires permissions for the lex:DeleteSlotTypeVersion action."},{"ref":"AWS.LexModelBuilding.html#delete_utterances/5","title":"AWS.LexModelBuilding.delete_utterances/5","type":"function","doc":"Deletes stored utterances. Amazon Lex stores the utterances that users send to your bot. Utterances are stored for 15 days for use with the GetUtterancesView operation, and then stored indefinitely for use in improving the ability of your bot to respond to user input. Use the DeleteUtterances operation to manually delete stored utterances for a specific user. When you use the DeleteUtterances operation, utterances stored for improving your bot&#39;s ability to respond to user input are deleted immediately. Utterances stored for use with the GetUtterancesView operation are deleted after 15 days. This operation requires permissions for the lex:DeleteUtterances action."},{"ref":"AWS.LexModelBuilding.html#get_bot/4","title":"AWS.LexModelBuilding.get_bot/4","type":"function","doc":"Returns metadata information for a specific bot. You must provide the bot name and the bot version or alias. This operation requires permissions for the lex:GetBot action."},{"ref":"AWS.LexModelBuilding.html#get_bot_alias/4","title":"AWS.LexModelBuilding.get_bot_alias/4","type":"function","doc":"Returns information about an Amazon Lex bot alias. For more information about aliases, see versioning-aliases. This operation requires permissions for the lex:GetBotAlias action."},{"ref":"AWS.LexModelBuilding.html#get_bot_aliases/6","title":"AWS.LexModelBuilding.get_bot_aliases/6","type":"function","doc":"Returns a list of aliases for a specified Amazon Lex bot. This operation requires permissions for the lex:GetBotAliases action."},{"ref":"AWS.LexModelBuilding.html#get_bot_channel_association/5","title":"AWS.LexModelBuilding.get_bot_channel_association/5","type":"function","doc":"Returns information about the association between an Amazon Lex bot and a messaging platform. This operation requires permissions for the lex:GetBotChannelAssociation action."},{"ref":"AWS.LexModelBuilding.html#get_bot_channel_associations/7","title":"AWS.LexModelBuilding.get_bot_channel_associations/7","type":"function","doc":"Returns a list of all of the channels associated with the specified bot. The GetBotChannelAssociations operation requires permissions for the lex:GetBotChannelAssociations action."},{"ref":"AWS.LexModelBuilding.html#get_bot_versions/5","title":"AWS.LexModelBuilding.get_bot_versions/5","type":"function","doc":"Gets information about all of the versions of a bot. The GetBotVersions operation returns a BotMetadata object for each version of a bot. For example, if a bot has three numbered versions, the GetBotVersions operation returns four BotMetadata objects in the response, one for each numbered version and one for the $LATEST version. The GetBotVersions operation always returns at least one version, the $LATEST version. This operation requires permissions for the lex:GetBotVersions action."},{"ref":"AWS.LexModelBuilding.html#get_bots/5","title":"AWS.LexModelBuilding.get_bots/5","type":"function","doc":"Returns bot information as follows: If you provide the nameContains field, the response includes information for the $LATEST version of all bots whose name contains the specified string. If you don&#39;t specify the nameContains field, the operation returns information about the $LATEST version of all of your bots. This operation requires permission for the lex:GetBots action."},{"ref":"AWS.LexModelBuilding.html#get_builtin_intent/3","title":"AWS.LexModelBuilding.get_builtin_intent/3","type":"function","doc":"Returns information about a built-in intent. This operation requires permission for the lex:GetBuiltinIntent action."},{"ref":"AWS.LexModelBuilding.html#get_builtin_intents/6","title":"AWS.LexModelBuilding.get_builtin_intents/6","type":"function","doc":"Gets a list of built-in intents that meet the specified criteria. This operation requires permission for the lex:GetBuiltinIntents action."},{"ref":"AWS.LexModelBuilding.html#get_builtin_slot_types/6","title":"AWS.LexModelBuilding.get_builtin_slot_types/6","type":"function","doc":"Gets a list of built-in slot types that meet the specified criteria. For a list of built-in slot types, see Slot Type Reference in the Alexa Skills Kit. This operation requires permission for the lex:GetBuiltInSlotTypes action."},{"ref":"AWS.LexModelBuilding.html#get_export/6","title":"AWS.LexModelBuilding.get_export/6","type":"function","doc":"Exports the contents of a Amazon Lex resource in a specified format."},{"ref":"AWS.LexModelBuilding.html#get_import/3","title":"AWS.LexModelBuilding.get_import/3","type":"function","doc":"Gets information about an import job started with the StartImport operation."},{"ref":"AWS.LexModelBuilding.html#get_intent/4","title":"AWS.LexModelBuilding.get_intent/4","type":"function","doc":"Returns information about an intent. In addition to the intent name, you must specify the intent version. This operation requires permissions to perform the lex:GetIntent action."},{"ref":"AWS.LexModelBuilding.html#get_intent_versions/5","title":"AWS.LexModelBuilding.get_intent_versions/5","type":"function","doc":"Gets information about all of the versions of an intent. The GetIntentVersions operation returns an IntentMetadata object for each version of an intent. For example, if an intent has three numbered versions, the GetIntentVersions operation returns four IntentMetadata objects in the response, one for each numbered version and one for the $LATEST version. The GetIntentVersions operation always returns at least one version, the $LATEST version. This operation requires permissions for the lex:GetIntentVersions action."},{"ref":"AWS.LexModelBuilding.html#get_intents/5","title":"AWS.LexModelBuilding.get_intents/5","type":"function","doc":"Returns intent information as follows: If you specify the nameContains field, returns the $LATEST version of all intents that contain the specified string. If you don&#39;t specify the nameContains field, returns information about the $LATEST version of all intents. The operation requires permission for the lex:GetIntents action."},{"ref":"AWS.LexModelBuilding.html#get_slot_type/4","title":"AWS.LexModelBuilding.get_slot_type/4","type":"function","doc":"Returns information about a specific version of a slot type. In addition to specifying the slot type name, you must specify the slot type version. This operation requires permissions for the lex:GetSlotType action."},{"ref":"AWS.LexModelBuilding.html#get_slot_type_versions/5","title":"AWS.LexModelBuilding.get_slot_type_versions/5","type":"function","doc":"Gets information about all versions of a slot type. The GetSlotTypeVersions operation returns a SlotTypeMetadata object for each version of a slot type. For example, if a slot type has three numbered versions, the GetSlotTypeVersions operation returns four SlotTypeMetadata objects in the response, one for each numbered version and one for the $LATEST version. The GetSlotTypeVersions operation always returns at least one version, the $LATEST version. This operation requires permissions for the lex:GetSlotTypeVersions action."},{"ref":"AWS.LexModelBuilding.html#get_slot_types/5","title":"AWS.LexModelBuilding.get_slot_types/5","type":"function","doc":"Returns slot type information as follows: If you specify the nameContains field, returns the $LATEST version of all slot types that contain the specified string. If you don&#39;t specify the nameContains field, returns information about the $LATEST version of all slot types. The operation requires permission for the lex:GetSlotTypes action."},{"ref":"AWS.LexModelBuilding.html#get_utterances_view/5","title":"AWS.LexModelBuilding.get_utterances_view/5","type":"function","doc":"Use the GetUtterancesView operation to get information about the utterances that your users have made to your bot. You can use this list to tune the utterances that your bot responds to. For example, say that you have created a bot to order flowers. After your users have used your bot for a while, use the GetUtterancesView operation to see the requests that they have made and whether they have been successful. You might find that the utterance &quot;I want flowers&quot; is not being recognized. You could add this utterance to the OrderFlowers intent so that your bot recognizes that utterance. After you publish a new version of a bot, you can get information about the old version and the new so that you can compare the performance across the two versions. Utterance statistics are generated once a day. Data is available for the last 15 days. You can request information for up to 5 versions of your bot in each request. Amazon Lex returns the most frequent utterances received by the bot in the last 15 days. The response contains information about a maximum of 100 utterances for each version. If you set childDirected field to true when you created your bot, or if you opted out of participating in improving Amazon Lex, utterances are not available. This operation requires permissions for the lex:GetUtterancesView action."},{"ref":"AWS.LexModelBuilding.html#list_tags_for_resource/3","title":"AWS.LexModelBuilding.list_tags_for_resource/3","type":"function","doc":"Gets a list of tags associated with the specified resource. Only bots, bot aliases, and bot channels can have tags associated with them."},{"ref":"AWS.LexModelBuilding.html#put_bot/4","title":"AWS.LexModelBuilding.put_bot/4","type":"function","doc":"Creates an Amazon Lex conversational bot or replaces an existing bot. When you create or update a bot you are only required to specify a name, a locale, and whether the bot is directed toward children under age 13. You can use this to add intents later, or to remove intents from an existing bot. When you create a bot with the minimum information, the bot is created or updated but Amazon Lex returns the responseFAILED. You can build the bot after you add one or more intents. For more information about Amazon Lex bots, seehow-it-works. If you specify the name of an existing bot, the fields in the request replace the existing values in the `$LATEST` version of the bot. Amazon Lex removes any fields that you don&#39;t provide values for in the request, except for the `idleTTLInSeconds` and `privacySettings` fields, which are set to their default values. If you don&#39;t specify values for required fields, Amazon Lex throws an exception. This operation requires permissions for the `lex:PutBot` action. For more information, see `security-iam`."},{"ref":"AWS.LexModelBuilding.html#put_bot_alias/5","title":"AWS.LexModelBuilding.put_bot_alias/5","type":"function","doc":"Creates an alias for the specified version of the bot or replaces an alias for the specified bot. To change the version of the bot that the alias points to, replace the alias. For more information about aliases, see versioning-aliases. This operation requires permissions for the lex:PutBotAlias action."},{"ref":"AWS.LexModelBuilding.html#put_intent/4","title":"AWS.LexModelBuilding.put_intent/4","type":"function","doc":"Creates an intent or replaces an existing intent. To define the interaction between the user and your bot, you use one or more intents. For a pizza ordering bot, for example, you would create an OrderPizza intent. To create an intent or replace an existing intent, you must provide the following: Intent name. For example, OrderPizza. Sample utterances. For example, &quot;Can I order a pizza, please.&quot; and &quot;I want to order a pizza.&quot; Information to be gathered. You specify slot types for the information that your bot will request from the user. You can specify standard slot types, such as a date or a time, or custom slot types such as the size and crust of a pizza. How the intent will be fulfilled. You can provide a Lambda function or configure the intent to return the intent information to the client application. If you use a Lambda function, when all of the intent information is available, Amazon Lex invokes your Lambda function. If you configure your intent to return the intent information to the client application. You can specify other optional information in the request, such as: A confirmation prompt to ask the user to confirm an intent. For example, &quot;Shall I order your pizza?&quot; A conclusion statement to send to the user after the intent has been fulfilled. For example, &quot;I placed your pizza order.&quot; A follow-up prompt that asks the user for additional activity. For example, asking &quot;Do you want to order a drink with your pizza?&quot; If you specify an existing intent name to update the intent, Amazon Lex replaces the values in the $LATEST version of the intent with the values in the request. Amazon Lex removes fields that you don&#39;t provide in the request. If you don&#39;t specify the required fields, Amazon Lex throws an exception. When you update the $LATEST version of an intent, the status field of any bot that uses the $LATEST version of the intent is set to NOT_BUILT. For more information, see how-it-works. This operation requires permissions for the lex:PutIntent action."},{"ref":"AWS.LexModelBuilding.html#put_slot_type/4","title":"AWS.LexModelBuilding.put_slot_type/4","type":"function","doc":"Creates a custom slot type or replaces an existing custom slot type. To create a custom slot type, specify a name for the slot type and a set of enumeration values, which are the values that a slot of this type can assume. For more information, see how-it-works. If you specify the name of an existing slot type, the fields in the request replace the existing values in the $LATEST version of the slot type. Amazon Lex removes the fields that you don&#39;t provide in the request. If you don&#39;t specify required fields, Amazon Lex throws an exception. When you update the $LATEST version of a slot type, if a bot uses the $LATEST version of an intent that contains the slot type, the bot&#39;s status field is set to NOT_BUILT. This operation requires permissions for the lex:PutSlotType action."},{"ref":"AWS.LexModelBuilding.html#start_import/3","title":"AWS.LexModelBuilding.start_import/3","type":"function","doc":"Starts a job to import a resource to Amazon Lex."},{"ref":"AWS.LexModelBuilding.html#tag_resource/4","title":"AWS.LexModelBuilding.tag_resource/4","type":"function","doc":"Adds the specified tags to the specified resource. If a tag key already exists, the existing value is replaced with the new value."},{"ref":"AWS.LexModelBuilding.html#untag_resource/4","title":"AWS.LexModelBuilding.untag_resource/4","type":"function","doc":"Removes tags from a bot, bot alias or bot channel."},{"ref":"AWS.LexRuntime.html","title":"AWS.LexRuntime","type":"module","doc":"Amazon Lex provides both build and runtime endpoints. Each endpoint provides a set of operations (API). Your conversational bot uses the runtime API to understand user utterances (user input text or voice). For example, suppose a user says &quot;I want pizza&quot;, your bot sends this input to Amazon Lex using the runtime API. Amazon Lex recognizes that the user request is for the OrderPizza intent (one of the intents defined in the bot). Then Amazon Lex engages in user conversation on behalf of the bot to elicit required information (slot values, such as pizza size and crust type), and then performs fulfillment activity (that you configured when you created the bot). You use the build-time API to create and manage your Amazon Lex bot. For a list of build-time operations, see the build-time API, ."},{"ref":"AWS.LexRuntime.html#delete_session/6","title":"AWS.LexRuntime.delete_session/6","type":"function","doc":"Removes session information for a specified bot, alias, and user ID."},{"ref":"AWS.LexRuntime.html#get_session/6","title":"AWS.LexRuntime.get_session/6","type":"function","doc":"Returns session information for a specified bot, alias, and user ID."},{"ref":"AWS.LexRuntime.html#post_content/6","title":"AWS.LexRuntime.post_content/6","type":"function","doc":"Sends user input (text or speech) to Amazon Lex. Clients use this API to send text and audio requests to Amazon Lex at runtime. Amazon Lex interprets the user input using the machine learning model that it built for the bot. The PostContent operation supports audio input at 8kHz and 16kHz. You can use 8kHz audio to achieve higher speech recognition accuracy in telephone audio applications. In response, Amazon Lex returns the next message to convey to the user. Consider the following example messages: For a user input &quot;I would like a pizza,&quot; Amazon Lex might return a response with a message eliciting slot data (for example, PizzaSize): &quot;What size pizza would you like?&quot;. After the user provides all of the pizza order information, Amazon Lex might return a response with a message to get user confirmation: &quot;Order the pizza?&quot;. After the user replies &quot;Yes&quot; to the confirmation prompt, Amazon Lex might return a conclusion statement: &quot;Thank you, your cheese pizza has been ordered.&quot;. Not all Amazon Lex messages require a response from the user. For example, conclusion statements do not require a response. Some messages require only a yes or no response. In addition to the message, Amazon Lex provides additional context about the message in the response that you can use to enhance client behavior, such as displaying the appropriate client user interface. Consider the following examples: If the message is to elicit slot data, Amazon Lex returns the following context information: x-amz-lex-dialog-state header set to ElicitSlot x-amz-lex-intent-name header set to the intent name in the current context x-amz-lex-slot-to-elicit header set to the slot name for which the message is eliciting information x-amz-lex-slots header set to a map of slots configured for the intent with their current values If the message is a confirmation prompt, the x-amz-lex-dialog-state header is set to Confirmation and the x-amz-lex-slot-to-elicit header is omitted. If the message is a clarification prompt configured for the intent, indicating that the user intent is not understood, the x-amz-dialog-state header is set to ElicitIntent and the x-amz-slot-to-elicit header is omitted. In addition, Amazon Lex also returns your application-specific sessionAttributes. For more information, see Managing Conversation Context."},{"ref":"AWS.LexRuntime.html#post_text/6","title":"AWS.LexRuntime.post_text/6","type":"function","doc":"Sends user input to Amazon Lex. Client applications can use this API to send requests to Amazon Lex at runtime. Amazon Lex then interprets the user input using the machine learning model it built for the bot. In response, Amazon Lex returns the next message to convey to the user an optional responseCard to display. Consider the following example messages: For a user input &quot;I would like a pizza&quot;, Amazon Lex might return a response with a message eliciting slot data (for example, PizzaSize): &quot;What size pizza would you like?&quot; After the user provides all of the pizza order information, Amazon Lex might return a response with a message to obtain user confirmation &quot;Proceed with the pizza order?&quot;. After the user replies to a confirmation prompt with a &quot;yes&quot;, Amazon Lex might return a conclusion statement: &quot;Thank you, your cheese pizza has been ordered.&quot;. Not all Amazon Lex messages require a user response. For example, a conclusion statement does not require a response. Some messages require only a &quot;yes&quot; or &quot;no&quot; user response. In addition to the message, Amazon Lex provides additional context about the message in the response that you might use to enhance client behavior, for example, to display the appropriate client user interface. These are the slotToElicit, dialogState, intentName, and slots fields in the response. Consider the following examples: If the message is to elicit slot data, Amazon Lex returns the following context information: dialogState set to ElicitSlot intentName set to the intent name in the current context slotToElicit set to the slot name for which the message is eliciting information slots set to a map of slots, configured for the intent, with currently known values If the message is a confirmation prompt, the dialogState is set to ConfirmIntent and SlotToElicit is set to null. If the message is a clarification prompt (configured for the intent) that indicates that user intent is not understood, the dialogState is set to ElicitIntent and slotToElicit is set to null. In addition, Amazon Lex also returns your application-specific sessionAttributes. For more information, see Managing Conversation Context."},{"ref":"AWS.LexRuntime.html#put_session/6","title":"AWS.LexRuntime.put_session/6","type":"function","doc":"Creates a new session or modifies an existing session with an Amazon Lex bot. Use this operation to enable your application to set the state of the bot. For more information, see Managing Sessions."},{"ref":"AWS.LicenseManager.html","title":"AWS.LicenseManager","type":"module","doc":"AWS License Manager AWS License Manager makes it easier to manage licenses from software vendors across multiple AWS accounts and on-premises servers."},{"ref":"AWS.LicenseManager.html#create_license_configuration/3","title":"AWS.LicenseManager.create_license_configuration/3","type":"function","doc":"Creates a license configuration. A license configuration is an abstraction of a customer license agreement that can be consumed and enforced by License Manager. Components include specifications for the license type (licensing by instance, socket, CPU, or vCPU), allowed tenancy (shared tenancy, Dedicated Instance, Dedicated Host, or all of these), license affinity to host (how long a license must be associated with a host), and the number of licenses purchased and used."},{"ref":"AWS.LicenseManager.html#delete_license_configuration/3","title":"AWS.LicenseManager.delete_license_configuration/3","type":"function","doc":"Deletes the specified license configuration. You cannot delete a license configuration that is in use."},{"ref":"AWS.LicenseManager.html#get_license_configuration/3","title":"AWS.LicenseManager.get_license_configuration/3","type":"function","doc":"Gets detailed information about the specified license configuration."},{"ref":"AWS.LicenseManager.html#get_service_settings/3","title":"AWS.LicenseManager.get_service_settings/3","type":"function","doc":"Gets the License Manager settings for the current Region."},{"ref":"AWS.LicenseManager.html#list_associations_for_license_configuration/3","title":"AWS.LicenseManager.list_associations_for_license_configuration/3","type":"function","doc":"Lists the resource associations for the specified license configuration. Resource associations need not consume licenses from a license configuration. For example, an AMI or a stopped instance might not consume a license (depending on the license rules)."},{"ref":"AWS.LicenseManager.html#list_failures_for_license_configuration_operations/3","title":"AWS.LicenseManager.list_failures_for_license_configuration_operations/3","type":"function","doc":"Lists the license configuration operations that failed."},{"ref":"AWS.LicenseManager.html#list_license_configurations/3","title":"AWS.LicenseManager.list_license_configurations/3","type":"function","doc":"Lists the license configurations for your account."},{"ref":"AWS.LicenseManager.html#list_license_specifications_for_resource/3","title":"AWS.LicenseManager.list_license_specifications_for_resource/3","type":"function","doc":"Describes the license configurations for the specified resource."},{"ref":"AWS.LicenseManager.html#list_resource_inventory/3","title":"AWS.LicenseManager.list_resource_inventory/3","type":"function","doc":"Lists resources managed using Systems Manager inventory."},{"ref":"AWS.LicenseManager.html#list_tags_for_resource/3","title":"AWS.LicenseManager.list_tags_for_resource/3","type":"function","doc":"Lists the tags for the specified license configuration."},{"ref":"AWS.LicenseManager.html#list_usage_for_license_configuration/3","title":"AWS.LicenseManager.list_usage_for_license_configuration/3","type":"function","doc":"Lists all license usage records for a license configuration, displaying license consumption details by resource at a selected point in time. Use this action to audit the current license consumption for any license inventory and configuration."},{"ref":"AWS.LicenseManager.html#tag_resource/3","title":"AWS.LicenseManager.tag_resource/3","type":"function","doc":"Adds the specified tags to the specified license configuration."},{"ref":"AWS.LicenseManager.html#untag_resource/3","title":"AWS.LicenseManager.untag_resource/3","type":"function","doc":"Removes the specified tags from the specified license configuration."},{"ref":"AWS.LicenseManager.html#update_license_configuration/3","title":"AWS.LicenseManager.update_license_configuration/3","type":"function","doc":"Modifies the attributes of an existing license configuration."},{"ref":"AWS.LicenseManager.html#update_license_specifications_for_resource/3","title":"AWS.LicenseManager.update_license_specifications_for_resource/3","type":"function","doc":"Adds or removes the specified license configurations for the specified AWS resource. You can update the license specifications of AMIs, instances, and hosts. You cannot update the license specifications for launch templates and AWS CloudFormation templates, as they send license configurations to the operation that creates the resource."},{"ref":"AWS.LicenseManager.html#update_service_settings/3","title":"AWS.LicenseManager.update_service_settings/3","type":"function","doc":"Updates License Manager settings for the current Region."},{"ref":"AWS.Lightsail.html","title":"AWS.Lightsail","type":"module","doc":"Amazon Lightsail is the easiest way to get started with Amazon Web Services (AWS) for developers who need to build websites or web applications. It includes everything you need to launch your project quickly  instances (virtual private servers), managed databases, SSD-based block storage, static IP addresses, load balancers, content delivery network (CDN) distributions, DNS management of registered domains, and snapshots (backups)  for a low, predictable monthly price. You can manage your Lightsail resources using the Lightsail console, Lightsail API, AWS Command Line Interface (AWS CLI), or SDKs. For more information about Lightsail concepts and tasks, see the Lightsail Dev Guide. This API Reference provides detailed information about the actions, data types, parameters, and errors of the Lightsail service. For more information about the supported AWS Regions, endpoints, and service quotas for the Lightsail service, see Amazon Lightsail Endpoints and Quotas in the AWS General Reference."},{"ref":"AWS.Lightsail.html#allocate_static_ip/3","title":"AWS.Lightsail.allocate_static_ip/3","type":"function","doc":"Allocates a static IP address."},{"ref":"AWS.Lightsail.html#attach_certificate_to_distribution/3","title":"AWS.Lightsail.attach_certificate_to_distribution/3","type":"function","doc":"Attaches an SSL/TLS certificate to your Amazon Lightsail content delivery network (CDN) distribution. After the certificate is attached, your distribution accepts HTTPS traffic for all of the domains that are associated with the certificate. Use the CreateCertificate action to create a certificate that you can attach to your distribution. Only certificates created in the us-east-1 AWS Region can be attached to Lightsail distributions. Lightsail distributions are global resources that can reference an origin in any AWS Region, and distribute its content globally. However, all distributions are located in the us-east-1 Region."},{"ref":"AWS.Lightsail.html#attach_disk/3","title":"AWS.Lightsail.attach_disk/3","type":"function","doc":"Attaches a block storage disk to a running or stopped Lightsail instance and exposes it to the instance with the specified disk name. The attach disk operation supports tag-based access control via resource tags applied to the resource identified by disk name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#attach_instances_to_load_balancer/3","title":"AWS.Lightsail.attach_instances_to_load_balancer/3","type":"function","doc":"Attaches one or more Lightsail instances to a load balancer. After some time, the instances are attached to the load balancer and the health check status is available. The attach instances to load balancer operation supports tag-based access control via resource tags applied to the resource identified by load balancer name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#attach_load_balancer_tls_certificate/3","title":"AWS.Lightsail.attach_load_balancer_tls_certificate/3","type":"function","doc":"Attaches a Transport Layer Security (TLS) certificate to your load balancer. TLS is just an updated, more secure version of Secure Socket Layer (SSL). Once you create and validate your certificate, you can attach it to your load balancer. You can also use this API to rotate the certificates on your account. Use the AttachLoadBalancerTlsCertificate action with the non-attached certificate, and it will replace the existing one and become the attached certificate. The AttachLoadBalancerTlsCertificate operation supports tag-based access control via resource tags applied to the resource identified by load balancer name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#attach_static_ip/3","title":"AWS.Lightsail.attach_static_ip/3","type":"function","doc":"Attaches a static IP address to a specific Amazon Lightsail instance."},{"ref":"AWS.Lightsail.html#close_instance_public_ports/3","title":"AWS.Lightsail.close_instance_public_ports/3","type":"function","doc":"Closes ports for a specific Amazon Lightsail instance. The CloseInstancePublicPorts action supports tag-based access control via resource tags applied to the resource identified by instanceName. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#copy_snapshot/3","title":"AWS.Lightsail.copy_snapshot/3","type":"function","doc":"Copies a manual snapshot of an instance or disk as another manual snapshot, or copies an automatic snapshot of an instance or disk as a manual snapshot. This operation can also be used to copy a manual or automatic snapshot of an instance or a disk from one AWS Region to another in Amazon Lightsail. When copying a manual snapshot, be sure to define the source region, source snapshot name, and target snapshot name parameters. When copying an automatic snapshot, be sure to define the source region, source resource name, target snapshot name, and either the restore date or the use latest restorable auto snapshot parameters."},{"ref":"AWS.Lightsail.html#create_certificate/3","title":"AWS.Lightsail.create_certificate/3","type":"function","doc":"Creates an SSL/TLS certificate for a Amazon Lightsail content delivery network (CDN) distribution. After the certificate is created, use the AttachCertificateToDistribution action to attach the certificate to your distribution. Only certificates created in the us-east-1 AWS Region can be attached to Lightsail distributions. Lightsail distributions are global resources that can reference an origin in any AWS Region, and distribute its content globally. However, all distributions are located in the us-east-1 Region."},{"ref":"AWS.Lightsail.html#create_cloud_formation_stack/3","title":"AWS.Lightsail.create_cloud_formation_stack/3","type":"function","doc":"Creates an AWS CloudFormation stack, which creates a new Amazon EC2 instance from an exported Amazon Lightsail snapshot. This operation results in a CloudFormation stack record that can be used to track the AWS CloudFormation stack created. Use the get cloud formation stack records operation to get a list of the CloudFormation stacks created. Wait until after your new Amazon EC2 instance is created before running the create cloud formation stack operation again with the same export snapshot record."},{"ref":"AWS.Lightsail.html#create_contact_method/3","title":"AWS.Lightsail.create_contact_method/3","type":"function","doc":"Creates an email or SMS text message contact method. A contact method is used to send you notifications about your Amazon Lightsail resources. You can add one email address and one mobile phone number contact method in each AWS Region. However, SMS text messaging is not supported in some AWS Regions, and SMS text messages cannot be sent to some countries/regions. For more information, see Notifications in Amazon Lightsail."},{"ref":"AWS.Lightsail.html#create_disk/3","title":"AWS.Lightsail.create_disk/3","type":"function","doc":"Creates a block storage disk that can be attached to an Amazon Lightsail instance in the same Availability Zone (e.g., us-east-2a). The create disk operation supports tag-based access control via request tags. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#create_disk_from_snapshot/3","title":"AWS.Lightsail.create_disk_from_snapshot/3","type":"function","doc":"Creates a block storage disk from a manual or automatic snapshot of a disk. The resulting disk can be attached to an Amazon Lightsail instance in the same Availability Zone (e.g., us-east-2a). The create disk from snapshot operation supports tag-based access control via request tags and resource tags applied to the resource identified by disk snapshot name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#create_disk_snapshot/3","title":"AWS.Lightsail.create_disk_snapshot/3","type":"function","doc":"Creates a snapshot of a block storage disk. You can use snapshots for backups, to make copies of disks, and to save data before shutting down a Lightsail instance. You can take a snapshot of an attached disk that is in use; however, snapshots only capture data that has been written to your disk at the time the snapshot command is issued. This may exclude any data that has been cached by any applications or the operating system. If you can pause any file systems on the disk long enough to take a snapshot, your snapshot should be complete. Nevertheless, if you cannot pause all file writes to the disk, you should unmount the disk from within the Lightsail instance, issue the create disk snapshot command, and then remount the disk to ensure a consistent and complete snapshot. You may remount and use your disk while the snapshot status is pending. You can also use this operation to create a snapshot of an instance&#39;s system volume. You might want to do this, for example, to recover data from the system volume of a botched instance or to create a backup of the system volume like you would for a block storage disk. To create a snapshot of a system volume, just define the instance name parameter when issuing the snapshot command, and a snapshot of the defined instance&#39;s system volume will be created. After the snapshot is available, you can create a block storage disk from the snapshot and attach it to a running instance to access the data on the disk. The create disk snapshot operation supports tag-based access control via request tags. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#create_distribution/3","title":"AWS.Lightsail.create_distribution/3","type":"function","doc":"Creates an Amazon Lightsail content delivery network (CDN) distribution. A distribution is a globally distributed network of caching servers that improve the performance of your website or web application hosted on a Lightsail instance. For more information, see Content delivery networks in Amazon Lightsail."},{"ref":"AWS.Lightsail.html#create_domain/3","title":"AWS.Lightsail.create_domain/3","type":"function","doc":"Creates a domain resource for the specified domain (e.g., example.com). The create domain operation supports tag-based access control via request tags. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#create_domain_entry/3","title":"AWS.Lightsail.create_domain_entry/3","type":"function","doc":"Creates one of the following entry records associated with the domain: Address (A), canonical name (CNAME), mail exchanger (MX), name server (NS), start of authority (SOA), service locator (SRV), or text (TXT). The create domain entry operation supports tag-based access control via resource tags applied to the resource identified by domain name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#create_instance_snapshot/3","title":"AWS.Lightsail.create_instance_snapshot/3","type":"function","doc":"Creates a snapshot of a specific virtual private server, or instance. You can use a snapshot to create a new instance that is based on that snapshot. The create instance snapshot operation supports tag-based access control via request tags. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#create_instances/3","title":"AWS.Lightsail.create_instances/3","type":"function","doc":"Creates one or more Amazon Lightsail instances. The create instances operation supports tag-based access control via request tags. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#create_instances_from_snapshot/3","title":"AWS.Lightsail.create_instances_from_snapshot/3","type":"function","doc":"Creates one or more new instances from a manual or automatic snapshot of an instance. The create instances from snapshot operation supports tag-based access control via request tags and resource tags applied to the resource identified by instance snapshot name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#create_key_pair/3","title":"AWS.Lightsail.create_key_pair/3","type":"function","doc":"Creates an SSH key pair. The create key pair operation supports tag-based access control via request tags. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#create_load_balancer/3","title":"AWS.Lightsail.create_load_balancer/3","type":"function","doc":"Creates a Lightsail load balancer. To learn more about deciding whether to load balance your application, see Configure your Lightsail instances for load balancing. You can create up to 5 load balancers per AWS Region in your account. When you create a load balancer, you can specify a unique name and port settings. To change additional load balancer settings, use the UpdateLoadBalancerAttribute operation. The create load balancer operation supports tag-based access control via request tags. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#create_load_balancer_tls_certificate/3","title":"AWS.Lightsail.create_load_balancer_tls_certificate/3","type":"function","doc":"Creates a Lightsail load balancer TLS certificate. TLS is just an updated, more secure version of Secure Socket Layer (SSL). The CreateLoadBalancerTlsCertificate operation supports tag-based access control via resource tags applied to the resource identified by load balancer name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#create_relational_database/3","title":"AWS.Lightsail.create_relational_database/3","type":"function","doc":"Creates a new database in Amazon Lightsail. The create relational database operation supports tag-based access control via request tags. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#create_relational_database_from_snapshot/3","title":"AWS.Lightsail.create_relational_database_from_snapshot/3","type":"function","doc":"Creates a new database from an existing database snapshot in Amazon Lightsail. You can create a new database from a snapshot in if something goes wrong with your original database, or to change it to a different plan, such as a high availability or standard plan. The create relational database from snapshot operation supports tag-based access control via request tags and resource tags applied to the resource identified by relationalDatabaseSnapshotName. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#create_relational_database_snapshot/3","title":"AWS.Lightsail.create_relational_database_snapshot/3","type":"function","doc":"Creates a snapshot of your database in Amazon Lightsail. You can use snapshots for backups, to make copies of a database, and to save data before deleting a database. The create relational database snapshot operation supports tag-based access control via request tags. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#delete_alarm/3","title":"AWS.Lightsail.delete_alarm/3","type":"function","doc":"Deletes an alarm. An alarm is used to monitor a single metric for one of your resources. When a metric condition is met, the alarm can notify you by email, SMS text message, and a banner displayed on the Amazon Lightsail console. For more information, see Alarms in Amazon Lightsail."},{"ref":"AWS.Lightsail.html#delete_auto_snapshot/3","title":"AWS.Lightsail.delete_auto_snapshot/3","type":"function","doc":"Deletes an automatic snapshot of an instance or disk. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#delete_certificate/3","title":"AWS.Lightsail.delete_certificate/3","type":"function","doc":"Deletes an SSL/TLS certificate for your Amazon Lightsail content delivery network (CDN) distribution. Certificates that are currently attached to a distribution cannot be deleted. Use the DetachCertificateFromDistribution action to detach a certificate from a distribution."},{"ref":"AWS.Lightsail.html#delete_contact_method/3","title":"AWS.Lightsail.delete_contact_method/3","type":"function","doc":"Deletes a contact method. A contact method is used to send you notifications about your Amazon Lightsail resources. You can add one email address and one mobile phone number contact method in each AWS Region. However, SMS text messaging is not supported in some AWS Regions, and SMS text messages cannot be sent to some countries/regions. For more information, see Notifications in Amazon Lightsail."},{"ref":"AWS.Lightsail.html#delete_disk/3","title":"AWS.Lightsail.delete_disk/3","type":"function","doc":"Deletes the specified block storage disk. The disk must be in the available state (not attached to a Lightsail instance). The disk may remain in the deleting state for several minutes. The delete disk operation supports tag-based access control via resource tags applied to the resource identified by disk name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#delete_disk_snapshot/3","title":"AWS.Lightsail.delete_disk_snapshot/3","type":"function","doc":"Deletes the specified disk snapshot. When you make periodic snapshots of a disk, the snapshots are incremental, and only the blocks on the device that have changed since your last snapshot are saved in the new snapshot. When you delete a snapshot, only the data not needed for any other snapshot is removed. So regardless of which prior snapshots have been deleted, all active snapshots will have access to all the information needed to restore the disk. The delete disk snapshot operation supports tag-based access control via resource tags applied to the resource identified by disk snapshot name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#delete_distribution/3","title":"AWS.Lightsail.delete_distribution/3","type":"function","doc":"Deletes your Amazon Lightsail content delivery network (CDN) distribution."},{"ref":"AWS.Lightsail.html#delete_domain/3","title":"AWS.Lightsail.delete_domain/3","type":"function","doc":"Deletes the specified domain recordset and all of its domain records. The delete domain operation supports tag-based access control via resource tags applied to the resource identified by domain name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#delete_domain_entry/3","title":"AWS.Lightsail.delete_domain_entry/3","type":"function","doc":"Deletes a specific domain entry. The delete domain entry operation supports tag-based access control via resource tags applied to the resource identified by domain name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#delete_instance/3","title":"AWS.Lightsail.delete_instance/3","type":"function","doc":"Deletes an Amazon Lightsail instance. The delete instance operation supports tag-based access control via resource tags applied to the resource identified by instance name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#delete_instance_snapshot/3","title":"AWS.Lightsail.delete_instance_snapshot/3","type":"function","doc":"Deletes a specific snapshot of a virtual private server (or instance). The delete instance snapshot operation supports tag-based access control via resource tags applied to the resource identified by instance snapshot name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#delete_key_pair/3","title":"AWS.Lightsail.delete_key_pair/3","type":"function","doc":"Deletes a specific SSH key pair. The delete key pair operation supports tag-based access control via resource tags applied to the resource identified by key pair name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#delete_known_host_keys/3","title":"AWS.Lightsail.delete_known_host_keys/3","type":"function","doc":"Deletes the known host key or certificate used by the Amazon Lightsail browser-based SSH or RDP clients to authenticate an instance. This operation enables the Lightsail browser-based SSH or RDP clients to connect to the instance after a host key mismatch. Perform this operation only if you were expecting the host key or certificate mismatch or if you are familiar with the new host key or certificate on the instance. For more information, see Troubleshooting connection issues when using the Amazon Lightsail browser-based SSH or RDP client."},{"ref":"AWS.Lightsail.html#delete_load_balancer/3","title":"AWS.Lightsail.delete_load_balancer/3","type":"function","doc":"Deletes a Lightsail load balancer and all its associated SSL/TLS certificates. Once the load balancer is deleted, you will need to create a new load balancer, create a new certificate, and verify domain ownership again. The delete load balancer operation supports tag-based access control via resource tags applied to the resource identified by load balancer name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#delete_load_balancer_tls_certificate/3","title":"AWS.Lightsail.delete_load_balancer_tls_certificate/3","type":"function","doc":"Deletes an SSL/TLS certificate associated with a Lightsail load balancer. The DeleteLoadBalancerTlsCertificate operation supports tag-based access control via resource tags applied to the resource identified by load balancer name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#delete_relational_database/3","title":"AWS.Lightsail.delete_relational_database/3","type":"function","doc":"Deletes a database in Amazon Lightsail. The delete relational database operation supports tag-based access control via resource tags applied to the resource identified by relationalDatabaseName. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#delete_relational_database_snapshot/3","title":"AWS.Lightsail.delete_relational_database_snapshot/3","type":"function","doc":"Deletes a database snapshot in Amazon Lightsail. The delete relational database snapshot operation supports tag-based access control via resource tags applied to the resource identified by relationalDatabaseName. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#detach_certificate_from_distribution/3","title":"AWS.Lightsail.detach_certificate_from_distribution/3","type":"function","doc":"Detaches an SSL/TLS certificate from your Amazon Lightsail content delivery network (CDN) distribution. After the certificate is detached, your distribution stops accepting traffic for all of the domains that are associated with the certificate."},{"ref":"AWS.Lightsail.html#detach_disk/3","title":"AWS.Lightsail.detach_disk/3","type":"function","doc":"Detaches a stopped block storage disk from a Lightsail instance. Make sure to unmount any file systems on the device within your operating system before stopping the instance and detaching the disk. The detach disk operation supports tag-based access control via resource tags applied to the resource identified by disk name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#detach_instances_from_load_balancer/3","title":"AWS.Lightsail.detach_instances_from_load_balancer/3","type":"function","doc":"Detaches the specified instances from a Lightsail load balancer. This operation waits until the instances are no longer needed before they are detached from the load balancer. The detach instances from load balancer operation supports tag-based access control via resource tags applied to the resource identified by load balancer name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#detach_static_ip/3","title":"AWS.Lightsail.detach_static_ip/3","type":"function","doc":"Detaches a static IP from the Amazon Lightsail instance to which it is attached."},{"ref":"AWS.Lightsail.html#disable_add_on/3","title":"AWS.Lightsail.disable_add_on/3","type":"function","doc":"Disables an add-on for an Amazon Lightsail resource. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#download_default_key_pair/3","title":"AWS.Lightsail.download_default_key_pair/3","type":"function","doc":"Downloads the default SSH key pair from the user&#39;s account."},{"ref":"AWS.Lightsail.html#enable_add_on/3","title":"AWS.Lightsail.enable_add_on/3","type":"function","doc":"Enables or modifies an add-on for an Amazon Lightsail resource. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#export_snapshot/3","title":"AWS.Lightsail.export_snapshot/3","type":"function","doc":"Exports an Amazon Lightsail instance or block storage disk snapshot to Amazon Elastic Compute Cloud (Amazon EC2). This operation results in an export snapshot record that can be used with the create cloud formation stack operation to create new Amazon EC2 instances. Exported instance snapshots appear in Amazon EC2 as Amazon Machine Images (AMIs), and the instance system disk appears as an Amazon Elastic Block Store (Amazon EBS) volume. Exported disk snapshots appear in Amazon EC2 as Amazon EBS volumes. Snapshots are exported to the same Amazon Web Services Region in Amazon EC2 as the source Lightsail snapshot. The export snapshot operation supports tag-based access control via resource tags applied to the resource identified by source snapshot name. For more information, see the Lightsail Dev Guide. Use the get instance snapshots or get disk snapshots operations to get a list of snapshots that you can export to Amazon EC2."},{"ref":"AWS.Lightsail.html#get_active_names/3","title":"AWS.Lightsail.get_active_names/3","type":"function","doc":"Returns the names of all active (not deleted) resources."},{"ref":"AWS.Lightsail.html#get_alarms/3","title":"AWS.Lightsail.get_alarms/3","type":"function","doc":"Returns information about the configured alarms. Specify an alarm name in your request to return information about a specific alarm, or specify a monitored resource name to return information about all alarms for a specific resource. An alarm is used to monitor a single metric for one of your resources. When a metric condition is met, the alarm can notify you by email, SMS text message, and a banner displayed on the Amazon Lightsail console. For more information, see Alarms in Amazon Lightsail."},{"ref":"AWS.Lightsail.html#get_auto_snapshots/3","title":"AWS.Lightsail.get_auto_snapshots/3","type":"function","doc":"Returns the available automatic snapshots for an instance or disk. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#get_blueprints/3","title":"AWS.Lightsail.get_blueprints/3","type":"function","doc":"Returns the list of available instance images, or blueprints. You can use a blueprint to create a new instance already running a specific operating system, as well as a preinstalled app or development stack. The software each instance is running depends on the blueprint image you choose. Use active blueprints when creating new instances. Inactive blueprints are listed to support customers with existing instances and are not necessarily available to create new instances. Blueprints are marked inactive when they become outdated due to operating system updates or new application releases."},{"ref":"AWS.Lightsail.html#get_bundles/3","title":"AWS.Lightsail.get_bundles/3","type":"function","doc":"Returns the list of bundles that are available for purchase. A bundle describes the specs for your virtual private server (or instance)."},{"ref":"AWS.Lightsail.html#get_certificates/3","title":"AWS.Lightsail.get_certificates/3","type":"function","doc":"Returns information about one or more Amazon Lightsail SSL/TLS certificates. To get a summary of a certificate, ommit includeCertificateDetails from your request. The response will include only the certificate Amazon Resource Name (ARN), certificate name, domain name, and tags."},{"ref":"AWS.Lightsail.html#get_cloud_formation_stack_records/3","title":"AWS.Lightsail.get_cloud_formation_stack_records/3","type":"function","doc":"Returns the CloudFormation stack record created as a result of the create cloud formation stack operation. An AWS CloudFormation stack is used to create a new Amazon EC2 instance from an exported Lightsail snapshot."},{"ref":"AWS.Lightsail.html#get_contact_methods/3","title":"AWS.Lightsail.get_contact_methods/3","type":"function","doc":"Returns information about the configured contact methods. Specify a protocol in your request to return information about a specific contact method. A contact method is used to send you notifications about your Amazon Lightsail resources. You can add one email address and one mobile phone number contact method in each AWS Region. However, SMS text messaging is not supported in some AWS Regions, and SMS text messages cannot be sent to some countries/regions. For more information, see Notifications in Amazon Lightsail."},{"ref":"AWS.Lightsail.html#get_disk/3","title":"AWS.Lightsail.get_disk/3","type":"function","doc":"Returns information about a specific block storage disk."},{"ref":"AWS.Lightsail.html#get_disk_snapshot/3","title":"AWS.Lightsail.get_disk_snapshot/3","type":"function","doc":"Returns information about a specific block storage disk snapshot."},{"ref":"AWS.Lightsail.html#get_disk_snapshots/3","title":"AWS.Lightsail.get_disk_snapshots/3","type":"function","doc":"Returns information about all block storage disk snapshots in your AWS account and region."},{"ref":"AWS.Lightsail.html#get_disks/3","title":"AWS.Lightsail.get_disks/3","type":"function","doc":"Returns information about all block storage disks in your AWS account and region."},{"ref":"AWS.Lightsail.html#get_distribution_bundles/3","title":"AWS.Lightsail.get_distribution_bundles/3","type":"function","doc":"Returns the list bundles that can be applied to you Amazon Lightsail content delivery network (CDN) distributions. A distribution bundle specifies the monthly network transfer quota and monthly cost of your dsitribution."},{"ref":"AWS.Lightsail.html#get_distribution_latest_cache_reset/3","title":"AWS.Lightsail.get_distribution_latest_cache_reset/3","type":"function","doc":"Returns the timestamp and status of the last cache reset of a specific Amazon Lightsail content delivery network (CDN) distribution."},{"ref":"AWS.Lightsail.html#get_distribution_metric_data/3","title":"AWS.Lightsail.get_distribution_metric_data/3","type":"function","doc":"Returns the data points of a specific metric for an Amazon Lightsail content delivery network (CDN) distribution. Metrics report the utilization of your resources, and the error counts generated by them. Monitor and collect metric data regularly to maintain the reliability, availability, and performance of your resources."},{"ref":"AWS.Lightsail.html#get_distributions/3","title":"AWS.Lightsail.get_distributions/3","type":"function","doc":"Returns information about one or more of your Amazon Lightsail content delivery network (CDN) distributions."},{"ref":"AWS.Lightsail.html#get_domain/3","title":"AWS.Lightsail.get_domain/3","type":"function","doc":"Returns information about a specific domain recordset."},{"ref":"AWS.Lightsail.html#get_domains/3","title":"AWS.Lightsail.get_domains/3","type":"function","doc":"Returns a list of all domains in the user&#39;s account."},{"ref":"AWS.Lightsail.html#get_export_snapshot_records/3","title":"AWS.Lightsail.get_export_snapshot_records/3","type":"function","doc":"Returns the export snapshot record created as a result of the export snapshot operation. An export snapshot record can be used to create a new Amazon EC2 instance and its related resources with the create cloud formation stack operation."},{"ref":"AWS.Lightsail.html#get_instance/3","title":"AWS.Lightsail.get_instance/3","type":"function","doc":"Returns information about a specific Amazon Lightsail instance, which is a virtual private server."},{"ref":"AWS.Lightsail.html#get_instance_access_details/3","title":"AWS.Lightsail.get_instance_access_details/3","type":"function","doc":"Returns temporary SSH keys you can use to connect to a specific virtual private server, or instance. The get instance access details operation supports tag-based access control via resource tags applied to the resource identified by instance name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#get_instance_metric_data/3","title":"AWS.Lightsail.get_instance_metric_data/3","type":"function","doc":"Returns the data points for the specified Amazon Lightsail instance metric, given an instance name. Metrics report the utilization of your resources, and the error counts generated by them. Monitor and collect metric data regularly to maintain the reliability, availability, and performance of your resources."},{"ref":"AWS.Lightsail.html#get_instance_port_states/3","title":"AWS.Lightsail.get_instance_port_states/3","type":"function","doc":"Returns the firewall port states for a specific Amazon Lightsail instance, the IP addresses allowed to connect to the instance through the ports, and the protocol."},{"ref":"AWS.Lightsail.html#get_instance_snapshot/3","title":"AWS.Lightsail.get_instance_snapshot/3","type":"function","doc":"Returns information about a specific instance snapshot."},{"ref":"AWS.Lightsail.html#get_instance_snapshots/3","title":"AWS.Lightsail.get_instance_snapshots/3","type":"function","doc":"Returns all instance snapshots for the user&#39;s account."},{"ref":"AWS.Lightsail.html#get_instance_state/3","title":"AWS.Lightsail.get_instance_state/3","type":"function","doc":"Returns the state of a specific instance. Works on one instance at a time."},{"ref":"AWS.Lightsail.html#get_instances/3","title":"AWS.Lightsail.get_instances/3","type":"function","doc":"Returns information about all Amazon Lightsail virtual private servers, or instances."},{"ref":"AWS.Lightsail.html#get_key_pair/3","title":"AWS.Lightsail.get_key_pair/3","type":"function","doc":"Returns information about a specific key pair."},{"ref":"AWS.Lightsail.html#get_key_pairs/3","title":"AWS.Lightsail.get_key_pairs/3","type":"function","doc":"Returns information about all key pairs in the user&#39;s account."},{"ref":"AWS.Lightsail.html#get_load_balancer/3","title":"AWS.Lightsail.get_load_balancer/3","type":"function","doc":"Returns information about the specified Lightsail load balancer."},{"ref":"AWS.Lightsail.html#get_load_balancer_metric_data/3","title":"AWS.Lightsail.get_load_balancer_metric_data/3","type":"function","doc":"Returns information about health metrics for your Lightsail load balancer. Metrics report the utilization of your resources, and the error counts generated by them. Monitor and collect metric data regularly to maintain the reliability, availability, and performance of your resources."},{"ref":"AWS.Lightsail.html#get_load_balancer_tls_certificates/3","title":"AWS.Lightsail.get_load_balancer_tls_certificates/3","type":"function","doc":"Returns information about the TLS certificates that are associated with the specified Lightsail load balancer. TLS is just an updated, more secure version of Secure Socket Layer (SSL). You can have a maximum of 2 certificates associated with a Lightsail load balancer. One is active and the other is inactive."},{"ref":"AWS.Lightsail.html#get_load_balancers/3","title":"AWS.Lightsail.get_load_balancers/3","type":"function","doc":"Returns information about all load balancers in an account."},{"ref":"AWS.Lightsail.html#get_operation/3","title":"AWS.Lightsail.get_operation/3","type":"function","doc":"Returns information about a specific operation. Operations include events such as when you create an instance, allocate a static IP, attach a static IP, and so on."},{"ref":"AWS.Lightsail.html#get_operations/3","title":"AWS.Lightsail.get_operations/3","type":"function","doc":"Returns information about all operations. Results are returned from oldest to newest, up to a maximum of 200. Results can be paged by making each subsequent call to GetOperations use the maximum (last) statusChangedAt value from the previous request."},{"ref":"AWS.Lightsail.html#get_operations_for_resource/3","title":"AWS.Lightsail.get_operations_for_resource/3","type":"function","doc":"Gets operations for a specific resource (e.g., an instance or a static IP)."},{"ref":"AWS.Lightsail.html#get_regions/3","title":"AWS.Lightsail.get_regions/3","type":"function","doc":"Returns a list of all valid regions for Amazon Lightsail. Use the include availability zones parameter to also return the Availability Zones in a region."},{"ref":"AWS.Lightsail.html#get_relational_database/3","title":"AWS.Lightsail.get_relational_database/3","type":"function","doc":"Returns information about a specific database in Amazon Lightsail."},{"ref":"AWS.Lightsail.html#get_relational_database_blueprints/3","title":"AWS.Lightsail.get_relational_database_blueprints/3","type":"function","doc":"Returns a list of available database blueprints in Amazon Lightsail. A blueprint describes the major engine version of a database. You can use a blueprint ID to create a new database that runs a specific database engine."},{"ref":"AWS.Lightsail.html#get_relational_database_bundles/3","title":"AWS.Lightsail.get_relational_database_bundles/3","type":"function","doc":"Returns the list of bundles that are available in Amazon Lightsail. A bundle describes the performance specifications for a database. You can use a bundle ID to create a new database with explicit performance specifications."},{"ref":"AWS.Lightsail.html#get_relational_database_events/3","title":"AWS.Lightsail.get_relational_database_events/3","type":"function","doc":"Returns a list of events for a specific database in Amazon Lightsail."},{"ref":"AWS.Lightsail.html#get_relational_database_log_events/3","title":"AWS.Lightsail.get_relational_database_log_events/3","type":"function","doc":"Returns a list of log events for a database in Amazon Lightsail."},{"ref":"AWS.Lightsail.html#get_relational_database_log_streams/3","title":"AWS.Lightsail.get_relational_database_log_streams/3","type":"function","doc":"Returns a list of available log streams for a specific database in Amazon Lightsail."},{"ref":"AWS.Lightsail.html#get_relational_database_master_user_password/3","title":"AWS.Lightsail.get_relational_database_master_user_password/3","type":"function","doc":"Returns the current, previous, or pending versions of the master user password for a Lightsail database. The GetRelationalDatabaseMasterUserPassword operation supports tag-based access control via resource tags applied to the resource identified by relationalDatabaseName."},{"ref":"AWS.Lightsail.html#get_relational_database_metric_data/3","title":"AWS.Lightsail.get_relational_database_metric_data/3","type":"function","doc":"Returns the data points of the specified metric for a database in Amazon Lightsail. Metrics report the utilization of your resources, and the error counts generated by them. Monitor and collect metric data regularly to maintain the reliability, availability, and performance of your resources."},{"ref":"AWS.Lightsail.html#get_relational_database_parameters/3","title":"AWS.Lightsail.get_relational_database_parameters/3","type":"function","doc":"Returns all of the runtime parameters offered by the underlying database software, or engine, for a specific database in Amazon Lightsail. In addition to the parameter names and values, this operation returns other information about each parameter. This information includes whether changes require a reboot, whether the parameter is modifiable, the allowed values, and the data types."},{"ref":"AWS.Lightsail.html#get_relational_database_snapshot/3","title":"AWS.Lightsail.get_relational_database_snapshot/3","type":"function","doc":"Returns information about a specific database snapshot in Amazon Lightsail."},{"ref":"AWS.Lightsail.html#get_relational_database_snapshots/3","title":"AWS.Lightsail.get_relational_database_snapshots/3","type":"function","doc":"Returns information about all of your database snapshots in Amazon Lightsail."},{"ref":"AWS.Lightsail.html#get_relational_databases/3","title":"AWS.Lightsail.get_relational_databases/3","type":"function","doc":"Returns information about all of your databases in Amazon Lightsail."},{"ref":"AWS.Lightsail.html#get_static_ip/3","title":"AWS.Lightsail.get_static_ip/3","type":"function","doc":"Returns information about a specific static IP."},{"ref":"AWS.Lightsail.html#get_static_ips/3","title":"AWS.Lightsail.get_static_ips/3","type":"function","doc":"Returns information about all static IPs in the user&#39;s account."},{"ref":"AWS.Lightsail.html#import_key_pair/3","title":"AWS.Lightsail.import_key_pair/3","type":"function","doc":"Imports a public SSH key from a specific key pair."},{"ref":"AWS.Lightsail.html#is_vpc_peered/3","title":"AWS.Lightsail.is_vpc_peered/3","type":"function","doc":"Returns a Boolean value indicating whether your Lightsail VPC is peered."},{"ref":"AWS.Lightsail.html#open_instance_public_ports/3","title":"AWS.Lightsail.open_instance_public_ports/3","type":"function","doc":"Opens ports for a specific Amazon Lightsail instance, and specifies the IP addresses allowed to connect to the instance through the ports, and the protocol. The OpenInstancePublicPorts action supports tag-based access control via resource tags applied to the resource identified by instanceName. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#peer_vpc/3","title":"AWS.Lightsail.peer_vpc/3","type":"function","doc":"Tries to peer the Lightsail VPC with the user&#39;s default VPC."},{"ref":"AWS.Lightsail.html#put_alarm/3","title":"AWS.Lightsail.put_alarm/3","type":"function","doc":"Creates or updates an alarm, and associates it with the specified metric. An alarm is used to monitor a single metric for one of your resources. When a metric condition is met, the alarm can notify you by email, SMS text message, and a banner displayed on the Amazon Lightsail console. For more information, see Alarms in Amazon Lightsail. When this action creates an alarm, the alarm state is immediately set to INSUFFICIENT_DATA. The alarm is then evaluated and its state is set appropriately. Any actions associated with the new state are then executed. When you update an existing alarm, its state is left unchanged, but the update completely overwrites the previous configuration of the alarm. The alarm is then evaluated with the updated configuration."},{"ref":"AWS.Lightsail.html#put_instance_public_ports/3","title":"AWS.Lightsail.put_instance_public_ports/3","type":"function","doc":"Opens ports for a specific Amazon Lightsail instance, and specifies the IP addresses allowed to connect to the instance through the ports, and the protocol. This action also closes all currently open ports that are not included in the request. Include all of the ports and the protocols you want to open in your PutInstancePublicPortsrequest. Or use the OpenInstancePublicPorts action to open ports without closing currently open ports. The PutInstancePublicPorts action supports tag-based access control via resource tags applied to the resource identified by instanceName. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#reboot_instance/3","title":"AWS.Lightsail.reboot_instance/3","type":"function","doc":"Restarts a specific instance. The reboot instance operation supports tag-based access control via resource tags applied to the resource identified by instance name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#reboot_relational_database/3","title":"AWS.Lightsail.reboot_relational_database/3","type":"function","doc":"Restarts a specific database in Amazon Lightsail. The reboot relational database operation supports tag-based access control via resource tags applied to the resource identified by relationalDatabaseName. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#release_static_ip/3","title":"AWS.Lightsail.release_static_ip/3","type":"function","doc":"Deletes a specific static IP from your account."},{"ref":"AWS.Lightsail.html#reset_distribution_cache/3","title":"AWS.Lightsail.reset_distribution_cache/3","type":"function","doc":"Deletes currently cached content from your Amazon Lightsail content delivery network (CDN) distribution. After resetting the cache, the next time a content request is made, your distribution pulls, serves, and caches it from the origin."},{"ref":"AWS.Lightsail.html#send_contact_method_verification/3","title":"AWS.Lightsail.send_contact_method_verification/3","type":"function","doc":"Sends a verification request to an email contact method to ensure it&#39;s owned by the requester. SMS contact methods don&#39;t need to be verified. A contact method is used to send you notifications about your Amazon Lightsail resources. You can add one email address and one mobile phone number contact method in each AWS Region. However, SMS text messaging is not supported in some AWS Regions, and SMS text messages cannot be sent to some countries/regions. For more information, see Notifications in Amazon Lightsail. A verification request is sent to the contact method when you initially create it. Use this action to send another verification request if a previous verification request was deleted, or has expired. Notifications are not sent to an email contact method until after it is verified, and confirmed as valid."},{"ref":"AWS.Lightsail.html#start_instance/3","title":"AWS.Lightsail.start_instance/3","type":"function","doc":"Starts a specific Amazon Lightsail instance from a stopped state. To restart an instance, use the reboot instance operation. When you start a stopped instance, Lightsail assigns a new public IP address to the instance. To use the same IP address after stopping and starting an instance, create a static IP address and attach it to the instance. For more information, see the Lightsail Dev Guide. The start instance operation supports tag-based access control via resource tags applied to the resource identified by instance name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#start_relational_database/3","title":"AWS.Lightsail.start_relational_database/3","type":"function","doc":"Starts a specific database from a stopped state in Amazon Lightsail. To restart a database, use the reboot relational database operation. The start relational database operation supports tag-based access control via resource tags applied to the resource identified by relationalDatabaseName. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#stop_instance/3","title":"AWS.Lightsail.stop_instance/3","type":"function","doc":"Stops a specific Amazon Lightsail instance that is currently running. When you start a stopped instance, Lightsail assigns a new public IP address to the instance. To use the same IP address after stopping and starting an instance, create a static IP address and attach it to the instance. For more information, see the Lightsail Dev Guide. The stop instance operation supports tag-based access control via resource tags applied to the resource identified by instance name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#stop_relational_database/3","title":"AWS.Lightsail.stop_relational_database/3","type":"function","doc":"Stops a specific database that is currently running in Amazon Lightsail. The stop relational database operation supports tag-based access control via resource tags applied to the resource identified by relationalDatabaseName. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#tag_resource/3","title":"AWS.Lightsail.tag_resource/3","type":"function","doc":"Adds one or more tags to the specified Amazon Lightsail resource. Each resource can have a maximum of 50 tags. Each tag consists of a key and an optional value. Tag keys must be unique per resource. For more information about tags, see the Lightsail Dev Guide. The tag resource operation supports tag-based access control via request tags and resource tags applied to the resource identified by resource name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#test_alarm/3","title":"AWS.Lightsail.test_alarm/3","type":"function","doc":"Tests an alarm by displaying a banner on the Amazon Lightsail console. If a notification trigger is configured for the specified alarm, the test also sends a notification to the notification protocol (Email and/or SMS) configured for the alarm. An alarm is used to monitor a single metric for one of your resources. When a metric condition is met, the alarm can notify you by email, SMS text message, and a banner displayed on the Amazon Lightsail console. For more information, see Alarms in Amazon Lightsail."},{"ref":"AWS.Lightsail.html#unpeer_vpc/3","title":"AWS.Lightsail.unpeer_vpc/3","type":"function","doc":"Attempts to unpeer the Lightsail VPC from the user&#39;s default VPC."},{"ref":"AWS.Lightsail.html#untag_resource/3","title":"AWS.Lightsail.untag_resource/3","type":"function","doc":"Deletes the specified set of tag keys and their values from the specified Amazon Lightsail resource. The untag resource operation supports tag-based access control via request tags and resource tags applied to the resource identified by resource name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#update_distribution/3","title":"AWS.Lightsail.update_distribution/3","type":"function","doc":"Updates an existing Amazon Lightsail content delivery network (CDN) distribution. Use this action to update the configuration of your existing distribution"},{"ref":"AWS.Lightsail.html#update_distribution_bundle/3","title":"AWS.Lightsail.update_distribution_bundle/3","type":"function","doc":"Updates the bundle of your Amazon Lightsail content delivery network (CDN) distribution. A distribution bundle specifies the monthly network transfer quota and monthly cost of your dsitribution. Update your distribution&#39;s bundle if your distribution is going over its monthly network transfer quota and is incurring an overage fee. You can update your distribution&#39;s bundle only one time within your monthly AWS billing cycle. To determine if you can update your distribution&#39;s bundle, use the GetDistributions action. The ableToUpdateBundle parameter in the result will indicate whether you can currently update your distribution&#39;s bundle."},{"ref":"AWS.Lightsail.html#update_domain_entry/3","title":"AWS.Lightsail.update_domain_entry/3","type":"function","doc":"Updates a domain recordset after it is created. The update domain entry operation supports tag-based access control via resource tags applied to the resource identified by domain name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#update_load_balancer_attribute/3","title":"AWS.Lightsail.update_load_balancer_attribute/3","type":"function","doc":"Updates the specified attribute for a load balancer. You can only update one attribute at a time. The update load balancer attribute operation supports tag-based access control via resource tags applied to the resource identified by load balancer name. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#update_relational_database/3","title":"AWS.Lightsail.update_relational_database/3","type":"function","doc":"Allows the update of one or more attributes of a database in Amazon Lightsail. Updates are applied immediately, or in cases where the updates could result in an outage, are applied during the database&#39;s predefined maintenance window. The update relational database operation supports tag-based access control via resource tags applied to the resource identified by relationalDatabaseName. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.Lightsail.html#update_relational_database_parameters/3","title":"AWS.Lightsail.update_relational_database_parameters/3","type":"function","doc":"Allows the update of one or more parameters of a database in Amazon Lightsail. Parameter updates don&#39;t cause outages; therefore, their application is not subject to the preferred maintenance window. However, there are two ways in which parameter updates are applied: dynamic or pending-reboot. Parameters marked with a dynamic apply type are applied immediately. Parameters marked with a pending-reboot apply type are applied only after the database is rebooted using the reboot relational database operation. The update relational database parameters operation supports tag-based access control via resource tags applied to the resource identified by relationalDatabaseName. For more information, see the Lightsail Dev Guide."},{"ref":"AWS.MTurk.html","title":"AWS.MTurk","type":"module","doc":"Amazon Mechanical Turk API Reference"},{"ref":"AWS.MTurk.html#accept_qualification_request/3","title":"AWS.MTurk.accept_qualification_request/3","type":"function","doc":"The AcceptQualificationRequest operation approves a Worker&#39;s request for a Qualification. Only the owner of the Qualification type can grant a Qualification request for that type. A successful request for the AcceptQualificationRequest operation returns with no errors and an empty body."},{"ref":"AWS.MTurk.html#approve_assignment/3","title":"AWS.MTurk.approve_assignment/3","type":"function","doc":"The ApproveAssignment operation approves the results of a completed assignment. Approving an assignment initiates two payments from the Requester&#39;s Amazon.com account The Worker who submitted the results is paid the reward specified in the HIT. Amazon Mechanical Turk fees are debited. If the Requester&#39;s account does not have adequate funds for these payments, the call to ApproveAssignment returns an exception, and the approval is not processed. You can include an optional feedback message with the approval, which the Worker can see in the Status section of the web site. You can also call this operation for assignments that were previous rejected and approve them by explicitly overriding the previous rejection. This only works on rejected assignments that were submitted within the previous 30 days and only if the assignment&#39;s related HIT has not been deleted."},{"ref":"AWS.MTurk.html#associate_qualification_with_worker/3","title":"AWS.MTurk.associate_qualification_with_worker/3","type":"function","doc":"The AssociateQualificationWithWorker operation gives a Worker a Qualification. AssociateQualificationWithWorker does not require that the Worker submit a Qualification request. It gives the Qualification directly to the Worker. You can only assign a Qualification of a Qualification type that you created (using the CreateQualificationType operation). Note: AssociateQualificationWithWorker does not affect any pending Qualification requests for the Qualification by the Worker. If you assign a Qualification to a Worker, then later grant a Qualification request made by the Worker, the granting of the request may modify the Qualification score. To resolve a pending Qualification request without affecting the Qualification the Worker already has, reject the request with the RejectQualificationRequest operation."},{"ref":"AWS.MTurk.html#create_additional_assignments_for_h_i_t/3","title":"AWS.MTurk.create_additional_assignments_for_h_i_t/3","type":"function","doc":"The CreateAdditionalAssignmentsForHIT operation increases the maximum number of assignments of an existing HIT. To extend the maximum number of assignments, specify the number of additional assignments. HITs created with fewer than 10 assignments cannot be extended to have 10 or more assignments. Attempting to add assignments in a way that brings the total number of assignments for a HIT from fewer than 10 assignments to 10 or more assignments will result in an AWS.MechanicalTurk.InvalidMaximumAssignmentsIncrease exception. HITs that were created before July 22, 2015 cannot be extended. Attempting to extend HITs that were created before July 22, 2015 will result in an AWS.MechanicalTurk.HITTooOldForExtension exception."},{"ref":"AWS.MTurk.html#create_h_i_t/3","title":"AWS.MTurk.create_h_i_t/3","type":"function","doc":"The CreateHIT operation creates a new Human Intelligence Task (HIT). The new HIT is made available for Workers to find and accept on the Amazon Mechanical Turk website. This operation allows you to specify a new HIT by passing in values for the properties of the HIT, such as its title, reward amount and number of assignments. When you pass these values to CreateHIT, a new HIT is created for you, with a new HITTypeID. The HITTypeID can be used to create additional HITs in the future without needing to specify common parameters such as the title, description and reward amount each time. An alternative way to create HITs is to first generate a HITTypeID using the CreateHITType operation and then call the CreateHITWithHITType operation. This is the recommended best practice for Requesters who are creating large numbers of HITs. CreateHIT also supports several ways to provide question data: by providing a value for the Question parameter that fully specifies the contents of the HIT, or by providing a HitLayoutId and associated HitLayoutParameters. If a HIT is created with 10 or more maximum assignments, there is an additional fee. For more information, see Amazon Mechanical Turk Pricing."},{"ref":"AWS.MTurk.html#create_h_i_t_type/3","title":"AWS.MTurk.create_h_i_t_type/3","type":"function","doc":"The CreateHITType operation creates a new HIT type. This operation allows you to define a standard set of HIT properties to use when creating HITs. If you register a HIT type with values that match an existing HIT type, the HIT type ID of the existing type will be returned."},{"ref":"AWS.MTurk.html#create_h_i_t_with_h_i_t_type/3","title":"AWS.MTurk.create_h_i_t_with_h_i_t_type/3","type":"function","doc":"The CreateHITWithHITType operation creates a new Human Intelligence Task (HIT) using an existing HITTypeID generated by the CreateHITType operation. This is an alternative way to create HITs from the CreateHIT operation. This is the recommended best practice for Requesters who are creating large numbers of HITs. CreateHITWithHITType also supports several ways to provide question data: by providing a value for the Question parameter that fully specifies the contents of the HIT, or by providing a HitLayoutId and associated HitLayoutParameters. If a HIT is created with 10 or more maximum assignments, there is an additional fee. For more information, see Amazon Mechanical Turk Pricing."},{"ref":"AWS.MTurk.html#create_qualification_type/3","title":"AWS.MTurk.create_qualification_type/3","type":"function","doc":"The CreateQualificationType operation creates a new Qualification type, which is represented by a QualificationType data structure."},{"ref":"AWS.MTurk.html#create_worker_block/3","title":"AWS.MTurk.create_worker_block/3","type":"function","doc":"The CreateWorkerBlock operation allows you to prevent a Worker from working on your HITs. For example, you can block a Worker who is producing poor quality work. You can block up to 100,000 Workers."},{"ref":"AWS.MTurk.html#delete_h_i_t/3","title":"AWS.MTurk.delete_h_i_t/3","type":"function","doc":"The DeleteHIT operation is used to delete HIT that is no longer needed. Only the Requester who created the HIT can delete it. You can only dispose of HITs that are in the Reviewable state, with all of their submitted assignments already either approved or rejected. If you call the DeleteHIT operation on a HIT that is not in the Reviewable state (for example, that has not expired, or still has active assignments), or on a HIT that is Reviewable but without all of its submitted assignments already approved or rejected, the service will return an error. HITs are automatically disposed of after 120 days. After you dispose of a HIT, you can no longer approve the HIT&#39;s rejected assignments. Disposed HITs are not returned in results for the ListHITs operation. Disposing HITs can improve the performance of operations such as ListReviewableHITs and ListHITs."},{"ref":"AWS.MTurk.html#delete_qualification_type/3","title":"AWS.MTurk.delete_qualification_type/3","type":"function","doc":"The DeleteQualificationType deletes a Qualification type and deletes any HIT types that are associated with the Qualification type. This operation does not revoke Qualifications already assigned to Workers because the Qualifications might be needed for active HITs. If there are any pending requests for the Qualification type, Amazon Mechanical Turk rejects those requests. After you delete a Qualification type, you can no longer use it to create HITs or HIT types. DeleteQualificationType must wait for all the HITs that use the deleted Qualification type to be deleted before completing. It may take up to 48 hours before DeleteQualificationType completes and the unique name of the Qualification type is available for reuse with CreateQualificationType."},{"ref":"AWS.MTurk.html#delete_worker_block/3","title":"AWS.MTurk.delete_worker_block/3","type":"function","doc":"The DeleteWorkerBlock operation allows you to reinstate a blocked Worker to work on your HITs. This operation reverses the effects of the CreateWorkerBlock operation. You need the Worker ID to use this operation. If the Worker ID is missing or invalid, this operation fails and returns the message WorkerId is invalid. If the specified Worker is not blocked, this operation returns successfully."},{"ref":"AWS.MTurk.html#disassociate_qualification_from_worker/3","title":"AWS.MTurk.disassociate_qualification_from_worker/3","type":"function","doc":"The DisassociateQualificationFromWorker revokes a previously granted Qualification from a user. You can provide a text message explaining why the Qualification was revoked. The user who had the Qualification can see this message."},{"ref":"AWS.MTurk.html#get_account_balance/3","title":"AWS.MTurk.get_account_balance/3","type":"function","doc":"The GetAccountBalance operation retrieves the amount of money in your Amazon Mechanical Turk account."},{"ref":"AWS.MTurk.html#get_assignment/3","title":"AWS.MTurk.get_assignment/3","type":"function","doc":"The GetAssignment operation retrieves the details of the specified Assignment."},{"ref":"AWS.MTurk.html#get_file_upload_u_r_l/3","title":"AWS.MTurk.get_file_upload_u_r_l/3","type":"function","doc":"The GetFileUploadURL operation generates and returns a temporary URL. You use the temporary URL to retrieve a file uploaded by a Worker as an answer to a FileUploadAnswer question for a HIT. The temporary URL is generated the instant the GetFileUploadURL operation is called, and is valid for 60 seconds. You can get a temporary file upload URL any time until the HIT is disposed. After the HIT is disposed, any uploaded files are deleted, and cannot be retrieved. Pending Deprecation on December 12, 2017. The Answer Specification structure will no longer support the FileUploadAnswer element to be used for the QuestionForm data structure. Instead, we recommend that Requesters who want to create HITs asking Workers to upload files to use Amazon S3."},{"ref":"AWS.MTurk.html#get_h_i_t/3","title":"AWS.MTurk.get_h_i_t/3","type":"function","doc":"The GetHIT operation retrieves the details of the specified HIT."},{"ref":"AWS.MTurk.html#get_qualification_score/3","title":"AWS.MTurk.get_qualification_score/3","type":"function","doc":"The GetQualificationScore operation returns the value of a Worker&#39;s Qualification for a given Qualification type. To get a Worker&#39;s Qualification, you must know the Worker&#39;s ID. The Worker&#39;s ID is included in the assignment data returned by the ListAssignmentsForHIT operation. Only the owner of a Qualification type can query the value of a Worker&#39;s Qualification of that type."},{"ref":"AWS.MTurk.html#get_qualification_type/3","title":"AWS.MTurk.get_qualification_type/3","type":"function","doc":"The GetQualificationTypeoperation retrieves information about a Qualification type using its ID."},{"ref":"AWS.MTurk.html#list_assignments_for_h_i_t/3","title":"AWS.MTurk.list_assignments_for_h_i_t/3","type":"function","doc":"The ListAssignmentsForHIT operation retrieves completed assignments for a HIT. You can use this operation to retrieve the results for a HIT. You can get assignments for a HIT at any time, even if the HIT is not yet Reviewable. If a HIT requested multiple assignments, and has received some results but has not yet become Reviewable, you can still retrieve the partial results with this operation. Use the AssignmentStatus parameter to control which set of assignments for a HIT are returned. The ListAssignmentsForHIT operation can return submitted assignments awaiting approval, or it can return assignments that have already been approved or rejected. You can set AssignmentStatus=Approved,Rejected to get assignments that have already been approved and rejected together in one result set. Only the Requester who created the HIT can retrieve the assignments for that HIT. Results are sorted and divided into numbered pages and the operation returns a single page of results. You can use the parameters of the operation to control sorting and pagination."},{"ref":"AWS.MTurk.html#list_bonus_payments/3","title":"AWS.MTurk.list_bonus_payments/3","type":"function","doc":"The ListBonusPayments operation retrieves the amounts of bonuses you have paid to Workers for a given HIT or assignment."},{"ref":"AWS.MTurk.html#list_h_i_ts/3","title":"AWS.MTurk.list_h_i_ts/3","type":"function","doc":"The ListHITs operation returns all of a Requester&#39;s HITs. The operation returns HITs of any status, except for HITs that have been deleted of with the DeleteHIT operation or that have been auto-deleted."},{"ref":"AWS.MTurk.html#list_h_i_ts_for_qualification_type/3","title":"AWS.MTurk.list_h_i_ts_for_qualification_type/3","type":"function","doc":"The ListHITsForQualificationType operation returns the HITs that use the given Qualification type for a Qualification requirement. The operation returns HITs of any status, except for HITs that have been deleted with the DeleteHIT operation or that have been auto-deleted."},{"ref":"AWS.MTurk.html#list_qualification_requests/3","title":"AWS.MTurk.list_qualification_requests/3","type":"function","doc":"The ListQualificationRequests operation retrieves requests for Qualifications of a particular Qualification type. The owner of the Qualification type calls this operation to poll for pending requests, and accepts them using the AcceptQualification operation."},{"ref":"AWS.MTurk.html#list_qualification_types/3","title":"AWS.MTurk.list_qualification_types/3","type":"function","doc":"The ListQualificationTypes operation returns a list of Qualification types, filtered by an optional search term."},{"ref":"AWS.MTurk.html#list_review_policy_results_for_h_i_t/3","title":"AWS.MTurk.list_review_policy_results_for_h_i_t/3","type":"function","doc":"The ListReviewPolicyResultsForHIT operation retrieves the computed results and the actions taken in the course of executing your Review Policies for a given HIT. For information about how to specify Review Policies when you call CreateHIT, see Review Policies. The ListReviewPolicyResultsForHIT operation can return results for both Assignment-level and HIT-level review results."},{"ref":"AWS.MTurk.html#list_reviewable_h_i_ts/3","title":"AWS.MTurk.list_reviewable_h_i_ts/3","type":"function","doc":"The ListReviewableHITs operation retrieves the HITs with Status equal to Reviewable or Status equal to Reviewing that belong to the Requester calling the operation."},{"ref":"AWS.MTurk.html#list_worker_blocks/3","title":"AWS.MTurk.list_worker_blocks/3","type":"function","doc":"The ListWorkersBlocks operation retrieves a list of Workers who are blocked from working on your HITs."},{"ref":"AWS.MTurk.html#list_workers_with_qualification_type/3","title":"AWS.MTurk.list_workers_with_qualification_type/3","type":"function","doc":"The ListWorkersWithQualificationType operation returns all of the Workers that have been associated with a given Qualification type."},{"ref":"AWS.MTurk.html#notify_workers/3","title":"AWS.MTurk.notify_workers/3","type":"function","doc":"The NotifyWorkers operation sends an email to one or more Workers that you specify with the Worker ID. You can specify up to 100 Worker IDs to send the same message with a single call to the NotifyWorkers operation. The NotifyWorkers operation will send a notification email to a Worker only if you have previously approved or rejected work from the Worker."},{"ref":"AWS.MTurk.html#reject_assignment/3","title":"AWS.MTurk.reject_assignment/3","type":"function","doc":"The RejectAssignment operation rejects the results of a completed assignment. You can include an optional feedback message with the rejection, which the Worker can see in the Status section of the web site. When you include a feedback message with the rejection, it helps the Worker understand why the assignment was rejected, and can improve the quality of the results the Worker submits in the future. Only the Requester who created the HIT can reject an assignment for the HIT."},{"ref":"AWS.MTurk.html#reject_qualification_request/3","title":"AWS.MTurk.reject_qualification_request/3","type":"function","doc":"The RejectQualificationRequest operation rejects a user&#39;s request for a Qualification. You can provide a text message explaining why the request was rejected. The Worker who made the request can see this message."},{"ref":"AWS.MTurk.html#send_bonus/3","title":"AWS.MTurk.send_bonus/3","type":"function","doc":"The SendBonus operation issues a payment of money from your account to a Worker. This payment happens separately from the reward you pay to the Worker when you approve the Worker&#39;s assignment. The SendBonus operation requires the Worker&#39;s ID and the assignment ID as parameters to initiate payment of the bonus. You must include a message that explains the reason for the bonus payment, as the Worker may not be expecting the payment. Amazon Mechanical Turk collects a fee for bonus payments, similar to the HIT listing fee. This operation fails if your account does not have enough funds to pay for both the bonus and the fees."},{"ref":"AWS.MTurk.html#send_test_event_notification/3","title":"AWS.MTurk.send_test_event_notification/3","type":"function","doc":"The SendTestEventNotification operation causes Amazon Mechanical Turk to send a notification message as if a HIT event occurred, according to the provided notification specification. This allows you to test notifications without setting up notifications for a real HIT type and trying to trigger them using the website. When you call this operation, the service attempts to send the test notification immediately."},{"ref":"AWS.MTurk.html#update_expiration_for_h_i_t/3","title":"AWS.MTurk.update_expiration_for_h_i_t/3","type":"function","doc":"The UpdateExpirationForHIT operation allows you update the expiration time of a HIT. If you update it to a time in the past, the HIT will be immediately expired."},{"ref":"AWS.MTurk.html#update_h_i_t_review_status/3","title":"AWS.MTurk.update_h_i_t_review_status/3","type":"function","doc":"The UpdateHITReviewStatus operation updates the status of a HIT. If the status is Reviewable, this operation can update the status to Reviewing, or it can revert a Reviewing HIT back to the Reviewable status."},{"ref":"AWS.MTurk.html#update_h_i_t_type_of_h_i_t/3","title":"AWS.MTurk.update_h_i_t_type_of_h_i_t/3","type":"function","doc":"The UpdateHITTypeOfHIT operation allows you to change the HITType properties of a HIT. This operation disassociates the HIT from its old HITType properties and associates it with the new HITType properties. The HIT takes on the properties of the new HITType in place of the old ones."},{"ref":"AWS.MTurk.html#update_notification_settings/3","title":"AWS.MTurk.update_notification_settings/3","type":"function","doc":"The UpdateNotificationSettings operation creates, updates, disables or re-enables notifications for a HIT type. If you call the UpdateNotificationSettings operation for a HIT type that already has a notification specification, the operation replaces the old specification with a new one. You can call the UpdateNotificationSettings operation to enable or disable notifications for the HIT type, without having to modify the notification specification itself by providing updates to the Active status without specifying a new notification specification. To change the Active status of a HIT type&#39;s notifications, the HIT type must already have a notification specification, or one must be provided in the same call to UpdateNotificationSettings."},{"ref":"AWS.MTurk.html#update_qualification_type/3","title":"AWS.MTurk.update_qualification_type/3","type":"function","doc":"The UpdateQualificationType operation modifies the attributes of an existing Qualification type, which is represented by a QualificationType data structure. Only the owner of a Qualification type can modify its attributes. Most attributes of a Qualification type can be changed after the type has been created. However, the Name and Keywords fields cannot be modified. The RetryDelayInSeconds parameter can be modified or added to change the delay or to enable retries, but RetryDelayInSeconds cannot be used to disable retries. You can use this operation to update the test for a Qualification type. The test is updated based on the values specified for the Test, TestDurationInSeconds and AnswerKey parameters. All three parameters specify the updated test. If you are updating the test for a type, you must specify the Test and TestDurationInSeconds parameters. The AnswerKey parameter is optional; omitting it specifies that the updated test does not have an answer key. If you omit the Test parameter, the test for the Qualification type is unchanged. There is no way to remove a test from a Qualification type that has one. If the type already has a test, you cannot update it to be AutoGranted. If the Qualification type does not have a test and one is provided by an update, the type will henceforth have a test. If you want to update the test duration or answer key for an existing test without changing the questions, you must specify a Test parameter with the original questions, along with the updated values. If you provide an updated Test but no AnswerKey, the new test will not have an answer key. Requests for such Qualifications must be granted manually. You can also update the AutoGranted and AutoGrantedValue attributes of the Qualification type."},{"ref":"AWS.Machinelearning.html","title":"AWS.Machinelearning","type":"module","doc":"Definition of the public APIs exposed by Amazon Machine Learning"},{"ref":"AWS.Machinelearning.html#add_tags/3","title":"AWS.Machinelearning.add_tags/3","type":"function","doc":"Adds one or more tags to an object, up to a limit of 10. Each tag consists of a key and an optional value. If you add a tag using a key that is already associated with the ML object, AddTags updates the tag&#39;s value."},{"ref":"AWS.Machinelearning.html#create_batch_prediction/3","title":"AWS.Machinelearning.create_batch_prediction/3","type":"function","doc":"Generates predictions for a group of observations. The observations to process exist in one or more data files referenced by a DataSource. This operation creates a new BatchPrediction, and uses an MLModel and the data files referenced by the DataSource as information sources. CreateBatchPrediction is an asynchronous operation. In response to CreateBatchPrediction, Amazon Machine Learning (Amazon ML) immediately returns and sets the BatchPrediction status to PENDING. After the BatchPrediction completes, Amazon ML sets the status to COMPLETED. You can poll for status updates by using the GetBatchPrediction operation and checking the Status parameter of the result. After the COMPLETED status appears, the results are available in the location specified by the OutputUri parameter."},{"ref":"AWS.Machinelearning.html#create_data_source_from_r_d_s/3","title":"AWS.Machinelearning.create_data_source_from_r_d_s/3","type":"function","doc":"Creates a DataSource object from an Amazon Relational Database Service (Amazon RDS). A DataSource references data that can be used to perform CreateMLModel, CreateEvaluation, or CreateBatchPrediction operations. CreateDataSourceFromRDS is an asynchronous operation. In response to CreateDataSourceFromRDS, Amazon Machine Learning (Amazon ML) immediately returns and sets the DataSource status to PENDING. After the DataSource is created and ready for use, Amazon ML sets the Status parameter to COMPLETED. DataSource in the COMPLETED or PENDING state can be used only to perform &gt;CreateMLModel&gt;, CreateEvaluation, or CreateBatchPrediction operations. If Amazon ML cannot accept the input source, it sets the Status parameter to FAILED and includes an error message in the Message attribute of the GetDataSource operation response."},{"ref":"AWS.Machinelearning.html#create_data_source_from_redshift/3","title":"AWS.Machinelearning.create_data_source_from_redshift/3","type":"function","doc":"Creates a DataSource from a database hosted on an Amazon Redshift cluster. A DataSource references data that can be used to perform either CreateMLModel, CreateEvaluation, or CreateBatchPrediction operations. CreateDataSourceFromRedshift is an asynchronous operation. In response to CreateDataSourceFromRedshift, Amazon Machine Learning (Amazon ML) immediately returns and sets the DataSource status to PENDING. After the DataSource is created and ready for use, Amazon ML sets the Status parameter to COMPLETED. DataSource in COMPLETED or PENDING states can be used to perform only CreateMLModel, CreateEvaluation, or CreateBatchPrediction operations. If Amazon ML can&#39;t accept the input source, it sets the Status parameter to FAILED and includes an error message in the Message attribute of the GetDataSource operation response. The observations should be contained in the database hosted on an Amazon Redshift cluster and should be specified by a SelectSqlQuery query. Amazon ML executes an Unload command in Amazon Redshift to transfer the result set of the SelectSqlQuery query to S3StagingLocation. After the DataSource has been created, it&#39;s ready for use in evaluations and batch predictions. If you plan to use the DataSource to train an MLModel, the DataSource also requires a recipe. A recipe describes how each input variable will be used in training an MLModel. Will the variable be included or excluded from training? Will the variable be manipulated; for example, will it be combined with another variable or will it be split apart into word combinations? The recipe provides answers to these questions. You can't change anexisting datasource, but you can copy and modify the settings from an existing Amazon Redshift datasource to create a new datasource. To do so, call GetDataSource for an existing datasource and copy the values to a CreateDataSource call. Change the settings that you want to change and make sure that all required fields have the appropriate values."},{"ref":"AWS.Machinelearning.html#create_data_source_from_s3/3","title":"AWS.Machinelearning.create_data_source_from_s3/3","type":"function","doc":"Creates a DataSource object. A DataSource references data that can be used to perform CreateMLModel, CreateEvaluation, or CreateBatchPrediction operations. CreateDataSourceFromS3 is an asynchronous operation. In response to CreateDataSourceFromS3, Amazon Machine Learning (Amazon ML) immediately returns and sets the DataSource status to PENDING. After the DataSource has been created and is ready for use, Amazon ML sets the Status parameter to COMPLETED. DataSource in the COMPLETED or PENDING state can be used to perform only CreateMLModel, CreateEvaluation or CreateBatchPrediction operations. If Amazon ML can&#39;t accept the input source, it sets the Status parameter to FAILED and includes an error message in the Message attribute of the GetDataSource operation response. The observation data used in a DataSource should be ready to use; that is, it should have a consistent structure, and missing data values should be kept to a minimum. The observation data must reside in one or more .csv files in an Amazon Simple Storage Service (Amazon S3) location, along with a schema that describes the data items by name and type. The same schema must be used for all of the data files referenced by the DataSource. After the DataSource has been created, it&#39;s ready to use in evaluations and batch predictions. If you plan to use the DataSource to train an MLModel, the DataSource also needs a recipe. A recipe describes how each input variable will be used in training an MLModel. Will the variable be included or excluded from training? Will the variable be manipulated; for example, will it be combined with another variable or will it be split apart into word combinations? The recipe provides answers to these questions."},{"ref":"AWS.Machinelearning.html#create_evaluation/3","title":"AWS.Machinelearning.create_evaluation/3","type":"function","doc":"Creates a new Evaluation of an MLModel. An MLModel is evaluated on a set of observations associated to a DataSource. Like a DataSource for an MLModel, the DataSource for an Evaluation contains values for the Target Variable. The Evaluation compares the predicted result for each observation to the actual outcome and provides a summary so that you know how effective the MLModel functions on the test data. Evaluation generates a relevant performance metric, such as BinaryAUC, RegressionRMSE or MulticlassAvgFScore based on the corresponding MLModelType: BINARY, REGRESSION or MULTICLASS. CreateEvaluation is an asynchronous operation. In response to CreateEvaluation, Amazon Machine Learning (Amazon ML) immediately returns and sets the evaluation status to PENDING. After the Evaluation is created and ready for use, Amazon ML sets the status to COMPLETED. You can use the GetEvaluation operation to check progress of the evaluation during the creation operation."},{"ref":"AWS.Machinelearning.html#create_m_l_model/3","title":"AWS.Machinelearning.create_m_l_model/3","type":"function","doc":"Creates a new MLModel using the DataSource and the recipe as information sources. An MLModel is nearly immutable. Users can update only the MLModelName and the ScoreThreshold in an MLModel without creating a new MLModel. CreateMLModel is an asynchronous operation. In response to CreateMLModel, Amazon Machine Learning (Amazon ML) immediately returns and sets the MLModel status to PENDING. After the MLModel has been created and ready is for use, Amazon ML sets the status to COMPLETED. You can use the GetMLModel operation to check the progress of the MLModel during the creation operation. CreateMLModel requires a DataSource with computed statistics, which can be created by setting ComputeStatistics to true in CreateDataSourceFromRDS, CreateDataSourceFromS3, or CreateDataSourceFromRedshift operations."},{"ref":"AWS.Machinelearning.html#create_realtime_endpoint/3","title":"AWS.Machinelearning.create_realtime_endpoint/3","type":"function","doc":"Creates a real-time endpoint for the MLModel. The endpoint contains the URI of the MLModel; that is, the location to send real-time prediction requests for the specified MLModel."},{"ref":"AWS.Machinelearning.html#delete_batch_prediction/3","title":"AWS.Machinelearning.delete_batch_prediction/3","type":"function","doc":"Assigns the DELETED status to a BatchPrediction, rendering it unusable. After using the DeleteBatchPrediction operation, you can use the GetBatchPrediction operation to verify that the status of the BatchPrediction changed to DELETED. Caution: The result of the DeleteBatchPrediction operation is irreversible."},{"ref":"AWS.Machinelearning.html#delete_data_source/3","title":"AWS.Machinelearning.delete_data_source/3","type":"function","doc":"Assigns the DELETED status to a DataSource, rendering it unusable. After using the DeleteDataSource operation, you can use the GetDataSource operation to verify that the status of the DataSource changed to DELETED. Caution: The results of the DeleteDataSource operation are irreversible."},{"ref":"AWS.Machinelearning.html#delete_evaluation/3","title":"AWS.Machinelearning.delete_evaluation/3","type":"function","doc":"Assigns the DELETED status to an Evaluation, rendering it unusable. After invoking the DeleteEvaluation operation, you can use the GetEvaluation operation to verify that the status of the Evaluation changed to DELETED. Caution The results of the `DeleteEvaluation` operation are irreversible."},{"ref":"AWS.Machinelearning.html#delete_m_l_model/3","title":"AWS.Machinelearning.delete_m_l_model/3","type":"function","doc":"Assigns the DELETED status to an MLModel, rendering it unusable. After using the DeleteMLModel operation, you can use the GetMLModel operation to verify that the status of the MLModel changed to DELETED. Caution: The result of the DeleteMLModel operation is irreversible."},{"ref":"AWS.Machinelearning.html#delete_realtime_endpoint/3","title":"AWS.Machinelearning.delete_realtime_endpoint/3","type":"function","doc":"Deletes a real time endpoint of an MLModel."},{"ref":"AWS.Machinelearning.html#delete_tags/3","title":"AWS.Machinelearning.delete_tags/3","type":"function","doc":"Deletes the specified tags associated with an ML object. After this operation is complete, you can&#39;t recover deleted tags. If you specify a tag that doesn&#39;t exist, Amazon ML ignores it."},{"ref":"AWS.Machinelearning.html#describe_batch_predictions/3","title":"AWS.Machinelearning.describe_batch_predictions/3","type":"function","doc":"Returns a list of BatchPrediction operations that match the search criteria in the request."},{"ref":"AWS.Machinelearning.html#describe_data_sources/3","title":"AWS.Machinelearning.describe_data_sources/3","type":"function","doc":"Returns a list of DataSource that match the search criteria in the request."},{"ref":"AWS.Machinelearning.html#describe_evaluations/3","title":"AWS.Machinelearning.describe_evaluations/3","type":"function","doc":"Returns a list of DescribeEvaluations that match the search criteria in the request."},{"ref":"AWS.Machinelearning.html#describe_m_l_models/3","title":"AWS.Machinelearning.describe_m_l_models/3","type":"function","doc":"Returns a list of MLModel that match the search criteria in the request."},{"ref":"AWS.Machinelearning.html#describe_tags/3","title":"AWS.Machinelearning.describe_tags/3","type":"function","doc":"Describes one or more of the tags for your Amazon ML object."},{"ref":"AWS.Machinelearning.html#get_batch_prediction/3","title":"AWS.Machinelearning.get_batch_prediction/3","type":"function","doc":"Returns a BatchPrediction that includes detailed metadata, status, and data file information for a Batch Prediction request."},{"ref":"AWS.Machinelearning.html#get_data_source/3","title":"AWS.Machinelearning.get_data_source/3","type":"function","doc":"Returns a DataSource that includes metadata and data file information, as well as the current status of the DataSource. GetDataSource provides results in normal or verbose format. The verbose format adds the schema description and the list of files pointed to by the DataSource to the normal format."},{"ref":"AWS.Machinelearning.html#get_evaluation/3","title":"AWS.Machinelearning.get_evaluation/3","type":"function","doc":"Returns an Evaluation that includes metadata as well as the current status of the Evaluation."},{"ref":"AWS.Machinelearning.html#get_m_l_model/3","title":"AWS.Machinelearning.get_m_l_model/3","type":"function","doc":"Returns an MLModel that includes detailed metadata, data source information, and the current status of the MLModel. GetMLModel provides results in normal or verbose format."},{"ref":"AWS.Machinelearning.html#predict/3","title":"AWS.Machinelearning.predict/3","type":"function","doc":"Generates a prediction for the observation using the specified ML Model. Note Not all response parameters will be populated. Whether a response parameter is populated depends on the type of model requested."},{"ref":"AWS.Machinelearning.html#update_batch_prediction/3","title":"AWS.Machinelearning.update_batch_prediction/3","type":"function","doc":"Updates the BatchPredictionName of a BatchPrediction. You can use the GetBatchPrediction operation to view the contents of the updated data element."},{"ref":"AWS.Machinelearning.html#update_data_source/3","title":"AWS.Machinelearning.update_data_source/3","type":"function","doc":"Updates the DataSourceName of a DataSource. You can use the GetDataSource operation to view the contents of the updated data element."},{"ref":"AWS.Machinelearning.html#update_evaluation/3","title":"AWS.Machinelearning.update_evaluation/3","type":"function","doc":"Updates the EvaluationName of an Evaluation. You can use the GetEvaluation operation to view the contents of the updated data element."},{"ref":"AWS.Machinelearning.html#update_m_l_model/3","title":"AWS.Machinelearning.update_m_l_model/3","type":"function","doc":"Updates the MLModelName and the ScoreThreshold of an MLModel. You can use the GetMLModel operation to view the contents of the updated data element."},{"ref":"AWS.Macie.html","title":"AWS.Macie","type":"module","doc":"Amazon Macie Classic Amazon Macie Classic is a security service that uses machine learning to automatically discover, classify, and protect sensitive data in AWS. Macie Classic recognizes sensitive data such as personally identifiable information (PII) or intellectual property, and provides you with dashboards and alerts that give visibility into how this data is being accessed or moved. For more information, see the Amazon Macie Classic User Guide. A new Amazon Macie is now available with significant design improvements and additional features, at a lower price and in most AWS Regions. We encourage you to explore and use the new and improved features, and benefit from the reduced cost. To learn about features and pricing for the new Amazon Macie, see Amazon Macie."},{"ref":"AWS.Macie.html#associate_member_account/3","title":"AWS.Macie.associate_member_account/3","type":"function","doc":"Associates a specified AWS account with Amazon Macie Classic as a member account."},{"ref":"AWS.Macie.html#associate_s3_resources/3","title":"AWS.Macie.associate_s3_resources/3","type":"function","doc":"Associates specified S3 resources with Amazon Macie Classic for monitoring and data classification. If memberAccountId isn&#39;t specified, the action associates specified S3 resources with Macie Classic for the current master account. If memberAccountId is specified, the action associates specified S3 resources with Macie Classic for the specified member account."},{"ref":"AWS.Macie.html#disassociate_member_account/3","title":"AWS.Macie.disassociate_member_account/3","type":"function","doc":"Removes the specified member account from Amazon Macie Classic."},{"ref":"AWS.Macie.html#disassociate_s3_resources/3","title":"AWS.Macie.disassociate_s3_resources/3","type":"function","doc":"Removes specified S3 resources from being monitored by Amazon Macie Classic. If memberAccountId isn&#39;t specified, the action removes specified S3 resources from Macie Classic for the current master account. If memberAccountId is specified, the action removes specified S3 resources from Macie Classic for the specified member account."},{"ref":"AWS.Macie.html#list_member_accounts/3","title":"AWS.Macie.list_member_accounts/3","type":"function","doc":"Lists all Amazon Macie Classic member accounts for the current Amazon Macie Classic master account."},{"ref":"AWS.Macie.html#list_s3_resources/3","title":"AWS.Macie.list_s3_resources/3","type":"function","doc":"Lists all the S3 resources associated with Amazon Macie Classic. If memberAccountId isn&#39;t specified, the action lists the S3 resources associated with Amazon Macie Classic for the current master account. If memberAccountId is specified, the action lists the S3 resources associated with Amazon Macie Classic for the specified member account."},{"ref":"AWS.Macie.html#update_s3_resources/3","title":"AWS.Macie.update_s3_resources/3","type":"function","doc":"Updates the classification types for the specified S3 resources. If memberAccountId isn&#39;t specified, the action updates the classification types of the S3 resources associated with Amazon Macie Classic for the current master account. If memberAccountId is specified, the action updates the classification types of the S3 resources associated with Amazon Macie Classic for the specified member account."},{"ref":"AWS.Macie2.html","title":"AWS.Macie2","type":"module","doc":"Amazon Macie is a fully managed data security and data privacy service that uses machine learning and pattern matching to discover and protect your sensitive data in AWS. Macie automates the discovery of sensitive data, such as PII and intellectual property, to provide you with insight into the data that your organization stores in AWS. Macie also provides an inventory of your Amazon S3 buckets, which it continually monitors for you. If Macie detects sensitive data or potential data access issues, it generates detailed findings for you to review and act upon as necessary."},{"ref":"AWS.Macie2.html#accept_invitation/3","title":"AWS.Macie2.accept_invitation/3","type":"function","doc":"Accepts an Amazon Macie membership invitation that was received from a specific account."},{"ref":"AWS.Macie2.html#batch_get_custom_data_identifiers/3","title":"AWS.Macie2.batch_get_custom_data_identifiers/3","type":"function","doc":"Retrieves information about one or more custom data identifiers."},{"ref":"AWS.Macie2.html#create_classification_job/3","title":"AWS.Macie2.create_classification_job/3","type":"function","doc":"Creates and defines the settings for a classification job."},{"ref":"AWS.Macie2.html#create_custom_data_identifier/3","title":"AWS.Macie2.create_custom_data_identifier/3","type":"function","doc":"Creates and defines the criteria and other settings for a custom data identifier."},{"ref":"AWS.Macie2.html#create_findings_filter/3","title":"AWS.Macie2.create_findings_filter/3","type":"function","doc":"Creates and defines the criteria and other settings for a findings filter."},{"ref":"AWS.Macie2.html#create_invitations/3","title":"AWS.Macie2.create_invitations/3","type":"function","doc":"Sends an Amazon Macie membership invitation to one or more accounts."},{"ref":"AWS.Macie2.html#create_member/3","title":"AWS.Macie2.create_member/3","type":"function","doc":"Associates an account with an Amazon Macie master account."},{"ref":"AWS.Macie2.html#create_sample_findings/3","title":"AWS.Macie2.create_sample_findings/3","type":"function","doc":"Creates sample findings."},{"ref":"AWS.Macie2.html#decline_invitations/3","title":"AWS.Macie2.decline_invitations/3","type":"function","doc":"Declines Amazon Macie membership invitations that were received from specific accounts."},{"ref":"AWS.Macie2.html#delete_custom_data_identifier/4","title":"AWS.Macie2.delete_custom_data_identifier/4","type":"function","doc":"Soft deletes a custom data identifier."},{"ref":"AWS.Macie2.html#delete_findings_filter/4","title":"AWS.Macie2.delete_findings_filter/4","type":"function","doc":"Deletes a findings filter."},{"ref":"AWS.Macie2.html#delete_invitations/3","title":"AWS.Macie2.delete_invitations/3","type":"function","doc":"Deletes Amazon Macie membership invitations that were received from specific accounts."},{"ref":"AWS.Macie2.html#delete_member/4","title":"AWS.Macie2.delete_member/4","type":"function","doc":"Deletes the association between an Amazon Macie master account and an account."},{"ref":"AWS.Macie2.html#describe_buckets/3","title":"AWS.Macie2.describe_buckets/3","type":"function","doc":"Retrieves (queries) statistical data and other information about one or more S3 buckets that Amazon Macie monitors and analyzes."},{"ref":"AWS.Macie2.html#describe_classification_job/3","title":"AWS.Macie2.describe_classification_job/3","type":"function","doc":"Retrieves information about the status and settings for a classification job."},{"ref":"AWS.Macie2.html#describe_organization_configuration/2","title":"AWS.Macie2.describe_organization_configuration/2","type":"function","doc":"Retrieves information about the Amazon Macie configuration settings for an AWS organization."},{"ref":"AWS.Macie2.html#disable_macie/3","title":"AWS.Macie2.disable_macie/3","type":"function","doc":"Disables an Amazon Macie account and deletes Macie resources for the account."},{"ref":"AWS.Macie2.html#disable_organization_admin_account/3","title":"AWS.Macie2.disable_organization_admin_account/3","type":"function","doc":"Disables an account as a delegated administrator of Amazon Macie for an AWS organization."},{"ref":"AWS.Macie2.html#disassociate_from_master_account/3","title":"AWS.Macie2.disassociate_from_master_account/3","type":"function","doc":"Disassociates a member account from its Amazon Macie master account."},{"ref":"AWS.Macie2.html#disassociate_member/4","title":"AWS.Macie2.disassociate_member/4","type":"function","doc":"Disassociates an Amazon Macie master account from a member account."},{"ref":"AWS.Macie2.html#enable_macie/3","title":"AWS.Macie2.enable_macie/3","type":"function","doc":"Enables Amazon Macie and specifies the configuration settings for a Macie account."},{"ref":"AWS.Macie2.html#enable_organization_admin_account/3","title":"AWS.Macie2.enable_organization_admin_account/3","type":"function","doc":"Enables an account as a delegated administrator of Amazon Macie for an AWS organization."},{"ref":"AWS.Macie2.html#get_bucket_statistics/3","title":"AWS.Macie2.get_bucket_statistics/3","type":"function","doc":"Retrieves (queries) aggregated statistical data for all the S3 buckets that Amazon Macie monitors and analyzes."},{"ref":"AWS.Macie2.html#get_classification_export_configuration/2","title":"AWS.Macie2.get_classification_export_configuration/2","type":"function","doc":"Retrieves the configuration settings for storing data classification results."},{"ref":"AWS.Macie2.html#get_custom_data_identifier/3","title":"AWS.Macie2.get_custom_data_identifier/3","type":"function","doc":"Retrieves information about the criteria and other settings for a custom data identifier."},{"ref":"AWS.Macie2.html#get_finding_statistics/3","title":"AWS.Macie2.get_finding_statistics/3","type":"function","doc":"Retrieves (queries) aggregated statistical data about findings."},{"ref":"AWS.Macie2.html#get_findings/3","title":"AWS.Macie2.get_findings/3","type":"function","doc":"Retrieves information about one or more findings."},{"ref":"AWS.Macie2.html#get_findings_filter/3","title":"AWS.Macie2.get_findings_filter/3","type":"function","doc":"Retrieves information about the criteria and other settings for a findings filter."},{"ref":"AWS.Macie2.html#get_invitations_count/2","title":"AWS.Macie2.get_invitations_count/2","type":"function","doc":"Retrieves the count of Amazon Macie membership invitations that were received by an account."},{"ref":"AWS.Macie2.html#get_macie_session/2","title":"AWS.Macie2.get_macie_session/2","type":"function","doc":"Retrieves information about the current status and configuration settings for an Amazon Macie account."},{"ref":"AWS.Macie2.html#get_master_account/2","title":"AWS.Macie2.get_master_account/2","type":"function","doc":"Retrieves information about the Amazon Macie master account for an account."},{"ref":"AWS.Macie2.html#get_member/3","title":"AWS.Macie2.get_member/3","type":"function","doc":"Retrieves information about a member account that&#39;s associated with an Amazon Macie master account."},{"ref":"AWS.Macie2.html#get_usage_statistics/3","title":"AWS.Macie2.get_usage_statistics/3","type":"function","doc":"Retrieves (queries) quotas and aggregated usage data for one or more accounts."},{"ref":"AWS.Macie2.html#get_usage_totals/2","title":"AWS.Macie2.get_usage_totals/2","type":"function","doc":"Retrieves (queries) aggregated usage data for an account."},{"ref":"AWS.Macie2.html#list_classification_jobs/3","title":"AWS.Macie2.list_classification_jobs/3","type":"function","doc":"Retrieves a subset of information about one or more classification jobs."},{"ref":"AWS.Macie2.html#list_custom_data_identifiers/3","title":"AWS.Macie2.list_custom_data_identifiers/3","type":"function","doc":"Retrieves a subset of information about all the custom data identifiers for an account."},{"ref":"AWS.Macie2.html#list_findings/3","title":"AWS.Macie2.list_findings/3","type":"function","doc":"Retrieves a subset of information about one or more findings."},{"ref":"AWS.Macie2.html#list_findings_filters/4","title":"AWS.Macie2.list_findings_filters/4","type":"function","doc":"Retrieves a subset of information about all the findings filters for an account."},{"ref":"AWS.Macie2.html#list_invitations/4","title":"AWS.Macie2.list_invitations/4","type":"function","doc":"Retrieves information about all the Amazon Macie membership invitations that were received by an account."},{"ref":"AWS.Macie2.html#list_members/5","title":"AWS.Macie2.list_members/5","type":"function","doc":"Retrieves information about the accounts that are associated with an Amazon Macie master account."},{"ref":"AWS.Macie2.html#list_organization_admin_accounts/4","title":"AWS.Macie2.list_organization_admin_accounts/4","type":"function","doc":"Retrieves information about the account that&#39;s designated as the delegated administrator of Amazon Macie for an AWS organization."},{"ref":"AWS.Macie2.html#list_tags_for_resource/3","title":"AWS.Macie2.list_tags_for_resource/3","type":"function","doc":"Retrieves the tags (keys and values) that are associated with a classification job, custom data identifier, findings filter, or member account."},{"ref":"AWS.Macie2.html#put_classification_export_configuration/3","title":"AWS.Macie2.put_classification_export_configuration/3","type":"function","doc":"Creates or updates the configuration settings for storing data classification results."},{"ref":"AWS.Macie2.html#tag_resource/4","title":"AWS.Macie2.tag_resource/4","type":"function","doc":"Adds or updates one or more tags (keys and values) that are associated with a classification job, custom data identifier, findings filter, or member account."},{"ref":"AWS.Macie2.html#test_custom_data_identifier/3","title":"AWS.Macie2.test_custom_data_identifier/3","type":"function","doc":"Tests a custom data identifier."},{"ref":"AWS.Macie2.html#untag_resource/4","title":"AWS.Macie2.untag_resource/4","type":"function","doc":"Removes one or more tags (keys and values) from a classification job, custom data identifier, findings filter, or member account."},{"ref":"AWS.Macie2.html#update_classification_job/4","title":"AWS.Macie2.update_classification_job/4","type":"function","doc":"Cancels a classification job."},{"ref":"AWS.Macie2.html#update_findings_filter/4","title":"AWS.Macie2.update_findings_filter/4","type":"function","doc":"Updates the criteria and other settings for a findings filter."},{"ref":"AWS.Macie2.html#update_macie_session/3","title":"AWS.Macie2.update_macie_session/3","type":"function","doc":"Suspends or re-enables an Amazon Macie account, or updates the configuration settings for a Macie account."},{"ref":"AWS.Macie2.html#update_member_session/4","title":"AWS.Macie2.update_member_session/4","type":"function","doc":"Enables an Amazon Macie master account to suspend or re-enable a member account."},{"ref":"AWS.Macie2.html#update_organization_configuration/3","title":"AWS.Macie2.update_organization_configuration/3","type":"function","doc":"Updates Amazon Macie configuration settings for an AWS organization."},{"ref":"AWS.ManagedBlockchain.html","title":"AWS.ManagedBlockchain","type":"module","doc":"Amazon Managed Blockchain is a fully managed service for creating and managing blockchain networks using open source frameworks. Blockchain allows you to build applications where multiple parties can securely and transparently run transactions and share data without the need for a trusted, central authority. Currently, Managed Blockchain supports the Hyperledger Fabric open source framework."},{"ref":"AWS.ManagedBlockchain.html#create_member/4","title":"AWS.ManagedBlockchain.create_member/4","type":"function","doc":"Creates a member within a Managed Blockchain network."},{"ref":"AWS.ManagedBlockchain.html#create_network/3","title":"AWS.ManagedBlockchain.create_network/3","type":"function","doc":"Creates a new blockchain network using Amazon Managed Blockchain."},{"ref":"AWS.ManagedBlockchain.html#create_node/5","title":"AWS.ManagedBlockchain.create_node/5","type":"function","doc":"Creates a peer node in a member."},{"ref":"AWS.ManagedBlockchain.html#create_proposal/4","title":"AWS.ManagedBlockchain.create_proposal/4","type":"function","doc":"Creates a proposal for a change to the network that other members of the network can vote on, for example, a proposal to add a new member to the network. Any member can create a proposal."},{"ref":"AWS.ManagedBlockchain.html#delete_member/5","title":"AWS.ManagedBlockchain.delete_member/5","type":"function","doc":"Deletes a member. Deleting a member removes the member and all associated resources from the network. DeleteMember can only be called for a specified MemberId if the principal performing the action is associated with the AWS account that owns the member. In all other cases, the DeleteMember action is carried out as the result of an approved proposal to remove a member. If MemberId is the last member in a network specified by the last AWS account, the network is deleted also."},{"ref":"AWS.ManagedBlockchain.html#delete_node/6","title":"AWS.ManagedBlockchain.delete_node/6","type":"function","doc":"Deletes a peer node from a member that your AWS account owns. All data on the node is lost and cannot be recovered."},{"ref":"AWS.ManagedBlockchain.html#get_member/4","title":"AWS.ManagedBlockchain.get_member/4","type":"function","doc":"Returns detailed information about a member."},{"ref":"AWS.ManagedBlockchain.html#get_network/3","title":"AWS.ManagedBlockchain.get_network/3","type":"function","doc":"Returns detailed information about a network."},{"ref":"AWS.ManagedBlockchain.html#get_node/5","title":"AWS.ManagedBlockchain.get_node/5","type":"function","doc":"Returns detailed information about a peer node."},{"ref":"AWS.ManagedBlockchain.html#get_proposal/4","title":"AWS.ManagedBlockchain.get_proposal/4","type":"function","doc":"Returns detailed information about a proposal."},{"ref":"AWS.ManagedBlockchain.html#list_invitations/4","title":"AWS.ManagedBlockchain.list_invitations/4","type":"function","doc":"Returns a listing of all invitations for the current AWS account."},{"ref":"AWS.ManagedBlockchain.html#list_members/8","title":"AWS.ManagedBlockchain.list_members/8","type":"function","doc":"Returns a listing of the members in a network and properties of their configurations."},{"ref":"AWS.ManagedBlockchain.html#list_networks/7","title":"AWS.ManagedBlockchain.list_networks/7","type":"function","doc":"Returns information about the networks in which the current AWS account has members."},{"ref":"AWS.ManagedBlockchain.html#list_nodes/7","title":"AWS.ManagedBlockchain.list_nodes/7","type":"function","doc":"Returns information about the nodes within a network."},{"ref":"AWS.ManagedBlockchain.html#list_proposal_votes/6","title":"AWS.ManagedBlockchain.list_proposal_votes/6","type":"function","doc":"Returns the listing of votes for a specified proposal, including the value of each vote and the unique identifier of the member that cast the vote."},{"ref":"AWS.ManagedBlockchain.html#list_proposals/5","title":"AWS.ManagedBlockchain.list_proposals/5","type":"function","doc":"Returns a listing of proposals for the network."},{"ref":"AWS.ManagedBlockchain.html#reject_invitation/4","title":"AWS.ManagedBlockchain.reject_invitation/4","type":"function","doc":"Rejects an invitation to join a network. This action can be called by a principal in an AWS account that has received an invitation to create a member and join a network."},{"ref":"AWS.ManagedBlockchain.html#update_member/5","title":"AWS.ManagedBlockchain.update_member/5","type":"function","doc":"Updates a member configuration with new parameters."},{"ref":"AWS.ManagedBlockchain.html#update_node/6","title":"AWS.ManagedBlockchain.update_node/6","type":"function","doc":"Updates a node configuration with new parameters."},{"ref":"AWS.ManagedBlockchain.html#vote_on_proposal/5","title":"AWS.ManagedBlockchain.vote_on_proposal/5","type":"function","doc":"Casts a vote for a specified ProposalId on behalf of a member. The member to vote as, specified by VoterMemberId, must be in the same AWS account as the principal that calls the action."},{"ref":"AWS.MarketplaceCatalog.html","title":"AWS.MarketplaceCatalog","type":"module","doc":"Catalog API actions allow you to manage your entities through list, describe, and update capabilities. An entity can be a product or an offer on AWS Marketplace. You can automate your entity update process by integrating the AWS Marketplace Catalog API with your AWS Marketplace product build or deployment pipelines. You can also create your own applications on top of the Catalog API to manage your products on AWS Marketplace."},{"ref":"AWS.MarketplaceCatalog.html#cancel_change_set/3","title":"AWS.MarketplaceCatalog.cancel_change_set/3","type":"function","doc":"Used to cancel an open change request. Must be sent before the status of the request changes to APPLYING, the final stage of completing your change request. You can describe a change during the 60-day request history retention period for API calls."},{"ref":"AWS.MarketplaceCatalog.html#describe_change_set/4","title":"AWS.MarketplaceCatalog.describe_change_set/4","type":"function","doc":"Provides information about a given change set."},{"ref":"AWS.MarketplaceCatalog.html#describe_entity/4","title":"AWS.MarketplaceCatalog.describe_entity/4","type":"function","doc":"Returns the metadata and content of the entity."},{"ref":"AWS.MarketplaceCatalog.html#list_change_sets/3","title":"AWS.MarketplaceCatalog.list_change_sets/3","type":"function","doc":"Returns the list of change sets owned by the account being used to make the call. You can filter this list by providing any combination of entityId, ChangeSetName, and status. If you provide more than one filter, the API operation applies a logical AND between the filters. You can describe a change during the 60-day request history retention period for API calls."},{"ref":"AWS.MarketplaceCatalog.html#list_entities/3","title":"AWS.MarketplaceCatalog.list_entities/3","type":"function","doc":"Provides the list of entities of a given type."},{"ref":"AWS.MarketplaceCatalog.html#start_change_set/3","title":"AWS.MarketplaceCatalog.start_change_set/3","type":"function","doc":"This operation allows you to request changes for your entities. Within a single ChangeSet, you cannot start the same change type against the same entity multiple times. Additionally, when a ChangeSet is running, all the entities targeted by the different changes are locked until the ChangeSet has completed (either succeeded, cancelled, or failed). If you try to start a ChangeSet containing a change against an entity that is already locked, you will receive a ResourceInUseException. For example, you cannot start the ChangeSet described in the example below because it contains two changes to execute the same change type (AddRevisions) against the same entity (entity-id@1)."},{"ref":"AWS.MarketplaceCommerceAnalytics.html","title":"AWS.MarketplaceCommerceAnalytics","type":"module","doc":"Provides AWS Marketplace business intelligence data on-demand."},{"ref":"AWS.MarketplaceCommerceAnalytics.html#generate_data_set/3","title":"AWS.MarketplaceCommerceAnalytics.generate_data_set/3","type":"function","doc":"Given a data set type and data set publication date, asynchronously publishes the requested data set to the specified S3 bucket and notifies the specified SNS topic once the data is available. Returns a unique request identifier that can be used to correlate requests with notifications from the SNS topic. Data sets will be published in comma-separated values (CSV) format with the file name {data_set_type}_YYYY-MM-DD.csv. If a file with the same name already exists (e.g. if the same data set is requested twice), the original file will be overwritten by the new file. Requires a Role with an attached permissions policy providing Allow permissions for the following actions: s3:PutObject, s3:GetBucketLocation, sns:GetTopicAttributes, sns:Publish, iam:GetRolePolicy."},{"ref":"AWS.MarketplaceCommerceAnalytics.html#start_support_data_export/3","title":"AWS.MarketplaceCommerceAnalytics.start_support_data_export/3","type":"function","doc":"Given a data set type and a from date, asynchronously publishes the requested customer support data to the specified S3 bucket and notifies the specified SNS topic once the data is available. Returns a unique request identifier that can be used to correlate requests with notifications from the SNS topic. Data sets will be published in comma-separated values (CSV) format with the file name {data_set_type}_YYYY-MM-DD&#39;T&#39;HH-mm-ss&#39;Z&#39;.csv. If a file with the same name already exists (e.g. if the same data set is requested twice), the original file will be overwritten by the new file. Requires a Role with an attached permissions policy providing Allow permissions for the following actions: s3:PutObject, s3:GetBucketLocation, sns:GetTopicAttributes, sns:Publish, iam:GetRolePolicy."},{"ref":"AWS.MarketplaceMetering.html","title":"AWS.MarketplaceMetering","type":"module","doc":"AWS Marketplace Metering Service This reference provides descriptions of the low-level AWS Marketplace Metering Service API. AWS Marketplace sellers can use this API to submit usage data for custom usage dimensions. For information on the permissions you need to use this API, see AWS Marketing metering and entitlement API permissions in the AWS Marketplace Seller Guide. Submitting Metering Records MeterUsage- Submits the metering record for a Marketplace product. MeterUsage is called from an EC2 instance or a container running on EKS or ECS. BatchMeterUsage- Submits the metering record for a set of customers. BatchMeterUsage is called from a software-as-a-service (SaaS) application. Accepting New Customers ResolveCustomer- Called by a SaaS application during the registration process. When a buyer visits your website during the registration process, the buyer submits a Registration Token through the browser. The Registration Token is resolved through this API to obtain a CustomerIdentifier and Product Code. Entitlement and Metering for Paid Container Products Paid container software products sold through AWS Marketplace must integrate with the AWS Marketplace Metering Service and call the RegisterUsage operation for software entitlement and metering. Free and BYOL products for Amazon ECS or Amazon EKS aren&#39;t required to call RegisterUsage, but you can do so if you want to receive usage data in your seller reports. For more information on using the RegisterUsage operation, see Container-Based Products. BatchMeterUsage API calls are captured by AWS CloudTrail. You can use Cloudtrail to verify that the SaaS metering records that you sent are accurate by searching for records with the eventName of BatchMeterUsage. You can also use CloudTrail to audit records over time. For more information, see the AWS CloudTrail User Guide ."},{"ref":"AWS.MarketplaceMetering.html#batch_meter_usage/3","title":"AWS.MarketplaceMetering.batch_meter_usage/3","type":"function","doc":"BatchMeterUsage is called from a SaaS application listed on the AWS Marketplace to post metering records for a set of customers. For identical requests, the API is idempotent; requests can be retried with the same records or a subset of the input records. Every request to BatchMeterUsage is for one product. If you need to meter usage for multiple products, you must make multiple calls to BatchMeterUsage. BatchMeterUsage can process up to 25 UsageRecords at a time."},{"ref":"AWS.MarketplaceMetering.html#meter_usage/3","title":"AWS.MarketplaceMetering.meter_usage/3","type":"function","doc":"API to emit metering records. For identical requests, the API is idempotent. It simply returns the metering record ID. MeterUsage is authenticated on the buyer&#39;s AWS account using credentials from the EC2 instance, ECS task, or EKS pod."},{"ref":"AWS.MarketplaceMetering.html#register_usage/3","title":"AWS.MarketplaceMetering.register_usage/3","type":"function","doc":"Paid container software products sold through AWS Marketplace must integrate with the AWS Marketplace Metering Service and call the RegisterUsage operation for software entitlement and metering. Free and BYOL products for Amazon ECS or Amazon EKS aren&#39;t required to call RegisterUsage, but you may choose to do so if you would like to receive usage data in your seller reports. The sections below explain the behavior of RegisterUsage. RegisterUsage performs two primary functions: metering and entitlement. Entitlement: RegisterUsage allows you to verify that the customer running your paid software is subscribed to your product on AWS Marketplace, enabling you to guard against unauthorized use. Your container image that integrates with RegisterUsage is only required to guard against unauthorized use at container startup, as such a CustomerNotSubscribedException/PlatformNotSupportedException will only be thrown on the initial call to RegisterUsage. Subsequent calls from the same Amazon ECS task instance (e.g. task-id) or Amazon EKS pod will not throw a CustomerNotSubscribedException, even if the customer unsubscribes while the Amazon ECS task or Amazon EKS pod is still running. Metering: RegisterUsage meters software use per ECS task, per hour, or per pod for Amazon EKS with usage prorated to the second. A minimum of 1 minute of usage applies to tasks that are short lived. For example, if a customer has a 10 node Amazon ECS or Amazon EKS cluster and a service configured as a Daemon Set, then Amazon ECS or Amazon EKS will launch a task on all 10 cluster nodes and the customer will be charged: (10 * hourly_rate). Metering for software use is automatically handled by the AWS Marketplace Metering Control Plane -- your software is not required to perform any metering specific actions, other than call RegisterUsage once for metering of software use to commence. The AWS Marketplace Metering Control Plane will also continue to bill customers for running ECS tasks and Amazon EKS pods, regardless of the customers subscription state, removing the need for your software to perform entitlement checks at runtime."},{"ref":"AWS.MarketplaceMetering.html#resolve_customer/3","title":"AWS.MarketplaceMetering.resolve_customer/3","type":"function","doc":"ResolveCustomer is called by a SaaS application during the registration process. When a buyer visits your website during the registration process, the buyer submits a registration token through their browser. The registration token is resolved through this API to obtain a CustomerIdentifier and product code."},{"ref":"AWS.MediaConnect.html","title":"AWS.MediaConnect","type":"module","doc":"API for AWS Elemental MediaConnect"},{"ref":"AWS.MediaConnect.html#add_flow_outputs/4","title":"AWS.MediaConnect.add_flow_outputs/4","type":"function","doc":"Adds outputs to an existing flow. You can create up to 50 outputs per flow."},{"ref":"AWS.MediaConnect.html#add_flow_sources/4","title":"AWS.MediaConnect.add_flow_sources/4","type":"function","doc":"Adds Sources to flow"},{"ref":"AWS.MediaConnect.html#add_flow_vpc_interfaces/4","title":"AWS.MediaConnect.add_flow_vpc_interfaces/4","type":"function","doc":"Adds VPC interfaces to flow"},{"ref":"AWS.MediaConnect.html#create_flow/3","title":"AWS.MediaConnect.create_flow/3","type":"function","doc":"Creates a new flow. The request must include one source. The request optionally can include outputs (up to 50) and entitlements (up to 50)."},{"ref":"AWS.MediaConnect.html#delete_flow/4","title":"AWS.MediaConnect.delete_flow/4","type":"function","doc":"Deletes a flow. Before you can delete a flow, you must stop the flow."},{"ref":"AWS.MediaConnect.html#describe_flow/3","title":"AWS.MediaConnect.describe_flow/3","type":"function","doc":"Displays the details of a flow. The response includes the flow ARN, name, and Availability Zone, as well as details about the source, outputs, and entitlements."},{"ref":"AWS.MediaConnect.html#describe_offering/3","title":"AWS.MediaConnect.describe_offering/3","type":"function","doc":"Displays the details of an offering. The response includes the offering description, duration, outbound bandwidth, price, and Amazon Resource Name (ARN)."},{"ref":"AWS.MediaConnect.html#describe_reservation/3","title":"AWS.MediaConnect.describe_reservation/3","type":"function","doc":"Displays the details of a reservation. The response includes the reservation name, state, start date and time, and the details of the offering that make up the rest of the reservation (such as price, duration, and outbound bandwidth)."},{"ref":"AWS.MediaConnect.html#grant_flow_entitlements/4","title":"AWS.MediaConnect.grant_flow_entitlements/4","type":"function","doc":"Grants entitlements to an existing flow."},{"ref":"AWS.MediaConnect.html#list_entitlements/4","title":"AWS.MediaConnect.list_entitlements/4","type":"function","doc":"Displays a list of all entitlements that have been granted to this account. This request returns 20 results per page."},{"ref":"AWS.MediaConnect.html#list_flows/4","title":"AWS.MediaConnect.list_flows/4","type":"function","doc":"Displays a list of flows that are associated with this account. This request returns a paginated result."},{"ref":"AWS.MediaConnect.html#list_offerings/4","title":"AWS.MediaConnect.list_offerings/4","type":"function","doc":"Displays a list of all offerings that are available to this account in the current AWS Region. If you have an active reservation (which means you&#39;ve purchased an offering that has already started and hasn&#39;t expired yet), your account isn&#39;t eligible for other offerings."},{"ref":"AWS.MediaConnect.html#list_reservations/4","title":"AWS.MediaConnect.list_reservations/4","type":"function","doc":"Displays a list of all reservations that have been purchased by this account in the current AWS Region. This list includes all reservations in all states (such as active and expired)."},{"ref":"AWS.MediaConnect.html#list_tags_for_resource/3","title":"AWS.MediaConnect.list_tags_for_resource/3","type":"function","doc":"List all tags on an AWS Elemental MediaConnect resource"},{"ref":"AWS.MediaConnect.html#purchase_offering/4","title":"AWS.MediaConnect.purchase_offering/4","type":"function","doc":"Submits a request to purchase an offering. If you already have an active reservation, you can&#39;t purchase another offering."},{"ref":"AWS.MediaConnect.html#remove_flow_output/5","title":"AWS.MediaConnect.remove_flow_output/5","type":"function","doc":"Removes an output from an existing flow. This request can be made only on an output that does not have an entitlement associated with it. If the output has an entitlement, you must revoke the entitlement instead. When an entitlement is revoked from a flow, the service automatically removes the associated output."},{"ref":"AWS.MediaConnect.html#remove_flow_source/5","title":"AWS.MediaConnect.remove_flow_source/5","type":"function","doc":"Removes a source from an existing flow. This request can be made only if there is more than one source on the flow."},{"ref":"AWS.MediaConnect.html#remove_flow_vpc_interface/5","title":"AWS.MediaConnect.remove_flow_vpc_interface/5","type":"function","doc":"Removes a VPC Interface from an existing flow. This request can be made only on a VPC interface that does not have a Source or Output associated with it. If the VPC interface is referenced by a Source or Output, you must first delete or update the Source or Output to no longer reference the VPC interface."},{"ref":"AWS.MediaConnect.html#revoke_flow_entitlement/5","title":"AWS.MediaConnect.revoke_flow_entitlement/5","type":"function","doc":"Revokes an entitlement from a flow. Once an entitlement is revoked, the content becomes unavailable to the subscriber and the associated output is removed."},{"ref":"AWS.MediaConnect.html#start_flow/4","title":"AWS.MediaConnect.start_flow/4","type":"function","doc":"Starts a flow."},{"ref":"AWS.MediaConnect.html#stop_flow/4","title":"AWS.MediaConnect.stop_flow/4","type":"function","doc":"Stops a flow."},{"ref":"AWS.MediaConnect.html#tag_resource/4","title":"AWS.MediaConnect.tag_resource/4","type":"function","doc":"Associates the specified tags to a resource with the specified resourceArn. If existing tags on a resource are not specified in the request parameters, they are not changed. When a resource is deleted, the tags associated with that resource are deleted as well."},{"ref":"AWS.MediaConnect.html#untag_resource/4","title":"AWS.MediaConnect.untag_resource/4","type":"function","doc":"Deletes specified tags from a resource."},{"ref":"AWS.MediaConnect.html#update_flow/4","title":"AWS.MediaConnect.update_flow/4","type":"function","doc":"Updates flow"},{"ref":"AWS.MediaConnect.html#update_flow_entitlement/5","title":"AWS.MediaConnect.update_flow_entitlement/5","type":"function","doc":"You can change an entitlement&#39;s description, subscribers, and encryption. If you change the subscribers, the service will remove the outputs that are are used by the subscribers that are removed."},{"ref":"AWS.MediaConnect.html#update_flow_output/5","title":"AWS.MediaConnect.update_flow_output/5","type":"function","doc":"Updates an existing flow output."},{"ref":"AWS.MediaConnect.html#update_flow_source/5","title":"AWS.MediaConnect.update_flow_source/5","type":"function","doc":"Updates the source of a flow."},{"ref":"AWS.MediaConvert.html","title":"AWS.MediaConvert","type":"module","doc":"AWS Elemental MediaConvert"},{"ref":"AWS.MediaConvert.html#associate_certificate/3","title":"AWS.MediaConvert.associate_certificate/3","type":"function","doc":"Associates an AWS Certificate Manager (ACM) Amazon Resource Name (ARN) with AWS Elemental MediaConvert."},{"ref":"AWS.MediaConvert.html#cancel_job/4","title":"AWS.MediaConvert.cancel_job/4","type":"function","doc":"Permanently cancel a job. Once you have canceled a job, you can&#39;t start it again."},{"ref":"AWS.MediaConvert.html#create_job/3","title":"AWS.MediaConvert.create_job/3","type":"function","doc":"Create a new transcoding job. For information about jobs and job settings, see the User Guide at http://docs.aws.amazon.com/mediaconvert/latest/ug/what-is.html"},{"ref":"AWS.MediaConvert.html#create_job_template/3","title":"AWS.MediaConvert.create_job_template/3","type":"function","doc":"Create a new job template. For information about job templates see the User Guide at http://docs.aws.amazon.com/mediaconvert/latest/ug/what-is.html"},{"ref":"AWS.MediaConvert.html#create_preset/3","title":"AWS.MediaConvert.create_preset/3","type":"function","doc":"Create a new preset. For information about job templates see the User Guide at http://docs.aws.amazon.com/mediaconvert/latest/ug/what-is.html"},{"ref":"AWS.MediaConvert.html#create_queue/3","title":"AWS.MediaConvert.create_queue/3","type":"function","doc":"Create a new transcoding queue. For information about queues, see Working With Queues in the User Guide at https://docs.aws.amazon.com/mediaconvert/latest/ug/working-with-queues.html"},{"ref":"AWS.MediaConvert.html#delete_job_template/4","title":"AWS.MediaConvert.delete_job_template/4","type":"function","doc":"Permanently delete a job template you have created."},{"ref":"AWS.MediaConvert.html#delete_preset/4","title":"AWS.MediaConvert.delete_preset/4","type":"function","doc":"Permanently delete a preset you have created."},{"ref":"AWS.MediaConvert.html#delete_queue/4","title":"AWS.MediaConvert.delete_queue/4","type":"function","doc":"Permanently delete a queue you have created."},{"ref":"AWS.MediaConvert.html#describe_endpoints/3","title":"AWS.MediaConvert.describe_endpoints/3","type":"function","doc":"Send an request with an empty body to the regional API endpoint to get your account API endpoint."},{"ref":"AWS.MediaConvert.html#disassociate_certificate/4","title":"AWS.MediaConvert.disassociate_certificate/4","type":"function","doc":"Removes an association between the Amazon Resource Name (ARN) of an AWS Certificate Manager (ACM) certificate and an AWS Elemental MediaConvert resource."},{"ref":"AWS.MediaConvert.html#get_job/3","title":"AWS.MediaConvert.get_job/3","type":"function","doc":"Retrieve the JSON for a specific completed transcoding job."},{"ref":"AWS.MediaConvert.html#get_job_template/3","title":"AWS.MediaConvert.get_job_template/3","type":"function","doc":"Retrieve the JSON for a specific job template."},{"ref":"AWS.MediaConvert.html#get_preset/3","title":"AWS.MediaConvert.get_preset/3","type":"function","doc":"Retrieve the JSON for a specific preset."},{"ref":"AWS.MediaConvert.html#get_queue/3","title":"AWS.MediaConvert.get_queue/3","type":"function","doc":"Retrieve the JSON for a specific queue."},{"ref":"AWS.MediaConvert.html#list_job_templates/7","title":"AWS.MediaConvert.list_job_templates/7","type":"function","doc":"Retrieve a JSON array of up to twenty of your job templates. This will return the templates themselves, not just a list of them. To retrieve the next twenty templates, use the nextToken string returned with the array"},{"ref":"AWS.MediaConvert.html#list_jobs/7","title":"AWS.MediaConvert.list_jobs/7","type":"function","doc":"Retrieve a JSON array of up to twenty of your most recently created jobs. This array includes in-process, completed, and errored jobs. This will return the jobs themselves, not just a list of the jobs. To retrieve the twenty next most recent jobs, use the nextToken string returned with the array."},{"ref":"AWS.MediaConvert.html#list_presets/7","title":"AWS.MediaConvert.list_presets/7","type":"function","doc":"Retrieve a JSON array of up to twenty of your presets. This will return the presets themselves, not just a list of them. To retrieve the next twenty presets, use the nextToken string returned with the array."},{"ref":"AWS.MediaConvert.html#list_queues/6","title":"AWS.MediaConvert.list_queues/6","type":"function","doc":"Retrieve a JSON array of up to twenty of your queues. This will return the queues themselves, not just a list of them. To retrieve the next twenty queues, use the nextToken string returned with the array."},{"ref":"AWS.MediaConvert.html#list_tags_for_resource/3","title":"AWS.MediaConvert.list_tags_for_resource/3","type":"function","doc":"Retrieve the tags for a MediaConvert resource."},{"ref":"AWS.MediaConvert.html#tag_resource/3","title":"AWS.MediaConvert.tag_resource/3","type":"function","doc":"Add tags to a MediaConvert queue, preset, or job template. For information about tagging, see the User Guide at https://docs.aws.amazon.com/mediaconvert/latest/ug/tagging-resources.html"},{"ref":"AWS.MediaConvert.html#untag_resource/4","title":"AWS.MediaConvert.untag_resource/4","type":"function","doc":"Remove tags from a MediaConvert queue, preset, or job template. For information about tagging, see the User Guide at https://docs.aws.amazon.com/mediaconvert/latest/ug/tagging-resources.html"},{"ref":"AWS.MediaConvert.html#update_job_template/4","title":"AWS.MediaConvert.update_job_template/4","type":"function","doc":"Modify one of your existing job templates."},{"ref":"AWS.MediaConvert.html#update_preset/4","title":"AWS.MediaConvert.update_preset/4","type":"function","doc":"Modify one of your existing presets."},{"ref":"AWS.MediaConvert.html#update_queue/4","title":"AWS.MediaConvert.update_queue/4","type":"function","doc":"Modify one of your existing queues."},{"ref":"AWS.MediaLive.html","title":"AWS.MediaLive","type":"module","doc":"API for AWS Elemental MediaLive"},{"ref":"AWS.MediaLive.html#batch_delete/3","title":"AWS.MediaLive.batch_delete/3","type":"function","doc":"Starts delete of resources."},{"ref":"AWS.MediaLive.html#batch_start/3","title":"AWS.MediaLive.batch_start/3","type":"function","doc":"Starts existing resources"},{"ref":"AWS.MediaLive.html#batch_stop/3","title":"AWS.MediaLive.batch_stop/3","type":"function","doc":"Stops running resources"},{"ref":"AWS.MediaLive.html#batch_update_schedule/4","title":"AWS.MediaLive.batch_update_schedule/4","type":"function","doc":"Update a channel schedule"},{"ref":"AWS.MediaLive.html#create_channel/3","title":"AWS.MediaLive.create_channel/3","type":"function","doc":"Creates a new channel"},{"ref":"AWS.MediaLive.html#create_input/3","title":"AWS.MediaLive.create_input/3","type":"function","doc":"Create an input"},{"ref":"AWS.MediaLive.html#create_input_security_group/3","title":"AWS.MediaLive.create_input_security_group/3","type":"function","doc":"Creates a Input Security Group"},{"ref":"AWS.MediaLive.html#create_multiplex/3","title":"AWS.MediaLive.create_multiplex/3","type":"function","doc":"Create a new multiplex."},{"ref":"AWS.MediaLive.html#create_multiplex_program/4","title":"AWS.MediaLive.create_multiplex_program/4","type":"function","doc":"Create a new program in the multiplex."},{"ref":"AWS.MediaLive.html#create_tags/4","title":"AWS.MediaLive.create_tags/4","type":"function","doc":"Create tags for a resource"},{"ref":"AWS.MediaLive.html#delete_channel/4","title":"AWS.MediaLive.delete_channel/4","type":"function","doc":"Starts deletion of channel. The associated outputs are also deleted."},{"ref":"AWS.MediaLive.html#delete_input/4","title":"AWS.MediaLive.delete_input/4","type":"function","doc":"Deletes the input end point"},{"ref":"AWS.MediaLive.html#delete_input_security_group/4","title":"AWS.MediaLive.delete_input_security_group/4","type":"function","doc":"Deletes an Input Security Group"},{"ref":"AWS.MediaLive.html#delete_multiplex/4","title":"AWS.MediaLive.delete_multiplex/4","type":"function","doc":"Delete a multiplex. The multiplex must be idle."},{"ref":"AWS.MediaLive.html#delete_multiplex_program/5","title":"AWS.MediaLive.delete_multiplex_program/5","type":"function","doc":"Delete a program from a multiplex."},{"ref":"AWS.MediaLive.html#delete_reservation/4","title":"AWS.MediaLive.delete_reservation/4","type":"function","doc":"Delete an expired reservation."},{"ref":"AWS.MediaLive.html#delete_schedule/4","title":"AWS.MediaLive.delete_schedule/4","type":"function","doc":"Delete all schedule actions on a channel."},{"ref":"AWS.MediaLive.html#delete_tags/4","title":"AWS.MediaLive.delete_tags/4","type":"function","doc":"Removes tags for a resource"},{"ref":"AWS.MediaLive.html#describe_channel/3","title":"AWS.MediaLive.describe_channel/3","type":"function","doc":"Gets details about a channel"},{"ref":"AWS.MediaLive.html#describe_input/3","title":"AWS.MediaLive.describe_input/3","type":"function","doc":"Produces details about an input"},{"ref":"AWS.MediaLive.html#describe_input_device/3","title":"AWS.MediaLive.describe_input_device/3","type":"function","doc":"Gets the details for the input device"},{"ref":"AWS.MediaLive.html#describe_input_device_thumbnail/4","title":"AWS.MediaLive.describe_input_device_thumbnail/4","type":"function","doc":"Get the latest thumbnail data for the input device."},{"ref":"AWS.MediaLive.html#describe_input_security_group/3","title":"AWS.MediaLive.describe_input_security_group/3","type":"function","doc":"Produces a summary of an Input Security Group"},{"ref":"AWS.MediaLive.html#describe_multiplex/3","title":"AWS.MediaLive.describe_multiplex/3","type":"function","doc":"Gets details about a multiplex."},{"ref":"AWS.MediaLive.html#describe_multiplex_program/4","title":"AWS.MediaLive.describe_multiplex_program/4","type":"function","doc":"Get the details for a program in a multiplex."},{"ref":"AWS.MediaLive.html#describe_offering/3","title":"AWS.MediaLive.describe_offering/3","type":"function","doc":"Get details for an offering."},{"ref":"AWS.MediaLive.html#describe_reservation/3","title":"AWS.MediaLive.describe_reservation/3","type":"function","doc":"Get details for a reservation."},{"ref":"AWS.MediaLive.html#describe_schedule/5","title":"AWS.MediaLive.describe_schedule/5","type":"function","doc":"Get a channel schedule"},{"ref":"AWS.MediaLive.html#list_channels/4","title":"AWS.MediaLive.list_channels/4","type":"function","doc":"Produces list of channels that have been created"},{"ref":"AWS.MediaLive.html#list_input_devices/4","title":"AWS.MediaLive.list_input_devices/4","type":"function","doc":"List input devices"},{"ref":"AWS.MediaLive.html#list_input_security_groups/4","title":"AWS.MediaLive.list_input_security_groups/4","type":"function","doc":"Produces a list of Input Security Groups for an account"},{"ref":"AWS.MediaLive.html#list_inputs/4","title":"AWS.MediaLive.list_inputs/4","type":"function","doc":"Produces list of inputs that have been created"},{"ref":"AWS.MediaLive.html#list_multiplex_programs/5","title":"AWS.MediaLive.list_multiplex_programs/5","type":"function","doc":"List the programs that currently exist for a specific multiplex."},{"ref":"AWS.MediaLive.html#list_multiplexes/4","title":"AWS.MediaLive.list_multiplexes/4","type":"function","doc":"Retrieve a list of the existing multiplexes."},{"ref":"AWS.MediaLive.html#list_offerings/14","title":"AWS.MediaLive.list_offerings/14","type":"function","doc":"List offerings available for purchase."},{"ref":"AWS.MediaLive.html#list_reservations/12","title":"AWS.MediaLive.list_reservations/12","type":"function","doc":"List purchased reservations."},{"ref":"AWS.MediaLive.html#list_tags_for_resource/3","title":"AWS.MediaLive.list_tags_for_resource/3","type":"function","doc":"Produces list of tags that have been created for a resource"},{"ref":"AWS.MediaLive.html#purchase_offering/4","title":"AWS.MediaLive.purchase_offering/4","type":"function","doc":"Purchase an offering and create a reservation."},{"ref":"AWS.MediaLive.html#start_channel/4","title":"AWS.MediaLive.start_channel/4","type":"function","doc":"Starts an existing channel"},{"ref":"AWS.MediaLive.html#start_multiplex/4","title":"AWS.MediaLive.start_multiplex/4","type":"function","doc":"Start (run) the multiplex. Starting the multiplex does not start the channels. You must explicitly start each channel."},{"ref":"AWS.MediaLive.html#stop_channel/4","title":"AWS.MediaLive.stop_channel/4","type":"function","doc":"Stops a running channel"},{"ref":"AWS.MediaLive.html#stop_multiplex/4","title":"AWS.MediaLive.stop_multiplex/4","type":"function","doc":"Stops a running multiplex. If the multiplex isn&#39;t running, this action has no effect."},{"ref":"AWS.MediaLive.html#update_channel/4","title":"AWS.MediaLive.update_channel/4","type":"function","doc":"Updates a channel."},{"ref":"AWS.MediaLive.html#update_channel_class/4","title":"AWS.MediaLive.update_channel_class/4","type":"function","doc":"Changes the class of the channel."},{"ref":"AWS.MediaLive.html#update_input/4","title":"AWS.MediaLive.update_input/4","type":"function","doc":"Updates an input."},{"ref":"AWS.MediaLive.html#update_input_device/4","title":"AWS.MediaLive.update_input_device/4","type":"function","doc":"Updates the parameters for the input device."},{"ref":"AWS.MediaLive.html#update_input_security_group/4","title":"AWS.MediaLive.update_input_security_group/4","type":"function","doc":"Update an Input Security Group&#39;s Whilelists."},{"ref":"AWS.MediaLive.html#update_multiplex/4","title":"AWS.MediaLive.update_multiplex/4","type":"function","doc":"Updates a multiplex."},{"ref":"AWS.MediaLive.html#update_multiplex_program/5","title":"AWS.MediaLive.update_multiplex_program/5","type":"function","doc":"Update a program in a multiplex."},{"ref":"AWS.MediaLive.html#update_reservation/4","title":"AWS.MediaLive.update_reservation/4","type":"function","doc":"Update reservation."},{"ref":"AWS.MediaPackage.html","title":"AWS.MediaPackage","type":"module","doc":"AWS Elemental MediaPackage"},{"ref":"AWS.MediaPackage.html#configure_logs/4","title":"AWS.MediaPackage.configure_logs/4","type":"function","doc":"Changes the Channel&#39;s properities to configure log subscription"},{"ref":"AWS.MediaPackage.html#create_channel/3","title":"AWS.MediaPackage.create_channel/3","type":"function","doc":"Creates a new Channel."},{"ref":"AWS.MediaPackage.html#create_harvest_job/3","title":"AWS.MediaPackage.create_harvest_job/3","type":"function","doc":"Creates a new HarvestJob record."},{"ref":"AWS.MediaPackage.html#create_origin_endpoint/3","title":"AWS.MediaPackage.create_origin_endpoint/3","type":"function","doc":"Creates a new OriginEndpoint record."},{"ref":"AWS.MediaPackage.html#delete_channel/4","title":"AWS.MediaPackage.delete_channel/4","type":"function","doc":"Deletes an existing Channel."},{"ref":"AWS.MediaPackage.html#delete_origin_endpoint/4","title":"AWS.MediaPackage.delete_origin_endpoint/4","type":"function","doc":"Deletes an existing OriginEndpoint."},{"ref":"AWS.MediaPackage.html#describe_channel/3","title":"AWS.MediaPackage.describe_channel/3","type":"function","doc":"Gets details about a Channel."},{"ref":"AWS.MediaPackage.html#describe_harvest_job/3","title":"AWS.MediaPackage.describe_harvest_job/3","type":"function","doc":"Gets details about an existing HarvestJob."},{"ref":"AWS.MediaPackage.html#describe_origin_endpoint/3","title":"AWS.MediaPackage.describe_origin_endpoint/3","type":"function","doc":"Gets details about an existing OriginEndpoint."},{"ref":"AWS.MediaPackage.html#list_channels/4","title":"AWS.MediaPackage.list_channels/4","type":"function","doc":"Returns a collection of Channels."},{"ref":"AWS.MediaPackage.html#list_harvest_jobs/6","title":"AWS.MediaPackage.list_harvest_jobs/6","type":"function","doc":"Returns a collection of HarvestJob records."},{"ref":"AWS.MediaPackage.html#list_origin_endpoints/5","title":"AWS.MediaPackage.list_origin_endpoints/5","type":"function","doc":"Returns a collection of OriginEndpoint records."},{"ref":"AWS.MediaPackage.html#list_tags_for_resource/3","title":"AWS.MediaPackage.list_tags_for_resource/3","type":"function","doc":""},{"ref":"AWS.MediaPackage.html#rotate_channel_credentials/4","title":"AWS.MediaPackage.rotate_channel_credentials/4","type":"function","doc":"Changes the Channel&#39;s first IngestEndpoint&#39;s username and password. WARNING - This API is deprecated. Please use RotateIngestEndpointCredentials instead"},{"ref":"AWS.MediaPackage.html#rotate_ingest_endpoint_credentials/5","title":"AWS.MediaPackage.rotate_ingest_endpoint_credentials/5","type":"function","doc":"Rotate the IngestEndpoint&#39;s username and password, as specified by the IngestEndpoint&#39;s id."},{"ref":"AWS.MediaPackage.html#tag_resource/4","title":"AWS.MediaPackage.tag_resource/4","type":"function","doc":""},{"ref":"AWS.MediaPackage.html#untag_resource/4","title":"AWS.MediaPackage.untag_resource/4","type":"function","doc":""},{"ref":"AWS.MediaPackage.html#update_channel/4","title":"AWS.MediaPackage.update_channel/4","type":"function","doc":"Updates an existing Channel."},{"ref":"AWS.MediaPackage.html#update_origin_endpoint/4","title":"AWS.MediaPackage.update_origin_endpoint/4","type":"function","doc":"Updates an existing OriginEndpoint."},{"ref":"AWS.MediaPackageVod.html","title":"AWS.MediaPackageVod","type":"module","doc":"AWS Elemental MediaPackage VOD"},{"ref":"AWS.MediaPackageVod.html#create_asset/3","title":"AWS.MediaPackageVod.create_asset/3","type":"function","doc":"Creates a new MediaPackage VOD Asset resource."},{"ref":"AWS.MediaPackageVod.html#create_packaging_configuration/3","title":"AWS.MediaPackageVod.create_packaging_configuration/3","type":"function","doc":"Creates a new MediaPackage VOD PackagingConfiguration resource."},{"ref":"AWS.MediaPackageVod.html#create_packaging_group/3","title":"AWS.MediaPackageVod.create_packaging_group/3","type":"function","doc":"Creates a new MediaPackage VOD PackagingGroup resource."},{"ref":"AWS.MediaPackageVod.html#delete_asset/4","title":"AWS.MediaPackageVod.delete_asset/4","type":"function","doc":"Deletes an existing MediaPackage VOD Asset resource."},{"ref":"AWS.MediaPackageVod.html#delete_packaging_configuration/4","title":"AWS.MediaPackageVod.delete_packaging_configuration/4","type":"function","doc":"Deletes a MediaPackage VOD PackagingConfiguration resource."},{"ref":"AWS.MediaPackageVod.html#delete_packaging_group/4","title":"AWS.MediaPackageVod.delete_packaging_group/4","type":"function","doc":"Deletes a MediaPackage VOD PackagingGroup resource."},{"ref":"AWS.MediaPackageVod.html#describe_asset/3","title":"AWS.MediaPackageVod.describe_asset/3","type":"function","doc":"Returns a description of a MediaPackage VOD Asset resource."},{"ref":"AWS.MediaPackageVod.html#describe_packaging_configuration/3","title":"AWS.MediaPackageVod.describe_packaging_configuration/3","type":"function","doc":"Returns a description of a MediaPackage VOD PackagingConfiguration resource."},{"ref":"AWS.MediaPackageVod.html#describe_packaging_group/3","title":"AWS.MediaPackageVod.describe_packaging_group/3","type":"function","doc":"Returns a description of a MediaPackage VOD PackagingGroup resource."},{"ref":"AWS.MediaPackageVod.html#list_assets/5","title":"AWS.MediaPackageVod.list_assets/5","type":"function","doc":"Returns a collection of MediaPackage VOD Asset resources."},{"ref":"AWS.MediaPackageVod.html#list_packaging_configurations/5","title":"AWS.MediaPackageVod.list_packaging_configurations/5","type":"function","doc":"Returns a collection of MediaPackage VOD PackagingConfiguration resources."},{"ref":"AWS.MediaPackageVod.html#list_packaging_groups/4","title":"AWS.MediaPackageVod.list_packaging_groups/4","type":"function","doc":"Returns a collection of MediaPackage VOD PackagingGroup resources."},{"ref":"AWS.MediaPackageVod.html#list_tags_for_resource/3","title":"AWS.MediaPackageVod.list_tags_for_resource/3","type":"function","doc":"Returns a list of the tags assigned to the specified resource."},{"ref":"AWS.MediaPackageVod.html#tag_resource/4","title":"AWS.MediaPackageVod.tag_resource/4","type":"function","doc":"Adds tags to the specified resource. You can specify one or more tags to add."},{"ref":"AWS.MediaPackageVod.html#untag_resource/4","title":"AWS.MediaPackageVod.untag_resource/4","type":"function","doc":"Removes tags from the specified resource. You can specify one or more tags to remove."},{"ref":"AWS.MediaPackageVod.html#update_packaging_group/4","title":"AWS.MediaPackageVod.update_packaging_group/4","type":"function","doc":"Updates a specific packaging group. You can&#39;t change the id attribute or any other system-generated attributes."},{"ref":"AWS.MediaStore.html","title":"AWS.MediaStore","type":"module","doc":"An AWS Elemental MediaStore container is a namespace that holds folders and objects. You use a container endpoint to create, read, and delete objects."},{"ref":"AWS.MediaStore.html#create_container/3","title":"AWS.MediaStore.create_container/3","type":"function","doc":"Creates a storage container to hold objects. A container is similar to a bucket in the Amazon S3 service."},{"ref":"AWS.MediaStore.html#delete_container/3","title":"AWS.MediaStore.delete_container/3","type":"function","doc":"Deletes the specified container. Before you make a DeleteContainer request, delete any objects in the container or in any folders in the container. You can delete only empty containers."},{"ref":"AWS.MediaStore.html#delete_container_policy/3","title":"AWS.MediaStore.delete_container_policy/3","type":"function","doc":"Deletes the access policy that is associated with the specified container."},{"ref":"AWS.MediaStore.html#delete_cors_policy/3","title":"AWS.MediaStore.delete_cors_policy/3","type":"function","doc":"Deletes the cross-origin resource sharing (CORS) configuration information that is set for the container. To use this operation, you must have permission to perform the MediaStore:DeleteCorsPolicy action. The container owner has this permission by default and can grant this permission to others."},{"ref":"AWS.MediaStore.html#delete_lifecycle_policy/3","title":"AWS.MediaStore.delete_lifecycle_policy/3","type":"function","doc":"Removes an object lifecycle policy from a container. It takes up to 20 minutes for the change to take effect."},{"ref":"AWS.MediaStore.html#delete_metric_policy/3","title":"AWS.MediaStore.delete_metric_policy/3","type":"function","doc":"Deletes the metric policy that is associated with the specified container. If there is no metric policy associated with the container, MediaStore doesn&#39;t send metrics to CloudWatch."},{"ref":"AWS.MediaStore.html#describe_container/3","title":"AWS.MediaStore.describe_container/3","type":"function","doc":"Retrieves the properties of the requested container. This request is commonly used to retrieve the endpoint of a container. An endpoint is a value assigned by the service when a new container is created. A container&#39;s endpoint does not change after it has been assigned. The DescribeContainer request returns a single Container object based on ContainerName. To return all Container objects that are associated with a specified AWS account, use ListContainers."},{"ref":"AWS.MediaStore.html#get_container_policy/3","title":"AWS.MediaStore.get_container_policy/3","type":"function","doc":"Retrieves the access policy for the specified container. For information about the data that is included in an access policy, see the AWS Identity and Access Management User Guide."},{"ref":"AWS.MediaStore.html#get_cors_policy/3","title":"AWS.MediaStore.get_cors_policy/3","type":"function","doc":"Returns the cross-origin resource sharing (CORS) configuration information that is set for the container. To use this operation, you must have permission to perform the MediaStore:GetCorsPolicy action. By default, the container owner has this permission and can grant it to others."},{"ref":"AWS.MediaStore.html#get_lifecycle_policy/3","title":"AWS.MediaStore.get_lifecycle_policy/3","type":"function","doc":"Retrieves the object lifecycle policy that is assigned to a container."},{"ref":"AWS.MediaStore.html#get_metric_policy/3","title":"AWS.MediaStore.get_metric_policy/3","type":"function","doc":"Returns the metric policy for the specified container."},{"ref":"AWS.MediaStore.html#list_containers/3","title":"AWS.MediaStore.list_containers/3","type":"function","doc":"Lists the properties of all containers in AWS Elemental MediaStore. You can query to receive all the containers in one response. Or you can include the MaxResults parameter to receive a limited number of containers in each response. In this case, the response includes a token. To get the next set of containers, send the command again, this time with the NextToken parameter (with the returned token as its value). The next set of responses appears, with a token if there are still more containers to receive. See also DescribeContainer, which gets the properties of one container."},{"ref":"AWS.MediaStore.html#list_tags_for_resource/3","title":"AWS.MediaStore.list_tags_for_resource/3","type":"function","doc":"Returns a list of the tags assigned to the specified container."},{"ref":"AWS.MediaStore.html#put_container_policy/3","title":"AWS.MediaStore.put_container_policy/3","type":"function","doc":"Creates an access policy for the specified container to restrict the users and clients that can access it. For information about the data that is included in an access policy, see the AWS Identity and Access Management User Guide. For this release of the REST API, you can create only one policy for a container. If you enter PutContainerPolicy twice, the second command modifies the existing policy."},{"ref":"AWS.MediaStore.html#put_cors_policy/3","title":"AWS.MediaStore.put_cors_policy/3","type":"function","doc":"Sets the cross-origin resource sharing (CORS) configuration on a container so that the container can service cross-origin requests. For example, you might want to enable a request whose origin is http://www.example.com to access your AWS Elemental MediaStore container at my.example.container.com by using the browser&#39;s XMLHttpRequest capability. To enable CORS on a container, you attach a CORS policy to the container. In the CORS policy, you configure rules that identify origins and the HTTP methods that can be executed on your container. The policy can contain up to 398,000 characters. You can add up to 100 rules to a CORS policy. If more than one rule applies, the service uses the first applicable rule listed. To learn more about CORS, see Cross-Origin Resource Sharing (CORS) in AWS Elemental MediaStore."},{"ref":"AWS.MediaStore.html#put_lifecycle_policy/3","title":"AWS.MediaStore.put_lifecycle_policy/3","type":"function","doc":"Writes an object lifecycle policy to a container. If the container already has an object lifecycle policy, the service replaces the existing policy with the new policy. It takes up to 20 minutes for the change to take effect. For information about how to construct an object lifecycle policy, see Components of an Object Lifecycle Policy."},{"ref":"AWS.MediaStore.html#put_metric_policy/3","title":"AWS.MediaStore.put_metric_policy/3","type":"function","doc":"The metric policy that you want to add to the container. A metric policy allows AWS Elemental MediaStore to send metrics to Amazon CloudWatch. It takes up to 20 minutes for the new policy to take effect."},{"ref":"AWS.MediaStore.html#start_access_logging/3","title":"AWS.MediaStore.start_access_logging/3","type":"function","doc":"Starts access logging on the specified container. When you enable access logging on a container, MediaStore delivers access logs for objects stored in that container to Amazon CloudWatch Logs."},{"ref":"AWS.MediaStore.html#stop_access_logging/3","title":"AWS.MediaStore.stop_access_logging/3","type":"function","doc":"Stops access logging on the specified container. When you stop access logging on a container, MediaStore stops sending access logs to Amazon CloudWatch Logs. These access logs are not saved and are not retrievable."},{"ref":"AWS.MediaStore.html#tag_resource/3","title":"AWS.MediaStore.tag_resource/3","type":"function","doc":"Adds tags to the specified AWS Elemental MediaStore container. Tags are key:value pairs that you can associate with AWS resources. For example, the tag key might be &quot;customer&quot; and the tag value might be &quot;companyA.&quot; You can specify one or more tags to add to each container. You can add up to 50 tags to each container. For more information about tagging, including naming and usage conventions, see Tagging Resources in MediaStore."},{"ref":"AWS.MediaStore.html#untag_resource/3","title":"AWS.MediaStore.untag_resource/3","type":"function","doc":"Removes tags from the specified container. You can specify one or more tags to remove."},{"ref":"AWS.MediaStoreData.html","title":"AWS.MediaStoreData","type":"module","doc":"An AWS Elemental MediaStore asset is an object, similar to an object in the Amazon S3 service. Objects are the fundamental entities that are stored in AWS Elemental MediaStore."},{"ref":"AWS.MediaStoreData.html#delete_object/4","title":"AWS.MediaStoreData.delete_object/4","type":"function","doc":"Deletes an object at the specified path."},{"ref":"AWS.MediaStoreData.html#describe_object/4","title":"AWS.MediaStoreData.describe_object/4","type":"function","doc":"Gets the headers for an object at the specified path."},{"ref":"AWS.MediaStoreData.html#get_object/4","title":"AWS.MediaStoreData.get_object/4","type":"function","doc":"Downloads the object at the specified path. If the objects upload availability is set to streaming, AWS Elemental MediaStore downloads the object even if its still uploading the object."},{"ref":"AWS.MediaStoreData.html#list_items/5","title":"AWS.MediaStoreData.list_items/5","type":"function","doc":"Provides a list of metadata entries about folders and objects in the specified folder."},{"ref":"AWS.MediaStoreData.html#put_object/4","title":"AWS.MediaStoreData.put_object/4","type":"function","doc":"Uploads an object to the specified path. Object sizes are limited to 25 MB for standard upload availability and 10 MB for streaming upload availability."},{"ref":"AWS.MediaTailor.html","title":"AWS.MediaTailor","type":"module","doc":"Use the AWS Elemental MediaTailor SDK to configure scalable ad insertion for your live and VOD content. With AWS Elemental MediaTailor, you can serve targeted ads to viewers while maintaining broadcast quality in over-the-top (OTT) video applications. For information about using the service, including detailed information about the settings covered in this guide, see the AWS Elemental MediaTailor User Guide. Through the SDK, you manage AWS Elemental MediaTailor configurations the same as you do through the console. For example, you specify ad insertion behavior and mapping information for the origin server and the ad decision server (ADS)."},{"ref":"AWS.MediaTailor.html#delete_playback_configuration/4","title":"AWS.MediaTailor.delete_playback_configuration/4","type":"function","doc":"Deletes the playback configuration for the specified name."},{"ref":"AWS.MediaTailor.html#get_playback_configuration/3","title":"AWS.MediaTailor.get_playback_configuration/3","type":"function","doc":"Returns the playback configuration for the specified name."},{"ref":"AWS.MediaTailor.html#list_playback_configurations/4","title":"AWS.MediaTailor.list_playback_configurations/4","type":"function","doc":"Returns a list of the playback configurations defined in AWS Elemental MediaTailor. You can specify a maximum number of configurations to return at a time. The default maximum is 50. Results are returned in pagefuls. If MediaTailor has more configurations than the specified maximum, it provides parameters in the response that you can use to retrieve the next pageful."},{"ref":"AWS.MediaTailor.html#list_tags_for_resource/3","title":"AWS.MediaTailor.list_tags_for_resource/3","type":"function","doc":"Returns a list of the tags assigned to the specified playback configuration resource."},{"ref":"AWS.MediaTailor.html#put_playback_configuration/3","title":"AWS.MediaTailor.put_playback_configuration/3","type":"function","doc":"Adds a new playback configuration to AWS Elemental MediaTailor."},{"ref":"AWS.MediaTailor.html#tag_resource/4","title":"AWS.MediaTailor.tag_resource/4","type":"function","doc":"Adds tags to the specified playback configuration resource. You can specify one or more tags to add."},{"ref":"AWS.MediaTailor.html#untag_resource/4","title":"AWS.MediaTailor.untag_resource/4","type":"function","doc":"Removes tags from the specified playback configuration resource. You can specify one or more tags to remove."},{"ref":"AWS.MigrationHub.html","title":"AWS.MigrationHub","type":"module","doc":"The AWS Migration Hub API methods help to obtain server and application migration status and integrate your resource-specific migration tool by providing a programmatic interface to Migration Hub. Remember that you must set your AWS Migration Hub home region before you call any of these APIs, or a HomeRegionNotSetException error will be returned. Also, you must make the API calls while in your home region."},{"ref":"AWS.MigrationHub.html#associate_created_artifact/3","title":"AWS.MigrationHub.associate_created_artifact/3","type":"function","doc":"Associates a created artifact of an AWS cloud resource, the target receiving the migration, with the migration task performed by a migration tool. This API has the following traits: Migration tools can call the AssociateCreatedArtifact operation to indicate which AWS artifact is associated with a migration task. The created artifact name must be provided in ARN (Amazon Resource Name) format which will contain information about type and region; for example: arn:aws:ec2:us-east-1:488216288981:image/ami-6d0ba87b. Examples of the AWS resource behind the created artifact are, AMI&#39;s, EC2 instance, or DMS endpoint, etc."},{"ref":"AWS.MigrationHub.html#associate_discovered_resource/3","title":"AWS.MigrationHub.associate_discovered_resource/3","type":"function","doc":"Associates a discovered resource ID from Application Discovery Service with a migration task."},{"ref":"AWS.MigrationHub.html#create_progress_update_stream/3","title":"AWS.MigrationHub.create_progress_update_stream/3","type":"function","doc":"Creates a progress update stream which is an AWS resource used for access control as well as a namespace for migration task names that is implicitly linked to your AWS account. It must uniquely identify the migration tool as it is used for all updates made by the tool; however, it does not need to be unique for each AWS account because it is scoped to the AWS account."},{"ref":"AWS.MigrationHub.html#delete_progress_update_stream/3","title":"AWS.MigrationHub.delete_progress_update_stream/3","type":"function","doc":"Deletes a progress update stream, including all of its tasks, which was previously created as an AWS resource used for access control. This API has the following traits: The only parameter needed for DeleteProgressUpdateStream is the stream name (same as a CreateProgressUpdateStream call). The call will return, and a background process will asynchronously delete the stream and all of its resources (tasks, associated resources, resource attributes, created artifacts). If the stream takes time to be deleted, it might still show up on a ListProgressUpdateStreams call. CreateProgressUpdateStream, ImportMigrationTask, NotifyMigrationTaskState, and all Associate[*] APIs related to the tasks belonging to the stream will throw &quot;InvalidInputException&quot; if the stream of the same name is in the process of being deleted. Once the stream and all of its resources are deleted, CreateProgressUpdateStream for a stream of the same name will succeed, and that stream will be an entirely new logical resource (without any resources associated with the old stream)."},{"ref":"AWS.MigrationHub.html#describe_application_state/3","title":"AWS.MigrationHub.describe_application_state/3","type":"function","doc":"Gets the migration status of an application."},{"ref":"AWS.MigrationHub.html#describe_migration_task/3","title":"AWS.MigrationHub.describe_migration_task/3","type":"function","doc":"Retrieves a list of all attributes associated with a specific migration task."},{"ref":"AWS.MigrationHub.html#disassociate_created_artifact/3","title":"AWS.MigrationHub.disassociate_created_artifact/3","type":"function","doc":"Disassociates a created artifact of an AWS resource with a migration task performed by a migration tool that was previously associated. This API has the following traits: A migration user can call the DisassociateCreatedArtifacts operation to disassociate a created AWS Artifact from a migration task. The created artifact name must be provided in ARN (Amazon Resource Name) format which will contain information about type and region; for example: arn:aws:ec2:us-east-1:488216288981:image/ami-6d0ba87b. Examples of the AWS resource behind the created artifact are, AMI&#39;s, EC2 instance, or RDS instance, etc."},{"ref":"AWS.MigrationHub.html#disassociate_discovered_resource/3","title":"AWS.MigrationHub.disassociate_discovered_resource/3","type":"function","doc":"Disassociate an Application Discovery Service discovered resource from a migration task."},{"ref":"AWS.MigrationHub.html#import_migration_task/3","title":"AWS.MigrationHub.import_migration_task/3","type":"function","doc":"Registers a new migration task which represents a server, database, etc., being migrated to AWS by a migration tool. This API is a prerequisite to calling the NotifyMigrationTaskState API as the migration tool must first register the migration task with Migration Hub."},{"ref":"AWS.MigrationHub.html#list_application_states/3","title":"AWS.MigrationHub.list_application_states/3","type":"function","doc":"Lists all the migration statuses for your applications. If you use the optional ApplicationIds parameter, only the migration statuses for those applications will be returned."},{"ref":"AWS.MigrationHub.html#list_created_artifacts/3","title":"AWS.MigrationHub.list_created_artifacts/3","type":"function","doc":"Lists the created artifacts attached to a given migration task in an update stream. This API has the following traits: Gets the list of the created artifacts while migration is taking place. Shows the artifacts created by the migration tool that was associated by the AssociateCreatedArtifact API. Lists created artifacts in a paginated interface."},{"ref":"AWS.MigrationHub.html#list_discovered_resources/3","title":"AWS.MigrationHub.list_discovered_resources/3","type":"function","doc":"Lists discovered resources associated with the given MigrationTask."},{"ref":"AWS.MigrationHub.html#list_migration_tasks/3","title":"AWS.MigrationHub.list_migration_tasks/3","type":"function","doc":"Lists all, or filtered by resource name, migration tasks associated with the user account making this call. This API has the following traits: Can show a summary list of the most recent migration tasks. Can show a summary list of migration tasks associated with a given discovered resource. Lists migration tasks in a paginated interface."},{"ref":"AWS.MigrationHub.html#list_progress_update_streams/3","title":"AWS.MigrationHub.list_progress_update_streams/3","type":"function","doc":"Lists progress update streams associated with the user account making this call."},{"ref":"AWS.MigrationHub.html#notify_application_state/3","title":"AWS.MigrationHub.notify_application_state/3","type":"function","doc":"Sets the migration state of an application. For a given application identified by the value passed to ApplicationId, its status is set or updated by passing one of three values to Status: NOT_STARTED | IN_PROGRESS | COMPLETED."},{"ref":"AWS.MigrationHub.html#notify_migration_task_state/3","title":"AWS.MigrationHub.notify_migration_task_state/3","type":"function","doc":"Notifies Migration Hub of the current status, progress, or other detail regarding a migration task. This API has the following traits: Migration tools will call the NotifyMigrationTaskState API to share the latest progress and status. MigrationTaskName is used for addressing updates to the correct target. ProgressUpdateStream is used for access control and to provide a namespace for each migration tool."},{"ref":"AWS.MigrationHub.html#put_resource_attributes/3","title":"AWS.MigrationHub.put_resource_attributes/3","type":"function","doc":"Provides identifying details of the resource being migrated so that it can be associated in the Application Discovery Service repository. This association occurs asynchronously after PutResourceAttributes returns. Keep in mind that subsequent calls to PutResourceAttributes will override previously stored attributes. For example, if it is first called with a MAC address, but later, it is desired to add an IP address, it will then be required to call it with both the IP and MAC addresses to prevent overriding the MAC address. Note the instructions regarding the special use case of the ResourceAttributeList parameter when specifying any &quot;VM&quot; related value. Because this is an asynchronous call, it will always return 200, whether an association occurs or not. To confirm if an association was found based on the provided details, call ListDiscoveredResources."},{"ref":"AWS.MigrationHubConfig.html","title":"AWS.MigrationHubConfig","type":"module","doc":"The AWS Migration Hub home region APIs are available specifically for working with your Migration Hub home region. You can use these APIs to determine a home region, as well as to create and work with controls that describe the home region. You must make API calls for write actions (create, notify, associate, disassociate, import, or put) while in your home region, or a HomeRegionNotSetException error is returned. API calls for read actions (list, describe, stop, and delete) are permitted outside of your home region. If you call a write API outside the home region, an InvalidInputException is returned. You can call GetHomeRegion action to obtain the account&#39;s Migration Hub home region. For specific API usage, see the sections that follow in this AWS Migration Hub Home Region API reference."},{"ref":"AWS.MigrationHubConfig.html#create_home_region_control/3","title":"AWS.MigrationHubConfig.create_home_region_control/3","type":"function","doc":"This API sets up the home region for the calling account only."},{"ref":"AWS.MigrationHubConfig.html#describe_home_region_controls/3","title":"AWS.MigrationHubConfig.describe_home_region_controls/3","type":"function","doc":"This API permits filtering on the ControlId and HomeRegion fields."},{"ref":"AWS.MigrationHubConfig.html#get_home_region/3","title":"AWS.MigrationHubConfig.get_home_region/3","type":"function","doc":"Returns the calling accounts home region, if configured. This API is used by other AWS services to determine the regional endpoint for calling AWS Application Discovery Service and Migration Hub. You must call GetHomeRegion at least once before you call any other AWS Application Discovery Service and AWS Migration Hub APIs, to obtain the account&#39;s Migration Hub home region."},{"ref":"AWS.Mobile.html","title":"AWS.Mobile","type":"module","doc":"AWS Mobile Service provides mobile app and website developers with capabilities required to configure AWS resources and bootstrap their developer desktop projects with the necessary SDKs, constants, tools and samples to make use of those resources."},{"ref":"AWS.Mobile.html#create_project/3","title":"AWS.Mobile.create_project/3","type":"function","doc":"Creates an AWS Mobile Hub project."},{"ref":"AWS.Mobile.html#delete_project/4","title":"AWS.Mobile.delete_project/4","type":"function","doc":"Delets a project in AWS Mobile Hub."},{"ref":"AWS.Mobile.html#describe_bundle/3","title":"AWS.Mobile.describe_bundle/3","type":"function","doc":"Get the bundle details for the requested bundle id."},{"ref":"AWS.Mobile.html#describe_project/4","title":"AWS.Mobile.describe_project/4","type":"function","doc":"Gets details about a project in AWS Mobile Hub."},{"ref":"AWS.Mobile.html#export_bundle/4","title":"AWS.Mobile.export_bundle/4","type":"function","doc":"Generates customized software development kit (SDK) and or tool packages used to integrate mobile web or mobile app clients with backend AWS resources."},{"ref":"AWS.Mobile.html#export_project/4","title":"AWS.Mobile.export_project/4","type":"function","doc":"Exports project configuration to a snapshot which can be downloaded and shared. Note that mobile app push credentials are encrypted in exported projects, so they can only be shared successfully within the same AWS account."},{"ref":"AWS.Mobile.html#list_bundles/4","title":"AWS.Mobile.list_bundles/4","type":"function","doc":"List all available bundles."},{"ref":"AWS.Mobile.html#list_projects/4","title":"AWS.Mobile.list_projects/4","type":"function","doc":"Lists projects in AWS Mobile Hub."},{"ref":"AWS.Mobile.html#update_project/3","title":"AWS.Mobile.update_project/3","type":"function","doc":"Update an existing project."},{"ref":"AWS.Mobileanalytics.html","title":"AWS.Mobileanalytics","type":"module","doc":"Amazon Mobile Analytics is a service for collecting, visualizing, and understanding app usage data at scale."},{"ref":"AWS.Mobileanalytics.html#put_events/3","title":"AWS.Mobileanalytics.put_events/3","type":"function","doc":"The PutEvents operation records one or more events. You can have up to 1,500 unique custom events per app, any combination of up to 40 attributes and metrics per custom event, and any number of attribute or metric values."},{"ref":"AWS.Mq.html","title":"AWS.Mq","type":"module","doc":"Amazon MQ is a managed message broker service for Apache ActiveMQ that makes it easy to set up and operate message brokers in the cloud. A message broker allows software applications and components to communicate using various programming languages, operating systems, and formal messaging protocols."},{"ref":"AWS.Mq.html#create_broker/3","title":"AWS.Mq.create_broker/3","type":"function","doc":"Creates a broker. Note: This API is asynchronous."},{"ref":"AWS.Mq.html#create_configuration/3","title":"AWS.Mq.create_configuration/3","type":"function","doc":"Creates a new configuration for the specified configuration name. Amazon MQ uses the default configuration (the engine type and version)."},{"ref":"AWS.Mq.html#create_tags/4","title":"AWS.Mq.create_tags/4","type":"function","doc":"Add a tag to a resource."},{"ref":"AWS.Mq.html#create_user/5","title":"AWS.Mq.create_user/5","type":"function","doc":"Creates an ActiveMQ user."},{"ref":"AWS.Mq.html#delete_broker/4","title":"AWS.Mq.delete_broker/4","type":"function","doc":"Deletes a broker. Note: This API is asynchronous."},{"ref":"AWS.Mq.html#delete_tags/4","title":"AWS.Mq.delete_tags/4","type":"function","doc":"Removes a tag from a resource."},{"ref":"AWS.Mq.html#delete_user/5","title":"AWS.Mq.delete_user/5","type":"function","doc":"Deletes an ActiveMQ user."},{"ref":"AWS.Mq.html#describe_broker/3","title":"AWS.Mq.describe_broker/3","type":"function","doc":"Returns information about the specified broker."},{"ref":"AWS.Mq.html#describe_broker_engine_types/5","title":"AWS.Mq.describe_broker_engine_types/5","type":"function","doc":"Describe available engine types and versions."},{"ref":"AWS.Mq.html#describe_broker_instance_options/7","title":"AWS.Mq.describe_broker_instance_options/7","type":"function","doc":"Describe available broker instance options."},{"ref":"AWS.Mq.html#describe_configuration/3","title":"AWS.Mq.describe_configuration/3","type":"function","doc":"Returns information about the specified configuration."},{"ref":"AWS.Mq.html#describe_configuration_revision/4","title":"AWS.Mq.describe_configuration_revision/4","type":"function","doc":"Returns the specified configuration revision for the specified configuration."},{"ref":"AWS.Mq.html#describe_user/4","title":"AWS.Mq.describe_user/4","type":"function","doc":"Returns information about an ActiveMQ user."},{"ref":"AWS.Mq.html#list_brokers/4","title":"AWS.Mq.list_brokers/4","type":"function","doc":"Returns a list of all brokers."},{"ref":"AWS.Mq.html#list_configuration_revisions/5","title":"AWS.Mq.list_configuration_revisions/5","type":"function","doc":"Returns a list of all revisions for the specified configuration."},{"ref":"AWS.Mq.html#list_configurations/4","title":"AWS.Mq.list_configurations/4","type":"function","doc":"Returns a list of all configurations."},{"ref":"AWS.Mq.html#list_tags/3","title":"AWS.Mq.list_tags/3","type":"function","doc":"Lists tags for a resource."},{"ref":"AWS.Mq.html#list_users/5","title":"AWS.Mq.list_users/5","type":"function","doc":"Returns a list of all ActiveMQ users."},{"ref":"AWS.Mq.html#reboot_broker/4","title":"AWS.Mq.reboot_broker/4","type":"function","doc":"Reboots a broker. Note: This API is asynchronous."},{"ref":"AWS.Mq.html#update_broker/4","title":"AWS.Mq.update_broker/4","type":"function","doc":"Adds a pending configuration change to a broker."},{"ref":"AWS.Mq.html#update_configuration/4","title":"AWS.Mq.update_configuration/4","type":"function","doc":"Updates the specified configuration."},{"ref":"AWS.Mq.html#update_user/5","title":"AWS.Mq.update_user/5","type":"function","doc":"Updates the information for an ActiveMQ user."},{"ref":"AWS.Neptune.html","title":"AWS.Neptune","type":"module","doc":"Amazon Neptune Amazon Neptune is a fast, reliable, fully-managed graph database service that makes it easy to build and run applications that work with highly connected datasets. The core of Amazon Neptune is a purpose-built, high-performance graph database engine optimized for storing billions of relationships and querying the graph with milliseconds latency. Amazon Neptune supports popular graph models Property Graph and W3C&#39;s RDF, and their respective query languages Apache TinkerPop Gremlin and SPARQL, allowing you to easily build queries that efficiently navigate highly connected datasets. Neptune powers graph use cases such as recommendation engines, fraud detection, knowledge graphs, drug discovery, and network security. This interface reference for Amazon Neptune contains documentation for a programming or command line interface you can use to manage Amazon Neptune. Note that Amazon Neptune is asynchronous, which means that some interfaces might require techniques such as polling or callback functions to determine when a command has been applied. In this reference, the parameter descriptions indicate whether a command is applied immediately, on the next instance reboot, or during the maintenance window. The reference structure is as follows, and we list following some related topics from the user guide."},{"ref":"AWS.Neptune.html#add_role_to_d_b_cluster/3","title":"AWS.Neptune.add_role_to_d_b_cluster/3","type":"function","doc":"Associates an Identity and Access Management (IAM) role from an Neptune DB cluster."},{"ref":"AWS.Neptune.html#add_source_identifier_to_subscription/3","title":"AWS.Neptune.add_source_identifier_to_subscription/3","type":"function","doc":"Adds a source identifier to an existing event notification subscription."},{"ref":"AWS.Neptune.html#add_tags_to_resource/3","title":"AWS.Neptune.add_tags_to_resource/3","type":"function","doc":"Adds metadata tags to an Amazon Neptune resource. These tags can also be used with cost allocation reporting to track cost associated with Amazon Neptune resources, or used in a Condition statement in an IAM policy for Amazon Neptune."},{"ref":"AWS.Neptune.html#apply_pending_maintenance_action/3","title":"AWS.Neptune.apply_pending_maintenance_action/3","type":"function","doc":"Applies a pending maintenance action to a resource (for example, to a DB instance)."},{"ref":"AWS.Neptune.html#copy_d_b_cluster_parameter_group/3","title":"AWS.Neptune.copy_d_b_cluster_parameter_group/3","type":"function","doc":"Copies the specified DB cluster parameter group."},{"ref":"AWS.Neptune.html#copy_d_b_cluster_snapshot/3","title":"AWS.Neptune.copy_d_b_cluster_snapshot/3","type":"function","doc":"Copies a snapshot of a DB cluster. To copy a DB cluster snapshot from a shared manual DB cluster snapshot, SourceDBClusterSnapshotIdentifier must be the Amazon Resource Name (ARN) of the shared DB cluster snapshot."},{"ref":"AWS.Neptune.html#copy_d_b_parameter_group/3","title":"AWS.Neptune.copy_d_b_parameter_group/3","type":"function","doc":"Copies the specified DB parameter group."},{"ref":"AWS.Neptune.html#create_d_b_cluster/3","title":"AWS.Neptune.create_d_b_cluster/3","type":"function","doc":"Creates a new Amazon Neptune DB cluster. You can use the ReplicationSourceIdentifier parameter to create the DB cluster as a Read Replica of another DB cluster or Amazon Neptune DB instance. Note that when you create a new cluster using CreateDBCluster directly, deletion protection is disabled by default (when you create a new production cluster in the console, deletion protection is enabled by default). You can only delete a DB cluster if its DeletionProtection field is set to false."},{"ref":"AWS.Neptune.html#create_d_b_cluster_parameter_group/3","title":"AWS.Neptune.create_d_b_cluster_parameter_group/3","type":"function","doc":"Creates a new DB cluster parameter group. Parameters in a DB cluster parameter group apply to all of the instances in a DB cluster. A DB cluster parameter group is initially created with the default parameters for the database engine used by instances in the DB cluster. To provide custom values for any of the parameters, you must modify the group after creating it using ModifyDBClusterParameterGroup. Once you&#39;ve created a DB cluster parameter group, you need to associate it with your DB cluster using ModifyDBCluster. When you associate a new DB cluster parameter group with a running DB cluster, you need to reboot the DB instances in the DB cluster without failover for the new DB cluster parameter group and associated settings to take effect. After you create a DB cluster parameter group, you should wait at least 5 minutes before creating your first DB cluster that uses that DB cluster parameter group as the default parameter group. This allows Amazon Neptune to fully complete the create action before the DB cluster parameter group is used as the default for a new DB cluster. This is especially important for parameters that are critical when creating the default database for a DB cluster, such as the character set for the default database defined by the character_set_database parameter. You can use the Parameter Groups option of the Amazon Neptune console or the DescribeDBClusterParameters command to verify that your DB cluster parameter group has been created or modified."},{"ref":"AWS.Neptune.html#create_d_b_cluster_snapshot/3","title":"AWS.Neptune.create_d_b_cluster_snapshot/3","type":"function","doc":"Creates a snapshot of a DB cluster."},{"ref":"AWS.Neptune.html#create_d_b_instance/3","title":"AWS.Neptune.create_d_b_instance/3","type":"function","doc":"Creates a new DB instance."},{"ref":"AWS.Neptune.html#create_d_b_parameter_group/3","title":"AWS.Neptune.create_d_b_parameter_group/3","type":"function","doc":"Creates a new DB parameter group. A DB parameter group is initially created with the default parameters for the database engine used by the DB instance. To provide custom values for any of the parameters, you must modify the group after creating it using ModifyDBParameterGroup. Once you&#39;ve created a DB parameter group, you need to associate it with your DB instance using ModifyDBInstance. When you associate a new DB parameter group with a running DB instance, you need to reboot the DB instance without failover for the new DB parameter group and associated settings to take effect. After you create a DB parameter group, you should wait at least 5 minutes before creating your first DB instance that uses that DB parameter group as the default parameter group. This allows Amazon Neptune to fully complete the create action before the parameter group is used as the default for a new DB instance. This is especially important for parameters that are critical when creating the default database for a DB instance, such as the character set for the default database defined by the character_set_database parameter. You can use the Parameter Groups option of the Amazon Neptune console or the DescribeDBParameters command to verify that your DB parameter group has been created or modified."},{"ref":"AWS.Neptune.html#create_d_b_subnet_group/3","title":"AWS.Neptune.create_d_b_subnet_group/3","type":"function","doc":"Creates a new DB subnet group. DB subnet groups must contain at least one subnet in at least two AZs in the AWS Region."},{"ref":"AWS.Neptune.html#create_event_subscription/3","title":"AWS.Neptune.create_event_subscription/3","type":"function","doc":"Creates an event notification subscription. This action requires a topic ARN (Amazon Resource Name) created by either the Neptune console, the SNS console, or the SNS API. To obtain an ARN with SNS, you must create a topic in Amazon SNS and subscribe to the topic. The ARN is displayed in the SNS console. You can specify the type of source (SourceType) you want to be notified of, provide a list of Neptune sources (SourceIds) that triggers the events, and provide a list of event categories (EventCategories) for events you want to be notified of. For example, you can specify SourceType = db-instance, SourceIds = mydbinstance1, mydbinstance2 and EventCategories = Availability, Backup. If you specify both the SourceType and SourceIds, such as SourceType = db-instance and SourceIdentifier = myDBInstance1, you are notified of all the db-instance events for the specified source. If you specify a SourceType but do not specify a SourceIdentifier, you receive notice of the events for that source type for all your Neptune sources. If you do not specify either the SourceType nor the SourceIdentifier, you are notified of events generated from all Neptune sources belonging to your customer account."},{"ref":"AWS.Neptune.html#delete_d_b_cluster/3","title":"AWS.Neptune.delete_d_b_cluster/3","type":"function","doc":"The DeleteDBCluster action deletes a previously provisioned DB cluster. When you delete a DB cluster, all automated backups for that DB cluster are deleted and can&#39;t be recovered. Manual DB cluster snapshots of the specified DB cluster are not deleted. Note that the DB Cluster cannot be deleted if deletion protection is enabled. To delete it, you must first set its DeletionProtection field to False."},{"ref":"AWS.Neptune.html#delete_d_b_cluster_parameter_group/3","title":"AWS.Neptune.delete_d_b_cluster_parameter_group/3","type":"function","doc":"Deletes a specified DB cluster parameter group. The DB cluster parameter group to be deleted can&#39;t be associated with any DB clusters."},{"ref":"AWS.Neptune.html#delete_d_b_cluster_snapshot/3","title":"AWS.Neptune.delete_d_b_cluster_snapshot/3","type":"function","doc":"Deletes a DB cluster snapshot. If the snapshot is being copied, the copy operation is terminated. The DB cluster snapshot must be in the available state to be deleted."},{"ref":"AWS.Neptune.html#delete_d_b_instance/3","title":"AWS.Neptune.delete_d_b_instance/3","type":"function","doc":"The DeleteDBInstance action deletes a previously provisioned DB instance. When you delete a DB instance, all automated backups for that instance are deleted and can&#39;t be recovered. Manual DB snapshots of the DB instance to be deleted by DeleteDBInstance are not deleted. If you request a final DB snapshot the status of the Amazon Neptune DB instance is deleting until the DB snapshot is created. The API action DescribeDBInstance is used to monitor the status of this operation. The action can&#39;t be canceled or reverted once submitted. Note that when a DB instance is in a failure state and has a status of failed, incompatible-restore, or incompatible-network, you can only delete it when the SkipFinalSnapshot parameter is set to true. You can&#39;t delete a DB instance if it is the only instance in the DB cluster, or if it has deletion protection enabled."},{"ref":"AWS.Neptune.html#delete_d_b_parameter_group/3","title":"AWS.Neptune.delete_d_b_parameter_group/3","type":"function","doc":"Deletes a specified DBParameterGroup. The DBParameterGroup to be deleted can&#39;t be associated with any DB instances."},{"ref":"AWS.Neptune.html#delete_d_b_subnet_group/3","title":"AWS.Neptune.delete_d_b_subnet_group/3","type":"function","doc":"Deletes a DB subnet group. The specified database subnet group must not be associated with any DB instances."},{"ref":"AWS.Neptune.html#delete_event_subscription/3","title":"AWS.Neptune.delete_event_subscription/3","type":"function","doc":"Deletes an event notification subscription."},{"ref":"AWS.Neptune.html#describe_d_b_cluster_parameter_groups/3","title":"AWS.Neptune.describe_d_b_cluster_parameter_groups/3","type":"function","doc":"Returns a list of DBClusterParameterGroup descriptions. If a DBClusterParameterGroupName parameter is specified, the list will contain only the description of the specified DB cluster parameter group."},{"ref":"AWS.Neptune.html#describe_d_b_cluster_parameters/3","title":"AWS.Neptune.describe_d_b_cluster_parameters/3","type":"function","doc":"Returns the detailed parameter list for a particular DB cluster parameter group."},{"ref":"AWS.Neptune.html#describe_d_b_cluster_snapshot_attributes/3","title":"AWS.Neptune.describe_d_b_cluster_snapshot_attributes/3","type":"function","doc":"Returns a list of DB cluster snapshot attribute names and values for a manual DB cluster snapshot. When sharing snapshots with other AWS accounts, DescribeDBClusterSnapshotAttributes returns the restore attribute and a list of IDs for the AWS accounts that are authorized to copy or restore the manual DB cluster snapshot. If all is included in the list of values for the restore attribute, then the manual DB cluster snapshot is public and can be copied or restored by all AWS accounts. To add or remove access for an AWS account to copy or restore a manual DB cluster snapshot, or to make the manual DB cluster snapshot public or private, use the ModifyDBClusterSnapshotAttribute API action."},{"ref":"AWS.Neptune.html#describe_d_b_cluster_snapshots/3","title":"AWS.Neptune.describe_d_b_cluster_snapshots/3","type":"function","doc":"Returns information about DB cluster snapshots. This API action supports pagination."},{"ref":"AWS.Neptune.html#describe_d_b_clusters/3","title":"AWS.Neptune.describe_d_b_clusters/3","type":"function","doc":"Returns information about provisioned DB clusters, and supports pagination. This operation can also return information for Amazon RDS clusters and Amazon DocDB clusters."},{"ref":"AWS.Neptune.html#describe_d_b_engine_versions/3","title":"AWS.Neptune.describe_d_b_engine_versions/3","type":"function","doc":"Returns a list of the available DB engines."},{"ref":"AWS.Neptune.html#describe_d_b_instances/3","title":"AWS.Neptune.describe_d_b_instances/3","type":"function","doc":"Returns information about provisioned instances, and supports pagination. This operation can also return information for Amazon RDS instances and Amazon DocDB instances."},{"ref":"AWS.Neptune.html#describe_d_b_parameter_groups/3","title":"AWS.Neptune.describe_d_b_parameter_groups/3","type":"function","doc":"Returns a list of DBParameterGroup descriptions. If a DBParameterGroupName is specified, the list will contain only the description of the specified DB parameter group."},{"ref":"AWS.Neptune.html#describe_d_b_parameters/3","title":"AWS.Neptune.describe_d_b_parameters/3","type":"function","doc":"Returns the detailed parameter list for a particular DB parameter group."},{"ref":"AWS.Neptune.html#describe_d_b_subnet_groups/3","title":"AWS.Neptune.describe_d_b_subnet_groups/3","type":"function","doc":"Returns a list of DBSubnetGroup descriptions. If a DBSubnetGroupName is specified, the list will contain only the descriptions of the specified DBSubnetGroup. For an overview of CIDR ranges, go to the Wikipedia Tutorial."},{"ref":"AWS.Neptune.html#describe_engine_default_cluster_parameters/3","title":"AWS.Neptune.describe_engine_default_cluster_parameters/3","type":"function","doc":"Returns the default engine and system parameter information for the cluster database engine."},{"ref":"AWS.Neptune.html#describe_engine_default_parameters/3","title":"AWS.Neptune.describe_engine_default_parameters/3","type":"function","doc":"Returns the default engine and system parameter information for the specified database engine."},{"ref":"AWS.Neptune.html#describe_event_categories/3","title":"AWS.Neptune.describe_event_categories/3","type":"function","doc":"Displays a list of categories for all event source types, or, if specified, for a specified source type."},{"ref":"AWS.Neptune.html#describe_event_subscriptions/3","title":"AWS.Neptune.describe_event_subscriptions/3","type":"function","doc":"Lists all the subscription descriptions for a customer account. The description for a subscription includes SubscriptionName, SNSTopicARN, CustomerID, SourceType, SourceID, CreationTime, and Status. If you specify a SubscriptionName, lists the description for that subscription."},{"ref":"AWS.Neptune.html#describe_events/3","title":"AWS.Neptune.describe_events/3","type":"function","doc":"Returns events related to DB instances, DB security groups, DB snapshots, and DB parameter groups for the past 14 days. Events specific to a particular DB instance, DB security group, database snapshot, or DB parameter group can be obtained by providing the name as a parameter. By default, the past hour of events are returned."},{"ref":"AWS.Neptune.html#describe_orderable_d_b_instance_options/3","title":"AWS.Neptune.describe_orderable_d_b_instance_options/3","type":"function","doc":"Returns a list of orderable DB instance options for the specified engine."},{"ref":"AWS.Neptune.html#describe_pending_maintenance_actions/3","title":"AWS.Neptune.describe_pending_maintenance_actions/3","type":"function","doc":"Returns a list of resources (for example, DB instances) that have at least one pending maintenance action."},{"ref":"AWS.Neptune.html#describe_valid_d_b_instance_modifications/3","title":"AWS.Neptune.describe_valid_d_b_instance_modifications/3","type":"function","doc":"You can call DescribeValidDBInstanceModifications to learn what modifications you can make to your DB instance. You can use this information when you call ModifyDBInstance."},{"ref":"AWS.Neptune.html#failover_d_b_cluster/3","title":"AWS.Neptune.failover_d_b_cluster/3","type":"function","doc":"Forces a failover for a DB cluster. A failover for a DB cluster promotes one of the Read Replicas (read-only instances) in the DB cluster to be the primary instance (the cluster writer). Amazon Neptune will automatically fail over to a Read Replica, if one exists, when the primary instance fails. You can force a failover when you want to simulate a failure of a primary instance for testing. Because each instance in a DB cluster has its own endpoint address, you will need to clean up and re-establish any existing connections that use those endpoint addresses when the failover is complete."},{"ref":"AWS.Neptune.html#list_tags_for_resource/3","title":"AWS.Neptune.list_tags_for_resource/3","type":"function","doc":"Lists all tags on an Amazon Neptune resource."},{"ref":"AWS.Neptune.html#modify_d_b_cluster/3","title":"AWS.Neptune.modify_d_b_cluster/3","type":"function","doc":"Modify a setting for a DB cluster. You can change one or more database configuration parameters by specifying these parameters and the new values in the request."},{"ref":"AWS.Neptune.html#modify_d_b_cluster_parameter_group/3","title":"AWS.Neptune.modify_d_b_cluster_parameter_group/3","type":"function","doc":"Modifies the parameters of a DB cluster parameter group. To modify more than one parameter, submit a list of the following: ParameterName, ParameterValue, and ApplyMethod. A maximum of 20 parameters can be modified in a single request. Changes to dynamic parameters are applied immediately. Changes to static parameters require a reboot without failover to the DB cluster associated with the parameter group before the change can take effect. After you create a DB cluster parameter group, you should wait at least 5 minutes before creating your first DB cluster that uses that DB cluster parameter group as the default parameter group. This allows Amazon Neptune to fully complete the create action before the parameter group is used as the default for a new DB cluster. This is especially important for parameters that are critical when creating the default database for a DB cluster, such as the character set for the default database defined by the character_set_database parameter. You can use the Parameter Groups option of the Amazon Neptune console or the DescribeDBClusterParameters command to verify that your DB cluster parameter group has been created or modified."},{"ref":"AWS.Neptune.html#modify_d_b_cluster_snapshot_attribute/3","title":"AWS.Neptune.modify_d_b_cluster_snapshot_attribute/3","type":"function","doc":"Adds an attribute and values to, or removes an attribute and values from, a manual DB cluster snapshot. To share a manual DB cluster snapshot with other AWS accounts, specify restore as the AttributeName and use the ValuesToAdd parameter to add a list of IDs of the AWS accounts that are authorized to restore the manual DB cluster snapshot. Use the value all to make the manual DB cluster snapshot public, which means that it can be copied or restored by all AWS accounts. Do not add the all value for any manual DB cluster snapshots that contain private information that you don&#39;t want available to all AWS accounts. If a manual DB cluster snapshot is encrypted, it can be shared, but only by specifying a list of authorized AWS account IDs for the ValuesToAdd parameter. You can&#39;t use all as a value for that parameter in this case. To view which AWS accounts have access to copy or restore a manual DB cluster snapshot, or whether a manual DB cluster snapshot public or private, use the DescribeDBClusterSnapshotAttributes API action."},{"ref":"AWS.Neptune.html#modify_d_b_instance/3","title":"AWS.Neptune.modify_d_b_instance/3","type":"function","doc":"Modifies settings for a DB instance. You can change one or more database configuration parameters by specifying these parameters and the new values in the request. To learn what modifications you can make to your DB instance, call DescribeValidDBInstanceModifications before you call ModifyDBInstance."},{"ref":"AWS.Neptune.html#modify_d_b_parameter_group/3","title":"AWS.Neptune.modify_d_b_parameter_group/3","type":"function","doc":"Modifies the parameters of a DB parameter group. To modify more than one parameter, submit a list of the following: ParameterName, ParameterValue, and ApplyMethod. A maximum of 20 parameters can be modified in a single request. Changes to dynamic parameters are applied immediately. Changes to static parameters require a reboot without failover to the DB instance associated with the parameter group before the change can take effect. After you modify a DB parameter group, you should wait at least 5 minutes before creating your first DB instance that uses that DB parameter group as the default parameter group. This allows Amazon Neptune to fully complete the modify action before the parameter group is used as the default for a new DB instance. This is especially important for parameters that are critical when creating the default database for a DB instance, such as the character set for the default database defined by the character_set_database parameter. You can use the Parameter Groups option of the Amazon Neptune console or the DescribeDBParameters command to verify that your DB parameter group has been created or modified."},{"ref":"AWS.Neptune.html#modify_d_b_subnet_group/3","title":"AWS.Neptune.modify_d_b_subnet_group/3","type":"function","doc":"Modifies an existing DB subnet group. DB subnet groups must contain at least one subnet in at least two AZs in the AWS Region."},{"ref":"AWS.Neptune.html#modify_event_subscription/3","title":"AWS.Neptune.modify_event_subscription/3","type":"function","doc":"Modifies an existing event notification subscription. Note that you can&#39;t modify the source identifiers using this call; to change source identifiers for a subscription, use the AddSourceIdentifierToSubscription and RemoveSourceIdentifierFromSubscription calls. You can see a list of the event categories for a given SourceType by using the DescribeEventCategories action."},{"ref":"AWS.Neptune.html#promote_read_replica_d_b_cluster/3","title":"AWS.Neptune.promote_read_replica_d_b_cluster/3","type":"function","doc":"Not supported."},{"ref":"AWS.Neptune.html#reboot_d_b_instance/3","title":"AWS.Neptune.reboot_d_b_instance/3","type":"function","doc":"You might need to reboot your DB instance, usually for maintenance reasons. For example, if you make certain modifications, or if you change the DB parameter group associated with the DB instance, you must reboot the instance for the changes to take effect. Rebooting a DB instance restarts the database engine service. Rebooting a DB instance results in a momentary outage, during which the DB instance status is set to rebooting."},{"ref":"AWS.Neptune.html#remove_role_from_d_b_cluster/3","title":"AWS.Neptune.remove_role_from_d_b_cluster/3","type":"function","doc":"Disassociates an Identity and Access Management (IAM) role from a DB cluster."},{"ref":"AWS.Neptune.html#remove_source_identifier_from_subscription/3","title":"AWS.Neptune.remove_source_identifier_from_subscription/3","type":"function","doc":"Removes a source identifier from an existing event notification subscription."},{"ref":"AWS.Neptune.html#remove_tags_from_resource/3","title":"AWS.Neptune.remove_tags_from_resource/3","type":"function","doc":"Removes metadata tags from an Amazon Neptune resource."},{"ref":"AWS.Neptune.html#reset_d_b_cluster_parameter_group/3","title":"AWS.Neptune.reset_d_b_cluster_parameter_group/3","type":"function","doc":"Modifies the parameters of a DB cluster parameter group to the default value. To reset specific parameters submit a list of the following: ParameterName and ApplyMethod. To reset the entire DB cluster parameter group, specify the DBClusterParameterGroupName and ResetAllParameters parameters. When resetting the entire group, dynamic parameters are updated immediately and static parameters are set to pending-reboot to take effect on the next DB instance restart or RebootDBInstance request. You must call RebootDBInstance for every DB instance in your DB cluster that you want the updated static parameter to apply to."},{"ref":"AWS.Neptune.html#reset_d_b_parameter_group/3","title":"AWS.Neptune.reset_d_b_parameter_group/3","type":"function","doc":"Modifies the parameters of a DB parameter group to the engine/system default value. To reset specific parameters, provide a list of the following: ParameterName and ApplyMethod. To reset the entire DB parameter group, specify the DBParameterGroup name and ResetAllParameters parameters. When resetting the entire group, dynamic parameters are updated immediately and static parameters are set to pending-reboot to take effect on the next DB instance restart or RebootDBInstance request."},{"ref":"AWS.Neptune.html#restore_d_b_cluster_from_snapshot/3","title":"AWS.Neptune.restore_d_b_cluster_from_snapshot/3","type":"function","doc":"Creates a new DB cluster from a DB snapshot or DB cluster snapshot. If a DB snapshot is specified, the target DB cluster is created from the source DB snapshot with a default configuration and default security group. If a DB cluster snapshot is specified, the target DB cluster is created from the source DB cluster restore point with the same configuration as the original source DB cluster, except that the new DB cluster is created with the default security group."},{"ref":"AWS.Neptune.html#restore_d_b_cluster_to_point_in_time/3","title":"AWS.Neptune.restore_d_b_cluster_to_point_in_time/3","type":"function","doc":"Restores a DB cluster to an arbitrary point in time. Users can restore to any point in time before LatestRestorableTime for up to BackupRetentionPeriod days. The target DB cluster is created from the source DB cluster with the same configuration as the original DB cluster, except that the new DB cluster is created with the default DB security group. This action only restores the DB cluster, not the DB instances for that DB cluster. You must invoke the CreateDBInstance action to create DB instances for the restored DB cluster, specifying the identifier of the restored DB cluster in DBClusterIdentifier. You can create DB instances only after the RestoreDBClusterToPointInTime action has completed and the DB cluster is available."},{"ref":"AWS.Neptune.html#start_d_b_cluster/3","title":"AWS.Neptune.start_d_b_cluster/3","type":"function","doc":"Starts an Amazon Neptune DB cluster that was stopped using the AWS console, the AWS CLI stop-db-cluster command, or the StopDBCluster API."},{"ref":"AWS.Neptune.html#stop_d_b_cluster/3","title":"AWS.Neptune.stop_d_b_cluster/3","type":"function","doc":"Stops an Amazon Neptune DB cluster. When you stop a DB cluster, Neptune retains the DB cluster&#39;s metadata, including its endpoints and DB parameter groups. Neptune also retains the transaction logs so you can do a point-in-time restore if necessary."},{"ref":"AWS.NetworkManager.html","title":"AWS.NetworkManager","type":"module","doc":"Transit Gateway Network Manager (Network Manager) enables you to create a global network, in which you can monitor your AWS and on-premises networks that are built around transit gateways."},{"ref":"AWS.NetworkManager.html#associate_customer_gateway/4","title":"AWS.NetworkManager.associate_customer_gateway/4","type":"function","doc":"Associates a customer gateway with a device and optionally, with a link. If you specify a link, it must be associated with the specified device. You can only associate customer gateways that are connected to a VPN attachment on a transit gateway. The transit gateway must be registered in your global network. When you register a transit gateway, customer gateways that are connected to the transit gateway are automatically included in the global network. To list customer gateways that are connected to a transit gateway, use the DescribeVpnConnections EC2 API and filter by transit-gateway-id. You cannot associate a customer gateway with more than one device and link."},{"ref":"AWS.NetworkManager.html#associate_link/4","title":"AWS.NetworkManager.associate_link/4","type":"function","doc":"Associates a link to a device. A device can be associated to multiple links and a link can be associated to multiple devices. The device and link must be in the same global network and the same site."},{"ref":"AWS.NetworkManager.html#create_device/4","title":"AWS.NetworkManager.create_device/4","type":"function","doc":"Creates a new device in a global network. If you specify both a site ID and a location, the location of the site is used for visualization in the Network Manager console."},{"ref":"AWS.NetworkManager.html#create_global_network/3","title":"AWS.NetworkManager.create_global_network/3","type":"function","doc":"Creates a new, empty global network."},{"ref":"AWS.NetworkManager.html#create_link/4","title":"AWS.NetworkManager.create_link/4","type":"function","doc":"Creates a new link for a specified site."},{"ref":"AWS.NetworkManager.html#create_site/4","title":"AWS.NetworkManager.create_site/4","type":"function","doc":"Creates a new site in a global network."},{"ref":"AWS.NetworkManager.html#delete_device/5","title":"AWS.NetworkManager.delete_device/5","type":"function","doc":"Deletes an existing device. You must first disassociate the device from any links and customer gateways."},{"ref":"AWS.NetworkManager.html#delete_global_network/4","title":"AWS.NetworkManager.delete_global_network/4","type":"function","doc":"Deletes an existing global network. You must first delete all global network objects (devices, links, and sites) and deregister all transit gateways."},{"ref":"AWS.NetworkManager.html#delete_link/5","title":"AWS.NetworkManager.delete_link/5","type":"function","doc":"Deletes an existing link. You must first disassociate the link from any devices and customer gateways."},{"ref":"AWS.NetworkManager.html#delete_site/5","title":"AWS.NetworkManager.delete_site/5","type":"function","doc":"Deletes an existing site. The site cannot be associated with any device or link."},{"ref":"AWS.NetworkManager.html#deregister_transit_gateway/5","title":"AWS.NetworkManager.deregister_transit_gateway/5","type":"function","doc":"Deregisters a transit gateway from your global network. This action does not delete your transit gateway, or modify any of its attachments. This action removes any customer gateway associations."},{"ref":"AWS.NetworkManager.html#describe_global_networks/5","title":"AWS.NetworkManager.describe_global_networks/5","type":"function","doc":"Describes one or more global networks. By default, all global networks are described. To describe the objects in your global network, you must use the appropriate Get* action. For example, to list the transit gateways in your global network, use GetTransitGatewayRegistrations."},{"ref":"AWS.NetworkManager.html#disassociate_customer_gateway/5","title":"AWS.NetworkManager.disassociate_customer_gateway/5","type":"function","doc":"Disassociates a customer gateway from a device and a link."},{"ref":"AWS.NetworkManager.html#disassociate_link/4","title":"AWS.NetworkManager.disassociate_link/4","type":"function","doc":"Disassociates an existing device from a link. You must first disassociate any customer gateways that are associated with the link."},{"ref":"AWS.NetworkManager.html#get_customer_gateway_associations/6","title":"AWS.NetworkManager.get_customer_gateway_associations/6","type":"function","doc":"Gets the association information for customer gateways that are associated with devices and links in your global network."},{"ref":"AWS.NetworkManager.html#get_devices/7","title":"AWS.NetworkManager.get_devices/7","type":"function","doc":"Gets information about one or more of your devices in a global network."},{"ref":"AWS.NetworkManager.html#get_link_associations/7","title":"AWS.NetworkManager.get_link_associations/7","type":"function","doc":"Gets the link associations for a device or a link. Either the device ID or the link ID must be specified."},{"ref":"AWS.NetworkManager.html#get_links/9","title":"AWS.NetworkManager.get_links/9","type":"function","doc":"Gets information about one or more links in a specified global network. If you specify the site ID, you cannot specify the type or provider in the same request. You can specify the type and provider in the same request."},{"ref":"AWS.NetworkManager.html#get_sites/6","title":"AWS.NetworkManager.get_sites/6","type":"function","doc":"Gets information about one or more of your sites in a global network."},{"ref":"AWS.NetworkManager.html#get_transit_gateway_registrations/6","title":"AWS.NetworkManager.get_transit_gateway_registrations/6","type":"function","doc":"Gets information about the transit gateway registrations in a specified global network."},{"ref":"AWS.NetworkManager.html#list_tags_for_resource/3","title":"AWS.NetworkManager.list_tags_for_resource/3","type":"function","doc":"Lists the tags for a specified resource."},{"ref":"AWS.NetworkManager.html#register_transit_gateway/4","title":"AWS.NetworkManager.register_transit_gateway/4","type":"function","doc":"Registers a transit gateway in your global network. The transit gateway can be in any AWS Region, but it must be owned by the same AWS account that owns the global network. You cannot register a transit gateway in more than one global network."},{"ref":"AWS.NetworkManager.html#tag_resource/4","title":"AWS.NetworkManager.tag_resource/4","type":"function","doc":"Tags a specified resource."},{"ref":"AWS.NetworkManager.html#untag_resource/4","title":"AWS.NetworkManager.untag_resource/4","type":"function","doc":"Removes tags from a specified resource."},{"ref":"AWS.NetworkManager.html#update_device/5","title":"AWS.NetworkManager.update_device/5","type":"function","doc":"Updates the details for an existing device. To remove information for any of the parameters, specify an empty string."},{"ref":"AWS.NetworkManager.html#update_global_network/4","title":"AWS.NetworkManager.update_global_network/4","type":"function","doc":"Updates an existing global network. To remove information for any of the parameters, specify an empty string."},{"ref":"AWS.NetworkManager.html#update_link/5","title":"AWS.NetworkManager.update_link/5","type":"function","doc":"Updates the details for an existing link. To remove information for any of the parameters, specify an empty string."},{"ref":"AWS.NetworkManager.html#update_site/5","title":"AWS.NetworkManager.update_site/5","type":"function","doc":"Updates the information for an existing site. To remove information for any of the parameters, specify an empty string."},{"ref":"AWS.OpsWorks.html","title":"AWS.OpsWorks","type":"module","doc":"AWS OpsWorks Welcome to the AWS OpsWorks Stacks API Reference. This guide provides descriptions, syntax, and usage examples for AWS OpsWorks Stacks actions and data types, including common parameters and error codes. AWS OpsWorks Stacks is an application management service that provides an integrated experience for overseeing the complete application lifecycle. For information about this product, go to the AWS OpsWorks details page. SDKs and CLI The most common way to use the AWS OpsWorks Stacks API is by using the AWS Command Line Interface (CLI) or by using one of the AWS SDKs to implement applications in your preferred language. For more information, see: AWS CLI AWS SDK for Java AWS SDK for .NET AWS SDK for PHP 2 AWS SDK for Ruby * AWS SDK for Node.js AWS SDK for Python(Boto) Endpoints AWS OpsWorks Stacks supports the following endpoints, all HTTPS. You must connect to one of the following endpoints. Stacks can only be accessed or managed within the endpoint in which they are created. opsworks.us-east-1.amazonaws.com opsworks.us-east-2.amazonaws.com opsworks.us-west-1.amazonaws.com opsworks.us-west-2.amazonaws.com opsworks.ca-central-1.amazonaws.com (API only; not available in the AWS console) opsworks.eu-west-1.amazonaws.com opsworks.eu-west-2.amazonaws.com opsworks.eu-west-3.amazonaws.com opsworks.eu-central-1.amazonaws.com opsworks.ap-northeast-1.amazonaws.com opsworks.ap-northeast-2.amazonaws.com opsworks.ap-south-1.amazonaws.com opsworks.ap-southeast-1.amazonaws.com opsworks.ap-southeast-2.amazonaws.com opsworks.sa-east-1.amazonaws.com Chef Versions When you call CreateStack, CloneStack, or UpdateStack we recommend you use the ConfigurationManager parameter to specify the Chef version. The recommended and default value for Linux stacks is currently 12. Windows stacks use Chef 12.2. For more information, see Chef Versions. You can specify Chef 12, 11.10, or 11.4 for your Linux stack. We recommend migrating your existing Linux stacks to Chef 12 as soon as possible."},{"ref":"AWS.OpsWorks.html#assign_instance/3","title":"AWS.OpsWorks.assign_instance/3","type":"function","doc":"Assign a registered instance to a layer. You can assign registered on-premises instances to any layer type. You can assign registered Amazon EC2 instances only to custom layers. You cannot use this action with instances that were created with AWS OpsWorks Stacks. Required Permissions: To use this action, an AWS Identity and Access Management (IAM) user must have a Manage permissions level for the stack or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#assign_volume/3","title":"AWS.OpsWorks.assign_volume/3","type":"function","doc":"Assigns one of the stack&#39;s registered Amazon EBS volumes to a specified instance. The volume must first be registered with the stack by calling RegisterVolume. After you register the volume, you must call UpdateVolume to specify a mount point before calling AssignVolume. For more information, see Resource Management. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#associate_elastic_ip/3","title":"AWS.OpsWorks.associate_elastic_ip/3","type":"function","doc":"Associates one of the stack&#39;s registered Elastic IP addresses with a specified instance. The address must first be registered with the stack by calling RegisterElasticIp. For more information, see Resource Management. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#attach_elastic_load_balancer/3","title":"AWS.OpsWorks.attach_elastic_load_balancer/3","type":"function","doc":"Attaches an Elastic Load Balancing load balancer to a specified layer. AWS OpsWorks Stacks does not support Application Load Balancer. You can only use Classic Load Balancer with AWS OpsWorks Stacks. For more information, see Elastic Load Balancing. You must create the Elastic Load Balancing instance separately, by using the Elastic Load Balancing console, API, or CLI. For more information, see Elastic Load Balancing Developer Guide. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#clone_stack/3","title":"AWS.OpsWorks.clone_stack/3","type":"function","doc":"Creates a clone of a specified stack. For more information, see Clone a Stack. By default, all parameters are set to the values used by the parent stack. Required Permissions: To use this action, an IAM user must have an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#create_app/3","title":"AWS.OpsWorks.create_app/3","type":"function","doc":"Creates an app for a specified stack. For more information, see Creating Apps. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#create_deployment/3","title":"AWS.OpsWorks.create_deployment/3","type":"function","doc":"Runs deployment or stack commands. For more information, see Deploying Apps and Run Stack Commands. Required Permissions: To use this action, an IAM user must have a Deploy or Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#create_instance/3","title":"AWS.OpsWorks.create_instance/3","type":"function","doc":"Creates an instance in a specified stack. For more information, see Adding an Instance to a Layer. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#create_layer/3","title":"AWS.OpsWorks.create_layer/3","type":"function","doc":"Creates a layer. For more information, see How to Create a Layer. You should use CreateLayer for noncustom layer types such as PHP App Server only if the stack does not have an existing layer of that type. A stack can have at most one instance of each noncustom layer; if you attempt to create a second instance, CreateLayer fails. A stack can have an arbitrary number of custom layers, so you can call CreateLayer as many times as you like for that layer type. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#create_stack/3","title":"AWS.OpsWorks.create_stack/3","type":"function","doc":"Creates a new stack. For more information, see Create a New Stack. Required Permissions: To use this action, an IAM user must have an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#create_user_profile/3","title":"AWS.OpsWorks.create_user_profile/3","type":"function","doc":"Creates a new user profile. Required Permissions: To use this action, an IAM user must have an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#delete_app/3","title":"AWS.OpsWorks.delete_app/3","type":"function","doc":"Deletes a specified app. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#delete_instance/3","title":"AWS.OpsWorks.delete_instance/3","type":"function","doc":"Deletes a specified instance, which terminates the associated Amazon EC2 instance. You must stop an instance before you can delete it. For more information, see Deleting Instances. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#delete_layer/3","title":"AWS.OpsWorks.delete_layer/3","type":"function","doc":"Deletes a specified layer. You must first stop and then delete all associated instances or unassign registered instances. For more information, see How to Delete a Layer. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#delete_stack/3","title":"AWS.OpsWorks.delete_stack/3","type":"function","doc":"Deletes a specified stack. You must first delete all instances, layers, and apps or deregister registered instances. For more information, see Shut Down a Stack. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#delete_user_profile/3","title":"AWS.OpsWorks.delete_user_profile/3","type":"function","doc":"Deletes a user profile. Required Permissions: To use this action, an IAM user must have an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#deregister_ecs_cluster/3","title":"AWS.OpsWorks.deregister_ecs_cluster/3","type":"function","doc":"Deregisters a specified Amazon ECS cluster from a stack. For more information, see Resource Management. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack or an attached policy that explicitly grants permissions. For more information on user permissions, see https://docs.aws.amazon.com/opsworks/latest/userguide/opsworks-security-users.html."},{"ref":"AWS.OpsWorks.html#deregister_elastic_ip/3","title":"AWS.OpsWorks.deregister_elastic_ip/3","type":"function","doc":"Deregisters a specified Elastic IP address. The address can then be registered by another stack. For more information, see Resource Management. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#deregister_instance/3","title":"AWS.OpsWorks.deregister_instance/3","type":"function","doc":"Deregister a registered Amazon EC2 or on-premises instance. This action removes the instance from the stack and returns it to your control. This action cannot be used with instances that were created with AWS OpsWorks Stacks. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#deregister_rds_db_instance/3","title":"AWS.OpsWorks.deregister_rds_db_instance/3","type":"function","doc":"Deregisters an Amazon RDS instance. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#deregister_volume/3","title":"AWS.OpsWorks.deregister_volume/3","type":"function","doc":"Deregisters an Amazon EBS volume. The volume can then be registered by another stack. For more information, see Resource Management. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#describe_agent_versions/3","title":"AWS.OpsWorks.describe_agent_versions/3","type":"function","doc":"Describes the available AWS OpsWorks Stacks agent versions. You must specify a stack ID or a configuration manager. DescribeAgentVersions returns a list of available agent versions for the specified stack or configuration manager."},{"ref":"AWS.OpsWorks.html#describe_apps/3","title":"AWS.OpsWorks.describe_apps/3","type":"function","doc":"Requests a description of a specified set of apps. This call accepts only one resource-identifying parameter. Required Permissions: To use this action, an IAM user must have a Show, Deploy, or Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#describe_commands/3","title":"AWS.OpsWorks.describe_commands/3","type":"function","doc":"Describes the results of specified commands. This call accepts only one resource-identifying parameter. Required Permissions: To use this action, an IAM user must have a Show, Deploy, or Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#describe_deployments/3","title":"AWS.OpsWorks.describe_deployments/3","type":"function","doc":"Requests a description of a specified set of deployments. This call accepts only one resource-identifying parameter. Required Permissions: To use this action, an IAM user must have a Show, Deploy, or Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#describe_ecs_clusters/3","title":"AWS.OpsWorks.describe_ecs_clusters/3","type":"function","doc":"Describes Amazon ECS clusters that are registered with a stack. If you specify only a stack ID, you can use the MaxResults and NextToken parameters to paginate the response. However, AWS OpsWorks Stacks currently supports only one cluster per layer, so the result set has a maximum of one element. Required Permissions: To use this action, an IAM user must have a Show, Deploy, or Manage permissions level for the stack or an attached policy that explicitly grants permission. For more information about user permissions, see Managing User Permissions. This call accepts only one resource-identifying parameter."},{"ref":"AWS.OpsWorks.html#describe_elastic_ips/3","title":"AWS.OpsWorks.describe_elastic_ips/3","type":"function","doc":"Describes Elastic IP addresses. This call accepts only one resource-identifying parameter. Required Permissions: To use this action, an IAM user must have a Show, Deploy, or Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#describe_elastic_load_balancers/3","title":"AWS.OpsWorks.describe_elastic_load_balancers/3","type":"function","doc":"Describes a stack&#39;s Elastic Load Balancing instances. This call accepts only one resource-identifying parameter. Required Permissions: To use this action, an IAM user must have a Show, Deploy, or Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#describe_instances/3","title":"AWS.OpsWorks.describe_instances/3","type":"function","doc":"Requests a description of a set of instances. This call accepts only one resource-identifying parameter. Required Permissions: To use this action, an IAM user must have a Show, Deploy, or Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#describe_layers/3","title":"AWS.OpsWorks.describe_layers/3","type":"function","doc":"Requests a description of one or more layers in a specified stack. This call accepts only one resource-identifying parameter. Required Permissions: To use this action, an IAM user must have a Show, Deploy, or Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#describe_load_based_auto_scaling/3","title":"AWS.OpsWorks.describe_load_based_auto_scaling/3","type":"function","doc":"Describes load-based auto scaling configurations for specified layers. You must specify at least one of the parameters. Required Permissions: To use this action, an IAM user must have a Show, Deploy, or Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#describe_my_user_profile/3","title":"AWS.OpsWorks.describe_my_user_profile/3","type":"function","doc":"Describes a user&#39;s SSH information. Required Permissions: To use this action, an IAM user must have self-management enabled or an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#describe_operating_systems/3","title":"AWS.OpsWorks.describe_operating_systems/3","type":"function","doc":"Describes the operating systems that are supported by AWS OpsWorks Stacks."},{"ref":"AWS.OpsWorks.html#describe_permissions/3","title":"AWS.OpsWorks.describe_permissions/3","type":"function","doc":"Describes the permissions for a specified stack. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#describe_raid_arrays/3","title":"AWS.OpsWorks.describe_raid_arrays/3","type":"function","doc":"Describe an instance&#39;s RAID arrays. This call accepts only one resource-identifying parameter. Required Permissions: To use this action, an IAM user must have a Show, Deploy, or Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#describe_rds_db_instances/3","title":"AWS.OpsWorks.describe_rds_db_instances/3","type":"function","doc":"Describes Amazon RDS instances. Required Permissions: To use this action, an IAM user must have a Show, Deploy, or Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions. This call accepts only one resource-identifying parameter."},{"ref":"AWS.OpsWorks.html#describe_service_errors/3","title":"AWS.OpsWorks.describe_service_errors/3","type":"function","doc":"Describes AWS OpsWorks Stacks service errors. Required Permissions: To use this action, an IAM user must have a Show, Deploy, or Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions. This call accepts only one resource-identifying parameter."},{"ref":"AWS.OpsWorks.html#describe_stack_provisioning_parameters/3","title":"AWS.OpsWorks.describe_stack_provisioning_parameters/3","type":"function","doc":"Requests a description of a stack&#39;s provisioning parameters. Required Permissions: To use this action, an IAM user must have a Show, Deploy, or Manage permissions level for the stack or an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#describe_stack_summary/3","title":"AWS.OpsWorks.describe_stack_summary/3","type":"function","doc":"Describes the number of layers and apps in a specified stack, and the number of instances in each state, such as running_setup or online. Required Permissions: To use this action, an IAM user must have a Show, Deploy, or Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#describe_stacks/3","title":"AWS.OpsWorks.describe_stacks/3","type":"function","doc":"Requests a description of one or more stacks. Required Permissions: To use this action, an IAM user must have a Show, Deploy, or Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#describe_time_based_auto_scaling/3","title":"AWS.OpsWorks.describe_time_based_auto_scaling/3","type":"function","doc":"Describes time-based auto scaling configurations for specified instances. You must specify at least one of the parameters. Required Permissions: To use this action, an IAM user must have a Show, Deploy, or Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#describe_user_profiles/3","title":"AWS.OpsWorks.describe_user_profiles/3","type":"function","doc":"Describe specified users. Required Permissions: To use this action, an IAM user must have an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#describe_volumes/3","title":"AWS.OpsWorks.describe_volumes/3","type":"function","doc":"Describes an instance&#39;s Amazon EBS volumes. This call accepts only one resource-identifying parameter. Required Permissions: To use this action, an IAM user must have a Show, Deploy, or Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#detach_elastic_load_balancer/3","title":"AWS.OpsWorks.detach_elastic_load_balancer/3","type":"function","doc":"Detaches a specified Elastic Load Balancing instance from its layer. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#disassociate_elastic_ip/3","title":"AWS.OpsWorks.disassociate_elastic_ip/3","type":"function","doc":"Disassociates an Elastic IP address from its instance. The address remains registered with the stack. For more information, see Resource Management. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#get_hostname_suggestion/3","title":"AWS.OpsWorks.get_hostname_suggestion/3","type":"function","doc":"Gets a generated host name for the specified layer, based on the current host name theme. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#grant_access/3","title":"AWS.OpsWorks.grant_access/3","type":"function","doc":"This action can be used only with Windows stacks. Grants RDP access to a Windows instance for a specified time period."},{"ref":"AWS.OpsWorks.html#list_tags/3","title":"AWS.OpsWorks.list_tags/3","type":"function","doc":"Returns a list of tags that are applied to the specified stack or layer."},{"ref":"AWS.OpsWorks.html#reboot_instance/3","title":"AWS.OpsWorks.reboot_instance/3","type":"function","doc":"Reboots a specified instance. For more information, see Starting, Stopping, and Rebooting Instances. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#register_ecs_cluster/3","title":"AWS.OpsWorks.register_ecs_cluster/3","type":"function","doc":"Registers a specified Amazon ECS cluster with a stack. You can register only one cluster with a stack. A cluster can be registered with only one stack. For more information, see Resource Management. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#register_elastic_ip/3","title":"AWS.OpsWorks.register_elastic_ip/3","type":"function","doc":"Registers an Elastic IP address with a specified stack. An address can be registered with only one stack at a time. If the address is already registered, you must first deregister it by calling DeregisterElasticIp. For more information, see Resource Management. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#register_instance/3","title":"AWS.OpsWorks.register_instance/3","type":"function","doc":"Registers instances that were created outside of AWS OpsWorks Stacks with a specified stack. We do not recommend using this action to register instances. The complete registration operation includes two tasks: installing the AWS OpsWorks Stacks agent on the instance, and registering the instance with the stack. RegisterInstance handles only the second step. You should instead use the AWS CLI register command, which performs the entire registration operation. For more information, see Registering an Instance with an AWS OpsWorks Stacks Stack. Registered instances have the same requirements as instances that are created by using the CreateInstance API. For example, registered instances must be running a supported Linux-based operating system, and they must have a supported instance type. For more information about requirements for instances that you want to register, see Preparing the Instance. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#register_rds_db_instance/3","title":"AWS.OpsWorks.register_rds_db_instance/3","type":"function","doc":"Registers an Amazon RDS instance with a stack. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#register_volume/3","title":"AWS.OpsWorks.register_volume/3","type":"function","doc":"Registers an Amazon EBS volume with a specified stack. A volume can be registered with only one stack at a time. If the volume is already registered, you must first deregister it by calling DeregisterVolume. For more information, see Resource Management. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#set_load_based_auto_scaling/3","title":"AWS.OpsWorks.set_load_based_auto_scaling/3","type":"function","doc":"Specify the load-based auto scaling configuration for a specified layer. For more information, see Managing Load with Time-based and Load-based Instances. To use load-based auto scaling, you must create a set of load-based auto scaling instances. Load-based auto scaling operates only on the instances from that set, so you must ensure that you have created enough instances to handle the maximum anticipated load. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#set_permission/3","title":"AWS.OpsWorks.set_permission/3","type":"function","doc":"Specifies a user&#39;s permissions. For more information, see Security and Permissions. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#set_time_based_auto_scaling/3","title":"AWS.OpsWorks.set_time_based_auto_scaling/3","type":"function","doc":"Specify the time-based auto scaling configuration for a specified instance. For more information, see Managing Load with Time-based and Load-based Instances. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#start_instance/3","title":"AWS.OpsWorks.start_instance/3","type":"function","doc":"Starts a specified instance. For more information, see Starting, Stopping, and Rebooting Instances. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#start_stack/3","title":"AWS.OpsWorks.start_stack/3","type":"function","doc":"Starts a stack&#39;s instances. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#stop_instance/3","title":"AWS.OpsWorks.stop_instance/3","type":"function","doc":"Stops a specified instance. When you stop a standard instance, the data disappears and must be reinstalled when you restart the instance. You can stop an Amazon EBS-backed instance without losing data. For more information, see Starting, Stopping, and Rebooting Instances. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#stop_stack/3","title":"AWS.OpsWorks.stop_stack/3","type":"function","doc":"Stops a specified stack. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#tag_resource/3","title":"AWS.OpsWorks.tag_resource/3","type":"function","doc":"Apply cost-allocation tags to a specified stack or layer in AWS OpsWorks Stacks. For more information about how tagging works, see Tags in the AWS OpsWorks User Guide."},{"ref":"AWS.OpsWorks.html#unassign_instance/3","title":"AWS.OpsWorks.unassign_instance/3","type":"function","doc":"Unassigns a registered instance from all layers that are using the instance. The instance remains in the stack as an unassigned instance, and can be assigned to another layer as needed. You cannot use this action with instances that were created with AWS OpsWorks Stacks. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack or an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#unassign_volume/3","title":"AWS.OpsWorks.unassign_volume/3","type":"function","doc":"Unassigns an assigned Amazon EBS volume. The volume remains registered with the stack. For more information, see Resource Management. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#untag_resource/3","title":"AWS.OpsWorks.untag_resource/3","type":"function","doc":"Removes tags from a specified stack or layer."},{"ref":"AWS.OpsWorks.html#update_app/3","title":"AWS.OpsWorks.update_app/3","type":"function","doc":"Updates a specified app. Required Permissions: To use this action, an IAM user must have a Deploy or Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#update_elastic_ip/3","title":"AWS.OpsWorks.update_elastic_ip/3","type":"function","doc":"Updates a registered Elastic IP address&#39;s name. For more information, see Resource Management. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#update_instance/3","title":"AWS.OpsWorks.update_instance/3","type":"function","doc":"Updates a specified instance. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#update_layer/3","title":"AWS.OpsWorks.update_layer/3","type":"function","doc":"Updates a specified layer. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#update_my_user_profile/3","title":"AWS.OpsWorks.update_my_user_profile/3","type":"function","doc":"Updates a user&#39;s SSH public key. Required Permissions: To use this action, an IAM user must have self-management enabled or an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#update_rds_db_instance/3","title":"AWS.OpsWorks.update_rds_db_instance/3","type":"function","doc":"Updates an Amazon RDS instance. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#update_stack/3","title":"AWS.OpsWorks.update_stack/3","type":"function","doc":"Updates a specified stack. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#update_user_profile/3","title":"AWS.OpsWorks.update_user_profile/3","type":"function","doc":"Updates a specified user profile. Required Permissions: To use this action, an IAM user must have an attached policy that explicitly grants permissions. For more information about user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorks.html#update_volume/3","title":"AWS.OpsWorks.update_volume/3","type":"function","doc":"Updates an Amazon EBS volume&#39;s name or mount point. For more information, see Resource Management. Required Permissions: To use this action, an IAM user must have a Manage permissions level for the stack, or an attached policy that explicitly grants permissions. For more information on user permissions, see Managing User Permissions."},{"ref":"AWS.OpsWorksCM.html","title":"AWS.OpsWorksCM","type":"module","doc":"AWS OpsWorks CM AWS OpsWorks for configuration management (CM) is a service that runs and manages configuration management servers. You can use AWS OpsWorks CM to create and manage AWS OpsWorks for Chef Automate and AWS OpsWorks for Puppet Enterprise servers, and add or remove nodes for the servers to manage. Glossary of terms Server: A configuration management server that can be highly-available. The configuration management server runs on an Amazon Elastic Compute Cloud (EC2) instance, and may use various other AWS services, such as Amazon Relational Database Service (RDS) and Elastic Load Balancing. A server is a generic abstraction over the configuration manager that you want to use, much like Amazon RDS. In AWS OpsWorks CM, you do not start or stop servers. After you create servers, they continue to run until they are deleted. Engine: The engine is the specific configuration manager that you want to use. Valid values in this release include ChefAutomate and Puppet. Backup: This is an application-level backup of the data that the configuration manager stores. AWS OpsWorks CM creates an S3 bucket for backups when you launch the first server. A backup maintains a snapshot of a server&#39;s configuration-related attributes at the time the backup starts. Events: Events are always related to a server. Events are written during server creation, when health checks run, when backups are created, when system maintenance is performed, etc. When you delete a server, the server&#39;s events are also deleted. Account attributes: Every account has attributes that are assigned in the AWS OpsWorks CM database. These attributes store information about configuration limits (servers, backups, etc.) and your customer account. Endpoints AWS OpsWorks CM supports the following endpoints, all HTTPS. You must connect to one of the following endpoints. Your servers can only be accessed or managed within the endpoint in which they are created. opsworks-cm.us-east-1.amazonaws.com opsworks-cm.us-east-2.amazonaws.com opsworks-cm.us-west-1.amazonaws.com opsworks-cm.us-west-2.amazonaws.com opsworks-cm.ap-northeast-1.amazonaws.com opsworks-cm.ap-southeast-1.amazonaws.com opsworks-cm.ap-southeast-2.amazonaws.com opsworks-cm.eu-central-1.amazonaws.com opsworks-cm.eu-west-1.amazonaws.com For more information, see AWS OpsWorks endpoints and quotas in the AWS General Reference. Throttling limits All API operations allow for five requests per second with a burst of 10 requests per second."},{"ref":"AWS.OpsWorksCM.html#associate_node/3","title":"AWS.OpsWorksCM.associate_node/3","type":"function","doc":"Associates a new node with the server. For more information about how to disassociate a node, see DisassociateNode. On a Chef server: This command is an alternative to knife bootstrap. Example (Chef): aws opsworks-cm associate-node --server-name *MyServer* --node-name *MyManagedNode* --engine-attributes &quot;Name=*CHEF_ORGANIZATION*,Value=default&quot; &quot;Name=*CHEF_NODE_PUBLIC_KEY*,Value=*public-key-pem*&quot; On a Puppet server, this command is an alternative to the puppet cert sign command that signs a Puppet node CSR. Example (Puppet): aws opsworks-cm associate-node --server-name *MyServer* --node-name *MyManagedNode* --engine-attributes &quot;Name=*PUPPET_NODE_CSR*,Value=*csr-pem*&quot; A node can can only be associated with servers that are in a HEALTHY state. Otherwise, an InvalidStateException is thrown. A ResourceNotFoundException is thrown when the server does not exist. A ValidationException is raised when parameters of the request are not valid. The AssociateNode API call can be integrated into Auto Scaling configurations, AWS Cloudformation templates, or the user data of a server&#39;s instance."},{"ref":"AWS.OpsWorksCM.html#create_backup/3","title":"AWS.OpsWorksCM.create_backup/3","type":"function","doc":"Creates an application-level backup of a server. While the server is in the BACKING_UP state, the server cannot be changed, and no additional backup can be created. Backups can be created for servers in RUNNING, HEALTHY, and UNHEALTHY states. By default, you can create a maximum of 50 manual backups. This operation is asynchronous. A LimitExceededException is thrown when the maximum number of manual backups is reached. An InvalidStateException is thrown when the server is not in any of the following states: RUNNING, HEALTHY, or UNHEALTHY. A ResourceNotFoundException is thrown when the server is not found. A ValidationException is thrown when parameters of the request are not valid."},{"ref":"AWS.OpsWorksCM.html#create_server/3","title":"AWS.OpsWorksCM.create_server/3","type":"function","doc":"Creates and immedately starts a new server. The server is ready to use when it is in the HEALTHY state. By default, you can create a maximum of 10 servers. This operation is asynchronous. A LimitExceededException is thrown when you have created the maximum number of servers (10). A ResourceAlreadyExistsException is thrown when a server with the same name already exists in the account. A ResourceNotFoundException is thrown when you specify a backup ID that is not valid or is for a backup that does not exist. A ValidationException is thrown when parameters of the request are not valid. If you do not specify a security group by adding the SecurityGroupIds parameter, AWS OpsWorks creates a new security group. Chef Automate: The default security group opens the Chef server to the world on TCP port 443. If a KeyName is present, AWS OpsWorks enables SSH access. SSH is also open to the world on TCP port 22. Puppet Enterprise: The default security group opens TCP ports 22, 443, 4433, 8140, 8142, 8143, and 8170. If a KeyName is present, AWS OpsWorks enables SSH access. SSH is also open to the world on TCP port 22. By default, your server is accessible from any IP address. We recommend that you update your security group rules to allow access from known IP addresses and address ranges only. To edit security group rules, open Security Groups in the navigation pane of the EC2 management console. To specify your own domain for a server, and provide your own self-signed or CA-signed certificate and private key, specify values for CustomDomain, CustomCertificate, and CustomPrivateKey."},{"ref":"AWS.OpsWorksCM.html#delete_backup/3","title":"AWS.OpsWorksCM.delete_backup/3","type":"function","doc":"Deletes a backup. You can delete both manual and automated backups. This operation is asynchronous. An InvalidStateException is thrown when a backup deletion is already in progress. A ResourceNotFoundException is thrown when the backup does not exist. A ValidationException is thrown when parameters of the request are not valid."},{"ref":"AWS.OpsWorksCM.html#delete_server/3","title":"AWS.OpsWorksCM.delete_server/3","type":"function","doc":"Deletes the server and the underlying AWS CloudFormation stacks (including the server&#39;s EC2 instance). When you run this command, the server state is updated to DELETING. After the server is deleted, it is no longer returned by DescribeServer requests. If the AWS CloudFormation stack cannot be deleted, the server cannot be deleted. This operation is asynchronous. An InvalidStateException is thrown when a server deletion is already in progress. A ResourceNotFoundException is thrown when the server does not exist. A ValidationException is raised when parameters of the request are not valid."},{"ref":"AWS.OpsWorksCM.html#describe_account_attributes/3","title":"AWS.OpsWorksCM.describe_account_attributes/3","type":"function","doc":"Describes your OpsWorks-CM account attributes. This operation is synchronous."},{"ref":"AWS.OpsWorksCM.html#describe_backups/3","title":"AWS.OpsWorksCM.describe_backups/3","type":"function","doc":"Describes backups. The results are ordered by time, with newest backups first. If you do not specify a BackupId or ServerName, the command returns all backups. This operation is synchronous. A ResourceNotFoundException is thrown when the backup does not exist. A ValidationException is raised when parameters of the request are not valid."},{"ref":"AWS.OpsWorksCM.html#describe_events/3","title":"AWS.OpsWorksCM.describe_events/3","type":"function","doc":"Describes events for a specified server. Results are ordered by time, with newest events first. This operation is synchronous. A ResourceNotFoundException is thrown when the server does not exist. A ValidationException is raised when parameters of the request are not valid."},{"ref":"AWS.OpsWorksCM.html#describe_node_association_status/3","title":"AWS.OpsWorksCM.describe_node_association_status/3","type":"function","doc":"Returns the current status of an existing association or disassociation request. A ResourceNotFoundException is thrown when no recent association or disassociation request with the specified token is found, or when the server does not exist. A ValidationException is raised when parameters of the request are not valid."},{"ref":"AWS.OpsWorksCM.html#describe_servers/3","title":"AWS.OpsWorksCM.describe_servers/3","type":"function","doc":"Lists all configuration management servers that are identified with your account. Only the stored results from Amazon DynamoDB are returned. AWS OpsWorks CM does not query other services. This operation is synchronous. A ResourceNotFoundException is thrown when the server does not exist. A ValidationException is raised when parameters of the request are not valid."},{"ref":"AWS.OpsWorksCM.html#disassociate_node/3","title":"AWS.OpsWorksCM.disassociate_node/3","type":"function","doc":"Disassociates a node from an AWS OpsWorks CM server, and removes the node from the server&#39;s managed nodes. After a node is disassociated, the node key pair is no longer valid for accessing the configuration manager&#39;s API. For more information about how to associate a node, see AssociateNode. A node can can only be disassociated from a server that is in a HEALTHY state. Otherwise, an InvalidStateException is thrown. A ResourceNotFoundException is thrown when the server does not exist. A ValidationException is raised when parameters of the request are not valid."},{"ref":"AWS.OpsWorksCM.html#export_server_engine_attribute/3","title":"AWS.OpsWorksCM.export_server_engine_attribute/3","type":"function","doc":"Exports a specified server engine attribute as a base64-encoded string. For example, you can export user data that you can use in EC2 to associate nodes with a server. This operation is synchronous. A ValidationException is raised when parameters of the request are not valid. A ResourceNotFoundException is thrown when the server does not exist. An InvalidStateException is thrown when the server is in any of the following states: CREATING, TERMINATED, FAILED or DELETING."},{"ref":"AWS.OpsWorksCM.html#list_tags_for_resource/3","title":"AWS.OpsWorksCM.list_tags_for_resource/3","type":"function","doc":"Returns a list of tags that are applied to the specified AWS OpsWorks for Chef Automate or AWS OpsWorks for Puppet Enterprise servers or backups."},{"ref":"AWS.OpsWorksCM.html#restore_server/3","title":"AWS.OpsWorksCM.restore_server/3","type":"function","doc":"Restores a backup to a server that is in a CONNECTION_LOST, HEALTHY, RUNNING, UNHEALTHY, or TERMINATED state. When you run RestoreServer, the server&#39;s EC2 instance is deleted, and a new EC2 instance is configured. RestoreServer maintains the existing server endpoint, so configuration management of the server&#39;s client devices (nodes) should continue to work. Restoring from a backup is performed by creating a new EC2 instance. If restoration is successful, and the server is in a HEALTHY state, AWS OpsWorks CM switches traffic over to the new instance. After restoration is finished, the old EC2 instance is maintained in a Running or Stopped state, but is eventually terminated. This operation is asynchronous. An InvalidStateException is thrown when the server is not in a valid state. A ResourceNotFoundException is thrown when the server does not exist. A ValidationException is raised when parameters of the request are not valid."},{"ref":"AWS.OpsWorksCM.html#start_maintenance/3","title":"AWS.OpsWorksCM.start_maintenance/3","type":"function","doc":"Manually starts server maintenance. This command can be useful if an earlier maintenance attempt failed, and the underlying cause of maintenance failure has been resolved. The server is in an UNDER_MAINTENANCE state while maintenance is in progress. Maintenance can only be started on servers in HEALTHY and UNHEALTHY states. Otherwise, an InvalidStateException is thrown. A ResourceNotFoundException is thrown when the server does not exist. A ValidationException is raised when parameters of the request are not valid."},{"ref":"AWS.OpsWorksCM.html#tag_resource/3","title":"AWS.OpsWorksCM.tag_resource/3","type":"function","doc":"Applies tags to an AWS OpsWorks for Chef Automate or AWS OpsWorks for Puppet Enterprise server, or to server backups."},{"ref":"AWS.OpsWorksCM.html#untag_resource/3","title":"AWS.OpsWorksCM.untag_resource/3","type":"function","doc":"Removes specified tags from an AWS OpsWorks-CM server or backup."},{"ref":"AWS.OpsWorksCM.html#update_server/3","title":"AWS.OpsWorksCM.update_server/3","type":"function","doc":"Updates settings for a server. This operation is synchronous."},{"ref":"AWS.OpsWorksCM.html#update_server_engine_attributes/3","title":"AWS.OpsWorksCM.update_server_engine_attributes/3","type":"function","doc":"Updates engine-specific attributes on a specified server. The server enters the MODIFYING state when this operation is in progress. Only one update can occur at a time. You can use this command to reset a Chef server&#39;s public key (CHEF_PIVOTAL_KEY) or a Puppet server&#39;s admin password (PUPPET_ADMIN_PASSWORD). This operation is asynchronous. This operation can only be called for servers in HEALTHY or UNHEALTHY states. Otherwise, an InvalidStateException is raised. A ResourceNotFoundException is thrown when the server does not exist. A ValidationException is raised when parameters of the request are not valid."},{"ref":"AWS.Organizations.html","title":"AWS.Organizations","type":"module","doc":"AWS Organizations"},{"ref":"AWS.Organizations.html#accept_handshake/3","title":"AWS.Organizations.accept_handshake/3","type":"function","doc":"Sends a response to the originator of a handshake agreeing to the action proposed by the handshake request. This operation can be called only by the following principals when they also have the relevant IAM permissions: Invitation to join or Approve all features request handshakes: only a principal from the member account. The user who calls the API for an invitation to join must have the organizations:AcceptHandshake permission. If you enabled all features in the organization, the user must also have the iam:CreateServiceLinkedRole permission so that AWS Organizations can create the required service-linked role named AWSServiceRoleForOrganizations. For more information, see AWS Organizations and Service-Linked Roles in the AWS Organizations User Guide. Enable all features final confirmation handshake: only a principal from the master account. For more information about invitations, see Inviting an AWS Account to Join Your Organization in the AWS Organizations User Guide. For more information about requests to enable all features in the organization, see Enabling All Features in Your Organization in the AWS Organizations User Guide. After you accept a handshake, it continues to appear in the results of relevant APIs for only 30 days. After that, it&#39;s deleted."},{"ref":"AWS.Organizations.html#attach_policy/3","title":"AWS.Organizations.attach_policy/3","type":"function","doc":"Attaches a policy to a root, an organizational unit (OU), or an individual account. How the policy affects accounts depends on the type of policy. Refer to the AWS Organizations User Guide for information about each policy type: AISERVICES_OPT_OUT_POLICY BACKUP_POLICY SERVICE_CONTROL_POLICY TAG_POLICY This operation can be called only from the organization&#39;s master account."},{"ref":"AWS.Organizations.html#cancel_handshake/3","title":"AWS.Organizations.cancel_handshake/3","type":"function","doc":"Cancels a handshake. Canceling a handshake sets the handshake state to CANCELED. This operation can be called only from the account that originated the handshake. The recipient of the handshake can&#39;t cancel it, but can use DeclineHandshake instead. After a handshake is canceled, the recipient can no longer respond to that handshake. After you cancel a handshake, it continues to appear in the results of relevant APIs for only 30 days. After that, it&#39;s deleted."},{"ref":"AWS.Organizations.html#create_account/3","title":"AWS.Organizations.create_account/3","type":"function","doc":"Creates an AWS account that is automatically a member of the organization whose credentials made the request. This is an asynchronous request that AWS performs in the background. Because CreateAccount operates asynchronously, it can return a successful completion message even though account initialization might still be in progress. You might need to wait a few minutes before you can successfully access the account. To check the status of the request, do one of the following: Use the OperationId response element from this operation to provide as a parameter to the DescribeCreateAccountStatus operation. Check the AWS CloudTrail log for the CreateAccountResult event. For information on using AWS CloudTrail with AWS Organizations, see Monitoring the Activity in Your Organization in the AWS Organizations User Guide. The user who calls the API to create an account must have the organizations:CreateAccount permission. If you enabled all features in the organization, AWS Organizations creates the required service-linked role named AWSServiceRoleForOrganizations. For more information, see AWS Organizations and Service-Linked Roles in the AWS Organizations User Guide. If the request includes tags, then the requester must have the organizations:TagResource permission. AWS Organizations preconfigures the new member account with a role (named OrganizationAccountAccessRole by default) that grants users in the master account administrator permissions in the new member account. Principals in the master account can assume the role. AWS Organizations clones the company name and address information for the new account from the organization&#39;s master account. This operation can be called only from the organization&#39;s master account. For more information about creating accounts, see Creating an AWS Account in Your Organization in the AWS Organizations User Guide. When you create an account in an organization using the AWS Organizations console, API, or CLI commands, the information required for the account to operate as a standalone account, such as a payment method and signing the end user license agreement (EULA) is not automatically collected. If you must remove an account from your organization later, you can do so only after you provide the missing information. Follow the steps at To leave an organization as a member account in the AWS Organizations User Guide. If you get an exception that indicates that you exceeded your account limits for the organization, contact AWS Support. If you get an exception that indicates that the operation failed because your organization is still initializing, wait one hour and then try again. If the error persists, contact AWS Support. Using CreateAccount to create multiple temporary accounts isn&#39;t recommended. You can only close an account from the Billing and Cost Management Console, and you must be signed in as the root user. For information on the requirements and process for closing an account, see Closing an AWS Account in the AWS Organizations User Guide. When you create a member account with this operation, you can choose whether to create the account with the IAM User and Role Access to Billing Information switch enabled. If you enable it, IAM users and roles that have appropriate permissions can view billing information for the account. If you disable it, only the account root user can access billing information. For information about how to disable this switch for an account, see Granting Access to Your Billing Information and Tools."},{"ref":"AWS.Organizations.html#create_gov_cloud_account/3","title":"AWS.Organizations.create_gov_cloud_account/3","type":"function","doc":"This action is available if all of the following are true: You&#39;re authorized to create accounts in the AWS GovCloud (US) Region. For more information on the AWS GovCloud (US) Region, see the AWS GovCloud User Guide. You already have an account in the AWS GovCloud (US) Region that is associated with your master account in the commercial Region. You call this action from the master account of your organization in the commercial Region. You have the organizations:CreateGovCloudAccount permission. AWS Organizations automatically creates the required service-linked role named AWSServiceRoleForOrganizations. For more information, see AWS Organizations and Service-Linked Roles in the AWS Organizations User Guide. AWS automatically enables AWS CloudTrail for AWS GovCloud (US) accounts, but you should also do the following: Verify that AWS CloudTrail is enabled to store logs. Create an S3 bucket for AWS CloudTrail log storage. For more information, see Verifying AWS CloudTrail Is Enabled in the AWS GovCloud User Guide. If the request includes tags, then the requester must have the organizations:TagResource permission. The tags are attached to the commercial account associated with the GovCloud account, rather than the GovCloud account itself. To add tags to the GovCloud account, call the TagResource operation in the GovCloud Region after the new GovCloud account exists. You call this action from the master account of your organization in the commercial Region to create a standalone AWS account in the AWS GovCloud (US) Region. After the account is created, the master account of an organization in the AWS GovCloud (US) Region can invite it to that organization. For more information on inviting standalone accounts in the AWS GovCloud (US) to join an organization, see AWS Organizations in the AWS GovCloud User Guide. Calling CreateGovCloudAccount is an asynchronous request that AWS performs in the background. Because CreateGovCloudAccount operates asynchronously, it can return a successful completion message even though account initialization might still be in progress. You might need to wait a few minutes before you can successfully access the account. To check the status of the request, do one of the following: Use the OperationId response element from this operation to provide as a parameter to the DescribeCreateAccountStatus operation. Check the AWS CloudTrail log for the CreateAccountResult event. For information on using AWS CloudTrail with Organizations, see Monitoring the Activity in Your Organization in the AWS Organizations User Guide. When you call the CreateGovCloudAccount action, you create two accounts: a standalone account in the AWS GovCloud (US) Region and an associated account in the commercial Region for billing and support purposes. The account in the commercial Region is automatically a member of the organization whose credentials made the request. Both accounts are associated with the same email address. A role is created in the new account in the commercial Region that allows the master account in the organization in the commercial Region to assume it. An AWS GovCloud (US) account is then created and associated with the commercial account that you just created. A role is also created in the new AWS GovCloud (US) account that can be assumed by the AWS GovCloud (US) account that is associated with the master account of the commercial organization. For more information and to view a diagram that explains how account access works, see AWS Organizations in the AWS GovCloud User Guide. For more information about creating accounts, see Creating an AWS Account in Your Organization in the AWS Organizations User Guide. When you create an account in an organization using the AWS Organizations console, API, or CLI commands, the information required for the account to operate as a standalone account is not automatically collected. This includes a payment method and signing the end user license agreement (EULA). If you must remove an account from your organization later, you can do so only after you provide the missing information. Follow the steps at To leave an organization as a member account in the AWS Organizations User Guide. If you get an exception that indicates that you exceeded your account limits for the organization, contact AWS Support. If you get an exception that indicates that the operation failed because your organization is still initializing, wait one hour and then try again. If the error persists, contact AWS Support. Using CreateGovCloudAccount to create multiple temporary accounts isn&#39;t recommended. You can only close an account from the AWS Billing and Cost Management console, and you must be signed in as the root user. For information on the requirements and process for closing an account, see Closing an AWS Account in the AWS Organizations User Guide. When you create a member account with this operation, you can choose whether to create the account with the IAM User and Role Access to Billing Information switch enabled. If you enable it, IAM users and roles that have appropriate permissions can view billing information for the account. If you disable it, only the account root user can access billing information. For information about how to disable this switch for an account, see Granting Access to Your Billing Information and Tools."},{"ref":"AWS.Organizations.html#create_organization/3","title":"AWS.Organizations.create_organization/3","type":"function","doc":"Creates an AWS organization. The account whose user is calling the CreateOrganization operation automatically becomes the master account of the new organization. This operation must be called using credentials from the account that is to become the new organization&#39;s master account. The principal must also have the relevant IAM permissions. By default (or if you set the FeatureSet parameter to ALL), the new organization is created with all features enabled and service control policies automatically enabled in the root. If you instead choose to create the organization supporting only the consolidated billing features by setting the FeatureSet parameter to CONSOLIDATED_BILLING&quot;, no policy types are enabled by default, and you can&#39;t use organization policies"},{"ref":"AWS.Organizations.html#create_organizational_unit/3","title":"AWS.Organizations.create_organizational_unit/3","type":"function","doc":"Creates an organizational unit (OU) within a root or parent OU. An OU is a container for accounts that enables you to organize your accounts to apply policies according to your business requirements. The number of levels deep that you can nest OUs is dependent upon the policy types enabled for that root. For service control policies, the limit is five. For more information about OUs, see Managing Organizational Units in the AWS Organizations User Guide. If the request includes tags, then the requester must have the organizations:TagResource permission. This operation can be called only from the organization&#39;s master account."},{"ref":"AWS.Organizations.html#create_policy/3","title":"AWS.Organizations.create_policy/3","type":"function","doc":"Creates a policy of a specified type that you can attach to a root, an organizational unit (OU), or an individual AWS account. For more information about policies and their use, see Managing Organization Policies. If the request includes tags, then the requester must have the organizations:TagResource permission. This operation can be called only from the organization&#39;s master account."},{"ref":"AWS.Organizations.html#decline_handshake/3","title":"AWS.Organizations.decline_handshake/3","type":"function","doc":"Declines a handshake request. This sets the handshake state to DECLINED and effectively deactivates the request. This operation can be called only from the account that received the handshake. The originator of the handshake can use CancelHandshake instead. The originator can&#39;t reactivate a declined request, but can reinitiate the process with a new handshake request. After you decline a handshake, it continues to appear in the results of relevant APIs for only 30 days. After that, it&#39;s deleted."},{"ref":"AWS.Organizations.html#delete_organization/3","title":"AWS.Organizations.delete_organization/3","type":"function","doc":"Deletes the organization. You can delete an organization only by using credentials from the master account. The organization must be empty of member accounts."},{"ref":"AWS.Organizations.html#delete_organizational_unit/3","title":"AWS.Organizations.delete_organizational_unit/3","type":"function","doc":"Deletes an organizational unit (OU) from a root or another OU. You must first remove all accounts and child OUs from the OU that you want to delete. This operation can be called only from the organization&#39;s master account."},{"ref":"AWS.Organizations.html#delete_policy/3","title":"AWS.Organizations.delete_policy/3","type":"function","doc":"Deletes the specified policy from your organization. Before you perform this operation, you must first detach the policy from all organizational units (OUs), roots, and accounts. This operation can be called only from the organization&#39;s master account."},{"ref":"AWS.Organizations.html#deregister_delegated_administrator/3","title":"AWS.Organizations.deregister_delegated_administrator/3","type":"function","doc":"Removes the specified member AWS account as a delegated administrator for the specified AWS service. Deregistering a delegated administrator can have unintended impacts on the functionality of the enabled AWS service. See the documentation for the enabled service before you deregister a delegated administrator so that you understand any potential impacts. You can run this action only for AWS services that support this feature. For a current list of services that support it, see the column Supports Delegated Administrator in the table at AWS Services that you can use with AWS Organizations in the AWS Organizations User Guide. This operation can be called only from the organization&#39;s master account."},{"ref":"AWS.Organizations.html#describe_account/3","title":"AWS.Organizations.describe_account/3","type":"function","doc":"Retrieves AWS Organizations-related information about the specified account. This operation can be called only from the organization&#39;s master account or by a member account that is a delegated administrator for an AWS service."},{"ref":"AWS.Organizations.html#describe_create_account_status/3","title":"AWS.Organizations.describe_create_account_status/3","type":"function","doc":"Retrieves the current status of an asynchronous request to create an account. This operation can be called only from the organization&#39;s master account or by a member account that is a delegated administrator for an AWS service."},{"ref":"AWS.Organizations.html#describe_effective_policy/3","title":"AWS.Organizations.describe_effective_policy/3","type":"function","doc":"Returns the contents of the effective policy for specified policy type and account. The effective policy is the aggregation of any policies of the specified type that the account inherits, plus any policy of that type that is directly attached to the account. This operation applies only to policy types other than service control policies (SCPs). For more information about policy inheritance, see How Policy Inheritance Works in the AWS Organizations User Guide. This operation can be called only from the organization&#39;s master account or by a member account that is a delegated administrator for an AWS service."},{"ref":"AWS.Organizations.html#describe_handshake/3","title":"AWS.Organizations.describe_handshake/3","type":"function","doc":"Retrieves information about a previously requested handshake. The handshake ID comes from the response to the original InviteAccountToOrganization operation that generated the handshake. You can access handshakes that are ACCEPTED, DECLINED, or CANCELED for only 30 days after they change to that state. They&#39;re then deleted and no longer accessible. This operation can be called from any account in the organization."},{"ref":"AWS.Organizations.html#describe_organization/3","title":"AWS.Organizations.describe_organization/3","type":"function","doc":"Retrieves information about the organization that the user&#39;s account belongs to. This operation can be called from any account in the organization. Even if a policy type is shown as available in the organization, you can disable it separately at the root level with DisablePolicyType. Use ListRoots to see the status of policy types for a specified root."},{"ref":"AWS.Organizations.html#describe_organizational_unit/3","title":"AWS.Organizations.describe_organizational_unit/3","type":"function","doc":"Retrieves information about an organizational unit (OU). This operation can be called only from the organization&#39;s master account or by a member account that is a delegated administrator for an AWS service."},{"ref":"AWS.Organizations.html#describe_policy/3","title":"AWS.Organizations.describe_policy/3","type":"function","doc":"Retrieves information about a policy. This operation can be called only from the organization&#39;s master account or by a member account that is a delegated administrator for an AWS service."},{"ref":"AWS.Organizations.html#detach_policy/3","title":"AWS.Organizations.detach_policy/3","type":"function","doc":"Detaches a policy from a target root, organizational unit (OU), or account. If the policy being detached is a service control policy (SCP), the changes to permissions for AWS Identity and Access Management (IAM) users and roles in affected accounts are immediate. Every root, OU, and account must have at least one SCP attached. If you want to replace the default FullAWSAccess policy with an SCP that limits the permissions that can be delegated, you must attach the replacement SCP before you can remove the default SCP. This is the authorization strategy of an &quot;allow list&quot;. If you instead attach a second SCP and leave the FullAWSAccess SCP still attached, and specify &quot;Effect&quot;: &quot;Deny&quot; in the second SCP to override the &quot;Effect&quot;: &quot;Allow&quot; in the FullAWSAccess policy (or any other attached SCP), you&#39;re using the authorization strategy of a &quot;deny list&quot;. This operation can be called only from the organization&#39;s master account."},{"ref":"AWS.Organizations.html#disable_a_w_s_service_access/3","title":"AWS.Organizations.disable_a_w_s_service_access/3","type":"function","doc":"Disables the integration of an AWS service (the service that is specified by ServicePrincipal) with AWS Organizations. When you disable integration, the specified service no longer can create a service-linked role in new accounts in your organization. This means the service can&#39;t perform operations on your behalf on any new accounts in your organization. The service can still perform operations in older accounts until the service completes its clean-up from AWS Organizations. We recommend that you disable integration between AWS Organizations and the specified AWS service by using the console or commands that are provided by the specified service. Doing so ensures that the other service is aware that it can clean up any resources that are required only for the integration. How the service cleans up its resources in the organization&#39;s accounts depends on that service. For more information, see the documentation for the other AWS service. After you perform the DisableAWSServiceAccess operation, the specified service can no longer perform operations in your organization&#39;s accounts unless the operations are explicitly permitted by the IAM policies that are attached to your roles. For more information about integrating other services with AWS Organizations, including the list of services that work with Organizations, see Integrating AWS Organizations with Other AWS Services in the AWS Organizations User Guide. This operation can be called only from the organization&#39;s master account."},{"ref":"AWS.Organizations.html#disable_policy_type/3","title":"AWS.Organizations.disable_policy_type/3","type":"function","doc":"Disables an organizational policy type in a root. A policy of a certain type can be attached to entities in a root only if that type is enabled in the root. After you perform this operation, you no longer can attach policies of the specified type to that root or to any organizational unit (OU) or account in that root. You can undo this by using the EnablePolicyType operation. This is an asynchronous request that AWS performs in the background. If you disable a policy type for a root, it still appears enabled for the organization if all features are enabled for the organization. AWS recommends that you first use ListRoots to see the status of policy types for a specified root, and then use this operation. This operation can be called only from the organization&#39;s master account. To view the status of available policy types in the organization, use DescribeOrganization."},{"ref":"AWS.Organizations.html#enable_a_w_s_service_access/3","title":"AWS.Organizations.enable_a_w_s_service_access/3","type":"function","doc":"Enables the integration of an AWS service (the service that is specified by ServicePrincipal) with AWS Organizations. When you enable integration, you allow the specified service to create a service-linked role in all the accounts in your organization. This allows the service to perform operations on your behalf in your organization and its accounts. We recommend that you enable integration between AWS Organizations and the specified AWS service by using the console or commands that are provided by the specified service. Doing so ensures that the service is aware that it can create the resources that are required for the integration. How the service creates those resources in the organization&#39;s accounts depends on that service. For more information, see the documentation for the other AWS service. For more information about enabling services to integrate with AWS Organizations, see Integrating AWS Organizations with Other AWS Services in the AWS Organizations User Guide. This operation can be called only from the organization&#39;s master account and only if the organization has enabled all features."},{"ref":"AWS.Organizations.html#enable_all_features/3","title":"AWS.Organizations.enable_all_features/3","type":"function","doc":"Enables all features in an organization. This enables the use of organization policies that can restrict the services and actions that can be called in each account. Until you enable all features, you have access only to consolidated billing, and you can&#39;t use any of the advanced account administration features that AWS Organizations supports. For more information, see Enabling All Features in Your Organization in the AWS Organizations User Guide. This operation is required only for organizations that were created explicitly with only the consolidated billing features enabled. Calling this operation sends a handshake to every invited account in the organization. The feature set change can be finalized and the additional features enabled only after all administrators in the invited accounts approve the change by accepting the handshake. After you enable all features, you can separately enable or disable individual policy types in a root using EnablePolicyType and DisablePolicyType. To see the status of policy types in a root, use ListRoots. After all invited member accounts accept the handshake, you finalize the feature set change by accepting the handshake that contains &quot;Action&quot;: &quot;ENABLE_ALL_FEATURES&quot;. This completes the change. After you enable all features in your organization, the master account in the organization can apply policies on all member accounts. These policies can restrict what users and even administrators in those accounts can do. The master account can apply policies that prevent accounts from leaving the organization. Ensure that your account administrators are aware of this. This operation can be called only from the organization&#39;s master account."},{"ref":"AWS.Organizations.html#enable_policy_type/3","title":"AWS.Organizations.enable_policy_type/3","type":"function","doc":"Enables a policy type in a root. After you enable a policy type in a root, you can attach policies of that type to the root, any organizational unit (OU), or account in that root. You can undo this by using the DisablePolicyType operation. This is an asynchronous request that AWS performs in the background. AWS recommends that you first use ListRoots to see the status of policy types for a specified root, and then use this operation. This operation can be called only from the organization&#39;s master account. You can enable a policy type in a root only if that policy type is available in the organization. To view the status of available policy types in the organization, use DescribeOrganization."},{"ref":"AWS.Organizations.html#invite_account_to_organization/3","title":"AWS.Organizations.invite_account_to_organization/3","type":"function","doc":"Sends an invitation to another account to join your organization as a member account. AWS Organizations sends email on your behalf to the email address that is associated with the other account&#39;s owner. The invitation is implemented as a Handshake whose details are in the response. You can invite AWS accounts only from the same seller as the master account. For example, if your organization&#39;s master account was created by Amazon Internet Services Pvt. Ltd (AISPL), an AWS seller in India, you can invite only other AISPL accounts to your organization. You can&#39;t combine accounts from AISPL and AWS or from any other AWS seller. For more information, see Consolidated Billing in India. If you receive an exception that indicates that you exceeded your account limits for the organization or that the operation failed because your organization is still initializing, wait one hour and then try again. If the error persists after an hour, contact AWS Support. If the request includes tags, then the requester must have the organizations:TagResource permission. This operation can be called only from the organization&#39;s master account."},{"ref":"AWS.Organizations.html#leave_organization/3","title":"AWS.Organizations.leave_organization/3","type":"function","doc":"Removes a member account from its parent organization. This version of the operation is performed by the account that wants to leave. To remove a member account as a user in the master account, use RemoveAccountFromOrganization instead. This operation can be called only from a member account in the organization. The master account in an organization with all features enabled can set service control policies (SCPs) that can restrict what administrators of member accounts can do. This includes preventing them from successfully calling LeaveOrganization and leaving the organization. You can leave an organization as a member account only if the account is configured with the information required to operate as a standalone account. When you create an account in an organization using the AWS Organizations console, API, or CLI commands, the information required of standalone accounts is not automatically collected. For each account that you want to make standalone, you must perform the following steps. If any of the steps are already completed for this account, that step doesn&#39;t appear. Choose a support plan Provide and verify the required contact information Provide a current payment method AWS uses the payment method to charge for any billable (not free tier) AWS activity that occurs while the account isn&#39;t attached to an organization. Follow the steps at To leave an organization when all required account information has not yet been provided in the AWS Organizations User Guide. You can leave an organization only after you enable IAM user access to billing in your account. For more information, see Activating Access to the Billing and Cost Management Console in the AWS Billing and Cost Management User Guide. After the account leaves the organization, all tags that were attached to the account object in the organization are deleted. AWS accounts outside of an organization do not support tags."},{"ref":"AWS.Organizations.html#list_a_w_s_service_access_for_organization/3","title":"AWS.Organizations.list_a_w_s_service_access_for_organization/3","type":"function","doc":"Returns a list of the AWS services that you enabled to integrate with your organization. After a service on this list creates the resources that it requires for the integration, it can perform operations on your organization and its accounts. For more information about integrating other services with AWS Organizations, including the list of services that currently work with Organizations, see Integrating AWS Organizations with Other AWS Services in the AWS Organizations User Guide. This operation can be called only from the organization&#39;s master account or by a member account that is a delegated administrator for an AWS service."},{"ref":"AWS.Organizations.html#list_accounts/3","title":"AWS.Organizations.list_accounts/3","type":"function","doc":"Lists all the accounts in the organization. To request only the accounts in a specified root or organizational unit (OU), use the ListAccountsForParent operation instead. Always check the NextToken response parameter for a null value when calling a List* operation. These operations can occasionally return an empty set of results even when there are more results available. The NextToken response parameter value is null only when there are no more results to display. This operation can be called only from the organization&#39;s master account or by a member account that is a delegated administrator for an AWS service."},{"ref":"AWS.Organizations.html#list_accounts_for_parent/3","title":"AWS.Organizations.list_accounts_for_parent/3","type":"function","doc":"Lists the accounts in an organization that are contained by the specified target root or organizational unit (OU). If you specify the root, you get a list of all the accounts that aren&#39;t in any OU. If you specify an OU, you get a list of all the accounts in only that OU and not in any child OUs. To get a list of all accounts in the organization, use the ListAccounts operation. Always check the NextToken response parameter for a null value when calling a List* operation. These operations can occasionally return an empty set of results even when there are more results available. The NextToken response parameter value is null only when there are no more results to display. This operation can be called only from the organization&#39;s master account or by a member account that is a delegated administrator for an AWS service."},{"ref":"AWS.Organizations.html#list_children/3","title":"AWS.Organizations.list_children/3","type":"function","doc":"Lists all of the organizational units (OUs) or accounts that are contained in the specified parent OU or root. This operation, along with ListParents enables you to traverse the tree structure that makes up this root. Always check the NextToken response parameter for a null value when calling a List* operation. These operations can occasionally return an empty set of results even when there are more results available. The NextToken response parameter value is null only when there are no more results to display. This operation can be called only from the organization&#39;s master account or by a member account that is a delegated administrator for an AWS service."},{"ref":"AWS.Organizations.html#list_create_account_status/3","title":"AWS.Organizations.list_create_account_status/3","type":"function","doc":"Lists the account creation requests that match the specified status that is currently being tracked for the organization. Always check the NextToken response parameter for a null value when calling a List* operation. These operations can occasionally return an empty set of results even when there are more results available. The NextToken response parameter value is null only when there are no more results to display. This operation can be called only from the organization&#39;s master account or by a member account that is a delegated administrator for an AWS service."},{"ref":"AWS.Organizations.html#list_delegated_administrators/3","title":"AWS.Organizations.list_delegated_administrators/3","type":"function","doc":"Lists the AWS accounts that are designated as delegated administrators in this organization. This operation can be called only from the organization&#39;s master account or by a member account that is a delegated administrator for an AWS service."},{"ref":"AWS.Organizations.html#list_delegated_services_for_account/3","title":"AWS.Organizations.list_delegated_services_for_account/3","type":"function","doc":"List the AWS services for which the specified account is a delegated administrator. This operation can be called only from the organization&#39;s master account or by a member account that is a delegated administrator for an AWS service."},{"ref":"AWS.Organizations.html#list_handshakes_for_account/3","title":"AWS.Organizations.list_handshakes_for_account/3","type":"function","doc":"Lists the current handshakes that are associated with the account of the requesting user. Handshakes that are ACCEPTED, DECLINED, or CANCELED appear in the results of this API for only 30 days after changing to that state. After that, they&#39;re deleted and no longer accessible. Always check the NextToken response parameter for a null value when calling a List* operation. These operations can occasionally return an empty set of results even when there are more results available. The NextToken response parameter value is null only when there are no more results to display. This operation can be called from any account in the organization."},{"ref":"AWS.Organizations.html#list_handshakes_for_organization/3","title":"AWS.Organizations.list_handshakes_for_organization/3","type":"function","doc":"Lists the handshakes that are associated with the organization that the requesting user is part of. The ListHandshakesForOrganization operation returns a list of handshake structures. Each structure contains details and status about a handshake. Handshakes that are ACCEPTED, DECLINED, or CANCELED appear in the results of this API for only 30 days after changing to that state. After that, they&#39;re deleted and no longer accessible. Always check the NextToken response parameter for a null value when calling a List* operation. These operations can occasionally return an empty set of results even when there are more results available. The NextToken response parameter value is null only when there are no more results to display. This operation can be called only from the organization&#39;s master account or by a member account that is a delegated administrator for an AWS service."},{"ref":"AWS.Organizations.html#list_organizational_units_for_parent/3","title":"AWS.Organizations.list_organizational_units_for_parent/3","type":"function","doc":"Lists the organizational units (OUs) in a parent organizational unit or root. Always check the NextToken response parameter for a null value when calling a List* operation. These operations can occasionally return an empty set of results even when there are more results available. The NextToken response parameter value is null only when there are no more results to display. This operation can be called only from the organization&#39;s master account or by a member account that is a delegated administrator for an AWS service."},{"ref":"AWS.Organizations.html#list_parents/3","title":"AWS.Organizations.list_parents/3","type":"function","doc":"Lists the root or organizational units (OUs) that serve as the immediate parent of the specified child OU or account. This operation, along with ListChildren enables you to traverse the tree structure that makes up this root. Always check the NextToken response parameter for a null value when calling a List* operation. These operations can occasionally return an empty set of results even when there are more results available. The NextToken response parameter value is null only when there are no more results to display. This operation can be called only from the organization&#39;s master account or by a member account that is a delegated administrator for an AWS service. In the current release, a child can have only a single parent."},{"ref":"AWS.Organizations.html#list_policies/3","title":"AWS.Organizations.list_policies/3","type":"function","doc":"Retrieves the list of all policies in an organization of a specified type. Always check the NextToken response parameter for a null value when calling a List* operation. These operations can occasionally return an empty set of results even when there are more results available. The NextToken response parameter value is null only when there are no more results to display. This operation can be called only from the organization&#39;s master account or by a member account that is a delegated administrator for an AWS service."},{"ref":"AWS.Organizations.html#list_policies_for_target/3","title":"AWS.Organizations.list_policies_for_target/3","type":"function","doc":"Lists the policies that are directly attached to the specified target root, organizational unit (OU), or account. You must specify the policy type that you want included in the returned list. Always check the NextToken response parameter for a null value when calling a List* operation. These operations can occasionally return an empty set of results even when there are more results available. The NextToken response parameter value is null only when there are no more results to display. This operation can be called only from the organization&#39;s master account or by a member account that is a delegated administrator for an AWS service."},{"ref":"AWS.Organizations.html#list_roots/3","title":"AWS.Organizations.list_roots/3","type":"function","doc":"Lists the roots that are defined in the current organization. Always check the NextToken response parameter for a null value when calling a List* operation. These operations can occasionally return an empty set of results even when there are more results available. The NextToken response parameter value is null only when there are no more results to display. This operation can be called only from the organization&#39;s master account or by a member account that is a delegated administrator for an AWS service. Policy types can be enabled and disabled in roots. This is distinct from whether they&#39;re available in the organization. When you enable all features, you make policy types available for use in that organization. Individual policy types can then be enabled and disabled in a root. To see the availability of a policy type in an organization, use DescribeOrganization."},{"ref":"AWS.Organizations.html#list_tags_for_resource/3","title":"AWS.Organizations.list_tags_for_resource/3","type":"function","doc":"Lists tags that are attached to the specified resource. You can attach tags to the following resources in AWS Organizations. AWS account Organization root Organizational unit (OU) Policy (any type) This operation can be called only from the organization&#39;s master account or by a member account that is a delegated administrator for an AWS service."},{"ref":"AWS.Organizations.html#list_targets_for_policy/3","title":"AWS.Organizations.list_targets_for_policy/3","type":"function","doc":"Lists all the roots, organizational units (OUs), and accounts that the specified policy is attached to. Always check the NextToken response parameter for a null value when calling a List* operation. These operations can occasionally return an empty set of results even when there are more results available. The NextToken response parameter value is null only when there are no more results to display. This operation can be called only from the organization&#39;s master account or by a member account that is a delegated administrator for an AWS service."},{"ref":"AWS.Organizations.html#move_account/3","title":"AWS.Organizations.move_account/3","type":"function","doc":"Moves an account from its current source parent root or organizational unit (OU) to the specified destination parent root or OU. This operation can be called only from the organization&#39;s master account."},{"ref":"AWS.Organizations.html#register_delegated_administrator/3","title":"AWS.Organizations.register_delegated_administrator/3","type":"function","doc":"Enables the specified member account to administer the Organizations features of the specified AWS service. It grants read-only access to AWS Organizations service data. The account still requires IAM permissions to access and administer the AWS service. You can run this action only for AWS services that support this feature. For a current list of services that support it, see the column Supports Delegated Administrator in the table at AWS Services that you can use with AWS Organizations in the AWS Organizations User Guide. This operation can be called only from the organization&#39;s master account."},{"ref":"AWS.Organizations.html#remove_account_from_organization/3","title":"AWS.Organizations.remove_account_from_organization/3","type":"function","doc":"Removes the specified account from the organization. The removed account becomes a standalone account that isn&#39;t a member of any organization. It&#39;s no longer subject to any policies and is responsible for its own bill payments. The organization&#39;s master account is no longer charged for any expenses accrued by the member account after it&#39;s removed from the organization. This operation can be called only from the organization&#39;s master account. Member accounts can remove themselves with LeaveOrganization instead. You can remove an account from your organization only if the account is configured with the information required to operate as a standalone account. When you create an account in an organization using the AWS Organizations console, API, or CLI commands, the information required of standalone accounts is not automatically collected. For an account that you want to make standalone, you must choose a support plan, provide and verify the required contact information, and provide a current payment method. AWS uses the payment method to charge for any billable (not free tier) AWS activity that occurs while the account isn&#39;t attached to an organization. To remove an account that doesn&#39;t yet have this information, you must sign in as the member account and follow the steps at To leave an organization when all required account information has not yet been provided in the AWS Organizations User Guide. After the account leaves the organization, all tags that were attached to the account object in the organization are deleted. AWS accounts outside of an organization do not support tags."},{"ref":"AWS.Organizations.html#tag_resource/3","title":"AWS.Organizations.tag_resource/3","type":"function","doc":"Adds one or more tags to the specified resource. Currently, you can attach tags to the following resources in AWS Organizations. AWS account Organization root Organizational unit (OU) Policy (any type) This operation can be called only from the organization&#39;s master account."},{"ref":"AWS.Organizations.html#untag_resource/3","title":"AWS.Organizations.untag_resource/3","type":"function","doc":"Removes any tags with the specified keys from the specified resource. You can attach tags to the following resources in AWS Organizations. AWS account Organization root Organizational unit (OU) Policy (any type) This operation can be called only from the organization&#39;s master account."},{"ref":"AWS.Organizations.html#update_organizational_unit/3","title":"AWS.Organizations.update_organizational_unit/3","type":"function","doc":"Renames the specified organizational unit (OU). The ID and ARN don&#39;t change. The child OUs and accounts remain in place, and any attached policies of the OU remain attached. This operation can be called only from the organization&#39;s master account."},{"ref":"AWS.Organizations.html#update_policy/3","title":"AWS.Organizations.update_policy/3","type":"function","doc":"Updates an existing policy with a new name, description, or content. If you don&#39;t supply any parameter, that value remains unchanged. You can&#39;t change a policy&#39;s type. This operation can be called only from the organization&#39;s master account."},{"ref":"AWS.Outposts.html","title":"AWS.Outposts","type":"module","doc":"AWS Outposts is a fully-managed service that extends AWS infrastructure, APIs, and tools to customer premises. By providing local access to AWS-managed infrastructure, AWS Outposts enables customers to build and run applications on premises using the same programming interfaces as in AWS Regions, while using local compute and storage resources for lower latency and local data processing needs."},{"ref":"AWS.Outposts.html#create_outpost/3","title":"AWS.Outposts.create_outpost/3","type":"function","doc":"Creates an Outpost."},{"ref":"AWS.Outposts.html#delete_outpost/4","title":"AWS.Outposts.delete_outpost/4","type":"function","doc":"Deletes the Outpost."},{"ref":"AWS.Outposts.html#delete_site/4","title":"AWS.Outposts.delete_site/4","type":"function","doc":"Deletes the site."},{"ref":"AWS.Outposts.html#get_outpost/3","title":"AWS.Outposts.get_outpost/3","type":"function","doc":"Gets information about the specified Outpost."},{"ref":"AWS.Outposts.html#get_outpost_instance_types/5","title":"AWS.Outposts.get_outpost_instance_types/5","type":"function","doc":"Lists the instance types for the specified Outpost."},{"ref":"AWS.Outposts.html#list_outposts/4","title":"AWS.Outposts.list_outposts/4","type":"function","doc":"List the Outposts for your AWS account."},{"ref":"AWS.Outposts.html#list_sites/4","title":"AWS.Outposts.list_sites/4","type":"function","doc":"Lists the sites for the specified AWS account."},{"ref":"AWS.PI.html","title":"AWS.PI","type":"module","doc":"AWS Performance Insights enables you to monitor and explore different dimensions of database load based on data captured from a running RDS instance. The guide provides detailed information about Performance Insights data types, parameters and errors. For more information about Performance Insights capabilities see Using Amazon RDS Performance Insights in the Amazon RDS User Guide. The AWS Performance Insights API provides visibility into the performance of your RDS instance, when Performance Insights is enabled for supported engine types. While Amazon CloudWatch provides the authoritative source for AWS service vended monitoring metrics, AWS Performance Insights offers a domain-specific view of database load measured as Average Active Sessions and provided to API consumers as a 2-dimensional time-series dataset. The time dimension of the data provides DB load data for each time point in the queried time range, and each time point decomposes overall load in relation to the requested dimensions, such as SQL, Wait-event, User or Host, measured at that time point."},{"ref":"AWS.PI.html#describe_dimension_keys/3","title":"AWS.PI.describe_dimension_keys/3","type":"function","doc":"For a specific time period, retrieve the top N dimension keys for a metric."},{"ref":"AWS.PI.html#get_resource_metrics/3","title":"AWS.PI.get_resource_metrics/3","type":"function","doc":"Retrieve Performance Insights metrics for a set of data sources, over a time period. You can provide specific dimension groups and dimensions, and provide aggregation and filtering criteria for each group."},{"ref":"AWS.Personalize.html","title":"AWS.Personalize","type":"module","doc":"Amazon Personalize is a machine learning service that makes it easy to add individualized recommendations to customers."},{"ref":"AWS.Personalize.html#create_batch_inference_job/3","title":"AWS.Personalize.create_batch_inference_job/3","type":"function","doc":"Creates a batch inference job. The operation can handle up to 50 million records and the input file must be in JSON format. For more information, see recommendations-batch."},{"ref":"AWS.Personalize.html#create_campaign/3","title":"AWS.Personalize.create_campaign/3","type":"function","doc":"Creates a campaign by deploying a solution version. When a client calls the GetRecommendations and GetPersonalizedRanking APIs, a campaign is specified in the request. Minimum Provisioned TPS and Auto-Scaling A transaction is a single GetRecommendations or GetPersonalizedRanking call. Transactions per second (TPS) is the throughput and unit of billing for Amazon Personalize. The minimum provisioned TPS (minProvisionedTPS) specifies the baseline throughput provisioned by Amazon Personalize, and thus, the minimum billing charge. If your TPS increases beyond minProvisionedTPS, Amazon Personalize auto-scales the provisioned capacity up and down, but never below minProvisionedTPS, to maintain a 70% utilization. There&#39;s a short time delay while the capacity is increased that might cause loss of transactions. It&#39;s recommended to start with a low minProvisionedTPS, track your usage using Amazon CloudWatch metrics, and then increase the minProvisionedTPS as necessary. Status A campaign can be in one of the following states: CREATE PENDING &gt; CREATE IN_PROGRESS &gt; ACTIVE -or- CREATE FAILED DELETE PENDING &gt; DELETE IN_PROGRESS To get the campaign status, call DescribeCampaign. Wait until the status of the campaign is ACTIVE before asking the campaign for recommendations. Related APIs ListCampaigns DescribeCampaign UpdateCampaign DeleteCampaign"},{"ref":"AWS.Personalize.html#create_dataset/3","title":"AWS.Personalize.create_dataset/3","type":"function","doc":"Creates an empty dataset and adds it to the specified dataset group. Use CreateDatasetImportJob to import your training data to a dataset. There are three types of datasets: Interactions Items Users Each dataset type has an associated schema with required field types. Only the Interactions dataset is required in order to train a model (also referred to as creating a solution). A dataset can be in one of the following states: CREATE PENDING &gt; CREATE IN_PROGRESS &gt; ACTIVE -or- CREATE FAILED DELETE PENDING &gt; DELETE IN_PROGRESS To get the status of the dataset, call DescribeDataset. Related APIs CreateDatasetGroup ListDatasets DescribeDataset DeleteDataset"},{"ref":"AWS.Personalize.html#create_dataset_group/3","title":"AWS.Personalize.create_dataset_group/3","type":"function","doc":"Creates an empty dataset group. A dataset group contains related datasets that supply data for training a model. A dataset group can contain at most three datasets, one for each type of dataset: Interactions Items Users To train a model (create a solution), a dataset group that contains an Interactions dataset is required. Call CreateDataset to add a dataset to the group. A dataset group can be in one of the following states: CREATE PENDING &gt; CREATE IN_PROGRESS &gt; ACTIVE -or- CREATE FAILED DELETE PENDING To get the status of the dataset group, call DescribeDatasetGroup. If the status shows as CREATE FAILED, the response includes a failureReason key, which describes why the creation failed. You must wait until the status of the dataset group is ACTIVE before adding a dataset to the group. You can specify an AWS Key Management Service (KMS) key to encrypt the datasets in the group. If you specify a KMS key, you must also include an AWS Identity and Access Management (IAM) role that has permission to access the key. APIs that require a dataset group ARN in the request CreateDataset CreateEventTracker CreateSolution Related APIs ListDatasetGroups DescribeDatasetGroup DeleteDatasetGroup"},{"ref":"AWS.Personalize.html#create_dataset_import_job/3","title":"AWS.Personalize.create_dataset_import_job/3","type":"function","doc":"Creates a job that imports training data from your data source (an Amazon S3 bucket) to an Amazon Personalize dataset. To allow Amazon Personalize to import the training data, you must specify an AWS Identity and Access Management (IAM) role that has permission to read from the data source, as Amazon Personalize makes a copy of your data and processes it in an internal AWS system. The dataset import job replaces any previous data in the dataset. Status A dataset import job can be in one of the following states: CREATE PENDING &gt; CREATE IN_PROGRESS &gt; ACTIVE -or- CREATE FAILED To get the status of the import job, call DescribeDatasetImportJob, providing the Amazon Resource Name (ARN) of the dataset import job. The dataset import is complete when the status shows as ACTIVE. If the status shows as CREATE FAILED, the response includes a failureReason key, which describes why the job failed. Importing takes time. You must wait until the status shows as ACTIVE before training a model using the dataset. Related APIs ListDatasetImportJobs DescribeDatasetImportJob"},{"ref":"AWS.Personalize.html#create_event_tracker/3","title":"AWS.Personalize.create_event_tracker/3","type":"function","doc":"Creates an event tracker that you use when sending event data to the specified dataset group using the PutEvents API. When Amazon Personalize creates an event tracker, it also creates an event-interactions dataset in the dataset group associated with the event tracker. The event-interactions dataset stores the event data from the PutEvents call. The contents of this dataset are not available to the user. Only one event tracker can be associated with a dataset group. You will get an error if you call CreateEventTracker using the same dataset group as an existing event tracker. When you send event data you include your tracking ID. The tracking ID identifies the customer and authorizes the customer to send the data. The event tracker can be in one of the following states: CREATE PENDING &gt; CREATE IN_PROGRESS &gt; ACTIVE -or- CREATE FAILED DELETE PENDING &gt; DELETE IN_PROGRESS To get the status of the event tracker, call DescribeEventTracker. The event tracker must be in the ACTIVE state before using the tracking ID. Related APIs ListEventTrackers DescribeEventTracker DeleteEventTracker"},{"ref":"AWS.Personalize.html#create_filter/3","title":"AWS.Personalize.create_filter/3","type":"function","doc":"Creates a recommendation filter. For more information, see Using Filters with Amazon Personalize."},{"ref":"AWS.Personalize.html#create_schema/3","title":"AWS.Personalize.create_schema/3","type":"function","doc":"Creates an Amazon Personalize schema from the specified schema string. The schema you create must be in Avro JSON format. Amazon Personalize recognizes three schema variants. Each schema is associated with a dataset type and has a set of required field and keywords. You specify a schema when you call CreateDataset. Related APIs ListSchemas DescribeSchema DeleteSchema"},{"ref":"AWS.Personalize.html#create_solution/3","title":"AWS.Personalize.create_solution/3","type":"function","doc":"Creates the configuration for training a model. A trained model is known as a solution. After the configuration is created, you train the model (create a solution) by calling the CreateSolutionVersion operation. Every time you call CreateSolutionVersion, a new version of the solution is created. After creating a solution version, you check its accuracy by calling GetSolutionMetrics. When you are satisfied with the version, you deploy it using CreateCampaign. The campaign provides recommendations to a client through the GetRecommendations API. To train a model, Amazon Personalize requires training data and a recipe. The training data comes from the dataset group that you provide in the request. A recipe specifies the training algorithm and a feature transformation. You can specify one of the predefined recipes provided by Amazon Personalize. Alternatively, you can specify performAutoML and Amazon Personalize will analyze your data and select the optimum USER_PERSONALIZATION recipe for you. Status A solution can be in one of the following states: CREATE PENDING &gt; CREATE IN_PROGRESS &gt; ACTIVE -or- CREATE FAILED DELETE PENDING &gt; DELETE IN_PROGRESS To get the status of the solution, call DescribeSolution. Wait until the status shows as ACTIVE before calling CreateSolutionVersion. Related APIs ListSolutions CreateSolutionVersion DescribeSolution DeleteSolution ListSolutionVersions DescribeSolutionVersion"},{"ref":"AWS.Personalize.html#create_solution_version/3","title":"AWS.Personalize.create_solution_version/3","type":"function","doc":"Trains or retrains an active solution. A solution is created using the CreateSolution operation and must be in the ACTIVE state before calling CreateSolutionVersion. A new version of the solution is created every time you call this operation. Status A solution version can be in one of the following states: CREATE PENDING &gt; CREATE IN_PROGRESS &gt; ACTIVE -or- CREATE FAILED To get the status of the version, call DescribeSolutionVersion. Wait until the status shows as ACTIVE before calling CreateCampaign. If the status shows as CREATE FAILED, the response includes a failureReason key, which describes why the job failed. Related APIs ListSolutionVersions DescribeSolutionVersion ListSolutions CreateSolution DescribeSolution DeleteSolution"},{"ref":"AWS.Personalize.html#delete_campaign/3","title":"AWS.Personalize.delete_campaign/3","type":"function","doc":"Removes a campaign by deleting the solution deployment. The solution that the campaign is based on is not deleted and can be redeployed when needed. A deleted campaign can no longer be specified in a GetRecommendations request. For more information on campaigns, see CreateCampaign."},{"ref":"AWS.Personalize.html#delete_dataset/3","title":"AWS.Personalize.delete_dataset/3","type":"function","doc":"Deletes a dataset. You can&#39;t delete a dataset if an associated DatasetImportJob or SolutionVersion is in the CREATE PENDING or IN PROGRESS state. For more information on datasets, see CreateDataset."},{"ref":"AWS.Personalize.html#delete_dataset_group/3","title":"AWS.Personalize.delete_dataset_group/3","type":"function","doc":"Deletes a dataset group. Before you delete a dataset group, you must delete the following: All associated event trackers. All associated solutions. All datasets in the dataset group."},{"ref":"AWS.Personalize.html#delete_event_tracker/3","title":"AWS.Personalize.delete_event_tracker/3","type":"function","doc":"Deletes the event tracker. Does not delete the event-interactions dataset from the associated dataset group. For more information on event trackers, see CreateEventTracker."},{"ref":"AWS.Personalize.html#delete_filter/3","title":"AWS.Personalize.delete_filter/3","type":"function","doc":"Deletes a filter."},{"ref":"AWS.Personalize.html#delete_schema/3","title":"AWS.Personalize.delete_schema/3","type":"function","doc":"Deletes a schema. Before deleting a schema, you must delete all datasets referencing the schema. For more information on schemas, see CreateSchema."},{"ref":"AWS.Personalize.html#delete_solution/3","title":"AWS.Personalize.delete_solution/3","type":"function","doc":"Deletes all versions of a solution and the Solution object itself. Before deleting a solution, you must delete all campaigns based on the solution. To determine what campaigns are using the solution, call ListCampaigns and supply the Amazon Resource Name (ARN) of the solution. You can&#39;t delete a solution if an associated SolutionVersion is in the CREATE PENDING or IN PROGRESS state. For more information on solutions, see CreateSolution."},{"ref":"AWS.Personalize.html#describe_algorithm/3","title":"AWS.Personalize.describe_algorithm/3","type":"function","doc":"Describes the given algorithm."},{"ref":"AWS.Personalize.html#describe_batch_inference_job/3","title":"AWS.Personalize.describe_batch_inference_job/3","type":"function","doc":"Gets the properties of a batch inference job including name, Amazon Resource Name (ARN), status, input and output configurations, and the ARN of the solution version used to generate the recommendations."},{"ref":"AWS.Personalize.html#describe_campaign/3","title":"AWS.Personalize.describe_campaign/3","type":"function","doc":"Describes the given campaign, including its status. A campaign can be in one of the following states: CREATE PENDING &gt; CREATE IN_PROGRESS &gt; ACTIVE -or- CREATE FAILED DELETE PENDING &gt; DELETE IN_PROGRESS When the status is CREATE FAILED, the response includes the failureReason key, which describes why. For more information on campaigns, see CreateCampaign."},{"ref":"AWS.Personalize.html#describe_dataset/3","title":"AWS.Personalize.describe_dataset/3","type":"function","doc":"Describes the given dataset. For more information on datasets, see CreateDataset."},{"ref":"AWS.Personalize.html#describe_dataset_group/3","title":"AWS.Personalize.describe_dataset_group/3","type":"function","doc":"Describes the given dataset group. For more information on dataset groups, see CreateDatasetGroup."},{"ref":"AWS.Personalize.html#describe_dataset_import_job/3","title":"AWS.Personalize.describe_dataset_import_job/3","type":"function","doc":"Describes the dataset import job created by CreateDatasetImportJob, including the import job status."},{"ref":"AWS.Personalize.html#describe_event_tracker/3","title":"AWS.Personalize.describe_event_tracker/3","type":"function","doc":"Describes an event tracker. The response includes the trackingId and status of the event tracker. For more information on event trackers, see CreateEventTracker."},{"ref":"AWS.Personalize.html#describe_feature_transformation/3","title":"AWS.Personalize.describe_feature_transformation/3","type":"function","doc":"Describes the given feature transformation."},{"ref":"AWS.Personalize.html#describe_filter/3","title":"AWS.Personalize.describe_filter/3","type":"function","doc":"Describes a filter&#39;s properties."},{"ref":"AWS.Personalize.html#describe_recipe/3","title":"AWS.Personalize.describe_recipe/3","type":"function","doc":"Describes a recipe. A recipe contains three items: An algorithm that trains a model. Hyperparameters that govern the training. Feature transformation information for modifying the input data before training. Amazon Personalize provides a set of predefined recipes. You specify a recipe when you create a solution with the CreateSolution API. CreateSolution trains a model by using the algorithm in the specified recipe and a training dataset. The solution, when deployed as a campaign, can provide recommendations using the GetRecommendations API."},{"ref":"AWS.Personalize.html#describe_schema/3","title":"AWS.Personalize.describe_schema/3","type":"function","doc":"Describes a schema. For more information on schemas, see CreateSchema."},{"ref":"AWS.Personalize.html#describe_solution/3","title":"AWS.Personalize.describe_solution/3","type":"function","doc":"Describes a solution. For more information on solutions, see CreateSolution."},{"ref":"AWS.Personalize.html#describe_solution_version/3","title":"AWS.Personalize.describe_solution_version/3","type":"function","doc":"Describes a specific version of a solution. For more information on solutions, see CreateSolution."},{"ref":"AWS.Personalize.html#get_solution_metrics/3","title":"AWS.Personalize.get_solution_metrics/3","type":"function","doc":"Gets the metrics for the specified solution version."},{"ref":"AWS.Personalize.html#list_batch_inference_jobs/3","title":"AWS.Personalize.list_batch_inference_jobs/3","type":"function","doc":"Gets a list of the batch inference jobs that have been performed off of a solution version."},{"ref":"AWS.Personalize.html#list_campaigns/3","title":"AWS.Personalize.list_campaigns/3","type":"function","doc":"Returns a list of campaigns that use the given solution. When a solution is not specified, all the campaigns associated with the account are listed. The response provides the properties for each campaign, including the Amazon Resource Name (ARN). For more information on campaigns, see CreateCampaign."},{"ref":"AWS.Personalize.html#list_dataset_groups/3","title":"AWS.Personalize.list_dataset_groups/3","type":"function","doc":"Returns a list of dataset groups. The response provides the properties for each dataset group, including the Amazon Resource Name (ARN). For more information on dataset groups, see CreateDatasetGroup."},{"ref":"AWS.Personalize.html#list_dataset_import_jobs/3","title":"AWS.Personalize.list_dataset_import_jobs/3","type":"function","doc":"Returns a list of dataset import jobs that use the given dataset. When a dataset is not specified, all the dataset import jobs associated with the account are listed. The response provides the properties for each dataset import job, including the Amazon Resource Name (ARN). For more information on dataset import jobs, see CreateDatasetImportJob. For more information on datasets, see CreateDataset."},{"ref":"AWS.Personalize.html#list_datasets/3","title":"AWS.Personalize.list_datasets/3","type":"function","doc":"Returns the list of datasets contained in the given dataset group. The response provides the properties for each dataset, including the Amazon Resource Name (ARN). For more information on datasets, see CreateDataset."},{"ref":"AWS.Personalize.html#list_event_trackers/3","title":"AWS.Personalize.list_event_trackers/3","type":"function","doc":"Returns the list of event trackers associated with the account. The response provides the properties for each event tracker, including the Amazon Resource Name (ARN) and tracking ID. For more information on event trackers, see CreateEventTracker."},{"ref":"AWS.Personalize.html#list_filters/3","title":"AWS.Personalize.list_filters/3","type":"function","doc":"Lists all filters that belong to a given dataset group."},{"ref":"AWS.Personalize.html#list_recipes/3","title":"AWS.Personalize.list_recipes/3","type":"function","doc":"Returns a list of available recipes. The response provides the properties for each recipe, including the recipe&#39;s Amazon Resource Name (ARN)."},{"ref":"AWS.Personalize.html#list_schemas/3","title":"AWS.Personalize.list_schemas/3","type":"function","doc":"Returns the list of schemas associated with the account. The response provides the properties for each schema, including the Amazon Resource Name (ARN). For more information on schemas, see CreateSchema."},{"ref":"AWS.Personalize.html#list_solution_versions/3","title":"AWS.Personalize.list_solution_versions/3","type":"function","doc":"Returns a list of solution versions for the given solution. When a solution is not specified, all the solution versions associated with the account are listed. The response provides the properties for each solution version, including the Amazon Resource Name (ARN). For more information on solutions, see CreateSolution."},{"ref":"AWS.Personalize.html#list_solutions/3","title":"AWS.Personalize.list_solutions/3","type":"function","doc":"Returns a list of solutions that use the given dataset group. When a dataset group is not specified, all the solutions associated with the account are listed. The response provides the properties for each solution, including the Amazon Resource Name (ARN). For more information on solutions, see CreateSolution."},{"ref":"AWS.Personalize.html#update_campaign/3","title":"AWS.Personalize.update_campaign/3","type":"function","doc":"Updates a campaign by either deploying a new solution or changing the value of the campaign&#39;s minProvisionedTPS parameter. To update a campaign, the campaign status must be ACTIVE or CREATE FAILED. Check the campaign status using the DescribeCampaign API. You must wait until the status of the updated campaign is ACTIVE before asking the campaign for recommendations. For more information on campaigns, see CreateCampaign."},{"ref":"AWS.PersonalizeEvents.html","title":"AWS.PersonalizeEvents","type":"module","doc":"Amazon Personalize can consume real-time user event data, such as stream or click data, and use it for model training either alone or combined with historical data. For more information see recording-events."},{"ref":"AWS.PersonalizeEvents.html#put_events/3","title":"AWS.PersonalizeEvents.put_events/3","type":"function","doc":"Records user interaction event data. For more information see event-record-api."},{"ref":"AWS.PersonalizeEvents.html#put_items/3","title":"AWS.PersonalizeEvents.put_items/3","type":"function","doc":"Adds one or more items to an Items dataset. For more information see importing-items."},{"ref":"AWS.PersonalizeEvents.html#put_users/3","title":"AWS.PersonalizeEvents.put_users/3","type":"function","doc":"Adds one or more users to a Users dataset. For more information see importing-users."},{"ref":"AWS.PersonalizeRuntime.html","title":"AWS.PersonalizeRuntime","type":"module","doc":""},{"ref":"AWS.PersonalizeRuntime.html#get_personalized_ranking/3","title":"AWS.PersonalizeRuntime.get_personalized_ranking/3","type":"function","doc":"Re-ranks a list of recommended items for the given user. The first item in the list is deemed the most likely item to be of interest to the user. The solution backing the campaign must have been created using a recipe of type PERSONALIZED_RANKING."},{"ref":"AWS.PersonalizeRuntime.html#get_recommendations/3","title":"AWS.PersonalizeRuntime.get_recommendations/3","type":"function","doc":"Returns a list of recommended items. The required input depends on the recipe type used to create the solution backing the campaign, as follows: RELATED_ITEMS - itemId required, userId not used USER_PERSONALIZATION - itemId optional, userId required Campaigns that are backed by a solution created using a recipe of type PERSONALIZED_RANKING use the API."},{"ref":"AWS.Pinpoint.html","title":"AWS.Pinpoint","type":"module","doc":"Doc Engage API - Amazon Pinpoint API"},{"ref":"AWS.Pinpoint.html#create_app/3","title":"AWS.Pinpoint.create_app/3","type":"function","doc":"Creates an application."},{"ref":"AWS.Pinpoint.html#create_campaign/4","title":"AWS.Pinpoint.create_campaign/4","type":"function","doc":"Creates a new campaign for an application or updates the settings of an existing campaign for an application."},{"ref":"AWS.Pinpoint.html#create_email_template/4","title":"AWS.Pinpoint.create_email_template/4","type":"function","doc":"Creates a message template for messages that are sent through the email channel."},{"ref":"AWS.Pinpoint.html#create_export_job/4","title":"AWS.Pinpoint.create_export_job/4","type":"function","doc":"Creates an export job for an application."},{"ref":"AWS.Pinpoint.html#create_import_job/4","title":"AWS.Pinpoint.create_import_job/4","type":"function","doc":"Creates an import job for an application."},{"ref":"AWS.Pinpoint.html#create_journey/4","title":"AWS.Pinpoint.create_journey/4","type":"function","doc":"Creates a journey for an application."},{"ref":"AWS.Pinpoint.html#create_push_template/4","title":"AWS.Pinpoint.create_push_template/4","type":"function","doc":"Creates a message template for messages that are sent through a push notification channel."},{"ref":"AWS.Pinpoint.html#create_recommender_configuration/3","title":"AWS.Pinpoint.create_recommender_configuration/3","type":"function","doc":"Creates an Amazon Pinpoint configuration for a recommender model."},{"ref":"AWS.Pinpoint.html#create_segment/4","title":"AWS.Pinpoint.create_segment/4","type":"function","doc":"Creates a new segment for an application or updates the configuration, dimension, and other settings for an existing segment that&#39;s associated with an application."},{"ref":"AWS.Pinpoint.html#create_sms_template/4","title":"AWS.Pinpoint.create_sms_template/4","type":"function","doc":"Creates a message template for messages that are sent through the SMS channel."},{"ref":"AWS.Pinpoint.html#create_voice_template/4","title":"AWS.Pinpoint.create_voice_template/4","type":"function","doc":"Creates a message template for messages that are sent through the voice channel."},{"ref":"AWS.Pinpoint.html#delete_adm_channel/4","title":"AWS.Pinpoint.delete_adm_channel/4","type":"function","doc":"Disables the ADM channel for an application and deletes any existing settings for the channel."},{"ref":"AWS.Pinpoint.html#delete_apns_channel/4","title":"AWS.Pinpoint.delete_apns_channel/4","type":"function","doc":"Disables the APNs channel for an application and deletes any existing settings for the channel."},{"ref":"AWS.Pinpoint.html#delete_apns_sandbox_channel/4","title":"AWS.Pinpoint.delete_apns_sandbox_channel/4","type":"function","doc":"Disables the APNs sandbox channel for an application and deletes any existing settings for the channel."},{"ref":"AWS.Pinpoint.html#delete_apns_voip_channel/4","title":"AWS.Pinpoint.delete_apns_voip_channel/4","type":"function","doc":"Disables the APNs VoIP channel for an application and deletes any existing settings for the channel."},{"ref":"AWS.Pinpoint.html#delete_apns_voip_sandbox_channel/4","title":"AWS.Pinpoint.delete_apns_voip_sandbox_channel/4","type":"function","doc":"Disables the APNs VoIP sandbox channel for an application and deletes any existing settings for the channel."},{"ref":"AWS.Pinpoint.html#delete_app/4","title":"AWS.Pinpoint.delete_app/4","type":"function","doc":"Deletes an application."},{"ref":"AWS.Pinpoint.html#delete_baidu_channel/4","title":"AWS.Pinpoint.delete_baidu_channel/4","type":"function","doc":"Disables the Baidu channel for an application and deletes any existing settings for the channel."},{"ref":"AWS.Pinpoint.html#delete_campaign/5","title":"AWS.Pinpoint.delete_campaign/5","type":"function","doc":"Deletes a campaign from an application."},{"ref":"AWS.Pinpoint.html#delete_email_channel/4","title":"AWS.Pinpoint.delete_email_channel/4","type":"function","doc":"Disables the email channel for an application and deletes any existing settings for the channel."},{"ref":"AWS.Pinpoint.html#delete_email_template/4","title":"AWS.Pinpoint.delete_email_template/4","type":"function","doc":"Deletes a message template for messages that were sent through the email channel."},{"ref":"AWS.Pinpoint.html#delete_endpoint/5","title":"AWS.Pinpoint.delete_endpoint/5","type":"function","doc":"Deletes an endpoint from an application."},{"ref":"AWS.Pinpoint.html#delete_event_stream/4","title":"AWS.Pinpoint.delete_event_stream/4","type":"function","doc":"Deletes the event stream for an application."},{"ref":"AWS.Pinpoint.html#delete_gcm_channel/4","title":"AWS.Pinpoint.delete_gcm_channel/4","type":"function","doc":"Disables the GCM channel for an application and deletes any existing settings for the channel."},{"ref":"AWS.Pinpoint.html#delete_journey/5","title":"AWS.Pinpoint.delete_journey/5","type":"function","doc":"Deletes a journey from an application."},{"ref":"AWS.Pinpoint.html#delete_push_template/4","title":"AWS.Pinpoint.delete_push_template/4","type":"function","doc":"Deletes a message template for messages that were sent through a push notification channel."},{"ref":"AWS.Pinpoint.html#delete_recommender_configuration/4","title":"AWS.Pinpoint.delete_recommender_configuration/4","type":"function","doc":"Deletes an Amazon Pinpoint configuration for a recommender model."},{"ref":"AWS.Pinpoint.html#delete_segment/5","title":"AWS.Pinpoint.delete_segment/5","type":"function","doc":"Deletes a segment from an application."},{"ref":"AWS.Pinpoint.html#delete_sms_channel/4","title":"AWS.Pinpoint.delete_sms_channel/4","type":"function","doc":"Disables the SMS channel for an application and deletes any existing settings for the channel."},{"ref":"AWS.Pinpoint.html#delete_sms_template/4","title":"AWS.Pinpoint.delete_sms_template/4","type":"function","doc":"Deletes a message template for messages that were sent through the SMS channel."},{"ref":"AWS.Pinpoint.html#delete_user_endpoints/5","title":"AWS.Pinpoint.delete_user_endpoints/5","type":"function","doc":"Deletes all the endpoints that are associated with a specific user ID."},{"ref":"AWS.Pinpoint.html#delete_voice_channel/4","title":"AWS.Pinpoint.delete_voice_channel/4","type":"function","doc":"Disables the voice channel for an application and deletes any existing settings for the channel."},{"ref":"AWS.Pinpoint.html#delete_voice_template/4","title":"AWS.Pinpoint.delete_voice_template/4","type":"function","doc":"Deletes a message template for messages that were sent through the voice channel."},{"ref":"AWS.Pinpoint.html#get_adm_channel/3","title":"AWS.Pinpoint.get_adm_channel/3","type":"function","doc":"Retrieves information about the status and settings of the ADM channel for an application."},{"ref":"AWS.Pinpoint.html#get_apns_channel/3","title":"AWS.Pinpoint.get_apns_channel/3","type":"function","doc":"Retrieves information about the status and settings of the APNs channel for an application."},{"ref":"AWS.Pinpoint.html#get_apns_sandbox_channel/3","title":"AWS.Pinpoint.get_apns_sandbox_channel/3","type":"function","doc":"Retrieves information about the status and settings of the APNs sandbox channel for an application."},{"ref":"AWS.Pinpoint.html#get_apns_voip_channel/3","title":"AWS.Pinpoint.get_apns_voip_channel/3","type":"function","doc":"Retrieves information about the status and settings of the APNs VoIP channel for an application."},{"ref":"AWS.Pinpoint.html#get_apns_voip_sandbox_channel/3","title":"AWS.Pinpoint.get_apns_voip_sandbox_channel/3","type":"function","doc":"Retrieves information about the status and settings of the APNs VoIP sandbox channel for an application."},{"ref":"AWS.Pinpoint.html#get_app/3","title":"AWS.Pinpoint.get_app/3","type":"function","doc":"Retrieves information about an application."},{"ref":"AWS.Pinpoint.html#get_application_date_range_kpi/8","title":"AWS.Pinpoint.get_application_date_range_kpi/8","type":"function","doc":"Retrieves (queries) pre-aggregated data for a standard metric that applies to an application."},{"ref":"AWS.Pinpoint.html#get_application_settings/3","title":"AWS.Pinpoint.get_application_settings/3","type":"function","doc":"Retrieves information about the settings for an application."},{"ref":"AWS.Pinpoint.html#get_apps/4","title":"AWS.Pinpoint.get_apps/4","type":"function","doc":"Retrieves information about all the applications that are associated with your Amazon Pinpoint account."},{"ref":"AWS.Pinpoint.html#get_baidu_channel/3","title":"AWS.Pinpoint.get_baidu_channel/3","type":"function","doc":"Retrieves information about the status and settings of the Baidu channel for an application."},{"ref":"AWS.Pinpoint.html#get_campaign/4","title":"AWS.Pinpoint.get_campaign/4","type":"function","doc":"Retrieves information about the status, configuration, and other settings for a campaign."},{"ref":"AWS.Pinpoint.html#get_campaign_activities/6","title":"AWS.Pinpoint.get_campaign_activities/6","type":"function","doc":"Retrieves information about all the activities for a campaign."},{"ref":"AWS.Pinpoint.html#get_campaign_date_range_kpi/9","title":"AWS.Pinpoint.get_campaign_date_range_kpi/9","type":"function","doc":"Retrieves (queries) pre-aggregated data for a standard metric that applies to a campaign."},{"ref":"AWS.Pinpoint.html#get_campaign_version/5","title":"AWS.Pinpoint.get_campaign_version/5","type":"function","doc":"Retrieves information about the status, configuration, and other settings for a specific version of a campaign."},{"ref":"AWS.Pinpoint.html#get_campaign_versions/6","title":"AWS.Pinpoint.get_campaign_versions/6","type":"function","doc":"Retrieves information about the status, configuration, and other settings for all versions of a campaign."},{"ref":"AWS.Pinpoint.html#get_campaigns/5","title":"AWS.Pinpoint.get_campaigns/5","type":"function","doc":"Retrieves information about the status, configuration, and other settings for all the campaigns that are associated with an application."},{"ref":"AWS.Pinpoint.html#get_channels/3","title":"AWS.Pinpoint.get_channels/3","type":"function","doc":"Retrieves information about the history and status of each channel for an application."},{"ref":"AWS.Pinpoint.html#get_email_channel/3","title":"AWS.Pinpoint.get_email_channel/3","type":"function","doc":"Retrieves information about the status and settings of the email channel for an application."},{"ref":"AWS.Pinpoint.html#get_email_template/4","title":"AWS.Pinpoint.get_email_template/4","type":"function","doc":"Retrieves the content and settings of a message template for messages that are sent through the email channel."},{"ref":"AWS.Pinpoint.html#get_endpoint/4","title":"AWS.Pinpoint.get_endpoint/4","type":"function","doc":"Retrieves information about the settings and attributes of a specific endpoint for an application."},{"ref":"AWS.Pinpoint.html#get_event_stream/3","title":"AWS.Pinpoint.get_event_stream/3","type":"function","doc":"Retrieves information about the event stream settings for an application."},{"ref":"AWS.Pinpoint.html#get_export_job/4","title":"AWS.Pinpoint.get_export_job/4","type":"function","doc":"Retrieves information about the status and settings of a specific export job for an application."},{"ref":"AWS.Pinpoint.html#get_export_jobs/5","title":"AWS.Pinpoint.get_export_jobs/5","type":"function","doc":"Retrieves information about the status and settings of all the export jobs for an application."},{"ref":"AWS.Pinpoint.html#get_gcm_channel/3","title":"AWS.Pinpoint.get_gcm_channel/3","type":"function","doc":"Retrieves information about the status and settings of the GCM channel for an application."},{"ref":"AWS.Pinpoint.html#get_import_job/4","title":"AWS.Pinpoint.get_import_job/4","type":"function","doc":"Retrieves information about the status and settings of a specific import job for an application."},{"ref":"AWS.Pinpoint.html#get_import_jobs/5","title":"AWS.Pinpoint.get_import_jobs/5","type":"function","doc":"Retrieves information about the status and settings of all the import jobs for an application."},{"ref":"AWS.Pinpoint.html#get_journey/4","title":"AWS.Pinpoint.get_journey/4","type":"function","doc":"Retrieves information about the status, configuration, and other settings for a journey."},{"ref":"AWS.Pinpoint.html#get_journey_date_range_kpi/9","title":"AWS.Pinpoint.get_journey_date_range_kpi/9","type":"function","doc":"Retrieves (queries) pre-aggregated data for a standard engagement metric that applies to a journey."},{"ref":"AWS.Pinpoint.html#get_journey_execution_activity_metrics/7","title":"AWS.Pinpoint.get_journey_execution_activity_metrics/7","type":"function","doc":"Retrieves (queries) pre-aggregated data for a standard execution metric that applies to a journey activity."},{"ref":"AWS.Pinpoint.html#get_journey_execution_metrics/6","title":"AWS.Pinpoint.get_journey_execution_metrics/6","type":"function","doc":"Retrieves (queries) pre-aggregated data for a standard execution metric that applies to a journey."},{"ref":"AWS.Pinpoint.html#get_push_template/4","title":"AWS.Pinpoint.get_push_template/4","type":"function","doc":"Retrieves the content and settings of a message template for messages that are sent through a push notification channel."},{"ref":"AWS.Pinpoint.html#get_recommender_configuration/3","title":"AWS.Pinpoint.get_recommender_configuration/3","type":"function","doc":"Retrieves information about an Amazon Pinpoint configuration for a recommender model."},{"ref":"AWS.Pinpoint.html#get_recommender_configurations/4","title":"AWS.Pinpoint.get_recommender_configurations/4","type":"function","doc":"Retrieves information about all the recommender model configurations that are associated with your Amazon Pinpoint account."},{"ref":"AWS.Pinpoint.html#get_segment/4","title":"AWS.Pinpoint.get_segment/4","type":"function","doc":"Retrieves information about the configuration, dimension, and other settings for a specific segment that&#39;s associated with an application."},{"ref":"AWS.Pinpoint.html#get_segment_export_jobs/6","title":"AWS.Pinpoint.get_segment_export_jobs/6","type":"function","doc":"Retrieves information about the status and settings of the export jobs for a segment."},{"ref":"AWS.Pinpoint.html#get_segment_import_jobs/6","title":"AWS.Pinpoint.get_segment_import_jobs/6","type":"function","doc":"Retrieves information about the status and settings of the import jobs for a segment."},{"ref":"AWS.Pinpoint.html#get_segment_version/5","title":"AWS.Pinpoint.get_segment_version/5","type":"function","doc":"Retrieves information about the configuration, dimension, and other settings for a specific version of a segment that&#39;s associated with an application."},{"ref":"AWS.Pinpoint.html#get_segment_versions/6","title":"AWS.Pinpoint.get_segment_versions/6","type":"function","doc":"Retrieves information about the configuration, dimension, and other settings for all the versions of a specific segment that&#39;s associated with an application."},{"ref":"AWS.Pinpoint.html#get_segments/5","title":"AWS.Pinpoint.get_segments/5","type":"function","doc":"Retrieves information about the configuration, dimension, and other settings for all the segments that are associated with an application."},{"ref":"AWS.Pinpoint.html#get_sms_channel/3","title":"AWS.Pinpoint.get_sms_channel/3","type":"function","doc":"Retrieves information about the status and settings of the SMS channel for an application."},{"ref":"AWS.Pinpoint.html#get_sms_template/4","title":"AWS.Pinpoint.get_sms_template/4","type":"function","doc":"Retrieves the content and settings of a message template for messages that are sent through the SMS channel."},{"ref":"AWS.Pinpoint.html#get_user_endpoints/4","title":"AWS.Pinpoint.get_user_endpoints/4","type":"function","doc":"Retrieves information about all the endpoints that are associated with a specific user ID."},{"ref":"AWS.Pinpoint.html#get_voice_channel/3","title":"AWS.Pinpoint.get_voice_channel/3","type":"function","doc":"Retrieves information about the status and settings of the voice channel for an application."},{"ref":"AWS.Pinpoint.html#get_voice_template/4","title":"AWS.Pinpoint.get_voice_template/4","type":"function","doc":"Retrieves the content and settings of a message template for messages that are sent through the voice channel."},{"ref":"AWS.Pinpoint.html#list_journeys/5","title":"AWS.Pinpoint.list_journeys/5","type":"function","doc":"Retrieves information about the status, configuration, and other settings for all the journeys that are associated with an application."},{"ref":"AWS.Pinpoint.html#list_tags_for_resource/3","title":"AWS.Pinpoint.list_tags_for_resource/3","type":"function","doc":"Retrieves all the tags (keys and values) that are associated with an application, campaign, message template, or segment."},{"ref":"AWS.Pinpoint.html#list_template_versions/6","title":"AWS.Pinpoint.list_template_versions/6","type":"function","doc":"Retrieves information about all the versions of a specific message template."},{"ref":"AWS.Pinpoint.html#list_templates/6","title":"AWS.Pinpoint.list_templates/6","type":"function","doc":"Retrieves information about all the message templates that are associated with your Amazon Pinpoint account."},{"ref":"AWS.Pinpoint.html#phone_number_validate/3","title":"AWS.Pinpoint.phone_number_validate/3","type":"function","doc":"Retrieves information about a phone number."},{"ref":"AWS.Pinpoint.html#put_event_stream/4","title":"AWS.Pinpoint.put_event_stream/4","type":"function","doc":"Creates a new event stream for an application or updates the settings of an existing event stream for an application."},{"ref":"AWS.Pinpoint.html#put_events/4","title":"AWS.Pinpoint.put_events/4","type":"function","doc":"Creates a new event to record for endpoints, or creates or updates endpoint data that existing events are associated with."},{"ref":"AWS.Pinpoint.html#remove_attributes/5","title":"AWS.Pinpoint.remove_attributes/5","type":"function","doc":"Removes one or more attributes, of the same attribute type, from all the endpoints that are associated with an application."},{"ref":"AWS.Pinpoint.html#send_messages/4","title":"AWS.Pinpoint.send_messages/4","type":"function","doc":"Creates and sends a direct message."},{"ref":"AWS.Pinpoint.html#send_users_messages/4","title":"AWS.Pinpoint.send_users_messages/4","type":"function","doc":"Creates and sends a message to a list of users."},{"ref":"AWS.Pinpoint.html#tag_resource/4","title":"AWS.Pinpoint.tag_resource/4","type":"function","doc":"Adds one or more tags (keys and values) to an application, campaign, message template, or segment."},{"ref":"AWS.Pinpoint.html#untag_resource/4","title":"AWS.Pinpoint.untag_resource/4","type":"function","doc":"Removes one or more tags (keys and values) from an application, campaign, message template, or segment."},{"ref":"AWS.Pinpoint.html#update_adm_channel/4","title":"AWS.Pinpoint.update_adm_channel/4","type":"function","doc":"Enables the ADM channel for an application or updates the status and settings of the ADM channel for an application."},{"ref":"AWS.Pinpoint.html#update_apns_channel/4","title":"AWS.Pinpoint.update_apns_channel/4","type":"function","doc":"Enables the APNs channel for an application or updates the status and settings of the APNs channel for an application."},{"ref":"AWS.Pinpoint.html#update_apns_sandbox_channel/4","title":"AWS.Pinpoint.update_apns_sandbox_channel/4","type":"function","doc":"Enables the APNs sandbox channel for an application or updates the status and settings of the APNs sandbox channel for an application."},{"ref":"AWS.Pinpoint.html#update_apns_voip_channel/4","title":"AWS.Pinpoint.update_apns_voip_channel/4","type":"function","doc":"Enables the APNs VoIP channel for an application or updates the status and settings of the APNs VoIP channel for an application."},{"ref":"AWS.Pinpoint.html#update_apns_voip_sandbox_channel/4","title":"AWS.Pinpoint.update_apns_voip_sandbox_channel/4","type":"function","doc":"Enables the APNs VoIP sandbox channel for an application or updates the status and settings of the APNs VoIP sandbox channel for an application."},{"ref":"AWS.Pinpoint.html#update_application_settings/4","title":"AWS.Pinpoint.update_application_settings/4","type":"function","doc":"Updates the settings for an application."},{"ref":"AWS.Pinpoint.html#update_baidu_channel/4","title":"AWS.Pinpoint.update_baidu_channel/4","type":"function","doc":"Enables the Baidu channel for an application or updates the status and settings of the Baidu channel for an application."},{"ref":"AWS.Pinpoint.html#update_campaign/5","title":"AWS.Pinpoint.update_campaign/5","type":"function","doc":"Updates the configuration and other settings for a campaign."},{"ref":"AWS.Pinpoint.html#update_email_channel/4","title":"AWS.Pinpoint.update_email_channel/4","type":"function","doc":"Enables the email channel for an application or updates the status and settings of the email channel for an application."},{"ref":"AWS.Pinpoint.html#update_email_template/4","title":"AWS.Pinpoint.update_email_template/4","type":"function","doc":"Updates an existing message template for messages that are sent through the email channel."},{"ref":"AWS.Pinpoint.html#update_endpoint/5","title":"AWS.Pinpoint.update_endpoint/5","type":"function","doc":"Creates a new endpoint for an application or updates the settings and attributes of an existing endpoint for an application. You can also use this operation to define custom attributes for an endpoint. If an update includes one or more values for a custom attribute, Amazon Pinpoint replaces (overwrites) any existing values with the new values."},{"ref":"AWS.Pinpoint.html#update_endpoints_batch/4","title":"AWS.Pinpoint.update_endpoints_batch/4","type":"function","doc":"Creates a new batch of endpoints for an application or updates the settings and attributes of a batch of existing endpoints for an application. You can also use this operation to define custom attributes for a batch of endpoints. If an update includes one or more values for a custom attribute, Amazon Pinpoint replaces (overwrites) any existing values with the new values."},{"ref":"AWS.Pinpoint.html#update_gcm_channel/4","title":"AWS.Pinpoint.update_gcm_channel/4","type":"function","doc":"Enables the GCM channel for an application or updates the status and settings of the GCM channel for an application."},{"ref":"AWS.Pinpoint.html#update_journey/5","title":"AWS.Pinpoint.update_journey/5","type":"function","doc":"Updates the configuration and other settings for a journey."},{"ref":"AWS.Pinpoint.html#update_journey_state/5","title":"AWS.Pinpoint.update_journey_state/5","type":"function","doc":"Cancels (stops) an active journey."},{"ref":"AWS.Pinpoint.html#update_push_template/4","title":"AWS.Pinpoint.update_push_template/4","type":"function","doc":"Updates an existing message template for messages that are sent through a push notification channel."},{"ref":"AWS.Pinpoint.html#update_recommender_configuration/4","title":"AWS.Pinpoint.update_recommender_configuration/4","type":"function","doc":"Updates an Amazon Pinpoint configuration for a recommender model."},{"ref":"AWS.Pinpoint.html#update_segment/5","title":"AWS.Pinpoint.update_segment/5","type":"function","doc":"Creates a new segment for an application or updates the configuration, dimension, and other settings for an existing segment that&#39;s associated with an application."},{"ref":"AWS.Pinpoint.html#update_sms_channel/4","title":"AWS.Pinpoint.update_sms_channel/4","type":"function","doc":"Enables the SMS channel for an application or updates the status and settings of the SMS channel for an application."},{"ref":"AWS.Pinpoint.html#update_sms_template/4","title":"AWS.Pinpoint.update_sms_template/4","type":"function","doc":"Updates an existing message template for messages that are sent through the SMS channel."},{"ref":"AWS.Pinpoint.html#update_template_active_version/5","title":"AWS.Pinpoint.update_template_active_version/5","type":"function","doc":"Changes the status of a specific version of a message template to active."},{"ref":"AWS.Pinpoint.html#update_voice_channel/4","title":"AWS.Pinpoint.update_voice_channel/4","type":"function","doc":"Enables the voice channel for an application or updates the status and settings of the voice channel for an application."},{"ref":"AWS.Pinpoint.html#update_voice_template/4","title":"AWS.Pinpoint.update_voice_template/4","type":"function","doc":"Updates an existing message template for messages that are sent through the voice channel."},{"ref":"AWS.PinpointEmail.html","title":"AWS.PinpointEmail","type":"module","doc":"Amazon Pinpoint Email Service Welcome to the Amazon Pinpoint Email API Reference. This guide provides information about the Amazon Pinpoint Email API (version 1.0), including supported operations, data types, parameters, and schemas. Amazon Pinpoint is an AWS service that you can use to engage with your customers across multiple messaging channels. You can use Amazon Pinpoint to send email, SMS text messages, voice messages, and push notifications. The Amazon Pinpoint Email API provides programmatic access to options that are unique to the email channel and supplement the options provided by the Amazon Pinpoint API. If you&#39;re new to Amazon Pinpoint, you might find it helpful to also review the Amazon Pinpoint Developer Guide. The Amazon Pinpoint Developer Guide provides tutorials, code samples, and procedures that demonstrate how to use Amazon Pinpoint features programmatically and how to integrate Amazon Pinpoint functionality into mobile apps and other types of applications. The guide also provides information about key topics such as Amazon Pinpoint integration with other AWS services and the limits that apply to using the service. The Amazon Pinpoint Email API is available in several AWS Regions and it provides an endpoint for each of these Regions. For a list of all the Regions and endpoints where the API is currently available, see AWS Service Endpoints in the Amazon Web Services General Reference. To learn more about AWS Regions, see Managing AWS Regions in the Amazon Web Services General Reference. In each Region, AWS maintains multiple Availability Zones. These Availability Zones are physically isolated from each other, but are united by private, low-latency, high-throughput, and highly redundant network connections. These Availability Zones enable us to provide very high levels of availability and redundancy, while also minimizing latency. To learn more about the number of Availability Zones that are available in each Region, see AWS Global Infrastructure."},{"ref":"AWS.PinpointEmail.html#create_configuration_set/3","title":"AWS.PinpointEmail.create_configuration_set/3","type":"function","doc":"Create a configuration set. Configuration sets are groups of rules that you can apply to the emails you send using Amazon Pinpoint. You apply a configuration set to an email by including a reference to the configuration set in the headers of the email. When you apply a configuration set to an email, all of the rules in that configuration set are applied to the email."},{"ref":"AWS.PinpointEmail.html#create_configuration_set_event_destination/4","title":"AWS.PinpointEmail.create_configuration_set_event_destination/4","type":"function","doc":"Create an event destination. In Amazon Pinpoint, events include message sends, deliveries, opens, clicks, bounces, and complaints. Event destinations are places that you can send information about these events to. For example, you can send event data to Amazon SNS to receive notifications when you receive bounces or complaints, or you can use Amazon Kinesis Data Firehose to stream data to Amazon S3 for long-term storage. A single configuration set can include more than one event destination."},{"ref":"AWS.PinpointEmail.html#create_dedicated_ip_pool/3","title":"AWS.PinpointEmail.create_dedicated_ip_pool/3","type":"function","doc":"Create a new pool of dedicated IP addresses. A pool can include one or more dedicated IP addresses that are associated with your Amazon Pinpoint account. You can associate a pool with a configuration set. When you send an email that uses that configuration set, Amazon Pinpoint sends it using only the IP addresses in the associated pool."},{"ref":"AWS.PinpointEmail.html#create_deliverability_test_report/3","title":"AWS.PinpointEmail.create_deliverability_test_report/3","type":"function","doc":"Create a new predictive inbox placement test. Predictive inbox placement tests can help you predict how your messages will be handled by various email providers around the world. When you perform a predictive inbox placement test, you provide a sample message that contains the content that you plan to send to your customers. Amazon Pinpoint then sends that message to special email addresses spread across several major email providers. After about 24 hours, the test is complete, and you can use the GetDeliverabilityTestReport operation to view the results of the test."},{"ref":"AWS.PinpointEmail.html#create_email_identity/3","title":"AWS.PinpointEmail.create_email_identity/3","type":"function","doc":"Verifies an email identity for use with Amazon Pinpoint. In Amazon Pinpoint, an identity is an email address or domain that you use when you send email. Before you can use an identity to send email with Amazon Pinpoint, you first have to verify it. By verifying an address, you demonstrate that you&#39;re the owner of the address, and that you&#39;ve given Amazon Pinpoint permission to send email from the address. When you verify an email address, Amazon Pinpoint sends an email to the address. Your email address is verified as soon as you follow the link in the verification email. When you verify a domain, this operation provides a set of DKIM tokens, which you can convert into CNAME tokens. You add these CNAME tokens to the DNS configuration for your domain. Your domain is verified when Amazon Pinpoint detects these records in the DNS configuration for your domain. It usually takes around 72 hours to complete the domain verification process."},{"ref":"AWS.PinpointEmail.html#delete_configuration_set/4","title":"AWS.PinpointEmail.delete_configuration_set/4","type":"function","doc":"Delete an existing configuration set. In Amazon Pinpoint, configuration sets are groups of rules that you can apply to the emails you send. You apply a configuration set to an email by including a reference to the configuration set in the headers of the email. When you apply a configuration set to an email, all of the rules in that configuration set are applied to the email."},{"ref":"AWS.PinpointEmail.html#delete_configuration_set_event_destination/5","title":"AWS.PinpointEmail.delete_configuration_set_event_destination/5","type":"function","doc":"Delete an event destination. In Amazon Pinpoint, events include message sends, deliveries, opens, clicks, bounces, and complaints. Event destinations are places that you can send information about these events to. For example, you can send event data to Amazon SNS to receive notifications when you receive bounces or complaints, or you can use Amazon Kinesis Data Firehose to stream data to Amazon S3 for long-term storage."},{"ref":"AWS.PinpointEmail.html#delete_dedicated_ip_pool/4","title":"AWS.PinpointEmail.delete_dedicated_ip_pool/4","type":"function","doc":"Delete a dedicated IP pool."},{"ref":"AWS.PinpointEmail.html#delete_email_identity/4","title":"AWS.PinpointEmail.delete_email_identity/4","type":"function","doc":"Deletes an email identity that you previously verified for use with Amazon Pinpoint. An identity can be either an email address or a domain name."},{"ref":"AWS.PinpointEmail.html#get_account/2","title":"AWS.PinpointEmail.get_account/2","type":"function","doc":"Obtain information about the email-sending status and capabilities of your Amazon Pinpoint account in the current AWS Region."},{"ref":"AWS.PinpointEmail.html#get_blacklist_reports/3","title":"AWS.PinpointEmail.get_blacklist_reports/3","type":"function","doc":"Retrieve a list of the blacklists that your dedicated IP addresses appear on."},{"ref":"AWS.PinpointEmail.html#get_configuration_set/3","title":"AWS.PinpointEmail.get_configuration_set/3","type":"function","doc":"Get information about an existing configuration set, including the dedicated IP pool that it&#39;s associated with, whether or not it&#39;s enabled for sending email, and more. In Amazon Pinpoint, configuration sets are groups of rules that you can apply to the emails you send. You apply a configuration set to an email by including a reference to the configuration set in the headers of the email. When you apply a configuration set to an email, all of the rules in that configuration set are applied to the email."},{"ref":"AWS.PinpointEmail.html#get_configuration_set_event_destinations/3","title":"AWS.PinpointEmail.get_configuration_set_event_destinations/3","type":"function","doc":"Retrieve a list of event destinations that are associated with a configuration set. In Amazon Pinpoint, events include message sends, deliveries, opens, clicks, bounces, and complaints. Event destinations are places that you can send information about these events to. For example, you can send event data to Amazon SNS to receive notifications when you receive bounces or complaints, or you can use Amazon Kinesis Data Firehose to stream data to Amazon S3 for long-term storage."},{"ref":"AWS.PinpointEmail.html#get_dedicated_ip/3","title":"AWS.PinpointEmail.get_dedicated_ip/3","type":"function","doc":"Get information about a dedicated IP address, including the name of the dedicated IP pool that it&#39;s associated with, as well information about the automatic warm-up process for the address."},{"ref":"AWS.PinpointEmail.html#get_dedicated_ips/5","title":"AWS.PinpointEmail.get_dedicated_ips/5","type":"function","doc":"List the dedicated IP addresses that are associated with your Amazon Pinpoint account."},{"ref":"AWS.PinpointEmail.html#get_deliverability_dashboard_options/2","title":"AWS.PinpointEmail.get_deliverability_dashboard_options/2","type":"function","doc":"Retrieve information about the status of the Deliverability dashboard for your Amazon Pinpoint account. When the Deliverability dashboard is enabled, you gain access to reputation, deliverability, and other metrics for the domains that you use to send email using Amazon Pinpoint. You also gain the ability to perform predictive inbox placement tests. When you use the Deliverability dashboard, you pay a monthly subscription charge, in addition to any other fees that you accrue by using Amazon Pinpoint. For more information about the features and cost of a Deliverability dashboard subscription, see Amazon Pinpoint Pricing."},{"ref":"AWS.PinpointEmail.html#get_deliverability_test_report/3","title":"AWS.PinpointEmail.get_deliverability_test_report/3","type":"function","doc":"Retrieve the results of a predictive inbox placement test."},{"ref":"AWS.PinpointEmail.html#get_domain_deliverability_campaign/3","title":"AWS.PinpointEmail.get_domain_deliverability_campaign/3","type":"function","doc":"Retrieve all the deliverability data for a specific campaign. This data is available for a campaign only if the campaign sent email by using a domain that the Deliverability dashboard is enabled for (PutDeliverabilityDashboardOption operation)."},{"ref":"AWS.PinpointEmail.html#get_domain_statistics_report/5","title":"AWS.PinpointEmail.get_domain_statistics_report/5","type":"function","doc":"Retrieve inbox placement and engagement rates for the domains that you use to send email."},{"ref":"AWS.PinpointEmail.html#get_email_identity/3","title":"AWS.PinpointEmail.get_email_identity/3","type":"function","doc":"Provides information about a specific identity associated with your Amazon Pinpoint account, including the identity&#39;s verification status, its DKIM authentication status, and its custom Mail-From settings."},{"ref":"AWS.PinpointEmail.html#list_configuration_sets/4","title":"AWS.PinpointEmail.list_configuration_sets/4","type":"function","doc":"List all of the configuration sets associated with your Amazon Pinpoint account in the current region. In Amazon Pinpoint, configuration sets are groups of rules that you can apply to the emails you send. You apply a configuration set to an email by including a reference to the configuration set in the headers of the email. When you apply a configuration set to an email, all of the rules in that configuration set are applied to the email."},{"ref":"AWS.PinpointEmail.html#list_dedicated_ip_pools/4","title":"AWS.PinpointEmail.list_dedicated_ip_pools/4","type":"function","doc":"List all of the dedicated IP pools that exist in your Amazon Pinpoint account in the current AWS Region."},{"ref":"AWS.PinpointEmail.html#list_deliverability_test_reports/4","title":"AWS.PinpointEmail.list_deliverability_test_reports/4","type":"function","doc":"Show a list of the predictive inbox placement tests that you&#39;ve performed, regardless of their statuses. For predictive inbox placement tests that are complete, you can use the GetDeliverabilityTestReport operation to view the results."},{"ref":"AWS.PinpointEmail.html#list_domain_deliverability_campaigns/7","title":"AWS.PinpointEmail.list_domain_deliverability_campaigns/7","type":"function","doc":"Retrieve deliverability data for all the campaigns that used a specific domain to send email during a specified time range. This data is available for a domain only if you enabled the Deliverability dashboard (PutDeliverabilityDashboardOption operation) for the domain."},{"ref":"AWS.PinpointEmail.html#list_email_identities/4","title":"AWS.PinpointEmail.list_email_identities/4","type":"function","doc":"Returns a list of all of the email identities that are associated with your Amazon Pinpoint account. An identity can be either an email address or a domain. This operation returns identities that are verified as well as those that aren&#39;t."},{"ref":"AWS.PinpointEmail.html#list_tags_for_resource/3","title":"AWS.PinpointEmail.list_tags_for_resource/3","type":"function","doc":"Retrieve a list of the tags (keys and values) that are associated with a specified resource. Atagis a label that you optionally define and associate with a resource in Amazon Pinpoint. Each tag consists of a requiredtag keyand an optional associatedtag value. A tag key is a general label that acts as a category for more specific tag values. A tag value acts as a descriptor within a tag key."},{"ref":"AWS.PinpointEmail.html#put_account_dedicated_ip_warmup_attributes/3","title":"AWS.PinpointEmail.put_account_dedicated_ip_warmup_attributes/3","type":"function","doc":"Enable or disable the automatic warm-up feature for dedicated IP addresses."},{"ref":"AWS.PinpointEmail.html#put_account_sending_attributes/3","title":"AWS.PinpointEmail.put_account_sending_attributes/3","type":"function","doc":"Enable or disable the ability of your account to send email."},{"ref":"AWS.PinpointEmail.html#put_configuration_set_delivery_options/4","title":"AWS.PinpointEmail.put_configuration_set_delivery_options/4","type":"function","doc":"Associate a configuration set with a dedicated IP pool. You can use dedicated IP pools to create groups of dedicated IP addresses for sending specific types of email."},{"ref":"AWS.PinpointEmail.html#put_configuration_set_reputation_options/4","title":"AWS.PinpointEmail.put_configuration_set_reputation_options/4","type":"function","doc":"Enable or disable collection of reputation metrics for emails that you send using a particular configuration set in a specific AWS Region."},{"ref":"AWS.PinpointEmail.html#put_configuration_set_sending_options/4","title":"AWS.PinpointEmail.put_configuration_set_sending_options/4","type":"function","doc":"Enable or disable email sending for messages that use a particular configuration set in a specific AWS Region."},{"ref":"AWS.PinpointEmail.html#put_configuration_set_tracking_options/4","title":"AWS.PinpointEmail.put_configuration_set_tracking_options/4","type":"function","doc":"Specify a custom domain to use for open and click tracking elements in email that you send using Amazon Pinpoint."},{"ref":"AWS.PinpointEmail.html#put_dedicated_ip_in_pool/4","title":"AWS.PinpointEmail.put_dedicated_ip_in_pool/4","type":"function","doc":"Move a dedicated IP address to an existing dedicated IP pool. The dedicated IP address that you specify must already exist, and must be associated with your Amazon Pinpoint account. The dedicated IP pool you specify must already exist. You can create a new pool by using the CreateDedicatedIpPool operation."},{"ref":"AWS.PinpointEmail.html#put_dedicated_ip_warmup_attributes/4","title":"AWS.PinpointEmail.put_dedicated_ip_warmup_attributes/4","type":"function","doc":""},{"ref":"AWS.PinpointEmail.html#put_deliverability_dashboard_option/3","title":"AWS.PinpointEmail.put_deliverability_dashboard_option/3","type":"function","doc":"Enable or disable the Deliverability dashboard for your Amazon Pinpoint account. When you enable the Deliverability dashboard, you gain access to reputation, deliverability, and other metrics for the domains that you use to send email using Amazon Pinpoint. You also gain the ability to perform predictive inbox placement tests. When you use the Deliverability dashboard, you pay a monthly subscription charge, in addition to any other fees that you accrue by using Amazon Pinpoint. For more information about the features and cost of a Deliverability dashboard subscription, see Amazon Pinpoint Pricing."},{"ref":"AWS.PinpointEmail.html#put_email_identity_dkim_attributes/4","title":"AWS.PinpointEmail.put_email_identity_dkim_attributes/4","type":"function","doc":"Used to enable or disable DKIM authentication for an email identity."},{"ref":"AWS.PinpointEmail.html#put_email_identity_feedback_attributes/4","title":"AWS.PinpointEmail.put_email_identity_feedback_attributes/4","type":"function","doc":"Used to enable or disable feedback forwarding for an identity. This setting determines what happens when an identity is used to send an email that results in a bounce or complaint event. When you enable feedback forwarding, Amazon Pinpoint sends you email notifications when bounce or complaint events occur. Amazon Pinpoint sends this notification to the address that you specified in the Return-Path header of the original email. When you disable feedback forwarding, Amazon Pinpoint sends notifications through other mechanisms, such as by notifying an Amazon SNS topic. You&#39;re required to have a method of tracking bounces and complaints. If you haven&#39;t set up another mechanism for receiving bounce or complaint notifications, Amazon Pinpoint sends an email notification when these events occur (even if this setting is disabled)."},{"ref":"AWS.PinpointEmail.html#put_email_identity_mail_from_attributes/4","title":"AWS.PinpointEmail.put_email_identity_mail_from_attributes/4","type":"function","doc":"Used to enable or disable the custom Mail-From domain configuration for an email identity."},{"ref":"AWS.PinpointEmail.html#send_email/3","title":"AWS.PinpointEmail.send_email/3","type":"function","doc":"Sends an email message. You can use the Amazon Pinpoint Email API to send two types of messages: Simple  A standard email message. When you create this type of message, you specify the sender, the recipient, and the message body, and Amazon Pinpoint assembles the message for you. Raw  A raw, MIME-formatted email message. When you send this type of email, you have to specify all of the message headers, as well as the message body. You can use this message type to send messages that contain attachments. The message that you specify has to be a valid MIME message."},{"ref":"AWS.PinpointEmail.html#tag_resource/3","title":"AWS.PinpointEmail.tag_resource/3","type":"function","doc":"Add one or more tags (keys and values) to a specified resource. A tagis a label that you optionally define and associate with a resource in Amazon Pinpoint. Tags can help you categorize and manage resources in different ways, such as by purpose, owner, environment, or other criteria. A resource can have as many as 50 tags. Each tag consists of a requiredtag keyand an associatedtag value, both of which you define. A tag key is a general label that acts as a category for more specific tag values. A tag value acts as a descriptor within a tag key."},{"ref":"AWS.PinpointEmail.html#untag_resource/3","title":"AWS.PinpointEmail.untag_resource/3","type":"function","doc":"Remove one or more tags (keys and values) from a specified resource."},{"ref":"AWS.PinpointEmail.html#update_configuration_set_event_destination/5","title":"AWS.PinpointEmail.update_configuration_set_event_destination/5","type":"function","doc":"Update the configuration of an event destination for a configuration set. In Amazon Pinpoint, events include message sends, deliveries, opens, clicks, bounces, and complaints. Event destinations are places that you can send information about these events to. For example, you can send event data to Amazon SNS to receive notifications when you receive bounces or complaints, or you can use Amazon Kinesis Data Firehose to stream data to Amazon S3 for long-term storage."},{"ref":"AWS.PinpointSMSVoice.html","title":"AWS.PinpointSMSVoice","type":"module","doc":"Pinpoint SMS and Voice Messaging public facing APIs"},{"ref":"AWS.PinpointSMSVoice.html#create_configuration_set/3","title":"AWS.PinpointSMSVoice.create_configuration_set/3","type":"function","doc":"Create a new configuration set. After you create the configuration set, you can add one or more event destinations to it."},{"ref":"AWS.PinpointSMSVoice.html#create_configuration_set_event_destination/4","title":"AWS.PinpointSMSVoice.create_configuration_set_event_destination/4","type":"function","doc":"Create a new event destination in a configuration set."},{"ref":"AWS.PinpointSMSVoice.html#delete_configuration_set/4","title":"AWS.PinpointSMSVoice.delete_configuration_set/4","type":"function","doc":"Deletes an existing configuration set."},{"ref":"AWS.PinpointSMSVoice.html#delete_configuration_set_event_destination/5","title":"AWS.PinpointSMSVoice.delete_configuration_set_event_destination/5","type":"function","doc":"Deletes an event destination in a configuration set."},{"ref":"AWS.PinpointSMSVoice.html#get_configuration_set_event_destinations/3","title":"AWS.PinpointSMSVoice.get_configuration_set_event_destinations/3","type":"function","doc":"Obtain information about an event destination, including the types of events it reports, the Amazon Resource Name (ARN) of the destination, and the name of the event destination."},{"ref":"AWS.PinpointSMSVoice.html#list_configuration_sets/4","title":"AWS.PinpointSMSVoice.list_configuration_sets/4","type":"function","doc":"List all of the configuration sets associated with your Amazon Pinpoint account in the current region."},{"ref":"AWS.PinpointSMSVoice.html#send_voice_message/3","title":"AWS.PinpointSMSVoice.send_voice_message/3","type":"function","doc":"Create a new voice message and send it to a recipient&#39;s phone number."},{"ref":"AWS.PinpointSMSVoice.html#update_configuration_set_event_destination/5","title":"AWS.PinpointSMSVoice.update_configuration_set_event_destination/5","type":"function","doc":"Update an event destination in a configuration set. An event destination is a location that you publish information about your voice calls to. For example, you can log an event to an Amazon CloudWatch destination when a call fails."},{"ref":"AWS.Polly.html","title":"AWS.Polly","type":"module","doc":"Amazon Polly is a web service that makes it easy to synthesize speech from text. The Amazon Polly service provides API operations for synthesizing high-quality speech from plain text and Speech Synthesis Markup Language (SSML), along with managing pronunciations lexicons that enable you to get the best results for your application domain."},{"ref":"AWS.Polly.html#delete_lexicon/4","title":"AWS.Polly.delete_lexicon/4","type":"function","doc":"Deletes the specified pronunciation lexicon stored in an AWS Region. A lexicon which has been deleted is not available for speech synthesis, nor is it possible to retrieve it using either the GetLexicon or ListLexicon APIs. For more information, see Managing Lexicons."},{"ref":"AWS.Polly.html#describe_voices/6","title":"AWS.Polly.describe_voices/6","type":"function","doc":"Returns the list of voices that are available for use when requesting speech synthesis. Each voice speaks a specified language, is either male or female, and is identified by an ID, which is the ASCII version of the voice name. When synthesizing speech ( SynthesizeSpeech ), you provide the voice ID for the voice you want from the list of voices returned by DescribeVoices. For example, you want your news reader application to read news in a specific language, but giving a user the option to choose the voice. Using the DescribeVoices operation you can provide the user with a list of available voices to select from. You can optionally specify a language code to filter the available voices. For example, if you specify en-US, the operation returns a list of all available US English voices. This operation requires permissions to perform the polly:DescribeVoices action."},{"ref":"AWS.Polly.html#get_lexicon/3","title":"AWS.Polly.get_lexicon/3","type":"function","doc":"Returns the content of the specified pronunciation lexicon stored in an AWS Region. For more information, see Managing Lexicons."},{"ref":"AWS.Polly.html#get_speech_synthesis_task/3","title":"AWS.Polly.get_speech_synthesis_task/3","type":"function","doc":"Retrieves a specific SpeechSynthesisTask object based on its TaskID. This object contains information about the given speech synthesis task, including the status of the task, and a link to the S3 bucket containing the output of the task."},{"ref":"AWS.Polly.html#list_lexicons/3","title":"AWS.Polly.list_lexicons/3","type":"function","doc":"Returns a list of pronunciation lexicons stored in an AWS Region. For more information, see Managing Lexicons."},{"ref":"AWS.Polly.html#list_speech_synthesis_tasks/5","title":"AWS.Polly.list_speech_synthesis_tasks/5","type":"function","doc":"Returns a list of SpeechSynthesisTask objects ordered by their creation date. This operation can filter the tasks by their status, for example, allowing users to list only tasks that are completed."},{"ref":"AWS.Polly.html#put_lexicon/4","title":"AWS.Polly.put_lexicon/4","type":"function","doc":"Stores a pronunciation lexicon in an AWS Region. If a lexicon with the same name already exists in the region, it is overwritten by the new lexicon. Lexicon operations have eventual consistency, therefore, it might take some time before the lexicon is available to the SynthesizeSpeech operation. For more information, see Managing Lexicons."},{"ref":"AWS.Polly.html#start_speech_synthesis_task/3","title":"AWS.Polly.start_speech_synthesis_task/3","type":"function","doc":"Allows the creation of an asynchronous synthesis task, by starting a new SpeechSynthesisTask. This operation requires all the standard information needed for speech synthesis, plus the name of an Amazon S3 bucket for the service to store the output of the synthesis task and two optional parameters (OutputS3KeyPrefix and SnsTopicArn). Once the synthesis task is created, this operation will return a SpeechSynthesisTask object, which will include an identifier of this task as well as the current status."},{"ref":"AWS.Polly.html#synthesize_speech/3","title":"AWS.Polly.synthesize_speech/3","type":"function","doc":"Synthesizes UTF-8 input, plain text or SSML, to a stream of bytes. SSML input must be valid, well-formed SSML. Some alphabets might not be available with all the voices (for example, Cyrillic might not be read at all by English voices) unless phoneme mapping is used. For more information, see How it Works."},{"ref":"AWS.QLDB.html","title":"AWS.QLDB","type":"module","doc":"The control plane for Amazon QLDB"},{"ref":"AWS.QLDB.html#cancel_journal_kinesis_stream/5","title":"AWS.QLDB.cancel_journal_kinesis_stream/5","type":"function","doc":"Ends a given Amazon QLDB journal stream. Before a stream can be canceled, its current status must be ACTIVE. You can&#39;t restart a stream after you cancel it. Canceled QLDB stream resources are subject to a 7-day retention period, so they are automatically deleted after this limit expires."},{"ref":"AWS.QLDB.html#create_ledger/3","title":"AWS.QLDB.create_ledger/3","type":"function","doc":"Creates a new ledger in your AWS account."},{"ref":"AWS.QLDB.html#delete_ledger/4","title":"AWS.QLDB.delete_ledger/4","type":"function","doc":"Deletes a ledger and all of its contents. This action is irreversible. If deletion protection is enabled, you must first disable it before you can delete the ledger using the QLDB API or the AWS Command Line Interface (AWS CLI). You can disable it by calling the UpdateLedger operation to set the flag to false. The QLDB console disables deletion protection for you when you use it to delete a ledger."},{"ref":"AWS.QLDB.html#describe_journal_kinesis_stream/4","title":"AWS.QLDB.describe_journal_kinesis_stream/4","type":"function","doc":"Returns detailed information about a given Amazon QLDB journal stream. The output includes the Amazon Resource Name (ARN), stream name, current status, creation time, and the parameters of your original stream creation request."},{"ref":"AWS.QLDB.html#describe_journal_s3_export/4","title":"AWS.QLDB.describe_journal_s3_export/4","type":"function","doc":"Returns information about a journal export job, including the ledger name, export ID, when it was created, current status, and its start and end time export parameters. This action does not return any expired export jobs. For more information, see Export Job Expiration in the Amazon QLDB Developer Guide. If the export job with the given ExportId doesn&#39;t exist, then throws ResourceNotFoundException. If the ledger with the given Name doesn&#39;t exist, then throws ResourceNotFoundException."},{"ref":"AWS.QLDB.html#describe_ledger/3","title":"AWS.QLDB.describe_ledger/3","type":"function","doc":"Returns information about a ledger, including its state and when it was created."},{"ref":"AWS.QLDB.html#export_journal_to_s3/4","title":"AWS.QLDB.export_journal_to_s3/4","type":"function","doc":"Exports journal contents within a date and time range from a ledger into a specified Amazon Simple Storage Service (Amazon S3) bucket. The data is written as files in Amazon Ion format. If the ledger with the given Name doesn&#39;t exist, then throws ResourceNotFoundException. If the ledger with the given Name is in CREATING status, then throws ResourcePreconditionNotMetException. You can initiate up to two concurrent journal export requests for each ledger. Beyond this limit, journal export requests throw LimitExceededException."},{"ref":"AWS.QLDB.html#get_block/4","title":"AWS.QLDB.get_block/4","type":"function","doc":"Returns a block object at a specified address in a journal. Also returns a proof of the specified block for verification if DigestTipAddress is provided. For information about the data contents in a block, see Journal contents in the Amazon QLDB Developer Guide. If the specified ledger doesn&#39;t exist or is in DELETING status, then throws ResourceNotFoundException. If the specified ledger is in CREATING status, then throws ResourcePreconditionNotMetException. If no block exists with the specified address, then throws InvalidParameterException."},{"ref":"AWS.QLDB.html#get_digest/4","title":"AWS.QLDB.get_digest/4","type":"function","doc":"Returns the digest of a ledger at the latest committed block in the journal. The response includes a 256-bit hash value and a block address."},{"ref":"AWS.QLDB.html#get_revision/4","title":"AWS.QLDB.get_revision/4","type":"function","doc":"Returns a revision data object for a specified document ID and block address. Also returns a proof of the specified revision for verification if DigestTipAddress is provided."},{"ref":"AWS.QLDB.html#list_journal_kinesis_streams_for_ledger/5","title":"AWS.QLDB.list_journal_kinesis_streams_for_ledger/5","type":"function","doc":"Returns an array of all Amazon QLDB journal stream descriptors for a given ledger. The output of each stream descriptor includes the same details that are returned by DescribeJournalKinesisStream. This action returns a maximum of MaxResults items. It is paginated so that you can retrieve all the items by calling ListJournalKinesisStreamsForLedger multiple times."},{"ref":"AWS.QLDB.html#list_journal_s3_exports/4","title":"AWS.QLDB.list_journal_s3_exports/4","type":"function","doc":"Returns an array of journal export job descriptions for all ledgers that are associated with the current AWS account and Region. This action returns a maximum of MaxResults items, and is paginated so that you can retrieve all the items by calling ListJournalS3Exports multiple times. This action does not return any expired export jobs. For more information, see Export Job Expiration in the Amazon QLDB Developer Guide."},{"ref":"AWS.QLDB.html#list_journal_s3_exports_for_ledger/5","title":"AWS.QLDB.list_journal_s3_exports_for_ledger/5","type":"function","doc":"Returns an array of journal export job descriptions for a specified ledger. This action returns a maximum of MaxResults items, and is paginated so that you can retrieve all the items by calling ListJournalS3ExportsForLedger multiple times. This action does not return any expired export jobs. For more information, see Export Job Expiration in the Amazon QLDB Developer Guide."},{"ref":"AWS.QLDB.html#list_ledgers/4","title":"AWS.QLDB.list_ledgers/4","type":"function","doc":"Returns an array of ledger summaries that are associated with the current AWS account and Region. This action returns a maximum of 100 items and is paginated so that you can retrieve all the items by calling ListLedgers multiple times."},{"ref":"AWS.QLDB.html#list_tags_for_resource/3","title":"AWS.QLDB.list_tags_for_resource/3","type":"function","doc":"Returns all tags for a specified Amazon QLDB resource."},{"ref":"AWS.QLDB.html#stream_journal_to_kinesis/4","title":"AWS.QLDB.stream_journal_to_kinesis/4","type":"function","doc":"Creates a journal stream for a given Amazon QLDB ledger. The stream captures every document revision that is committed to the ledger&#39;s journal and delivers the data to a specified Amazon Kinesis Data Streams resource."},{"ref":"AWS.QLDB.html#tag_resource/4","title":"AWS.QLDB.tag_resource/4","type":"function","doc":"Adds one or more tags to a specified Amazon QLDB resource. A resource can have up to 50 tags. If you try to create more than 50 tags for a resource, your request fails and returns an error."},{"ref":"AWS.QLDB.html#untag_resource/4","title":"AWS.QLDB.untag_resource/4","type":"function","doc":"Removes one or more tags from a specified Amazon QLDB resource. You can specify up to 50 tag keys to remove."},{"ref":"AWS.QLDB.html#update_ledger/4","title":"AWS.QLDB.update_ledger/4","type":"function","doc":"Updates properties on a ledger."},{"ref":"AWS.QLDBSession.html","title":"AWS.QLDBSession","type":"module","doc":"The transactional data APIs for Amazon QLDB Instead of interacting directly with this API, we recommend that you use the Amazon QLDB Driver or the QLDB Shell to execute data transactions on a ledger. If you are working with an AWS SDK, use the QLDB Driver. The driver provides a high-level abstraction layer above this qldbsession data plane and manages SendCommand API calls for you. For information and a list of supported programming languages, see Getting started with the driver in the Amazon QLDB Developer Guide. If you are working with the AWS Command Line Interface (AWS CLI), use the QLDB Shell. The shell is a command line interface that uses the QLDB Driver to interact with a ledger. For information, see Accessing Amazon QLDB using the QLDB Shell."},{"ref":"AWS.QLDBSession.html#send_command/3","title":"AWS.QLDBSession.send_command/3","type":"function","doc":"Sends a command to an Amazon QLDB ledger. Instead of interacting directly with this API, we recommend that you use the Amazon QLDB Driver or the QLDB Shell to execute data transactions on a ledger. If you are working with an AWS SDK, use the QLDB Driver. The driver provides a high-level abstraction layer above this qldbsession data plane and manages SendCommand API calls for you. For information and a list of supported programming languages, see Getting started with the driver in the Amazon QLDB Developer Guide. If you are working with the AWS Command Line Interface (AWS CLI), use the QLDB Shell. The shell is a command line interface that uses the QLDB Driver to interact with a ledger. For information, see Accessing Amazon QLDB using the QLDB Shell."},{"ref":"AWS.QuickSight.html","title":"AWS.QuickSight","type":"module","doc":"Amazon QuickSight API Reference Amazon QuickSight is a fully managed, serverless business intelligence service for the AWS Cloud that makes it easy to extend data and insights to every user in your organization. This API reference contains documentation for a programming interface that you can use to manage Amazon QuickSight."},{"ref":"AWS.QuickSight.html#cancel_ingestion/6","title":"AWS.QuickSight.cancel_ingestion/6","type":"function","doc":"Cancels an ongoing ingestion of data into SPICE."},{"ref":"AWS.QuickSight.html#create_account_customization/4","title":"AWS.QuickSight.create_account_customization/4","type":"function","doc":"Creates Amazon QuickSight customizations the current AWS Region. Currently, you can add a custom default theme by using the CreateAccountCustomization or UpdateAccountCustomization API operation. To further customize QuickSight by removing QuickSight sample assets and videos for all new users, see Customizing QuickSight in the Amazon QuickSight User Guide. You can create customizations for your AWS account or, if you specify a namespace, for a QuickSight namespace instead. Customizations that apply to a namespace always override customizations that apply to an AWS account. To find out which customizations apply, use the DescribeAccountCustomization API operation. Before you use the CreateAccountCustomization API operation to add a theme as the namespace default, make sure that you first share the theme with the namespace. If you don&#39;t share it with the namespace, the theme isn&#39;t visible to your users even if you make it the default theme. To check if the theme is shared, view the current permissions by using the DescribeThemePermissions API operation. To share the theme, grant permissions by using the UpdateThemePermissions API operation."},{"ref":"AWS.QuickSight.html#create_analysis/5","title":"AWS.QuickSight.create_analysis/5","type":"function","doc":"Creates an analysis in Amazon QuickSight."},{"ref":"AWS.QuickSight.html#create_dashboard/5","title":"AWS.QuickSight.create_dashboard/5","type":"function","doc":"Creates a dashboard from a template. To first create a template, see the CreateTemplate API operation. A dashboard is an entity in QuickSight that identifies QuickSight reports, created from analyses. You can share QuickSight dashboards. With the right permissions, you can create scheduled email reports from them. If you have the correct permissions, you can create a dashboard from a template that exists in a different AWS account."},{"ref":"AWS.QuickSight.html#create_data_set/4","title":"AWS.QuickSight.create_data_set/4","type":"function","doc":"Creates a dataset."},{"ref":"AWS.QuickSight.html#create_data_source/4","title":"AWS.QuickSight.create_data_source/4","type":"function","doc":"Creates a data source."},{"ref":"AWS.QuickSight.html#create_group/5","title":"AWS.QuickSight.create_group/5","type":"function","doc":"Creates an Amazon QuickSight group. The permissions resource is arn:aws:quicksight:us-east-1:*&lt;relevant-aws-account-id&gt;*:group/default/*&lt;group-name&gt;*. The response is a group object."},{"ref":"AWS.QuickSight.html#create_group_membership/7","title":"AWS.QuickSight.create_group_membership/7","type":"function","doc":"Adds an Amazon QuickSight user to an Amazon QuickSight group."},{"ref":"AWS.QuickSight.html#create_i_a_m_policy_assignment/5","title":"AWS.QuickSight.create_i_a_m_policy_assignment/5","type":"function","doc":"Creates an assignment with one specified IAM policy, identified by its Amazon Resource Name (ARN). This policy will be assigned to specified groups or users of Amazon QuickSight. The users and groups need to be in the same namespace."},{"ref":"AWS.QuickSight.html#create_ingestion/6","title":"AWS.QuickSight.create_ingestion/6","type":"function","doc":"Creates and starts a new SPICE ingestion on a dataset Any ingestions operating on tagged datasets inherit the same tags automatically for use in access control. For an example, see How do I create an IAM policy to control access to Amazon EC2 resources using tags? in the AWS Knowledge Center. Tags are visible on the tagged dataset, but not on the ingestion resource."},{"ref":"AWS.QuickSight.html#create_namespace/4","title":"AWS.QuickSight.create_namespace/4","type":"function","doc":"(Enterprise edition only) Creates a new namespace for you to use with Amazon QuickSight. A namespace allows you to isolate the QuickSight users and groups that are registered for that namespace. Users that access the namespace can share assets only with other users or groups in the same namespace. They can&#39;t see users and groups in other namespaces. You can create a namespace after your AWS account is subscribed to QuickSight. The namespace must be unique within the AWS account. By default, there is a limit of 100 namespaces per AWS account. To increase your limit, create a ticket with AWS Support."},{"ref":"AWS.QuickSight.html#create_template/5","title":"AWS.QuickSight.create_template/5","type":"function","doc":"Creates a template from an existing QuickSight analysis or template. You can use the resulting template to create a dashboard. A template is an entity in QuickSight that encapsulates the metadata required to create an analysis and that you can use to create s dashboard. A template adds a layer of abstraction by using placeholders to replace the dataset associated with the analysis. You can use templates to create dashboards by replacing dataset placeholders with datasets that follow the same schema that was used to create the source analysis and template."},{"ref":"AWS.QuickSight.html#create_template_alias/6","title":"AWS.QuickSight.create_template_alias/6","type":"function","doc":"Creates a template alias for a template."},{"ref":"AWS.QuickSight.html#create_theme/5","title":"AWS.QuickSight.create_theme/5","type":"function","doc":"Creates a theme. A theme is set of configuration options for color and layout. Themes apply to analyses and dashboards. For more information, see Using Themes in Amazon QuickSight in the Amazon QuickSight User Guide."},{"ref":"AWS.QuickSight.html#create_theme_alias/6","title":"AWS.QuickSight.create_theme_alias/6","type":"function","doc":"Creates a theme alias for a theme."},{"ref":"AWS.QuickSight.html#delete_account_customization/4","title":"AWS.QuickSight.delete_account_customization/4","type":"function","doc":"Deletes all Amazon QuickSight customizations in this AWS Region for the specified AWS account and QuickSight namespace."},{"ref":"AWS.QuickSight.html#delete_analysis/5","title":"AWS.QuickSight.delete_analysis/5","type":"function","doc":"Deletes an analysis from Amazon QuickSight. You can optionally include a recovery window during which you can restore the analysis. If you don&#39;t specify a recovery window value, the operation defaults to 30 days. QuickSight attaches a DeletionTime stamp to the response that specifies the end of the recovery window. At the end of the recovery window, QuickSight deletes the analysis permanently. At any time before recovery window ends, you can use the RestoreAnalysis API operation to remove the DeletionTime stamp and cancel the deletion of the analysis. The analysis remains visible in the API until it&#39;s deleted, so you can describe it but you can&#39;t make a template from it. An analysis that&#39;s scheduled for deletion isn&#39;t accessible in the QuickSight console. To access it in the console, restore it. Deleting an analysis doesn&#39;t delete the dashboards that you publish from it."},{"ref":"AWS.QuickSight.html#delete_dashboard/5","title":"AWS.QuickSight.delete_dashboard/5","type":"function","doc":"Deletes a dashboard."},{"ref":"AWS.QuickSight.html#delete_data_set/5","title":"AWS.QuickSight.delete_data_set/5","type":"function","doc":"Deletes a dataset."},{"ref":"AWS.QuickSight.html#delete_data_source/5","title":"AWS.QuickSight.delete_data_source/5","type":"function","doc":"Deletes the data source permanently. This operation breaks all the datasets that reference the deleted data source."},{"ref":"AWS.QuickSight.html#delete_group/6","title":"AWS.QuickSight.delete_group/6","type":"function","doc":"Removes a user group from Amazon QuickSight."},{"ref":"AWS.QuickSight.html#delete_group_membership/7","title":"AWS.QuickSight.delete_group_membership/7","type":"function","doc":"Removes a user from a group so that the user is no longer a member of the group."},{"ref":"AWS.QuickSight.html#delete_i_a_m_policy_assignment/6","title":"AWS.QuickSight.delete_i_a_m_policy_assignment/6","type":"function","doc":"Deletes an existing IAM policy assignment."},{"ref":"AWS.QuickSight.html#delete_namespace/5","title":"AWS.QuickSight.delete_namespace/5","type":"function","doc":"Deletes a namespace and the users and groups that are associated with the namespace. This is an asynchronous process. Assets including dashboards, analyses, datasets and data sources are not deleted. To delete these assets, you use the API operations for the relevant asset."},{"ref":"AWS.QuickSight.html#delete_template/5","title":"AWS.QuickSight.delete_template/5","type":"function","doc":"Deletes a template."},{"ref":"AWS.QuickSight.html#delete_template_alias/6","title":"AWS.QuickSight.delete_template_alias/6","type":"function","doc":"Deletes the item that the specified template alias points to. If you provide a specific alias, you delete the version of the template that the alias points to."},{"ref":"AWS.QuickSight.html#delete_theme/5","title":"AWS.QuickSight.delete_theme/5","type":"function","doc":"Deletes a theme."},{"ref":"AWS.QuickSight.html#delete_theme_alias/6","title":"AWS.QuickSight.delete_theme_alias/6","type":"function","doc":"Deletes the version of the theme that the specified theme alias points to. If you provide a specific alias, you delete the version of the theme that the alias points to."},{"ref":"AWS.QuickSight.html#delete_user/6","title":"AWS.QuickSight.delete_user/6","type":"function","doc":"Deletes the Amazon QuickSight user that is associated with the identity of the AWS Identity and Access Management (IAM) user or role that&#39;s making the call. The IAM user isn&#39;t deleted as a result of this call."},{"ref":"AWS.QuickSight.html#delete_user_by_principal_id/6","title":"AWS.QuickSight.delete_user_by_principal_id/6","type":"function","doc":"Deletes a user identified by its principal ID."},{"ref":"AWS.QuickSight.html#describe_account_customization/5","title":"AWS.QuickSight.describe_account_customization/5","type":"function","doc":"Describes the customizations associated with the provided AWS account and Amazon QuickSight namespace in an AWS Region. The QuickSight console evaluates which customizations to apply by running this API operation with the Resolved flag included. To determine what customizations display when you run this command, it can help to visualize the relationship of the entities involved. AWS Account - The AWS account exists at the top of the hierarchy. It has the potential to use all of the AWS Regions and AWS Services. When you subscribe to QuickSight, you choose one AWS Region to use as your home Region. That&#39;s where your free SPICE capacity is located. You can use QuickSight in any supported AWS Region. AWS Region - In each AWS Region where you sign in to QuickSight at least once, QuickSight acts as a separate instance of the same service. If you have a user directory, it resides in us-east-1, which is the US East (N. Virginia). Generally speaking, these users have access to QuickSight in any AWS Region, unless they are constrained to a namespace. To run the command in a different AWS Region, you change your Region settings. If you&#39;re using the AWS CLI, you can use one of the following options: * Use [command line options](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-options.html). * Use [named profiles](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-profiles.html). * Run `aws configure` to change your default AWS Region. Use Enter to key the same settings for your keys. For more information, see Configuring the AWS CLI. Namespace - A QuickSight namespace is a partition that contains users and assets (data sources, datasets, dashboards, and so on). To access assets that are in a specific namespace, users and groups must also be part of the same namespace. People who share a namespace are completely isolated from users and assets in other namespaces, even if they are in the same AWS account and AWS Region. Applied customizations - Within an AWS Region, a set of QuickSight customizations can apply to an AWS account or to a namespace. Settings that you apply to a namespace override settings that you apply to an AWS account. All settings are isolated to a single AWS Region. To apply them in other AWS Regions, run the CreateAccountCustomization command in each AWS Region where you want to apply the same customizations."},{"ref":"AWS.QuickSight.html#describe_account_settings/3","title":"AWS.QuickSight.describe_account_settings/3","type":"function","doc":"Describes the settings that were used when your QuickSight subscription was first created in this AWS account."},{"ref":"AWS.QuickSight.html#describe_analysis/4","title":"AWS.QuickSight.describe_analysis/4","type":"function","doc":"Provides a summary of the metadata for an analysis."},{"ref":"AWS.QuickSight.html#describe_analysis_permissions/4","title":"AWS.QuickSight.describe_analysis_permissions/4","type":"function","doc":"Provides the read and write permissions for an analysis."},{"ref":"AWS.QuickSight.html#describe_dashboard/6","title":"AWS.QuickSight.describe_dashboard/6","type":"function","doc":"Provides a summary for a dashboard."},{"ref":"AWS.QuickSight.html#describe_dashboard_permissions/4","title":"AWS.QuickSight.describe_dashboard_permissions/4","type":"function","doc":"Describes read and write permissions for a dashboard."},{"ref":"AWS.QuickSight.html#describe_data_set/4","title":"AWS.QuickSight.describe_data_set/4","type":"function","doc":"Describes a dataset."},{"ref":"AWS.QuickSight.html#describe_data_set_permissions/4","title":"AWS.QuickSight.describe_data_set_permissions/4","type":"function","doc":"Describes the permissions on a dataset. The permissions resource is arn:aws:quicksight:region:aws-account-id:dataset/data-set-id."},{"ref":"AWS.QuickSight.html#describe_data_source/4","title":"AWS.QuickSight.describe_data_source/4","type":"function","doc":"Describes a data source."},{"ref":"AWS.QuickSight.html#describe_data_source_permissions/4","title":"AWS.QuickSight.describe_data_source_permissions/4","type":"function","doc":"Describes the resource permissions for a data source."},{"ref":"AWS.QuickSight.html#describe_group/5","title":"AWS.QuickSight.describe_group/5","type":"function","doc":"Returns an Amazon QuickSight group&#39;s description and Amazon Resource Name (ARN)."},{"ref":"AWS.QuickSight.html#describe_i_a_m_policy_assignment/5","title":"AWS.QuickSight.describe_i_a_m_policy_assignment/5","type":"function","doc":"Describes an existing IAM policy assignment, as specified by the assignment name."},{"ref":"AWS.QuickSight.html#describe_ingestion/5","title":"AWS.QuickSight.describe_ingestion/5","type":"function","doc":"Describes a SPICE ingestion."},{"ref":"AWS.QuickSight.html#describe_namespace/4","title":"AWS.QuickSight.describe_namespace/4","type":"function","doc":"Describes the current namespace."},{"ref":"AWS.QuickSight.html#describe_template/6","title":"AWS.QuickSight.describe_template/6","type":"function","doc":"Describes a template&#39;s metadata."},{"ref":"AWS.QuickSight.html#describe_template_alias/5","title":"AWS.QuickSight.describe_template_alias/5","type":"function","doc":"Describes the template alias for a template."},{"ref":"AWS.QuickSight.html#describe_template_permissions/4","title":"AWS.QuickSight.describe_template_permissions/4","type":"function","doc":"Describes read and write permissions on a template."},{"ref":"AWS.QuickSight.html#describe_theme/6","title":"AWS.QuickSight.describe_theme/6","type":"function","doc":"Describes a theme."},{"ref":"AWS.QuickSight.html#describe_theme_alias/5","title":"AWS.QuickSight.describe_theme_alias/5","type":"function","doc":"Describes the alias for a theme."},{"ref":"AWS.QuickSight.html#describe_theme_permissions/4","title":"AWS.QuickSight.describe_theme_permissions/4","type":"function","doc":"Describes the read and write permissions for a theme."},{"ref":"AWS.QuickSight.html#describe_user/5","title":"AWS.QuickSight.describe_user/5","type":"function","doc":"Returns information about a user, given the user name."},{"ref":"AWS.QuickSight.html#get_dashboard_embed_url/9","title":"AWS.QuickSight.get_dashboard_embed_url/9","type":"function","doc":"Generates a session URL and authorization code that you can use to embed an Amazon QuickSight read-only dashboard in your web server code. Before you use this command, make sure that you have configured the dashboards and permissions. Currently, you can use GetDashboardEmbedURL only from the server, not from the user&#39;s browser. The following rules apply to the combination of URL and authorization code: They must be used together. They can be used one time only. They are valid for 5 minutes after you run this command. The resulting user session is valid for 10 hours. For more information, see Embedding Amazon QuickSight in the Amazon QuickSight User Guide ."},{"ref":"AWS.QuickSight.html#get_session_embed_url/6","title":"AWS.QuickSight.get_session_embed_url/6","type":"function","doc":"Generates a session URL and authorization code that you can use to embed the Amazon QuickSight console in your web server code. Use GetSessionEmbedUrl where you want to provide an authoring portal that allows users to create data sources, datasets, analyses, and dashboards. The users who access an embedded QuickSight console need belong to the author or admin security cohort. If you want to restrict permissions to some of these features, add a custom permissions profile to the user with the UpdateUser API operation. Use RegisterUser API operation to add a new user with a custom permission profile attached. For more information, see the following sections in the Amazon QuickSight User Guide: Embedding the Amazon QuickSight Console Customizing Access to the Amazon QuickSight Console"},{"ref":"AWS.QuickSight.html#list_analyses/5","title":"AWS.QuickSight.list_analyses/5","type":"function","doc":"Lists Amazon QuickSight analyses that exist in the specified AWS account."},{"ref":"AWS.QuickSight.html#list_dashboard_versions/6","title":"AWS.QuickSight.list_dashboard_versions/6","type":"function","doc":"Lists all the versions of the dashboards in the QuickSight subscription."},{"ref":"AWS.QuickSight.html#list_dashboards/5","title":"AWS.QuickSight.list_dashboards/5","type":"function","doc":"Lists dashboards in an AWS account."},{"ref":"AWS.QuickSight.html#list_data_sets/5","title":"AWS.QuickSight.list_data_sets/5","type":"function","doc":"Lists all of the datasets belonging to the current AWS account in an AWS Region. The permissions resource is arn:aws:quicksight:region:aws-account-id:dataset/*."},{"ref":"AWS.QuickSight.html#list_data_sources/5","title":"AWS.QuickSight.list_data_sources/5","type":"function","doc":"Lists data sources in current AWS Region that belong to this AWS account."},{"ref":"AWS.QuickSight.html#list_group_memberships/7","title":"AWS.QuickSight.list_group_memberships/7","type":"function","doc":"Lists member users in a group."},{"ref":"AWS.QuickSight.html#list_groups/6","title":"AWS.QuickSight.list_groups/6","type":"function","doc":"Lists all user groups in Amazon QuickSight."},{"ref":"AWS.QuickSight.html#list_i_a_m_policy_assignments/6","title":"AWS.QuickSight.list_i_a_m_policy_assignments/6","type":"function","doc":"Lists IAM policy assignments in the current Amazon QuickSight account."},{"ref":"AWS.QuickSight.html#list_i_a_m_policy_assignments_for_user/7","title":"AWS.QuickSight.list_i_a_m_policy_assignments_for_user/7","type":"function","doc":"Lists all the IAM policy assignments, including the Amazon Resource Names (ARNs) for the IAM policies assigned to the specified user and group or groups that the user belongs to."},{"ref":"AWS.QuickSight.html#list_ingestions/6","title":"AWS.QuickSight.list_ingestions/6","type":"function","doc":"Lists the history of SPICE ingestions for a dataset."},{"ref":"AWS.QuickSight.html#list_namespaces/5","title":"AWS.QuickSight.list_namespaces/5","type":"function","doc":"Lists the namespaces for the specified AWS account."},{"ref":"AWS.QuickSight.html#list_tags_for_resource/3","title":"AWS.QuickSight.list_tags_for_resource/3","type":"function","doc":"Lists the tags assigned to a resource."},{"ref":"AWS.QuickSight.html#list_template_aliases/6","title":"AWS.QuickSight.list_template_aliases/6","type":"function","doc":"Lists all the aliases of a template."},{"ref":"AWS.QuickSight.html#list_template_versions/6","title":"AWS.QuickSight.list_template_versions/6","type":"function","doc":"Lists all the versions of the templates in the current Amazon QuickSight account."},{"ref":"AWS.QuickSight.html#list_templates/5","title":"AWS.QuickSight.list_templates/5","type":"function","doc":"Lists all the templates in the current Amazon QuickSight account."},{"ref":"AWS.QuickSight.html#list_theme_aliases/6","title":"AWS.QuickSight.list_theme_aliases/6","type":"function","doc":"Lists all the aliases of a theme."},{"ref":"AWS.QuickSight.html#list_theme_versions/6","title":"AWS.QuickSight.list_theme_versions/6","type":"function","doc":"Lists all the versions of the themes in the current AWS account."},{"ref":"AWS.QuickSight.html#list_themes/6","title":"AWS.QuickSight.list_themes/6","type":"function","doc":"Lists all the themes in the current AWS account."},{"ref":"AWS.QuickSight.html#list_user_groups/7","title":"AWS.QuickSight.list_user_groups/7","type":"function","doc":"Lists the Amazon QuickSight groups that an Amazon QuickSight user is a member of."},{"ref":"AWS.QuickSight.html#list_users/6","title":"AWS.QuickSight.list_users/6","type":"function","doc":"Returns a list of all of the Amazon QuickSight users belonging to this account."},{"ref":"AWS.QuickSight.html#register_user/5","title":"AWS.QuickSight.register_user/5","type":"function","doc":"Creates an Amazon QuickSight user, whose identity is associated with the AWS Identity and Access Management (IAM) identity or role specified in the request."},{"ref":"AWS.QuickSight.html#restore_analysis/5","title":"AWS.QuickSight.restore_analysis/5","type":"function","doc":"Restores an analysis."},{"ref":"AWS.QuickSight.html#search_analyses/4","title":"AWS.QuickSight.search_analyses/4","type":"function","doc":"Searches for analyses that belong to the user specified in the filter."},{"ref":"AWS.QuickSight.html#search_dashboards/4","title":"AWS.QuickSight.search_dashboards/4","type":"function","doc":"Searches for dashboards that belong to a user."},{"ref":"AWS.QuickSight.html#tag_resource/4","title":"AWS.QuickSight.tag_resource/4","type":"function","doc":"Assigns one or more tags (key-value pairs) to the specified QuickSight resource. Tags can help you organize and categorize your resources. You can also use them to scope user permissions, by granting a user permission to access or change only resources with certain tag values. You can use the TagResource operation with a resource that already has tags. If you specify a new tag key for the resource, this tag is appended to the list of tags associated with the resource. If you specify a tag key that is already associated with the resource, the new tag value that you specify replaces the previous value for that tag. You can associate as many as 50 tags with a resource. QuickSight supports tagging on data set, data source, dashboard, and template. Tagging for QuickSight works in a similar way to tagging for other AWS services, except for the following: You can&#39;t use tags to track AWS costs for QuickSight. This restriction is because QuickSight costs are based on users and SPICE capacity, which aren&#39;t taggable resources. QuickSight doesn&#39;t currently support the Tag Editor for AWS Resource Groups."},{"ref":"AWS.QuickSight.html#untag_resource/4","title":"AWS.QuickSight.untag_resource/4","type":"function","doc":"Removes a tag or tags from a resource."},{"ref":"AWS.QuickSight.html#update_account_customization/4","title":"AWS.QuickSight.update_account_customization/4","type":"function","doc":"Updates Amazon QuickSight customizations the current AWS Region. Currently, the only customization you can use is a theme. You can use customizations for your AWS account or, if you specify a namespace, for a QuickSight namespace instead. Customizations that apply to a namespace override customizations that apply to an AWS account. To find out which customizations apply, use the DescribeAccountCustomization API operation."},{"ref":"AWS.QuickSight.html#update_account_settings/4","title":"AWS.QuickSight.update_account_settings/4","type":"function","doc":"Updates the Amazon QuickSight settings in your AWS account."},{"ref":"AWS.QuickSight.html#update_analysis/5","title":"AWS.QuickSight.update_analysis/5","type":"function","doc":"Updates an analysis in Amazon QuickSight"},{"ref":"AWS.QuickSight.html#update_analysis_permissions/5","title":"AWS.QuickSight.update_analysis_permissions/5","type":"function","doc":"Updates the read and write permissions for an analysis."},{"ref":"AWS.QuickSight.html#update_dashboard/5","title":"AWS.QuickSight.update_dashboard/5","type":"function","doc":"Updates a dashboard in an AWS account."},{"ref":"AWS.QuickSight.html#update_dashboard_permissions/5","title":"AWS.QuickSight.update_dashboard_permissions/5","type":"function","doc":"Updates read and write permissions on a dashboard."},{"ref":"AWS.QuickSight.html#update_dashboard_published_version/6","title":"AWS.QuickSight.update_dashboard_published_version/6","type":"function","doc":"Updates the published version of a dashboard."},{"ref":"AWS.QuickSight.html#update_data_set/5","title":"AWS.QuickSight.update_data_set/5","type":"function","doc":"Updates a dataset."},{"ref":"AWS.QuickSight.html#update_data_set_permissions/5","title":"AWS.QuickSight.update_data_set_permissions/5","type":"function","doc":"Updates the permissions on a dataset. The permissions resource is arn:aws:quicksight:region:aws-account-id:dataset/data-set-id."},{"ref":"AWS.QuickSight.html#update_data_source/5","title":"AWS.QuickSight.update_data_source/5","type":"function","doc":"Updates a data source."},{"ref":"AWS.QuickSight.html#update_data_source_permissions/5","title":"AWS.QuickSight.update_data_source_permissions/5","type":"function","doc":"Updates the permissions to a data source."},{"ref":"AWS.QuickSight.html#update_group/6","title":"AWS.QuickSight.update_group/6","type":"function","doc":"Changes a group description."},{"ref":"AWS.QuickSight.html#update_i_a_m_policy_assignment/6","title":"AWS.QuickSight.update_i_a_m_policy_assignment/6","type":"function","doc":"Updates an existing IAM policy assignment. This operation updates only the optional parameter or parameters that are specified in the request."},{"ref":"AWS.QuickSight.html#update_template/5","title":"AWS.QuickSight.update_template/5","type":"function","doc":"Updates a template from an existing Amazon QuickSight analysis or another template."},{"ref":"AWS.QuickSight.html#update_template_alias/6","title":"AWS.QuickSight.update_template_alias/6","type":"function","doc":"Updates the template alias of a template."},{"ref":"AWS.QuickSight.html#update_template_permissions/5","title":"AWS.QuickSight.update_template_permissions/5","type":"function","doc":"Updates the resource permissions for a template."},{"ref":"AWS.QuickSight.html#update_theme/5","title":"AWS.QuickSight.update_theme/5","type":"function","doc":"Updates a theme."},{"ref":"AWS.QuickSight.html#update_theme_alias/6","title":"AWS.QuickSight.update_theme_alias/6","type":"function","doc":"Updates an alias of a theme."},{"ref":"AWS.QuickSight.html#update_theme_permissions/5","title":"AWS.QuickSight.update_theme_permissions/5","type":"function","doc":"Updates the resource permissions for a theme. Permissions apply to the action to grant or revoke permissions on, for example &quot;quicksight:DescribeTheme&quot;. Theme permissions apply in groupings. Valid groupings include the following for the three levels of permissions, which are user, owner, or no permissions: User &quot;quicksight:DescribeTheme&quot; &quot;quicksight:DescribeThemeAlias&quot; &quot;quicksight:ListThemeAliases&quot; &quot;quicksight:ListThemeVersions&quot; Owner &quot;quicksight:DescribeTheme&quot; &quot;quicksight:DescribeThemeAlias&quot; &quot;quicksight:ListThemeAliases&quot; &quot;quicksight:ListThemeVersions&quot; &quot;quicksight:DeleteTheme&quot; &quot;quicksight:UpdateTheme&quot; &quot;quicksight:CreateThemeAlias&quot; &quot;quicksight:DeleteThemeAlias&quot; &quot;quicksight:UpdateThemeAlias&quot; &quot;quicksight:UpdateThemePermissions&quot; &quot;quicksight:DescribeThemePermissions&quot; To specify no permissions, omit the permissions list."},{"ref":"AWS.QuickSight.html#update_user/6","title":"AWS.QuickSight.update_user/6","type":"function","doc":"Updates an Amazon QuickSight user."},{"ref":"AWS.RAM.html","title":"AWS.RAM","type":"module","doc":"Use AWS Resource Access Manager to share AWS resources between AWS accounts. To share a resource, you create a resource share, associate the resource with the resource share, and specify the principals that can access the resources associated with the resource share. The following principals are supported: AWS accounts, organizational units (OU) from AWS Organizations, and organizations from AWS Organizations. For more information, see the AWS Resource Access Manager User Guide."},{"ref":"AWS.RAM.html#accept_resource_share_invitation/3","title":"AWS.RAM.accept_resource_share_invitation/3","type":"function","doc":"Accepts an invitation to a resource share from another AWS account."},{"ref":"AWS.RAM.html#associate_resource_share/3","title":"AWS.RAM.associate_resource_share/3","type":"function","doc":"Associates the specified resource share with the specified principals and resources."},{"ref":"AWS.RAM.html#associate_resource_share_permission/3","title":"AWS.RAM.associate_resource_share_permission/3","type":"function","doc":"Associates a permission with a resource share."},{"ref":"AWS.RAM.html#create_resource_share/3","title":"AWS.RAM.create_resource_share/3","type":"function","doc":"Creates a resource share."},{"ref":"AWS.RAM.html#delete_resource_share/3","title":"AWS.RAM.delete_resource_share/3","type":"function","doc":"Deletes the specified resource share."},{"ref":"AWS.RAM.html#disassociate_resource_share/3","title":"AWS.RAM.disassociate_resource_share/3","type":"function","doc":"Disassociates the specified principals or resources from the specified resource share."},{"ref":"AWS.RAM.html#disassociate_resource_share_permission/3","title":"AWS.RAM.disassociate_resource_share_permission/3","type":"function","doc":"Disassociates an AWS RAM permission from a resource share."},{"ref":"AWS.RAM.html#enable_sharing_with_aws_organization/3","title":"AWS.RAM.enable_sharing_with_aws_organization/3","type":"function","doc":"Enables resource sharing within your AWS Organization. The caller must be the master account for the AWS Organization."},{"ref":"AWS.RAM.html#get_permission/3","title":"AWS.RAM.get_permission/3","type":"function","doc":"Gets the contents of an AWS RAM permission in JSON format."},{"ref":"AWS.RAM.html#get_resource_policies/3","title":"AWS.RAM.get_resource_policies/3","type":"function","doc":"Gets the policies for the specified resources that you own and have shared."},{"ref":"AWS.RAM.html#get_resource_share_associations/3","title":"AWS.RAM.get_resource_share_associations/3","type":"function","doc":"Gets the resources or principals for the resource shares that you own."},{"ref":"AWS.RAM.html#get_resource_share_invitations/3","title":"AWS.RAM.get_resource_share_invitations/3","type":"function","doc":"Gets the invitations for resource sharing that you&#39;ve received."},{"ref":"AWS.RAM.html#get_resource_shares/3","title":"AWS.RAM.get_resource_shares/3","type":"function","doc":"Gets the resource shares that you own or the resource shares that are shared with you."},{"ref":"AWS.RAM.html#list_pending_invitation_resources/3","title":"AWS.RAM.list_pending_invitation_resources/3","type":"function","doc":"Lists the resources in a resource share that is shared with you but that the invitation is still pending for."},{"ref":"AWS.RAM.html#list_permissions/3","title":"AWS.RAM.list_permissions/3","type":"function","doc":"Lists the AWS RAM permissions."},{"ref":"AWS.RAM.html#list_principals/3","title":"AWS.RAM.list_principals/3","type":"function","doc":"Lists the principals that you have shared resources with or that have shared resources with you."},{"ref":"AWS.RAM.html#list_resource_share_permissions/3","title":"AWS.RAM.list_resource_share_permissions/3","type":"function","doc":"Lists the AWS RAM permissions that are associated with a resource share."},{"ref":"AWS.RAM.html#list_resource_types/3","title":"AWS.RAM.list_resource_types/3","type":"function","doc":"Lists the shareable resource types supported by AWS RAM."},{"ref":"AWS.RAM.html#list_resources/3","title":"AWS.RAM.list_resources/3","type":"function","doc":"Lists the resources that you added to a resource shares or the resources that are shared with you."},{"ref":"AWS.RAM.html#promote_resource_share_created_from_policy/3","title":"AWS.RAM.promote_resource_share_created_from_policy/3","type":"function","doc":"Resource shares that were created by attaching a policy to a resource are visible only to the resource share owner, and the resource share cannot be modified in AWS RAM. Use this API action to promote the resource share. When you promote the resource share, it becomes: Visible to all principals that it is shared with. Modifiable in AWS RAM."},{"ref":"AWS.RAM.html#reject_resource_share_invitation/3","title":"AWS.RAM.reject_resource_share_invitation/3","type":"function","doc":"Rejects an invitation to a resource share from another AWS account."},{"ref":"AWS.RAM.html#tag_resource/3","title":"AWS.RAM.tag_resource/3","type":"function","doc":"Adds the specified tags to the specified resource share that you own."},{"ref":"AWS.RAM.html#untag_resource/3","title":"AWS.RAM.untag_resource/3","type":"function","doc":"Removes the specified tags from the specified resource share that you own."},{"ref":"AWS.RAM.html#update_resource_share/3","title":"AWS.RAM.update_resource_share/3","type":"function","doc":"Updates the specified resource share that you own."},{"ref":"AWS.RDS.html","title":"AWS.RDS","type":"module","doc":"Amazon Relational Database Service Amazon Relational Database Service (Amazon RDS) is a web service that makes it easier to set up, operate, and scale a relational database in the cloud. It provides cost-efficient, resizeable capacity for an industry-standard relational database and manages common database administration tasks, freeing up developers to focus on what makes their applications and businesses unique. Amazon RDS gives you access to the capabilities of a MySQL, MariaDB, PostgreSQL, Microsoft SQL Server, Oracle, or Amazon Aurora database server. These capabilities mean that the code, applications, and tools you already use today with your existing databases work with Amazon RDS without modification. Amazon RDS automatically backs up your database and maintains the database software that powers your DB instance. Amazon RDS is flexible: you can scale your DB instance&#39;s compute resources and storage capacity to meet your application&#39;s demand. As with all Amazon Web Services, there are no up-front investments, and you pay only for the resources you use. This interface reference for Amazon RDS contains documentation for a programming or command line interface you can use to manage Amazon RDS. Amazon RDS is asynchronous, which means that some interfaces might require techniques such as polling or callback functions to determine when a command has been applied. In this reference, the parameter descriptions indicate whether a command is applied immediately, on the next instance reboot, or during the maintenance window. The reference structure is as follows, and we list following some related topics from the user guide. Amazon RDS API Reference For the alphabetical list of API actions, see API Actions. For the alphabetical list of data types, see Data Types. For a list of common query parameters, see Common Parameters. For descriptions of the error codes, see Common Errors. Amazon RDS User Guide For a summary of the Amazon RDS interfaces, see Available RDS Interfaces. For more information about how to use the Query API, see Using the Query API."},{"ref":"AWS.RDS.html#add_role_to_d_b_cluster/3","title":"AWS.RDS.add_role_to_d_b_cluster/3","type":"function","doc":"Associates an Identity and Access Management (IAM) role from an Amazon Aurora DB cluster. For more information, see Authorizing Amazon Aurora MySQL to Access Other AWS Services on Your Behalf in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#add_role_to_d_b_instance/3","title":"AWS.RDS.add_role_to_d_b_instance/3","type":"function","doc":"Associates an AWS Identity and Access Management (IAM) role with a DB instance. To add a role to a DB instance, the status of the DB instance must be available."},{"ref":"AWS.RDS.html#add_source_identifier_to_subscription/3","title":"AWS.RDS.add_source_identifier_to_subscription/3","type":"function","doc":"Adds a source identifier to an existing RDS event notification subscription."},{"ref":"AWS.RDS.html#add_tags_to_resource/3","title":"AWS.RDS.add_tags_to_resource/3","type":"function","doc":"Adds metadata tags to an Amazon RDS resource. These tags can also be used with cost allocation reporting to track cost associated with Amazon RDS resources, or used in a Condition statement in an IAM policy for Amazon RDS. For an overview on tagging Amazon RDS resources, see Tagging Amazon RDS Resources."},{"ref":"AWS.RDS.html#apply_pending_maintenance_action/3","title":"AWS.RDS.apply_pending_maintenance_action/3","type":"function","doc":"Applies a pending maintenance action to a resource (for example, to a DB instance)."},{"ref":"AWS.RDS.html#authorize_d_b_security_group_ingress/3","title":"AWS.RDS.authorize_d_b_security_group_ingress/3","type":"function","doc":"Enables ingress to a DBSecurityGroup using one of two forms of authorization. First, EC2 or VPC security groups can be added to the DBSecurityGroup if the application using the database is running on EC2 or VPC instances. Second, IP ranges are available if the application accessing your database is running on the Internet. Required parameters for this API are one of CIDR range, EC2SecurityGroupId for VPC, or (EC2SecurityGroupOwnerId and either EC2SecurityGroupName or EC2SecurityGroupId for non-VPC). You can&#39;t authorize ingress from an EC2 security group in one AWS Region to an Amazon RDS DB instance in another. You can&#39;t authorize ingress from a VPC security group in one VPC to an Amazon RDS DB instance in another. For an overview of CIDR ranges, go to the Wikipedia Tutorial."},{"ref":"AWS.RDS.html#backtrack_d_b_cluster/3","title":"AWS.RDS.backtrack_d_b_cluster/3","type":"function","doc":"Backtracks a DB cluster to a specific time, without creating a new DB cluster. For more information on backtracking, see Backtracking an Aurora DB Cluster in the Amazon Aurora User Guide. This action only applies to Aurora MySQL DB clusters."},{"ref":"AWS.RDS.html#cancel_export_task/3","title":"AWS.RDS.cancel_export_task/3","type":"function","doc":"Cancels an export task in progress that is exporting a snapshot to Amazon S3. Any data that has already been written to the S3 bucket isn&#39;t removed."},{"ref":"AWS.RDS.html#copy_d_b_cluster_parameter_group/3","title":"AWS.RDS.copy_d_b_cluster_parameter_group/3","type":"function","doc":"Copies the specified DB cluster parameter group. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#copy_d_b_cluster_snapshot/3","title":"AWS.RDS.copy_d_b_cluster_snapshot/3","type":"function","doc":"Copies a snapshot of a DB cluster. To copy a DB cluster snapshot from a shared manual DB cluster snapshot, SourceDBClusterSnapshotIdentifier must be the Amazon Resource Name (ARN) of the shared DB cluster snapshot. You can copy an encrypted DB cluster snapshot from another AWS Region. In that case, the AWS Region where you call the CopyDBClusterSnapshot action is the destination AWS Region for the encrypted DB cluster snapshot to be copied to. To copy an encrypted DB cluster snapshot from another AWS Region, you must provide the following values: KmsKeyId - The AWS Key Management System (AWS KMS) key identifier for the key to use to encrypt the copy of the DB cluster snapshot in the destination AWS Region. PreSignedUrl - A URL that contains a Signature Version 4 signed request for the CopyDBClusterSnapshot action to be called in the source AWS Region where the DB cluster snapshot is copied from. The pre-signed URL must be a valid request for the CopyDBClusterSnapshot API action that can be executed in the source AWS Region that contains the encrypted DB cluster snapshot to be copied. The pre-signed URL request must contain the following parameter values: * `KmsKeyId` - The KMS key identifier for the key to use to encrypt the copy of the DB cluster snapshot in the destination AWS Region. This is the same identifier for both the CopyDBClusterSnapshot action that is called in the destination AWS Region, and the action contained in the pre-signed URL. * `DestinationRegion` - The name of the AWS Region that the DB cluster snapshot is to be created in. * `SourceDBClusterSnapshotIdentifier` - The DB cluster snapshot identifier for the encrypted DB cluster snapshot to be copied. This identifier must be in the Amazon Resource Name (ARN) format for the source AWS Region. For example, if you are copying an encrypted DB cluster snapshot from the us-west-2 AWS Region, then your SourceDBClusterSnapshotIdentifier looks like the following example: arn:aws:rds:us-west-2:123456789012:cluster-snapshot:aurora-cluster1-snapshot-20161115. To learn how to generate a Signature Version 4 signed request, see Authenticating Requests: Using Query Parameters (AWS Signature Version 4) and Signature Version 4 Signing Process. If you are using an AWS SDK tool or the AWS CLI, you can specify SourceRegion (or --source-region for the AWS CLI) instead of specifying PreSignedUrl manually. Specifying SourceRegion autogenerates a pre-signed URL that is a valid request for the operation that can be executed in the source AWS Region. TargetDBClusterSnapshotIdentifier - The identifier for the new copy of the DB cluster snapshot in the destination AWS Region. SourceDBClusterSnapshotIdentifier - The DB cluster snapshot identifier for the encrypted DB cluster snapshot to be copied. This identifier must be in the ARN format for the source AWS Region and is the same value as the SourceDBClusterSnapshotIdentifier in the pre-signed URL. To cancel the copy operation once it is in progress, delete the target DB cluster snapshot identified by TargetDBClusterSnapshotIdentifier while that DB cluster snapshot is in &quot;copying&quot; status. For more information on copying encrypted DB cluster snapshots from one AWS Region to another, see Copying a Snapshot in the Amazon Aurora User Guide. For more information on Amazon Aurora, see What Is Amazon Aurora? in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#copy_d_b_parameter_group/3","title":"AWS.RDS.copy_d_b_parameter_group/3","type":"function","doc":"Copies the specified DB parameter group."},{"ref":"AWS.RDS.html#copy_d_b_snapshot/3","title":"AWS.RDS.copy_d_b_snapshot/3","type":"function","doc":"Copies the specified DB snapshot. The source DB snapshot must be in the available or storage-optimization state. You can copy a snapshot from one AWS Region to another. In that case, the AWS Region where you call the CopyDBSnapshot action is the destination AWS Region for the DB snapshot copy. For more information about copying snapshots, see Copying a DB Snapshot in the Amazon RDS User Guide."},{"ref":"AWS.RDS.html#copy_option_group/3","title":"AWS.RDS.copy_option_group/3","type":"function","doc":"Copies the specified option group."},{"ref":"AWS.RDS.html#create_custom_availability_zone/3","title":"AWS.RDS.create_custom_availability_zone/3","type":"function","doc":"Creates a custom Availability Zone (AZ). A custom AZ is an on-premises AZ that is integrated with a VMware vSphere cluster. For more information about RDS on VMware, see the RDS on VMware User Guide."},{"ref":"AWS.RDS.html#create_d_b_cluster/3","title":"AWS.RDS.create_d_b_cluster/3","type":"function","doc":"Creates a new Amazon Aurora DB cluster. You can use the ReplicationSourceIdentifier parameter to create the DB cluster as a read replica of another DB cluster or Amazon RDS MySQL DB instance. For cross-region replication where the DB cluster identified by ReplicationSourceIdentifier is encrypted, you must also specify the PreSignedUrl parameter. For more information on Amazon Aurora, see What Is Amazon Aurora? in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#create_d_b_cluster_endpoint/3","title":"AWS.RDS.create_d_b_cluster_endpoint/3","type":"function","doc":"Creates a new custom endpoint and associates it with an Amazon Aurora DB cluster. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#create_d_b_cluster_parameter_group/3","title":"AWS.RDS.create_d_b_cluster_parameter_group/3","type":"function","doc":"Creates a new DB cluster parameter group. Parameters in a DB cluster parameter group apply to all of the instances in a DB cluster. A DB cluster parameter group is initially created with the default parameters for the database engine used by instances in the DB cluster. To provide custom values for any of the parameters, you must modify the group after creating it using ModifyDBClusterParameterGroup. Once you&#39;ve created a DB cluster parameter group, you need to associate it with your DB cluster using ModifyDBCluster. When you associate a new DB cluster parameter group with a running DB cluster, you need to reboot the DB instances in the DB cluster without failover for the new DB cluster parameter group and associated settings to take effect. After you create a DB cluster parameter group, you should wait at least 5 minutes before creating your first DB cluster that uses that DB cluster parameter group as the default parameter group. This allows Amazon RDS to fully complete the create action before the DB cluster parameter group is used as the default for a new DB cluster. This is especially important for parameters that are critical when creating the default database for a DB cluster, such as the character set for the default database defined by the character_set_database parameter. You can use the Parameter Groups option of the Amazon RDS console or the DescribeDBClusterParameters action to verify that your DB cluster parameter group has been created or modified. For more information on Amazon Aurora, see What Is Amazon Aurora? in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#create_d_b_cluster_snapshot/3","title":"AWS.RDS.create_d_b_cluster_snapshot/3","type":"function","doc":"Creates a snapshot of a DB cluster. For more information on Amazon Aurora, see What Is Amazon Aurora? in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#create_d_b_instance/3","title":"AWS.RDS.create_d_b_instance/3","type":"function","doc":"Creates a new DB instance."},{"ref":"AWS.RDS.html#create_d_b_instance_read_replica/3","title":"AWS.RDS.create_d_b_instance_read_replica/3","type":"function","doc":"Creates a new DB instance that acts as a read replica for an existing source DB instance. You can create a read replica for a DB instance running MySQL, MariaDB, Oracle, PostgreSQL, or SQL Server. For more information, see Working with Read Replicas in the Amazon RDS User Guide. Amazon Aurora doesn&#39;t support this action. Call the CreateDBInstance action to create a DB instance for an Aurora DB cluster. All read replica DB instances are created with backups disabled. All other DB instance attributes (including DB security groups and DB parameter groups) are inherited from the source DB instance, except as specified. Your source DB instance must have backup retention enabled."},{"ref":"AWS.RDS.html#create_d_b_parameter_group/3","title":"AWS.RDS.create_d_b_parameter_group/3","type":"function","doc":"Creates a new DB parameter group. A DB parameter group is initially created with the default parameters for the database engine used by the DB instance. To provide custom values for any of the parameters, you must modify the group after creating it using ModifyDBParameterGroup. Once you&#39;ve created a DB parameter group, you need to associate it with your DB instance using ModifyDBInstance. When you associate a new DB parameter group with a running DB instance, you need to reboot the DB instance without failover for the new DB parameter group and associated settings to take effect. After you create a DB parameter group, you should wait at least 5 minutes before creating your first DB instance that uses that DB parameter group as the default parameter group. This allows Amazon RDS to fully complete the create action before the parameter group is used as the default for a new DB instance. This is especially important for parameters that are critical when creating the default database for a DB instance, such as the character set for the default database defined by the character_set_database parameter. You can use the Parameter Groups option of the Amazon RDS console or the DescribeDBParameters command to verify that your DB parameter group has been created or modified."},{"ref":"AWS.RDS.html#create_d_b_proxy/3","title":"AWS.RDS.create_d_b_proxy/3","type":"function","doc":"Creates a new DB proxy."},{"ref":"AWS.RDS.html#create_d_b_security_group/3","title":"AWS.RDS.create_d_b_security_group/3","type":"function","doc":"Creates a new DB security group. DB security groups control access to a DB instance. A DB security group controls access to EC2-Classic DB instances that are not in a VPC."},{"ref":"AWS.RDS.html#create_d_b_snapshot/3","title":"AWS.RDS.create_d_b_snapshot/3","type":"function","doc":"Creates a DBSnapshot. The source DBInstance must be in &quot;available&quot; state."},{"ref":"AWS.RDS.html#create_d_b_subnet_group/3","title":"AWS.RDS.create_d_b_subnet_group/3","type":"function","doc":"Creates a new DB subnet group. DB subnet groups must contain at least one subnet in at least two AZs in the AWS Region."},{"ref":"AWS.RDS.html#create_event_subscription/3","title":"AWS.RDS.create_event_subscription/3","type":"function","doc":"Creates an RDS event notification subscription. This action requires a topic Amazon Resource Name (ARN) created by either the RDS console, the SNS console, or the SNS API. To obtain an ARN with SNS, you must create a topic in Amazon SNS and subscribe to the topic. The ARN is displayed in the SNS console. You can specify the type of source (SourceType) that you want to be notified of and provide a list of RDS sources (SourceIds) that triggers the events. You can also provide a list of event categories (EventCategories) for events that you want to be notified of. For example, you can specify SourceType = db-instance, SourceIds = mydbinstance1, mydbinstance2 and EventCategories = Availability, Backup. If you specify both the SourceType and SourceIds, such as SourceType = db-instance and SourceIdentifier = myDBInstance1, you are notified of all the db-instance events for the specified source. If you specify a SourceType but do not specify a SourceIdentifier, you receive notice of the events for that source type for all your RDS sources. If you don&#39;t specify either the SourceType or the SourceIdentifier, you are notified of events generated from all RDS sources belonging to your customer account. RDS event notification is only available for unencrypted SNS topics. If you specify an encrypted SNS topic, event notifications aren&#39;t sent for the topic."},{"ref":"AWS.RDS.html#create_global_cluster/3","title":"AWS.RDS.create_global_cluster/3","type":"function","doc":"Creates an Aurora global database spread across multiple AWS Regions. The global database contains a single primary cluster with read-write capability, and a read-only secondary cluster that receives data from the primary cluster through high-speed replication performed by the Aurora storage subsystem. You can create a global database that is initially empty, and then add a primary cluster and a secondary cluster to it. Or you can specify an existing Aurora cluster during the create operation, and this cluster becomes the primary cluster of the global database. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#create_option_group/3","title":"AWS.RDS.create_option_group/3","type":"function","doc":"Creates a new option group. You can create up to 20 option groups."},{"ref":"AWS.RDS.html#delete_custom_availability_zone/3","title":"AWS.RDS.delete_custom_availability_zone/3","type":"function","doc":"Deletes a custom Availability Zone (AZ). A custom AZ is an on-premises AZ that is integrated with a VMware vSphere cluster. For more information about RDS on VMware, see the RDS on VMware User Guide."},{"ref":"AWS.RDS.html#delete_d_b_cluster/3","title":"AWS.RDS.delete_d_b_cluster/3","type":"function","doc":"The DeleteDBCluster action deletes a previously provisioned DB cluster. When you delete a DB cluster, all automated backups for that DB cluster are deleted and can&#39;t be recovered. Manual DB cluster snapshots of the specified DB cluster are not deleted. For more information on Amazon Aurora, see What Is Amazon Aurora? in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#delete_d_b_cluster_endpoint/3","title":"AWS.RDS.delete_d_b_cluster_endpoint/3","type":"function","doc":"Deletes a custom endpoint and removes it from an Amazon Aurora DB cluster. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#delete_d_b_cluster_parameter_group/3","title":"AWS.RDS.delete_d_b_cluster_parameter_group/3","type":"function","doc":"Deletes a specified DB cluster parameter group. The DB cluster parameter group to be deleted can&#39;t be associated with any DB clusters. For more information on Amazon Aurora, see What Is Amazon Aurora? in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#delete_d_b_cluster_snapshot/3","title":"AWS.RDS.delete_d_b_cluster_snapshot/3","type":"function","doc":"Deletes a DB cluster snapshot. If the snapshot is being copied, the copy operation is terminated. The DB cluster snapshot must be in the available state to be deleted. For more information on Amazon Aurora, see What Is Amazon Aurora? in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#delete_d_b_instance/3","title":"AWS.RDS.delete_d_b_instance/3","type":"function","doc":"The DeleteDBInstance action deletes a previously provisioned DB instance. When you delete a DB instance, all automated backups for that instance are deleted and can&#39;t be recovered. Manual DB snapshots of the DB instance to be deleted by DeleteDBInstance are not deleted. If you request a final DB snapshot the status of the Amazon RDS DB instance is deleting until the DB snapshot is created. The API action DescribeDBInstance is used to monitor the status of this operation. The action can&#39;t be canceled or reverted once submitted. When a DB instance is in a failure state and has a status of failed, incompatible-restore, or incompatible-network, you can only delete it when you skip creation of the final snapshot with the SkipFinalSnapshot parameter. If the specified DB instance is part of an Amazon Aurora DB cluster, you can&#39;t delete the DB instance if both of the following conditions are true: The DB cluster is a read replica of another Amazon Aurora DB cluster. The DB instance is the only instance in the DB cluster. To delete a DB instance in this case, first call the PromoteReadReplicaDBCluster API action to promote the DB cluster so it&#39;s no longer a read replica. After the promotion completes, then call the DeleteDBInstance API action to delete the final instance in the DB cluster."},{"ref":"AWS.RDS.html#delete_d_b_instance_automated_backup/3","title":"AWS.RDS.delete_d_b_instance_automated_backup/3","type":"function","doc":"Deletes automated backups based on the source instance&#39;s DbiResourceId value or the restorable instance&#39;s resource ID."},{"ref":"AWS.RDS.html#delete_d_b_parameter_group/3","title":"AWS.RDS.delete_d_b_parameter_group/3","type":"function","doc":"Deletes a specified DB parameter group. The DB parameter group to be deleted can&#39;t be associated with any DB instances."},{"ref":"AWS.RDS.html#delete_d_b_proxy/3","title":"AWS.RDS.delete_d_b_proxy/3","type":"function","doc":"Deletes an existing proxy."},{"ref":"AWS.RDS.html#delete_d_b_security_group/3","title":"AWS.RDS.delete_d_b_security_group/3","type":"function","doc":"Deletes a DB security group. The specified DB security group must not be associated with any DB instances."},{"ref":"AWS.RDS.html#delete_d_b_snapshot/3","title":"AWS.RDS.delete_d_b_snapshot/3","type":"function","doc":"Deletes a DB snapshot. If the snapshot is being copied, the copy operation is terminated. The DB snapshot must be in the available state to be deleted."},{"ref":"AWS.RDS.html#delete_d_b_subnet_group/3","title":"AWS.RDS.delete_d_b_subnet_group/3","type":"function","doc":"Deletes a DB subnet group. The specified database subnet group must not be associated with any DB instances."},{"ref":"AWS.RDS.html#delete_event_subscription/3","title":"AWS.RDS.delete_event_subscription/3","type":"function","doc":"Deletes an RDS event notification subscription."},{"ref":"AWS.RDS.html#delete_global_cluster/3","title":"AWS.RDS.delete_global_cluster/3","type":"function","doc":"Deletes a global database cluster. The primary and secondary clusters must already be detached or destroyed first. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#delete_installation_media/3","title":"AWS.RDS.delete_installation_media/3","type":"function","doc":"Deletes the installation medium for a DB engine that requires an on-premises customer provided license, such as Microsoft SQL Server."},{"ref":"AWS.RDS.html#delete_option_group/3","title":"AWS.RDS.delete_option_group/3","type":"function","doc":"Deletes an existing option group."},{"ref":"AWS.RDS.html#deregister_d_b_proxy_targets/3","title":"AWS.RDS.deregister_d_b_proxy_targets/3","type":"function","doc":"Remove the association between one or more DBProxyTarget data structures and a DBProxyTargetGroup."},{"ref":"AWS.RDS.html#describe_account_attributes/3","title":"AWS.RDS.describe_account_attributes/3","type":"function","doc":"Lists all of the attributes for a customer account. The attributes include Amazon RDS quotas for the account, such as the number of DB instances allowed. The description for a quota includes the quota name, current usage toward that quota, and the quota&#39;s maximum value. This command doesn&#39;t take any parameters."},{"ref":"AWS.RDS.html#describe_certificates/3","title":"AWS.RDS.describe_certificates/3","type":"function","doc":"Lists the set of CA certificates provided by Amazon RDS for this AWS account."},{"ref":"AWS.RDS.html#describe_custom_availability_zones/3","title":"AWS.RDS.describe_custom_availability_zones/3","type":"function","doc":"Returns information about custom Availability Zones (AZs). A custom AZ is an on-premises AZ that is integrated with a VMware vSphere cluster. For more information about RDS on VMware, see the RDS on VMware User Guide."},{"ref":"AWS.RDS.html#describe_d_b_cluster_backtracks/3","title":"AWS.RDS.describe_d_b_cluster_backtracks/3","type":"function","doc":"Returns information about backtracks for a DB cluster. For more information on Amazon Aurora, see What Is Amazon Aurora? in the Amazon Aurora User Guide. This action only applies to Aurora MySQL DB clusters."},{"ref":"AWS.RDS.html#describe_d_b_cluster_endpoints/3","title":"AWS.RDS.describe_d_b_cluster_endpoints/3","type":"function","doc":"Returns information about endpoints for an Amazon Aurora DB cluster. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#describe_d_b_cluster_parameter_groups/3","title":"AWS.RDS.describe_d_b_cluster_parameter_groups/3","type":"function","doc":"Returns a list of DBClusterParameterGroup descriptions. If a DBClusterParameterGroupName parameter is specified, the list will contain only the description of the specified DB cluster parameter group. For more information on Amazon Aurora, see What Is Amazon Aurora? in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#describe_d_b_cluster_parameters/3","title":"AWS.RDS.describe_d_b_cluster_parameters/3","type":"function","doc":"Returns the detailed parameter list for a particular DB cluster parameter group. For more information on Amazon Aurora, see What Is Amazon Aurora? in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#describe_d_b_cluster_snapshot_attributes/3","title":"AWS.RDS.describe_d_b_cluster_snapshot_attributes/3","type":"function","doc":"Returns a list of DB cluster snapshot attribute names and values for a manual DB cluster snapshot. When sharing snapshots with other AWS accounts, DescribeDBClusterSnapshotAttributes returns the restore attribute and a list of IDs for the AWS accounts that are authorized to copy or restore the manual DB cluster snapshot. If all is included in the list of values for the restore attribute, then the manual DB cluster snapshot is public and can be copied or restored by all AWS accounts. To add or remove access for an AWS account to copy or restore a manual DB cluster snapshot, or to make the manual DB cluster snapshot public or private, use the ModifyDBClusterSnapshotAttribute API action. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#describe_d_b_cluster_snapshots/3","title":"AWS.RDS.describe_d_b_cluster_snapshots/3","type":"function","doc":"Returns information about DB cluster snapshots. This API action supports pagination. For more information on Amazon Aurora, see What Is Amazon Aurora? in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#describe_d_b_clusters/3","title":"AWS.RDS.describe_d_b_clusters/3","type":"function","doc":"Returns information about provisioned Aurora DB clusters. This API supports pagination. For more information on Amazon Aurora, see What Is Amazon Aurora? in the Amazon Aurora User Guide. This operation can also return information for Amazon Neptune DB instances and Amazon DocumentDB instances."},{"ref":"AWS.RDS.html#describe_d_b_engine_versions/3","title":"AWS.RDS.describe_d_b_engine_versions/3","type":"function","doc":"Returns a list of the available DB engines."},{"ref":"AWS.RDS.html#describe_d_b_instance_automated_backups/3","title":"AWS.RDS.describe_d_b_instance_automated_backups/3","type":"function","doc":"Displays backups for both current and deleted instances. For example, use this operation to find details about automated backups for previously deleted instances. Current instances with retention periods greater than zero (0) are returned for both the DescribeDBInstanceAutomatedBackups and DescribeDBInstances operations. All parameters are optional."},{"ref":"AWS.RDS.html#describe_d_b_instances/3","title":"AWS.RDS.describe_d_b_instances/3","type":"function","doc":"Returns information about provisioned RDS instances. This API supports pagination. This operation can also return information for Amazon Neptune DB instances and Amazon DocumentDB instances."},{"ref":"AWS.RDS.html#describe_d_b_log_files/3","title":"AWS.RDS.describe_d_b_log_files/3","type":"function","doc":"Returns a list of DB log files for the DB instance."},{"ref":"AWS.RDS.html#describe_d_b_parameter_groups/3","title":"AWS.RDS.describe_d_b_parameter_groups/3","type":"function","doc":"Returns a list of DBParameterGroup descriptions. If a DBParameterGroupName is specified, the list will contain only the description of the specified DB parameter group."},{"ref":"AWS.RDS.html#describe_d_b_parameters/3","title":"AWS.RDS.describe_d_b_parameters/3","type":"function","doc":"Returns the detailed parameter list for a particular DB parameter group."},{"ref":"AWS.RDS.html#describe_d_b_proxies/3","title":"AWS.RDS.describe_d_b_proxies/3","type":"function","doc":"Returns information about DB proxies."},{"ref":"AWS.RDS.html#describe_d_b_proxy_target_groups/3","title":"AWS.RDS.describe_d_b_proxy_target_groups/3","type":"function","doc":"Returns information about DB proxy target groups, represented by DBProxyTargetGroup data structures."},{"ref":"AWS.RDS.html#describe_d_b_proxy_targets/3","title":"AWS.RDS.describe_d_b_proxy_targets/3","type":"function","doc":"Returns information about DBProxyTarget objects. This API supports pagination."},{"ref":"AWS.RDS.html#describe_d_b_security_groups/3","title":"AWS.RDS.describe_d_b_security_groups/3","type":"function","doc":"Returns a list of DBSecurityGroup descriptions. If a DBSecurityGroupName is specified, the list will contain only the descriptions of the specified DB security group."},{"ref":"AWS.RDS.html#describe_d_b_snapshot_attributes/3","title":"AWS.RDS.describe_d_b_snapshot_attributes/3","type":"function","doc":"Returns a list of DB snapshot attribute names and values for a manual DB snapshot. When sharing snapshots with other AWS accounts, DescribeDBSnapshotAttributes returns the restore attribute and a list of IDs for the AWS accounts that are authorized to copy or restore the manual DB snapshot. If all is included in the list of values for the restore attribute, then the manual DB snapshot is public and can be copied or restored by all AWS accounts. To add or remove access for an AWS account to copy or restore a manual DB snapshot, or to make the manual DB snapshot public or private, use the ModifyDBSnapshotAttribute API action."},{"ref":"AWS.RDS.html#describe_d_b_snapshots/3","title":"AWS.RDS.describe_d_b_snapshots/3","type":"function","doc":"Returns information about DB snapshots. This API action supports pagination."},{"ref":"AWS.RDS.html#describe_d_b_subnet_groups/3","title":"AWS.RDS.describe_d_b_subnet_groups/3","type":"function","doc":"Returns a list of DBSubnetGroup descriptions. If a DBSubnetGroupName is specified, the list will contain only the descriptions of the specified DBSubnetGroup. For an overview of CIDR ranges, go to the Wikipedia Tutorial."},{"ref":"AWS.RDS.html#describe_engine_default_cluster_parameters/3","title":"AWS.RDS.describe_engine_default_cluster_parameters/3","type":"function","doc":"Returns the default engine and system parameter information for the cluster database engine. For more information on Amazon Aurora, see What Is Amazon Aurora? in the Amazon Aurora User Guide."},{"ref":"AWS.RDS.html#describe_engine_default_parameters/3","title":"AWS.RDS.describe_engine_default_parameters/3","type":"function","doc":"Returns the default engine and system parameter information for the specified database engine."},{"ref":"AWS.RDS.html#describe_event_categories/3","title":"AWS.RDS.describe_event_categories/3","type":"function","doc":"Displays a list of categories for all event source types, or, if specified, for a specified source type. You can see a list of the event categories and source types in Events in the Amazon RDS User Guide."},{"ref":"AWS.RDS.html#describe_event_subscriptions/3","title":"AWS.RDS.describe_event_subscriptions/3","type":"function","doc":"Lists all the subscription descriptions for a customer account. The description for a subscription includes SubscriptionName, SNSTopicARN, CustomerID, SourceType, SourceID, CreationTime, and Status. If you specify a SubscriptionName, lists the description for that subscription."},{"ref":"AWS.RDS.html#describe_events/3","title":"AWS.RDS.describe_events/3","type":"function","doc":"Returns events related to DB instances, DB clusters, DB parameter groups, DB security groups, DB snapshots, and DB cluster snapshots for the past 14 days. Events specific to a particular DB instances, DB clusters, DB parameter groups, DB security groups, DB snapshots, and DB cluster snapshots group can be obtained by providing the name as a parameter. By default, the past hour of events are returned."},{"ref":"AWS.RDS.html#describe_export_tasks/3","title":"AWS.RDS.describe_export_tasks/3","type":"function","doc":"Returns information about a snapshot export to Amazon S3. This API operation supports pagination."},{"ref":"AWS.RDS.html#describe_global_clusters/3","title":"AWS.RDS.describe_global_clusters/3","type":"function","doc":"Returns information about Aurora global database clusters. This API supports pagination. For more information on Amazon Aurora, see What Is Amazon Aurora? in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#describe_installation_media/3","title":"AWS.RDS.describe_installation_media/3","type":"function","doc":"Describes the available installation media for a DB engine that requires an on-premises customer provided license, such as Microsoft SQL Server."},{"ref":"AWS.RDS.html#describe_option_group_options/3","title":"AWS.RDS.describe_option_group_options/3","type":"function","doc":"Describes all available options."},{"ref":"AWS.RDS.html#describe_option_groups/3","title":"AWS.RDS.describe_option_groups/3","type":"function","doc":"Describes the available option groups."},{"ref":"AWS.RDS.html#describe_orderable_d_b_instance_options/3","title":"AWS.RDS.describe_orderable_d_b_instance_options/3","type":"function","doc":"Returns a list of orderable DB instance options for the specified engine."},{"ref":"AWS.RDS.html#describe_pending_maintenance_actions/3","title":"AWS.RDS.describe_pending_maintenance_actions/3","type":"function","doc":"Returns a list of resources (for example, DB instances) that have at least one pending maintenance action."},{"ref":"AWS.RDS.html#describe_reserved_d_b_instances/3","title":"AWS.RDS.describe_reserved_d_b_instances/3","type":"function","doc":"Returns information about reserved DB instances for this account, or about a specified reserved DB instance."},{"ref":"AWS.RDS.html#describe_reserved_d_b_instances_offerings/3","title":"AWS.RDS.describe_reserved_d_b_instances_offerings/3","type":"function","doc":"Lists available reserved DB instance offerings."},{"ref":"AWS.RDS.html#describe_source_regions/3","title":"AWS.RDS.describe_source_regions/3","type":"function","doc":"Returns a list of the source AWS Regions where the current AWS Region can create a read replica or copy a DB snapshot from. This API action supports pagination."},{"ref":"AWS.RDS.html#describe_valid_d_b_instance_modifications/3","title":"AWS.RDS.describe_valid_d_b_instance_modifications/3","type":"function","doc":"You can call DescribeValidDBInstanceModifications to learn what modifications you can make to your DB instance. You can use this information when you call ModifyDBInstance."},{"ref":"AWS.RDS.html#download_d_b_log_file_portion/3","title":"AWS.RDS.download_d_b_log_file_portion/3","type":"function","doc":"Downloads all or a portion of the specified log file, up to 1 MB in size."},{"ref":"AWS.RDS.html#failover_d_b_cluster/3","title":"AWS.RDS.failover_d_b_cluster/3","type":"function","doc":"Forces a failover for a DB cluster. A failover for a DB cluster promotes one of the Aurora Replicas (read-only instances) in the DB cluster to be the primary instance (the cluster writer). Amazon Aurora will automatically fail over to an Aurora Replica, if one exists, when the primary instance fails. You can force a failover when you want to simulate a failure of a primary instance for testing. Because each instance in a DB cluster has its own endpoint address, you will need to clean up and re-establish any existing connections that use those endpoint addresses when the failover is complete. For more information on Amazon Aurora, see What Is Amazon Aurora? in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#import_installation_media/3","title":"AWS.RDS.import_installation_media/3","type":"function","doc":"Imports the installation media for a DB engine that requires an on-premises customer provided license, such as SQL Server."},{"ref":"AWS.RDS.html#list_tags_for_resource/3","title":"AWS.RDS.list_tags_for_resource/3","type":"function","doc":"Lists all tags on an Amazon RDS resource. For an overview on tagging an Amazon RDS resource, see Tagging Amazon RDS Resources in the Amazon RDS User Guide."},{"ref":"AWS.RDS.html#modify_certificates/3","title":"AWS.RDS.modify_certificates/3","type":"function","doc":"Override the system-default Secure Sockets Layer/Transport Layer Security (SSL/TLS) certificate for Amazon RDS for new DB instances temporarily, or remove the override. By using this operation, you can specify an RDS-approved SSL/TLS certificate for new DB instances that is different from the default certificate provided by RDS. You can also use this operation to remove the override, so that new DB instances use the default certificate provided by RDS. You might need to override the default certificate in the following situations: You already migrated your applications to support the latest certificate authority (CA) certificate, but the new CA certificate is not yet the RDS default CA certificate for the specified AWS Region. RDS has already moved to a new default CA certificate for the specified AWS Region, but you are still in the process of supporting the new CA certificate. In this case, you temporarily need additional time to finish your application changes. For more information about rotating your SSL/TLS certificate for RDS DB engines, see Rotating Your SSL/TLS Certificate in the Amazon RDS User Guide. For more information about rotating your SSL/TLS certificate for Aurora DB engines, see Rotating Your SSL/TLS Certificate in the Amazon Aurora User Guide."},{"ref":"AWS.RDS.html#modify_current_d_b_cluster_capacity/3","title":"AWS.RDS.modify_current_d_b_cluster_capacity/3","type":"function","doc":"Set the capacity of an Aurora Serverless DB cluster to a specific value. Aurora Serverless scales seamlessly based on the workload on the DB cluster. In some cases, the capacity might not scale fast enough to meet a sudden change in workload, such as a large number of new transactions. Call ModifyCurrentDBClusterCapacity to set the capacity explicitly. After this call sets the DB cluster capacity, Aurora Serverless can automatically scale the DB cluster based on the cooldown period for scaling up and the cooldown period for scaling down. For more information about Aurora Serverless, see Using Amazon Aurora Serverless in the Amazon Aurora User Guide. If you call ModifyCurrentDBClusterCapacity with the default TimeoutAction, connections that prevent Aurora Serverless from finding a scaling point might be dropped. For more information about scaling points, see Autoscaling for Aurora Serverless in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#modify_d_b_cluster/3","title":"AWS.RDS.modify_d_b_cluster/3","type":"function","doc":"Modify a setting for an Amazon Aurora DB cluster. You can change one or more database configuration parameters by specifying these parameters and the new values in the request. For more information on Amazon Aurora, see What Is Amazon Aurora? in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#modify_d_b_cluster_endpoint/3","title":"AWS.RDS.modify_d_b_cluster_endpoint/3","type":"function","doc":"Modifies the properties of an endpoint in an Amazon Aurora DB cluster. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#modify_d_b_cluster_parameter_group/3","title":"AWS.RDS.modify_d_b_cluster_parameter_group/3","type":"function","doc":"Modifies the parameters of a DB cluster parameter group. To modify more than one parameter, submit a list of the following: ParameterName, ParameterValue, and ApplyMethod. A maximum of 20 parameters can be modified in a single request. For more information on Amazon Aurora, see What Is Amazon Aurora? in the Amazon Aurora User Guide. Changes to dynamic parameters are applied immediately. Changes to static parameters require a reboot without failover to the DB cluster associated with the parameter group before the change can take effect. After you create a DB cluster parameter group, you should wait at least 5 minutes before creating your first DB cluster that uses that DB cluster parameter group as the default parameter group. This allows Amazon RDS to fully complete the create action before the parameter group is used as the default for a new DB cluster. This is especially important for parameters that are critical when creating the default database for a DB cluster, such as the character set for the default database defined by the character_set_database parameter. You can use the Parameter Groups option of the Amazon RDS console or the DescribeDBClusterParameters action to verify that your DB cluster parameter group has been created or modified. If the modified DB cluster parameter group is used by an Aurora Serverless cluster, Aurora applies the update immediately. The cluster restart might interrupt your workload. In that case, your application must reopen any connections and retry any transactions that were active when the parameter changes took effect. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#modify_d_b_cluster_snapshot_attribute/3","title":"AWS.RDS.modify_d_b_cluster_snapshot_attribute/3","type":"function","doc":"Adds an attribute and values to, or removes an attribute and values from, a manual DB cluster snapshot. To share a manual DB cluster snapshot with other AWS accounts, specify restore as the AttributeName and use the ValuesToAdd parameter to add a list of IDs of the AWS accounts that are authorized to restore the manual DB cluster snapshot. Use the value all to make the manual DB cluster snapshot public, which means that it can be copied or restored by all AWS accounts. Don&#39;t add the all value for any manual DB cluster snapshots that contain private information that you don&#39;t want available to all AWS accounts. If a manual DB cluster snapshot is encrypted, it can be shared, but only by specifying a list of authorized AWS account IDs for the ValuesToAdd parameter. You can&#39;t use all as a value for that parameter in this case. To view which AWS accounts have access to copy or restore a manual DB cluster snapshot, or whether a manual DB cluster snapshot is public or private, use the DescribeDBClusterSnapshotAttributes API action. The accounts are returned as values for the restore attribute. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#modify_d_b_instance/3","title":"AWS.RDS.modify_d_b_instance/3","type":"function","doc":"Modifies settings for a DB instance. You can change one or more database configuration parameters by specifying these parameters and the new values in the request. To learn what modifications you can make to your DB instance, call DescribeValidDBInstanceModifications before you call ModifyDBInstance."},{"ref":"AWS.RDS.html#modify_d_b_parameter_group/3","title":"AWS.RDS.modify_d_b_parameter_group/3","type":"function","doc":"Modifies the parameters of a DB parameter group. To modify more than one parameter, submit a list of the following: ParameterName, ParameterValue, and ApplyMethod. A maximum of 20 parameters can be modified in a single request. Changes to dynamic parameters are applied immediately. Changes to static parameters require a reboot without failover to the DB instance associated with the parameter group before the change can take effect. After you modify a DB parameter group, you should wait at least 5 minutes before creating your first DB instance that uses that DB parameter group as the default parameter group. This allows Amazon RDS to fully complete the modify action before the parameter group is used as the default for a new DB instance. This is especially important for parameters that are critical when creating the default database for a DB instance, such as the character set for the default database defined by the character_set_database parameter. You can use the Parameter Groups option of the Amazon RDS console or the DescribeDBParameters command to verify that your DB parameter group has been created or modified."},{"ref":"AWS.RDS.html#modify_d_b_proxy/3","title":"AWS.RDS.modify_d_b_proxy/3","type":"function","doc":"Changes the settings for an existing DB proxy."},{"ref":"AWS.RDS.html#modify_d_b_proxy_target_group/3","title":"AWS.RDS.modify_d_b_proxy_target_group/3","type":"function","doc":"Modifies the properties of a DBProxyTargetGroup."},{"ref":"AWS.RDS.html#modify_d_b_snapshot/3","title":"AWS.RDS.modify_d_b_snapshot/3","type":"function","doc":"Updates a manual DB snapshot with a new engine version. The snapshot can be encrypted or unencrypted, but not shared or public. Amazon RDS supports upgrading DB snapshots for MySQL, Oracle, and PostgreSQL."},{"ref":"AWS.RDS.html#modify_d_b_snapshot_attribute/3","title":"AWS.RDS.modify_d_b_snapshot_attribute/3","type":"function","doc":"Adds an attribute and values to, or removes an attribute and values from, a manual DB snapshot. To share a manual DB snapshot with other AWS accounts, specify restore as the AttributeName and use the ValuesToAdd parameter to add a list of IDs of the AWS accounts that are authorized to restore the manual DB snapshot. Uses the value all to make the manual DB snapshot public, which means it can be copied or restored by all AWS accounts. Don&#39;t add the all value for any manual DB snapshots that contain private information that you don&#39;t want available to all AWS accounts. If the manual DB snapshot is encrypted, it can be shared, but only by specifying a list of authorized AWS account IDs for the ValuesToAdd parameter. You can&#39;t use all as a value for that parameter in this case. To view which AWS accounts have access to copy or restore a manual DB snapshot, or whether a manual DB snapshot public or private, use the DescribeDBSnapshotAttributes API action. The accounts are returned as values for the restore attribute."},{"ref":"AWS.RDS.html#modify_d_b_subnet_group/3","title":"AWS.RDS.modify_d_b_subnet_group/3","type":"function","doc":"Modifies an existing DB subnet group. DB subnet groups must contain at least one subnet in at least two AZs in the AWS Region."},{"ref":"AWS.RDS.html#modify_event_subscription/3","title":"AWS.RDS.modify_event_subscription/3","type":"function","doc":"Modifies an existing RDS event notification subscription. You can&#39;t modify the source identifiers using this call. To change source identifiers for a subscription, use the AddSourceIdentifierToSubscription and RemoveSourceIdentifierFromSubscription calls. You can see a list of the event categories for a given source type (SourceType) in Events in the Amazon RDS User Guide or by using the DescribeEventCategories operation."},{"ref":"AWS.RDS.html#modify_global_cluster/3","title":"AWS.RDS.modify_global_cluster/3","type":"function","doc":"Modify a setting for an Amazon Aurora global cluster. You can change one or more database configuration parameters by specifying these parameters and the new values in the request. For more information on Amazon Aurora, see What Is Amazon Aurora? in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#modify_option_group/3","title":"AWS.RDS.modify_option_group/3","type":"function","doc":"Modifies an existing option group."},{"ref":"AWS.RDS.html#promote_read_replica/3","title":"AWS.RDS.promote_read_replica/3","type":"function","doc":"Promotes a read replica DB instance to a standalone DB instance. Backup duration is a function of the amount of changes to the database since the previous backup. If you plan to promote a read replica to a standalone instance, we recommend that you enable backups and complete at least one backup prior to promotion. In addition, a read replica cannot be promoted to a standalone instance when it is in the backing-up status. If you have enabled backups on your read replica, configure the automated backup window so that daily backups do not interfere with read replica promotion. This command doesn&#39;t apply to Aurora MySQL and Aurora PostgreSQL."},{"ref":"AWS.RDS.html#promote_read_replica_d_b_cluster/3","title":"AWS.RDS.promote_read_replica_d_b_cluster/3","type":"function","doc":"Promotes a read replica DB cluster to a standalone DB cluster. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#purchase_reserved_d_b_instances_offering/3","title":"AWS.RDS.purchase_reserved_d_b_instances_offering/3","type":"function","doc":"Purchases a reserved DB instance offering."},{"ref":"AWS.RDS.html#reboot_d_b_instance/3","title":"AWS.RDS.reboot_d_b_instance/3","type":"function","doc":"You might need to reboot your DB instance, usually for maintenance reasons. For example, if you make certain modifications, or if you change the DB parameter group associated with the DB instance, you must reboot the instance for the changes to take effect. Rebooting a DB instance restarts the database engine service. Rebooting a DB instance results in a momentary outage, during which the DB instance status is set to rebooting. For more information about rebooting, see Rebooting a DB Instance in the Amazon RDS User Guide."},{"ref":"AWS.RDS.html#register_d_b_proxy_targets/3","title":"AWS.RDS.register_d_b_proxy_targets/3","type":"function","doc":"Associate one or more DBProxyTarget data structures with a DBProxyTargetGroup."},{"ref":"AWS.RDS.html#remove_from_global_cluster/3","title":"AWS.RDS.remove_from_global_cluster/3","type":"function","doc":"Detaches an Aurora secondary cluster from an Aurora global database cluster. The cluster becomes a standalone cluster with read-write capability instead of being read-only and receiving data from a primary cluster in a different region. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#remove_role_from_d_b_cluster/3","title":"AWS.RDS.remove_role_from_d_b_cluster/3","type":"function","doc":"Disassociates an AWS Identity and Access Management (IAM) role from an Amazon Aurora DB cluster. For more information, see Authorizing Amazon Aurora MySQL to Access Other AWS Services on Your Behalf in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#remove_role_from_d_b_instance/3","title":"AWS.RDS.remove_role_from_d_b_instance/3","type":"function","doc":"Disassociates an AWS Identity and Access Management (IAM) role from a DB instance."},{"ref":"AWS.RDS.html#remove_source_identifier_from_subscription/3","title":"AWS.RDS.remove_source_identifier_from_subscription/3","type":"function","doc":"Removes a source identifier from an existing RDS event notification subscription."},{"ref":"AWS.RDS.html#remove_tags_from_resource/3","title":"AWS.RDS.remove_tags_from_resource/3","type":"function","doc":"Removes metadata tags from an Amazon RDS resource. For an overview on tagging an Amazon RDS resource, see Tagging Amazon RDS Resources in the Amazon RDS User Guide."},{"ref":"AWS.RDS.html#reset_d_b_cluster_parameter_group/3","title":"AWS.RDS.reset_d_b_cluster_parameter_group/3","type":"function","doc":"Modifies the parameters of a DB cluster parameter group to the default value. To reset specific parameters submit a list of the following: ParameterName and ApplyMethod. To reset the entire DB cluster parameter group, specify the DBClusterParameterGroupName and ResetAllParameters parameters. When resetting the entire group, dynamic parameters are updated immediately and static parameters are set to pending-reboot to take effect on the next DB instance restart or RebootDBInstance request. You must call RebootDBInstance for every DB instance in your DB cluster that you want the updated static parameter to apply to. For more information on Amazon Aurora, see What Is Amazon Aurora? in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#reset_d_b_parameter_group/3","title":"AWS.RDS.reset_d_b_parameter_group/3","type":"function","doc":"Modifies the parameters of a DB parameter group to the engine/system default value. To reset specific parameters, provide a list of the following: ParameterName and ApplyMethod. To reset the entire DB parameter group, specify the DBParameterGroup name and ResetAllParameters parameters. When resetting the entire group, dynamic parameters are updated immediately and static parameters are set to pending-reboot to take effect on the next DB instance restart or RebootDBInstance request."},{"ref":"AWS.RDS.html#restore_d_b_cluster_from_s3/3","title":"AWS.RDS.restore_d_b_cluster_from_s3/3","type":"function","doc":"Creates an Amazon Aurora DB cluster from MySQL data stored in an Amazon S3 bucket. Amazon RDS must be authorized to access the Amazon S3 bucket and the data must be created using the Percona XtraBackup utility as described in Migrating Data from MySQL by Using an Amazon S3 Bucket in the Amazon Aurora User Guide. This action only restores the DB cluster, not the DB instances for that DB cluster. You must invoke the CreateDBInstance action to create DB instances for the restored DB cluster, specifying the identifier of the restored DB cluster in DBClusterIdentifier. You can create DB instances only after the RestoreDBClusterFromS3 action has completed and the DB cluster is available. For more information on Amazon Aurora, see What Is Amazon Aurora? in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters. The source DB engine must be MySQL."},{"ref":"AWS.RDS.html#restore_d_b_cluster_from_snapshot/3","title":"AWS.RDS.restore_d_b_cluster_from_snapshot/3","type":"function","doc":"Creates a new DB cluster from a DB snapshot or DB cluster snapshot. This action only applies to Aurora DB clusters. The target DB cluster is created from the source snapshot with a default configuration. If you don&#39;t specify a security group, the new DB cluster is associated with the default security group. This action only restores the DB cluster, not the DB instances for that DB cluster. You must invoke the CreateDBInstance action to create DB instances for the restored DB cluster, specifying the identifier of the restored DB cluster in DBClusterIdentifier. You can create DB instances only after the RestoreDBClusterFromSnapshot action has completed and the DB cluster is available. For more information on Amazon Aurora, see What Is Amazon Aurora? in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#restore_d_b_cluster_to_point_in_time/3","title":"AWS.RDS.restore_d_b_cluster_to_point_in_time/3","type":"function","doc":"Restores a DB cluster to an arbitrary point in time. Users can restore to any point in time before LatestRestorableTime for up to BackupRetentionPeriod days. The target DB cluster is created from the source DB cluster with the same configuration as the original DB cluster, except that the new DB cluster is created with the default DB security group. This action only restores the DB cluster, not the DB instances for that DB cluster. You must invoke the CreateDBInstance action to create DB instances for the restored DB cluster, specifying the identifier of the restored DB cluster in DBClusterIdentifier. You can create DB instances only after the RestoreDBClusterToPointInTime action has completed and the DB cluster is available. For more information on Amazon Aurora, see What Is Amazon Aurora? in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#restore_d_b_instance_from_d_b_snapshot/3","title":"AWS.RDS.restore_d_b_instance_from_d_b_snapshot/3","type":"function","doc":"Creates a new DB instance from a DB snapshot. The target database is created from the source database restore point with the most of original configuration with the default security group and the default DB parameter group. By default, the new DB instance is created as a single-AZ deployment except when the instance is a SQL Server instance that has an option group that is associated with mirroring; in this case, the instance becomes a mirrored AZ deployment and not a single-AZ deployment. If your intent is to replace your original DB instance with the new, restored DB instance, then rename your original DB instance before you call the RestoreDBInstanceFromDBSnapshot action. RDS doesn&#39;t allow two DB instances with the same name. Once you have renamed your original DB instance with a different identifier, then you can pass the original name of the DB instance as the DBInstanceIdentifier in the call to the RestoreDBInstanceFromDBSnapshot action. The result is that you will replace the original DB instance with the DB instance created from the snapshot. If you are restoring from a shared manual DB snapshot, the DBSnapshotIdentifier must be the ARN of the shared DB snapshot. This command doesn&#39;t apply to Aurora MySQL and Aurora PostgreSQL. For Aurora, use RestoreDBClusterFromSnapshot."},{"ref":"AWS.RDS.html#restore_d_b_instance_from_s3/3","title":"AWS.RDS.restore_d_b_instance_from_s3/3","type":"function","doc":"Amazon Relational Database Service (Amazon RDS) supports importing MySQL databases by using backup files. You can create a backup of your on-premises database, store it on Amazon Simple Storage Service (Amazon S3), and then restore the backup file onto a new Amazon RDS DB instance running MySQL. For more information, see Importing Data into an Amazon RDS MySQL DB Instance in the Amazon RDS User Guide."},{"ref":"AWS.RDS.html#restore_d_b_instance_to_point_in_time/3","title":"AWS.RDS.restore_d_b_instance_to_point_in_time/3","type":"function","doc":"Restores a DB instance to an arbitrary point in time. You can restore to any point in time before the time identified by the LatestRestorableTime property. You can restore to a point up to the number of days specified by the BackupRetentionPeriod property. The target database is created with most of the original configuration, but in a system-selected Availability Zone, with the default security group, the default subnet group, and the default DB parameter group. By default, the new DB instance is created as a single-AZ deployment except when the instance is a SQL Server instance that has an option group that is associated with mirroring; in this case, the instance becomes a mirrored deployment and not a single-AZ deployment. This command doesn&#39;t apply to Aurora MySQL and Aurora PostgreSQL. For Aurora, use RestoreDBClusterToPointInTime."},{"ref":"AWS.RDS.html#revoke_d_b_security_group_ingress/3","title":"AWS.RDS.revoke_d_b_security_group_ingress/3","type":"function","doc":"Revokes ingress from a DBSecurityGroup for previously authorized IP ranges or EC2 or VPC Security Groups. Required parameters for this API are one of CIDRIP, EC2SecurityGroupId for VPC, or (EC2SecurityGroupOwnerId and either EC2SecurityGroupName or EC2SecurityGroupId)."},{"ref":"AWS.RDS.html#start_activity_stream/3","title":"AWS.RDS.start_activity_stream/3","type":"function","doc":"Starts a database activity stream to monitor activity on the database. For more information, see Database Activity Streams in the Amazon Aurora User Guide."},{"ref":"AWS.RDS.html#start_d_b_cluster/3","title":"AWS.RDS.start_d_b_cluster/3","type":"function","doc":"Starts an Amazon Aurora DB cluster that was stopped using the AWS console, the stop-db-cluster AWS CLI command, or the StopDBCluster action. For more information, see Stopping and Starting an Aurora Cluster in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#start_d_b_instance/3","title":"AWS.RDS.start_d_b_instance/3","type":"function","doc":"Starts an Amazon RDS DB instance that was stopped using the AWS console, the stop-db-instance AWS CLI command, or the StopDBInstance action. For more information, see Starting an Amazon RDS DB instance That Was Previously Stopped in the Amazon RDS User Guide. This command doesn&#39;t apply to Aurora MySQL and Aurora PostgreSQL. For Aurora DB clusters, use StartDBCluster instead."},{"ref":"AWS.RDS.html#start_export_task/3","title":"AWS.RDS.start_export_task/3","type":"function","doc":"Starts an export of a snapshot to Amazon S3. The provided IAM role must have access to the S3 bucket."},{"ref":"AWS.RDS.html#stop_activity_stream/3","title":"AWS.RDS.stop_activity_stream/3","type":"function","doc":"Stops a database activity stream that was started using the AWS console, the start-activity-stream AWS CLI command, or the StartActivityStream action. For more information, see Database Activity Streams in the Amazon Aurora User Guide."},{"ref":"AWS.RDS.html#stop_d_b_cluster/3","title":"AWS.RDS.stop_d_b_cluster/3","type":"function","doc":"Stops an Amazon Aurora DB cluster. When you stop a DB cluster, Aurora retains the DB cluster&#39;s metadata, including its endpoints and DB parameter groups. Aurora also retains the transaction logs so you can do a point-in-time restore if necessary. For more information, see Stopping and Starting an Aurora Cluster in the Amazon Aurora User Guide. This action only applies to Aurora DB clusters."},{"ref":"AWS.RDS.html#stop_d_b_instance/3","title":"AWS.RDS.stop_d_b_instance/3","type":"function","doc":"Stops an Amazon RDS DB instance. When you stop a DB instance, Amazon RDS retains the DB instance&#39;s metadata, including its endpoint, DB parameter group, and option group membership. Amazon RDS also retains the transaction logs so you can do a point-in-time restore if necessary. For more information, see Stopping an Amazon RDS DB Instance Temporarily in the Amazon RDS User Guide. This command doesn&#39;t apply to Aurora MySQL and Aurora PostgreSQL. For Aurora clusters, use StopDBCluster instead."},{"ref":"AWS.RDSData.html","title":"AWS.RDSData","type":"module","doc":"Amazon RDS Data Service Amazon RDS provides an HTTP endpoint to run SQL statements on an Amazon Aurora Serverless DB cluster. To run these statements, you work with the Data Service API. For more information about the Data Service API, see Using the Data API for Aurora Serverless in the Amazon Aurora User Guide. If you have questions or comments related to the Data API, send email to Rds-data-api-feedback@amazon.com."},{"ref":"AWS.RDSData.html#batch_execute_statement/3","title":"AWS.RDSData.batch_execute_statement/3","type":"function","doc":"Runs a batch SQL statement over an array of data. You can run bulk update and insert operations for multiple records using a DML statement with different parameter sets. Bulk operations can provide a significant performance improvement over individual insert and update operations. If a call isn&#39;t part of a transaction because it doesn&#39;t include the transactionID parameter, changes that result from the call are committed automatically."},{"ref":"AWS.RDSData.html#begin_transaction/3","title":"AWS.RDSData.begin_transaction/3","type":"function","doc":"Starts a SQL transaction. A transaction can run for a maximum of 24 hours. A transaction is terminated and rolled back automatically after 24 hours. A transaction times out if no calls use its transaction ID in three minutes. If a transaction times out before it&#39;s committed, it&#39;s rolled back automatically. DDL statements inside a transaction cause an implicit commit. We recommend that you run each DDL statement in a separateExecuteStatementcall withcontinueAfterTimeoutenabled."},{"ref":"AWS.RDSData.html#commit_transaction/3","title":"AWS.RDSData.commit_transaction/3","type":"function","doc":"Ends a SQL transaction started with the BeginTransaction operation and commits the changes."},{"ref":"AWS.RDSData.html#execute_sql/3","title":"AWS.RDSData.execute_sql/3","type":"function","doc":"Runs one or more SQL statements. This operation is deprecated. Use the BatchExecuteStatement or ExecuteStatement operation."},{"ref":"AWS.RDSData.html#execute_statement/3","title":"AWS.RDSData.execute_statement/3","type":"function","doc":"Runs a SQL statement against a database. If a call isn&#39;t part of a transaction because it doesn&#39;t include the transactionID parameter, changes that result from the call are committed automatically. The response size limit is 1 MB. If the call returns more than 1 MB of response data, the call is terminated."},{"ref":"AWS.RDSData.html#rollback_transaction/3","title":"AWS.RDSData.rollback_transaction/3","type":"function","doc":"Performs a rollback of a transaction. Rolling back a transaction cancels its changes."},{"ref":"AWS.Redshift.html","title":"AWS.Redshift","type":"module","doc":"Amazon Redshift Overview This is an interface reference for Amazon Redshift. It contains documentation for one of the programming or command line interfaces you can use to manage Amazon Redshift clusters. Note that Amazon Redshift is asynchronous, which means that some interfaces may require techniques, such as polling or asynchronous callback handlers, to determine when a command has been applied. In this reference, the parameter descriptions indicate whether a change is applied immediately, on the next instance reboot, or during the next maintenance window. For a summary of the Amazon Redshift cluster management interfaces, go to Using the Amazon Redshift Management Interfaces. Amazon Redshift manages all the work of setting up, operating, and scaling a data warehouse: provisioning capacity, monitoring and backing up the cluster, and applying patches and upgrades to the Amazon Redshift engine. You can focus on using your data to acquire new insights for your business and customers. If you are a first-time user of Amazon Redshift, we recommend that you begin by reading the Amazon Redshift Getting Started Guide. If you are a database developer, the Amazon Redshift Database Developer Guide explains how to design, build, query, and maintain the databases that make up your data warehouse."},{"ref":"AWS.Redshift.html#accept_reserved_node_exchange/3","title":"AWS.Redshift.accept_reserved_node_exchange/3","type":"function","doc":"Exchanges a DC1 Reserved Node for a DC2 Reserved Node with no changes to the configuration (term, payment type, or number of nodes) and no additional costs."},{"ref":"AWS.Redshift.html#authorize_cluster_security_group_ingress/3","title":"AWS.Redshift.authorize_cluster_security_group_ingress/3","type":"function","doc":"Adds an inbound (ingress) rule to an Amazon Redshift security group. Depending on whether the application accessing your cluster is running on the Internet or an Amazon EC2 instance, you can authorize inbound access to either a Classless Interdomain Routing (CIDR)/Internet Protocol (IP) range or to an Amazon EC2 security group. You can add as many as 20 ingress rules to an Amazon Redshift security group. If you authorize access to an Amazon EC2 security group, specify EC2SecurityGroupName and EC2SecurityGroupOwnerId. The Amazon EC2 security group and Amazon Redshift cluster must be in the same AWS Region. If you authorize access to a CIDR/IP address range, specify CIDRIP. For an overview of CIDR blocks, see the Wikipedia article on Classless Inter-Domain Routing. You must also associate the security group with a cluster so that clients running on these IP addresses or the EC2 instance are authorized to connect to the cluster. For information about managing security groups, go to Working with Security Groups in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#authorize_snapshot_access/3","title":"AWS.Redshift.authorize_snapshot_access/3","type":"function","doc":"Authorizes the specified AWS customer account to restore the specified snapshot. For more information about working with snapshots, go to Amazon Redshift Snapshots in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#batch_delete_cluster_snapshots/3","title":"AWS.Redshift.batch_delete_cluster_snapshots/3","type":"function","doc":"Deletes a set of cluster snapshots."},{"ref":"AWS.Redshift.html#batch_modify_cluster_snapshots/3","title":"AWS.Redshift.batch_modify_cluster_snapshots/3","type":"function","doc":"Modifies the settings for a set of cluster snapshots."},{"ref":"AWS.Redshift.html#cancel_resize/3","title":"AWS.Redshift.cancel_resize/3","type":"function","doc":"Cancels a resize operation for a cluster."},{"ref":"AWS.Redshift.html#copy_cluster_snapshot/3","title":"AWS.Redshift.copy_cluster_snapshot/3","type":"function","doc":"Copies the specified automated cluster snapshot to a new manual cluster snapshot. The source must be an automated snapshot and it must be in the available state. When you delete a cluster, Amazon Redshift deletes any automated snapshots of the cluster. Also, when the retention period of the snapshot expires, Amazon Redshift automatically deletes it. If you want to keep an automated snapshot for a longer period, you can make a manual copy of the snapshot. Manual snapshots are retained until you delete them. For more information about working with snapshots, go to Amazon Redshift Snapshots in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#create_cluster/3","title":"AWS.Redshift.create_cluster/3","type":"function","doc":"Creates a new cluster with the specified parameters. To create a cluster in Virtual Private Cloud (VPC), you must provide a cluster subnet group name. The cluster subnet group identifies the subnets of your VPC that Amazon Redshift uses when creating the cluster. For more information about managing clusters, go to Amazon Redshift Clusters in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#create_cluster_parameter_group/3","title":"AWS.Redshift.create_cluster_parameter_group/3","type":"function","doc":"Creates an Amazon Redshift parameter group. Creating parameter groups is independent of creating clusters. You can associate a cluster with a parameter group when you create the cluster. You can also associate an existing cluster with a parameter group after the cluster is created by using ModifyCluster. Parameters in the parameter group define specific behavior that applies to the databases you create on the cluster. For more information about parameters and parameter groups, go to Amazon Redshift Parameter Groups in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#create_cluster_security_group/3","title":"AWS.Redshift.create_cluster_security_group/3","type":"function","doc":"Creates a new Amazon Redshift security group. You use security groups to control access to non-VPC clusters. For information about managing security groups, go to Amazon Redshift Cluster Security Groups in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#create_cluster_snapshot/3","title":"AWS.Redshift.create_cluster_snapshot/3","type":"function","doc":"Creates a manual snapshot of the specified cluster. The cluster must be in the available state. For more information about working with snapshots, go to Amazon Redshift Snapshots in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#create_cluster_subnet_group/3","title":"AWS.Redshift.create_cluster_subnet_group/3","type":"function","doc":"Creates a new Amazon Redshift subnet group. You must provide a list of one or more subnets in your existing Amazon Virtual Private Cloud (Amazon VPC) when creating Amazon Redshift subnet group. For information about subnet groups, go to Amazon Redshift Cluster Subnet Groups in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#create_event_subscription/3","title":"AWS.Redshift.create_event_subscription/3","type":"function","doc":"Creates an Amazon Redshift event notification subscription. This action requires an ARN (Amazon Resource Name) of an Amazon SNS topic created by either the Amazon Redshift console, the Amazon SNS console, or the Amazon SNS API. To obtain an ARN with Amazon SNS, you must create a topic in Amazon SNS and subscribe to the topic. The ARN is displayed in the SNS console. You can specify the source type, and lists of Amazon Redshift source IDs, event categories, and event severities. Notifications will be sent for all events you want that match those criteria. For example, you can specify source type = cluster, source ID = my-cluster-1 and mycluster2, event categories = Availability, Backup, and severity = ERROR. The subscription will only send notifications for those ERROR events in the Availability and Backup categories for the specified clusters. If you specify both the source type and source IDs, such as source type = cluster and source identifier = my-cluster-1, notifications will be sent for all the cluster events for my-cluster-1. If you specify a source type but do not specify a source identifier, you will receive notice of the events for the objects of that type in your AWS account. If you do not specify either the SourceType nor the SourceIdentifier, you will be notified of events generated from all Amazon Redshift sources belonging to your AWS account. You must specify a source type if you specify a source ID."},{"ref":"AWS.Redshift.html#create_hsm_client_certificate/3","title":"AWS.Redshift.create_hsm_client_certificate/3","type":"function","doc":"Creates an HSM client certificate that an Amazon Redshift cluster will use to connect to the client&#39;s HSM in order to store and retrieve the keys used to encrypt the cluster databases. The command returns a public key, which you must store in the HSM. In addition to creating the HSM certificate, you must create an Amazon Redshift HSM configuration that provides a cluster the information needed to store and use encryption keys in the HSM. For more information, go to Hardware Security Modules in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#create_hsm_configuration/3","title":"AWS.Redshift.create_hsm_configuration/3","type":"function","doc":"Creates an HSM configuration that contains the information required by an Amazon Redshift cluster to store and use database encryption keys in a Hardware Security Module (HSM). After creating the HSM configuration, you can specify it as a parameter when creating a cluster. The cluster will then store its encryption keys in the HSM. In addition to creating an HSM configuration, you must also create an HSM client certificate. For more information, go to Hardware Security Modules in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#create_scheduled_action/3","title":"AWS.Redshift.create_scheduled_action/3","type":"function","doc":"Creates a scheduled action. A scheduled action contains a schedule and an Amazon Redshift API action. For example, you can create a schedule of when to run the ResizeCluster API operation."},{"ref":"AWS.Redshift.html#create_snapshot_copy_grant/3","title":"AWS.Redshift.create_snapshot_copy_grant/3","type":"function","doc":"Creates a snapshot copy grant that permits Amazon Redshift to use a customer master key (CMK) from AWS Key Management Service (AWS KMS) to encrypt copied snapshots in a destination region. For more information about managing snapshot copy grants, go to Amazon Redshift Database Encryption in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#create_snapshot_schedule/3","title":"AWS.Redshift.create_snapshot_schedule/3","type":"function","doc":"Create a snapshot schedule that can be associated to a cluster and which overrides the default system backup schedule."},{"ref":"AWS.Redshift.html#create_tags/3","title":"AWS.Redshift.create_tags/3","type":"function","doc":"Adds tags to a cluster. A resource can have up to 50 tags. If you try to create more than 50 tags for a resource, you will receive an error and the attempt will fail. If you specify a key that already exists for the resource, the value for that key will be updated with the new value."},{"ref":"AWS.Redshift.html#create_usage_limit/3","title":"AWS.Redshift.create_usage_limit/3","type":"function","doc":"Creates a usage limit for a specified Amazon Redshift feature on a cluster. The usage limit is identified by the returned usage limit identifier."},{"ref":"AWS.Redshift.html#delete_cluster/3","title":"AWS.Redshift.delete_cluster/3","type":"function","doc":"Deletes a previously provisioned cluster without its final snapshot being created. A successful response from the web service indicates that the request was received correctly. Use DescribeClusters to monitor the status of the deletion. The delete operation cannot be canceled or reverted once submitted. For more information about managing clusters, go to Amazon Redshift Clusters in the Amazon Redshift Cluster Management Guide. If you want to shut down the cluster and retain it for future use, set SkipFinalClusterSnapshot to false and specify a name for FinalClusterSnapshotIdentifier. You can later restore this snapshot to resume using the cluster. If a final cluster snapshot is requested, the status of the cluster will be &quot;final-snapshot&quot; while the snapshot is being taken, then it&#39;s &quot;deleting&quot; once Amazon Redshift begins deleting the cluster. For more information about managing clusters, go to Amazon Redshift Clusters in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#delete_cluster_parameter_group/3","title":"AWS.Redshift.delete_cluster_parameter_group/3","type":"function","doc":"Deletes a specified Amazon Redshift parameter group. You cannot delete a parameter group if it is associated with a cluster."},{"ref":"AWS.Redshift.html#delete_cluster_security_group/3","title":"AWS.Redshift.delete_cluster_security_group/3","type":"function","doc":"Deletes an Amazon Redshift security group. You cannot delete a security group that is associated with any clusters. You cannot delete the default security group. For information about managing security groups, go to Amazon Redshift Cluster Security Groups in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#delete_cluster_snapshot/3","title":"AWS.Redshift.delete_cluster_snapshot/3","type":"function","doc":"Deletes the specified manual snapshot. The snapshot must be in the available state, with no other users authorized to access the snapshot. Unlike automated snapshots, manual snapshots are retained even after you delete your cluster. Amazon Redshift does not delete your manual snapshots. You must delete manual snapshot explicitly to avoid getting charged. If other accounts are authorized to access the snapshot, you must revoke all of the authorizations before you can delete the snapshot."},{"ref":"AWS.Redshift.html#delete_cluster_subnet_group/3","title":"AWS.Redshift.delete_cluster_subnet_group/3","type":"function","doc":"Deletes the specified cluster subnet group."},{"ref":"AWS.Redshift.html#delete_event_subscription/3","title":"AWS.Redshift.delete_event_subscription/3","type":"function","doc":"Deletes an Amazon Redshift event notification subscription."},{"ref":"AWS.Redshift.html#delete_hsm_client_certificate/3","title":"AWS.Redshift.delete_hsm_client_certificate/3","type":"function","doc":"Deletes the specified HSM client certificate."},{"ref":"AWS.Redshift.html#delete_hsm_configuration/3","title":"AWS.Redshift.delete_hsm_configuration/3","type":"function","doc":"Deletes the specified Amazon Redshift HSM configuration."},{"ref":"AWS.Redshift.html#delete_scheduled_action/3","title":"AWS.Redshift.delete_scheduled_action/3","type":"function","doc":"Deletes a scheduled action."},{"ref":"AWS.Redshift.html#delete_snapshot_copy_grant/3","title":"AWS.Redshift.delete_snapshot_copy_grant/3","type":"function","doc":"Deletes the specified snapshot copy grant."},{"ref":"AWS.Redshift.html#delete_snapshot_schedule/3","title":"AWS.Redshift.delete_snapshot_schedule/3","type":"function","doc":"Deletes a snapshot schedule."},{"ref":"AWS.Redshift.html#delete_tags/3","title":"AWS.Redshift.delete_tags/3","type":"function","doc":"Deletes tags from a resource. You must provide the ARN of the resource from which you want to delete the tag or tags."},{"ref":"AWS.Redshift.html#delete_usage_limit/3","title":"AWS.Redshift.delete_usage_limit/3","type":"function","doc":"Deletes a usage limit from a cluster."},{"ref":"AWS.Redshift.html#describe_account_attributes/3","title":"AWS.Redshift.describe_account_attributes/3","type":"function","doc":"Returns a list of attributes attached to an account"},{"ref":"AWS.Redshift.html#describe_cluster_db_revisions/3","title":"AWS.Redshift.describe_cluster_db_revisions/3","type":"function","doc":"Returns an array of ClusterDbRevision objects."},{"ref":"AWS.Redshift.html#describe_cluster_parameter_groups/3","title":"AWS.Redshift.describe_cluster_parameter_groups/3","type":"function","doc":"Returns a list of Amazon Redshift parameter groups, including parameter groups you created and the default parameter group. For each parameter group, the response includes the parameter group name, description, and parameter group family name. You can optionally specify a name to retrieve the description of a specific parameter group. For more information about parameters and parameter groups, go to Amazon Redshift Parameter Groups in the Amazon Redshift Cluster Management Guide. If you specify both tag keys and tag values in the same request, Amazon Redshift returns all parameter groups that match any combination of the specified keys and values. For example, if you have owner and environment for tag keys, and admin and test for tag values, all parameter groups that have any combination of those values are returned. If both tag keys and values are omitted from the request, parameter groups are returned regardless of whether they have tag keys or values associated with them."},{"ref":"AWS.Redshift.html#describe_cluster_parameters/3","title":"AWS.Redshift.describe_cluster_parameters/3","type":"function","doc":"Returns a detailed list of parameters contained within the specified Amazon Redshift parameter group. For each parameter the response includes information such as parameter name, description, data type, value, whether the parameter value is modifiable, and so on. You can specify source filter to retrieve parameters of only specific type. For example, to retrieve parameters that were modified by a user action such as from ModifyClusterParameterGroup, you can specify source equal to user. For more information about parameters and parameter groups, go to Amazon Redshift Parameter Groups in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#describe_cluster_security_groups/3","title":"AWS.Redshift.describe_cluster_security_groups/3","type":"function","doc":"Returns information about Amazon Redshift security groups. If the name of a security group is specified, the response will contain only information about only that security group. For information about managing security groups, go to Amazon Redshift Cluster Security Groups in the Amazon Redshift Cluster Management Guide. If you specify both tag keys and tag values in the same request, Amazon Redshift returns all security groups that match any combination of the specified keys and values. For example, if you have owner and environment for tag keys, and admin and test for tag values, all security groups that have any combination of those values are returned. If both tag keys and values are omitted from the request, security groups are returned regardless of whether they have tag keys or values associated with them."},{"ref":"AWS.Redshift.html#describe_cluster_snapshots/3","title":"AWS.Redshift.describe_cluster_snapshots/3","type":"function","doc":"Returns one or more snapshot objects, which contain metadata about your cluster snapshots. By default, this operation returns information about all snapshots of all clusters that are owned by you AWS customer account. No information is returned for snapshots owned by inactive AWS customer accounts. If you specify both tag keys and tag values in the same request, Amazon Redshift returns all snapshots that match any combination of the specified keys and values. For example, if you have owner and environment for tag keys, and admin and test for tag values, all snapshots that have any combination of those values are returned. Only snapshots that you own are returned in the response; shared snapshots are not returned with the tag key and tag value request parameters. If both tag keys and values are omitted from the request, snapshots are returned regardless of whether they have tag keys or values associated with them."},{"ref":"AWS.Redshift.html#describe_cluster_subnet_groups/3","title":"AWS.Redshift.describe_cluster_subnet_groups/3","type":"function","doc":"Returns one or more cluster subnet group objects, which contain metadata about your cluster subnet groups. By default, this operation returns information about all cluster subnet groups that are defined in you AWS account. If you specify both tag keys and tag values in the same request, Amazon Redshift returns all subnet groups that match any combination of the specified keys and values. For example, if you have owner and environment for tag keys, and admin and test for tag values, all subnet groups that have any combination of those values are returned. If both tag keys and values are omitted from the request, subnet groups are returned regardless of whether they have tag keys or values associated with them."},{"ref":"AWS.Redshift.html#describe_cluster_tracks/3","title":"AWS.Redshift.describe_cluster_tracks/3","type":"function","doc":"Returns a list of all the available maintenance tracks."},{"ref":"AWS.Redshift.html#describe_cluster_versions/3","title":"AWS.Redshift.describe_cluster_versions/3","type":"function","doc":"Returns descriptions of the available Amazon Redshift cluster versions. You can call this operation even before creating any clusters to learn more about the Amazon Redshift versions. For more information about managing clusters, go to Amazon Redshift Clusters in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#describe_clusters/3","title":"AWS.Redshift.describe_clusters/3","type":"function","doc":"Returns properties of provisioned clusters including general cluster properties, cluster database properties, maintenance and backup properties, and security and access properties. This operation supports pagination. For more information about managing clusters, go to Amazon Redshift Clusters in the Amazon Redshift Cluster Management Guide. If you specify both tag keys and tag values in the same request, Amazon Redshift returns all clusters that match any combination of the specified keys and values. For example, if you have owner and environment for tag keys, and admin and test for tag values, all clusters that have any combination of those values are returned. If both tag keys and values are omitted from the request, clusters are returned regardless of whether they have tag keys or values associated with them."},{"ref":"AWS.Redshift.html#describe_default_cluster_parameters/3","title":"AWS.Redshift.describe_default_cluster_parameters/3","type":"function","doc":"Returns a list of parameter settings for the specified parameter group family. For more information about parameters and parameter groups, go to Amazon Redshift Parameter Groups in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#describe_event_categories/3","title":"AWS.Redshift.describe_event_categories/3","type":"function","doc":"Displays a list of event categories for all event source types, or for a specified source type. For a list of the event categories and source types, go to Amazon Redshift Event Notifications."},{"ref":"AWS.Redshift.html#describe_event_subscriptions/3","title":"AWS.Redshift.describe_event_subscriptions/3","type":"function","doc":"Lists descriptions of all the Amazon Redshift event notification subscriptions for a customer account. If you specify a subscription name, lists the description for that subscription. If you specify both tag keys and tag values in the same request, Amazon Redshift returns all event notification subscriptions that match any combination of the specified keys and values. For example, if you have owner and environment for tag keys, and admin and test for tag values, all subscriptions that have any combination of those values are returned. If both tag keys and values are omitted from the request, subscriptions are returned regardless of whether they have tag keys or values associated with them."},{"ref":"AWS.Redshift.html#describe_events/3","title":"AWS.Redshift.describe_events/3","type":"function","doc":"Returns events related to clusters, security groups, snapshots, and parameter groups for the past 14 days. Events specific to a particular cluster, security group, snapshot or parameter group can be obtained by providing the name as a parameter. By default, the past hour of events are returned."},{"ref":"AWS.Redshift.html#describe_hsm_client_certificates/3","title":"AWS.Redshift.describe_hsm_client_certificates/3","type":"function","doc":"Returns information about the specified HSM client certificate. If no certificate ID is specified, returns information about all the HSM certificates owned by your AWS customer account. If you specify both tag keys and tag values in the same request, Amazon Redshift returns all HSM client certificates that match any combination of the specified keys and values. For example, if you have owner and environment for tag keys, and admin and test for tag values, all HSM client certificates that have any combination of those values are returned. If both tag keys and values are omitted from the request, HSM client certificates are returned regardless of whether they have tag keys or values associated with them."},{"ref":"AWS.Redshift.html#describe_hsm_configurations/3","title":"AWS.Redshift.describe_hsm_configurations/3","type":"function","doc":"Returns information about the specified Amazon Redshift HSM configuration. If no configuration ID is specified, returns information about all the HSM configurations owned by your AWS customer account. If you specify both tag keys and tag values in the same request, Amazon Redshift returns all HSM connections that match any combination of the specified keys and values. For example, if you have owner and environment for tag keys, and admin and test for tag values, all HSM connections that have any combination of those values are returned. If both tag keys and values are omitted from the request, HSM connections are returned regardless of whether they have tag keys or values associated with them."},{"ref":"AWS.Redshift.html#describe_logging_status/3","title":"AWS.Redshift.describe_logging_status/3","type":"function","doc":"Describes whether information, such as queries and connection attempts, is being logged for the specified Amazon Redshift cluster."},{"ref":"AWS.Redshift.html#describe_node_configuration_options/3","title":"AWS.Redshift.describe_node_configuration_options/3","type":"function","doc":"Returns properties of possible node configurations such as node type, number of nodes, and disk usage for the specified action type."},{"ref":"AWS.Redshift.html#describe_orderable_cluster_options/3","title":"AWS.Redshift.describe_orderable_cluster_options/3","type":"function","doc":"Returns a list of orderable cluster options. Before you create a new cluster you can use this operation to find what options are available, such as the EC2 Availability Zones (AZ) in the specific AWS Region that you can specify, and the node types you can request. The node types differ by available storage, memory, CPU and price. With the cost involved you might want to obtain a list of cluster options in the specific region and specify values when creating a cluster. For more information about managing clusters, go to Amazon Redshift Clusters in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#describe_reserved_node_offerings/3","title":"AWS.Redshift.describe_reserved_node_offerings/3","type":"function","doc":"Returns a list of the available reserved node offerings by Amazon Redshift with their descriptions including the node type, the fixed and recurring costs of reserving the node and duration the node will be reserved for you. These descriptions help you determine which reserve node offering you want to purchase. You then use the unique offering ID in you call to PurchaseReservedNodeOffering to reserve one or more nodes for your Amazon Redshift cluster. For more information about reserved node offerings, go to Purchasing Reserved Nodes in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#describe_reserved_nodes/3","title":"AWS.Redshift.describe_reserved_nodes/3","type":"function","doc":"Returns the descriptions of the reserved nodes."},{"ref":"AWS.Redshift.html#describe_resize/3","title":"AWS.Redshift.describe_resize/3","type":"function","doc":"Returns information about the last resize operation for the specified cluster. If no resize operation has ever been initiated for the specified cluster, a HTTP 404 error is returned. If a resize operation was initiated and completed, the status of the resize remains as SUCCEEDED until the next resize. A resize operation can be requested using ModifyCluster and specifying a different number or type of nodes for the cluster."},{"ref":"AWS.Redshift.html#describe_scheduled_actions/3","title":"AWS.Redshift.describe_scheduled_actions/3","type":"function","doc":"Describes properties of scheduled actions."},{"ref":"AWS.Redshift.html#describe_snapshot_copy_grants/3","title":"AWS.Redshift.describe_snapshot_copy_grants/3","type":"function","doc":"Returns a list of snapshot copy grants owned by the AWS account in the destination region. For more information about managing snapshot copy grants, go to Amazon Redshift Database Encryption in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#describe_snapshot_schedules/3","title":"AWS.Redshift.describe_snapshot_schedules/3","type":"function","doc":"Returns a list of snapshot schedules."},{"ref":"AWS.Redshift.html#describe_storage/3","title":"AWS.Redshift.describe_storage/3","type":"function","doc":"Returns account level backups storage size and provisional storage."},{"ref":"AWS.Redshift.html#describe_table_restore_status/3","title":"AWS.Redshift.describe_table_restore_status/3","type":"function","doc":"Lists the status of one or more table restore requests made using the RestoreTableFromClusterSnapshot API action. If you don&#39;t specify a value for the TableRestoreRequestId parameter, then DescribeTableRestoreStatus returns the status of all table restore requests ordered by the date and time of the request in ascending order. Otherwise DescribeTableRestoreStatus returns the status of the table specified by TableRestoreRequestId."},{"ref":"AWS.Redshift.html#describe_tags/3","title":"AWS.Redshift.describe_tags/3","type":"function","doc":"Returns a list of tags. You can return tags from a specific resource by specifying an ARN, or you can return all tags for a given type of resource, such as clusters, snapshots, and so on. The following are limitations for DescribeTags: You cannot specify an ARN and a resource-type value together in the same request. You cannot use the MaxRecords and Marker parameters together with the ARN parameter. The MaxRecords parameter can be a range from 10 to 50 results to return in a request. If you specify both tag keys and tag values in the same request, Amazon Redshift returns all resources that match any combination of the specified keys and values. For example, if you have owner and environment for tag keys, and admin and test for tag values, all resources that have any combination of those values are returned. If both tag keys and values are omitted from the request, resources are returned regardless of whether they have tag keys or values associated with them."},{"ref":"AWS.Redshift.html#describe_usage_limits/3","title":"AWS.Redshift.describe_usage_limits/3","type":"function","doc":"Shows usage limits on a cluster. Results are filtered based on the combination of input usage limit identifier, cluster identifier, and feature type parameters: If usage limit identifier, cluster identifier, and feature type are not provided, then all usage limit objects for the current account in the current region are returned. If usage limit identifier is provided, then the corresponding usage limit object is returned. If cluster identifier is provided, then all usage limit objects for the specified cluster are returned. If cluster identifier and feature type are provided, then all usage limit objects for the combination of cluster and feature are returned."},{"ref":"AWS.Redshift.html#disable_logging/3","title":"AWS.Redshift.disable_logging/3","type":"function","doc":"Stops logging information, such as queries and connection attempts, for the specified Amazon Redshift cluster."},{"ref":"AWS.Redshift.html#disable_snapshot_copy/3","title":"AWS.Redshift.disable_snapshot_copy/3","type":"function","doc":"Disables the automatic copying of snapshots from one region to another region for a specified cluster. If your cluster and its snapshots are encrypted using a customer master key (CMK) from AWS KMS, use DeleteSnapshotCopyGrant to delete the grant that grants Amazon Redshift permission to the CMK in the destination region."},{"ref":"AWS.Redshift.html#enable_logging/3","title":"AWS.Redshift.enable_logging/3","type":"function","doc":"Starts logging information, such as queries and connection attempts, for the specified Amazon Redshift cluster."},{"ref":"AWS.Redshift.html#enable_snapshot_copy/3","title":"AWS.Redshift.enable_snapshot_copy/3","type":"function","doc":"Enables the automatic copy of snapshots from one region to another region for a specified cluster."},{"ref":"AWS.Redshift.html#get_cluster_credentials/3","title":"AWS.Redshift.get_cluster_credentials/3","type":"function","doc":"Returns a database user name and temporary password with temporary authorization to log on to an Amazon Redshift database. The action returns the database user name prefixed with IAM: if AutoCreate is False or IAMA: if AutoCreate is True. You can optionally specify one or more database user groups that the user will join at log on. By default, the temporary credentials expire in 900 seconds. You can optionally specify a duration between 900 seconds (15 minutes) and 3600 seconds (60 minutes). For more information, see Using IAM Authentication to Generate Database User Credentials in the Amazon Redshift Cluster Management Guide. The AWS Identity and Access Management (IAM)user or role that executes GetClusterCredentials must have an IAM policy attached that allows access to all necessary actions and resources. For more information about permissions, see Resource Policies for GetClusterCredentials in the Amazon Redshift Cluster Management Guide. If the DbGroups parameter is specified, the IAM policy must allow the redshift:JoinGroup action with access to the listed dbgroups. In addition, if the AutoCreate parameter is set to True, then the policy must include the redshift:CreateClusterUser privilege. If the DbName parameter is specified, the IAM policy must allow access to the resource dbname for the specified database name."},{"ref":"AWS.Redshift.html#get_reserved_node_exchange_offerings/3","title":"AWS.Redshift.get_reserved_node_exchange_offerings/3","type":"function","doc":"Returns an array of DC2 ReservedNodeOfferings that matches the payment type, term, and usage price of the given DC1 reserved node."},{"ref":"AWS.Redshift.html#modify_cluster/3","title":"AWS.Redshift.modify_cluster/3","type":"function","doc":"Modifies the settings for a cluster. You can also change node type and the number of nodes to scale up or down the cluster. When resizing a cluster, you must specify both the number of nodes and the node type even if one of the parameters does not change. You can add another security or parameter group, or change the master user password. Resetting a cluster password or modifying the security groups associated with a cluster do not need a reboot. However, modifying a parameter group requires a reboot for parameters to take effect. For more information about managing clusters, go to Amazon Redshift Clusters in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#modify_cluster_db_revision/3","title":"AWS.Redshift.modify_cluster_db_revision/3","type":"function","doc":"Modifies the database revision of a cluster. The database revision is a unique revision of the database running in a cluster."},{"ref":"AWS.Redshift.html#modify_cluster_iam_roles/3","title":"AWS.Redshift.modify_cluster_iam_roles/3","type":"function","doc":"Modifies the list of AWS Identity and Access Management (IAM) roles that can be used by the cluster to access other AWS services. A cluster can have up to 10 IAM roles associated at any time."},{"ref":"AWS.Redshift.html#modify_cluster_maintenance/3","title":"AWS.Redshift.modify_cluster_maintenance/3","type":"function","doc":"Modifies the maintenance settings of a cluster."},{"ref":"AWS.Redshift.html#modify_cluster_parameter_group/3","title":"AWS.Redshift.modify_cluster_parameter_group/3","type":"function","doc":"Modifies the parameters of a parameter group. For more information about parameters and parameter groups, go to Amazon Redshift Parameter Groups in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#modify_cluster_snapshot/3","title":"AWS.Redshift.modify_cluster_snapshot/3","type":"function","doc":"Modifies the settings for a snapshot. This exanmple modifies the manual retention period setting for a cluster snapshot."},{"ref":"AWS.Redshift.html#modify_cluster_snapshot_schedule/3","title":"AWS.Redshift.modify_cluster_snapshot_schedule/3","type":"function","doc":"Modifies a snapshot schedule for a cluster."},{"ref":"AWS.Redshift.html#modify_cluster_subnet_group/3","title":"AWS.Redshift.modify_cluster_subnet_group/3","type":"function","doc":"Modifies a cluster subnet group to include the specified list of VPC subnets. The operation replaces the existing list of subnets with the new list of subnets."},{"ref":"AWS.Redshift.html#modify_event_subscription/3","title":"AWS.Redshift.modify_event_subscription/3","type":"function","doc":"Modifies an existing Amazon Redshift event notification subscription."},{"ref":"AWS.Redshift.html#modify_scheduled_action/3","title":"AWS.Redshift.modify_scheduled_action/3","type":"function","doc":"Modifies a scheduled action."},{"ref":"AWS.Redshift.html#modify_snapshot_copy_retention_period/3","title":"AWS.Redshift.modify_snapshot_copy_retention_period/3","type":"function","doc":"Modifies the number of days to retain snapshots in the destination AWS Region after they are copied from the source AWS Region. By default, this operation only changes the retention period of copied automated snapshots. The retention periods for both new and existing copied automated snapshots are updated with the new retention period. You can set the manual option to change only the retention periods of copied manual snapshots. If you set this option, only newly copied manual snapshots have the new retention period."},{"ref":"AWS.Redshift.html#modify_snapshot_schedule/3","title":"AWS.Redshift.modify_snapshot_schedule/3","type":"function","doc":"Modifies a snapshot schedule. Any schedule associated with a cluster is modified asynchronously."},{"ref":"AWS.Redshift.html#modify_usage_limit/3","title":"AWS.Redshift.modify_usage_limit/3","type":"function","doc":"Modifies a usage limit in a cluster. You can&#39;t modify the feature type or period of a usage limit."},{"ref":"AWS.Redshift.html#pause_cluster/3","title":"AWS.Redshift.pause_cluster/3","type":"function","doc":"Pauses a cluster."},{"ref":"AWS.Redshift.html#purchase_reserved_node_offering/3","title":"AWS.Redshift.purchase_reserved_node_offering/3","type":"function","doc":"Allows you to purchase reserved nodes. Amazon Redshift offers a predefined set of reserved node offerings. You can purchase one or more of the offerings. You can call the DescribeReservedNodeOfferings API to obtain the available reserved node offerings. You can call this API by providing a specific reserved node offering and the number of nodes you want to reserve. For more information about reserved node offerings, go to Purchasing Reserved Nodes in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#reboot_cluster/3","title":"AWS.Redshift.reboot_cluster/3","type":"function","doc":"Reboots a cluster. This action is taken as soon as possible. It results in a momentary outage to the cluster, during which the cluster status is set to rebooting. A cluster event is created when the reboot is completed. Any pending cluster modifications (see ModifyCluster) are applied at this reboot. For more information about managing clusters, go to Amazon Redshift Clusters in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#reset_cluster_parameter_group/3","title":"AWS.Redshift.reset_cluster_parameter_group/3","type":"function","doc":"Sets one or more parameters of the specified parameter group to their default values and sets the source values of the parameters to &quot;engine-default&quot;. To reset the entire parameter group specify the ResetAllParameters parameter. For parameter changes to take effect you must reboot any associated clusters."},{"ref":"AWS.Redshift.html#resize_cluster/3","title":"AWS.Redshift.resize_cluster/3","type":"function","doc":"Changes the size of the cluster. You can change the cluster&#39;s type, or change the number or type of nodes. The default behavior is to use the elastic resize method. With an elastic resize, your cluster is available for read and write operations more quickly than with the classic resize method. Elastic resize operations have the following restrictions: You can only resize clusters of the following types: dc1.large (if your cluster is in a VPC) dc1.8xlarge (if your cluster is in a VPC) dc2.large dc2.8xlarge ds2.xlarge ds2.8xlarge ra3.4xlarge ra3.16xlarge The type of nodes that you add must match the node type for the cluster."},{"ref":"AWS.Redshift.html#restore_from_cluster_snapshot/3","title":"AWS.Redshift.restore_from_cluster_snapshot/3","type":"function","doc":"Creates a new cluster from a snapshot. By default, Amazon Redshift creates the resulting cluster with the same configuration as the original cluster from which the snapshot was created, except that the new cluster is created with the default cluster security and parameter groups. After Amazon Redshift creates the cluster, you can use the ModifyCluster API to associate a different security group and different parameter group with the restored cluster. If you are using a DS node type, you can also choose to change to another DS node type of the same size during restore. If you restore a cluster into a VPC, you must provide a cluster subnet group where you want the cluster restored. For more information about working with snapshots, go to Amazon Redshift Snapshots in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#restore_table_from_cluster_snapshot/3","title":"AWS.Redshift.restore_table_from_cluster_snapshot/3","type":"function","doc":"Creates a new table from a table in an Amazon Redshift cluster snapshot. You must create the new table within the Amazon Redshift cluster that the snapshot was taken from. You cannot use RestoreTableFromClusterSnapshot to restore a table with the same name as an existing table in an Amazon Redshift cluster. That is, you cannot overwrite an existing table in a cluster with a restored table. If you want to replace your original table with a new, restored table, then rename or drop your original table before you call RestoreTableFromClusterSnapshot. When you have renamed your original table, then you can pass the original name of the table as the NewTableName parameter value in the call to RestoreTableFromClusterSnapshot. This way, you can replace the original table with the table created from the snapshot."},{"ref":"AWS.Redshift.html#resume_cluster/3","title":"AWS.Redshift.resume_cluster/3","type":"function","doc":"Resumes a paused cluster."},{"ref":"AWS.Redshift.html#revoke_cluster_security_group_ingress/3","title":"AWS.Redshift.revoke_cluster_security_group_ingress/3","type":"function","doc":"Revokes an ingress rule in an Amazon Redshift security group for a previously authorized IP range or Amazon EC2 security group. To add an ingress rule, see AuthorizeClusterSecurityGroupIngress. For information about managing security groups, go to Amazon Redshift Cluster Security Groups in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#revoke_snapshot_access/3","title":"AWS.Redshift.revoke_snapshot_access/3","type":"function","doc":"Removes the ability of the specified AWS customer account to restore the specified snapshot. If the account is currently restoring the snapshot, the restore will run to completion. For more information about working with snapshots, go to Amazon Redshift Snapshots in the Amazon Redshift Cluster Management Guide."},{"ref":"AWS.Redshift.html#rotate_encryption_key/3","title":"AWS.Redshift.rotate_encryption_key/3","type":"function","doc":"Rotates the encryption keys for a cluster."},{"ref":"AWS.RedshiftData.html","title":"AWS.RedshiftData","type":"module","doc":"You can use the Amazon Redshift Data API to run queries on Amazon Redshift tables. You can run individual SQL statements, which are committed if the statement succeeds."},{"ref":"AWS.RedshiftData.html#cancel_statement/3","title":"AWS.RedshiftData.cancel_statement/3","type":"function","doc":"Cancels a running query. To be canceled, a query must be running."},{"ref":"AWS.RedshiftData.html#describe_statement/3","title":"AWS.RedshiftData.describe_statement/3","type":"function","doc":"Describes the details about a specific instance when a query was run by the Amazon Redshift Data API. The information includes when the query started, when it finished, the query status, the number of rows returned, and the SQL statement."},{"ref":"AWS.RedshiftData.html#describe_table/3","title":"AWS.RedshiftData.describe_table/3","type":"function","doc":"Describes the detailed information about a table from metadata in the cluster. The information includes its columns. A token is returned to page through the column list. Depending on the authorization method, use one of the following combinations of request parameters: AWS Secrets Manager - specify the Amazon Resource Name (ARN) of the secret and the cluster identifier that matches the cluster in the secret. Temporary credentials - specify the cluster identifier, the database name, and the database user name. Permission to call the redshift:GetClusterCredentials operation is required to use this method."},{"ref":"AWS.RedshiftData.html#execute_statement/3","title":"AWS.RedshiftData.execute_statement/3","type":"function","doc":"Runs an SQL statement, which can be data manipulation language (DML) or data definition language (DDL). This statement must be a single SQL statement. Depending on the authorization method, use one of the following combinations of request parameters: AWS Secrets Manager - specify the Amazon Resource Name (ARN) of the secret and the cluster identifier that matches the cluster in the secret. Temporary credentials - specify the cluster identifier, the database name, and the database user name. Permission to call the redshift:GetClusterCredentials operation is required to use this method."},{"ref":"AWS.RedshiftData.html#get_statement_result/3","title":"AWS.RedshiftData.get_statement_result/3","type":"function","doc":"Fetches the temporarily cached result of an SQL statement. A token is returned to page through the statement results."},{"ref":"AWS.RedshiftData.html#list_databases/3","title":"AWS.RedshiftData.list_databases/3","type":"function","doc":"List the databases in a cluster. A token is returned to page through the database list. Depending on the authorization method, use one of the following combinations of request parameters: AWS Secrets Manager - specify the Amazon Resource Name (ARN) of the secret and the cluster identifier that matches the cluster in the secret. Temporary credentials - specify the cluster identifier, the database name, and the database user name. Permission to call the redshift:GetClusterCredentials operation is required to use this method."},{"ref":"AWS.RedshiftData.html#list_schemas/3","title":"AWS.RedshiftData.list_schemas/3","type":"function","doc":"Lists the schemas in a database. A token is returned to page through the schema list. Depending on the authorization method, use one of the following combinations of request parameters: AWS Secrets Manager - specify the Amazon Resource Name (ARN) of the secret and the cluster identifier that matches the cluster in the secret. Temporary credentials - specify the cluster identifier, the database name, and the database user name. Permission to call the redshift:GetClusterCredentials operation is required to use this method."},{"ref":"AWS.RedshiftData.html#list_statements/3","title":"AWS.RedshiftData.list_statements/3","type":"function","doc":"List of SQL statements. By default, only finished statements are shown. A token is returned to page through the statement list."},{"ref":"AWS.RedshiftData.html#list_tables/3","title":"AWS.RedshiftData.list_tables/3","type":"function","doc":"List the tables in a database. If neither SchemaPattern nor TablePattern are specified, then all tables in the database are returned. A token is returned to page through the table list. Depending on the authorization method, use one of the following combinations of request parameters: AWS Secrets Manager - specify the Amazon Resource Name (ARN) of the secret and the cluster identifier that matches the cluster in the secret. Temporary credentials - specify the cluster identifier, the database name, and the database user name. Permission to call the redshift:GetClusterCredentials operation is required to use this method."},{"ref":"AWS.Rekognition.html","title":"AWS.Rekognition","type":"module","doc":"This is the Amazon Rekognition API reference."},{"ref":"AWS.Rekognition.html#compare_faces/3","title":"AWS.Rekognition.compare_faces/3","type":"function","doc":"Compares a face in the source input image with each of the 100 largest faces detected in the target input image. If the source image contains multiple faces, the service detects the largest face and compares it with each face detected in the target image. You pass the input and target images either as base64-encoded image bytes or as references to images in an Amazon S3 bucket. If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes isn&#39;t supported. The image must be formatted as a PNG or JPEG file. In response, the operation returns an array of face matches ordered by similarity score in descending order. For each face match, the response provides a bounding box of the face, facial landmarks, pose details (pitch, role, and yaw), quality (brightness and sharpness), and confidence value (indicating the level of confidence that the bounding box contains a face). The response also provides a similarity score, which indicates how closely the faces match. By default, only faces with a similarity score of greater than or equal to 80% are returned in the response. You can change this value by specifying the SimilarityThreshold parameter. CompareFaces also returns an array of faces that don&#39;t match the source image. For each face, it returns a bounding box, confidence value, landmarks, pose details, and quality. The response also returns information about the face in the source image, including the bounding box of the face and confidence value. The QualityFilter input parameter allows you to filter out detected faces that dont meet a required quality bar. The quality bar is based on a variety of common use cases. Use QualityFilter to set the quality bar by specifying LOW, MEDIUM, or HIGH. If you do not want to filter detected faces, specify NONE. The default value is NONE. If the image doesn&#39;t contain Exif metadata, CompareFaces returns orientation information for the source and target images. Use these values to display the images with the correct image orientation. If no faces are detected in the source or target images, CompareFaces returns an InvalidParameterException error. This is a stateless API operation. That is, data returned by this operation doesn&#39;t persist. For an example, see Comparing Faces in Images in the Amazon Rekognition Developer Guide. This operation requires permissions to perform the rekognition:CompareFaces action."},{"ref":"AWS.Rekognition.html#create_collection/3","title":"AWS.Rekognition.create_collection/3","type":"function","doc":"Creates a collection in an AWS Region. You can add faces to the collection using the IndexFaces operation. For example, you might create collections, one for each of your application users. A user can then index faces using the IndexFaces operation and persist results in a specific collection. Then, a user can search the collection for faces in the user-specific container. When you create a collection, it is associated with the latest version of the face model version. Collection names are case-sensitive. This operation requires permissions to perform the rekognition:CreateCollection action."},{"ref":"AWS.Rekognition.html#create_project/3","title":"AWS.Rekognition.create_project/3","type":"function","doc":"Creates a new Amazon Rekognition Custom Labels project. A project is a logical grouping of resources (images, Labels, models) and operations (training, evaluation and detection). This operation requires permissions to perform the rekognition:CreateProject action."},{"ref":"AWS.Rekognition.html#create_project_version/3","title":"AWS.Rekognition.create_project_version/3","type":"function","doc":"Creates a new version of a model and begins training. Models are managed as part of an Amazon Rekognition Custom Labels project. You can specify one training dataset and one testing dataset. The response from CreateProjectVersion is an Amazon Resource Name (ARN) for the version of the model. Training takes a while to complete. You can get the current status by calling DescribeProjectVersions. Once training has successfully completed, call DescribeProjectVersions to get the training results and evaluate the model. After evaluating the model, you start the model by calling StartProjectVersion. This operation requires permissions to perform the rekognition:CreateProjectVersion action."},{"ref":"AWS.Rekognition.html#create_stream_processor/3","title":"AWS.Rekognition.create_stream_processor/3","type":"function","doc":"Creates an Amazon Rekognition stream processor that you can use to detect and recognize faces in a streaming video. Amazon Rekognition Video is a consumer of live video from Amazon Kinesis Video Streams. Amazon Rekognition Video sends analysis results to Amazon Kinesis Data Streams. You provide as input a Kinesis video stream (Input) and a Kinesis data stream (Output) stream. You also specify the face recognition criteria in Settings. For example, the collection containing faces that you want to recognize. Use Name to assign an identifier for the stream processor. You use Name to manage the stream processor. For example, you can start processing the source video by calling StartStreamProcessor with the Name field. After you have finished analyzing a streaming video, use StopStreamProcessor to stop processing. You can delete the stream processor by calling DeleteStreamProcessor."},{"ref":"AWS.Rekognition.html#delete_collection/3","title":"AWS.Rekognition.delete_collection/3","type":"function","doc":"Deletes the specified collection. Note that this operation removes all faces in the collection. For an example, see delete-collection-procedure. This operation requires permissions to perform the rekognition:DeleteCollection action."},{"ref":"AWS.Rekognition.html#delete_faces/3","title":"AWS.Rekognition.delete_faces/3","type":"function","doc":"Deletes faces from a collection. You specify a collection ID and an array of face IDs to remove from the collection. This operation requires permissions to perform the rekognition:DeleteFaces action."},{"ref":"AWS.Rekognition.html#delete_project/3","title":"AWS.Rekognition.delete_project/3","type":"function","doc":"Deletes an Amazon Rekognition Custom Labels project. To delete a project you must first delete all models associated with the project. To delete a model, see DeleteProjectVersion. This operation requires permissions to perform the rekognition:DeleteProject action."},{"ref":"AWS.Rekognition.html#delete_project_version/3","title":"AWS.Rekognition.delete_project_version/3","type":"function","doc":"Deletes an Amazon Rekognition Custom Labels model. You can&#39;t delete a model if it is running or if it is training. To check the status of a model, use the Status field returned from DescribeProjectVersions. To stop a running model call StopProjectVersion. If the model is training, wait until it finishes. This operation requires permissions to perform the rekognition:DeleteProjectVersion action."},{"ref":"AWS.Rekognition.html#delete_stream_processor/3","title":"AWS.Rekognition.delete_stream_processor/3","type":"function","doc":"Deletes the stream processor identified by Name. You assign the value for Name when you create the stream processor with CreateStreamProcessor. You might not be able to use the same name for a stream processor for a few seconds after calling DeleteStreamProcessor."},{"ref":"AWS.Rekognition.html#describe_collection/3","title":"AWS.Rekognition.describe_collection/3","type":"function","doc":"Describes the specified collection. You can use DescribeCollection to get information, such as the number of faces indexed into a collection and the version of the model used by the collection for face detection. For more information, see Describing a Collection in the Amazon Rekognition Developer Guide."},{"ref":"AWS.Rekognition.html#describe_project_versions/3","title":"AWS.Rekognition.describe_project_versions/3","type":"function","doc":"Lists and describes the models in an Amazon Rekognition Custom Labels project. You can specify up to 10 model versions in ProjectVersionArns. If you don&#39;t specify a value, descriptions for all models are returned. This operation requires permissions to perform the rekognition:DescribeProjectVersions action."},{"ref":"AWS.Rekognition.html#describe_projects/3","title":"AWS.Rekognition.describe_projects/3","type":"function","doc":"Lists and gets information about your Amazon Rekognition Custom Labels projects. This operation requires permissions to perform the rekognition:DescribeProjects action."},{"ref":"AWS.Rekognition.html#describe_stream_processor/3","title":"AWS.Rekognition.describe_stream_processor/3","type":"function","doc":"Provides information about a stream processor created by CreateStreamProcessor. You can get information about the input and output streams, the input parameters for the face recognition being performed, and the current status of the stream processor."},{"ref":"AWS.Rekognition.html#detect_custom_labels/3","title":"AWS.Rekognition.detect_custom_labels/3","type":"function","doc":"Detects custom labels in a supplied image by using an Amazon Rekognition Custom Labels model. You specify which version of a model version to use by using the ProjectVersionArn input parameter. You pass the input image as base64-encoded image bytes or as a reference to an image in an Amazon S3 bucket. If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes is not supported. The image must be either a PNG or JPEG formatted file. For each object that the model version detects on an image, the API returns a (CustomLabel) object in an array (CustomLabels). Each CustomLabel object provides the label name (Name), the level of confidence that the image contains the object (Confidence), and object location information, if it exists, for the label on the image (Geometry). During training model calculates a threshold value that determines if a prediction for a label is true. By default, DetectCustomLabels doesn&#39;t return labels whose confidence value is below the model&#39;s calculated threshold value. To filter labels that are returned, specify a value for MinConfidence that is higher than the model&#39;s calculated threshold. You can get the model&#39;s calculated threshold from the model&#39;s training results shown in the Amazon Rekognition Custom Labels console. To get all labels, regardless of confidence, specify a MinConfidence value of 0. You can also add the MaxResults parameter to limit the number of labels returned. This is a stateless API operation. That is, the operation does not persist any data. This operation requires permissions to perform the rekognition:DetectCustomLabels action."},{"ref":"AWS.Rekognition.html#detect_faces/3","title":"AWS.Rekognition.detect_faces/3","type":"function","doc":"Detects faces within an image that is provided as input. DetectFaces detects the 100 largest faces in the image. For each face detected, the operation returns face details. These details include a bounding box of the face, a confidence value (that the bounding box contains a face), and a fixed set of attributes such as facial landmarks (for example, coordinates of eye and mouth), presence of beard, sunglasses, and so on. The face-detection algorithm is most effective on frontal faces. For non-frontal or obscured faces, the algorithm might not detect the faces or might detect faces with lower confidence. You pass the input image either as base64-encoded image bytes or as a reference to an image in an Amazon S3 bucket. If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes is not supported. The image must be either a PNG or JPEG formatted file. This is a stateless API operation. That is, the operation does not persist any data. This operation requires permissions to perform the rekognition:DetectFaces action."},{"ref":"AWS.Rekognition.html#detect_labels/3","title":"AWS.Rekognition.detect_labels/3","type":"function","doc":"Detects instances of real-world entities within an image (JPEG or PNG) provided as input. This includes objects like flower, tree, and table; events like wedding, graduation, and birthday party; and concepts like landscape, evening, and nature. For an example, see Analyzing Images Stored in an Amazon S3 Bucket in the Amazon Rekognition Developer Guide. DetectLabels does not support the detection of activities. However, activity detection is supported for label detection in videos. For more information, see StartLabelDetection in the Amazon Rekognition Developer Guide. You pass the input image as base64-encoded image bytes or as a reference to an image in an Amazon S3 bucket. If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes is not supported. The image must be either a PNG or JPEG formatted file. For each object, scene, and concept the API returns one or more labels. Each label provides the object name, and the level of confidence that the image contains the object. For example, suppose the input image has a lighthouse, the sea, and a rock. The response includes all three labels, one for each object. {Name: lighthouse, Confidence: 98.4629} {Name: rock,Confidence: 79.2097} {Name: sea,Confidence: 75.061} In the preceding example, the operation returns one label for each of the three objects. The operation can also return multiple labels for the same object in the image. For example, if the input image shows a flower (for example, a tulip), the operation might return the following three labels. {Name: flower,Confidence: 99.0562} {Name: plant,Confidence: 99.0562} {Name: tulip,Confidence: 99.0562} In this example, the detection algorithm more precisely identifies the flower as a tulip. In response, the API returns an array of labels. In addition, the response also includes the orientation correction. Optionally, you can specify MinConfidence to control the confidence threshold for the labels returned. The default is 55%. You can also add the MaxLabels parameter to limit the number of labels returned. If the object detected is a person, the operation doesn&#39;t provide the same facial details that the DetectFaces operation provides. DetectLabels returns bounding boxes for instances of common object labels in an array of Instance objects. An Instance object contains a BoundingBox object, for the location of the label on the image. It also includes the confidence by which the bounding box was detected. DetectLabels also returns a hierarchical taxonomy of detected labels. For example, a detected car might be assigned the label car. The label car has two parent labels: Vehicle (its parent) and Transportation (its grandparent). The response returns the entire list of ancestors for a label. Each ancestor is a unique label in the response. In the previous example, Car, Vehicle, and Transportation are returned as unique labels in the response. This is a stateless API operation. That is, the operation does not persist any data. This operation requires permissions to perform the rekognition:DetectLabels action."},{"ref":"AWS.Rekognition.html#detect_moderation_labels/3","title":"AWS.Rekognition.detect_moderation_labels/3","type":"function","doc":"Detects unsafe content in a specified JPEG or PNG format image. Use DetectModerationLabels to moderate images depending on your requirements. For example, you might want to filter images that contain nudity, but not images containing suggestive content. To filter images, use the labels returned by DetectModerationLabels to determine which types of content are appropriate. For information about moderation labels, see Detecting Unsafe Content in the Amazon Rekognition Developer Guide. You pass the input image either as base64-encoded image bytes or as a reference to an image in an Amazon S3 bucket. If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes is not supported. The image must be either a PNG or JPEG formatted file."},{"ref":"AWS.Rekognition.html#detect_text/3","title":"AWS.Rekognition.detect_text/3","type":"function","doc":"Detects text in the input image and converts it into machine-readable text. Pass the input image as base64-encoded image bytes or as a reference to an image in an Amazon S3 bucket. If you use the AWS CLI to call Amazon Rekognition operations, you must pass it as a reference to an image in an Amazon S3 bucket. For the AWS CLI, passing image bytes is not supported. The image must be either a .png or .jpeg formatted file. The DetectText operation returns text in an array of TextDetection elements, TextDetections. Each TextDetection element provides information about a single word or line of text that was detected in the image. A word is one or more ISO basic latin script characters that are not separated by spaces. DetectText can detect up to 50 words in an image. A line is a string of equally spaced words. A line isn&#39;t necessarily a complete sentence. For example, a driver&#39;s license number is detected as a line. A line ends when there is no aligned text after it. Also, a line ends when there is a large gap between words, relative to the length of the words. This means, depending on the gap between words, Amazon Rekognition may detect multiple lines in text aligned in the same direction. Periods don&#39;t represent the end of a line. If a sentence spans multiple lines, the DetectText operation returns multiple lines. To determine whether a TextDetection element is a line of text or a word, use the TextDetection object Type field. To be detected, text must be within +/- 90 degrees orientation of the horizontal axis. For more information, see DetectText in the Amazon Rekognition Developer Guide."},{"ref":"AWS.Rekognition.html#get_celebrity_info/3","title":"AWS.Rekognition.get_celebrity_info/3","type":"function","doc":"Gets the name and additional information about a celebrity based on his or her Amazon Rekognition ID. The additional information is returned as an array of URLs. If there is no additional information about the celebrity, this list is empty. For more information, see Recognizing Celebrities in an Image in the Amazon Rekognition Developer Guide. This operation requires permissions to perform the rekognition:GetCelebrityInfo action."},{"ref":"AWS.Rekognition.html#get_celebrity_recognition/3","title":"AWS.Rekognition.get_celebrity_recognition/3","type":"function","doc":"Gets the celebrity recognition results for a Amazon Rekognition Video analysis started by StartCelebrityRecognition. Celebrity recognition in a video is an asynchronous operation. Analysis is started by a call to StartCelebrityRecognition which returns a job identifier (JobId). When the celebrity recognition operation finishes, Amazon Rekognition Video publishes a completion status to the Amazon Simple Notification Service topic registered in the initial call to StartCelebrityRecognition. To get the results of the celebrity recognition analysis, first check that the status value published to the Amazon SNS topic is SUCCEEDED. If so, call GetCelebrityDetection and pass the job identifier (JobId) from the initial call to StartCelebrityDetection. For more information, see Working With Stored Videos in the Amazon Rekognition Developer Guide. GetCelebrityRecognition returns detected celebrities and the time(s) they are detected in an array (Celebrities) of CelebrityRecognition objects. Each CelebrityRecognition contains information about the celebrity in a CelebrityDetail object and the time, Timestamp, the celebrity was detected. GetCelebrityRecognition only returns the default facial attributes (BoundingBox, Confidence, Landmarks, Pose, and Quality). The other facial attributes listed in the Face object of the following response syntax are not returned. For more information, see FaceDetail in the Amazon Rekognition Developer Guide. By default, the Celebrities array is sorted by time (milliseconds from the start of the video). You can also sort the array by celebrity by specifying the value ID in the SortBy input parameter. The CelebrityDetail object includes the celebrity identifer and additional information urls. If you don&#39;t store the additional information urls, you can get them later by calling GetCelebrityInfo with the celebrity identifer. No information is returned for faces not recognized as celebrities. Use MaxResults parameter to limit the number of labels returned. If there are more results than specified in MaxResults, the value of NextToken in the operation response contains a pagination token for getting the next set of results. To get the next page of results, call GetCelebrityDetection and populate the NextToken request parameter with the token value returned from the previous call to GetCelebrityRecognition."},{"ref":"AWS.Rekognition.html#get_content_moderation/3","title":"AWS.Rekognition.get_content_moderation/3","type":"function","doc":"Gets the unsafe content analysis results for a Amazon Rekognition Video analysis started by StartContentModeration. Unsafe content analysis of a video is an asynchronous operation. You start analysis by calling StartContentModeration which returns a job identifier (JobId). When analysis finishes, Amazon Rekognition Video publishes a completion status to the Amazon Simple Notification Service topic registered in the initial call to StartContentModeration. To get the results of the unsafe content analysis, first check that the status value published to the Amazon SNS topic is SUCCEEDED. If so, call GetContentModeration and pass the job identifier (JobId) from the initial call to StartContentModeration. For more information, see Working with Stored Videos in the Amazon Rekognition Devlopers Guide. GetContentModeration returns detected unsafe content labels, and the time they are detected, in an array, ModerationLabels, of ContentModerationDetection objects. By default, the moderated labels are returned sorted by time, in milliseconds from the start of the video. You can also sort them by moderated label by specifying NAME for the SortBy input parameter. Since video analysis can return a large number of results, use the MaxResults parameter to limit the number of labels returned in a single call to GetContentModeration. If there are more results than specified in MaxResults, the value of NextToken in the operation response contains a pagination token for getting the next set of results. To get the next page of results, call GetContentModeration and populate the NextToken request parameter with the value of NextToken returned from the previous call to GetContentModeration. For more information, see Detecting Unsafe Content in the Amazon Rekognition Developer Guide."},{"ref":"AWS.Rekognition.html#get_face_detection/3","title":"AWS.Rekognition.get_face_detection/3","type":"function","doc":"Gets face detection results for a Amazon Rekognition Video analysis started by StartFaceDetection. Face detection with Amazon Rekognition Video is an asynchronous operation. You start face detection by calling StartFaceDetection which returns a job identifier (JobId). When the face detection operation finishes, Amazon Rekognition Video publishes a completion status to the Amazon Simple Notification Service topic registered in the initial call to StartFaceDetection. To get the results of the face detection operation, first check that the status value published to the Amazon SNS topic is SUCCEEDED. If so, call GetFaceDetection and pass the job identifier (JobId) from the initial call to StartFaceDetection. GetFaceDetection returns an array of detected faces (Faces) sorted by the time the faces were detected. Use MaxResults parameter to limit the number of labels returned. If there are more results than specified in MaxResults, the value of NextToken in the operation response contains a pagination token for getting the next set of results. To get the next page of results, call GetFaceDetection and populate the NextToken request parameter with the token value returned from the previous call to GetFaceDetection."},{"ref":"AWS.Rekognition.html#get_face_search/3","title":"AWS.Rekognition.get_face_search/3","type":"function","doc":"Gets the face search results for Amazon Rekognition Video face search started by StartFaceSearch. The search returns faces in a collection that match the faces of persons detected in a video. It also includes the time(s) that faces are matched in the video. Face search in a video is an asynchronous operation. You start face search by calling to StartFaceSearch which returns a job identifier (JobId). When the search operation finishes, Amazon Rekognition Video publishes a completion status to the Amazon Simple Notification Service topic registered in the initial call to StartFaceSearch. To get the search results, first check that the status value published to the Amazon SNS topic is SUCCEEDED. If so, call GetFaceSearch and pass the job identifier (JobId) from the initial call to StartFaceSearch. For more information, see Searching Faces in a Collection in the Amazon Rekognition Developer Guide. The search results are retured in an array, Persons, of PersonMatch objects. EachPersonMatch element contains details about the matching faces in the input collection, person information (facial attributes, bounding boxes, and person identifer) for the matched person, and the time the person was matched in the video. GetFaceSearch only returns the default facial attributes (BoundingBox, Confidence, Landmarks, Pose, and Quality). The other facial attributes listed in the Face object of the following response syntax are not returned. For more information, see FaceDetail in the Amazon Rekognition Developer Guide. By default, the Persons array is sorted by the time, in milliseconds from the start of the video, persons are matched. You can also sort by persons by specifying INDEX for the SORTBY input parameter."},{"ref":"AWS.Rekognition.html#get_label_detection/3","title":"AWS.Rekognition.get_label_detection/3","type":"function","doc":"Gets the label detection results of a Amazon Rekognition Video analysis started by StartLabelDetection. The label detection operation is started by a call to StartLabelDetection which returns a job identifier (JobId). When the label detection operation finishes, Amazon Rekognition publishes a completion status to the Amazon Simple Notification Service topic registered in the initial call to StartlabelDetection. To get the results of the label detection operation, first check that the status value published to the Amazon SNS topic is SUCCEEDED. If so, call GetLabelDetection and pass the job identifier (JobId) from the initial call to StartLabelDetection. GetLabelDetection returns an array of detected labels (Labels) sorted by the time the labels were detected. You can also sort by the label name by specifying NAME for the SortBy input parameter. The labels returned include the label name, the percentage confidence in the accuracy of the detected label, and the time the label was detected in the video. The returned labels also include bounding box information for common objects, a hierarchical taxonomy of detected labels, and the version of the label model used for detection. Use MaxResults parameter to limit the number of labels returned. If there are more results than specified in MaxResults, the value of NextToken in the operation response contains a pagination token for getting the next set of results. To get the next page of results, call GetlabelDetection and populate the NextToken request parameter with the token value returned from the previous call to GetLabelDetection."},{"ref":"AWS.Rekognition.html#get_person_tracking/3","title":"AWS.Rekognition.get_person_tracking/3","type":"function","doc":"Gets the path tracking results of a Amazon Rekognition Video analysis started by StartPersonTracking. The person path tracking operation is started by a call to StartPersonTracking which returns a job identifier (JobId). When the operation finishes, Amazon Rekognition Video publishes a completion status to the Amazon Simple Notification Service topic registered in the initial call to StartPersonTracking. To get the results of the person path tracking operation, first check that the status value published to the Amazon SNS topic is SUCCEEDED. If so, call GetPersonTracking and pass the job identifier (JobId) from the initial call to StartPersonTracking. GetPersonTracking returns an array, Persons, of tracked persons and the time(s) their paths were tracked in the video. GetPersonTracking only returns the default facial attributes (BoundingBox, Confidence, Landmarks, Pose, and Quality). The other facial attributes listed in the Face object of the following response syntax are not returned. For more information, see FaceDetail in the Amazon Rekognition Developer Guide. By default, the array is sorted by the time(s) a person&#39;s path is tracked in the video. You can sort by tracked persons by specifying INDEX for the SortBy input parameter. Use the MaxResults parameter to limit the number of items returned. If there are more results than specified in MaxResults, the value of NextToken in the operation response contains a pagination token for getting the next set of results. To get the next page of results, call GetPersonTracking and populate the NextToken request parameter with the token value returned from the previous call to GetPersonTracking."},{"ref":"AWS.Rekognition.html#get_segment_detection/3","title":"AWS.Rekognition.get_segment_detection/3","type":"function","doc":"Gets the segment detection results of a Amazon Rekognition Video analysis started by StartSegmentDetection. Segment detection with Amazon Rekognition Video is an asynchronous operation. You start segment detection by calling StartSegmentDetection which returns a job identifier (JobId). When the segment detection operation finishes, Amazon Rekognition publishes a completion status to the Amazon Simple Notification Service topic registered in the initial call to StartSegmentDetection. To get the results of the segment detection operation, first check that the status value published to the Amazon SNS topic is SUCCEEDED. if so, call GetSegmentDetection and pass the job identifier (JobId) from the initial call of StartSegmentDetection. GetSegmentDetection returns detected segments in an array (Segments) of SegmentDetection objects. Segments is sorted by the segment types specified in the SegmentTypes input parameter of StartSegmentDetection. Each element of the array includes the detected segment, the precentage confidence in the acuracy of the detected segment, the type of the segment, and the frame in which the segment was detected. Use SelectedSegmentTypes to find out the type of segment detection requested in the call to StartSegmentDetection. Use the MaxResults parameter to limit the number of segment detections returned. If there are more results than specified in MaxResults, the value of NextToken in the operation response contains a pagination token for getting the next set of results. To get the next page of results, call GetSegmentDetection and populate the NextToken request parameter with the token value returned from the previous call to GetSegmentDetection. For more information, see Detecting Video Segments in Stored Video in the Amazon Rekognition Developer Guide."},{"ref":"AWS.Rekognition.html#get_text_detection/3","title":"AWS.Rekognition.get_text_detection/3","type":"function","doc":"Gets the text detection results of a Amazon Rekognition Video analysis started by StartTextDetection. Text detection with Amazon Rekognition Video is an asynchronous operation. You start text detection by calling StartTextDetection which returns a job identifier (JobId) When the text detection operation finishes, Amazon Rekognition publishes a completion status to the Amazon Simple Notification Service topic registered in the initial call to StartTextDetection. To get the results of the text detection operation, first check that the status value published to the Amazon SNS topic is SUCCEEDED. if so, call GetTextDetection and pass the job identifier (JobId) from the initial call of StartLabelDetection. GetTextDetection returns an array of detected text (TextDetections) sorted by the time the text was detected, up to 50 words per frame of video. Each element of the array includes the detected text, the precentage confidence in the acuracy of the detected text, the time the text was detected, bounding box information for where the text was located, and unique identifiers for words and their lines. Use MaxResults parameter to limit the number of text detections returned. If there are more results than specified in MaxResults, the value of NextToken in the operation response contains a pagination token for getting the next set of results. To get the next page of results, call GetTextDetection and populate the NextToken request parameter with the token value returned from the previous call to GetTextDetection."},{"ref":"AWS.Rekognition.html#index_faces/3","title":"AWS.Rekognition.index_faces/3","type":"function","doc":"Detects faces in the input image and adds them to the specified collection. Amazon Rekognition doesn&#39;t save the actual faces that are detected. Instead, the underlying detection algorithm first detects the faces in the input image. For each face, the algorithm extracts facial features into a feature vector, and stores it in the backend database. Amazon Rekognition uses feature vectors when it performs face match and search operations using the SearchFaces and SearchFacesByImage operations. For more information, see Adding Faces to a Collection in the Amazon Rekognition Developer Guide. To get the number of faces in a collection, call DescribeCollection. If you&#39;re using version 1.0 of the face detection model, IndexFaces indexes the 15 largest faces in the input image. Later versions of the face detection model index the 100 largest faces in the input image. If you&#39;re using version 4 or later of the face model, image orientation information is not returned in the OrientationCorrection field. To determine which version of the model you&#39;re using, call DescribeCollection and supply the collection ID. You can also get the model version from the value of FaceModelVersion in the response from IndexFaces For more information, see Model Versioning in the Amazon Rekognition Developer Guide. If you provide the optional ExternalImageId for the input image you provided, Amazon Rekognition associates this ID with all faces that it detects. When you call the ListFaces operation, the response returns the external ID. You can use this external image ID to create a client-side index to associate the faces with each image. You can then use the index to find all faces in an image. You can specify the maximum number of faces to index with the MaxFaces input parameter. This is useful when you want to index the largest faces in an image and don&#39;t want to index smaller faces, such as those belonging to people standing in the background. The QualityFilter input parameter allows you to filter out detected faces that dont meet a required quality bar. The quality bar is based on a variety of common use cases. By default, IndexFaces chooses the quality bar that&#39;s used to filter faces. You can also explicitly choose the quality bar. Use QualityFilter, to set the quality bar by specifying LOW, MEDIUM, or HIGH. If you do not want to filter detected faces, specify NONE. To use quality filtering, you need a collection associated with version 3 of the face model or higher. To get the version of the face model associated with a collection, call DescribeCollection. Information about faces detected in an image, but not indexed, is returned in an array of UnindexedFace objects, UnindexedFaces. Faces aren&#39;t indexed for reasons such as: The number of faces detected exceeds the value of the MaxFaces request parameter. The face is too small compared to the image dimensions. The face is too blurry. The image is too dark. The face has an extreme pose. The face doesnt have enough detail to be suitable for face search. In response, the IndexFaces operation returns an array of metadata for all detected faces, FaceRecords. This includes: The bounding box, BoundingBox, of the detected face. A confidence value, Confidence, which indicates the confidence that the bounding box contains a face. A face ID, FaceId, assigned by the service for each face that&#39;s detected and stored. An image ID, ImageId, assigned by the service for the input image. If you request all facial attributes (by using the detectionAttributes parameter), Amazon Rekognition returns detailed facial attributes, such as facial landmarks (for example, location of eye and mouth) and other facial attributes. If you provide the same image, specify the same collection, and use the same external ID in the IndexFaces operation, Amazon Rekognition doesn&#39;t save duplicate face metadata. The input image is passed either as base64-encoded image bytes, or as a reference to an image in an Amazon S3 bucket. If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes isn&#39;t supported. The image must be formatted as a PNG or JPEG file. This operation requires permissions to perform the rekognition:IndexFaces action."},{"ref":"AWS.Rekognition.html#list_collections/3","title":"AWS.Rekognition.list_collections/3","type":"function","doc":"Returns list of collection IDs in your account. If the result is truncated, the response also provides a NextToken that you can use in the subsequent request to fetch the next set of collection IDs. For an example, see Listing Collections in the Amazon Rekognition Developer Guide. This operation requires permissions to perform the rekognition:ListCollections action."},{"ref":"AWS.Rekognition.html#list_faces/3","title":"AWS.Rekognition.list_faces/3","type":"function","doc":"Returns metadata for faces in the specified collection. This metadata includes information such as the bounding box coordinates, the confidence (that the bounding box contains a face), and face ID. For an example, see Listing Faces in a Collection in the Amazon Rekognition Developer Guide. This operation requires permissions to perform the rekognition:ListFaces action."},{"ref":"AWS.Rekognition.html#list_stream_processors/3","title":"AWS.Rekognition.list_stream_processors/3","type":"function","doc":"Gets a list of stream processors that you have created with CreateStreamProcessor."},{"ref":"AWS.Rekognition.html#recognize_celebrities/3","title":"AWS.Rekognition.recognize_celebrities/3","type":"function","doc":"Returns an array of celebrities recognized in the input image. For more information, see Recognizing Celebrities in the Amazon Rekognition Developer Guide. RecognizeCelebrities returns the 64 largest faces in the image. It lists recognized celebrities in the CelebrityFaces array and unrecognized faces in the UnrecognizedFaces array. RecognizeCelebrities doesn&#39;t return celebrities whose faces aren&#39;t among the largest 64 faces in the image. For each celebrity recognized, RecognizeCelebrities returns a Celebrity object. The Celebrity object contains the celebrity name, ID, URL links to additional information, match confidence, and a ComparedFace object that you can use to locate the celebrity&#39;s face on the image. Amazon Rekognition doesn&#39;t retain information about which images a celebrity has been recognized in. Your application must store this information and use the Celebrity ID property as a unique identifier for the celebrity. If you don&#39;t store the celebrity name or additional information URLs returned by RecognizeCelebrities, you will need the ID to identify the celebrity in a call to the GetCelebrityInfo operation. You pass the input image either as base64-encoded image bytes or as a reference to an image in an Amazon S3 bucket. If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes is not supported. The image must be either a PNG or JPEG formatted file. For an example, see Recognizing Celebrities in an Image in the Amazon Rekognition Developer Guide. This operation requires permissions to perform the rekognition:RecognizeCelebrities operation."},{"ref":"AWS.Rekognition.html#search_faces/3","title":"AWS.Rekognition.search_faces/3","type":"function","doc":"For a given input face ID, searches for matching faces in the collection the face belongs to. You get a face ID when you add a face to the collection using the IndexFaces operation. The operation compares the features of the input face with faces in the specified collection. You can also search faces without indexing faces by using the SearchFacesByImage operation. The operation response returns an array of faces that match, ordered by similarity score with the highest similarity first. More specifically, it is an array of metadata for each face match that is found. Along with the metadata, the response also includes a confidence value for each face match, indicating the confidence that the specific face matches the input face. For an example, see Searching for a Face Using Its Face ID in the Amazon Rekognition Developer Guide. This operation requires permissions to perform the rekognition:SearchFaces action."},{"ref":"AWS.Rekognition.html#search_faces_by_image/3","title":"AWS.Rekognition.search_faces_by_image/3","type":"function","doc":"For a given input image, first detects the largest face in the image, and then searches the specified collection for matching faces. The operation compares the features of the input face with faces in the specified collection. To search for all faces in an input image, you might first call the IndexFaces operation, and then use the face IDs returned in subsequent calls to the SearchFaces operation. You can also call the DetectFaces operation and use the bounding boxes in the response to make face crops, which then you can pass in to the SearchFacesByImage operation. You pass the input image either as base64-encoded image bytes or as a reference to an image in an Amazon S3 bucket. If you use the AWS CLI to call Amazon Rekognition operations, passing image bytes is not supported. The image must be either a PNG or JPEG formatted file. The response returns an array of faces that match, ordered by similarity score with the highest similarity first. More specifically, it is an array of metadata for each face match found. Along with the metadata, the response also includes a similarity indicating how similar the face is to the input face. In the response, the operation also returns the bounding box (and a confidence level that the bounding box contains a face) of the face that Amazon Rekognition used for the input image. For an example, Searching for a Face Using an Image in the Amazon Rekognition Developer Guide. The QualityFilter input parameter allows you to filter out detected faces that dont meet a required quality bar. The quality bar is based on a variety of common use cases. Use QualityFilter to set the quality bar for filtering by specifying LOW, MEDIUM, or HIGH. If you do not want to filter detected faces, specify NONE. The default value is NONE. To use quality filtering, you need a collection associated with version 3 of the face model or higher. To get the version of the face model associated with a collection, call DescribeCollection. This operation requires permissions to perform the rekognition:SearchFacesByImage action."},{"ref":"AWS.Rekognition.html#start_celebrity_recognition/3","title":"AWS.Rekognition.start_celebrity_recognition/3","type":"function","doc":"Starts asynchronous recognition of celebrities in a stored video. Amazon Rekognition Video can detect celebrities in a video must be stored in an Amazon S3 bucket. Use Video to specify the bucket name and the filename of the video. StartCelebrityRecognition returns a job identifier (JobId) which you use to get the results of the analysis. When celebrity recognition analysis is finished, Amazon Rekognition Video publishes a completion status to the Amazon Simple Notification Service topic that you specify in NotificationChannel. To get the results of the celebrity recognition analysis, first check that the status value published to the Amazon SNS topic is SUCCEEDED. If so, call GetCelebrityRecognition and pass the job identifier (JobId) from the initial call to StartCelebrityRecognition. For more information, see Recognizing Celebrities in the Amazon Rekognition Developer Guide."},{"ref":"AWS.Rekognition.html#start_content_moderation/3","title":"AWS.Rekognition.start_content_moderation/3","type":"function","doc":"Starts asynchronous detection of unsafe content in a stored video. Amazon Rekognition Video can moderate content in a video stored in an Amazon S3 bucket. Use Video to specify the bucket name and the filename of the video. StartContentModeration returns a job identifier (JobId) which you use to get the results of the analysis. When unsafe content analysis is finished, Amazon Rekognition Video publishes a completion status to the Amazon Simple Notification Service topic that you specify in NotificationChannel. To get the results of the unsafe content analysis, first check that the status value published to the Amazon SNS topic is SUCCEEDED. If so, call GetContentModeration and pass the job identifier (JobId) from the initial call to StartContentModeration. For more information, see Detecting Unsafe Content in the Amazon Rekognition Developer Guide."},{"ref":"AWS.Rekognition.html#start_face_detection/3","title":"AWS.Rekognition.start_face_detection/3","type":"function","doc":"Starts asynchronous detection of faces in a stored video. Amazon Rekognition Video can detect faces in a video stored in an Amazon S3 bucket. Use Video to specify the bucket name and the filename of the video. StartFaceDetection returns a job identifier (JobId) that you use to get the results of the operation. When face detection is finished, Amazon Rekognition Video publishes a completion status to the Amazon Simple Notification Service topic that you specify in NotificationChannel. To get the results of the face detection operation, first check that the status value published to the Amazon SNS topic is SUCCEEDED. If so, call GetFaceDetection and pass the job identifier (JobId) from the initial call to StartFaceDetection. For more information, see Detecting Faces in a Stored Video in the Amazon Rekognition Developer Guide."},{"ref":"AWS.Rekognition.html#start_face_search/3","title":"AWS.Rekognition.start_face_search/3","type":"function","doc":"Starts the asynchronous search for faces in a collection that match the faces of persons detected in a stored video. The video must be stored in an Amazon S3 bucket. Use Video to specify the bucket name and the filename of the video. StartFaceSearch returns a job identifier (JobId) which you use to get the search results once the search has completed. When searching is finished, Amazon Rekognition Video publishes a completion status to the Amazon Simple Notification Service topic that you specify in NotificationChannel. To get the search results, first check that the status value published to the Amazon SNS topic is SUCCEEDED. If so, call GetFaceSearch and pass the job identifier (JobId) from the initial call to StartFaceSearch. For more information, see procedure-person-search-videos."},{"ref":"AWS.Rekognition.html#start_label_detection/3","title":"AWS.Rekognition.start_label_detection/3","type":"function","doc":"Starts asynchronous detection of labels in a stored video. Amazon Rekognition Video can detect labels in a video. Labels are instances of real-world entities. This includes objects like flower, tree, and table; events like wedding, graduation, and birthday party; concepts like landscape, evening, and nature; and activities like a person getting out of a car or a person skiing. The video must be stored in an Amazon S3 bucket. Use Video to specify the bucket name and the filename of the video. StartLabelDetection returns a job identifier (JobId) which you use to get the results of the operation. When label detection is finished, Amazon Rekognition Video publishes a completion status to the Amazon Simple Notification Service topic that you specify in NotificationChannel. To get the results of the label detection operation, first check that the status value published to the Amazon SNS topic is SUCCEEDED. If so, call GetLabelDetection and pass the job identifier (JobId) from the initial call to StartLabelDetection."},{"ref":"AWS.Rekognition.html#start_person_tracking/3","title":"AWS.Rekognition.start_person_tracking/3","type":"function","doc":"Starts the asynchronous tracking of a person&#39;s path in a stored video. Amazon Rekognition Video can track the path of people in a video stored in an Amazon S3 bucket. Use Video to specify the bucket name and the filename of the video. StartPersonTracking returns a job identifier (JobId) which you use to get the results of the operation. When label detection is finished, Amazon Rekognition publishes a completion status to the Amazon Simple Notification Service topic that you specify in NotificationChannel. To get the results of the person detection operation, first check that the status value published to the Amazon SNS topic is SUCCEEDED. If so, call GetPersonTracking and pass the job identifier (JobId) from the initial call to StartPersonTracking."},{"ref":"AWS.Rekognition.html#start_project_version/3","title":"AWS.Rekognition.start_project_version/3","type":"function","doc":"Starts the running of the version of a model. Starting a model takes a while to complete. To check the current state of the model, use DescribeProjectVersions. Once the model is running, you can detect custom labels in new images by calling DetectCustomLabels. You are charged for the amount of time that the model is running. To stop a running model, call StopProjectVersion. This operation requires permissions to perform the rekognition:StartProjectVersion action."},{"ref":"AWS.Rekognition.html#start_segment_detection/3","title":"AWS.Rekognition.start_segment_detection/3","type":"function","doc":"Starts asynchronous detection of segment detection in a stored video. Amazon Rekognition Video can detect segments in a video stored in an Amazon S3 bucket. Use Video to specify the bucket name and the filename of the video. StartSegmentDetection returns a job identifier (JobId) which you use to get the results of the operation. When segment detection is finished, Amazon Rekognition Video publishes a completion status to the Amazon Simple Notification Service topic that you specify in NotificationChannel. You can use the Filters (StartSegmentDetectionFilters) input parameter to specify the minimum detection confidence returned in the response. Within Filters, use ShotFilter (StartShotDetectionFilter) to filter detected shots. Use TechnicalCueFilter (StartTechnicalCueDetectionFilter) to filter technical cues. To get the results of the segment detection operation, first check that the status value published to the Amazon SNS topic is SUCCEEDED. if so, call GetSegmentDetection and pass the job identifier (JobId) from the initial call to StartSegmentDetection. For more information, see Detecting Video Segments in Stored Video in the Amazon Rekognition Developer Guide."},{"ref":"AWS.Rekognition.html#start_stream_processor/3","title":"AWS.Rekognition.start_stream_processor/3","type":"function","doc":"Starts processing a stream processor. You create a stream processor by calling CreateStreamProcessor. To tell StartStreamProcessor which stream processor to start, use the value of the Name field specified in the call to CreateStreamProcessor."},{"ref":"AWS.Rekognition.html#start_text_detection/3","title":"AWS.Rekognition.start_text_detection/3","type":"function","doc":"Starts asynchronous detection of text in a stored video. Amazon Rekognition Video can detect text in a video stored in an Amazon S3 bucket. Use Video to specify the bucket name and the filename of the video. StartTextDetection returns a job identifier (JobId) which you use to get the results of the operation. When text detection is finished, Amazon Rekognition Video publishes a completion status to the Amazon Simple Notification Service topic that you specify in NotificationChannel. To get the results of the text detection operation, first check that the status value published to the Amazon SNS topic is SUCCEEDED. if so, call GetTextDetection and pass the job identifier (JobId) from the initial call to StartTextDetection."},{"ref":"AWS.Rekognition.html#stop_project_version/3","title":"AWS.Rekognition.stop_project_version/3","type":"function","doc":"Stops a running model. The operation might take a while to complete. To check the current status, call DescribeProjectVersions."},{"ref":"AWS.Rekognition.html#stop_stream_processor/3","title":"AWS.Rekognition.stop_stream_processor/3","type":"function","doc":"Stops a running stream processor that was created by CreateStreamProcessor."},{"ref":"AWS.Request.html","title":"AWS.Request","type":"module","doc":""},{"ref":"AWS.Request.html#add_headers/2","title":"AWS.Request.add_headers/2","type":"function","doc":"Include additions only if they do not already exist in the provided list."},{"ref":"AWS.Request.html#build_params/2","title":"AWS.Request.build_params/2","type":"function","doc":"Build request params (header or querystring) based on a list of key-value pairs representing the mapping from the input name (key) to the param name (value) and a map with the input params."},{"ref":"AWS.Request.html#sign_v4/5","title":"AWS.Request.sign_v4/5","type":"function","doc":"Generate headers with an AWS signature version 4 for the specified request."},{"ref":"AWS.Request.html#sign_v4/6","title":"AWS.Request.sign_v4/6","type":"function","doc":"Generate headers with an AWS signature version 4 for the specified request using the specified time."},{"ref":"AWS.Request.html#sign_v4_query/5","title":"AWS.Request.sign_v4_query/5","type":"function","doc":"Generate headers with an AWS signature version 4 for the specified request that can be transformed into a query string."},{"ref":"AWS.Request.html#sign_v4_query/6","title":"AWS.Request.sign_v4_query/6","type":"function","doc":"Generate headers with an AWS signature version 4 for the specified request using the specified time that can be transformed into a query string."},{"ref":"AWS.Request.Internal.html","title":"AWS.Request.Internal","type":"module","doc":""},{"ref":"AWS.Request.Internal.html#add_authorization_header/2","title":"AWS.Request.Internal.add_authorization_header/2","type":"function","doc":"Add an Authorization header with an AWS4-HMAC-SHA256 signature to the list of headers."},{"ref":"AWS.Request.Internal.html#add_content_hash/2","title":"AWS.Request.Internal.add_content_hash/2","type":"function","doc":"Add an X-Amz-Content-SHA256 header which is the hash of the payload. This header is required for S3 when using the v4 signature. Adding it in requests for all services does not cause any issues."},{"ref":"AWS.Request.Internal.html#add_date_header/2","title":"AWS.Request.Internal.add_date_header/2","type":"function","doc":"Add an X-Amz-Date header with a long date value in YYMMDDTHHMMSSZ format to a list of headers."},{"ref":"AWS.Request.Internal.html#add_security_token/2","title":"AWS.Request.Internal.add_security_token/2","type":"function","doc":"Add an X-Amz-Security-Token if credentials configurations are configured for it"},{"ref":"AWS.Request.Internal.html#authorization/4","title":"AWS.Request.Internal.authorization/4","type":"function","doc":"Generate an AWS4-HMAC-SHA256 authorization signature."},{"ref":"AWS.Request.Internal.html#canonical_header/1","title":"AWS.Request.Internal.canonical_header/1","type":"function","doc":"Strip leading and trailing whitespace around name and value, convert name to lowercase, and add a trailing newline."},{"ref":"AWS.Request.Internal.html#canonical_headers/1","title":"AWS.Request.Internal.canonical_headers/1","type":"function","doc":"Convert a list of headers to canonical header format. Leading and trailing whitespace around header names and values is stripped, header names are lowercased, and headers are newline-joined in alphabetical order (with a trailing newline)."},{"ref":"AWS.Request.Internal.html#canonical_request/4","title":"AWS.Request.Internal.canonical_request/4","type":"function","doc":"Process and merge request values into a canonical request for AWS signature version 4."},{"ref":"AWS.Request.Internal.html#credential_scope/3","title":"AWS.Request.Internal.credential_scope/3","type":"function","doc":"Generate a credential scope from a short date in YYMMDD format, a region identifier and a service identifier."},{"ref":"AWS.Request.Internal.html#signed_header/1","title":"AWS.Request.Internal.signed_header/1","type":"function","doc":"Strip leading and trailing whitespace around Name and convert it to lowercase."},{"ref":"AWS.Request.Internal.html#signed_headers/1","title":"AWS.Request.Internal.signed_headers/1","type":"function","doc":"Convert a list of headers to canonicals signed header format. Leading and trailing whitespace around names is stripped, header names are lowercased, and header names are semicolon-joined in alphabetical order."},{"ref":"AWS.Request.Internal.html#signing_key/4","title":"AWS.Request.Internal.signing_key/4","type":"function","doc":"Generate a signing key from a secret access key, a short date in YYMMDD format, a region identifier and a service identifier."},{"ref":"AWS.Request.Internal.html#split_url/1","title":"AWS.Request.Internal.split_url/1","type":"function","doc":"Strip the query string from the URL, if one if present, and return the URL and query string as separate values."},{"ref":"AWS.Request.Internal.html#string_to_sign/3","title":"AWS.Request.Internal.string_to_sign/3","type":"function","doc":"Generate the text to sign from a long date in YYMMDDTHHMMSSZ format, a credential scope and a hashed canonical request."},{"ref":"AWS.ResourceGroups.html","title":"AWS.ResourceGroups","type":"module","doc":"AWS Resource Groups AWS Resource Groups lets you organize AWS resources such as Amazon EC2 instances, Amazon Relational Database Service databases, and Amazon S3 buckets into groups using criteria that you define as tags. A resource group is a collection of resources that match the resource types specified in a query, and share one or more tags or portions of tags. You can create a group of resources based on their roles in your cloud infrastructure, lifecycle stages, regions, application layers, or virtually any criteria. Resource Groups enable you to automate management tasks, such as those in AWS Systems Manager Automation documents, on tag-related resources in AWS Systems Manager. Groups of tagged resources also let you quickly view a custom console in AWS Systems Manager that shows AWS Config compliance and other monitoring data about member resources. To create a resource group, build a resource query, and specify tags that identify the criteria that members of the group have in common. Tags are key-value pairs. For more information about Resource Groups, see the AWS Resource Groups User Guide. AWS Resource Groups uses a REST-compliant API that you can use to perform the following types of operations. Create, Read, Update, and Delete (CRUD) operations on resource groups and resource query entities Applying, editing, and removing tags from resource groups Resolving resource group member ARNs so they can be returned as search results Getting data about resources that are members of a group Searching AWS resources based on a resource query"},{"ref":"AWS.ResourceGroups.html#create_group/3","title":"AWS.ResourceGroups.create_group/3","type":"function","doc":"Creates a resource group with the specified name and description. You can optionally include a resource query, or a service configuration."},{"ref":"AWS.ResourceGroups.html#delete_group/3","title":"AWS.ResourceGroups.delete_group/3","type":"function","doc":"Deletes the specified resource group. Deleting a resource group does not delete any resources that are members of the group; it only deletes the group structure."},{"ref":"AWS.ResourceGroups.html#get_group/3","title":"AWS.ResourceGroups.get_group/3","type":"function","doc":"Returns information about a specified resource group."},{"ref":"AWS.ResourceGroups.html#get_group_configuration/3","title":"AWS.ResourceGroups.get_group_configuration/3","type":"function","doc":"Returns the service configuration associated with the specified resource group. AWS Resource Groups supports configurations for the following resource group types: AWS::EC2::CapacityReservationPool - Amazon EC2 capacity reservation pools. For more information, see Working with capacity reservation groups in the EC2 Users Guide."},{"ref":"AWS.ResourceGroups.html#get_group_query/3","title":"AWS.ResourceGroups.get_group_query/3","type":"function","doc":"Retrieves the resource query associated with the specified resource group."},{"ref":"AWS.ResourceGroups.html#get_tags/3","title":"AWS.ResourceGroups.get_tags/3","type":"function","doc":"Returns a list of tags that are associated with a resource group, specified by an ARN."},{"ref":"AWS.ResourceGroups.html#group_resources/3","title":"AWS.ResourceGroups.group_resources/3","type":"function","doc":"Adds the specified resources to the specified group."},{"ref":"AWS.ResourceGroups.html#list_group_resources/3","title":"AWS.ResourceGroups.list_group_resources/3","type":"function","doc":"Returns a list of ARNs of the resources that are members of a specified resource group."},{"ref":"AWS.ResourceGroups.html#list_groups/3","title":"AWS.ResourceGroups.list_groups/3","type":"function","doc":"Returns a list of existing resource groups in your account."},{"ref":"AWS.ResourceGroups.html#search_resources/3","title":"AWS.ResourceGroups.search_resources/3","type":"function","doc":"Returns a list of AWS resource identifiers that matches the specified query. The query uses the same format as a resource query in a CreateGroup or UpdateGroupQuery operation."},{"ref":"AWS.ResourceGroups.html#tag/4","title":"AWS.ResourceGroups.tag/4","type":"function","doc":"Adds tags to a resource group with the specified ARN. Existing tags on a resource group are not changed if they are not specified in the request parameters. Do not store personally identifiable information (PII) or other confidential or sensitive information in tags. We use tags to provide you with billing and administration services. Tags are not intended to be used for private or sensitive data."},{"ref":"AWS.ResourceGroups.html#ungroup_resources/3","title":"AWS.ResourceGroups.ungroup_resources/3","type":"function","doc":"Removes the specified resources from the specified group."},{"ref":"AWS.ResourceGroups.html#untag/4","title":"AWS.ResourceGroups.untag/4","type":"function","doc":"Deletes tags from a specified resource group."},{"ref":"AWS.ResourceGroups.html#update_group/3","title":"AWS.ResourceGroups.update_group/3","type":"function","doc":"Updates the description for an existing group. You cannot update the name of a resource group."},{"ref":"AWS.ResourceGroups.html#update_group_query/3","title":"AWS.ResourceGroups.update_group_query/3","type":"function","doc":"Updates the resource query of a group."},{"ref":"AWS.ResourceGroupsTaggingAPI.html","title":"AWS.ResourceGroupsTaggingAPI","type":"module","doc":"Resource Groups Tagging API This guide describes the API operations for the resource groups tagging. A tag is a label that you assign to an AWS resource. A tag consists of a key and a value, both of which you define. For example, if you have two Amazon EC2 instances, you might assign both a tag key of &quot;Stack.&quot; But the value of &quot;Stack&quot; might be &quot;Testing&quot; for one and &quot;Production&quot; for the other. Do not store personally identifiable information (PII) or other confidential or sensitive information in tags. We use tags to provide you with billing and administration services. Tags are not intended to be used for private or sensitive data. Tagging can help you organize your resources and enables you to simplify resource management, access management and cost allocation. You can use the resource groups tagging API operations to complete the following tasks: Tag and untag supported resources located in the specified Region for the AWS account. Use tag-based filters to search for resources located in the specified Region for the AWS account. List all existing tag keys in the specified Region for the AWS account. List all existing values for the specified key in the specified Region for the AWS account. To use resource groups tagging API operations, you must add the following permissions to your IAM policy: tag:GetResources tag:TagResources tag:UntagResources tag:GetTagKeys tag:GetTagValues You&#39;ll also need permissions to access the resources of individual services so that you can tag and untag those resources. For more information on IAM policies, see Managing IAM Policies in the IAM User Guide. Services that support the Resource Groups Tagging API * You can use the Resource Groups Tagging API to tag resources for the following AWS services. Alexa for Business (a4b) * API Gateway Amazon AppStream * AWS AppSync AWS App Mesh * Amazon Athena Amazon Aurora * AWS Backup AWS Certificate Manager * AWS Certificate Manager Private CA Amazon Cloud Directory * AWS Cloud Map AWS CloudFormation * Amazon CloudFront AWS CloudHSM * AWS CloudTrail Amazon CloudWatch (alarms only) * Amazon CloudWatch Events Amazon CloudWatch Logs Amazon Cloudwatch Synthetics * AWS CodeBuild AWS CodeCommit * AWS CodeGuru Profiler AWS CodePipeline * AWS CodeStar AWS CodeStar Connections Amazon Cognito Identity * Amazon Cognito User Pools Amazon Comprehend * AWS Config Amazon Connect AWS Data Exchange * AWS Data Pipeline AWS Database Migration Service * AWS DataSync AWS Device Farm * AWS Direct Connect AWS Directory Service * Amazon DynamoDB Amazon EBS * Amazon EC2 EC2 Image Builder * Amazon ECR Amazon ECS * Amazon EKS AWS Elastic Beanstalk * Amazon Elastic File System Elastic Load Balancing * Amazon Elastic Inference Amazon ElastiCache * Amazon Elasticsearch Service AWS Elemental MediaLive * AWS Elemental MediaPackage AWS Elemental MediaPackage VoD * AWS Elemental MediaTailor Amazon EMR * Amazon EventBridge Schema AWS Firewall Manager * Amazon Forecast Amazon Fraud Detector * Amazon FSx Amazon S3 Glacier AWS Global Accelerator * AWS Ground Station AWS Glue * Amazon GuardDuty Amazon Inspector * Amazon Interactive Video Service AWS IoT Analytics * AWS IoT Core AWS IoT Device Defender * AWS IoT Device Management AWS IoT Events * AWS IoT Greengrass AWS IoT 1-Click * AWS IoT Sitewise AWS IoT Things Graph * Amazon Kendra AWS Key Management Service * Amazon Kinesis Amazon Kinesis Data Analytics Amazon Kinesis Data Firehose AWS Lambda * Amazon Lex AWS License Manager * Amazon Lightsail Amazon Macie * Amazon Machine Learning Amazon MQ * Amazon MSK Amazon MSK * Amazon Neptune AWS Network Manager AWS OpsWorks * AWS OpsWorks CM AWS Organizations * Amazon Pinpoint Amazon Quantum Ledger Database (QLDB) * Amazon RDS Amazon Redshift * AWS Resource Access Manager AWS Resource Groups * AWS RoboMaker Amazon Route 53 * Amazon Route 53 Resolver Amazon S3 (buckets only) * Amazon SageMaker Savings Plans * AWS Secrets Manager AWS Security Hub * AWS Service Catalog Amazon Simple Email Service (SES) * Amazon Simple Notification Service (SNS) Amazon Simple Queue Service (SQS) * Amazon Simple Workflow Service AWS Step Functions * AWS Storage Gateway AWS Systems Manager * AWS Transfer for SFTP Amazon VPC * AWS WAF AWS WAF Regional * Amazon WorkLink Amazon WorkSpaces"},{"ref":"AWS.ResourceGroupsTaggingAPI.html#describe_report_creation/3","title":"AWS.ResourceGroupsTaggingAPI.describe_report_creation/3","type":"function","doc":"Describes the status of the StartReportCreation operation. You can call this operation only from the organization&#39;s master account and from the us-east-1 Region."},{"ref":"AWS.ResourceGroupsTaggingAPI.html#get_compliance_summary/3","title":"AWS.ResourceGroupsTaggingAPI.get_compliance_summary/3","type":"function","doc":"Returns a table that shows counts of resources that are noncompliant with their tag policies. For more information on tag policies, see Tag Policies in the AWS Organizations User Guide. You can call this operation only from the organization&#39;s master account and from the us-east-1 Region."},{"ref":"AWS.ResourceGroupsTaggingAPI.html#get_resources/3","title":"AWS.ResourceGroupsTaggingAPI.get_resources/3","type":"function","doc":"Returns all the tagged or previously tagged resources that are located in the specified Region for the AWS account. Depending on what information you want returned, you can also specify the following: Filters that specify what tags and resource types you want returned. The response includes all tags that are associated with the requested resources. Information about compliance with the account&#39;s effective tag policy. For more information on tag policies, see Tag Policies in the AWS Organizations User Guide. You can check the PaginationToken response parameter to determine if a query is complete. Queries occasionally return fewer results on a page than allowed. The PaginationToken response parameter value is null only when there are no more results to display."},{"ref":"AWS.ResourceGroupsTaggingAPI.html#get_tag_keys/3","title":"AWS.ResourceGroupsTaggingAPI.get_tag_keys/3","type":"function","doc":"Returns all tag keys in the specified Region for the AWS account."},{"ref":"AWS.ResourceGroupsTaggingAPI.html#get_tag_values/3","title":"AWS.ResourceGroupsTaggingAPI.get_tag_values/3","type":"function","doc":"Returns all tag values for the specified key in the specified Region for the AWS account."},{"ref":"AWS.ResourceGroupsTaggingAPI.html#start_report_creation/3","title":"AWS.ResourceGroupsTaggingAPI.start_report_creation/3","type":"function","doc":"Generates a report that lists all tagged resources in accounts across your organization and tells whether each resource is compliant with the effective tag policy. Compliance data is refreshed daily. The generated report is saved to the following location: s3://example-bucket/AwsTagPolicies/o-exampleorgid/YYYY-MM-ddTHH:mm:ssZ/report.csv You can call this operation only from the organization&#39;s master account and from the us-east-1 Region."},{"ref":"AWS.ResourceGroupsTaggingAPI.html#tag_resources/3","title":"AWS.ResourceGroupsTaggingAPI.tag_resources/3","type":"function","doc":"Applies one or more tags to the specified resources. Note the following: Not all resources can have tags. For a list of services that support tagging, see this list. Each resource can have up to 50 tags. For other limits, see Tag Naming and Usage Conventions in the AWS General Reference.* You can only tag resources that are located in the specified Region for the AWS account. To add tags to a resource, you need the necessary permissions for the service that the resource belongs to as well as permissions for adding tags. For more information, see this list. Do not store personally identifiable information (PII) or other confidential or sensitive information in tags. We use tags to provide you with billing and administration services. Tags are not intended to be used for private or sensitive data."},{"ref":"AWS.ResourceGroupsTaggingAPI.html#untag_resources/3","title":"AWS.ResourceGroupsTaggingAPI.untag_resources/3","type":"function","doc":"Removes the specified tags from the specified resources. When you specify a tag key, the action removes both that key and its associated value. The operation succeeds even if you attempt to remove tags from a resource that were already removed. Note the following: To remove tags from a resource, you need the necessary permissions for the service that the resource belongs to as well as permissions for removing tags. For more information, see this list. You can only tag resources that are located in the specified Region for the AWS account."},{"ref":"AWS.RoboMaker.html","title":"AWS.RoboMaker","type":"module","doc":"This section provides documentation for the AWS RoboMaker API operations."},{"ref":"AWS.RoboMaker.html#batch_delete_worlds/3","title":"AWS.RoboMaker.batch_delete_worlds/3","type":"function","doc":"Deletes one or more worlds in a batch operation."},{"ref":"AWS.RoboMaker.html#batch_describe_simulation_job/3","title":"AWS.RoboMaker.batch_describe_simulation_job/3","type":"function","doc":"Describes one or more simulation jobs."},{"ref":"AWS.RoboMaker.html#cancel_deployment_job/3","title":"AWS.RoboMaker.cancel_deployment_job/3","type":"function","doc":"Cancels the specified deployment job."},{"ref":"AWS.RoboMaker.html#cancel_simulation_job/3","title":"AWS.RoboMaker.cancel_simulation_job/3","type":"function","doc":"Cancels the specified simulation job."},{"ref":"AWS.RoboMaker.html#cancel_simulation_job_batch/3","title":"AWS.RoboMaker.cancel_simulation_job_batch/3","type":"function","doc":"Cancels a simulation job batch. When you cancel a simulation job batch, you are also cancelling all of the active simulation jobs created as part of the batch."},{"ref":"AWS.RoboMaker.html#cancel_world_export_job/3","title":"AWS.RoboMaker.cancel_world_export_job/3","type":"function","doc":"Cancels the specified export job."},{"ref":"AWS.RoboMaker.html#cancel_world_generation_job/3","title":"AWS.RoboMaker.cancel_world_generation_job/3","type":"function","doc":"Cancels the specified world generator job."},{"ref":"AWS.RoboMaker.html#create_deployment_job/3","title":"AWS.RoboMaker.create_deployment_job/3","type":"function","doc":"Deploys a specific version of a robot application to robots in a fleet. The robot application must have a numbered applicationVersion for consistency reasons. To create a new version, use CreateRobotApplicationVersion or see Creating a Robot Application Version. After 90 days, deployment jobs expire and will be deleted. They will no longer be accessible."},{"ref":"AWS.RoboMaker.html#create_fleet/3","title":"AWS.RoboMaker.create_fleet/3","type":"function","doc":"Creates a fleet, a logical group of robots running the same robot application."},{"ref":"AWS.RoboMaker.html#create_robot/3","title":"AWS.RoboMaker.create_robot/3","type":"function","doc":"Creates a robot."},{"ref":"AWS.RoboMaker.html#create_robot_application/3","title":"AWS.RoboMaker.create_robot_application/3","type":"function","doc":"Creates a robot application."},{"ref":"AWS.RoboMaker.html#create_robot_application_version/3","title":"AWS.RoboMaker.create_robot_application_version/3","type":"function","doc":"Creates a version of a robot application."},{"ref":"AWS.RoboMaker.html#create_simulation_application/3","title":"AWS.RoboMaker.create_simulation_application/3","type":"function","doc":"Creates a simulation application."},{"ref":"AWS.RoboMaker.html#create_simulation_application_version/3","title":"AWS.RoboMaker.create_simulation_application_version/3","type":"function","doc":"Creates a simulation application with a specific revision id."},{"ref":"AWS.RoboMaker.html#create_simulation_job/3","title":"AWS.RoboMaker.create_simulation_job/3","type":"function","doc":"Creates a simulation job. After 90 days, simulation jobs expire and will be deleted. They will no longer be accessible."},{"ref":"AWS.RoboMaker.html#create_world_export_job/3","title":"AWS.RoboMaker.create_world_export_job/3","type":"function","doc":"Creates a world export job."},{"ref":"AWS.RoboMaker.html#create_world_generation_job/3","title":"AWS.RoboMaker.create_world_generation_job/3","type":"function","doc":"Creates worlds using the specified template."},{"ref":"AWS.RoboMaker.html#create_world_template/3","title":"AWS.RoboMaker.create_world_template/3","type":"function","doc":"Creates a world template."},{"ref":"AWS.RoboMaker.html#delete_fleet/3","title":"AWS.RoboMaker.delete_fleet/3","type":"function","doc":"Deletes a fleet."},{"ref":"AWS.RoboMaker.html#delete_robot/3","title":"AWS.RoboMaker.delete_robot/3","type":"function","doc":"Deletes a robot."},{"ref":"AWS.RoboMaker.html#delete_robot_application/3","title":"AWS.RoboMaker.delete_robot_application/3","type":"function","doc":"Deletes a robot application."},{"ref":"AWS.RoboMaker.html#delete_simulation_application/3","title":"AWS.RoboMaker.delete_simulation_application/3","type":"function","doc":"Deletes a simulation application."},{"ref":"AWS.RoboMaker.html#delete_world_template/3","title":"AWS.RoboMaker.delete_world_template/3","type":"function","doc":"Deletes a world template."},{"ref":"AWS.RoboMaker.html#deregister_robot/3","title":"AWS.RoboMaker.deregister_robot/3","type":"function","doc":"Deregisters a robot."},{"ref":"AWS.RoboMaker.html#describe_deployment_job/3","title":"AWS.RoboMaker.describe_deployment_job/3","type":"function","doc":"Describes a deployment job."},{"ref":"AWS.RoboMaker.html#describe_fleet/3","title":"AWS.RoboMaker.describe_fleet/3","type":"function","doc":"Describes a fleet."},{"ref":"AWS.RoboMaker.html#describe_robot/3","title":"AWS.RoboMaker.describe_robot/3","type":"function","doc":"Describes a robot."},{"ref":"AWS.RoboMaker.html#describe_robot_application/3","title":"AWS.RoboMaker.describe_robot_application/3","type":"function","doc":"Describes a robot application."},{"ref":"AWS.RoboMaker.html#describe_simulation_application/3","title":"AWS.RoboMaker.describe_simulation_application/3","type":"function","doc":"Describes a simulation application."},{"ref":"AWS.RoboMaker.html#describe_simulation_job/3","title":"AWS.RoboMaker.describe_simulation_job/3","type":"function","doc":"Describes a simulation job."},{"ref":"AWS.RoboMaker.html#describe_simulation_job_batch/3","title":"AWS.RoboMaker.describe_simulation_job_batch/3","type":"function","doc":"Describes a simulation job batch."},{"ref":"AWS.RoboMaker.html#describe_world/3","title":"AWS.RoboMaker.describe_world/3","type":"function","doc":"Describes a world."},{"ref":"AWS.RoboMaker.html#describe_world_export_job/3","title":"AWS.RoboMaker.describe_world_export_job/3","type":"function","doc":"Describes a world export job."},{"ref":"AWS.RoboMaker.html#describe_world_generation_job/3","title":"AWS.RoboMaker.describe_world_generation_job/3","type":"function","doc":"Describes a world generation job."},{"ref":"AWS.RoboMaker.html#describe_world_template/3","title":"AWS.RoboMaker.describe_world_template/3","type":"function","doc":"Describes a world template."},{"ref":"AWS.RoboMaker.html#get_world_template_body/3","title":"AWS.RoboMaker.get_world_template_body/3","type":"function","doc":"Gets the world template body."},{"ref":"AWS.RoboMaker.html#list_deployment_jobs/3","title":"AWS.RoboMaker.list_deployment_jobs/3","type":"function","doc":"Returns a list of deployment jobs for a fleet. You can optionally provide filters to retrieve specific deployment jobs."},{"ref":"AWS.RoboMaker.html#list_fleets/3","title":"AWS.RoboMaker.list_fleets/3","type":"function","doc":"Returns a list of fleets. You can optionally provide filters to retrieve specific fleets."},{"ref":"AWS.RoboMaker.html#list_robot_applications/3","title":"AWS.RoboMaker.list_robot_applications/3","type":"function","doc":"Returns a list of robot application. You can optionally provide filters to retrieve specific robot applications."},{"ref":"AWS.RoboMaker.html#list_robots/3","title":"AWS.RoboMaker.list_robots/3","type":"function","doc":"Returns a list of robots. You can optionally provide filters to retrieve specific robots."},{"ref":"AWS.RoboMaker.html#list_simulation_applications/3","title":"AWS.RoboMaker.list_simulation_applications/3","type":"function","doc":"Returns a list of simulation applications. You can optionally provide filters to retrieve specific simulation applications."},{"ref":"AWS.RoboMaker.html#list_simulation_job_batches/3","title":"AWS.RoboMaker.list_simulation_job_batches/3","type":"function","doc":"Returns a list simulation job batches. You can optionally provide filters to retrieve specific simulation batch jobs."},{"ref":"AWS.RoboMaker.html#list_simulation_jobs/3","title":"AWS.RoboMaker.list_simulation_jobs/3","type":"function","doc":"Returns a list of simulation jobs. You can optionally provide filters to retrieve specific simulation jobs."},{"ref":"AWS.RoboMaker.html#list_tags_for_resource/3","title":"AWS.RoboMaker.list_tags_for_resource/3","type":"function","doc":"Lists all tags on a AWS RoboMaker resource."},{"ref":"AWS.RoboMaker.html#list_world_export_jobs/3","title":"AWS.RoboMaker.list_world_export_jobs/3","type":"function","doc":"Lists world export jobs."},{"ref":"AWS.RoboMaker.html#list_world_generation_jobs/3","title":"AWS.RoboMaker.list_world_generation_jobs/3","type":"function","doc":"Lists world generator jobs."},{"ref":"AWS.RoboMaker.html#list_world_templates/3","title":"AWS.RoboMaker.list_world_templates/3","type":"function","doc":"Lists world templates."},{"ref":"AWS.RoboMaker.html#list_worlds/3","title":"AWS.RoboMaker.list_worlds/3","type":"function","doc":"Lists worlds."},{"ref":"AWS.RoboMaker.html#register_robot/3","title":"AWS.RoboMaker.register_robot/3","type":"function","doc":"Registers a robot with a fleet."},{"ref":"AWS.RoboMaker.html#restart_simulation_job/3","title":"AWS.RoboMaker.restart_simulation_job/3","type":"function","doc":"Restarts a running simulation job."},{"ref":"AWS.RoboMaker.html#start_simulation_job_batch/3","title":"AWS.RoboMaker.start_simulation_job_batch/3","type":"function","doc":"Starts a new simulation job batch. The batch is defined using one or more SimulationJobRequest objects."},{"ref":"AWS.RoboMaker.html#sync_deployment_job/3","title":"AWS.RoboMaker.sync_deployment_job/3","type":"function","doc":"Syncrhonizes robots in a fleet to the latest deployment. This is helpful if robots were added after a deployment."},{"ref":"AWS.RoboMaker.html#tag_resource/4","title":"AWS.RoboMaker.tag_resource/4","type":"function","doc":"Adds or edits tags for a AWS RoboMaker resource. Each tag consists of a tag key and a tag value. Tag keys and tag values are both required, but tag values can be empty strings. For information about the rules that apply to tag keys and tag values, see User-Defined Tag Restrictions in the AWS Billing and Cost Management User Guide."},{"ref":"AWS.RoboMaker.html#untag_resource/4","title":"AWS.RoboMaker.untag_resource/4","type":"function","doc":"Removes the specified tags from the specified AWS RoboMaker resource. To remove a tag, specify the tag key. To change the tag value of an existing tag key, use TagResource ."},{"ref":"AWS.RoboMaker.html#update_robot_application/3","title":"AWS.RoboMaker.update_robot_application/3","type":"function","doc":"Updates a robot application."},{"ref":"AWS.RoboMaker.html#update_simulation_application/3","title":"AWS.RoboMaker.update_simulation_application/3","type":"function","doc":"Updates a simulation application."},{"ref":"AWS.RoboMaker.html#update_world_template/3","title":"AWS.RoboMaker.update_world_template/3","type":"function","doc":"Updates a world template."},{"ref":"AWS.Route53.html","title":"AWS.Route53","type":"module","doc":"Amazon Route 53 is a highly available and scalable Domain Name System (DNS) web service."},{"ref":"AWS.Route53.html#associate_v_p_c_with_hosted_zone/4","title":"AWS.Route53.associate_v_p_c_with_hosted_zone/4","type":"function","doc":"Associates an Amazon VPC with a private hosted zone. To perform the association, the VPC and the private hosted zone must already exist. You can&#39;t convert a public hosted zone into a private hosted zone. If you want to associate a VPC that was created by using one AWS account with a private hosted zone that was created by using a different account, the AWS account that created the private hosted zone must first submit a CreateVPCAssociationAuthorization request. Then the account that created the VPC must submit an AssociateVPCWithHostedZone request."},{"ref":"AWS.Route53.html#change_resource_record_sets/4","title":"AWS.Route53.change_resource_record_sets/4","type":"function","doc":"Creates, changes, or deletes a resource record set, which contains authoritative DNS information for a specified domain name or subdomain name. For example, you can use ChangeResourceRecordSets to create a resource record set that routes traffic for test.example.com to a web server that has an IP address of 192.0.2.44. Deleting Resource Record Sets To delete a resource record set, you must specify all the same values that you specified when you created it. Change Batches and Transactional Changes The request body must include a document with a ChangeResourceRecordSetsRequest element. The request body contains a list of change items, known as a change batch. Change batches are considered transactional changes. Route 53 validates the changes in the request and then either makes all or none of the changes in the change batch request. This ensures that DNS routing isn&#39;t adversely affected by partial changes to the resource record sets in a hosted zone. For example, suppose a change batch request contains two changes: it deletes the CNAME resource record set for www.example.com and creates an alias resource record set for www.example.com. If validation for both records succeeds, Route 53 deletes the first resource record set and creates the second resource record set in a single operation. If validation for either the DELETE or the CREATE action fails, then the request is canceled, and the original CNAME record continues to exist. If you try to delete the same resource record set more than once in a single change batch, Route 53 returns an InvalidChangeBatch error. Traffic Flow To create resource record sets for complex routing configurations, use either the traffic flow visual editor in the Route 53 console or the API actions for traffic policies and traffic policy instances. Save the configuration as a traffic policy, then associate the traffic policy with one or more domain names (such as example.com) or subdomain names (such as www.example.com), in the same hosted zone or in multiple hosted zones. You can roll back the updates if the new configuration isn&#39;t performing as expected. For more information, see Using Traffic Flow to Route DNS Traffic in the Amazon Route 53 Developer Guide. Create, Delete, and Upsert Use ChangeResourceRecordsSetsRequest to perform the following actions: CREATE: Creates a resource record set that has the specified values. DELETE: Deletes an existing resource record set that has the specified values. UPSERT: If a resource record set does not already exist, AWS creates it. If a resource set does exist, Route 53 updates it with the values in the request. Syntaxes for Creating, Updating, and Deleting Resource Record Sets The syntax for a request depends on the type of resource record set that you want to create, delete, or update, such as weighted, alias, or failover. The XML elements in your request must appear in the order listed in the syntax. For an example for each type of resource record set, see &quot;Examples.&quot; Don&#39;t refer to the syntax in the &quot;Parameter Syntax&quot; section, which includes all of the elements for every kind of resource record set that you can create, delete, or update by using ChangeResourceRecordSets. Change Propagation to Route 53 DNS Servers When you submit a ChangeResourceRecordSets request, Route 53 propagates your changes to all of the Route 53 authoritative DNS servers. While your changes are propagating, GetChange returns a status of PENDING. When propagation is complete, GetChange returns a status of INSYNC. Changes generally propagate to all Route 53 name servers within 60 seconds. For more information, see GetChange. Limits on ChangeResourceRecordSets Requests For information about the limits on a ChangeResourceRecordSets request, see Limits in the Amazon Route 53 Developer Guide."},{"ref":"AWS.Route53.html#change_tags_for_resource/5","title":"AWS.Route53.change_tags_for_resource/5","type":"function","doc":"Adds, edits, or deletes tags for a health check or a hosted zone. For information about using tags for cost allocation, see Using Cost Allocation Tags in the AWS Billing and Cost Management User Guide."},{"ref":"AWS.Route53.html#create_health_check/3","title":"AWS.Route53.create_health_check/3","type":"function","doc":"Creates a new health check. For information about adding health checks to resource record sets, see HealthCheckId in ChangeResourceRecordSets. ELB Load Balancers If you&#39;re registering EC2 instances with an Elastic Load Balancing (ELB) load balancer, do not create Amazon Route 53 health checks for the EC2 instances. When you register an EC2 instance with a load balancer, you configure settings for an ELB health check, which performs a similar function to a Route 53 health check. Private Hosted Zones You can associate health checks with failover resource record sets in a private hosted zone. Note the following: Route 53 health checkers are outside the VPC. To check the health of an endpoint within a VPC by IP address, you must assign a public IP address to the instance in the VPC. You can configure a health checker to check the health of an external resource that the instance relies on, such as a database server. You can create a CloudWatch metric, associate an alarm with the metric, and then create a health check that is based on the state of the alarm. For example, you might create a CloudWatch metric that checks the status of the Amazon EC2 StatusCheckFailed metric, add an alarm to the metric, and then create a health check that is based on the state of the alarm. For information about creating CloudWatch metrics and alarms by using the CloudWatch console, see the Amazon CloudWatch User Guide."},{"ref":"AWS.Route53.html#create_hosted_zone/3","title":"AWS.Route53.create_hosted_zone/3","type":"function","doc":"Creates a new public or private hosted zone. You create records in a public hosted zone to define how you want to route traffic on the internet for a domain, such as example.com, and its subdomains (apex.example.com, acme.example.com). You create records in a private hosted zone to define how you want to route traffic for a domain and its subdomains within one or more Amazon Virtual Private Clouds (Amazon VPCs). You can&#39;t convert a public hosted zone to a private hosted zone or vice versa. Instead, you must create a new hosted zone with the same name and create new resource record sets. For more information about charges for hosted zones, see Amazon Route 53 Pricing. Note the following: You can&#39;t create a hosted zone for a top-level domain (TLD) such as .com. For public hosted zones, Route 53 automatically creates a default SOA record and four NS records for the zone. For more information about SOA and NS records, see NS and SOA Records that Route 53 Creates for a Hosted Zone in the Amazon Route 53 Developer Guide. If you want to use the same name servers for multiple public hosted zones, you can optionally associate a reusable delegation set with the hosted zone. See the DelegationSetId element. If your domain is registered with a registrar other than Route 53, you must update the name servers with your registrar to make Route 53 the DNS service for the domain. For more information, see Migrating DNS Service for an Existing Domain to Amazon Route 53 in the Amazon Route 53 Developer Guide. When you submit a CreateHostedZone request, the initial status of the hosted zone is PENDING. For public hosted zones, this means that the NS and SOA records are not yet available on all Route 53 DNS servers. When the NS and SOA records are available, the status of the zone changes to INSYNC."},{"ref":"AWS.Route53.html#create_query_logging_config/3","title":"AWS.Route53.create_query_logging_config/3","type":"function","doc":"Creates a configuration for DNS query logging. After you create a query logging configuration, Amazon Route 53 begins to publish log data to an Amazon CloudWatch Logs log group. DNS query logs contain information about the queries that Route 53 receives for a specified public hosted zone, such as the following: Route 53 edge location that responded to the DNS query Domain or subdomain that was requested DNS record type, such as A or AAAA DNS response code, such as NoError or ServFail Definitions Log Group and Resource Policy Before you create a query logging configuration, perform the following operations. If you create a query logging configuration using the Route 53 console, Route 53 performs these operations automatically. Create a CloudWatch Logs log group, and make note of the ARN, which you specify when you create a query logging configuration. Note the following: You must create the log group in the us-east-1 region. You must use the same AWS account to create the log group and the hosted zone that you want to configure query logging for. When you create log groups for query logging, we recommend that you use a consistent prefix, for example: /aws/route53/*hosted zone name* In the next step, you&#39;ll create a resource policy, which controls access to one or more log groups and the associated AWS resources, such as Route 53 hosted zones. There&#39;s a limit on the number of resource policies that you can create, so we recommend that you use a consistent prefix so you can use the same resource policy for all the log groups that you create for query logging. Create a CloudWatch Logs resource policy, and give it the permissions that Route 53 needs to create log streams and to send query logs to log streams. For the value of Resource, specify the ARN for the log group that you created in the previous step. To use the same resource policy for all the CloudWatch Logs log groups that you created for query logging configurations, replace the hosted zone name with *, for example: arn:aws:logs:us-east-1:123412341234:log-group:/aws/route53/* You can&#39;t use the CloudWatch console to create or edit a resource policy. You must use the CloudWatch API, one of the AWS SDKs, or the AWS CLI. Log Streams and Edge Locations When Route 53 finishes creating the configuration for DNS query logging, it does the following: Creates a log stream for an edge location the first time that the edge location responds to DNS queries for the specified hosted zone. That log stream is used to log all queries that Route 53 responds to for that edge location. Begins to send query logs to the applicable log stream. The name of each log stream is in the following format: *hosted zone ID*/*edge location code* The edge location code is a three-letter code and an arbitrarily assigned number, for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) For a list of edge locations, see &quot;The Route 53 Global Network&quot; on the Route 53 Product Details page. Queries That Are Logged Query logs contain only the queries that DNS resolvers forward to Route 53. If a DNS resolver has already cached the response to a query (such as the IP address for a load balancer for example.com), the resolver will continue to return the cached response. It doesn&#39;t forward another query to Route 53 until the TTL for the corresponding resource record set expires. Depending on how many DNS queries are submitted for a resource record set, and depending on the TTL for that resource record set, query logs might contain information about only one query out of every several thousand queries that are submitted to DNS. For more information about how DNS works, see Routing Internet Traffic to Your Website or Web Application in the Amazon Route 53 Developer Guide. Log File Format For a list of the values in each query log and the format of each value, see Logging DNS Queries in the Amazon Route 53 Developer Guide. Pricing For information about charges for query logs, see Amazon CloudWatch Pricing. How to Stop Logging If you want Route 53 to stop sending query logs to CloudWatch Logs, delete the query logging configuration. For more information, see DeleteQueryLoggingConfig."},{"ref":"AWS.Route53.html#create_reusable_delegation_set/3","title":"AWS.Route53.create_reusable_delegation_set/3","type":"function","doc":"Creates a delegation set (a group of four name servers) that can be reused by multiple hosted zones that were created by the same AWS account. You can also create a reusable delegation set that uses the four name servers that are associated with an existing hosted zone. Specify the hosted zone ID in the CreateReusableDelegationSet request. You can&#39;t associate a reusable delegation set with a private hosted zone. For information about using a reusable delegation set to configure white label name servers, see Configuring White Label Name Servers. The process for migrating existing hosted zones to use a reusable delegation set is comparable to the process for configuring white label name servers. You need to perform the following steps: Create a reusable delegation set. Recreate hosted zones, and reduce the TTL to 60 seconds or less. Recreate resource record sets in the new hosted zones. Change the registrar&#39;s name servers to use the name servers for the new hosted zones. Monitor traffic for the website or application. Change TTLs back to their original values. If you want to migrate existing hosted zones to use a reusable delegation set, the existing hosted zones can&#39;t use any of the name servers that are assigned to the reusable delegation set. If one or more hosted zones do use one or more name servers that are assigned to the reusable delegation set, you can do one of the following: For small numbers of hosted zonesup to a few hundredit&#39;s relatively easy to create reusable delegation sets until you get one that has four name servers that don&#39;t overlap with any of the name servers in your hosted zones. For larger numbers of hosted zones, the easiest solution is to use more than one reusable delegation set. For larger numbers of hosted zones, you can also migrate hosted zones that have overlapping name servers to hosted zones that don&#39;t have overlapping name servers, then migrate the hosted zones again to use the reusable delegation set."},{"ref":"AWS.Route53.html#create_traffic_policy/3","title":"AWS.Route53.create_traffic_policy/3","type":"function","doc":"Creates a traffic policy, which you use to create multiple DNS resource record sets for one domain name (such as example.com) or one subdomain name (such as www.example.com)."},{"ref":"AWS.Route53.html#create_traffic_policy_instance/3","title":"AWS.Route53.create_traffic_policy_instance/3","type":"function","doc":"Creates resource record sets in a specified hosted zone based on the settings in a specified traffic policy version. In addition, CreateTrafficPolicyInstance associates the resource record sets with a specified domain name (such as example.com) or subdomain name (such as www.example.com). Amazon Route 53 responds to DNS queries for the domain or subdomain name by using the resource record sets that CreateTrafficPolicyInstance created."},{"ref":"AWS.Route53.html#create_traffic_policy_version/4","title":"AWS.Route53.create_traffic_policy_version/4","type":"function","doc":"Creates a new version of an existing traffic policy. When you create a new version of a traffic policy, you specify the ID of the traffic policy that you want to update and a JSON-formatted document that describes the new version. You use traffic policies to create multiple DNS resource record sets for one domain name (such as example.com) or one subdomain name (such as www.example.com). You can create a maximum of 1000 versions of a traffic policy. If you reach the limit and need to create another version, you&#39;ll need to start a new traffic policy."},{"ref":"AWS.Route53.html#create_v_p_c_association_authorization/4","title":"AWS.Route53.create_v_p_c_association_authorization/4","type":"function","doc":"Authorizes the AWS account that created a specified VPC to submit an AssociateVPCWithHostedZone request to associate the VPC with a specified hosted zone that was created by a different account. To submit a CreateVPCAssociationAuthorization request, you must use the account that created the hosted zone. After you authorize the association, use the account that created the VPC to submit an AssociateVPCWithHostedZone request. If you want to associate multiple VPCs that you created by using one account with a hosted zone that you created by using a different account, you must submit one authorization request for each VPC."},{"ref":"AWS.Route53.html#delete_health_check/4","title":"AWS.Route53.delete_health_check/4","type":"function","doc":"Deletes a health check. Amazon Route 53 does not prevent you from deleting a health check even if the health check is associated with one or more resource record sets. If you delete a health check and you don&#39;t update the associated resource record sets, the future status of the health check can&#39;t be predicted and may change. This will affect the routing of DNS queries for your DNS failover configuration. For more information, see Replacing and Deleting Health Checks in the Amazon Route 53 Developer Guide. If you&#39;re using AWS Cloud Map and you configured Cloud Map to create a Route 53 health check when you register an instance, you can&#39;t use the Route 53 DeleteHealthCheck command to delete the health check. The health check is deleted automatically when you deregister the instance; there can be a delay of several hours before the health check is deleted from Route 53."},{"ref":"AWS.Route53.html#delete_hosted_zone/4","title":"AWS.Route53.delete_hosted_zone/4","type":"function","doc":"Deletes a hosted zone. If the hosted zone was created by another service, such as AWS Cloud Map, see Deleting Public Hosted Zones That Were Created by Another Service in the Amazon Route 53 Developer Guide for information about how to delete it. (The process is the same for public and private hosted zones that were created by another service.) If you want to keep your domain registration but you want to stop routing internet traffic to your website or web application, we recommend that you delete resource record sets in the hosted zone instead of deleting the hosted zone. If you delete a hosted zone, you can&#39;t undelete it. You must create a new hosted zone and update the name servers for your domain registration, which can require up to 48 hours to take effect. (If you delegated responsibility for a subdomain to a hosted zone and you delete the child hosted zone, you must update the name servers in the parent hosted zone.) In addition, if you delete a hosted zone, someone could hijack the domain and route traffic to their own resources using your domain name. If you want to avoid the monthly charge for the hosted zone, you can transfer DNS service for the domain to a free DNS service. When you transfer DNS service, you have to update the name servers for the domain registration. If the domain is registered with Route 53, see UpdateDomainNameservers for information about how to replace Route 53 name servers with name servers for the new DNS service. If the domain is registered with another registrar, use the method provided by the registrar to update name servers for the domain registration. For more information, perform an internet search on &quot;free DNS service.&quot; You can delete a hosted zone only if it contains only the default SOA record and NS resource record sets. If the hosted zone contains other resource record sets, you must delete them before you can delete the hosted zone. If you try to delete a hosted zone that contains other resource record sets, the request fails, and Route 53 returns a HostedZoneNotEmpty error. For information about deleting records from your hosted zone, see ChangeResourceRecordSets. To verify that the hosted zone has been deleted, do one of the following: Use the GetHostedZone action to request information about the hosted zone. Use the ListHostedZones action to get a list of the hosted zones associated with the current AWS account."},{"ref":"AWS.Route53.html#delete_query_logging_config/4","title":"AWS.Route53.delete_query_logging_config/4","type":"function","doc":"Deletes a configuration for DNS query logging. If you delete a configuration, Amazon Route 53 stops sending query logs to CloudWatch Logs. Route 53 doesn&#39;t delete any logs that are already in CloudWatch Logs. For more information about DNS query logs, see CreateQueryLoggingConfig."},{"ref":"AWS.Route53.html#delete_reusable_delegation_set/4","title":"AWS.Route53.delete_reusable_delegation_set/4","type":"function","doc":"Deletes a reusable delegation set. You can delete a reusable delegation set only if it isn&#39;t associated with any hosted zones. To verify that the reusable delegation set is not associated with any hosted zones, submit a GetReusableDelegationSet request and specify the ID of the reusable delegation set that you want to delete."},{"ref":"AWS.Route53.html#delete_traffic_policy/5","title":"AWS.Route53.delete_traffic_policy/5","type":"function","doc":"Deletes a traffic policy. When you delete a traffic policy, Route 53 sets a flag on the policy to indicate that it has been deleted. However, Route 53 never fully deletes the traffic policy. Note the following: Deleted traffic policies aren&#39;t listed if you run ListTrafficPolicies. * There&#39;s no way to get a list of deleted policies. If you retain the ID of the policy, you can get information about the policy, including the traffic policy document, by running GetTrafficPolicy."},{"ref":"AWS.Route53.html#delete_traffic_policy_instance/4","title":"AWS.Route53.delete_traffic_policy_instance/4","type":"function","doc":"Deletes a traffic policy instance and all of the resource record sets that Amazon Route 53 created when you created the instance. In the Route 53 console, traffic policy instances are known as policy records."},{"ref":"AWS.Route53.html#delete_v_p_c_association_authorization/4","title":"AWS.Route53.delete_v_p_c_association_authorization/4","type":"function","doc":"Removes authorization to submit an AssociateVPCWithHostedZone request to associate a specified VPC with a hosted zone that was created by a different account. You must use the account that created the hosted zone to submit a DeleteVPCAssociationAuthorization request. Sending this request only prevents the AWS account that created the VPC from associating the VPC with the Amazon Route 53 hosted zone in the future. If the VPC is already associated with the hosted zone, DeleteVPCAssociationAuthorization won&#39;t disassociate the VPC from the hosted zone. If you want to delete an existing association, use DisassociateVPCFromHostedZone."},{"ref":"AWS.Route53.html#disassociate_v_p_c_from_hosted_zone/4","title":"AWS.Route53.disassociate_v_p_c_from_hosted_zone/4","type":"function","doc":"Disassociates an Amazon Virtual Private Cloud (Amazon VPC) from an Amazon Route 53 private hosted zone. Note the following: You can&#39;t disassociate the last Amazon VPC from a private hosted zone. You can&#39;t convert a private hosted zone into a public hosted zone. You can submit a DisassociateVPCFromHostedZone request using either the account that created the hosted zone or the account that created the Amazon VPC. Some services, such as AWS Cloud Map and Amazon Elastic File System (Amazon EFS) automatically create hosted zones and associate VPCs with the hosted zones. A service can create a hosted zone using your account or using its own account. You can disassociate a VPC from a hosted zone only if the service created the hosted zone using your account. When you run DisassociateVPCFromHostedZone, if the hosted zone has a value for OwningAccount, you can use DisassociateVPCFromHostedZone. If the hosted zone has a value for OwningService, you can&#39;t use DisassociateVPCFromHostedZone."},{"ref":"AWS.Route53.html#get_account_limit/3","title":"AWS.Route53.get_account_limit/3","type":"function","doc":"Gets the specified limit for the current account, for example, the maximum number of health checks that you can create using the account. For the default limit, see Limits in the Amazon Route 53 Developer Guide. To request a higher limit, open a case. You can also view account limits in AWS Trusted Advisor. Sign in to the AWS Management Console and open the Trusted Advisor console at https://console.aws.amazon.com/trustedadvisor/. Then choose Service limits in the navigation pane."},{"ref":"AWS.Route53.html#get_change/3","title":"AWS.Route53.get_change/3","type":"function","doc":"Returns the current status of a change batch request. The status is one of the following values: PENDING indicates that the changes in this request have not propagated to all Amazon Route 53 DNS servers. This is the initial status of all change batch requests. INSYNC indicates that the changes have propagated to all Route 53 DNS servers."},{"ref":"AWS.Route53.html#get_checker_ip_ranges/2","title":"AWS.Route53.get_checker_ip_ranges/2","type":"function","doc":"GetCheckerIpRanges still works, but we recommend that you download ip-ranges.json, which includes IP address ranges for all AWS services. For more information, see IP Address Ranges of Amazon Route 53 Servers in the Amazon Route 53 Developer Guide."},{"ref":"AWS.Route53.html#get_geo_location/5","title":"AWS.Route53.get_geo_location/5","type":"function","doc":"Gets information about whether a specified geographic location is supported for Amazon Route 53 geolocation resource record sets. Use the following syntax to determine whether a continent is supported for geolocation: GET /2013-04-01/geolocation?continentcode=*two-letter abbreviation for a continent* Use the following syntax to determine whether a country is supported for geolocation: GET /2013-04-01/geolocation?countrycode=*two-character country code* Use the following syntax to determine whether a subdivision of a country is supported for geolocation: GET /2013-04-01/geolocation?countrycode=*two-character country code*&amp;subdivisioncode=*subdivision code*"},{"ref":"AWS.Route53.html#get_health_check/3","title":"AWS.Route53.get_health_check/3","type":"function","doc":"Gets information about a specified health check."},{"ref":"AWS.Route53.html#get_health_check_count/2","title":"AWS.Route53.get_health_check_count/2","type":"function","doc":"Retrieves the number of health checks that are associated with the current AWS account."},{"ref":"AWS.Route53.html#get_health_check_last_failure_reason/3","title":"AWS.Route53.get_health_check_last_failure_reason/3","type":"function","doc":"Gets the reason that a specified health check failed most recently."},{"ref":"AWS.Route53.html#get_health_check_status/3","title":"AWS.Route53.get_health_check_status/3","type":"function","doc":"Gets status of a specified health check."},{"ref":"AWS.Route53.html#get_hosted_zone/3","title":"AWS.Route53.get_hosted_zone/3","type":"function","doc":"Gets information about a specified hosted zone including the four name servers assigned to the hosted zone."},{"ref":"AWS.Route53.html#get_hosted_zone_count/2","title":"AWS.Route53.get_hosted_zone_count/2","type":"function","doc":"Retrieves the number of hosted zones that are associated with the current AWS account."},{"ref":"AWS.Route53.html#get_hosted_zone_limit/4","title":"AWS.Route53.get_hosted_zone_limit/4","type":"function","doc":"Gets the specified limit for a specified hosted zone, for example, the maximum number of records that you can create in the hosted zone. For the default limit, see Limits in the Amazon Route 53 Developer Guide. To request a higher limit, open a case."},{"ref":"AWS.Route53.html#get_query_logging_config/3","title":"AWS.Route53.get_query_logging_config/3","type":"function","doc":"Gets information about a specified configuration for DNS query logging. For more information about DNS query logs, see CreateQueryLoggingConfig and Logging DNS Queries."},{"ref":"AWS.Route53.html#get_reusable_delegation_set/3","title":"AWS.Route53.get_reusable_delegation_set/3","type":"function","doc":"Retrieves information about a specified reusable delegation set, including the four name servers that are assigned to the delegation set."},{"ref":"AWS.Route53.html#get_reusable_delegation_set_limit/4","title":"AWS.Route53.get_reusable_delegation_set_limit/4","type":"function","doc":"Gets the maximum number of hosted zones that you can associate with the specified reusable delegation set. For the default limit, see Limits in the Amazon Route 53 Developer Guide. To request a higher limit, open a case."},{"ref":"AWS.Route53.html#get_traffic_policy/4","title":"AWS.Route53.get_traffic_policy/4","type":"function","doc":"Gets information about a specific traffic policy version. For information about how of deleting a traffic policy affects the response from GetTrafficPolicy, see DeleteTrafficPolicy."},{"ref":"AWS.Route53.html#get_traffic_policy_instance/3","title":"AWS.Route53.get_traffic_policy_instance/3","type":"function","doc":"Gets information about a specified traffic policy instance. After you submit a CreateTrafficPolicyInstance or an UpdateTrafficPolicyInstance request, there&#39;s a brief delay while Amazon Route 53 creates the resource record sets that are specified in the traffic policy definition. For more information, see the State response element. In the Route 53 console, traffic policy instances are known as policy records."},{"ref":"AWS.Route53.html#get_traffic_policy_instance_count/2","title":"AWS.Route53.get_traffic_policy_instance_count/2","type":"function","doc":"Gets the number of traffic policy instances that are associated with the current AWS account."},{"ref":"AWS.Route53.html#list_geo_locations/6","title":"AWS.Route53.list_geo_locations/6","type":"function","doc":"Retrieves a list of supported geographic locations. Countries are listed first, and continents are listed last. If Amazon Route 53 supports subdivisions for a country (for example, states or provinces), the subdivisions for that country are listed in alphabetical order immediately after the corresponding country. For a list of supported geolocation codes, see the GeoLocation data type."},{"ref":"AWS.Route53.html#list_health_checks/4","title":"AWS.Route53.list_health_checks/4","type":"function","doc":"Retrieve a list of the health checks that are associated with the current AWS account."},{"ref":"AWS.Route53.html#list_hosted_zones/5","title":"AWS.Route53.list_hosted_zones/5","type":"function","doc":"Retrieves a list of the public and private hosted zones that are associated with the current AWS account. The response includes a HostedZones child element for each hosted zone. Amazon Route 53 returns a maximum of 100 items in each response. If you have a lot of hosted zones, you can use the maxitems parameter to list them in groups of up to 100."},{"ref":"AWS.Route53.html#list_hosted_zones_by_name/5","title":"AWS.Route53.list_hosted_zones_by_name/5","type":"function","doc":"Retrieves a list of your hosted zones in lexicographic order. The response includes a HostedZones child element for each hosted zone created by the current AWS account. ListHostedZonesByName sorts hosted zones by name with the labels reversed. For example: com.example.www. Note the trailing dot, which can change the sort order in some circumstances. If the domain name includes escape characters or Punycode, ListHostedZonesByName alphabetizes the domain name using the escaped or Punycoded value, which is the format that Amazon Route 53 saves in its database. For example, to create a hosted zone for exmple.com, you specify ex344mple.com for the domain name. ListHostedZonesByName alphabetizes it as: com.ex344mple. The labels are reversed and alphabetized using the escaped value. For more information about valid domain name formats, including internationalized domain names, see DNS Domain Name Format in the Amazon Route 53 Developer Guide. Route 53 returns up to 100 items in each response. If you have a lot of hosted zones, use the MaxItems parameter to list them in groups of up to 100. The response includes values that help navigate from one group of MaxItems hosted zones to the next: The DNSName and HostedZoneId elements in the response contain the values, if any, specified for the dnsname and hostedzoneid parameters in the request that produced the current response. The MaxItems element in the response contains the value, if any, that you specified for the maxitems parameter in the request that produced the current response. If the value of IsTruncated in the response is true, there are more hosted zones associated with the current AWS account. If IsTruncated is false, this response includes the last hosted zone that is associated with the current account. The NextDNSName element and NextHostedZoneId elements are omitted from the response. The NextDNSName and NextHostedZoneId elements in the response contain the domain name and the hosted zone ID of the next hosted zone that is associated with the current AWS account. If you want to list more hosted zones, make another call to ListHostedZonesByName, and specify the value of NextDNSName and NextHostedZoneId in the dnsname and hostedzoneid parameters, respectively."},{"ref":"AWS.Route53.html#list_hosted_zones_by_v_p_c/6","title":"AWS.Route53.list_hosted_zones_by_v_p_c/6","type":"function","doc":"Lists all the private hosted zones that a specified VPC is associated with, regardless of which AWS account or AWS service owns the hosted zones. The HostedZoneOwner structure in the response contains one of the following values: An OwningAccount element, which contains the account number of either the current AWS account or another AWS account. Some services, such as AWS Cloud Map, create hosted zones using the current account. An OwningService element, which identifies the AWS service that created and owns the hosted zone. For example, if a hosted zone was created by Amazon Elastic File System (Amazon EFS), the value of Owner is efs.amazonaws.com."},{"ref":"AWS.Route53.html#list_query_logging_configs/5","title":"AWS.Route53.list_query_logging_configs/5","type":"function","doc":"Lists the configurations for DNS query logging that are associated with the current AWS account or the configuration that is associated with a specified hosted zone. For more information about DNS query logs, see CreateQueryLoggingConfig. Additional information, including the format of DNS query logs, appears in Logging DNS Queries in the Amazon Route 53 Developer Guide."},{"ref":"AWS.Route53.html#list_resource_record_sets/7","title":"AWS.Route53.list_resource_record_sets/7","type":"function","doc":"Lists the resource record sets in a specified hosted zone. ListResourceRecordSets returns up to 100 resource record sets at a time in ASCII order, beginning at a position specified by the name and type elements. Sort order ListResourceRecordSets sorts results first by DNS name with the labels reversed, for example: com.example.www. Note the trailing dot, which can change the sort order when the record name contains characters that appear before . (decimal 46) in the ASCII table. These characters include the following: ! &quot; # $ % &amp; &#39; ( ) * + , - When multiple records have the same DNS name, ListResourceRecordSets sorts results by the record type. Specifying where to start listing records You can use the name and type elements to specify the resource record set that the list begins with: Definitions If you do not specify Name or Type The results begin with the first resource record set that the hosted zone contains. If you specify Name but not Type The results begin with the first resource record set in the list whose name is greater than or equal to Name. If you specify Type but not Name Amazon Route 53 returns the InvalidInput error. If you specify both Name and Type The results begin with the first resource record set in the list whose name is greater than or equal to Name, and whose type is greater than or equal to Type. Resource record sets that are PENDING This action returns the most current version of the records. This includes records that are PENDING, and that are not yet available on all Route 53 DNS servers. Changing resource record sets To ensure that you get an accurate listing of the resource record sets for a hosted zone at a point in time, do not submit a ChangeResourceRecordSets request while you&#39;re paging through the results of a ListResourceRecordSets request. If you do, some pages may display results without the latest changes while other pages display results with the latest changes. Displaying the next page of results If a ListResourceRecordSets command returns more than one page of results, the value of IsTruncated is true. To display the next page of results, get the values of NextRecordName, NextRecordType, and NextRecordIdentifier (if any) from the response. Then submit another ListResourceRecordSets request, and specify those values for StartRecordName, StartRecordType, and StartRecordIdentifier."},{"ref":"AWS.Route53.html#list_reusable_delegation_sets/4","title":"AWS.Route53.list_reusable_delegation_sets/4","type":"function","doc":"Retrieves a list of the reusable delegation sets that are associated with the current AWS account."},{"ref":"AWS.Route53.html#list_tags_for_resource/4","title":"AWS.Route53.list_tags_for_resource/4","type":"function","doc":"Lists tags for one health check or hosted zone. For information about using tags for cost allocation, see Using Cost Allocation Tags in the AWS Billing and Cost Management User Guide."},{"ref":"AWS.Route53.html#list_tags_for_resources/4","title":"AWS.Route53.list_tags_for_resources/4","type":"function","doc":"Lists tags for up to 10 health checks or hosted zones. For information about using tags for cost allocation, see Using Cost Allocation Tags in the AWS Billing and Cost Management User Guide."},{"ref":"AWS.Route53.html#list_traffic_policies/4","title":"AWS.Route53.list_traffic_policies/4","type":"function","doc":"Gets information about the latest version for every traffic policy that is associated with the current AWS account. Policies are listed in the order that they were created in. For information about how of deleting a traffic policy affects the response from ListTrafficPolicies, see DeleteTrafficPolicy."},{"ref":"AWS.Route53.html#list_traffic_policy_instances/6","title":"AWS.Route53.list_traffic_policy_instances/6","type":"function","doc":"Gets information about the traffic policy instances that you created by using the current AWS account. After you submit an UpdateTrafficPolicyInstance request, there&#39;s a brief delay while Amazon Route 53 creates the resource record sets that are specified in the traffic policy definition. For more information, see the State response element. Route 53 returns a maximum of 100 items in each response. If you have a lot of traffic policy instances, you can use the MaxItems parameter to list them in groups of up to 100."},{"ref":"AWS.Route53.html#list_traffic_policy_instances_by_hosted_zone/6","title":"AWS.Route53.list_traffic_policy_instances_by_hosted_zone/6","type":"function","doc":"Gets information about the traffic policy instances that you created in a specified hosted zone. After you submit a CreateTrafficPolicyInstance or an UpdateTrafficPolicyInstance request, there&#39;s a brief delay while Amazon Route 53 creates the resource record sets that are specified in the traffic policy definition. For more information, see the State response element. Route 53 returns a maximum of 100 items in each response. If you have a lot of traffic policy instances, you can use the MaxItems parameter to list them in groups of up to 100."},{"ref":"AWS.Route53.html#list_traffic_policy_instances_by_policy/8","title":"AWS.Route53.list_traffic_policy_instances_by_policy/8","type":"function","doc":"Gets information about the traffic policy instances that you created by using a specify traffic policy version. After you submit a CreateTrafficPolicyInstance or an UpdateTrafficPolicyInstance request, there&#39;s a brief delay while Amazon Route 53 creates the resource record sets that are specified in the traffic policy definition. For more information, see the State response element. Route 53 returns a maximum of 100 items in each response. If you have a lot of traffic policy instances, you can use the MaxItems parameter to list them in groups of up to 100."},{"ref":"AWS.Route53.html#list_traffic_policy_versions/5","title":"AWS.Route53.list_traffic_policy_versions/5","type":"function","doc":"Gets information about all of the versions for a specified traffic policy. Traffic policy versions are listed in numerical order by VersionNumber."},{"ref":"AWS.Route53.html#list_v_p_c_association_authorizations/5","title":"AWS.Route53.list_v_p_c_association_authorizations/5","type":"function","doc":"Gets a list of the VPCs that were created by other accounts and that can be associated with a specified hosted zone because you&#39;ve submitted one or more CreateVPCAssociationAuthorization requests. The response includes a VPCs element with a VPC child element for each VPC that can be associated with the hosted zone."},{"ref":"AWS.Route53.html#test_d_n_s_answer/8","title":"AWS.Route53.test_d_n_s_answer/8","type":"function","doc":"Gets the value that Amazon Route 53 returns in response to a DNS request for a specified record name and type. You can optionally specify the IP address of a DNS resolver, an EDNS0 client subnet IP address, and a subnet mask."},{"ref":"AWS.Route53.html#update_health_check/4","title":"AWS.Route53.update_health_check/4","type":"function","doc":"Updates an existing health check. Note that some values can&#39;t be updated. For more information about updating health checks, see Creating, Updating, and Deleting Health Checks in the Amazon Route 53 Developer Guide."},{"ref":"AWS.Route53.html#update_hosted_zone_comment/4","title":"AWS.Route53.update_hosted_zone_comment/4","type":"function","doc":"Updates the comment for a specified hosted zone."},{"ref":"AWS.Route53.html#update_traffic_policy_comment/5","title":"AWS.Route53.update_traffic_policy_comment/5","type":"function","doc":"Updates the comment for a specified traffic policy version."},{"ref":"AWS.Route53.html#update_traffic_policy_instance/4","title":"AWS.Route53.update_traffic_policy_instance/4","type":"function","doc":"Updates the resource record sets in a specified hosted zone that were created based on the settings in a specified traffic policy version. When you update a traffic policy instance, Amazon Route 53 continues to respond to DNS queries for the root resource record set name (such as example.com) while it replaces one group of resource record sets with another. Route 53 performs the following operations: Route 53 creates a new group of resource record sets based on the specified traffic policy. This is true regardless of how significant the differences are between the existing resource record sets and the new resource record sets. When all of the new resource record sets have been created, Route 53 starts to respond to DNS queries for the root resource record set name (such as example.com) by using the new resource record sets. Route 53 deletes the old group of resource record sets that are associated with the root resource record set name."},{"ref":"AWS.Route53Domains.html","title":"AWS.Route53Domains","type":"module","doc":"Amazon Route 53 API actions let you register domain names and perform related operations."},{"ref":"AWS.Route53Domains.html#accept_domain_transfer_from_another_aws_account/3","title":"AWS.Route53Domains.accept_domain_transfer_from_another_aws_account/3","type":"function","doc":"Accepts the transfer of a domain from another AWS account to the current AWS account. You initiate a transfer between AWS accounts using TransferDomainToAnotherAwsAccount. Use either ListOperations or GetOperationDetail to determine whether the operation succeeded. GetOperationDetail provides additional information, for example, Domain Transfer from Aws Account 111122223333 has been cancelled."},{"ref":"AWS.Route53Domains.html#cancel_domain_transfer_to_another_aws_account/3","title":"AWS.Route53Domains.cancel_domain_transfer_to_another_aws_account/3","type":"function","doc":"Cancels the transfer of a domain from the current AWS account to another AWS account. You initiate a transfer between AWS accounts using TransferDomainToAnotherAwsAccount. You must cancel the transfer before the other AWS account accepts the transfer using AcceptDomainTransferFromAnotherAwsAccount. Use either ListOperations or GetOperationDetail to determine whether the operation succeeded. GetOperationDetail provides additional information, for example, Domain Transfer from Aws Account 111122223333 has been cancelled."},{"ref":"AWS.Route53Domains.html#check_domain_availability/3","title":"AWS.Route53Domains.check_domain_availability/3","type":"function","doc":"This operation checks the availability of one domain name. Note that if the availability status of a domain is pending, you must submit another request to determine the availability of the domain name."},{"ref":"AWS.Route53Domains.html#check_domain_transferability/3","title":"AWS.Route53Domains.check_domain_transferability/3","type":"function","doc":"Checks whether a domain name can be transferred to Amazon Route 53."},{"ref":"AWS.Route53Domains.html#delete_tags_for_domain/3","title":"AWS.Route53Domains.delete_tags_for_domain/3","type":"function","doc":"This operation deletes the specified tags for a domain. All tag operations are eventually consistent; subsequent operations might not immediately represent all issued operations."},{"ref":"AWS.Route53Domains.html#disable_domain_auto_renew/3","title":"AWS.Route53Domains.disable_domain_auto_renew/3","type":"function","doc":"This operation disables automatic renewal of domain registration for the specified domain."},{"ref":"AWS.Route53Domains.html#disable_domain_transfer_lock/3","title":"AWS.Route53Domains.disable_domain_transfer_lock/3","type":"function","doc":"This operation removes the transfer lock on the domain (specifically the clientTransferProhibited status) to allow domain transfers. We recommend you refrain from performing this action unless you intend to transfer the domain to a different registrar. Successful submission returns an operation ID that you can use to track the progress and completion of the action. If the request is not completed successfully, the domain registrant will be notified by email."},{"ref":"AWS.Route53Domains.html#enable_domain_auto_renew/3","title":"AWS.Route53Domains.enable_domain_auto_renew/3","type":"function","doc":"This operation configures Amazon Route 53 to automatically renew the specified domain before the domain registration expires. The cost of renewing your domain registration is billed to your AWS account. The period during which you can renew a domain name varies by TLD. For a list of TLDs and their renewal policies, see Domains That You Can Register with Amazon Route 53 in the Amazon Route 53 Developer Guide. Route 53 requires that you renew before the end of the renewal period so we can complete processing before the deadline."},{"ref":"AWS.Route53Domains.html#enable_domain_transfer_lock/3","title":"AWS.Route53Domains.enable_domain_transfer_lock/3","type":"function","doc":"This operation sets the transfer lock on the domain (specifically the clientTransferProhibited status) to prevent domain transfers. Successful submission returns an operation ID that you can use to track the progress and completion of the action. If the request is not completed successfully, the domain registrant will be notified by email."},{"ref":"AWS.Route53Domains.html#get_contact_reachability_status/3","title":"AWS.Route53Domains.get_contact_reachability_status/3","type":"function","doc":"For operations that require confirmation that the email address for the registrant contact is valid, such as registering a new domain, this operation returns information about whether the registrant contact has responded. If you want us to resend the email, use the ResendContactReachabilityEmail operation."},{"ref":"AWS.Route53Domains.html#get_domain_detail/3","title":"AWS.Route53Domains.get_domain_detail/3","type":"function","doc":"This operation returns detailed information about a specified domain that is associated with the current AWS account. Contact information for the domain is also returned as part of the output."},{"ref":"AWS.Route53Domains.html#get_domain_suggestions/3","title":"AWS.Route53Domains.get_domain_suggestions/3","type":"function","doc":"The GetDomainSuggestions operation returns a list of suggested domain names."},{"ref":"AWS.Route53Domains.html#get_operation_detail/3","title":"AWS.Route53Domains.get_operation_detail/3","type":"function","doc":"This operation returns the current status of an operation that is not completed."},{"ref":"AWS.Route53Domains.html#list_domains/3","title":"AWS.Route53Domains.list_domains/3","type":"function","doc":"This operation returns all the domain names registered with Amazon Route 53 for the current AWS account."},{"ref":"AWS.Route53Domains.html#list_operations/3","title":"AWS.Route53Domains.list_operations/3","type":"function","doc":"Returns information about all of the operations that return an operation ID and that have ever been performed on domains that were registered by the current account."},{"ref":"AWS.Route53Domains.html#list_tags_for_domain/3","title":"AWS.Route53Domains.list_tags_for_domain/3","type":"function","doc":"This operation returns all of the tags that are associated with the specified domain. All tag operations are eventually consistent; subsequent operations might not immediately represent all issued operations."},{"ref":"AWS.Route53Domains.html#register_domain/3","title":"AWS.Route53Domains.register_domain/3","type":"function","doc":"This operation registers a domain. Domains are registered either by Amazon Registrar (for .com, .net, and .org domains) or by our registrar associate, Gandi (for all other domains). For some top-level domains (TLDs), this operation requires extra parameters. When you register a domain, Amazon Route 53 does the following: Creates a Route 53 hosted zone that has the same name as the domain. Route 53 assigns four name servers to your hosted zone and automatically updates your domain registration with the names of these name servers. Enables autorenew, so your domain registration will renew automatically each year. We&#39;ll notify you in advance of the renewal date so you can choose whether to renew the registration. Optionally enables privacy protection, so WHOIS queries return contact information either for Amazon Registrar (for .com, .net, and .org domains) or for our registrar associate, Gandi (for all other TLDs). If you don&#39;t enable privacy protection, WHOIS queries return the information that you entered for the registrant, admin, and tech contacts. If registration is successful, returns an operation ID that you can use to track the progress and completion of the action. If the request is not completed successfully, the domain registrant is notified by email. Charges your AWS account an amount based on the top-level domain. For more information, see Amazon Route 53 Pricing."},{"ref":"AWS.Route53Domains.html#reject_domain_transfer_from_another_aws_account/3","title":"AWS.Route53Domains.reject_domain_transfer_from_another_aws_account/3","type":"function","doc":"Rejects the transfer of a domain from another AWS account to the current AWS account. You initiate a transfer between AWS accounts using TransferDomainToAnotherAwsAccount. Use either ListOperations or GetOperationDetail to determine whether the operation succeeded. GetOperationDetail provides additional information, for example, Domain Transfer from Aws Account 111122223333 has been cancelled."},{"ref":"AWS.Route53Domains.html#renew_domain/3","title":"AWS.Route53Domains.renew_domain/3","type":"function","doc":"This operation renews a domain for the specified number of years. The cost of renewing your domain is billed to your AWS account. We recommend that you renew your domain several weeks before the expiration date. Some TLD registries delete domains before the expiration date if you haven&#39;t renewed far enough in advance. For more information about renewing domain registration, see Renewing Registration for a Domain in the Amazon Route 53 Developer Guide."},{"ref":"AWS.Route53Domains.html#resend_contact_reachability_email/3","title":"AWS.Route53Domains.resend_contact_reachability_email/3","type":"function","doc":"For operations that require confirmation that the email address for the registrant contact is valid, such as registering a new domain, this operation resends the confirmation email to the current email address for the registrant contact."},{"ref":"AWS.Route53Domains.html#retrieve_domain_auth_code/3","title":"AWS.Route53Domains.retrieve_domain_auth_code/3","type":"function","doc":"This operation returns the AuthCode for the domain. To transfer a domain to another registrar, you provide this value to the new registrar."},{"ref":"AWS.Route53Domains.html#transfer_domain/3","title":"AWS.Route53Domains.transfer_domain/3","type":"function","doc":"Transfers a domain from another registrar to Amazon Route 53. When the transfer is complete, the domain is registered either with Amazon Registrar (for .com, .net, and .org domains) or with our registrar associate, Gandi (for all other TLDs). For more information about transferring domains, see the following topics: For transfer requirements, a detailed procedure, and information about viewing the status of a domain that you&#39;re transferring to Route 53, see Transferring Registration for a Domain to Amazon Route 53 in the Amazon Route 53 Developer Guide. For information about how to transfer a domain from one AWS account to another, see TransferDomainToAnotherAwsAccount. For information about how to transfer a domain to another domain registrar, see Transferring a Domain from Amazon Route 53 to Another Registrar in the Amazon Route 53 Developer Guide*. If the registrar for your domain is also the DNS service provider for the domain, we highly recommend that you transfer your DNS service to Route 53 or to another DNS service provider before you transfer your registration. Some registrars provide free DNS service when you purchase a domain registration. When you transfer the registration, the previous registrar will not renew your domain registration and could end your DNS service at any time. If the registrar for your domain is also the DNS service provider for the domain and you don&#39;t transfer DNS service to another provider, your website, email, and the web applications associated with the domain might become unavailable. If the transfer is successful, this method returns an operation ID that you can use to track the progress and completion of the action. If the transfer doesn&#39;t complete successfully, the domain registrant will be notified by email."},{"ref":"AWS.Route53Domains.html#transfer_domain_to_another_aws_account/3","title":"AWS.Route53Domains.transfer_domain_to_another_aws_account/3","type":"function","doc":"Transfers a domain from the current AWS account to another AWS account. Note the following: The AWS account that you&#39;re transferring the domain to must accept the transfer. If the other account doesn&#39;t accept the transfer within 3 days, we cancel the transfer. See AcceptDomainTransferFromAnotherAwsAccount. * You can cancel the transfer before the other account accepts it. See CancelDomainTransferToAnotherAwsAccount. The other account can reject the transfer. See RejectDomainTransferFromAnotherAwsAccount. When you transfer a domain from one AWS account to another, Route 53 doesn&#39;t transfer the hosted zone that is associated with the domain. DNS resolution isn&#39;t affected if the domain and the hosted zone are owned by separate accounts, so transferring the hosted zone is optional. For information about transferring the hosted zone to another AWS account, see Migrating a Hosted Zone to a Different AWS Account in the Amazon Route 53 Developer Guide. Use either ListOperations or GetOperationDetail to determine whether the operation succeeded. GetOperationDetail provides additional information, for example, Domain Transfer from Aws Account 111122223333 has been cancelled."},{"ref":"AWS.Route53Domains.html#update_domain_contact/3","title":"AWS.Route53Domains.update_domain_contact/3","type":"function","doc":"This operation updates the contact information for a particular domain. You must specify information for at least one contact: registrant, administrator, or technical. If the update is successful, this method returns an operation ID that you can use to track the progress and completion of the action. If the request is not completed successfully, the domain registrant will be notified by email."},{"ref":"AWS.Route53Domains.html#update_domain_contact_privacy/3","title":"AWS.Route53Domains.update_domain_contact_privacy/3","type":"function","doc":"This operation updates the specified domain contact&#39;s privacy setting. When privacy protection is enabled, contact information such as email address is replaced either with contact information for Amazon Registrar (for .com, .net, and .org domains) or with contact information for our registrar associate, Gandi. This operation affects only the contact information for the specified contact type (registrant, administrator, or tech). If the request succeeds, Amazon Route 53 returns an operation ID that you can use with GetOperationDetail to track the progress and completion of the action. If the request doesn&#39;t complete successfully, the domain registrant will be notified by email. By disabling the privacy service via API, you consent to the publication of the contact information provided for this domain via the public WHOIS database. You certify that you are the registrant of this domain name and have the authority to make this decision. You may withdraw your consent at any time by enabling privacy protection using either UpdateDomainContactPrivacy or the Route 53 console. Enabling privacy protection removes the contact information provided for this domain from the WHOIS database. For more information on our privacy practices, see https://aws.amazon.com/privacy/."},{"ref":"AWS.Route53Domains.html#update_domain_nameservers/3","title":"AWS.Route53Domains.update_domain_nameservers/3","type":"function","doc":"This operation replaces the current set of name servers for the domain with the specified set of name servers. If you use Amazon Route 53 as your DNS service, specify the four name servers in the delegation set for the hosted zone for the domain. If successful, this operation returns an operation ID that you can use to track the progress and completion of the action. If the request is not completed successfully, the domain registrant will be notified by email."},{"ref":"AWS.Route53Domains.html#update_tags_for_domain/3","title":"AWS.Route53Domains.update_tags_for_domain/3","type":"function","doc":"This operation adds or updates tags for a specified domain. All tag operations are eventually consistent; subsequent operations might not immediately represent all issued operations."},{"ref":"AWS.Route53Domains.html#view_billing/3","title":"AWS.Route53Domains.view_billing/3","type":"function","doc":"Returns all the domain-related billing records for the current AWS account for a specified period"},{"ref":"AWS.Route53Resolver.html","title":"AWS.Route53Resolver","type":"module","doc":"When you create a VPC using Amazon VPC, you automatically get DNS resolution within the VPC from Route 53 Resolver. By default, Resolver answers DNS queries for VPC domain names such as domain names for EC2 instances or ELB load balancers. Resolver performs recursive lookups against public name servers for all other domain names. You can also configure DNS resolution between your VPC and your network over a Direct Connect or VPN connection: Forward DNS queries from resolvers on your network to Route 53 Resolver DNS resolvers on your network can forward DNS queries to Resolver in a specified VPC. This allows your DNS resolvers to easily resolve domain names for AWS resources such as EC2 instances or records in a Route 53 private hosted zone. For more information, see How DNS Resolvers on Your Network Forward DNS Queries to Route 53 Resolver in the Amazon Route 53 Developer Guide. Conditionally forward queries from a VPC to resolvers on your network You can configure Resolver to forward queries that it receives from EC2 instances in your VPCs to DNS resolvers on your network. To forward selected queries, you create Resolver rules that specify the domain names for the DNS queries that you want to forward (such as example.com), and the IP addresses of the DNS resolvers on your network that you want to forward the queries to. If a query matches multiple rules (example.com, acme.example.com), Resolver chooses the rule with the most specific match (acme.example.com) and forwards the query to the IP addresses that you specified in that rule. For more information, see How Route 53 Resolver Forwards DNS Queries from Your VPCs to Your Network in the Amazon Route 53 Developer Guide. Like Amazon VPC, Resolver is regional. In each region where you have VPCs, you can choose whether to forward queries from your VPCs to your network (outbound queries), from your network to your VPCs (inbound queries), or both."},{"ref":"AWS.Route53Resolver.html#associate_resolver_endpoint_ip_address/3","title":"AWS.Route53Resolver.associate_resolver_endpoint_ip_address/3","type":"function","doc":"Adds IP addresses to an inbound or an outbound Resolver endpoint. If you want to add more than one IP address, submit one AssociateResolverEndpointIpAddress request for each IP address. To remove an IP address from an endpoint, see DisassociateResolverEndpointIpAddress."},{"ref":"AWS.Route53Resolver.html#associate_resolver_query_log_config/3","title":"AWS.Route53Resolver.associate_resolver_query_log_config/3","type":"function","doc":"Associates an Amazon VPC with a specified query logging configuration. Route 53 Resolver logs DNS queries that originate in all of the Amazon VPCs that are associated with a specified query logging configuration. To associate more than one VPC with a configuration, submit one AssociateResolverQueryLogConfig request for each VPC. The VPCs that you associate with a query logging configuration must be in the same Region as the configuration. To remove a VPC from a query logging configuration, see DisassociateResolverQueryLogConfig."},{"ref":"AWS.Route53Resolver.html#associate_resolver_rule/3","title":"AWS.Route53Resolver.associate_resolver_rule/3","type":"function","doc":"Associates a Resolver rule with a VPC. When you associate a rule with a VPC, Resolver forwards all DNS queries for the domain name that is specified in the rule and that originate in the VPC. The queries are forwarded to the IP addresses for the DNS resolvers that are specified in the rule. For more information about rules, see CreateResolverRule."},{"ref":"AWS.Route53Resolver.html#create_resolver_endpoint/3","title":"AWS.Route53Resolver.create_resolver_endpoint/3","type":"function","doc":"Creates a Resolver endpoint. There are two types of Resolver endpoints, inbound and outbound: An inbound Resolver endpoint forwards DNS queries to the DNS service for a VPC from your network. An outbound Resolver endpoint forwards DNS queries from the DNS service for a VPC to your network."},{"ref":"AWS.Route53Resolver.html#create_resolver_query_log_config/3","title":"AWS.Route53Resolver.create_resolver_query_log_config/3","type":"function","doc":"Creates a Resolver query logging configuration, which defines where you want Resolver to save DNS query logs that originate in your VPCs. Resolver can log queries only for VPCs that are in the same Region as the query logging configuration. To specify which VPCs you want to log queries for, you use AssociateResolverQueryLogConfig. For more information, see AssociateResolverQueryLogConfig. You can optionally use AWS Resource Access Manager (AWS RAM) to share a query logging configuration with other AWS accounts. The other accounts can then associate VPCs with the configuration. The query logs that Resolver creates for a configuration include all DNS queries that originate in all VPCs that are associated with the configuration."},{"ref":"AWS.Route53Resolver.html#create_resolver_rule/3","title":"AWS.Route53Resolver.create_resolver_rule/3","type":"function","doc":"For DNS queries that originate in your VPCs, specifies which Resolver endpoint the queries pass through, one domain name that you want to forward to your network, and the IP addresses of the DNS resolvers in your network."},{"ref":"AWS.Route53Resolver.html#delete_resolver_endpoint/3","title":"AWS.Route53Resolver.delete_resolver_endpoint/3","type":"function","doc":"Deletes a Resolver endpoint. The effect of deleting a Resolver endpoint depends on whether it&#39;s an inbound or an outbound Resolver endpoint: Inbound: DNS queries from your network are no longer routed to the DNS service for the specified VPC. Outbound: DNS queries from a VPC are no longer routed to your network."},{"ref":"AWS.Route53Resolver.html#delete_resolver_query_log_config/3","title":"AWS.Route53Resolver.delete_resolver_query_log_config/3","type":"function","doc":"Deletes a query logging configuration. When you delete a configuration, Resolver stops logging DNS queries for all of the Amazon VPCs that are associated with the configuration. This also applies if the query logging configuration is shared with other AWS accounts, and the other accounts have associated VPCs with the shared configuration. Before you can delete a query logging configuration, you must first disassociate all VPCs from the configuration. See DisassociateResolverQueryLogConfig. If you used Resource Access Manager (RAM) to share a query logging configuration with other accounts, you must stop sharing the configuration before you can delete a configuration. The accounts that you shared the configuration with can first disassociate VPCs that they associated with the configuration, but that&#39;s not necessary. If you stop sharing the configuration, those VPCs are automatically disassociated from the configuration."},{"ref":"AWS.Route53Resolver.html#delete_resolver_rule/3","title":"AWS.Route53Resolver.delete_resolver_rule/3","type":"function","doc":"Deletes a Resolver rule. Before you can delete a Resolver rule, you must disassociate it from all the VPCs that you associated the Resolver rule with. For more information, see DisassociateResolverRule."},{"ref":"AWS.Route53Resolver.html#disassociate_resolver_endpoint_ip_address/3","title":"AWS.Route53Resolver.disassociate_resolver_endpoint_ip_address/3","type":"function","doc":"Removes IP addresses from an inbound or an outbound Resolver endpoint. If you want to remove more than one IP address, submit one DisassociateResolverEndpointIpAddress request for each IP address. To add an IP address to an endpoint, see AssociateResolverEndpointIpAddress."},{"ref":"AWS.Route53Resolver.html#disassociate_resolver_query_log_config/3","title":"AWS.Route53Resolver.disassociate_resolver_query_log_config/3","type":"function","doc":"Disassociates a VPC from a query logging configuration. Before you can delete a query logging configuration, you must first disassociate all VPCs from the configuration. If you used Resource Access Manager (RAM) to share a query logging configuration with other accounts, VPCs can be disassociated from the configuration in the following ways: The accounts that you shared the configuration with can disassociate VPCs from the configuration. You can stop sharing the configuration."},{"ref":"AWS.Route53Resolver.html#disassociate_resolver_rule/3","title":"AWS.Route53Resolver.disassociate_resolver_rule/3","type":"function","doc":"Removes the association between a specified Resolver rule and a specified VPC. If you disassociate a Resolver rule from a VPC, Resolver stops forwarding DNS queries for the domain name that you specified in the Resolver rule."},{"ref":"AWS.Route53Resolver.html#get_resolver_endpoint/3","title":"AWS.Route53Resolver.get_resolver_endpoint/3","type":"function","doc":"Gets information about a specified Resolver endpoint, such as whether it&#39;s an inbound or an outbound Resolver endpoint, and the current status of the endpoint."},{"ref":"AWS.Route53Resolver.html#get_resolver_query_log_config/3","title":"AWS.Route53Resolver.get_resolver_query_log_config/3","type":"function","doc":"Gets information about a specified Resolver query logging configuration, such as the number of VPCs that the configuration is logging queries for and the location that logs are sent to."},{"ref":"AWS.Route53Resolver.html#get_resolver_query_log_config_association/3","title":"AWS.Route53Resolver.get_resolver_query_log_config_association/3","type":"function","doc":"Gets information about a specified association between a Resolver query logging configuration and an Amazon VPC. When you associate a VPC with a query logging configuration, Resolver logs DNS queries that originate in that VPC."},{"ref":"AWS.Route53Resolver.html#get_resolver_query_log_config_policy/3","title":"AWS.Route53Resolver.get_resolver_query_log_config_policy/3","type":"function","doc":"Gets information about a query logging policy. A query logging policy specifies the Resolver query logging operations and resources that you want to allow another AWS account to be able to use."},{"ref":"AWS.Route53Resolver.html#get_resolver_rule/3","title":"AWS.Route53Resolver.get_resolver_rule/3","type":"function","doc":"Gets information about a specified Resolver rule, such as the domain name that the rule forwards DNS queries for and the ID of the outbound Resolver endpoint that the rule is associated with."},{"ref":"AWS.Route53Resolver.html#get_resolver_rule_association/3","title":"AWS.Route53Resolver.get_resolver_rule_association/3","type":"function","doc":"Gets information about an association between a specified Resolver rule and a VPC. You associate a Resolver rule and a VPC using AssociateResolverRule."},{"ref":"AWS.Route53Resolver.html#get_resolver_rule_policy/3","title":"AWS.Route53Resolver.get_resolver_rule_policy/3","type":"function","doc":"Gets information about a Resolver rule policy. A Resolver rule policy specifies the Resolver operations and resources that you want to allow another AWS account to be able to use."},{"ref":"AWS.Route53Resolver.html#list_resolver_endpoint_ip_addresses/3","title":"AWS.Route53Resolver.list_resolver_endpoint_ip_addresses/3","type":"function","doc":"Gets the IP addresses for a specified Resolver endpoint."},{"ref":"AWS.Route53Resolver.html#list_resolver_endpoints/3","title":"AWS.Route53Resolver.list_resolver_endpoints/3","type":"function","doc":"Lists all the Resolver endpoints that were created using the current AWS account."},{"ref":"AWS.Route53Resolver.html#list_resolver_query_log_config_associations/3","title":"AWS.Route53Resolver.list_resolver_query_log_config_associations/3","type":"function","doc":"Lists information about associations between Amazon VPCs and query logging configurations."},{"ref":"AWS.Route53Resolver.html#list_resolver_query_log_configs/3","title":"AWS.Route53Resolver.list_resolver_query_log_configs/3","type":"function","doc":"Lists information about the specified query logging configurations. Each configuration defines where you want Resolver to save DNS query logs and specifies the VPCs that you want to log queries for."},{"ref":"AWS.Route53Resolver.html#list_resolver_rule_associations/3","title":"AWS.Route53Resolver.list_resolver_rule_associations/3","type":"function","doc":"Lists the associations that were created between Resolver rules and VPCs using the current AWS account."},{"ref":"AWS.Route53Resolver.html#list_resolver_rules/3","title":"AWS.Route53Resolver.list_resolver_rules/3","type":"function","doc":"Lists the Resolver rules that were created using the current AWS account."},{"ref":"AWS.Route53Resolver.html#list_tags_for_resource/3","title":"AWS.Route53Resolver.list_tags_for_resource/3","type":"function","doc":"Lists the tags that you associated with the specified resource."},{"ref":"AWS.Route53Resolver.html#put_resolver_query_log_config_policy/3","title":"AWS.Route53Resolver.put_resolver_query_log_config_policy/3","type":"function","doc":"Specifies an AWS account that you want to share a query logging configuration with, the query logging configuration that you want to share, and the operations that you want the account to be able to perform on the configuration."},{"ref":"AWS.Route53Resolver.html#put_resolver_rule_policy/3","title":"AWS.Route53Resolver.put_resolver_rule_policy/3","type":"function","doc":"Specifies an AWS account that you want to share rules with, the Resolver rules that you want to share, and the operations that you want the account to be able to perform on those rules."},{"ref":"AWS.Route53Resolver.html#tag_resource/3","title":"AWS.Route53Resolver.tag_resource/3","type":"function","doc":"Adds one or more tags to a specified resource."},{"ref":"AWS.Route53Resolver.html#untag_resource/3","title":"AWS.Route53Resolver.untag_resource/3","type":"function","doc":"Removes one or more tags from a specified resource."},{"ref":"AWS.Route53Resolver.html#update_resolver_endpoint/3","title":"AWS.Route53Resolver.update_resolver_endpoint/3","type":"function","doc":"Updates the name of an inbound or an outbound Resolver endpoint."},{"ref":"AWS.Route53Resolver.html#update_resolver_rule/3","title":"AWS.Route53Resolver.update_resolver_rule/3","type":"function","doc":"Updates settings for a specified Resolver rule. ResolverRuleId is required, and all other parameters are optional. If you don&#39;t specify a parameter, it retains its current value."},{"ref":"AWS.S3.html","title":"AWS.S3","type":"module","doc":""},{"ref":"AWS.S3.html#abort_multipart_upload/5","title":"AWS.S3.abort_multipart_upload/5","type":"function","doc":"This operation aborts a multipart upload. After a multipart upload is aborted, no additional parts can be uploaded using that upload ID. The storage consumed by any previously uploaded parts will be freed. However, if any part uploads are currently in progress, those part uploads might or might not succeed. As a result, it might be necessary to abort a given multipart upload multiple times in order to completely free all storage consumed by all parts. To verify that all parts have been removed, so you don&#39;t get charged for the part storage, you should call the ListParts operation and ensure that the parts list is empty. For information about permissions required to use the multipart upload API, see Multipart Upload API and Permissions. The following operations are related to AbortMultipartUpload: CreateMultipartUpload UploadPart CompleteMultipartUpload ListParts * ListMultipartUploads"},{"ref":"AWS.S3.html#complete_multipart_upload/5","title":"AWS.S3.complete_multipart_upload/5","type":"function","doc":"Completes a multipart upload by assembling previously uploaded parts. You first initiate the multipart upload and then upload all parts using the UploadPart operation. After successfully uploading all relevant parts of an upload, you call this operation to complete the upload. Upon receiving this request, Amazon S3 concatenates all the parts in ascending order by part number to create a new object. In the Complete Multipart Upload request, you must provide the parts list. You must ensure that the parts list is complete. This operation concatenates the parts that you provide in the list. For each part in the list, you must provide the part number and the ETag value, returned after that part was uploaded. Processing of a Complete Multipart Upload request could take several minutes to complete. After Amazon S3 begins processing the request, it sends an HTTP response header that specifies a 200 OK response. While processing is in progress, Amazon S3 periodically sends white space characters to keep the connection from timing out. Because a request could fail after the initial 200 OK response has been sent, it is important that you check the response body to determine whether the request succeeded. Note that if CompleteMultipartUpload fails, applications should be prepared to retry the failed requests. For more information, see Amazon S3 Error Best Practices. For more information about multipart uploads, see Uploading Objects Using Multipart Upload. For information about permissions required to use the multipart upload API, see Multipart Upload API and Permissions. CompleteMultipartUpload has the following special errors: Error code: EntityTooSmall Description: Your proposed upload is smaller than the minimum allowed object size. Each part must be at least 5 MB in size, except the last part. 400 Bad Request Error code: InvalidPart Description: One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part&#39;s entity tag. 400 Bad Request Error code: InvalidPartOrder Description: The list of parts was not in ascending order. The parts list must be specified in order by part number. 400 Bad Request Error code: NoSuchUpload Description: The specified multipart upload does not exist. The upload ID might be invalid, or the multipart upload might have been aborted or completed. 404 Not Found The following operations are related to CompleteMultipartUpload: CreateMultipartUpload UploadPart AbortMultipartUpload ListParts * ListMultipartUploads"},{"ref":"AWS.S3.html#copy_object/5","title":"AWS.S3.copy_object/5","type":"function","doc":"Creates a copy of an object that is already stored in Amazon S3. You can store individual objects of up to 5 TB in Amazon S3. You create a copy of your object up to 5 GB in size in a single atomic operation using this API. However, to copy an object greater than 5 GB, you must use the multipart upload Upload Part - Copy API. For more information, see Copy Object Using the REST Multipart Upload API. All copy requests must be authenticated. Additionally, you must have read access to the source object and write access to the destination bucket. For more information, see REST Authentication. Both the Region that you want to copy the object from and the Region that you want to copy the object to must be enabled for your account. A copy request might return an error when Amazon S3 receives the copy request or while Amazon S3 is copying the files. If the error occurs before the copy operation starts, you receive a standard Amazon S3 error. If the error occurs during the copy operation, the error response is embedded in the 200 OK response. This means that a 200 OK response can contain either a success or an error. Design your application to parse the contents of the response and handle it appropriately. If the copy is successful, you receive a response with information about the copied object. If the request is an HTTP 1.1 request, the response is chunk encoded. If it were not, it would not contain the content-length, and you would need to read the entire body. The copy request charge is based on the storage class and Region that you specify for the destination object. For pricing information, see Amazon S3 pricing. Amazon S3 transfer acceleration does not support cross-Region copies. If you request a cross-Region copy using a transfer acceleration endpoint, you get a 400 Bad Request error. For more information, see Transfer Acceleration. Metadata When copying an object, you can preserve all metadata (default) or specify new metadata. However, the ACL is not preserved and is set to private for the user making the request. To override the default ACL setting, specify a new ACL when generating a copy request. For more information, see Using ACLs. To specify whether you want the object metadata copied from the source object or replaced with metadata provided in the request, you can optionally add the x-amz-metadata-directive header. When you grant permissions, you can use the s3:x-amz-metadata-directive condition key to enforce certain metadata behavior when objects are uploaded. For more information, see Specifying Conditions in a Policy in the Amazon S3 Developer Guide. For a complete list of Amazon S3-specific condition keys, see Actions, Resources, and Condition Keys for Amazon S3. x-amz-copy-source-if Headers To only copy an object under certain conditions, such as whether the Etag matches or whether the object was modified before or after a specified date, use the following request parameters: x-amz-copy-source-if-match x-amz-copy-source-if-none-match x-amz-copy-source-if-unmodified-since x-amz-copy-source-if-modified-since If both the x-amz-copy-source-if-match and x-amz-copy-source-if-unmodified-since headers are present in the request and evaluate as follows, Amazon S3 returns 200 OK and copies the data: x-amz-copy-source-if-match condition evaluates to true x-amz-copy-source-if-unmodified-since condition evaluates to false If both the x-amz-copy-source-if-none-match and x-amz-copy-source-if-modified-since headers are present in the request and evaluate as follows, Amazon S3 returns the 412 Precondition Failed response code: x-amz-copy-source-if-none-match condition evaluates to false x-amz-copy-source-if-modified-since condition evaluates to true All headers with the x-amz- prefix, including x-amz-copy-source, must be signed. Encryption The source object that you are copying can be encrypted or unencrypted. The source object can be encrypted with server-side encryption using AWS managed encryption keys (SSE-S3 or SSE-KMS) or by using a customer-provided encryption key. With server-side encryption, Amazon S3 encrypts your data as it writes it to disks in its data centers and decrypts the data when you access it. You can optionally use the appropriate encryption-related headers to request server-side encryption for the target object. You have the option to provide your own encryption key or use SSE-S3 or SSE-KMS, regardless of the form of server-side encryption that was used to encrypt the source object. You can even request encryption if the source object was not encrypted. For more information about server-side encryption, see Using Server-Side Encryption. Access Control List (ACL)-Specific Request Headers When copying an object, you can optionally use headers to grant ACL-based permissions. By default, all objects are private. Only the owner has full access control. When adding a new object, you can grant permissions to individual AWS accounts or to predefined groups defined by Amazon S3. These permissions are then added to the ACL on the object. For more information, see Access Control List (ACL) Overview and Managing ACLs Using the REST API. Storage Class Options You can use the CopyObject operation to change the storage class of an object that is already stored in Amazon S3 using the StorageClass parameter. For more information, see Storage Classes in the Amazon S3 Service Developer Guide. Versioning By default, x-amz-copy-source identifies the current version of an object to copy. If the current version is a delete marker, Amazon S3 behaves as if the object was deleted. To copy a different version, use the versionId subresource. If you enable versioning on the target bucket, Amazon S3 generates a unique version ID for the object being copied. This version ID is different from the version ID of the source object. Amazon S3 returns the version ID of the copied object in the x-amz-version-id response header in the response. If you do not enable versioning or suspend it on the target bucket, the version ID that Amazon S3 generates is always null. If the source object&#39;s storage class is GLACIER, you must restore a copy of this object before you can use it as a source object for the copy operation. For more information, see RestoreObject. The following operations are related to CopyObject: PutObject GetObject For more information, see Copying Objects."},{"ref":"AWS.S3.html#create_bucket/4","title":"AWS.S3.create_bucket/4","type":"function","doc":"Creates a new S3 bucket. To create a bucket, you must register with Amazon S3 and have a valid AWS Access Key ID to authenticate requests. Anonymous requests are never allowed to create buckets. By creating the bucket, you become the bucket owner. Not every string is an acceptable bucket name. For information about bucket naming restrictions, see Working with Amazon S3 buckets. If you want to create an Amazon S3 on Outposts bucket, see Create Bucket. By default, the bucket is created in the US East (N. Virginia) Region. You can optionally specify a Region in the request body. You might choose a Region to optimize latency, minimize costs, or address regulatory requirements. For example, if you reside in Europe, you will probably find it advantageous to create buckets in the Europe (Ireland) Region. For more information, see Accessing a bucket. If you send your create bucket request to the s3.amazonaws.com endpoint, the request goes to the us-east-1 Region. Accordingly, the signature calculations in Signature Version 4 must use us-east-1 as the Region, even if the location constraint in the request specifies another Region where the bucket is to be created. If you create a bucket in a Region other than US East (N. Virginia), your application must be able to handle 307 redirect. For more information, see Virtual hosting of buckets. When creating a bucket using this operation, you can optionally specify the accounts or groups that should be granted specific permissions on the bucket. There are two ways to grant the appropriate permissions using the request headers. Specify a canned ACL using the x-amz-acl request header. Amazon S3 supports a set of predefined ACLs, known as canned ACLs. Each canned ACL has a predefined set of grantees and permissions. For more information, see Canned ACL. Specify access permissions explicitly using the x-amz-grant-read, x-amz-grant-write, x-amz-grant-read-acp, x-amz-grant-write-acp, and x-amz-grant-full-control headers. These headers map to the set of permissions Amazon S3 supports in an ACL. For more information, see Access control list (ACL) overview. You specify each grantee as a type=value pair, where the type is one of the following: * `id`  if the value specified is the canonical user ID of an AWS account * `uri`  if you are granting permissions to a predefined group * `emailAddress`  if the value specified is the email address of an AWS account Using email addresses to specify a grantee is only supported in the following AWS Regions: US East (N. Virginia) US West (N. California) US West (Oregon) Asia Pacific (Singapore) Asia Pacific (Sydney) Asia Pacific (Tokyo) Europe (Ireland) South America (So Paulo) For a list of all the Amazon S3 supported Regions and endpoints, see Regions and Endpoints in the AWS General Reference. For example, the following x-amz-grant-read header grants the AWS accounts identified by account IDs permissions to read object data and its metadata: x-amz-grant-read: id=&quot;11112222333&quot;, id=&quot;444455556666&quot; You can use either a canned ACL or specify access permissions explicitly. You cannot do both. The following operations are related to CreateBucket: PutObject * DeleteBucket"},{"ref":"AWS.S3.html#create_multipart_upload/5","title":"AWS.S3.create_multipart_upload/5","type":"function","doc":"This operation initiates a multipart upload and returns an upload ID. This upload ID is used to associate all of the parts in the specific multipart upload. You specify this upload ID in each of your subsequent upload part requests (see UploadPart). You also include this upload ID in the final request to either complete or abort the multipart upload request. For more information about multipart uploads, see Multipart Upload Overview. If you have configured a lifecycle rule to abort incomplete multipart uploads, the upload must complete within the number of days specified in the bucket lifecycle configuration. Otherwise, the incomplete multipart upload becomes eligible for an abort operation and Amazon S3 aborts the multipart upload. For more information, see Aborting Incomplete Multipart Uploads Using a Bucket Lifecycle Policy. For information about the permissions required to use the multipart upload API, see Multipart Upload API and Permissions. For request signing, multipart upload is just a series of regular requests. You initiate a multipart upload, send one or more requests to upload parts, and then complete the multipart upload process. You sign each request individually. There is nothing special about signing multipart upload requests. For more information about signing, see Authenticating Requests (AWS Signature Version 4). After you initiate a multipart upload and upload one or more parts, to stop being charged for storing the uploaded parts, you must either complete or abort the multipart upload. Amazon S3 frees up the space used to store the parts and stop charging you for storing them only after you either complete or abort a multipart upload. You can optionally request server-side encryption. For server-side encryption, Amazon S3 encrypts your data as it writes it to disks in its data centers and decrypts it when you access it. You can provide your own encryption key, or use AWS Key Management Service (AWS KMS) customer master keys (CMKs) or Amazon S3-managed encryption keys. If you choose to provide your own encryption key, the request headers you provide in UploadPart and UploadPartCopy requests must match the headers you used in the request to initiate the upload by using CreateMultipartUpload. To perform a multipart upload with encryption using an AWS KMS CMK, the requester must have permission to the kms:Encrypt, kms:Decrypt, kms:ReEncrypt*, kms:GenerateDataKey*, and kms:DescribeKey actions on the key. These permissions are required because Amazon S3 must decrypt and read data from the encrypted file parts before it completes the multipart upload. If your AWS Identity and Access Management (IAM) user or role is in the same AWS account as the AWS KMS CMK, then you must have these permissions on the key policy. If your IAM user or role belongs to a different account than the key, then you must have the permissions on both the key policy and your IAM user or role. For more information, see Protecting Data Using Server-Side Encryption. Definitions Access Permissions When copying an object, you can optionally specify the accounts or groups that should be granted specific permissions on the new object. There are two ways to grant the permissions using the request headers: Specify a canned ACL with the x-amz-acl request header. For more information, see Canned ACL. Specify access permissions explicitly with the x-amz-grant-read, x-amz-grant-read-acp, x-amz-grant-write-acp, and x-amz-grant-full-control headers. These parameters map to the set of permissions that Amazon S3 supports in an ACL. For more information, see Access Control List (ACL) Overview. You can use either a canned ACL or specify access permissions explicitly. You cannot do both. Server-Side- Encryption-Specific Request Headers You can optionally tell Amazon S3 to encrypt data at rest using server-side encryption. Server-side encryption is for data encryption at rest. Amazon S3 encrypts your data as it writes it to disks in its data centers and decrypts it when you access it. The option you use depends on whether you want to use AWS managed encryption keys or provide your own encryption key. Use encryption keys managed by Amazon S3 or customer master keys (CMKs) stored in AWS Key Management Service (AWS KMS)  If you want AWS to manage the keys used to encrypt data, specify the following headers in the request. x-amz-server-side-encryption x-amz-server-side-encryption-aws-kms-key-id x-amz-server-side-encryption-context If you specify x-amz-server-side-encryption:aws:kms, but don&#39;t provide x-amz-server-side-encryption-aws-kms-key-id, Amazon S3 uses the AWS managed CMK in AWS KMS to protect the data. All GET and PUT requests for an object protected by AWS KMS fail if you don&#39;t make them with SSL or by using SigV4. For more information about server-side encryption with CMKs stored in AWS KMS (SSE-KMS), see Protecting Data Using Server-Side Encryption with CMKs stored in AWS KMS. Use customer-provided encryption keys  If you want to manage your own encryption keys, provide all the following headers in the request. x-amz-server-side-encryption-customer-algorithm x-amz-server-side-encryption-customer-key x-amz-server-side-encryption-customer-key-MD5 For more information about server-side encryption with CMKs stored in AWS KMS (SSE-KMS), see Protecting Data Using Server-Side Encryption with CMKs stored in AWS KMS. Access-Control-List (ACL)-Specific Request Headers You also can use the following access controlrelated headers with this operation. By default, all objects are private. Only the owner has full access control. When adding a new object, you can grant permissions to individual AWS accounts or to predefined groups defined by Amazon S3. These permissions are then added to the access control list (ACL) on the object. For more information, see Using ACLs. With this operation, you can grant access permissions using one of the following two methods: Specify a canned ACL (x-amz-acl)  Amazon S3 supports a set of predefined ACLs, known as canned ACLs. Each canned ACL has a predefined set of grantees and permissions. For more information, see Canned ACL. Specify access permissions explicitly  To explicitly grant access permissions to specific AWS accounts or groups, use the following headers. Each header maps to specific permissions that Amazon S3 supports in an ACL. For more information, see Access Control List (ACL) Overview. In the header, you specify a list of grantees who get the specific permission. To grant permissions explicitly, use: x-amz-grant-read x-amz-grant-write x-amz-grant-read-acp x-amz-grant-write-acp x-amz-grant-full-control You specify each grantee as a type=value pair, where the type is one of the following: `id`  if the value specified is the canonical user ID of an AWS account `uri`  if you are granting permissions to a predefined group `emailAddress`  if the value specified is the email address of an AWS account Using email addresses to specify a grantee is only supported in the following AWS Regions: US East (N. Virginia) US West (N. California) US West (Oregon) Asia Pacific (Singapore) Asia Pacific (Sydney) Asia Pacific (Tokyo) Europe (Ireland) South America (So Paulo) For a list of all the Amazon S3 supported Regions and endpoints, see Regions and Endpoints in the AWS General Reference. For example, the following x-amz-grant-read header grants the AWS accounts identified by account IDs permissions to read object data and its metadata: x-amz-grant-read: id=&quot;11112222333&quot;, id=&quot;444455556666&quot; The following operations are related to CreateMultipartUpload: UploadPart * CompleteMultipartUpload AbortMultipartUpload ListParts * ListMultipartUploads"},{"ref":"AWS.S3.html#delete_bucket/4","title":"AWS.S3.delete_bucket/4","type":"function","doc":"Deletes the S3 bucket. All objects (including all object versions and delete markers) in the bucket must be deleted before the bucket itself can be deleted. Related Resources CreateBucket DeleteObject"},{"ref":"AWS.S3.html#delete_bucket_analytics_configuration/4","title":"AWS.S3.delete_bucket_analytics_configuration/4","type":"function","doc":"Deletes an analytics configuration for the bucket (specified by the analytics configuration ID). To use this operation, you must have permissions to perform the s3:PutAnalyticsConfiguration action. The bucket owner has this permission by default. The bucket owner can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources. For information about the Amazon S3 analytics feature, see Amazon S3 Analytics  Storage Class Analysis. The following operations are related to DeleteBucketAnalyticsConfiguration: GetBucketAnalyticsConfiguration ListBucketAnalyticsConfigurations * PutBucketAnalyticsConfiguration"},{"ref":"AWS.S3.html#delete_bucket_cors/4","title":"AWS.S3.delete_bucket_cors/4","type":"function","doc":"Deletes the cors configuration information set for the bucket. To use this operation, you must have permission to perform the s3:PutBucketCORS action. The bucket owner has this permission by default and can grant this permission to others. For information about cors, see Enabling Cross-Origin Resource Sharing in the Amazon Simple Storage Service Developer Guide. Related Resources: PutBucketCors RESTOPTIONSobject"},{"ref":"AWS.S3.html#delete_bucket_encryption/4","title":"AWS.S3.delete_bucket_encryption/4","type":"function","doc":"This implementation of the DELETE operation removes default encryption from the bucket. For information about the Amazon S3 default encryption feature, see Amazon S3 Default Bucket Encryption in the Amazon Simple Storage Service Developer Guide. To use this operation, you must have permissions to perform the s3:PutEncryptionConfiguration action. The bucket owner has this permission by default. The bucket owner can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to your Amazon S3 Resources in the Amazon Simple Storage Service Developer Guide. Related Resources PutBucketEncryption GetBucketEncryption"},{"ref":"AWS.S3.html#delete_bucket_inventory_configuration/4","title":"AWS.S3.delete_bucket_inventory_configuration/4","type":"function","doc":"Deletes an inventory configuration (identified by the inventory ID) from the bucket. To use this operation, you must have permissions to perform the s3:PutInventoryConfiguration action. The bucket owner has this permission by default. The bucket owner can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources. For information about the Amazon S3 inventory feature, see Amazon S3 Inventory. Operations related to DeleteBucketInventoryConfiguration include: GetBucketInventoryConfiguration PutBucketInventoryConfiguration * ListBucketInventoryConfigurations"},{"ref":"AWS.S3.html#delete_bucket_lifecycle/4","title":"AWS.S3.delete_bucket_lifecycle/4","type":"function","doc":"Deletes the lifecycle configuration from the specified bucket. Amazon S3 removes all the lifecycle configuration rules in the lifecycle subresource associated with the bucket. Your objects never expire, and Amazon S3 no longer automatically deletes any objects on the basis of rules contained in the deleted lifecycle configuration. To use this operation, you must have permission to perform the s3:PutLifecycleConfiguration action. By default, the bucket owner has this permission and the bucket owner can grant this permission to others. There is usually some time lag before lifecycle configuration deletion is fully propagated to all the Amazon S3 systems. For more information about the object expiration, see Elements to Describe Lifecycle Actions. Related actions include: PutBucketLifecycleConfiguration GetBucketLifecycleConfiguration"},{"ref":"AWS.S3.html#delete_bucket_metrics_configuration/4","title":"AWS.S3.delete_bucket_metrics_configuration/4","type":"function","doc":"Deletes a metrics configuration for the Amazon CloudWatch request metrics (specified by the metrics configuration ID) from the bucket. Note that this doesn&#39;t include the daily storage metrics. To use this operation, you must have permissions to perform the s3:PutMetricsConfiguration action. The bucket owner has this permission by default. The bucket owner can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources. For information about CloudWatch request metrics for Amazon S3, see Monitoring Metrics with Amazon CloudWatch. The following operations are related to DeleteBucketMetricsConfiguration: GetBucketMetricsConfiguration PutBucketMetricsConfiguration ListBucketMetricsConfigurations Monitoring Metrics with Amazon CloudWatch"},{"ref":"AWS.S3.html#delete_bucket_ownership_controls/4","title":"AWS.S3.delete_bucket_ownership_controls/4","type":"function","doc":"Removes OwnershipControls for an Amazon S3 bucket. To use this operation, you must have the s3:PutBucketOwnershipControls permission. For more information about Amazon S3 permissions, see Specifying Permissions in a Policy. For information about Amazon S3 Object Ownership, see Using Object Ownership. The following operations are related to DeleteBucketOwnershipControls: GetBucketOwnershipControls PutBucketOwnershipControls"},{"ref":"AWS.S3.html#delete_bucket_policy/4","title":"AWS.S3.delete_bucket_policy/4","type":"function","doc":"This implementation of the DELETE operation uses the policy subresource to delete the policy of a specified bucket. If you are using an identity other than the root user of the AWS account that owns the bucket, the calling identity must have the DeleteBucketPolicy permissions on the specified bucket and belong to the bucket owner&#39;s account to use this operation. If you don&#39;t have DeleteBucketPolicy permissions, Amazon S3 returns a 403 Access Denied error. If you have the correct permissions, but you&#39;re not using an identity that belongs to the bucket owner&#39;s account, Amazon S3 returns a 405 Method Not Allowed error. As a security precaution, the root user of the AWS account that owns a bucket can always use this operation, even if the policy explicitly denies the root user the ability to perform this action. For more information about bucket policies, see Using Bucket Policies and UserPolicies. The following operations are related to DeleteBucketPolicy * CreateBucket * DeleteObject"},{"ref":"AWS.S3.html#delete_bucket_replication/4","title":"AWS.S3.delete_bucket_replication/4","type":"function","doc":"Deletes the replication configuration from the bucket. To use this operation, you must have permissions to perform the s3:PutReplicationConfiguration action. The bucket owner has these permissions by default and can grant it to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources. It can take a while for the deletion of a replication configuration to fully propagate. For information about replication configuration, see Replication in the Amazon S3 Developer Guide. The following operations are related to DeleteBucketReplication: * PutBucketReplication * GetBucketReplication"},{"ref":"AWS.S3.html#delete_bucket_tagging/4","title":"AWS.S3.delete_bucket_tagging/4","type":"function","doc":"Deletes the tags from the bucket. To use this operation, you must have permission to perform the s3:PutBucketTagging action. By default, the bucket owner has this permission and can grant this permission to others. The following operations are related to DeleteBucketTagging: GetBucketTagging PutBucketTagging"},{"ref":"AWS.S3.html#delete_bucket_website/4","title":"AWS.S3.delete_bucket_website/4","type":"function","doc":"This operation removes the website configuration for a bucket. Amazon S3 returns a 200 OK response upon successfully deleting a website configuration on the specified bucket. You will get a 200 OK response if the website configuration you are trying to delete does not exist on the bucket. Amazon S3 returns a 404 response if the bucket specified in the request does not exist. This DELETE operation requires the S3:DeleteBucketWebsite permission. By default, only the bucket owner can delete the website configuration attached to a bucket. However, bucket owners can grant other users permission to delete the website configuration by writing a bucket policy granting them the S3:DeleteBucketWebsite permission. For more information about hosting websites, see Hosting Websites on Amazon S3. The following operations are related to DeleteBucketWebsite: GetBucketWebsite PutBucketWebsite"},{"ref":"AWS.S3.html#delete_object/5","title":"AWS.S3.delete_object/5","type":"function","doc":"Removes the null version (if there is one) of an object and inserts a delete marker, which becomes the latest version of the object. If there isn&#39;t a null version, Amazon S3 does not remove any objects. To remove a specific version, you must be the bucket owner and you must use the version Id subresource. Using this subresource permanently deletes the version. If the object deleted is a delete marker, Amazon S3 sets the response header, x-amz-delete-marker, to true. If the object you want to delete is in a bucket where the bucket versioning configuration is MFA Delete enabled, you must include the x-amz-mfa request header in the DELETE versionId request. Requests that include x-amz-mfa must use HTTPS. For more information about MFA Delete, see Using MFA Delete. To see sample requests that use versioning, see Sample Request. You can delete objects by explicitly calling the DELETE Object API or configure its lifecycle (PutBucketLifecycle) to enable Amazon S3 to remove them for you. If you want to block users or accounts from removing or deleting objects from your bucket, you must deny them the s3:DeleteObject, s3:DeleteObjectVersion, and s3:PutLifeCycleConfiguration actions. The following operation is related to DeleteObject: PutObject"},{"ref":"AWS.S3.html#delete_object_tagging/5","title":"AWS.S3.delete_object_tagging/5","type":"function","doc":"Removes the entire tag set from the specified object. For more information about managing object tags, see Object Tagging. To use this operation, you must have permission to perform the s3:DeleteObjectTagging action. To delete tags of a specific object version, add the versionId query parameter in the request. You will need permission for the s3:DeleteObjectVersionTagging action. The following operations are related to DeleteBucketMetricsConfiguration: PutObjectTagging GetObjectTagging"},{"ref":"AWS.S3.html#delete_objects/4","title":"AWS.S3.delete_objects/4","type":"function","doc":"This operation enables you to delete multiple objects from a bucket using a single HTTP request. If you know the object keys that you want to delete, then this operation provides a suitable alternative to sending individual delete requests, reducing per-request overhead. The request contains a list of up to 1000 keys that you want to delete. In the XML, you provide the object key names, and optionally, version IDs if you want to delete a specific version of the object from a versioning-enabled bucket. For each key, Amazon S3 performs a delete operation and returns the result of that delete, success, or failure, in the response. Note that if the object specified in the request is not found, Amazon S3 returns the result as deleted. The operation supports two modes for the response: verbose and quiet. By default, the operation uses verbose mode in which the response includes the result of deletion of each key in your request. In quiet mode the response includes only keys where the delete operation encountered an error. For a successful deletion, the operation does not return any information about the delete in the response body. When performing this operation on an MFA Delete enabled bucket, that attempts to delete any versioned objects, you must include an MFA token. If you do not provide one, the entire request will fail, even if there are non-versioned objects you are trying to delete. If you provide an invalid token, whether there are versioned keys in the request or not, the entire Multi-Object Delete request will fail. For information about MFA Delete, see MFA Delete. Finally, the Content-MD5 header is required for all Multi-Object Delete requests. Amazon S3 uses the header value to ensure that your request body has not been altered in transit. The following operations are related to DeleteObjects: CreateMultipartUpload UploadPart CompleteMultipartUpload ListParts * AbortMultipartUpload"},{"ref":"AWS.S3.html#delete_public_access_block/4","title":"AWS.S3.delete_public_access_block/4","type":"function","doc":"Removes the PublicAccessBlock configuration for an Amazon S3 bucket. To use this operation, you must have the s3:PutBucketPublicAccessBlock permission. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources. The following operations are related to DeletePublicAccessBlock: Using Amazon S3 Block Public Access GetPublicAccessBlock PutPublicAccessBlock * GetBucketPolicyStatus"},{"ref":"AWS.S3.html#get_bucket_accelerate_configuration/4","title":"AWS.S3.get_bucket_accelerate_configuration/4","type":"function","doc":"This implementation of the GET operation uses the accelerate subresource to return the Transfer Acceleration state of a bucket, which is either Enabled or Suspended. Amazon S3 Transfer Acceleration is a bucket-level feature that enables you to perform faster data transfers to and from Amazon S3. To use this operation, you must have permission to perform the s3:GetAccelerateConfiguration action. The bucket owner has this permission by default. The bucket owner can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to your Amazon S3 Resources in the Amazon Simple Storage Service Developer Guide. You set the Transfer Acceleration state of an existing bucket to Enabled or Suspended by using the PutBucketAccelerateConfiguration operation. A GET accelerate request does not return a state value for a bucket that has no transfer acceleration state. A bucket has no Transfer Acceleration state if a state has never been set on the bucket. For more information about transfer acceleration, see Transfer Acceleration in the Amazon Simple Storage Service Developer Guide. Related Resources * PutBucketAccelerateConfiguration"},{"ref":"AWS.S3.html#get_bucket_acl/4","title":"AWS.S3.get_bucket_acl/4","type":"function","doc":"This implementation of the GET operation uses the acl subresource to return the access control list (ACL) of a bucket. To use GET to return the ACL of the bucket, you must have READ_ACP access to the bucket. If READ_ACP permission is granted to the anonymous user, you can return the ACL of the bucket without using an authorization header. Related Resources ListObjects"},{"ref":"AWS.S3.html#get_bucket_analytics_configuration/5","title":"AWS.S3.get_bucket_analytics_configuration/5","type":"function","doc":"This implementation of the GET operation returns an analytics configuration (identified by the analytics configuration ID) from the bucket. To use this operation, you must have permissions to perform the s3:GetAnalyticsConfiguration action. The bucket owner has this permission by default. The bucket owner can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources in the Amazon Simple Storage Service Developer Guide. For information about Amazon S3 analytics feature, see Amazon S3 Analytics  Storage Class Analysis in the Amazon Simple Storage Service Developer Guide. Related Resources DeleteBucketAnalyticsConfiguration ListBucketAnalyticsConfigurations * PutBucketAnalyticsConfiguration"},{"ref":"AWS.S3.html#get_bucket_cors/4","title":"AWS.S3.get_bucket_cors/4","type":"function","doc":"Returns the cors configuration information set for the bucket. To use this operation, you must have permission to perform the s3:GetBucketCORS action. By default, the bucket owner has this permission and can grant it to others. For more information about cors, see Enabling Cross-Origin Resource Sharing. The following operations are related to GetBucketCors: PutBucketCors DeleteBucketCors"},{"ref":"AWS.S3.html#get_bucket_encryption/4","title":"AWS.S3.get_bucket_encryption/4","type":"function","doc":"Returns the default encryption configuration for an Amazon S3 bucket. For information about the Amazon S3 default encryption feature, see Amazon S3 Default Bucket Encryption. To use this operation, you must have permission to perform the s3:GetEncryptionConfiguration action. The bucket owner has this permission by default. The bucket owner can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources. The following operations are related to GetBucketEncryption: PutBucketEncryption DeleteBucketEncryption"},{"ref":"AWS.S3.html#get_bucket_inventory_configuration/5","title":"AWS.S3.get_bucket_inventory_configuration/5","type":"function","doc":"Returns an inventory configuration (identified by the inventory configuration ID) from the bucket. To use this operation, you must have permissions to perform the s3:GetInventoryConfiguration action. The bucket owner has this permission by default and can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources. For information about the Amazon S3 inventory feature, see Amazon S3 Inventory. The following operations are related to GetBucketInventoryConfiguration: DeleteBucketInventoryConfiguration ListBucketInventoryConfigurations * PutBucketInventoryConfiguration"},{"ref":"AWS.S3.html#get_bucket_lifecycle/4","title":"AWS.S3.get_bucket_lifecycle/4","type":"function","doc":"For an updated version of this API, see GetBucketLifecycleConfiguration. If you configured a bucket lifecycle using the filter element, you should see the updated version of this topic. This topic is provided for backward compatibility. Returns the lifecycle configuration information set on the bucket. For information about lifecycle configuration, see Object Lifecycle Management. To use this operation, you must have permission to perform the s3:GetLifecycleConfiguration action. The bucket owner has this permission by default. The bucket owner can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources. GetBucketLifecycle has the following special error: Error code: NoSuchLifecycleConfiguration Description: The lifecycle configuration does not exist. HTTP Status Code: 404 Not Found SOAP Fault Code Prefix: Client The following operations are related to GetBucketLifecycle: GetBucketLifecycleConfiguration PutBucketLifecycle * DeleteBucketLifecycle"},{"ref":"AWS.S3.html#get_bucket_lifecycle_configuration/4","title":"AWS.S3.get_bucket_lifecycle_configuration/4","type":"function","doc":"Bucket lifecycle configuration now supports specifying a lifecycle rule using an object key name prefix, one or more object tags, or a combination of both. Accordingly, this section describes the latest API. The response describes the new filter element that you can use to specify a filter to select a subset of objects to which the rule applies. If you are using a previous version of the lifecycle configuration, it still works. For the earlier API description, see GetBucketLifecycle. Returns the lifecycle configuration information set on the bucket. For information about lifecycle configuration, see Object Lifecycle Management. To use this operation, you must have permission to perform the s3:GetLifecycleConfiguration action. The bucket owner has this permission, by default. The bucket owner can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources. GetBucketLifecycleConfiguration has the following special error: Error code: NoSuchLifecycleConfiguration Description: The lifecycle configuration does not exist. HTTP Status Code: 404 Not Found SOAP Fault Code Prefix: Client The following operations are related to GetBucketLifecycleConfiguration: GetBucketLifecycle PutBucketLifecycle * DeleteBucketLifecycle"},{"ref":"AWS.S3.html#get_bucket_location/4","title":"AWS.S3.get_bucket_location/4","type":"function","doc":"Returns the Region the bucket resides in. You set the bucket&#39;s Region using the LocationConstraint request parameter in a CreateBucket request. For more information, see CreateBucket. To use this implementation of the operation, you must be the bucket owner. The following operations are related to GetBucketLocation: GetObject * CreateBucket"},{"ref":"AWS.S3.html#get_bucket_logging/4","title":"AWS.S3.get_bucket_logging/4","type":"function","doc":"Returns the logging status of a bucket and the permissions users have to view and modify that status. To use GET, you must be the bucket owner. The following operations are related to GetBucketLogging: CreateBucket PutBucketLogging"},{"ref":"AWS.S3.html#get_bucket_metrics_configuration/5","title":"AWS.S3.get_bucket_metrics_configuration/5","type":"function","doc":"Gets a metrics configuration (specified by the metrics configuration ID) from the bucket. Note that this doesn&#39;t include the daily storage metrics. To use this operation, you must have permissions to perform the s3:GetMetricsConfiguration action. The bucket owner has this permission by default. The bucket owner can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources. For information about CloudWatch request metrics for Amazon S3, see Monitoring Metrics with Amazon CloudWatch. The following operations are related to GetBucketMetricsConfiguration: PutBucketMetricsConfiguration DeleteBucketMetricsConfiguration ListBucketMetricsConfigurations Monitoring Metrics with Amazon CloudWatch"},{"ref":"AWS.S3.html#get_bucket_notification/4","title":"AWS.S3.get_bucket_notification/4","type":"function","doc":"No longer used, see GetBucketNotificationConfiguration."},{"ref":"AWS.S3.html#get_bucket_notification_configuration/4","title":"AWS.S3.get_bucket_notification_configuration/4","type":"function","doc":"Returns the notification configuration of a bucket. If notifications are not enabled on the bucket, the operation returns an empty NotificationConfiguration element. By default, you must be the bucket owner to read the notification configuration of a bucket. However, the bucket owner can use a bucket policy to grant permission to other users to read this configuration with the s3:GetBucketNotification permission. For more information about setting and reading the notification configuration on a bucket, see Setting Up Notification of Bucket Events. For more information about bucket policies, see Using Bucket Policies. The following operation is related to GetBucketNotification: * PutBucketNotification"},{"ref":"AWS.S3.html#get_bucket_ownership_controls/4","title":"AWS.S3.get_bucket_ownership_controls/4","type":"function","doc":"Retrieves OwnershipControls for an Amazon S3 bucket. To use this operation, you must have the s3:GetBucketOwnershipControls permission. For more information about Amazon S3 permissions, see Specifying Permissions in a Policy. For information about Amazon S3 Object Ownership, see Using Object Ownership. The following operations are related to GetBucketOwnershipControls: PutBucketOwnershipControls DeleteBucketOwnershipControls"},{"ref":"AWS.S3.html#get_bucket_policy/4","title":"AWS.S3.get_bucket_policy/4","type":"function","doc":"Returns the policy of a specified bucket. If you are using an identity other than the root user of the AWS account that owns the bucket, the calling identity must have the GetBucketPolicy permissions on the specified bucket and belong to the bucket owner&#39;s account in order to use this operation. If you don&#39;t have GetBucketPolicy permissions, Amazon S3 returns a 403 Access Denied error. If you have the correct permissions, but you&#39;re not using an identity that belongs to the bucket owner&#39;s account, Amazon S3 returns a 405 Method Not Allowed error. As a security precaution, the root user of the AWS account that owns a bucket can always use this operation, even if the policy explicitly denies the root user the ability to perform this action. For more information about bucket policies, see Using Bucket Policies and User Policies. The following operation is related to GetBucketPolicy: GetObject"},{"ref":"AWS.S3.html#get_bucket_policy_status/4","title":"AWS.S3.get_bucket_policy_status/4","type":"function","doc":"Retrieves the policy status for an Amazon S3 bucket, indicating whether the bucket is public. In order to use this operation, you must have the s3:GetBucketPolicyStatus permission. For more information about Amazon S3 permissions, see Specifying Permissions in a Policy. For more information about when Amazon S3 considers a bucket public, see The Meaning of &quot;Public&quot;. The following operations are related to GetBucketPolicyStatus: Using Amazon S3 Block Public Access GetPublicAccessBlock PutPublicAccessBlock * DeletePublicAccessBlock"},{"ref":"AWS.S3.html#get_bucket_replication/4","title":"AWS.S3.get_bucket_replication/4","type":"function","doc":"Returns the replication configuration of a bucket. It can take a while to propagate the put or delete a replication configuration to all Amazon S3 systems. Therefore, a get request soon after put or delete can return a wrong result. For information about replication configuration, see Replication in the Amazon Simple Storage Service Developer Guide. This operation requires permissions for the s3:GetReplicationConfiguration action. For more information about permissions, see Using Bucket Policies and User Policies. If you include the Filter element in a replication configuration, you must also include the DeleteMarkerReplication and Priority elements. The response also returns those elements. For information about GetBucketReplication errors, see List of replication-related error codes The following operations are related to GetBucketReplication: PutBucketReplication DeleteBucketReplication"},{"ref":"AWS.S3.html#get_bucket_request_payment/4","title":"AWS.S3.get_bucket_request_payment/4","type":"function","doc":"Returns the request payment configuration of a bucket. To use this version of the operation, you must be the bucket owner. For more information, see Requester Pays Buckets. The following operations are related to GetBucketRequestPayment: ListObjects"},{"ref":"AWS.S3.html#get_bucket_tagging/4","title":"AWS.S3.get_bucket_tagging/4","type":"function","doc":"Returns the tag set associated with the bucket. To use this operation, you must have permission to perform the s3:GetBucketTagging action. By default, the bucket owner has this permission and can grant this permission to others. GetBucketTagging has the following special error: Error code: NoSuchTagSetError Description: There is no tag set associated with the bucket. The following operations are related to GetBucketTagging: PutBucketTagging DeleteBucketTagging"},{"ref":"AWS.S3.html#get_bucket_versioning/4","title":"AWS.S3.get_bucket_versioning/4","type":"function","doc":"Returns the versioning state of a bucket. To retrieve the versioning state of a bucket, you must be the bucket owner. This implementation also returns the MFA Delete status of the versioning state. If the MFA Delete status is enabled, the bucket owner must use an authentication device to change the versioning state of the bucket. The following operations are related to GetBucketVersioning: GetObject * PutObject * DeleteObject"},{"ref":"AWS.S3.html#get_bucket_website/4","title":"AWS.S3.get_bucket_website/4","type":"function","doc":"Returns the website configuration for a bucket. To host website on Amazon S3, you can configure a bucket as website by adding a website configuration. For more information about hosting websites, see Hosting Websites on Amazon S3. This GET operation requires the S3:GetBucketWebsite permission. By default, only the bucket owner can read the bucket website configuration. However, bucket owners can allow other users to read the website configuration by writing a bucket policy granting them the S3:GetBucketWebsite permission. The following operations are related to DeleteBucketWebsite: DeleteBucketWebsite PutBucketWebsite"},{"ref":"AWS.S3.html#get_object/22","title":"AWS.S3.get_object/22","type":"function","doc":"Retrieves objects from Amazon S3. To use GET, you must have READ access to the object. If you grant READ access to the anonymous user, you can return the object without using an authorization header. An Amazon S3 bucket has no directory hierarchy such as you would find in a typical computer file system. You can, however, create a logical hierarchy by using object key names that imply a folder structure. For example, instead of naming an object sample.jpg, you can name it photos/2006/February/sample.jpg. To get an object from such a logical hierarchy, specify the full key name for the object in the GET operation. For a virtual hosted-style request example, if you have the object photos/2006/February/sample.jpg, specify the resource as /photos/2006/February/sample.jpg. For a path-style request example, if you have the object photos/2006/February/sample.jpg in the bucket named examplebucket, specify the resource as /examplebucket/photos/2006/February/sample.jpg. For more information about request types, see HTTP Host Header Bucket Specification. To distribute large files to many people, you can save bandwidth costs by using BitTorrent. For more information, see Amazon S3 Torrent. For more information about returning the ACL of an object, see GetObjectAcl. If the object you are retrieving is stored in the GLACIER or DEEP_ARCHIVE storage classes, before you can retrieve the object you must first restore a copy using RestoreObject. Otherwise, this operation returns an InvalidObjectStateError error. For information about restoring archived objects, see Restoring Archived Objects. Encryption request headers, like x-amz-server-side-encryption, should not be sent for GET requests if your object uses server-side encryption with CMKs stored in AWS KMS (SSE-KMS) or server-side encryption with Amazon S3managed encryption keys (SSE-S3). If your object does use these types of keys, youll get an HTTP 400 BadRequest error. If you encrypt an object by using server-side encryption with customer-provided encryption keys (SSE-C) when you store the object in Amazon S3, then when you GET the object, you must use the following headers: x-amz-server-side-encryption-customer-algorithm x-amz-server-side-encryption-customer-key x-amz-server-side-encryption-customer-key-MD5 For more information about SSE-C, see Server-Side Encryption (Using Customer-Provided Encryption Keys). Assuming you have permission to read object tags (permission for the s3:GetObjectVersionTagging action), the response also returns the x-amz-tagging-count header that provides the count of number of tags associated with the object. You can use GetObjectTagging to retrieve the tag set associated with an object. Permissions You need the s3:GetObject permission for this operation. For more information, see Specifying Permissions in a Policy. If the object you request does not exist, the error Amazon S3 returns depends on whether you also have the s3:ListBucket permission. If you have the s3:ListBucket permission on the bucket, Amazon S3 will return an HTTP status code 404 (&quot;no such key&quot;) error. If you dont have the s3:ListBucket permission, Amazon S3 will return an HTTP status code 403 (&quot;access denied&quot;) error. Versioning By default, the GET operation returns the current version of an object. To return a different version, use the versionId subresource. If the current version of the object is a delete marker, Amazon S3 behaves as if the object was deleted and includes x-amz-delete-marker: true in the response. For more information about versioning, see PutBucketVersioning. Overriding Response Header Values There are times when you want to override certain response header values in a GET response. For example, you might override the Content-Disposition response header value in your GET request. You can override values for a set of response headers using the following query parameters. These response header values are sent only on a successful request, that is, when status code 200 OK is returned. The set of headers you can override using these parameters is a subset of the headers that Amazon S3 accepts when you create an object. The response headers that you can override for the GET response are Content-Type, Content-Language, Expires, Cache-Control, Content-Disposition, and Content-Encoding. To override these header values in the GET response, you use the following request parameters. You must sign the request, either using an Authorization header or a presigned URL, when using these parameters. They cannot be used with an unsigned (anonymous) request. response-content-type response-content-language response-expires response-cache-control response-content-disposition response-content-encoding Additional Considerations about Request Headers If both of the If-Match and If-Unmodified-Since headers are present in the request as follows: If-Match condition evaluates to true, and; If-Unmodified-Since condition evaluates to false; then, S3 returns 200 OK and the data requested. If both of the If-None-Match and If-Modified-Since headers are present in the request as follows:If-None-Match condition evaluates to false, and; If-Modified-Since condition evaluates to true; then, S3 returns 304 Not Modified response code. For more information about conditional requests, see RFC 7232. The following operations are related to GetObject: ListBuckets * GetObjectAcl"},{"ref":"AWS.S3.html#get_object_acl/7","title":"AWS.S3.get_object_acl/7","type":"function","doc":"Returns the access control list (ACL) of an object. To use this operation, you must have READ_ACP access to the object. This action is not supported by Amazon S3 on Outposts. Versioning By default, GET returns ACL information about the current version of an object. To return ACL information about a different version, use the versionId subresource. The following operations are related to GetObjectAcl: GetObject * DeleteObject PutObject"},{"ref":"AWS.S3.html#get_object_legal_hold/7","title":"AWS.S3.get_object_legal_hold/7","type":"function","doc":"Gets an object&#39;s current Legal Hold status. For more information, see Locking Objects. This action is not supported by Amazon S3 on Outposts."},{"ref":"AWS.S3.html#get_object_lock_configuration/4","title":"AWS.S3.get_object_lock_configuration/4","type":"function","doc":"Gets the Object Lock configuration for a bucket. The rule specified in the Object Lock configuration will be applied by default to every new object placed in the specified bucket. For more information, see Locking Objects."},{"ref":"AWS.S3.html#get_object_retention/7","title":"AWS.S3.get_object_retention/7","type":"function","doc":"Retrieves an object&#39;s retention settings. For more information, see Locking Objects. This action is not supported by Amazon S3 on Outposts."},{"ref":"AWS.S3.html#get_object_tagging/6","title":"AWS.S3.get_object_tagging/6","type":"function","doc":"Returns the tag-set of an object. You send the GET request against the tagging subresource associated with the object. To use this operation, you must have permission to perform the s3:GetObjectTagging action. By default, the GET operation returns information about current version of an object. For a versioned bucket, you can have multiple versions of an object in your bucket. To retrieve tags of any other version, use the versionId query parameter. You also need permission for the s3:GetObjectVersionTagging action. By default, the bucket owner has this permission and can grant this permission to others. For information about the Amazon S3 object tagging feature, see Object Tagging. The following operation is related to GetObjectTagging: * PutObjectTagging"},{"ref":"AWS.S3.html#get_object_torrent/6","title":"AWS.S3.get_object_torrent/6","type":"function","doc":"Returns torrent files from a bucket. BitTorrent can save you bandwidth when you&#39;re distributing large files. For more information about BitTorrent, see Using BitTorrent with Amazon S3. You can get torrent only for objects that are less than 5 GB in size, and that are not encrypted using server-side encryption with a customer-provided encryption key. To use GET, you must have READ access to the object. This action is not supported by Amazon S3 on Outposts. The following operation is related to GetObjectTorrent: GetObject"},{"ref":"AWS.S3.html#get_public_access_block/4","title":"AWS.S3.get_public_access_block/4","type":"function","doc":"Retrieves the PublicAccessBlock configuration for an Amazon S3 bucket. To use this operation, you must have the s3:GetBucketPublicAccessBlock permission. For more information about Amazon S3 permissions, see Specifying Permissions in a Policy. When Amazon S3 evaluates the PublicAccessBlock configuration for a bucket or an object, it checks the PublicAccessBlock configuration for both the bucket (or the bucket that contains the object) and the bucket owner&#39;s account. If the PublicAccessBlock settings are different between the bucket and the account, Amazon S3 uses the most restrictive combination of the bucket-level and account-level settings. For more information about when Amazon S3 considers a bucket or an object public, see The Meaning of &quot;Public&quot;. The following operations are related to GetPublicAccessBlock: Using Amazon S3 Block Public Access PutPublicAccessBlock GetPublicAccessBlock * DeletePublicAccessBlock"},{"ref":"AWS.S3.html#head_bucket/4","title":"AWS.S3.head_bucket/4","type":"function","doc":"This operation is useful to determine if a bucket exists and you have permission to access it. The operation returns a 200 OK if the bucket exists and you have permission to access it. Otherwise, the operation might return responses such as 404 Not Found and 403 Forbidden. To use this operation, you must have permissions to perform the s3:ListBucket action. The bucket owner has this permission by default and can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources."},{"ref":"AWS.S3.html#head_object/5","title":"AWS.S3.head_object/5","type":"function","doc":"The HEAD operation retrieves metadata from an object without returning the object itself. This operation is useful if you&#39;re only interested in an object&#39;s metadata. To use HEAD, you must have READ access to the object. A HEAD request has the same options as a GET operation on an object. The response is identical to the GET response except that there is no response body. If you encrypt an object by using server-side encryption with customer-provided encryption keys (SSE-C) when you store the object in Amazon S3, then when you retrieve the metadata from the object, you must use the following headers: x-amz-server-side-encryption-customer-algorithm x-amz-server-side-encryption-customer-key x-amz-server-side-encryption-customer-key-MD5 For more information about SSE-C, see Server-Side Encryption (Using Customer-Provided Encryption Keys). Encryption request headers, like x-amz-server-side-encryption, should not be sent for GET requests if your object uses server-side encryption with CMKs stored in AWS KMS (SSE-KMS) or server-side encryption with Amazon S3managed encryption keys (SSE-S3). If your object does use these types of keys, youll get an HTTP 400 BadRequest error. Request headers are limited to 8 KB in size. For more information, see Common Request Headers. Consider the following when using request headers: Consideration 1  If both of the If-Match and If-Unmodified-Since headers are present in the request as follows: If-Match condition evaluates to true, and; If-Unmodified-Since condition evaluates to false; Then Amazon S3 returns 200 OK and the data requested. Consideration 2  If both of the If-None-Match and If-Modified-Since headers are present in the request as follows: If-None-Match condition evaluates to false, and; If-Modified-Since condition evaluates to true; Then Amazon S3 returns the 304 Not Modified response code. For more information about conditional requests, see RFC 7232. Permissions You need the s3:GetObject permission for this operation. For more information, see Specifying Permissions in a Policy. If the object you request does not exist, the error Amazon S3 returns depends on whether you also have the s3:ListBucket permission. If you have the s3:ListBucket permission on the bucket, Amazon S3 returns an HTTP status code 404 (&quot;no such key&quot;) error. If you dont have the s3:ListBucket permission, Amazon S3 returns an HTTP status code 403 (&quot;access denied&quot;) error. The following operation is related to HeadObject: GetObject"},{"ref":"AWS.S3.html#list_bucket_analytics_configurations/5","title":"AWS.S3.list_bucket_analytics_configurations/5","type":"function","doc":"Lists the analytics configurations for the bucket. You can have up to 1,000 analytics configurations per bucket. This operation supports list pagination and does not return more than 100 configurations at a time. You should always check the IsTruncated element in the response. If there are no more configurations to list, IsTruncated is set to false. If there are more configurations to list, IsTruncated is set to true, and there will be a value in NextContinuationToken. You use the NextContinuationToken value to continue the pagination of the list by passing the value in continuation-token in the request to GET the next page. To use this operation, you must have permissions to perform the s3:GetAnalyticsConfiguration action. The bucket owner has this permission by default. The bucket owner can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources. For information about Amazon S3 analytics feature, see Amazon S3 Analytics  Storage Class Analysis. The following operations are related to ListBucketAnalyticsConfigurations: GetBucketAnalyticsConfiguration DeleteBucketAnalyticsConfiguration * PutBucketAnalyticsConfiguration"},{"ref":"AWS.S3.html#list_bucket_inventory_configurations/5","title":"AWS.S3.list_bucket_inventory_configurations/5","type":"function","doc":"Returns a list of inventory configurations for the bucket. You can have up to 1,000 analytics configurations per bucket. This operation supports list pagination and does not return more than 100 configurations at a time. Always check the IsTruncated element in the response. If there are no more configurations to list, IsTruncated is set to false. If there are more configurations to list, IsTruncated is set to true, and there is a value in NextContinuationToken. You use the NextContinuationToken value to continue the pagination of the list by passing the value in continuation-token in the request to GET the next page. To use this operation, you must have permissions to perform the s3:GetInventoryConfiguration action. The bucket owner has this permission by default. The bucket owner can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources. For information about the Amazon S3 inventory feature, see Amazon S3 Inventory The following operations are related to ListBucketInventoryConfigurations: GetBucketInventoryConfiguration DeleteBucketInventoryConfiguration * PutBucketInventoryConfiguration"},{"ref":"AWS.S3.html#list_bucket_metrics_configurations/5","title":"AWS.S3.list_bucket_metrics_configurations/5","type":"function","doc":"Lists the metrics configurations for the bucket. The metrics configurations are only for the request metrics of the bucket and do not provide information on daily storage metrics. You can have up to 1,000 configurations per bucket. This operation supports list pagination and does not return more than 100 configurations at a time. Always check the IsTruncated element in the response. If there are no more configurations to list, IsTruncated is set to false. If there are more configurations to list, IsTruncated is set to true, and there is a value in NextContinuationToken. You use the NextContinuationToken value to continue the pagination of the list by passing the value in continuation-token in the request to GET the next page. To use this operation, you must have permissions to perform the s3:GetMetricsConfiguration action. The bucket owner has this permission by default. The bucket owner can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources. For more information about metrics configurations and CloudWatch request metrics, see Monitoring Metrics with Amazon CloudWatch. The following operations are related to ListBucketMetricsConfigurations: PutBucketMetricsConfiguration GetBucketMetricsConfiguration * DeleteBucketMetricsConfiguration"},{"ref":"AWS.S3.html#list_buckets/2","title":"AWS.S3.list_buckets/2","type":"function","doc":"Returns a list of all buckets owned by the authenticated sender of the request."},{"ref":"AWS.S3.html#list_multipart_uploads/10","title":"AWS.S3.list_multipart_uploads/10","type":"function","doc":"This operation lists in-progress multipart uploads. An in-progress multipart upload is a multipart upload that has been initiated using the Initiate Multipart Upload request, but has not yet been completed or aborted. This operation returns at most 1,000 multipart uploads in the response. 1,000 multipart uploads is the maximum number of uploads a response can include, which is also the default value. You can further limit the number of uploads in a response by specifying the max-uploads parameter in the response. If additional multipart uploads satisfy the list criteria, the response will contain an IsTruncated element with the value true. To list the additional multipart uploads, use the key-marker and upload-id-marker request parameters. In the response, the uploads are sorted by key. If your application has initiated more than one multipart upload using the same object key, then uploads in the response are first sorted by key. Additionally, uploads are sorted in ascending order within each key by the upload initiation time. For more information on multipart uploads, see Uploading Objects Using Multipart Upload. For information on permissions required to use the multipart upload API, see Multipart Upload API and Permissions. The following operations are related to ListMultipartUploads: CreateMultipartUpload UploadPart CompleteMultipartUpload ListParts * AbortMultipartUpload"},{"ref":"AWS.S3.html#list_object_versions/10","title":"AWS.S3.list_object_versions/10","type":"function","doc":"Returns metadata about all versions of the objects in a bucket. You can also use request parameters as selection criteria to return metadata about a subset of all the object versions. A 200 OK response can contain valid or invalid XML. Make sure to design your application to parse the contents of the response and handle it appropriately. To use this operation, you must have READ access to the bucket. This action is not supported by Amazon S3 on Outposts. The following operations are related to ListObjectVersions: ListObjectsV2 GetObject PutObject * DeleteObject"},{"ref":"AWS.S3.html#list_objects/10","title":"AWS.S3.list_objects/10","type":"function","doc":"Returns some or all (up to 1,000) of the objects in a bucket. You can use the request parameters as selection criteria to return a subset of the objects in a bucket. A 200 OK response can contain valid or invalid XML. Be sure to design your application to parse the contents of the response and handle it appropriately. This API has been revised. We recommend that you use the newer version, ListObjectsV2, when developing applications. For backward compatibility, Amazon S3 continues to support ListObjects. The following operations are related to ListObjects: * ListObjectsV2 GetObject * PutObject CreateBucket ListBuckets"},{"ref":"AWS.S3.html#list_objects_v2/12","title":"AWS.S3.list_objects_v2/12","type":"function","doc":"Returns some or all (up to 1,000) of the objects in a bucket. You can use the request parameters as selection criteria to return a subset of the objects in a bucket. A 200 OK response can contain valid or invalid XML. Make sure to design your application to parse the contents of the response and handle it appropriately. To use this operation, you must have READ access to the bucket. To use this operation in an AWS Identity and Access Management (IAM) policy, you must have permissions to perform the s3:ListBucket action. The bucket owner has this permission by default and can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources. This section describes the latest revision of the API. We recommend that you use this revised API for application development. For backward compatibility, Amazon S3 continues to support the prior version of this API, ListObjects. To get a list of your buckets, see ListBuckets. The following operations are related to ListObjectsV2: GetObject * PutObject * CreateBucket"},{"ref":"AWS.S3.html#list_parts/9","title":"AWS.S3.list_parts/9","type":"function","doc":"Lists the parts that have been uploaded for a specific multipart upload. This operation must include the upload ID, which you obtain by sending the initiate multipart upload request (see CreateMultipartUpload). This request returns a maximum of 1,000 uploaded parts. The default number of parts returned is 1,000 parts. You can restrict the number of parts returned by specifying the max-parts request parameter. If your multipart upload consists of more than 1,000 parts, the response returns an IsTruncated field with the value of true, and a NextPartNumberMarker element. In subsequent ListParts requests you can include the part-number-marker query string parameter and set its value to the NextPartNumberMarker field value from the previous response. For more information on multipart uploads, see Uploading Objects Using Multipart Upload. For information on permissions required to use the multipart upload API, see Multipart Upload API and Permissions. The following operations are related to ListParts: CreateMultipartUpload UploadPart CompleteMultipartUpload AbortMultipartUpload * ListMultipartUploads"},{"ref":"AWS.S3.html#put_bucket_accelerate_configuration/4","title":"AWS.S3.put_bucket_accelerate_configuration/4","type":"function","doc":"Sets the accelerate configuration of an existing bucket. Amazon S3 Transfer Acceleration is a bucket-level feature that enables you to perform faster data transfers to Amazon S3. To use this operation, you must have permission to perform the s3:PutAccelerateConfiguration action. The bucket owner has this permission by default. The bucket owner can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources. The Transfer Acceleration state of a bucket can be set to one of the following two values: Enabled  Enables accelerated data transfers to the bucket. Suspended  Disables accelerated data transfers to the bucket. The GetBucketAccelerateConfiguration operation returns the transfer acceleration state of a bucket. After setting the Transfer Acceleration state of a bucket to Enabled, it might take up to thirty minutes before the data transfer rates to the bucket increase. The name of the bucket used for Transfer Acceleration must be DNS-compliant and must not contain periods (&quot;.&quot;). For more information about transfer acceleration, see Transfer Acceleration. The following operations are related to PutBucketAccelerateConfiguration: GetBucketAccelerateConfiguration CreateBucket"},{"ref":"AWS.S3.html#put_bucket_acl/4","title":"AWS.S3.put_bucket_acl/4","type":"function","doc":"Sets the permissions on an existing bucket using access control lists (ACL). For more information, see Using ACLs. To set the ACL of a bucket, you must have WRITE_ACP permission. You can use one of the following two ways to set a bucket&#39;s permissions: Specify the ACL in the request body Specify permissions using request headers You cannot specify access permission using both the body and the request headers. Depending on your application needs, you may choose to set the ACL on a bucket using either the request body or the headers. For example, if you have an existing application that updates a bucket ACL using the request body, then you can continue to use that approach. Access Permissions You can set access permissions using one of the following methods: Specify a canned ACL with the x-amz-acl request header. Amazon S3 supports a set of predefined ACLs, known as canned ACLs. Each canned ACL has a predefined set of grantees and permissions. Specify the canned ACL name as the value of x-amz-acl. If you use this header, you cannot use other access control-specific headers in your request. For more information, see Canned ACL. * Specify access permissions explicitly with the x-amz-grant-read, x-amz-grant-read-acp, x-amz-grant-write-acp, and x-amz-grant-full-control headers. When using these headers, you specify explicit access permissions and grantees (AWS accounts or Amazon S3 groups) who will receive the permission. If you use these ACL-specific headers, you cannot use the x-amz-acl header to set a canned ACL. These parameters map to the set of permissions that Amazon S3 supports in an ACL. For more information, see Access Control List (ACL) Overview. You specify each grantee as a type=value pair, where the type is one of the following: * `id`  if the value specified is the canonical user ID of an AWS account * `uri`  if you are granting permissions to a predefined group * `emailAddress`  if the value specified is the email address of an AWS account Using email addresses to specify a grantee is only supported in the following AWS Regions: US East (N. Virginia) US West (N. California) US West (Oregon) Asia Pacific (Singapore) Asia Pacific (Sydney) Asia Pacific (Tokyo) Europe (Ireland) South America (So Paulo) For a list of all the Amazon S3 supported Regions and endpoints, see Regions and Endpoints in the AWS General Reference. For example, the following x-amz-grant-write header grants create, overwrite, and delete objects permission to LogDelivery group predefined by Amazon S3 and two AWS accounts identified by their email addresses. x-amz-grant-write: uri=&quot;http://acs.amazonaws.com/groups/s3/LogDelivery&quot;, id=&quot;111122223333&quot;, id=&quot;555566667777&quot; You can use either a canned ACL or specify access permissions explicitly. You cannot do both. Grantee Values You can specify the person (grantee) to whom you&#39;re assigning access rights (using request elements) in the following ways: By the person&#39;s ID: &lt;Grantee xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:type=&quot;CanonicalUser&quot;&gt;&lt;ID&gt;&lt;&gt;ID&lt;&gt;&lt;/ID&gt;&lt;DisplayName&gt;&lt;&gt;GranteesEmail&lt;&gt;&lt;/DisplayName&gt; &lt;/Grantee&gt; DisplayName is optional and ignored in the request By URI: &lt;Grantee xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:type=&quot;Group&quot;&gt;&lt;URI&gt;&lt;&gt;http://acs.amazonaws.com/groups/global/AuthenticatedUsers&lt;&gt;&lt;/URI&gt;&lt;/Grantee&gt; By Email address: &lt;Grantee xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:type=&quot;AmazonCustomerByEmail&quot;&gt;&lt;EmailAddress&gt;&lt;&gt;Grantees@email.com&lt;&gt;&lt;/EmailAddress&gt;lt;/Grantee&gt; The grantee is resolved to the CanonicalUser and, in a response to a GET Object acl request, appears as the CanonicalUser. Using email addresses to specify a grantee is only supported in the following AWS Regions: US East (N. Virginia) US West (N. California) US West (Oregon) Asia Pacific (Singapore) Asia Pacific (Sydney) Asia Pacific (Tokyo) Europe (Ireland) South America (So Paulo) For a list of all the Amazon S3 supported Regions and endpoints, see Regions and Endpoints in the AWS General Reference. Related Resources CreateBucket DeleteBucket * GetObjectAcl"},{"ref":"AWS.S3.html#put_bucket_analytics_configuration/4","title":"AWS.S3.put_bucket_analytics_configuration/4","type":"function","doc":"Sets an analytics configuration for the bucket (specified by the analytics configuration ID). You can have up to 1,000 analytics configurations per bucket. You can choose to have storage class analysis export analysis reports sent to a comma-separated values (CSV) flat file. See the DataExport request element. Reports are updated daily and are based on the object filters that you configure. When selecting data export, you specify a destination bucket and an optional destination prefix where the file is written. You can export the data to a destination bucket in a different account. However, the destination bucket must be in the same Region as the bucket that you are making the PUT analytics configuration to. For more information, see Amazon S3 Analytics  Storage Class Analysis. You must create a bucket policy on the destination bucket where the exported file is written to grant permissions to Amazon S3 to write objects to the bucket. For an example policy, see Granting Permissions for Amazon S3 Inventory and Storage Class Analysis. To use this operation, you must have permissions to perform the s3:PutAnalyticsConfiguration action. The bucket owner has this permission by default. The bucket owner can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources. Special Errors HTTP Error: HTTP 400 Bad Request Code: InvalidArgument Cause: Invalid argument. HTTP Error: HTTP 400 Bad Request Code: TooManyConfigurations Cause: You are attempting to create a new configuration but have already reached the 1,000-configuration limit. HTTP Error: HTTP 403 Forbidden Code: AccessDenied Cause: You are not the owner of the specified bucket, or you do not have the s3:PutAnalyticsConfiguration bucket permission to set the configuration on the bucket. Related Resources GetBucketAnalyticsConfiguration DeleteBucketAnalyticsConfiguration * ListBucketAnalyticsConfigurations"},{"ref":"AWS.S3.html#put_bucket_cors/4","title":"AWS.S3.put_bucket_cors/4","type":"function","doc":"Sets the cors configuration for your bucket. If the configuration exists, Amazon S3 replaces it. To use this operation, you must be allowed to perform the s3:PutBucketCORS action. By default, the bucket owner has this permission and can grant it to others. You set this configuration on a bucket so that the bucket can service cross-origin requests. For example, you might want to enable a request whose origin is http://www.example.com to access your Amazon S3 bucket at my.example.bucket.com by using the browser&#39;s XMLHttpRequest capability. To enable cross-origin resource sharing (CORS) on a bucket, you add the cors subresource to the bucket. The cors subresource is an XML document in which you configure rules that identify origins and the HTTP methods that can be executed on your bucket. The document is limited to 64 KB in size. When Amazon S3 receives a cross-origin request (or a pre-flight OPTIONS request) against a bucket, it evaluates the cors configuration on the bucket and uses the first CORSRule rule that matches the incoming browser request to enable a cross-origin request. For a rule to match, the following conditions must be met: The request&#39;s Origin header must match AllowedOrigin elements. The request method (for example, GET, PUT, HEAD, and so on) or the Access-Control-Request-Method header in case of a pre-flight OPTIONS request must be one of the AllowedMethod elements. Every header specified in the Access-Control-Request-Headers request header of a pre-flight request must match an AllowedHeader element. For more information about CORS, go to Enabling Cross-Origin Resource Sharing in the Amazon Simple Storage Service Developer Guide. Related Resources GetBucketCors DeleteBucketCors * RESTOPTIONSobject"},{"ref":"AWS.S3.html#put_bucket_encryption/4","title":"AWS.S3.put_bucket_encryption/4","type":"function","doc":"This implementation of the PUT operation uses the encryption subresource to set the default encryption state of an existing bucket. This implementation of the PUT operation sets default encryption for a bucket using server-side encryption with Amazon S3-managed keys SSE-S3 or AWS KMS customer master keys (CMKs) (SSE-KMS). For information about the Amazon S3 default encryption feature, see Amazon S3 Default Bucket Encryption. This operation requires AWS Signature Version 4. For more information, see Authenticating Requests (AWS Signature Version 4). To use this operation, you must have permissions to perform the s3:PutEncryptionConfiguration action. The bucket owner has this permission by default. The bucket owner can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources in the Amazon Simple Storage Service Developer Guide. Related Resources GetBucketEncryption DeleteBucketEncryption"},{"ref":"AWS.S3.html#put_bucket_inventory_configuration/4","title":"AWS.S3.put_bucket_inventory_configuration/4","type":"function","doc":"This implementation of the PUT operation adds an inventory configuration (identified by the inventory ID) to the bucket. You can have up to 1,000 inventory configurations per bucket. Amazon S3 inventory generates inventories of the objects in the bucket on a daily or weekly basis, and the results are published to a flat file. The bucket that is inventoried is called the source bucket, and the bucket where the inventory flat file is stored is called the destination bucket. The destination bucket must be in the same AWS Region as the source bucket. When you configure an inventory for a source bucket, you specify the destination bucket where you want the inventory to be stored, and whether to generate the inventory daily or weekly. You can also configure what object metadata to include and whether to inventory all object versions or only current versions. For more information, see Amazon S3 Inventory in the Amazon Simple Storage Service Developer Guide. You must create a bucket policy on the destination bucket to grant permissions to Amazon S3 to write objects to the bucket in the defined location. For an example policy, see Granting Permissions for Amazon S3 Inventory and Storage Class Analysis. To use this operation, you must have permissions to perform the s3:PutInventoryConfiguration action. The bucket owner has this permission by default and can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources in the Amazon Simple Storage Service Developer Guide. Special Errors HTTP 400 Bad Request Error Code: InvalidArgument Cause: Invalid Argument HTTP 400 Bad Request Error Code: TooManyConfigurations Cause: You are attempting to create a new configuration but have already reached the 1,000-configuration limit. HTTP 403 Forbidden Error Code: AccessDenied Cause: You are not the owner of the specified bucket, or you do not have the s3:PutInventoryConfiguration bucket permission to set the configuration on the bucket. Related Resources GetBucketInventoryConfiguration DeleteBucketInventoryConfiguration * ListBucketInventoryConfigurations"},{"ref":"AWS.S3.html#put_bucket_lifecycle/4","title":"AWS.S3.put_bucket_lifecycle/4","type":"function","doc":"For an updated version of this API, see PutBucketLifecycleConfiguration. This version has been deprecated. Existing lifecycle configurations will work. For new lifecycle configurations, use the updated API. Creates a new lifecycle configuration for the bucket or replaces an existing lifecycle configuration. For information about lifecycle configuration, see Object Lifecycle Management in the Amazon Simple Storage Service Developer Guide. By default, all Amazon S3 resources, including buckets, objects, and related subresources (for example, lifecycle configuration and website configuration) are private. Only the resource owner, the AWS account that created the resource, can access it. The resource owner can optionally grant access permissions to others by writing an access policy. For this operation, users must get the s3:PutLifecycleConfiguration permission. You can also explicitly deny permissions. Explicit denial also supersedes any other permissions. If you want to prevent users or accounts from removing or deleting objects from your bucket, you must deny them permissions for the following actions: s3:DeleteObject s3:DeleteObjectVersion s3:PutLifecycleConfiguration For more information about permissions, see Managing Access Permissions to your Amazon S3 Resources in the Amazon Simple Storage Service Developer Guide. For more examples of transitioning objects to storage classes such as STANDARD_IA or ONEZONE_IA, see Examples of Lifecycle Configuration. Related Resources GetBucketLifecycle(Deprecated) GetBucketLifecycleConfiguration RestoreObject By default, a resource ownerin this case, a bucket owner, which is the AWS account that created the bucketcan perform any of the operations. A resource owner can also grant others permission to perform the operation. For more information, see the following topics in the Amazon Simple Storage Service Developer Guide: * [Specifying Permissions in a Policy](https://docs.aws.amazon.com/AmazonS3/latest/dev/using-with-s3-actions.html) * [Managing Access Permissions to your Amazon S3 Resources](https://docs.aws.amazon.com/AmazonS3/latest/dev/s3-access-control.html)"},{"ref":"AWS.S3.html#put_bucket_lifecycle_configuration/4","title":"AWS.S3.put_bucket_lifecycle_configuration/4","type":"function","doc":"Creates a new lifecycle configuration for the bucket or replaces an existing lifecycle configuration. For information about lifecycle configuration, see Managing Access Permissions to Your Amazon S3 Resources. Bucket lifecycle configuration now supports specifying a lifecycle rule using an object key name prefix, one or more object tags, or a combination of both. Accordingly, this section describes the latest API. The previous version of the API supported filtering based only on an object key name prefix, which is supported for backward compatibility. For the related API description, see PutBucketLifecycle. Rules You specify the lifecycle configuration in your request body. The lifecycle configuration is specified as XML consisting of one or more rules. Each rule consists of the following: Filter identifying a subset of objects to which the rule applies. The filter can be based on a key name prefix, object tags, or a combination of both. Status whether the rule is in effect. One or more lifecycle transition and expiration actions that you want Amazon S3 to perform on the objects identified by the filter. If the state of your bucket is versioning-enabled or versioning-suspended, you can have many versions of the same object (one current version and zero or more noncurrent versions). Amazon S3 provides predefined actions that you can specify for current and noncurrent object versions. For more information, see Object Lifecycle Management and Lifecycle Configuration Elements. Permissions By default, all Amazon S3 resources are private, including buckets, objects, and related subresources (for example, lifecycle configuration and website configuration). Only the resource owner (that is, the AWS account that created it) can access the resource. The resource owner can optionally grant access permissions to others by writing an access policy. For this operation, a user must get the s3:PutLifecycleConfiguration permission. You can also explicitly deny permissions. Explicit deny also supersedes any other permissions. If you want to block users or accounts from removing or deleting objects from your bucket, you must deny them permissions for the following actions: s3:DeleteObject s3:DeleteObjectVersion s3:PutLifecycleConfiguration For more information about permissions, see Managing Access Permissions to Your Amazon S3 Resources. The following are related to PutBucketLifecycleConfiguration: Examples of Lifecycle Configuration GetBucketLifecycleConfiguration DeleteBucketLifecycle"},{"ref":"AWS.S3.html#put_bucket_logging/4","title":"AWS.S3.put_bucket_logging/4","type":"function","doc":"Set the logging parameters for a bucket and to specify permissions for who can view and modify the logging parameters. All logs are saved to buckets in the same AWS Region as the source bucket. To set the logging status of a bucket, you must be the bucket owner. The bucket owner is automatically granted FULL_CONTROL to all logs. You use the Grantee request element to grant access to other people. The Permissions request element specifies the kind of access the grantee has to the logs. Grantee Values You can specify the person (grantee) to whom you&#39;re assigning access rights (using request elements) in the following ways: By the person&#39;s ID: &lt;Grantee xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:type=&quot;CanonicalUser&quot;&gt;&lt;ID&gt;&lt;&gt;ID&lt;&gt;&lt;/ID&gt;&lt;DisplayName&gt;&lt;&gt;GranteesEmail&lt;&gt;&lt;/DisplayName&gt; &lt;/Grantee&gt; DisplayName is optional and ignored in the request. By Email address: &lt;Grantee xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:type=&quot;AmazonCustomerByEmail&quot;&gt;&lt;EmailAddress&gt;&lt;&gt;Grantees@email.com&lt;&gt;&lt;/EmailAddress&gt;&lt;/Grantee&gt; The grantee is resolved to the CanonicalUser and, in a response to a GET Object acl request, appears as the CanonicalUser. By URI: &lt;Grantee xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:type=&quot;Group&quot;&gt;&lt;URI&gt;&lt;&gt;http://acs.amazonaws.com/groups/global/AuthenticatedUsers&lt;&gt;&lt;/URI&gt;&lt;/Grantee&gt; To enable logging, you use LoggingEnabled and its children request elements. To disable logging, you use an empty BucketLoggingStatus request element: &lt;BucketLoggingStatus xmlns=&quot;http://doc.s3.amazonaws.com/2006-03-01&quot; /&gt; For more information about server access logging, see Server Access Logging. For more information about creating a bucket, see CreateBucket. For more information about returning the logging status of a bucket, see GetBucketLogging. The following operations are related to PutBucketLogging: PutObject * DeleteBucket CreateBucket GetBucketLogging"},{"ref":"AWS.S3.html#put_bucket_metrics_configuration/4","title":"AWS.S3.put_bucket_metrics_configuration/4","type":"function","doc":"Sets a metrics configuration (specified by the metrics configuration ID) for the bucket. You can have up to 1,000 metrics configurations per bucket. If you&#39;re updating an existing metrics configuration, note that this is a full replacement of the existing metrics configuration. If you don&#39;t include the elements you want to keep, they are erased. To use this operation, you must have permissions to perform the s3:PutMetricsConfiguration action. The bucket owner has this permission by default. The bucket owner can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources. For information about CloudWatch request metrics for Amazon S3, see Monitoring Metrics with Amazon CloudWatch. The following operations are related to PutBucketMetricsConfiguration: DeleteBucketMetricsConfiguration PutBucketMetricsConfiguration * ListBucketMetricsConfigurations GetBucketLifecycle has the following special error: Error code: TooManyConfigurations Description: You are attempting to create a new configuration but have already reached the 1,000-configuration limit. HTTP Status Code: HTTP 400 Bad Request"},{"ref":"AWS.S3.html#put_bucket_notification/4","title":"AWS.S3.put_bucket_notification/4","type":"function","doc":"No longer used, see the PutBucketNotificationConfiguration operation."},{"ref":"AWS.S3.html#put_bucket_notification_configuration/4","title":"AWS.S3.put_bucket_notification_configuration/4","type":"function","doc":"Enables notifications of specified events for a bucket. For more information about event notifications, see Configuring Event Notifications. Using this API, you can replace an existing notification configuration. The configuration is an XML file that defines the event types that you want Amazon S3 to publish and the destination where you want Amazon S3 to publish an event notification when it detects an event of the specified type. By default, your bucket has no event notifications configured. That is, the notification configuration will be an empty NotificationConfiguration. &lt;NotificationConfiguration&gt; &lt;/NotificationConfiguration&gt; This operation replaces the existing notification configuration with the configuration you include in the request body. After Amazon S3 receives this request, it first verifies that any Amazon Simple Notification Service (Amazon SNS) or Amazon Simple Queue Service (Amazon SQS) destination exists, and that the bucket owner has permission to publish to it by sending a test notification. In the case of AWS Lambda destinations, Amazon S3 verifies that the Lambda function permissions grant Amazon S3 permission to invoke the function from the Amazon S3 bucket. For more information, see Configuring Notifications for Amazon S3 Events. You can disable notifications by adding the empty NotificationConfiguration element. By default, only the bucket owner can configure notifications on a bucket. However, bucket owners can use a bucket policy to grant permission to other users to set this configuration with s3:PutBucketNotification permission. The PUT notification is an atomic operation. For example, suppose your notification configuration includes SNS topic, SQS queue, and Lambda function configurations. When you send a PUT request with this configuration, Amazon S3 sends test messages to your SNS topic. If the message fails, the entire PUT operation will fail, and Amazon S3 will not add the configuration to your bucket. Responses If the configuration in the request body includes only one TopicConfiguration specifying only the s3:ReducedRedundancyLostObject event type, the response will also include the x-amz-sns-test-message-id header containing the message ID of the test notification sent to the topic. The following operation is related to PutBucketNotificationConfiguration: * GetBucketNotificationConfiguration"},{"ref":"AWS.S3.html#put_bucket_ownership_controls/4","title":"AWS.S3.put_bucket_ownership_controls/4","type":"function","doc":"Creates or modifies OwnershipControls for an Amazon S3 bucket. To use this operation, you must have the s3:GetBucketOwnershipControls permission. For more information about Amazon S3 permissions, see Specifying Permissions in a Policy. For information about Amazon S3 Object Ownership, see Using Object Ownership. The following operations are related to GetBucketOwnershipControls: GetBucketOwnershipControls DeleteBucketOwnershipControls"},{"ref":"AWS.S3.html#put_bucket_policy/4","title":"AWS.S3.put_bucket_policy/4","type":"function","doc":"Applies an Amazon S3 bucket policy to an Amazon S3 bucket. If you are using an identity other than the root user of the AWS account that owns the bucket, the calling identity must have the PutBucketPolicy permissions on the specified bucket and belong to the bucket owner&#39;s account in order to use this operation. If you don&#39;t have PutBucketPolicy permissions, Amazon S3 returns a 403 Access Denied error. If you have the correct permissions, but you&#39;re not using an identity that belongs to the bucket owner&#39;s account, Amazon S3 returns a 405 Method Not Allowed error. As a security precaution, the root user of the AWS account that owns a bucket can always use this operation, even if the policy explicitly denies the root user the ability to perform this action. For more information about bucket policies, see Using Bucket Policies and User Policies. The following operations are related to PutBucketPolicy: CreateBucket DeleteBucket"},{"ref":"AWS.S3.html#put_bucket_replication/4","title":"AWS.S3.put_bucket_replication/4","type":"function","doc":"Creates a replication configuration or replaces an existing one. For more information, see Replication in the Amazon S3 Developer Guide. To perform this operation, the user or role performing the operation must have the iam:PassRole permission. Specify the replication configuration in the request body. In the replication configuration, you provide the name of the destination bucket where you want Amazon S3 to replicate objects, the IAM role that Amazon S3 can assume to replicate objects on your behalf, and other relevant information. A replication configuration must include at least one rule, and can contain a maximum of 1,000. Each rule identifies a subset of objects to replicate by filtering the objects in the source bucket. To choose additional subsets of objects to replicate, add a rule for each subset. All rules must specify the same destination bucket. To specify a subset of the objects in the source bucket to apply a replication rule to, add the Filter element as a child of the Rule element. You can filter objects based on an object key prefix, one or more object tags, or both. When you add the Filter element in the configuration, you must also add the following elements: DeleteMarkerReplication, Status, and Priority. The latest version of the replication configuration XML is V2. XML V2 replication configurations are those that contain the Filter element for rules, and rules that specify S3 Replication Time Control (S3 RTC). In XML V2 replication configurations, Amazon S3 doesn&#39;t replicate delete markers. Therefore, you must set the DeleteMarkerReplication element to Disabled. For backward compatibility, Amazon S3 continues to support the XML V1 replication configuration. For information about enabling versioning on a bucket, see Using Versioning. By default, a resource owner, in this case the AWS account that created the bucket, can perform this operation. The resource owner can also grant others permissions to perform the operation. For more information about permissions, see Specifying Permissions in a Policy and Managing Access Permissions to Your Amazon S3 Resources. Handling Replication of Encrypted Objects By default, Amazon S3 doesn&#39;t replicate objects that are stored at rest using server-side encryption with CMKs stored in AWS KMS. To replicate AWS KMS-encrypted objects, add the following: SourceSelectionCriteria, SseKmsEncryptedObjects, Status, EncryptionConfiguration, and ReplicaKmsKeyID. For information about replication configuration, see Replicating Objects Created with SSE Using CMKs stored in AWS KMS. For information on PutBucketReplication errors, see List of replication-related error codes The following operations are related to PutBucketReplication: GetBucketReplication DeleteBucketReplication"},{"ref":"AWS.S3.html#put_bucket_request_payment/4","title":"AWS.S3.put_bucket_request_payment/4","type":"function","doc":"Sets the request payment configuration for a bucket. By default, the bucket owner pays for downloads from the bucket. This configuration parameter enables the bucket owner (only) to specify that the person requesting the download will be charged for the download. For more information, see Requester Pays Buckets. The following operations are related to PutBucketRequestPayment: CreateBucket GetBucketRequestPayment"},{"ref":"AWS.S3.html#put_bucket_tagging/4","title":"AWS.S3.put_bucket_tagging/4","type":"function","doc":"Sets the tags for a bucket. Use tags to organize your AWS bill to reflect your own cost structure. To do this, sign up to get your AWS account bill with tag key values included. Then, to see the cost of combined resources, organize your billing information according to resources with the same tag key values. For example, you can tag several resources with a specific application name, and then organize your billing information to see the total cost of that application across several services. For more information, see Cost Allocation and Tagging. Within a bucket, if you add a tag that has the same key as an existing tag, the new value overwrites the old value. For more information, see Using Cost Allocation in Amazon S3 Bucket Tags. To use this operation, you must have permissions to perform the s3:PutBucketTagging action. The bucket owner has this permission by default and can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources. PutBucketTagging has the following special errors: Error code: InvalidTagError Description: The tag provided was not a valid tag. This error can occur if the tag did not pass input validation. For information about tag restrictions, see User-Defined Tag Restrictions and AWS-Generated Cost Allocation Tag Restrictions. Error code: MalformedXMLError Description: The XML provided does not match the schema. Error code: OperationAbortedError Description: A conflicting conditional operation is currently in progress against this resource. Please try again. Error code: InternalError Description: The service was unable to apply the provided tag to the bucket. The following operations are related to PutBucketTagging: GetBucketTagging DeleteBucketTagging"},{"ref":"AWS.S3.html#put_bucket_versioning/4","title":"AWS.S3.put_bucket_versioning/4","type":"function","doc":"Sets the versioning state of an existing bucket. To set the versioning state, you must be the bucket owner. You can set the versioning state with one of the following values: EnabledEnables versioning for the objects in the bucket. All objects added to the bucket receive a unique version ID. SuspendedDisables versioning for the objects in the bucket. All objects added to the bucket receive the version ID null. If the versioning state has never been set on a bucket, it has no versioning state; a GetBucketVersioning request does not return a versioning state value. If the bucket owner enables MFA Delete in the bucket versioning configuration, the bucket owner must include the x-amz-mfa request header and the Status and the MfaDelete request elements in a request to set the versioning state of the bucket. If you have an object expiration lifecycle policy in your non-versioned bucket and you want to maintain the same permanent delete behavior when you enable versioning, you must add a noncurrent expiration policy. The noncurrent expiration lifecycle policy will manage the deletes of the noncurrent object versions in the version-enabled bucket. (A version-enabled bucket maintains one current and zero or more noncurrent object versions.) For more information, see Lifecycle and Versioning. Related Resources CreateBucket DeleteBucket * GetBucketVersioning"},{"ref":"AWS.S3.html#put_bucket_website/4","title":"AWS.S3.put_bucket_website/4","type":"function","doc":"Sets the configuration of the website that is specified in the website subresource. To configure a bucket as a website, you can add this subresource on the bucket with website configuration information such as the file name of the index document and any redirect rules. For more information, see Hosting Websites on Amazon S3. This PUT operation requires the S3:PutBucketWebsite permission. By default, only the bucket owner can configure the website attached to a bucket; however, bucket owners can allow other users to set the website configuration by writing a bucket policy that grants them the S3:PutBucketWebsite permission. To redirect all website requests sent to the bucket&#39;s website endpoint, you add a website configuration with the following elements. Because all requests are sent to another website, you don&#39;t need to provide index document name for the bucket. WebsiteConfiguration RedirectAllRequestsTo HostName Protocol If you want granular control over redirects, you can use the following elements to add routing rules that describe conditions for redirecting requests and information about the redirect destination. In this case, the website configuration must provide an index document for the bucket, because some requests might not be redirected. WebsiteConfiguration IndexDocument Suffix ErrorDocument Key RoutingRules RoutingRule Condition HttpErrorCodeReturnedEquals KeyPrefixEquals Redirect Protocol HostName ReplaceKeyPrefixWith ReplaceKeyWith HttpRedirectCode Amazon S3 has a limitation of 50 routing rules per website configuration. If you require more than 50 routing rules, you can use object redirect. For more information, see Configuring an Object Redirect in the Amazon Simple Storage Service Developer Guide."},{"ref":"AWS.S3.html#put_object/5","title":"AWS.S3.put_object/5","type":"function","doc":"Adds an object to a bucket. You must have WRITE permissions on a bucket to add an object to it. Amazon S3 never adds partial objects; if you receive a success response, Amazon S3 added the entire object to the bucket. Amazon S3 is a distributed system. If it receives multiple write requests for the same object simultaneously, it overwrites all but the last object written. Amazon S3 does not provide object locking; if you need this, make sure to build it into your application layer or use versioning instead. To ensure that data is not corrupted traversing the network, use the Content-MD5 header. When you use this header, Amazon S3 checks the object against the provided MD5 value and, if they do not match, returns an error. Additionally, you can calculate the MD5 while putting an object to Amazon S3 and compare the returned ETag to the calculated MD5 value. The Content-MD5 header is required for any request to upload an object with a retention period configured using Amazon S3 Object Lock. For more information about Amazon S3 Object Lock, see Amazon S3 Object Lock Overview in the Amazon Simple Storage Service Developer Guide. Server-side Encryption You can optionally request server-side encryption. With server-side encryption, Amazon S3 encrypts your data as it writes it to disks in its data centers and decrypts the data when you access it. You have the option to provide your own encryption key or use AWS managed encryption keys. For more information, see Using Server-Side Encryption. Access Control List (ACL)-Specific Request Headers You can use headers to grant ACL- based permissions. By default, all objects are private. Only the owner has full access control. When adding a new object, you can grant permissions to individual AWS accounts or to predefined groups defined by Amazon S3. These permissions are then added to the ACL on the object. For more information, see Access Control List (ACL) Overview and Managing ACLs Using the REST API. Storage Class Options By default, Amazon S3 uses the STANDARD Storage Class to store newly created objects. The STANDARD storage class provides high durability and high availability. Depending on performance needs, you can specify a different Storage Class. Amazon S3 on Outposts only uses the OUTPOSTS Storage Class. For more information, see Storage Classes in the Amazon S3 Service Developer Guide. Versioning If you enable versioning for a bucket, Amazon S3 automatically generates a unique version ID for the object being stored. Amazon S3 returns this ID in the response. When you enable versioning for a bucket, if Amazon S3 receives multiple write requests for the same object simultaneously, it stores all of the objects. For more information about versioning, see Adding Objects to Versioning Enabled Buckets. For information about returning the versioning state of a bucket, see GetBucketVersioning. Related Resources CopyObject * DeleteObject"},{"ref":"AWS.S3.html#put_object_acl/5","title":"AWS.S3.put_object_acl/5","type":"function","doc":"Uses the acl subresource to set the access control list (ACL) permissions for a new or existing object in an S3 bucket. You must have WRITE_ACP permission to set the ACL of an object. For more information, see What permissions can I grant? in the Amazon Simple Storage Service Developer Guide. This action is not supported by Amazon S3 on Outposts. Depending on your application needs, you can choose to set the ACL on an object using either the request body or the headers. For example, if you have an existing application that updates a bucket ACL using the request body, you can continue to use that approach. For more information, see Access Control List (ACL) Overview in the Amazon S3 Developer Guide. Access Permissions You can set access permissions using one of the following methods: Specify a canned ACL with the x-amz-acl request header. Amazon S3 supports a set of predefined ACLs, known as canned ACLs. Each canned ACL has a predefined set of grantees and permissions. Specify the canned ACL name as the value of x-amz-acl. If you use this header, you cannot use other access control-specific headers in your request. For more information, see Canned ACL. * Specify access permissions explicitly with the x-amz-grant-read, x-amz-grant-read-acp, x-amz-grant-write-acp, and x-amz-grant-full-control headers. When using these headers, you specify explicit access permissions and grantees (AWS accounts or Amazon S3 groups) who will receive the permission. If you use these ACL-specific headers, you cannot use x-amz-acl header to set a canned ACL. These parameters map to the set of permissions that Amazon S3 supports in an ACL. For more information, see Access Control List (ACL) Overview. You specify each grantee as a type=value pair, where the type is one of the following: * `id`  if the value specified is the canonical user ID of an AWS account * `uri`  if you are granting permissions to a predefined group * `emailAddress`  if the value specified is the email address of an AWS account Using email addresses to specify a grantee is only supported in the following AWS Regions: US East (N. Virginia) US West (N. California) US West (Oregon) Asia Pacific (Singapore) Asia Pacific (Sydney) Asia Pacific (Tokyo) Europe (Ireland) South America (So Paulo) For a list of all the Amazon S3 supported Regions and endpoints, see Regions and Endpoints in the AWS General Reference. For example, the following x-amz-grant-read header grants list objects permission to the two AWS accounts identified by their email addresses. x-amz-grant-read: emailAddress=&quot;xyz@amazon.com&quot;, emailAddress=&quot;abc@amazon.com&quot; You can use either a canned ACL or specify access permissions explicitly. You cannot do both. Grantee Values You can specify the person (grantee) to whom you&#39;re assigning access rights (using request elements) in the following ways: By the person&#39;s ID: &lt;Grantee xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:type=&quot;CanonicalUser&quot;&gt;&lt;ID&gt;&lt;&gt;ID&lt;&gt;&lt;/ID&gt;&lt;DisplayName&gt;&lt;&gt;GranteesEmail&lt;&gt;&lt;/DisplayName&gt; &lt;/Grantee&gt; DisplayName is optional and ignored in the request. By URI: &lt;Grantee xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:type=&quot;Group&quot;&gt;&lt;URI&gt;&lt;&gt;http://acs.amazonaws.com/groups/global/AuthenticatedUsers&lt;&gt;&lt;/URI&gt;&lt;/Grantee&gt; By Email address: &lt;Grantee xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:type=&quot;AmazonCustomerByEmail&quot;&gt;&lt;EmailAddress&gt;&lt;&gt;Grantees@email.com&lt;&gt;&lt;/EmailAddress&gt;lt;/Grantee&gt; The grantee is resolved to the CanonicalUser and, in a response to a GET Object acl request, appears as the CanonicalUser. Using email addresses to specify a grantee is only supported in the following AWS Regions: US East (N. Virginia) US West (N. California) US West (Oregon) Asia Pacific (Singapore) Asia Pacific (Sydney) Asia Pacific (Tokyo) Europe (Ireland) South America (So Paulo) For a list of all the Amazon S3 supported Regions and endpoints, see Regions and Endpoints in the AWS General Reference. Versioning The ACL of an object is set at the object version level. By default, PUT sets the ACL of the current version of an object. To set the ACL of a different version, use the versionId subresource. Related Resources CopyObject * GetObject"},{"ref":"AWS.S3.html#put_object_legal_hold/5","title":"AWS.S3.put_object_legal_hold/5","type":"function","doc":"Applies a Legal Hold configuration to the specified object. This action is not supported by Amazon S3 on Outposts. Related Resources Locking Objects"},{"ref":"AWS.S3.html#put_object_lock_configuration/4","title":"AWS.S3.put_object_lock_configuration/4","type":"function","doc":"Places an Object Lock configuration on the specified bucket. The rule specified in the Object Lock configuration will be applied by default to every new object placed in the specified bucket. DefaultRetention requires either Days or Years. You can&#39;t specify both at the same time. Related Resources Locking Objects"},{"ref":"AWS.S3.html#put_object_retention/5","title":"AWS.S3.put_object_retention/5","type":"function","doc":"Places an Object Retention configuration on an object. This action is not supported by Amazon S3 on Outposts. Related Resources Locking Objects"},{"ref":"AWS.S3.html#put_object_tagging/5","title":"AWS.S3.put_object_tagging/5","type":"function","doc":"Sets the supplied tag-set to an object that already exists in a bucket. A tag is a key-value pair. You can associate tags with an object by sending a PUT request against the tagging subresource that is associated with the object. You can retrieve tags by sending a GET request. For more information, see GetObjectTagging. For tagging-related restrictions related to characters and encodings, see Tag Restrictions. Note that Amazon S3 limits the maximum number of tags to 10 tags per object. To use this operation, you must have permission to perform the s3:PutObjectTagging action. By default, the bucket owner has this permission and can grant this permission to others. To put tags of any other version, use the versionId query parameter. You also need permission for the s3:PutObjectVersionTagging action. For information about the Amazon S3 object tagging feature, see Object Tagging. Special Errors Code: InvalidTagError Cause: The tag provided was not a valid tag. This error can occur if the tag did not pass input validation. For more information, see Object Tagging. Code: MalformedXMLError Cause: The XML provided does not match the schema. Code: OperationAbortedError Cause: A conflicting conditional operation is currently in progress against this resource. Please try again. Code: InternalError Cause: The service was unable to apply the provided tag to the object. Related Resources * GetObjectTagging"},{"ref":"AWS.S3.html#put_public_access_block/4","title":"AWS.S3.put_public_access_block/4","type":"function","doc":"Creates or modifies the PublicAccessBlock configuration for an Amazon S3 bucket. To use this operation, you must have the s3:PutBucketPublicAccessBlock permission. For more information about Amazon S3 permissions, see Specifying Permissions in a Policy. When Amazon S3 evaluates the PublicAccessBlock configuration for a bucket or an object, it checks the PublicAccessBlock configuration for both the bucket (or the bucket that contains the object) and the bucket owner&#39;s account. If the PublicAccessBlock configurations are different between the bucket and the account, Amazon S3 uses the most restrictive combination of the bucket-level and account-level settings. For more information about when Amazon S3 considers a bucket or an object public, see The Meaning of &quot;Public&quot;. Related Resources GetPublicAccessBlock DeletePublicAccessBlock GetBucketPolicyStatus Using Amazon S3 Block Public Access"},{"ref":"AWS.S3.html#restore_object/5","title":"AWS.S3.restore_object/5","type":"function","doc":"Restores an archived copy of an object back into Amazon S3 This action is not supported by Amazon S3 on Outposts. This action performs the following types of requests: select - Perform a select query on an archived object restore an archive - Restore an archived object To use this operation, you must have permissions to perform the s3:RestoreObject action. The bucket owner has this permission by default and can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources in the Amazon Simple Storage Service Developer Guide. Querying Archives with Select Requests You use a select type of request to perform SQL queries on archived objects. The archived objects that are being queried by the select request must be formatted as uncompressed comma-separated values (CSV) files. You can run queries and custom analytics on your archived data without having to restore your data to a hotter Amazon S3 tier. For an overview about select requests, see Querying Archived Objects in the Amazon Simple Storage Service Developer Guide. When making a select request, do the following: Define an output location for the select query&#39;s output. This must be an Amazon S3 bucket in the same AWS Region as the bucket that contains the archive object that is being queried. The AWS account that initiates the job must have permissions to write to the S3 bucket. You can specify the storage class and encryption for the output objects stored in the bucket. For more information about output, see Querying Archived Objects in the Amazon Simple Storage Service Developer Guide. For more information about the S3 structure in the request body, see the following: * PutObject Managing Access with ACLs in the Amazon Simple Storage Service Developer Guide* * [Protecting Data Using Server-Side Encryption](https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html) in the Amazon Simple Storage Service Developer Guide Define the SQL expression for the SELECT type of restoration for your query in the request body&#39;s SelectParameters structure. You can use expressions like the following examples. The following expression returns all records from the specified object. SELECT * FROM Object * Assuming that you are not using any headers for data stored in the object, you can specify columns with positional headers. SELECT s._1, s._2 FROM Object s WHERE s._3 &gt; 100 * If you have headers and you set the `fileHeaderInfo` in the `CSV` structure in the request body to USE, you can specify headers in the query. (If you set the fileHeaderInfo field to IGNORE, the first row is skipped for the query.) You cannot mix ordinal positions with header column names. SELECT s.Id, s.FirstName, s.SSN FROM S3Object s For more information about using SQL with S3 Glacier Select restore, see SQL Reference for Amazon S3 Select and S3 Glacier Select in the Amazon Simple Storage Service Developer Guide. When making a select request, you can also do the following: To expedite your queries, specify the Expedited tier. For more information about tiers, see &quot;Restoring Archives,&quot; later in this topic. Specify details about the data serialization format of both the input object that is being queried and the serialization of the CSV-encoded query results. The following are additional important facts about the select feature: The output results are new Amazon S3 objects. Unlike archive retrievals, they are stored until explicitly deleted-manually or through a lifecycle policy. You can issue more than one select request on the same Amazon S3 object. Amazon S3 doesn&#39;t deduplicate requests, so avoid issuing duplicate requests. Amazon S3 accepts a select request even if the object has already been restored. A select request doesnt return error response 409. Restoring Archives Objects in the GLACIER and DEEP_ARCHIVE storage classes are archived. To access an archived object, you must first initiate a restore request. This restores a temporary copy of the archived object. In a restore request, you specify the number of days that you want the restored copy to exist. After the specified period, Amazon S3 deletes the temporary copy but the object remains archived in the GLACIER or DEEP_ARCHIVE storage class that object was restored from. To restore a specific object version, you can provide a version ID. If you don&#39;t provide a version ID, Amazon S3 restores the current version. The time it takes restore jobs to finish depends on which storage class the object is being restored from and which data access tier you specify. When restoring an archived object (or using a select request), you can specify one of the following data access tier options in the Tier element of the request body: Expedited - Expedited retrievals allow you to quickly access your data stored in the GLACIER storage class when occasional urgent requests for a subset of archives are required. For all but the largest archived objects (250 MB+), data accessed using Expedited retrievals are typically made available within 15 minutes. Provisioned capacity ensures that retrieval capacity for Expedited retrievals is available when you need it. Expedited retrievals and provisioned capacity are not available for the DEEP_ARCHIVE storage class. Standard - S3 Standard retrievals allow you to access any of your archived objects within several hours. This is the default option for the GLACIER and DEEP_ARCHIVE retrieval requests that do not specify the retrieval option. S3 Standard retrievals typically complete within 3-5 hours from the GLACIER storage class and typically complete within 12 hours from the DEEP_ARCHIVE storage class. Bulk - Bulk retrievals are Amazon S3 Glaciers lowest-cost retrieval option, enabling you to retrieve large amounts, even petabytes, of data inexpensively in a day. Bulk retrievals typically complete within 5-12 hours from the GLACIER storage class and typically complete within 48 hours from the DEEP_ARCHIVE storage class. For more information about archive retrieval options and provisioned capacity for Expedited data access, see Restoring Archived Objects in the Amazon Simple Storage Service Developer Guide. You can use Amazon S3 restore speed upgrade to change the restore speed to a faster speed while it is in progress. You upgrade the speed of an in-progress restoration by issuing another restore request to the same object, setting a new Tier request element. When issuing a request to upgrade the restore tier, you must choose a tier that is faster than the tier that the in-progress restore is using. You must not change any other parameters, such as the Days request element. For more information, see Upgrading the Speed of an In-Progress Restore in the Amazon Simple Storage Service Developer Guide. To get the status of object restoration, you can send a HEAD request. Operations return the x-amz-restore header, which provides information about the restoration status, in the response. You can use Amazon S3 event notifications to notify you when a restore is initiated or completed. For more information, see Configuring Amazon S3 Event Notifications in the Amazon Simple Storage Service Developer Guide. After restoring an archived object, you can update the restoration period by reissuing the request with a new period. Amazon S3 updates the restoration period relative to the current time and charges only for the request-there are no data transfer charges. You cannot update the restoration period when Amazon S3 is actively processing your current restore request for the object. If your bucket has a lifecycle configuration with a rule that includes an expiration action, the object expiration overrides the life span that you specify in a restore request. For example, if you restore an object copy for 10 days, but the object is scheduled to expire in 3 days, Amazon S3 deletes the object in 3 days. For more information about lifecycle configuration, see PutBucketLifecycleConfiguration and Object Lifecycle Management in Amazon Simple Storage Service Developer Guide. Responses A successful operation returns either the 200 OK or 202 Accepted status code. If the object copy is not previously restored, then Amazon S3 returns 202 Accepted in the response. If the object copy is previously restored, Amazon S3 returns 200 OK in the response. Special Errors Code: RestoreAlreadyInProgress Cause: Object restore is already in progress. (This error does not apply to SELECT type requests.) HTTP Status Code: 409 Conflict SOAP Fault Code Prefix: Client Code: GlacierExpeditedRetrievalNotAvailable Cause: S3 Glacier expedited retrievals are currently not available. Try again later. (Returned if there is insufficient capacity to process the Expedited request. This error applies only to Expedited retrievals and not to S3 Standard or Bulk retrievals.) HTTP Status Code: 503 SOAP Fault Code Prefix: N/A Related Resources PutBucketLifecycleConfiguration GetBucketNotificationConfiguration SQL Reference for Amazon S3 Select and S3 Glacier Select in the Amazon Simple Storage Service Developer Guide"},{"ref":"AWS.S3.html#select_object_content/5","title":"AWS.S3.select_object_content/5","type":"function","doc":"This operation filters the contents of an Amazon S3 object based on a simple structured query language (SQL) statement. In the request, along with the SQL expression, you must also specify a data serialization format (JSON, CSV, or Apache Parquet) of the object. Amazon S3 uses this format to parse object data into records, and returns only records that match the specified SQL expression. You must also specify the data serialization format for the response. This action is not supported by Amazon S3 on Outposts. For more information about Amazon S3 Select, see Selecting Content from Objects in the Amazon Simple Storage Service Developer Guide. For more information about using SQL with Amazon S3 Select, see SQL Reference for Amazon S3 Select and S3 Glacier Select in the Amazon Simple Storage Service Developer Guide. Permissions You must have s3:GetObject permission for this operation.Amazon S3 Select does not support anonymous access. For more information about permissions, see Specifying Permissions in a Policy in the Amazon Simple Storage Service Developer Guide. Object Data Formats You can use Amazon S3 Select to query objects that have the following format properties: CSV, JSON, and Parquet - Objects must be in CSV, JSON, or Parquet format. UTF-8 - UTF-8 is the only encoding type Amazon S3 Select supports. GZIP or BZIP2 - CSV and JSON files can be compressed using GZIP or BZIP2. GZIP and BZIP2 are the only compression formats that Amazon S3 Select supports for CSV and JSON files. Amazon S3 Select supports columnar compression for Parquet using GZIP or Snappy. Amazon S3 Select does not support whole-object compression for Parquet objects. Server-side encryption - Amazon S3 Select supports querying objects that are protected with server-side encryption. For objects that are encrypted with customer-provided encryption keys (SSE-C), you must use HTTPS, and you must use the headers that are documented in the GetObject. For more information about SSE-C, see Server-Side Encryption (Using Customer-Provided Encryption Keys) in the Amazon Simple Storage Service Developer Guide. For objects that are encrypted with Amazon S3 managed encryption keys (SSE-S3) and customer master keys (CMKs) stored in AWS Key Management Service (SSE-KMS), server-side encryption is handled transparently, so you don&#39;t need to specify anything. For more information about server-side encryption, including SSE-S3 and SSE-KMS, see Protecting Data Using Server-Side Encryption in the Amazon Simple Storage Service Developer Guide. Working with the Response Body Given the response size is unknown, Amazon S3 Select streams the response as a series of messages and includes a Transfer-Encoding header with chunked as its value in the response. For more information, see Appendix: SelectObjectContent Response . GetObject Support The SelectObjectContent operation does not support the following GetObject functionality. For more information, see GetObject. * Range: Although you can specify a scan range for an Amazon S3 Select request (see SelectObjectContentRequest - ScanRange in the request parameters), you cannot specify the range of bytes of an object to return. GLACIER, DEEP_ARCHIVE and REDUCED_REDUNDANCY storage classes: You cannot specify the GLACIER, DEEP_ARCHIVE, or REDUCED_REDUNDANCY storage classes. For more information, about storage classes see Storage Classes in the Amazon Simple Storage Service Developer Guide. Special Errors For a list of special errors for this operation, see List of SELECT Object Content Error Codes Related Resources GetObject * GetBucketLifecycleConfiguration * PutBucketLifecycleConfiguration"},{"ref":"AWS.S3.html#upload_part/5","title":"AWS.S3.upload_part/5","type":"function","doc":"Uploads a part in a multipart upload. In this operation, you provide part data in your request. However, you have an option to specify your existing Amazon S3 object as a data source for the part you are uploading. To upload a part from an existing object, you use the UploadPartCopy operation. You must initiate a multipart upload (see CreateMultipartUpload) before you can upload any part. In response to your initiate request, Amazon S3 returns an upload ID, a unique identifier, that you must include in your upload part request. Part numbers can be any number from 1 to 10,000, inclusive. A part number uniquely identifies a part and also defines its position within the object being created. If you upload a new part using the same part number that was used with a previous part, the previously uploaded part is overwritten. Each part must be at least 5 MB in size, except the last part. There is no size limit on the last part of your multipart upload. To ensure that data is not corrupted when traversing the network, specify the Content-MD5 header in the upload part request. Amazon S3 checks the part data against the provided MD5 value. If they do not match, Amazon S3 returns an error. If the upload request is signed with Signature Version 4, then AWS S3 uses the x-amz-content-sha256 header as a checksum instead of Content-MD5. For more information see Authenticating Requests: Using the Authorization Header (AWS Signature Version 4). Note: After you initiate multipart upload and upload one or more parts, you must either complete or abort multipart upload in order to stop getting charged for storage of the uploaded parts. Only after you either complete or abort multipart upload, Amazon S3 frees up the parts storage and stops charging you for the parts storage. For more information on multipart uploads, go to Multipart Upload Overview in the Amazon Simple Storage Service Developer Guide . For information on the permissions required to use the multipart upload API, go to Multipart Upload API and Permissions in the Amazon Simple Storage Service Developer Guide. You can optionally request server-side encryption where Amazon S3 encrypts your data as it writes it to disks in its data centers and decrypts it for you when you access it. You have the option of providing your own encryption key, or you can use the AWS managed encryption keys. If you choose to provide your own encryption key, the request headers you provide in the request must match the headers you used in the request to initiate the upload by using CreateMultipartUpload. For more information, go to Using Server-Side Encryption in the Amazon Simple Storage Service Developer Guide. Server-side encryption is supported by the S3 Multipart Upload actions. Unless you are using a customer-provided encryption key, you don&#39;t need to specify the encryption parameters in each UploadPart request. Instead, you only need to specify the server-side encryption parameters in the initial Initiate Multipart request. For more information, see CreateMultipartUpload. If you requested server-side encryption using a customer-provided encryption key in your initiate multipart upload request, you must provide identical encryption information in each part upload using the following headers. x-amz-server-side-encryption-customer-algorithm x-amz-server-side-encryption-customer-key x-amz-server-side-encryption-customer-key-MD5 Special Errors Code: NoSuchUpload Cause: The specified multipart upload does not exist. The upload ID might be invalid, or the multipart upload might have been aborted or completed. HTTP Status Code: 404 Not Found * SOAP Fault Code Prefix: Client Related Resources * CreateMultipartUpload CompleteMultipartUpload AbortMultipartUpload ListParts * ListMultipartUploads"},{"ref":"AWS.S3.html#upload_part_copy/5","title":"AWS.S3.upload_part_copy/5","type":"function","doc":"Uploads a part by copying data from an existing object as data source. You specify the data source by adding the request header x-amz-copy-source in your request and a byte range by adding the request header x-amz-copy-source-range in your request. The minimum allowable part size for a multipart upload is 5 MB. For more information about multipart upload limits, go to Quick Facts in the Amazon Simple Storage Service Developer Guide. Instead of using an existing object as part data, you might use the UploadPart operation and provide data in your request. You must initiate a multipart upload before you can upload any part. In response to your initiate request. Amazon S3 returns a unique identifier, the upload ID, that you must include in your upload part request. For more information about using the UploadPartCopy operation, see the following: For conceptual information about multipart uploads, see Uploading Objects Using Multipart Upload in the Amazon Simple Storage Service Developer Guide. For information about permissions required to use the multipart upload API, see Multipart Upload API and Permissions in the Amazon Simple Storage Service Developer Guide. For information about copying objects using a single atomic operation vs. the multipart upload, see Operations on Objects in the Amazon Simple Storage Service Developer Guide. For information about using server-side encryption with customer-provided encryption keys with the UploadPartCopy operation, see CopyObject and UploadPart. Note the following additional considerations about the request headers x-amz-copy-source-if-match, x-amz-copy-source-if-none-match, x-amz-copy-source-if-unmodified-since, and x-amz-copy-source-if-modified-since: Consideration 1 - If both of the x-amz-copy-source-if-match and x-amz-copy-source-if-unmodified-since headers are present in the request as follows: x-amz-copy-source-if-match condition evaluates to true, and; x-amz-copy-source-if-unmodified-since condition evaluates to false; Amazon S3 returns 200 OK and copies the data. Consideration 2 - If both of the x-amz-copy-source-if-none-match and x-amz-copy-source-if-modified-since headers are present in the request as follows: x-amz-copy-source-if-none-match condition evaluates to false, and; x-amz-copy-source-if-modified-since condition evaluates to true; Amazon S3 returns 412 Precondition Failed response code. Versioning If your bucket has versioning enabled, you could have multiple versions of the same object. By default, x-amz-copy-source identifies the current version of the object to copy. If the current version is a delete marker and you don&#39;t specify a versionId in the x-amz-copy-source, Amazon S3 returns a 404 error, because the object does not exist. If you specify versionId in the x-amz-copy-source and the versionId is a delete marker, Amazon S3 returns an HTTP 400 error, because you are not allowed to specify a delete marker as a version for the x-amz-copy-source. You can optionally specify a specific version of the source object to copy by adding the versionId subresource as shown in the following example: x-amz-copy-source: /bucket/object?versionId=version id Special Errors Code: NoSuchUpload Cause: The specified multipart upload does not exist. The upload ID might be invalid, or the multipart upload might have been aborted or completed. HTTP Status Code: 404 Not Found Code: InvalidRequest Cause: The specified copy source is not supported as a byte-range copy source. HTTP Status Code: 400 Bad Request Related Resources CreateMultipartUpload UploadPart CompleteMultipartUpload AbortMultipartUpload ListParts * ListMultipartUploads"},{"ref":"AWS.S3Control.html","title":"AWS.S3Control","type":"module","doc":"AWS S3 Control provides access to Amazon S3 control plane operations."},{"ref":"AWS.S3Control.html#create_access_point/4","title":"AWS.S3Control.create_access_point/4","type":"function","doc":"Creates an access point and associates it with the specified bucket. For more information, see Managing Data Access with Amazon S3 Access Points in the Amazon Simple Storage Service Developer Guide. Using this action with Amazon S3 on Outposts This action: Requires a virtual private cloud (VPC) configuration as S3 on Outposts only supports VPC style access points. Does not support ACL on S3 on Outposts buckets. Does not support Public Access on S3 on Outposts buckets. Does not support object lock for S3 on Outposts buckets. For more information, see Using Amazon S3 on Outposts in the Amazon Simple Storage Service Developer Guide . All Amazon S3 on Outposts REST API requests for this action require an additional parameter of outpost-id to be passed with the request and an S3 on Outposts endpoint hostname prefix instead of s3-control. For an example of the request syntax for Amazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the outpost-id derived using the access point ARN, see the Example section below. The following actions are related to CreateAccessPoint: GetAccessPoint DeleteAccessPoint * ListAccessPoints"},{"ref":"AWS.S3Control.html#create_bucket/4","title":"AWS.S3Control.create_bucket/4","type":"function","doc":"This API operation creates an Amazon S3 on Outposts bucket. To create an S3 bucket, see Create Bucket in the Amazon Simple Storage Service API. Creates a new Outposts bucket. By creating the bucket, you become the bucket owner. To create an Outposts bucket, you must have S3 on Outposts. For more information, see Using Amazon S3 on Outposts in Amazon Simple Storage Service Developer Guide. Not every string is an acceptable bucket name. For information on bucket naming restrictions, see Working with Amazon S3 Buckets. S3 on Outposts buckets do not support ACLs. Instead, configure access point policies to manage access to buckets. Public access. Object Lock Bucket Location constraint For an example of the request syntax for Amazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and outpost-id in your API request, see the Example section below. The following actions are related to CreateBucket for Amazon S3 on Outposts: PutObject * GetBucket DeleteBucket CreateAccessPoint * PutAccessPointPolicy"},{"ref":"AWS.S3Control.html#create_job/3","title":"AWS.S3Control.create_job/3","type":"function","doc":"S3 Batch Operations performs large-scale Batch Operations on Amazon S3 objects. Batch Operations can run a single operation or action on lists of Amazon S3 objects that you specify. For more information, see S3 Batch Operations in the Amazon Simple Storage Service Developer Guide. This operation creates a S3 Batch Operations job. Related actions include: DescribeJob ListJobs UpdateJobPriority UpdateJobStatus"},{"ref":"AWS.S3Control.html#delete_access_point/4","title":"AWS.S3Control.delete_access_point/4","type":"function","doc":"Deletes the specified access point. All Amazon S3 on Outposts REST API requests for this action require an additional parameter of outpost-id to be passed with the request and an S3 on Outposts endpoint hostname prefix instead of s3-control. For an example of the request syntax for Amazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the outpost-id derived using the access point ARN, see the ARN, see the Example section below. The following actions are related to DeleteAccessPoint: CreateAccessPoint GetAccessPoint * ListAccessPoints"},{"ref":"AWS.S3Control.html#delete_access_point_policy/4","title":"AWS.S3Control.delete_access_point_policy/4","type":"function","doc":"Deletes the access point policy for the specified access point. All Amazon S3 on Outposts REST API requests for this action require an additional parameter of outpost-id to be passed with the request and an S3 on Outposts endpoint hostname prefix instead of s3-control. For an example of the request syntax for Amazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the outpost-id derived using the access point ARN, see the Example section below. The following actions are related to DeleteAccessPointPolicy: PutAccessPointPolicy GetAccessPointPolicy"},{"ref":"AWS.S3Control.html#delete_bucket/4","title":"AWS.S3Control.delete_bucket/4","type":"function","doc":"This API operation deletes an Amazon S3 on Outposts bucket. To delete an S3 bucket, see DeleteBucket in the Amazon Simple Storage Service API. Deletes the Amazon S3 on Outposts bucket. All objects (including all object versions and delete markers) in the bucket must be deleted before the bucket itself can be deleted. For more information, see Using Amazon S3 on Outposts in Amazon Simple Storage Service Developer Guide. All Amazon S3 on Outposts REST API requests for this action require an additional parameter of outpost-id to be passed with the request and an S3 on Outposts endpoint hostname prefix instead of s3-control. For an example of the request syntax for Amazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the outpost-id derived using the access point ARN, see the Example section below. Related Resources CreateBucket GetBucket * DeleteObject"},{"ref":"AWS.S3Control.html#delete_bucket_lifecycle_configuration/4","title":"AWS.S3Control.delete_bucket_lifecycle_configuration/4","type":"function","doc":"This API action deletes an Amazon S3 on Outposts bucket&#39;s lifecycle configuration. To delete an S3 bucket&#39;s lifecycle configuration, see DeleteBucketLifecycle in the Amazon Simple Storage Service API. Deletes the lifecycle configuration from the specified Outposts bucket. Amazon S3 on Outposts removes all the lifecycle configuration rules in the lifecycle subresource associated with the bucket. Your objects never expire, and Amazon S3 on Outposts no longer automatically deletes any objects on the basis of rules contained in the deleted lifecycle configuration. For more information, see Using Amazon S3 on Outposts in Amazon Simple Storage Service Developer Guide. To use this operation, you must have permission to perform the s3outposts:DeleteLifecycleConfiguration action. By default, the bucket owner has this permission and the Outposts bucket owner can grant this permission to others. All Amazon S3 on Outposts REST API requests for this action require an additional parameter of outpost-id to be passed with the request and an S3 on Outposts endpoint hostname prefix instead of s3-control. For an example of the request syntax for Amazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the outpost-id derived using the access point ARN, see the Example section below. For more information about object expiration, see Elements to Describe Lifecycle Actions. Related actions include: PutBucketLifecycleConfiguration GetBucketLifecycleConfiguration"},{"ref":"AWS.S3Control.html#delete_bucket_policy/4","title":"AWS.S3Control.delete_bucket_policy/4","type":"function","doc":"This API operation deletes an Amazon S3 on Outposts bucket policy. To delete an S3 bucket policy, see DeleteBucketPolicy in the Amazon Simple Storage Service API. This implementation of the DELETE operation uses the policy subresource to delete the policy of a specified Amazon S3 on Outposts bucket. If you are using an identity other than the root user of the AWS account that owns the bucket, the calling identity must have the s3outposts:DeleteBucketPolicy permissions on the specified Outposts bucket and belong to the bucket owner&#39;s account to use this operation. For more information, see Using Amazon S3 on Outposts in Amazon Simple Storage Service Developer Guide. If you don&#39;t have DeleteBucketPolicy permissions, Amazon S3 returns a 403 Access Denied error. If you have the correct permissions, but you&#39;re not using an identity that belongs to the bucket owner&#39;s account, Amazon S3 returns a 405 Method Not Allowed error. As a security precaution, the root user of the AWS account that owns a bucket can always use this operation, even if the policy explicitly denies the root user the ability to perform this action. For more information about bucket policies, see Using Bucket Policies and User Policies. All Amazon S3 on Outposts REST API requests for this action require an additional parameter of outpost-id to be passed with the request and an S3 on Outposts endpoint hostname prefix instead of s3-control. For an example of the request syntax for Amazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the outpost-id derived using the access point ARN, see the Example section below. The following actions are related to DeleteBucketPolicy: GetBucketPolicy PutBucketPolicy"},{"ref":"AWS.S3Control.html#delete_bucket_tagging/4","title":"AWS.S3Control.delete_bucket_tagging/4","type":"function","doc":"This API operation deletes an Amazon S3 on Outposts bucket&#39;s tags. To delete an S3 bucket tags, see DeleteBucketTagging in the Amazon Simple Storage Service API. Deletes the tags from the Outposts bucket. For more information, see Using Amazon S3 on Outposts in Amazon Simple Storage Service Developer Guide. To use this operation, you must have permission to perform the PutBucketTagging action. By default, the bucket owner has this permission and can grant this permission to others. All Amazon S3 on Outposts REST API requests for this action require an additional parameter of outpost-id to be passed with the request and an S3 on Outposts endpoint hostname prefix instead of s3-control. For an example of the request syntax for Amazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the outpost-id derived using the access point ARN, see the Example section below. The following actions are related to DeleteBucketTagging: GetBucketTagging PutBucketTagging"},{"ref":"AWS.S3Control.html#delete_job_tagging/4","title":"AWS.S3Control.delete_job_tagging/4","type":"function","doc":"Removes the entire tag set from the specified S3 Batch Operations job. To use this operation, you must have permission to perform the s3:DeleteJobTagging action. For more information, see Controlling access and labeling jobs using tags in the Amazon Simple Storage Service Developer Guide. Related actions include: CreateJob GetJobTagging * PutJobTagging"},{"ref":"AWS.S3Control.html#delete_public_access_block/3","title":"AWS.S3Control.delete_public_access_block/3","type":"function","doc":"Removes the PublicAccessBlock configuration for an AWS account. For more information, see Using Amazon S3 block public access. Related actions include: GetPublicAccessBlock PutPublicAccessBlock"},{"ref":"AWS.S3Control.html#describe_job/4","title":"AWS.S3Control.describe_job/4","type":"function","doc":"Retrieves the configuration parameters and status for a Batch Operations job. For more information, see S3 Batch Operations in the Amazon Simple Storage Service Developer Guide. Related actions include: CreateJob ListJobs UpdateJobPriority UpdateJobStatus"},{"ref":"AWS.S3Control.html#get_access_point/4","title":"AWS.S3Control.get_access_point/4","type":"function","doc":"Returns configuration information about the specified access point. All Amazon S3 on Outposts REST API requests for this action require an additional parameter of outpost-id to be passed with the request and an S3 on Outposts endpoint hostname prefix instead of s3-control. For an example of the request syntax for Amazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the outpost-id derived using the access point ARN, see the Example section below. The following actions are related to GetAccessPoint: CreateAccessPoint DeleteAccessPoint * ListAccessPoints"},{"ref":"AWS.S3Control.html#get_access_point_policy/4","title":"AWS.S3Control.get_access_point_policy/4","type":"function","doc":"Returns the access point policy associated with the specified access point. The following actions are related to GetAccessPointPolicy: PutAccessPointPolicy DeleteAccessPointPolicy"},{"ref":"AWS.S3Control.html#get_access_point_policy_status/4","title":"AWS.S3Control.get_access_point_policy_status/4","type":"function","doc":"Indicates whether the specified access point currently has a policy that allows public access. For more information about public access through access points, see Managing Data Access with Amazon S3 Access Points in the Amazon Simple Storage Service Developer Guide."},{"ref":"AWS.S3Control.html#get_bucket/4","title":"AWS.S3Control.get_bucket/4","type":"function","doc":"Gets an Amazon S3 on Outposts bucket. For more information, see Using Amazon S3 on Outposts in the Amazon Simple Storage Service Developer Guide. The following actions are related to GetBucket for Amazon S3 on Outposts: PutObject * CreateBucket * DeleteBucket"},{"ref":"AWS.S3Control.html#get_bucket_lifecycle_configuration/4","title":"AWS.S3Control.get_bucket_lifecycle_configuration/4","type":"function","doc":"This API operation gets an Amazon S3 on Outposts bucket&#39;s lifecycle configuration. To get an S3 bucket&#39;s lifecycle configuration, see GetBucketLifecycleConfiguration in the Amazon Simple Storage Service API. Returns the lifecycle configuration information set on the Outposts bucket. For more information, see Using Amazon S3 on Outposts and for information about lifecycle configuration, see Object Lifecycle Management in Amazon Simple Storage Service Developer Guide. To use this operation, you must have permission to perform the s3outposts:GetLifecycleConfiguration action. The Outposts bucket owner has this permission, by default. The bucket owner can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources. All Amazon S3 on Outposts REST API requests for this action require an additional parameter of outpost-id to be passed with the request and an S3 on Outposts endpoint hostname prefix instead of s3-control. For an example of the request syntax for Amazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the outpost-id derived using the access point ARN, see the Example section below. GetBucketLifecycleConfiguration has the following special error: Error code: NoSuchLifecycleConfiguration Description: The lifecycle configuration does not exist. HTTP Status Code: 404 Not Found SOAP Fault Code Prefix: Client The following actions are related to GetBucketLifecycleConfiguration: PutBucketLifecycleConfiguration DeleteBucketLifecycleConfiguration"},{"ref":"AWS.S3Control.html#get_bucket_policy/4","title":"AWS.S3Control.get_bucket_policy/4","type":"function","doc":"This API action gets a bucket policy for an Amazon S3 on Outposts bucket. To get a policy for an S3 bucket, see GetBucketPolicy in the Amazon Simple Storage Service API. Returns the policy of a specified Outposts bucket. For more information, see Using Amazon S3 on Outposts in the Amazon Simple Storage Service Developer Guide. If you are using an identity other than the root user of the AWS account that owns the bucket, the calling identity must have the GetBucketPolicy permissions on the specified bucket and belong to the bucket owner&#39;s account in order to use this operation. If you don&#39;t have s3outposts:GetBucketPolicy permissions, Amazon S3 returns a 403 Access Denied error. If you have the correct permissions, but you&#39;re not using an identity that belongs to the bucket owner&#39;s account, Amazon S3 returns a 405 Method Not Allowed error. As a security precaution, the root user of the AWS account that owns a bucket can always use this operation, even if the policy explicitly denies the root user the ability to perform this action. For more information about bucket policies, see Using Bucket Policies and User Policies. All Amazon S3 on Outposts REST API requests for this action require an additional parameter of outpost-id to be passed with the request and an S3 on Outposts endpoint hostname prefix instead of s3-control. For an example of the request syntax for Amazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the outpost-id derived using the access point ARN, see the Example section below. The following actions are related to GetBucketPolicy: GetObject * PutBucketPolicy * DeleteBucketPolicy"},{"ref":"AWS.S3Control.html#get_bucket_tagging/4","title":"AWS.S3Control.get_bucket_tagging/4","type":"function","doc":"This API operation gets an Amazon S3 on Outposts bucket&#39;s tags. To get an S3 bucket tags, see GetBucketTagging in the Amazon Simple Storage Service API. Returns the tag set associated with the Outposts bucket. For more information, see Using Amazon S3 on Outposts in the Amazon Simple Storage Service Developer Guide. To use this operation, you must have permission to perform the GetBucketTagging action. By default, the bucket owner has this permission and can grant this permission to others. GetBucketTagging has the following special error: Error code: NoSuchTagSetError Description: There is no tag set associated with the bucket. All Amazon S3 on Outposts REST API requests for this action require an additional parameter of outpost-id to be passed with the request and an S3 on Outposts endpoint hostname prefix instead of s3-control. For an example of the request syntax for Amazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the outpost-id derived using the access point ARN, see the Example section below. The following actions are related to GetBucketTagging: PutBucketTagging DeleteBucketTagging"},{"ref":"AWS.S3Control.html#get_job_tagging/4","title":"AWS.S3Control.get_job_tagging/4","type":"function","doc":"Returns the tags on an S3 Batch Operations job. To use this operation, you must have permission to perform the s3:GetJobTagging action. For more information, see Controlling access and labeling jobs using tags in the Amazon Simple Storage Service Developer Guide. Related actions include: CreateJob PutJobTagging * DeleteJobTagging"},{"ref":"AWS.S3Control.html#get_public_access_block/3","title":"AWS.S3Control.get_public_access_block/3","type":"function","doc":"Retrieves the PublicAccessBlock configuration for an AWS account. For more information, see Using Amazon S3 block public access. Related actions include: DeletePublicAccessBlock PutPublicAccessBlock"},{"ref":"AWS.S3Control.html#list_access_points/6","title":"AWS.S3Control.list_access_points/6","type":"function","doc":"Returns a list of the access points currently associated with the specified bucket. You can retrieve up to 1000 access points per call. If the specified bucket has more than 1,000 access points (or the number specified in maxResults, whichever is less), the response will include a continuation token that you can use to list the additional access points. All Amazon S3 on Outposts REST API requests for this action require an additional parameter of outpost-id to be passed with the request and an S3 on Outposts endpoint hostname prefix instead of s3-control. For an example of the request syntax for Amazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the outpost-id derived using the access point ARN, see the Example section below. The following actions are related to ListAccessPoints: CreateAccessPoint DeleteAccessPoint * GetAccessPoint"},{"ref":"AWS.S3Control.html#list_jobs/6","title":"AWS.S3Control.list_jobs/6","type":"function","doc":"Lists current S3 Batch Operations jobs and jobs that have ended within the last 30 days for the AWS account making the request. For more information, see S3 Batch Operations in the Amazon Simple Storage Service Developer Guide. Related actions include: CreateJob DescribeJob UpdateJobPriority UpdateJobStatus"},{"ref":"AWS.S3Control.html#list_regional_buckets/6","title":"AWS.S3Control.list_regional_buckets/6","type":"function","doc":"Returns a list of all Outposts buckets in an Outposts that are owned by the authenticated sender of the request. For more information, see Using Amazon S3 on Outposts in the Amazon Simple Storage Service Developer Guide. For an example of the request syntax for Amazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and outpost-id in your API request, see the Example section below."},{"ref":"AWS.S3Control.html#put_access_point_policy/4","title":"AWS.S3Control.put_access_point_policy/4","type":"function","doc":"Associates an access policy with the specified access point. Each access point can have only one policy, so a request made to this API replaces any existing policy associated with the specified access point. All Amazon S3 on Outposts REST API requests for this action require an additional parameter of outpost-id to be passed with the request and an S3 on Outposts endpoint hostname prefix instead of s3-control. For an example of the request syntax for Amazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the outpost-id derived using the access point ARN, see the Example section below. The following actions are related to PutAccessPointPolicy: GetAccessPointPolicy DeleteAccessPointPolicy"},{"ref":"AWS.S3Control.html#put_bucket_lifecycle_configuration/4","title":"AWS.S3Control.put_bucket_lifecycle_configuration/4","type":"function","doc":"This API action puts a lifecycle configuration to an Amazon S3 on Outposts bucket. To put a lifecycle configuration to an S3 bucket, see PutBucketLifecycleConfiguration in the Amazon Simple Storage Service API. Creates a new lifecycle configuration for the Outposts bucket or replaces an existing lifecycle configuration. Outposts buckets can only support a lifecycle that deletes objects after a certain period of time. For more information, see Managing Lifecycle Permissions for Amazon S3 on Outposts. All Amazon S3 on Outposts REST API requests for this action require an additional parameter of outpost-id to be passed with the request and an S3 on Outposts endpoint hostname prefix instead of s3-control. For an example of the request syntax for Amazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the outpost-id derived using the access point ARN, see the Example section below. The following actions are related to PutBucketLifecycleConfiguration: GetBucketLifecycleConfiguration DeleteBucketLifecycleConfiguration"},{"ref":"AWS.S3Control.html#put_bucket_policy/4","title":"AWS.S3Control.put_bucket_policy/4","type":"function","doc":"This API action puts a bucket policy to an Amazon S3 on Outposts bucket. To put a policy on an S3 bucket, see PutBucketPolicy in the Amazon Simple Storage Service API. Applies an Amazon S3 bucket policy to an Outposts bucket. For more information, see Using Amazon S3 on Outposts in the Amazon Simple Storage Service Developer Guide. If you are using an identity other than the root user of the AWS account that owns the Outposts bucket, the calling identity must have the PutBucketPolicy permissions on the specified Outposts bucket and belong to the bucket owner&#39;s account in order to use this operation. If you don&#39;t have PutBucketPolicy permissions, Amazon S3 returns a 403 Access Denied error. If you have the correct permissions, but you&#39;re not using an identity that belongs to the bucket owner&#39;s account, Amazon S3 returns a 405 Method Not Allowed error. As a security precaution, the root user of the AWS account that owns a bucket can always use this operation, even if the policy explicitly denies the root user the ability to perform this action. For more information about bucket policies, see Using Bucket Policies and User Policies. All Amazon S3 on Outposts REST API requests for this action require an additional parameter of outpost-id to be passed with the request and an S3 on Outposts endpoint hostname prefix instead of s3-control. For an example of the request syntax for Amazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the outpost-id derived using the access point ARN, see the Example section below. The following actions are related to PutBucketPolicy: GetBucketPolicy DeleteBucketPolicy"},{"ref":"AWS.S3Control.html#put_bucket_tagging/4","title":"AWS.S3Control.put_bucket_tagging/4","type":"function","doc":"This API action puts tags on an Amazon S3 on Outposts bucket. To put tags on an S3 bucket, see PutBucketTagging in the Amazon Simple Storage Service API. Sets the tags for an Outposts bucket. For more information, see Using Amazon S3 on Outposts in the Amazon Simple Storage Service Developer Guide. Use tags to organize your AWS bill to reflect your own cost structure. To do this, sign up to get your AWS account bill with tag key values included. Then, to see the cost of combined resources, organize your billing information according to resources with the same tag key values. For example, you can tag several resources with a specific application name, and then organize your billing information to see the total cost of that application across several services. For more information, see Cost Allocation and Tagging. Within a bucket, if you add a tag that has the same key as an existing tag, the new value overwrites the old value. For more information, see Using Cost Allocation in Amazon S3 Bucket Tags. To use this operation, you must have permissions to perform the s3outposts:PutBucketTagging action. The Outposts bucket owner has this permission by default and can grant this permission to others. For more information about permissions, see Permissions Related to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources. PutBucketTagging has the following special errors: Error code: InvalidTagError Description: The tag provided was not a valid tag. This error can occur if the tag did not pass input validation. For information about tag restrictions, see User-Defined Tag Restrictions and AWS-Generated Cost Allocation Tag Restrictions. Error code: MalformedXMLError Description: The XML provided does not match the schema. Error code: OperationAbortedError Description: A conflicting conditional operation is currently in progress against this resource. Try again. Error code: InternalError Description: The service was unable to apply the provided tag to the bucket. All Amazon S3 on Outposts REST API requests for this action require an additional parameter of outpost-id to be passed with the request and an S3 on Outposts endpoint hostname prefix instead of s3-control. For an example of the request syntax for Amazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the outpost-id derived using the access point ARN, see the Example section below. The following actions are related to PutBucketTagging: GetBucketTagging DeleteBucketTagging"},{"ref":"AWS.S3Control.html#put_job_tagging/4","title":"AWS.S3Control.put_job_tagging/4","type":"function","doc":"Sets the supplied tag-set on an S3 Batch Operations job. A tag is a key-value pair. You can associate S3 Batch Operations tags with any job by sending a PUT request against the tagging subresource that is associated with the job. To modify the existing tag set, you can either replace the existing tag set entirely, or make changes within the existing tag set by retrieving the existing tag set using GetJobTagging, modify that tag set, and use this API action to replace the tag set with the one you modified. For more information, see Controlling access and labeling jobs using tags in the Amazon Simple Storage Service Developer Guide. If you send this request with an empty tag set, Amazon S3 deletes the existing tag set on the Batch Operations job. If you use this method, you are charged for a Tier 1 Request (PUT). For more information, see Amazon S3 pricing. * For deleting existing tags for your Batch Operations job, a DeleteJobTagging request is preferred because it achieves the same result without incurring charges. A few things to consider about using tags: Amazon S3 limits the maximum number of tags to 50 tags per job. You can associate up to 50 tags with a job as long as they have unique tag keys. A tag key can be up to 128 Unicode characters in length, and tag values can be up to 256 Unicode characters in length. The key and values are case sensitive. For tagging-related restrictions related to characters and encodings, see User-Defined Tag Restrictions in the AWS Billing and Cost Management User Guide. To use this operation, you must have permission to perform the s3:PutJobTagging action. Related actions include: CreatJob GetJobTagging * DeleteJobTagging"},{"ref":"AWS.S3Control.html#put_public_access_block/3","title":"AWS.S3Control.put_public_access_block/3","type":"function","doc":"Creates or modifies the PublicAccessBlock configuration for an AWS account. For more information, see Using Amazon S3 block public access. Related actions include: GetPublicAccessBlock DeletePublicAccessBlock"},{"ref":"AWS.S3Control.html#update_job_priority/4","title":"AWS.S3Control.update_job_priority/4","type":"function","doc":"Updates an existing S3 Batch Operations job&#39;s priority. For more information, see S3 Batch Operations in the Amazon Simple Storage Service Developer Guide. Related actions include: CreateJob ListJobs DescribeJob UpdateJobStatus"},{"ref":"AWS.S3Control.html#update_job_status/4","title":"AWS.S3Control.update_job_status/4","type":"function","doc":"Updates the status for the specified job. Use this operation to confirm that you want to run a job or to cancel an existing job. For more information, see S3 Batch Operations in the Amazon Simple Storage Service Developer Guide. Related actions include: CreateJob ListJobs DescribeJob UpdateJobStatus"},{"ref":"AWS.S3Outposts.html","title":"AWS.S3Outposts","type":"module","doc":"Amazon S3 on Outposts provides access to S3 on Outposts operations."},{"ref":"AWS.S3Outposts.html#create_endpoint/3","title":"AWS.S3Outposts.create_endpoint/3","type":"function","doc":"S3 on Outposts access points simplify managing data access at scale for shared datasets in Amazon S3 on Outposts. S3 on Outposts uses endpoints to connect to Outposts buckets so that you can perform actions within your virtual private cloud (VPC). This action creates an endpoint and associates it with the specified Outpost. Related actions include: DeleteEndpoint ListEndpoints"},{"ref":"AWS.S3Outposts.html#delete_endpoint/3","title":"AWS.S3Outposts.delete_endpoint/3","type":"function","doc":"S3 on Outposts access points simplify managing data access at scale for shared datasets in Amazon S3 on Outposts. S3 on Outposts uses endpoints to connect to Outposts buckets so that you can perform actions within your virtual private cloud (VPC). This action deletes an endpoint. Related actions include: CreateEndpoint ListEndpoints"},{"ref":"AWS.S3Outposts.html#list_endpoints/4","title":"AWS.S3Outposts.list_endpoints/4","type":"function","doc":"S3 on Outposts access points simplify managing data access at scale for shared datasets in Amazon S3 on Outposts. S3 on Outposts uses endpoints to connect to Outposts buckets so that you can perform actions within your virtual private cloud (VPC). This action lists endpoints associated with the Outpost. Related actions include: CreateEndpoint DeleteEndpoint"},{"ref":"AWS.SES.html","title":"AWS.SES","type":"module","doc":"Amazon Simple Email Service This document contains reference information for the Amazon Simple Email Service (Amazon SES) API, version 2010-12-01. This document is best used in conjunction with the Amazon SES Developer Guide. For a list of Amazon SES endpoints to use in service requests, see Regions and Amazon SES in the Amazon SES Developer Guide."},{"ref":"AWS.SES.html#clone_receipt_rule_set/3","title":"AWS.SES.clone_receipt_rule_set/3","type":"function","doc":"Creates a receipt rule set by cloning an existing one. All receipt rules and configurations are copied to the new receipt rule set and are completely independent of the source rule set. For information about setting up rule sets, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#create_configuration_set/3","title":"AWS.SES.create_configuration_set/3","type":"function","doc":"Creates a configuration set. Configuration sets enable you to publish email sending events. For information about using configuration sets, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#create_configuration_set_event_destination/3","title":"AWS.SES.create_configuration_set_event_destination/3","type":"function","doc":"Creates a configuration set event destination. When you create or update an event destination, you must provide one, and only one, destination. The destination can be CloudWatch, Amazon Kinesis Firehose, or Amazon Simple Notification Service (Amazon SNS). An event destination is the AWS service to which Amazon SES publishes the email sending events associated with a configuration set. For information about using configuration sets, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#create_configuration_set_tracking_options/3","title":"AWS.SES.create_configuration_set_tracking_options/3","type":"function","doc":"Creates an association between a configuration set and a custom domain for open and click event tracking. By default, images and links used for tracking open and click events are hosted on domains operated by Amazon SES. You can configure a subdomain of your own to handle these events. For information about using custom domains, see the Amazon SES Developer Guide."},{"ref":"AWS.SES.html#create_custom_verification_email_template/3","title":"AWS.SES.create_custom_verification_email_template/3","type":"function","doc":"Creates a new custom verification email template. For more information about custom verification email templates, see Using Custom Verification Email Templates in the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#create_receipt_filter/3","title":"AWS.SES.create_receipt_filter/3","type":"function","doc":"Creates a new IP address filter. For information about setting up IP address filters, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#create_receipt_rule/3","title":"AWS.SES.create_receipt_rule/3","type":"function","doc":"Creates a receipt rule. For information about setting up receipt rules, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#create_receipt_rule_set/3","title":"AWS.SES.create_receipt_rule_set/3","type":"function","doc":"Creates an empty receipt rule set. For information about setting up receipt rule sets, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#create_template/3","title":"AWS.SES.create_template/3","type":"function","doc":"Creates an email template. Email templates enable you to send personalized email to one or more destinations in a single API operation. For more information, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#delete_configuration_set/3","title":"AWS.SES.delete_configuration_set/3","type":"function","doc":"Deletes a configuration set. Configuration sets enable you to publish email sending events. For information about using configuration sets, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#delete_configuration_set_event_destination/3","title":"AWS.SES.delete_configuration_set_event_destination/3","type":"function","doc":"Deletes a configuration set event destination. Configuration set event destinations are associated with configuration sets, which enable you to publish email sending events. For information about using configuration sets, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#delete_configuration_set_tracking_options/3","title":"AWS.SES.delete_configuration_set_tracking_options/3","type":"function","doc":"Deletes an association between a configuration set and a custom domain for open and click event tracking. By default, images and links used for tracking open and click events are hosted on domains operated by Amazon SES. You can configure a subdomain of your own to handle these events. For information about using custom domains, see the Amazon SES Developer Guide. Deleting this kind of association will result in emails sent using the specified configuration set to capture open and click events using the standard, Amazon SES-operated domains."},{"ref":"AWS.SES.html#delete_custom_verification_email_template/3","title":"AWS.SES.delete_custom_verification_email_template/3","type":"function","doc":"Deletes an existing custom verification email template. For more information about custom verification email templates, see Using Custom Verification Email Templates in the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#delete_identity/3","title":"AWS.SES.delete_identity/3","type":"function","doc":"Deletes the specified identity (an email address or a domain) from the list of verified identities. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#delete_identity_policy/3","title":"AWS.SES.delete_identity_policy/3","type":"function","doc":"Deletes the specified sending authorization policy for the given identity (an email address or a domain). This API returns successfully even if a policy with the specified name does not exist. This API is for the identity owner only. If you have not verified the identity, this API will return an error. Sending authorization is a feature that enables an identity owner to authorize other senders to use its identities. For information about using sending authorization, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#delete_receipt_filter/3","title":"AWS.SES.delete_receipt_filter/3","type":"function","doc":"Deletes the specified IP address filter. For information about managing IP address filters, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#delete_receipt_rule/3","title":"AWS.SES.delete_receipt_rule/3","type":"function","doc":"Deletes the specified receipt rule. For information about managing receipt rules, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#delete_receipt_rule_set/3","title":"AWS.SES.delete_receipt_rule_set/3","type":"function","doc":"Deletes the specified receipt rule set and all of the receipt rules it contains. The currently active rule set cannot be deleted. For information about managing receipt rule sets, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#delete_template/3","title":"AWS.SES.delete_template/3","type":"function","doc":"Deletes an email template. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#delete_verified_email_address/3","title":"AWS.SES.delete_verified_email_address/3","type":"function","doc":"Deprecated. Use the DeleteIdentity operation to delete email addresses and domains."},{"ref":"AWS.SES.html#describe_active_receipt_rule_set/3","title":"AWS.SES.describe_active_receipt_rule_set/3","type":"function","doc":"Returns the metadata and receipt rules for the receipt rule set that is currently active. For information about setting up receipt rule sets, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#describe_configuration_set/3","title":"AWS.SES.describe_configuration_set/3","type":"function","doc":"Returns the details of the specified configuration set. For information about using configuration sets, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#describe_receipt_rule/3","title":"AWS.SES.describe_receipt_rule/3","type":"function","doc":"Returns the details of the specified receipt rule. For information about setting up receipt rules, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#describe_receipt_rule_set/3","title":"AWS.SES.describe_receipt_rule_set/3","type":"function","doc":"Returns the details of the specified receipt rule set. For information about managing receipt rule sets, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#get_account_sending_enabled/3","title":"AWS.SES.get_account_sending_enabled/3","type":"function","doc":"Returns the email sending status of the Amazon SES account for the current region. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#get_custom_verification_email_template/3","title":"AWS.SES.get_custom_verification_email_template/3","type":"function","doc":"Returns the custom email verification template for the template name you specify. For more information about custom verification email templates, see Using Custom Verification Email Templates in the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#get_identity_dkim_attributes/3","title":"AWS.SES.get_identity_dkim_attributes/3","type":"function","doc":"Returns the current status of Easy DKIM signing for an entity. For domain name identities, this operation also returns the DKIM tokens that are required for Easy DKIM signing, and whether Amazon SES has successfully verified that these tokens have been published. This operation takes a list of identities as input and returns the following information for each: Whether Easy DKIM signing is enabled or disabled. A set of DKIM tokens that represent the identity. If the identity is an email address, the tokens represent the domain of that address. Whether Amazon SES has successfully verified the DKIM tokens published in the domain&#39;s DNS. This information is only returned for domain name identities, not for email addresses. This operation is throttled at one request per second and can only get DKIM attributes for up to 100 identities at a time. For more information about creating DNS records using DKIM tokens, go to the Amazon SES Developer Guide."},{"ref":"AWS.SES.html#get_identity_mail_from_domain_attributes/3","title":"AWS.SES.get_identity_mail_from_domain_attributes/3","type":"function","doc":"Returns the custom MAIL FROM attributes for a list of identities (email addresses : domains). This operation is throttled at one request per second and can only get custom MAIL FROM attributes for up to 100 identities at a time."},{"ref":"AWS.SES.html#get_identity_notification_attributes/3","title":"AWS.SES.get_identity_notification_attributes/3","type":"function","doc":"Given a list of verified identities (email addresses and/or domains), returns a structure describing identity notification attributes. This operation is throttled at one request per second and can only get notification attributes for up to 100 identities at a time. For more information about using notifications with Amazon SES, see the Amazon SES Developer Guide."},{"ref":"AWS.SES.html#get_identity_policies/3","title":"AWS.SES.get_identity_policies/3","type":"function","doc":"Returns the requested sending authorization policies for the given identity (an email address or a domain). The policies are returned as a map of policy names to policy contents. You can retrieve a maximum of 20 policies at a time. This API is for the identity owner only. If you have not verified the identity, this API will return an error. Sending authorization is a feature that enables an identity owner to authorize other senders to use its identities. For information about using sending authorization, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#get_identity_verification_attributes/3","title":"AWS.SES.get_identity_verification_attributes/3","type":"function","doc":"Given a list of identities (email addresses and/or domains), returns the verification status and (for domain identities) the verification token for each identity. The verification status of an email address is &quot;Pending&quot; until the email address owner clicks the link within the verification email that Amazon SES sent to that address. If the email address owner clicks the link within 24 hours, the verification status of the email address changes to &quot;Success&quot;. If the link is not clicked within 24 hours, the verification status changes to &quot;Failed.&quot; In that case, if you still want to verify the email address, you must restart the verification process from the beginning. For domain identities, the domain&#39;s verification status is &quot;Pending&quot; as Amazon SES searches for the required TXT record in the DNS settings of the domain. When Amazon SES detects the record, the domain&#39;s verification status changes to &quot;Success&quot;. If Amazon SES is unable to detect the record within 72 hours, the domain&#39;s verification status changes to &quot;Failed.&quot; In that case, if you still want to verify the domain, you must restart the verification process from the beginning. This operation is throttled at one request per second and can only get verification attributes for up to 100 identities at a time."},{"ref":"AWS.SES.html#get_send_quota/3","title":"AWS.SES.get_send_quota/3","type":"function","doc":"Provides the sending limits for the Amazon SES account. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#get_send_statistics/3","title":"AWS.SES.get_send_statistics/3","type":"function","doc":"Provides sending statistics for the current AWS Region. The result is a list of data points, representing the last two weeks of sending activity. Each data point in the list contains statistics for a 15-minute period of time. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#get_template/3","title":"AWS.SES.get_template/3","type":"function","doc":"Displays the template object (which includes the Subject line, HTML part and text part) for the template you specify. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#list_configuration_sets/3","title":"AWS.SES.list_configuration_sets/3","type":"function","doc":"Provides a list of the configuration sets associated with your Amazon SES account in the current AWS Region. For information about using configuration sets, see Monitoring Your Amazon SES Sending Activity in the Amazon SES Developer Guide. You can execute this operation no more than once per second. This operation will return up to 1,000 configuration sets each time it is run. If your Amazon SES account has more than 1,000 configuration sets, this operation will also return a NextToken element. You can then execute the ListConfigurationSets operation again, passing the NextToken parameter and the value of the NextToken element to retrieve additional results."},{"ref":"AWS.SES.html#list_custom_verification_email_templates/3","title":"AWS.SES.list_custom_verification_email_templates/3","type":"function","doc":"Lists the existing custom verification email templates for your account in the current AWS Region. For more information about custom verification email templates, see Using Custom Verification Email Templates in the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#list_identities/3","title":"AWS.SES.list_identities/3","type":"function","doc":"Returns a list containing all of the identities (email addresses and domains) for your AWS account in the current AWS Region, regardless of verification status. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#list_identity_policies/3","title":"AWS.SES.list_identity_policies/3","type":"function","doc":"Returns a list of sending authorization policies that are attached to the given identity (an email address or a domain). This API returns only a list. If you want the actual policy content, you can use GetIdentityPolicies. This API is for the identity owner only. If you have not verified the identity, this API will return an error. Sending authorization is a feature that enables an identity owner to authorize other senders to use its identities. For information about using sending authorization, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#list_receipt_filters/3","title":"AWS.SES.list_receipt_filters/3","type":"function","doc":"Lists the IP address filters associated with your AWS account in the current AWS Region. For information about managing IP address filters, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#list_receipt_rule_sets/3","title":"AWS.SES.list_receipt_rule_sets/3","type":"function","doc":"Lists the receipt rule sets that exist under your AWS account in the current AWS Region. If there are additional receipt rule sets to be retrieved, you will receive a NextToken that you can provide to the next call to ListReceiptRuleSets to retrieve the additional entries. For information about managing receipt rule sets, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#list_templates/3","title":"AWS.SES.list_templates/3","type":"function","doc":"Lists the email templates present in your Amazon SES account in the current AWS Region. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#list_verified_email_addresses/3","title":"AWS.SES.list_verified_email_addresses/3","type":"function","doc":"Deprecated. Use the ListIdentities operation to list the email addresses and domains associated with your account."},{"ref":"AWS.SES.html#put_configuration_set_delivery_options/3","title":"AWS.SES.put_configuration_set_delivery_options/3","type":"function","doc":"Adds or updates the delivery options for a configuration set."},{"ref":"AWS.SES.html#put_identity_policy/3","title":"AWS.SES.put_identity_policy/3","type":"function","doc":"Adds or updates a sending authorization policy for the specified identity (an email address or a domain). This API is for the identity owner only. If you have not verified the identity, this API will return an error. Sending authorization is a feature that enables an identity owner to authorize other senders to use its identities. For information about using sending authorization, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#reorder_receipt_rule_set/3","title":"AWS.SES.reorder_receipt_rule_set/3","type":"function","doc":"Reorders the receipt rules within a receipt rule set. All of the rules in the rule set must be represented in this request. That is, this API will return an error if the reorder request doesn&#39;t explicitly position all of the rules. For information about managing receipt rule sets, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#send_bounce/3","title":"AWS.SES.send_bounce/3","type":"function","doc":"Generates and sends a bounce message to the sender of an email you received through Amazon SES. You can only use this API on an email up to 24 hours after you receive it. You cannot use this API to send generic bounces for mail that was not received by Amazon SES. For information about receiving email through Amazon SES, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#send_bulk_templated_email/3","title":"AWS.SES.send_bulk_templated_email/3","type":"function","doc":"Composes an email message to multiple destinations. The message body is created using an email template. In order to send email using the SendBulkTemplatedEmail operation, your call to the API must meet the following requirements: The call must refer to an existing email template. You can create email templates using the CreateTemplate operation. The message must be sent from a verified email address or domain. If your account is still in the Amazon SES sandbox, you may only send to verified addresses or domains, or to email addresses associated with the Amazon SES Mailbox Simulator. For more information, see Verifying Email Addresses and Domains in the Amazon SES Developer Guide. The maximum message size is 10 MB. Each Destination parameter must include at least one recipient email address. The recipient address can be a To: address, a CC: address, or a BCC: address. If a recipient email address is invalid (that is, it is not in the format UserName@[SubDomain.]Domain.TopLevelDomain), the entire message will be rejected, even if the message contains other recipients that are valid. The message may not include more than 50 recipients, across the To:, CC: and BCC: fields. If you need to send an email message to a larger audience, you can divide your recipient list into groups of 50 or fewer, and then call the SendBulkTemplatedEmail operation several times to send the message to each group. The number of destinations you can contact in a single call to the API may be limited by your account&#39;s maximum sending rate."},{"ref":"AWS.SES.html#send_custom_verification_email/3","title":"AWS.SES.send_custom_verification_email/3","type":"function","doc":"Adds an email address to the list of identities for your Amazon SES account in the current AWS Region and attempts to verify it. As a result of executing this operation, a customized verification email is sent to the specified address. To use this operation, you must first create a custom verification email template. For more information about creating and using custom verification email templates, see Using Custom Verification Email Templates in the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#send_email/3","title":"AWS.SES.send_email/3","type":"function","doc":"Composes an email message and immediately queues it for sending. In order to send email using the SendEmail operation, your message must meet the following requirements: The message must be sent from a verified email address or domain. If you attempt to send email using a non-verified address or domain, the operation will result in an &quot;Email address not verified&quot; error. If your account is still in the Amazon SES sandbox, you may only send to verified addresses or domains, or to email addresses associated with the Amazon SES Mailbox Simulator. For more information, see Verifying Email Addresses and Domains in the Amazon SES Developer Guide. The maximum message size is 10 MB. The message must include at least one recipient email address. The recipient address can be a To: address, a CC: address, or a BCC: address. If a recipient email address is invalid (that is, it is not in the format UserName@[SubDomain.]Domain.TopLevelDomain), the entire message will be rejected, even if the message contains other recipients that are valid. The message may not include more than 50 recipients, across the To:, CC: and BCC: fields. If you need to send an email message to a larger audience, you can divide your recipient list into groups of 50 or fewer, and then call the SendEmail operation several times to send the message to each group. For every message that you send, the total number of recipients (including each recipient in the To:, CC: and BCC: fields) is counted against the maximum number of emails you can send in a 24-hour period (your sending quota). For more information about sending quotas in Amazon SES, see Managing Your Amazon SES Sending Limits in the Amazon SES Developer Guide."},{"ref":"AWS.SES.html#send_raw_email/3","title":"AWS.SES.send_raw_email/3","type":"function","doc":"Composes an email message and immediately queues it for sending. This operation is more flexible than the SendEmail API operation. When you use the SendRawEmail operation, you can specify the headers of the message as well as its content. This flexibility is useful, for example, when you want to send a multipart MIME email (such a message that contains both a text and an HTML version). You can also use this operation to send messages that include attachments. The SendRawEmail operation has the following requirements: You can only send email from verified email addresses or domains. If you try to send email from an address that isn&#39;t verified, the operation results in an &quot;Email address not verified&quot; error. If your account is still in the Amazon SES sandbox, you can only send email to other verified addresses in your account, or to addresses that are associated with the Amazon SES mailbox simulator. The maximum message size, including attachments, is 10 MB. Each message has to include at least one recipient address. A recipient address includes any address on the To:, CC:, or BCC: lines. If you send a single message to more than one recipient address, and one of the recipient addresses isn&#39;t in a valid format (that is, it&#39;s not in the format UserName@[SubDomain.]Domain.TopLevelDomain), Amazon SES rejects the entire message, even if the other addresses are valid. Each message can include up to 50 recipient addresses across the To:, CC:, or BCC: lines. If you need to send a single message to more than 50 recipients, you have to split the list of recipient addresses into groups of less than 50 recipients, and send separate messages to each group. Amazon SES allows you to specify 8-bit Content-Transfer-Encoding for MIME message parts. However, if Amazon SES has to modify the contents of your message (for example, if you use open and click tracking), 8-bit content isn&#39;t preserved. For this reason, we highly recommend that you encode all content that isn&#39;t 7-bit ASCII. For more information, see MIME Encoding in the Amazon SES Developer Guide. Additionally, keep the following considerations in mind when using the SendRawEmail operation: Although you can customize the message headers when using the SendRawEmail operation, Amazon SES will automatically apply its own Message-ID and Date headers; if you passed these headers when creating the message, they will be overwritten by the values that Amazon SES provides. If you are using sending authorization to send on behalf of another user, SendRawEmail enables you to specify the cross-account identity for the email&#39;s Source, From, and Return-Path parameters in one of two ways: you can pass optional parameters SourceArn, FromArn, and/or ReturnPathArn to the API, or you can include the following X-headers in the header of your raw email: X-SES-SOURCE-ARN X-SES-FROM-ARN X-SES-RETURN-PATH-ARN Don&#39;t include these X-headers in the DKIM signature. Amazon SES removes these before it sends the email. If you only specify the SourceIdentityArn parameter, Amazon SES sets the From and Return-Path addresses to the same identity that you specified. For more information about sending authorization, see the Using Sending Authorization with Amazon SES in the Amazon SES Developer Guide. For every message that you send, the total number of recipients (including each recipient in the To:, CC: and BCC: fields) is counted against the maximum number of emails you can send in a 24-hour period (your sending quota). For more information about sending quotas in Amazon SES, see Managing Your Amazon SES Sending Limits in the Amazon SES Developer Guide."},{"ref":"AWS.SES.html#send_templated_email/3","title":"AWS.SES.send_templated_email/3","type":"function","doc":"Composes an email message using an email template and immediately queues it for sending. In order to send email using the SendTemplatedEmail operation, your call to the API must meet the following requirements: The call must refer to an existing email template. You can create email templates using the CreateTemplate operation. The message must be sent from a verified email address or domain. If your account is still in the Amazon SES sandbox, you may only send to verified addresses or domains, or to email addresses associated with the Amazon SES Mailbox Simulator. For more information, see Verifying Email Addresses and Domains in the Amazon SES Developer Guide. The maximum message size is 10 MB. Calls to the SendTemplatedEmail operation may only include one Destination parameter. A destination is a set of recipients who will receive the same version of the email. The Destination parameter can include up to 50 recipients, across the To:, CC: and BCC: fields. The Destination parameter must include at least one recipient email address. The recipient address can be a To: address, a CC: address, or a BCC: address. If a recipient email address is invalid (that is, it is not in the format UserName@[SubDomain.]Domain.TopLevelDomain), the entire message will be rejected, even if the message contains other recipients that are valid. If your call to the SendTemplatedEmail operation includes all of the required parameters, Amazon SES accepts it and returns a Message ID. However, if Amazon SES can&#39;t render the email because the template contains errors, it doesn&#39;t send the email. Additionally, because it already accepted the message, Amazon SES doesn&#39;t return a message stating that it was unable to send the email. For these reasons, we highly recommend that you set up Amazon SES to send you notifications when Rendering Failure events occur. For more information, see Sending Personalized Email Using the Amazon SES API in the Amazon Simple Email Service Developer Guide."},{"ref":"AWS.SES.html#set_active_receipt_rule_set/3","title":"AWS.SES.set_active_receipt_rule_set/3","type":"function","doc":"Sets the specified receipt rule set as the active receipt rule set. To disable your email-receiving through Amazon SES completely, you can call this API with RuleSetName set to null. For information about managing receipt rule sets, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#set_identity_dkim_enabled/3","title":"AWS.SES.set_identity_dkim_enabled/3","type":"function","doc":"Enables or disables Easy DKIM signing of email sent from an identity. If Easy DKIM signing is enabled for a domain, then Amazon SES uses DKIM to sign all email that it sends from addresses on that domain. If Easy DKIM signing is enabled for an email address, then Amazon SES uses DKIM to sign all email it sends from that address. For email addresses (for example, user@example.com), you can only enable DKIM signing if the corresponding domain (in this case, example.com) has been set up to use Easy DKIM. You can enable DKIM signing for an identity at any time after you start the verification process for the identity, even if the verification process isn&#39;t complete. You can execute this operation no more than once per second. For more information about Easy DKIM signing, go to the Amazon SES Developer Guide."},{"ref":"AWS.SES.html#set_identity_feedback_forwarding_enabled/3","title":"AWS.SES.set_identity_feedback_forwarding_enabled/3","type":"function","doc":"Given an identity (an email address or a domain), enables or disables whether Amazon SES forwards bounce and complaint notifications as email. Feedback forwarding can only be disabled when Amazon Simple Notification Service (Amazon SNS) topics are specified for both bounces and complaints. Feedback forwarding does not apply to delivery notifications. Delivery notifications are only available through Amazon SNS. You can execute this operation no more than once per second. For more information about using notifications with Amazon SES, see the Amazon SES Developer Guide."},{"ref":"AWS.SES.html#set_identity_headers_in_notifications_enabled/3","title":"AWS.SES.set_identity_headers_in_notifications_enabled/3","type":"function","doc":"Given an identity (an email address or a domain), sets whether Amazon SES includes the original email headers in the Amazon Simple Notification Service (Amazon SNS) notifications of a specified type. You can execute this operation no more than once per second. For more information about using notifications with Amazon SES, see the Amazon SES Developer Guide."},{"ref":"AWS.SES.html#set_identity_mail_from_domain/3","title":"AWS.SES.set_identity_mail_from_domain/3","type":"function","doc":"Enables or disables the custom MAIL FROM domain setup for a verified identity (an email address or a domain). To send emails using the specified MAIL FROM domain, you must add an MX record to your MAIL FROM domain&#39;s DNS settings. If you want your emails to pass Sender Policy Framework (SPF) checks, you must also add or update an SPF record. For more information, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#set_identity_notification_topic/3","title":"AWS.SES.set_identity_notification_topic/3","type":"function","doc":"Sets an Amazon Simple Notification Service (Amazon SNS) topic to use when delivering notifications. When you use this operation, you specify a verified identity, such as an email address or domain. When you send an email that uses the chosen identity in the Source field, Amazon SES sends notifications to the topic you specified. You can send bounce, complaint, or delivery notifications (or any combination of the three) to the Amazon SNS topic that you specify. You can execute this operation no more than once per second. For more information about feedback notification, see the Amazon SES Developer Guide."},{"ref":"AWS.SES.html#set_receipt_rule_position/3","title":"AWS.SES.set_receipt_rule_position/3","type":"function","doc":"Sets the position of the specified receipt rule in the receipt rule set. For information about managing receipt rules, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#test_render_template/3","title":"AWS.SES.test_render_template/3","type":"function","doc":"Creates a preview of the MIME content of an email when provided with a template and a set of replacement data. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#update_account_sending_enabled/3","title":"AWS.SES.update_account_sending_enabled/3","type":"function","doc":"Enables or disables email sending across your entire Amazon SES account in the current AWS Region. You can use this operation in conjunction with Amazon CloudWatch alarms to temporarily pause email sending across your Amazon SES account in a given AWS Region when reputation metrics (such as your bounce or complaint rates) reach certain thresholds. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#update_configuration_set_event_destination/3","title":"AWS.SES.update_configuration_set_event_destination/3","type":"function","doc":"Updates the event destination of a configuration set. Event destinations are associated with configuration sets, which enable you to publish email sending events to Amazon CloudWatch, Amazon Kinesis Firehose, or Amazon Simple Notification Service (Amazon SNS). For information about using configuration sets, see Monitoring Your Amazon SES Sending Activity in the Amazon SES Developer Guide. When you create or update an event destination, you must provide one, and only one, destination. The destination can be Amazon CloudWatch, Amazon Kinesis Firehose, or Amazon Simple Notification Service (Amazon SNS). You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#update_configuration_set_reputation_metrics_enabled/3","title":"AWS.SES.update_configuration_set_reputation_metrics_enabled/3","type":"function","doc":"Enables or disables the publishing of reputation metrics for emails sent using a specific configuration set in a given AWS Region. Reputation metrics include bounce and complaint rates. These metrics are published to Amazon CloudWatch. By using CloudWatch, you can create alarms when bounce or complaint rates exceed certain thresholds. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#update_configuration_set_sending_enabled/3","title":"AWS.SES.update_configuration_set_sending_enabled/3","type":"function","doc":"Enables or disables email sending for messages sent using a specific configuration set in a given AWS Region. You can use this operation in conjunction with Amazon CloudWatch alarms to temporarily pause email sending for a configuration set when the reputation metrics for that configuration set (such as your bounce on complaint rate) exceed certain thresholds. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#update_configuration_set_tracking_options/3","title":"AWS.SES.update_configuration_set_tracking_options/3","type":"function","doc":"Modifies an association between a configuration set and a custom domain for open and click event tracking. By default, images and links used for tracking open and click events are hosted on domains operated by Amazon SES. You can configure a subdomain of your own to handle these events. For information about using custom domains, see the Amazon SES Developer Guide."},{"ref":"AWS.SES.html#update_custom_verification_email_template/3","title":"AWS.SES.update_custom_verification_email_template/3","type":"function","doc":"Updates an existing custom verification email template. For more information about custom verification email templates, see Using Custom Verification Email Templates in the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#update_receipt_rule/3","title":"AWS.SES.update_receipt_rule/3","type":"function","doc":"Updates a receipt rule. For information about managing receipt rules, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#update_template/3","title":"AWS.SES.update_template/3","type":"function","doc":"Updates an email template. Email templates enable you to send personalized email to one or more destinations in a single API operation. For more information, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#verify_domain_dkim/3","title":"AWS.SES.verify_domain_dkim/3","type":"function","doc":"Returns a set of DKIM tokens for a domain identity. When you execute the VerifyDomainDkim operation, the domain that you specify is added to the list of identities that are associated with your account. This is true even if you haven&#39;t already associated the domain with your account by using the VerifyDomainIdentity operation. However, you can&#39;t send email from the domain until you either successfully verify it or you successfully set up DKIM for it. You use the tokens that are generated by this operation to create CNAME records. When Amazon SES detects that you&#39;ve added these records to the DNS configuration for a domain, you can start sending email from that domain. You can start sending email even if you haven&#39;t added the TXT record provided by the VerifyDomainIdentity operation to the DNS configuration for your domain. All email that you send from the domain is authenticated using DKIM. To create the CNAME records for DKIM authentication, use the following values: Name: token._domainkey.example.com Type: CNAME Value: token.dkim.amazonses.com In the preceding example, replace token with one of the tokens that are generated when you execute this operation. Replace example.com with your domain. Repeat this process for each token that&#39;s generated by this operation. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#verify_domain_identity/3","title":"AWS.SES.verify_domain_identity/3","type":"function","doc":"Adds a domain to the list of identities for your Amazon SES account in the current AWS Region and attempts to verify it. For more information about verifying domains, see Verifying Email Addresses and Domains in the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SES.html#verify_email_address/3","title":"AWS.SES.verify_email_address/3","type":"function","doc":"Deprecated. Use the VerifyEmailIdentity operation to verify a new email address."},{"ref":"AWS.SES.html#verify_email_identity/3","title":"AWS.SES.verify_email_identity/3","type":"function","doc":"Adds an email address to the list of identities for your Amazon SES account in the current AWS region and attempts to verify it. As a result of executing this operation, a verification email is sent to the specified address. You can execute this operation no more than once per second."},{"ref":"AWS.SESv2.html","title":"AWS.SESv2","type":"module","doc":"Amazon SES API v2 Welcome to the Amazon SES API v2 Reference. This guide provides information about the Amazon SES API v2, including supported operations, data types, parameters, and schemas. Amazon SES is an AWS service that you can use to send email messages to your customers. If you&#39;re new to Amazon SES API v2, you might find it helpful to also review the Amazon Simple Email Service Developer Guide. The Amazon SES Developer Guide provides information and code samples that demonstrate how to use Amazon SES API v2 features programmatically. The Amazon SES API v2 is available in several AWS Regions and it provides an endpoint for each of these Regions. For a list of all the Regions and endpoints where the API is currently available, see AWS Service Endpoints in the Amazon Web Services General Reference. To learn more about AWS Regions, see Managing AWS Regions in the Amazon Web Services General Reference. In each Region, AWS maintains multiple Availability Zones. These Availability Zones are physically isolated from each other, but are united by private, low-latency, high-throughput, and highly redundant network connections. These Availability Zones enable us to provide very high levels of availability and redundancy, while also minimizing latency. To learn more about the number of Availability Zones that are available in each Region, see AWS Global Infrastructure."},{"ref":"AWS.SESv2.html#create_configuration_set/3","title":"AWS.SESv2.create_configuration_set/3","type":"function","doc":"Create a configuration set. Configuration sets are groups of rules that you can apply to the emails that you send. You apply a configuration set to an email by specifying the name of the configuration set when you call the Amazon SES API v2. When you apply a configuration set to an email, all of the rules in that configuration set are applied to the email."},{"ref":"AWS.SESv2.html#create_configuration_set_event_destination/4","title":"AWS.SESv2.create_configuration_set_event_destination/4","type":"function","doc":"Create an event destination. Events include message sends, deliveries, opens, clicks, bounces, and complaints. Event destinations are places that you can send information about these events to. For example, you can send event data to Amazon SNS to receive notifications when you receive bounces or complaints, or you can use Amazon Kinesis Data Firehose to stream data to Amazon S3 for long-term storage. A single configuration set can include more than one event destination."},{"ref":"AWS.SESv2.html#create_custom_verification_email_template/3","title":"AWS.SESv2.create_custom_verification_email_template/3","type":"function","doc":"Creates a new custom verification email template. For more information about custom verification email templates, see Using Custom Verification Email Templates in the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SESv2.html#create_dedicated_ip_pool/3","title":"AWS.SESv2.create_dedicated_ip_pool/3","type":"function","doc":"Create a new pool of dedicated IP addresses. A pool can include one or more dedicated IP addresses that are associated with your AWS account. You can associate a pool with a configuration set. When you send an email that uses that configuration set, the message is sent from one of the addresses in the associated pool."},{"ref":"AWS.SESv2.html#create_deliverability_test_report/3","title":"AWS.SESv2.create_deliverability_test_report/3","type":"function","doc":"Create a new predictive inbox placement test. Predictive inbox placement tests can help you predict how your messages will be handled by various email providers around the world. When you perform a predictive inbox placement test, you provide a sample message that contains the content that you plan to send to your customers. Amazon SES then sends that message to special email addresses spread across several major email providers. After about 24 hours, the test is complete, and you can use the GetDeliverabilityTestReport operation to view the results of the test."},{"ref":"AWS.SESv2.html#create_email_identity/3","title":"AWS.SESv2.create_email_identity/3","type":"function","doc":"Starts the process of verifying an email identity. An identity is an email address or domain that you use when you send email. Before you can use an identity to send email, you first have to verify it. By verifying an identity, you demonstrate that you&#39;re the owner of the identity, and that you&#39;ve given Amazon SES API v2 permission to send email from the identity. When you verify an email address, Amazon SES sends an email to the address. Your email address is verified as soon as you follow the link in the verification email. When you verify a domain without specifying the DkimSigningAttributes object, this operation provides a set of DKIM tokens. You can convert these tokens into CNAME records, which you then add to the DNS configuration for your domain. Your domain is verified when Amazon SES detects these records in the DNS configuration for your domain. This verification method is known as Easy DKIM. Alternatively, you can perform the verification process by providing your own public-private key pair. This verification method is known as Bring Your Own DKIM (BYODKIM). To use BYODKIM, your call to the CreateEmailIdentity operation has to include the DkimSigningAttributes object. When you specify this object, you provide a selector (a component of the DNS record name that identifies the public key that you want to use for DKIM authentication) and a private key."},{"ref":"AWS.SESv2.html#create_email_identity_policy/5","title":"AWS.SESv2.create_email_identity_policy/5","type":"function","doc":"Creates the specified sending authorization policy for the given identity (an email address or a domain). This API is for the identity owner only. If you have not verified the identity, this API will return an error. Sending authorization is a feature that enables an identity owner to authorize other senders to use its identities. For information about using sending authorization, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SESv2.html#create_email_template/3","title":"AWS.SESv2.create_email_template/3","type":"function","doc":"Creates an email template. Email templates enable you to send personalized email to one or more destinations in a single API operation. For more information, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SESv2.html#create_import_job/3","title":"AWS.SESv2.create_import_job/3","type":"function","doc":"Creates an import job for a data destination."},{"ref":"AWS.SESv2.html#delete_configuration_set/4","title":"AWS.SESv2.delete_configuration_set/4","type":"function","doc":"Delete an existing configuration set. Configuration sets are groups of rules that you can apply to the emails you send. You apply a configuration set to an email by including a reference to the configuration set in the headers of the email. When you apply a configuration set to an email, all of the rules in that configuration set are applied to the email."},{"ref":"AWS.SESv2.html#delete_configuration_set_event_destination/5","title":"AWS.SESv2.delete_configuration_set_event_destination/5","type":"function","doc":"Delete an event destination. Events include message sends, deliveries, opens, clicks, bounces, and complaints. Event destinations are places that you can send information about these events to. For example, you can send event data to Amazon SNS to receive notifications when you receive bounces or complaints, or you can use Amazon Kinesis Data Firehose to stream data to Amazon S3 for long-term storage."},{"ref":"AWS.SESv2.html#delete_custom_verification_email_template/4","title":"AWS.SESv2.delete_custom_verification_email_template/4","type":"function","doc":"Deletes an existing custom verification email template. For more information about custom verification email templates, see Using Custom Verification Email Templates in the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SESv2.html#delete_dedicated_ip_pool/4","title":"AWS.SESv2.delete_dedicated_ip_pool/4","type":"function","doc":"Delete a dedicated IP pool."},{"ref":"AWS.SESv2.html#delete_email_identity/4","title":"AWS.SESv2.delete_email_identity/4","type":"function","doc":"Deletes an email identity. An identity can be either an email address or a domain name."},{"ref":"AWS.SESv2.html#delete_email_identity_policy/5","title":"AWS.SESv2.delete_email_identity_policy/5","type":"function","doc":"Deletes the specified sending authorization policy for the given identity (an email address or a domain). This API returns successfully even if a policy with the specified name does not exist. This API is for the identity owner only. If you have not verified the identity, this API will return an error. Sending authorization is a feature that enables an identity owner to authorize other senders to use its identities. For information about using sending authorization, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SESv2.html#delete_email_template/4","title":"AWS.SESv2.delete_email_template/4","type":"function","doc":"Deletes an email template. You can execute this operation no more than once per second."},{"ref":"AWS.SESv2.html#delete_suppressed_destination/4","title":"AWS.SESv2.delete_suppressed_destination/4","type":"function","doc":"Removes an email address from the suppression list for your account."},{"ref":"AWS.SESv2.html#get_account/2","title":"AWS.SESv2.get_account/2","type":"function","doc":"Obtain information about the email-sending status and capabilities of your Amazon SES account in the current AWS Region."},{"ref":"AWS.SESv2.html#get_blacklist_reports/3","title":"AWS.SESv2.get_blacklist_reports/3","type":"function","doc":"Retrieve a list of the blacklists that your dedicated IP addresses appear on."},{"ref":"AWS.SESv2.html#get_configuration_set/3","title":"AWS.SESv2.get_configuration_set/3","type":"function","doc":"Get information about an existing configuration set, including the dedicated IP pool that it&#39;s associated with, whether or not it&#39;s enabled for sending email, and more. Configuration sets are groups of rules that you can apply to the emails you send. You apply a configuration set to an email by including a reference to the configuration set in the headers of the email. When you apply a configuration set to an email, all of the rules in that configuration set are applied to the email."},{"ref":"AWS.SESv2.html#get_configuration_set_event_destinations/3","title":"AWS.SESv2.get_configuration_set_event_destinations/3","type":"function","doc":"Retrieve a list of event destinations that are associated with a configuration set. Events include message sends, deliveries, opens, clicks, bounces, and complaints. Event destinations are places that you can send information about these events to. For example, you can send event data to Amazon SNS to receive notifications when you receive bounces or complaints, or you can use Amazon Kinesis Data Firehose to stream data to Amazon S3 for long-term storage."},{"ref":"AWS.SESv2.html#get_custom_verification_email_template/3","title":"AWS.SESv2.get_custom_verification_email_template/3","type":"function","doc":"Returns the custom email verification template for the template name you specify. For more information about custom verification email templates, see Using Custom Verification Email Templates in the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SESv2.html#get_dedicated_ip/3","title":"AWS.SESv2.get_dedicated_ip/3","type":"function","doc":"Get information about a dedicated IP address, including the name of the dedicated IP pool that it&#39;s associated with, as well information about the automatic warm-up process for the address."},{"ref":"AWS.SESv2.html#get_dedicated_ips/5","title":"AWS.SESv2.get_dedicated_ips/5","type":"function","doc":"List the dedicated IP addresses that are associated with your AWS account."},{"ref":"AWS.SESv2.html#get_deliverability_dashboard_options/2","title":"AWS.SESv2.get_deliverability_dashboard_options/2","type":"function","doc":"Retrieve information about the status of the Deliverability dashboard for your account. When the Deliverability dashboard is enabled, you gain access to reputation, deliverability, and other metrics for the domains that you use to send email. You also gain the ability to perform predictive inbox placement tests. When you use the Deliverability dashboard, you pay a monthly subscription charge, in addition to any other fees that you accrue by using Amazon SES and other AWS services. For more information about the features and cost of a Deliverability dashboard subscription, see Amazon SES Pricing."},{"ref":"AWS.SESv2.html#get_deliverability_test_report/3","title":"AWS.SESv2.get_deliverability_test_report/3","type":"function","doc":"Retrieve the results of a predictive inbox placement test."},{"ref":"AWS.SESv2.html#get_domain_deliverability_campaign/3","title":"AWS.SESv2.get_domain_deliverability_campaign/3","type":"function","doc":"Retrieve all the deliverability data for a specific campaign. This data is available for a campaign only if the campaign sent email by using a domain that the Deliverability dashboard is enabled for."},{"ref":"AWS.SESv2.html#get_domain_statistics_report/5","title":"AWS.SESv2.get_domain_statistics_report/5","type":"function","doc":"Retrieve inbox placement and engagement rates for the domains that you use to send email."},{"ref":"AWS.SESv2.html#get_email_identity/3","title":"AWS.SESv2.get_email_identity/3","type":"function","doc":"Provides information about a specific identity, including the identity&#39;s verification status, sending authorization policies, its DKIM authentication status, and its custom Mail-From settings."},{"ref":"AWS.SESv2.html#get_email_identity_policies/3","title":"AWS.SESv2.get_email_identity_policies/3","type":"function","doc":"Returns the requested sending authorization policies for the given identity (an email address or a domain). The policies are returned as a map of policy names to policy contents. You can retrieve a maximum of 20 policies at a time. This API is for the identity owner only. If you have not verified the identity, this API will return an error. Sending authorization is a feature that enables an identity owner to authorize other senders to use its identities. For information about using sending authorization, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SESv2.html#get_email_template/3","title":"AWS.SESv2.get_email_template/3","type":"function","doc":"Displays the template object (which includes the subject line, HTML part and text part) for the template you specify. You can execute this operation no more than once per second."},{"ref":"AWS.SESv2.html#get_import_job/3","title":"AWS.SESv2.get_import_job/3","type":"function","doc":"Provides information about an import job."},{"ref":"AWS.SESv2.html#get_suppressed_destination/3","title":"AWS.SESv2.get_suppressed_destination/3","type":"function","doc":"Retrieves information about a specific email address that&#39;s on the suppression list for your account."},{"ref":"AWS.SESv2.html#list_configuration_sets/4","title":"AWS.SESv2.list_configuration_sets/4","type":"function","doc":"List all of the configuration sets associated with your account in the current region. Configuration sets are groups of rules that you can apply to the emails you send. You apply a configuration set to an email by including a reference to the configuration set in the headers of the email. When you apply a configuration set to an email, all of the rules in that configuration set are applied to the email."},{"ref":"AWS.SESv2.html#list_custom_verification_email_templates/4","title":"AWS.SESv2.list_custom_verification_email_templates/4","type":"function","doc":"Lists the existing custom verification email templates for your account in the current AWS Region. For more information about custom verification email templates, see Using Custom Verification Email Templates in the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SESv2.html#list_dedicated_ip_pools/4","title":"AWS.SESv2.list_dedicated_ip_pools/4","type":"function","doc":"List all of the dedicated IP pools that exist in your AWS account in the current Region."},{"ref":"AWS.SESv2.html#list_deliverability_test_reports/4","title":"AWS.SESv2.list_deliverability_test_reports/4","type":"function","doc":"Show a list of the predictive inbox placement tests that you&#39;ve performed, regardless of their statuses. For predictive inbox placement tests that are complete, you can use the GetDeliverabilityTestReport operation to view the results."},{"ref":"AWS.SESv2.html#list_domain_deliverability_campaigns/7","title":"AWS.SESv2.list_domain_deliverability_campaigns/7","type":"function","doc":"Retrieve deliverability data for all the campaigns that used a specific domain to send email during a specified time range. This data is available for a domain only if you enabled the Deliverability dashboard for the domain."},{"ref":"AWS.SESv2.html#list_email_identities/4","title":"AWS.SESv2.list_email_identities/4","type":"function","doc":"Returns a list of all of the email identities that are associated with your AWS account. An identity can be either an email address or a domain. This operation returns identities that are verified as well as those that aren&#39;t. This operation returns identities that are associated with Amazon SES and Amazon Pinpoint."},{"ref":"AWS.SESv2.html#list_email_templates/4","title":"AWS.SESv2.list_email_templates/4","type":"function","doc":"Lists the email templates present in your Amazon SES account in the current AWS Region. You can execute this operation no more than once per second."},{"ref":"AWS.SESv2.html#list_import_jobs/4","title":"AWS.SESv2.list_import_jobs/4","type":"function","doc":"Lists all of the import jobs."},{"ref":"AWS.SESv2.html#list_suppressed_destinations/7","title":"AWS.SESv2.list_suppressed_destinations/7","type":"function","doc":"Retrieves a list of email addresses that are on the suppression list for your account."},{"ref":"AWS.SESv2.html#list_tags_for_resource/3","title":"AWS.SESv2.list_tags_for_resource/3","type":"function","doc":"Retrieve a list of the tags (keys and values) that are associated with a specified resource. Atagis a label that you optionally define and associate with a resource. Each tag consists of a requiredtag keyand an optional associatedtag value. A tag key is a general label that acts as a category for more specific tag values. A tag value acts as a descriptor within a tag key."},{"ref":"AWS.SESv2.html#put_account_dedicated_ip_warmup_attributes/3","title":"AWS.SESv2.put_account_dedicated_ip_warmup_attributes/3","type":"function","doc":"Enable or disable the automatic warm-up feature for dedicated IP addresses."},{"ref":"AWS.SESv2.html#put_account_details/3","title":"AWS.SESv2.put_account_details/3","type":"function","doc":"Update your Amazon SES account details."},{"ref":"AWS.SESv2.html#put_account_sending_attributes/3","title":"AWS.SESv2.put_account_sending_attributes/3","type":"function","doc":"Enable or disable the ability of your account to send email."},{"ref":"AWS.SESv2.html#put_account_suppression_attributes/3","title":"AWS.SESv2.put_account_suppression_attributes/3","type":"function","doc":"Change the settings for the account-level suppression list."},{"ref":"AWS.SESv2.html#put_configuration_set_delivery_options/4","title":"AWS.SESv2.put_configuration_set_delivery_options/4","type":"function","doc":"Associate a configuration set with a dedicated IP pool. You can use dedicated IP pools to create groups of dedicated IP addresses for sending specific types of email."},{"ref":"AWS.SESv2.html#put_configuration_set_reputation_options/4","title":"AWS.SESv2.put_configuration_set_reputation_options/4","type":"function","doc":"Enable or disable collection of reputation metrics for emails that you send using a particular configuration set in a specific AWS Region."},{"ref":"AWS.SESv2.html#put_configuration_set_sending_options/4","title":"AWS.SESv2.put_configuration_set_sending_options/4","type":"function","doc":"Enable or disable email sending for messages that use a particular configuration set in a specific AWS Region."},{"ref":"AWS.SESv2.html#put_configuration_set_suppression_options/4","title":"AWS.SESv2.put_configuration_set_suppression_options/4","type":"function","doc":"Specify the account suppression list preferences for a configuration set."},{"ref":"AWS.SESv2.html#put_configuration_set_tracking_options/4","title":"AWS.SESv2.put_configuration_set_tracking_options/4","type":"function","doc":"Specify a custom domain to use for open and click tracking elements in email that you send."},{"ref":"AWS.SESv2.html#put_dedicated_ip_in_pool/4","title":"AWS.SESv2.put_dedicated_ip_in_pool/4","type":"function","doc":"Move a dedicated IP address to an existing dedicated IP pool. The dedicated IP address that you specify must already exist, and must be associated with your AWS account. The dedicated IP pool you specify must already exist. You can create a new pool by using the CreateDedicatedIpPool operation."},{"ref":"AWS.SESv2.html#put_dedicated_ip_warmup_attributes/4","title":"AWS.SESv2.put_dedicated_ip_warmup_attributes/4","type":"function","doc":""},{"ref":"AWS.SESv2.html#put_deliverability_dashboard_option/3","title":"AWS.SESv2.put_deliverability_dashboard_option/3","type":"function","doc":"Enable or disable the Deliverability dashboard. When you enable the Deliverability dashboard, you gain access to reputation, deliverability, and other metrics for the domains that you use to send email. You also gain the ability to perform predictive inbox placement tests. When you use the Deliverability dashboard, you pay a monthly subscription charge, in addition to any other fees that you accrue by using Amazon SES and other AWS services. For more information about the features and cost of a Deliverability dashboard subscription, see Amazon SES Pricing."},{"ref":"AWS.SESv2.html#put_email_identity_dkim_attributes/4","title":"AWS.SESv2.put_email_identity_dkim_attributes/4","type":"function","doc":"Used to enable or disable DKIM authentication for an email identity."},{"ref":"AWS.SESv2.html#put_email_identity_dkim_signing_attributes/4","title":"AWS.SESv2.put_email_identity_dkim_signing_attributes/4","type":"function","doc":"Used to configure or change the DKIM authentication settings for an email domain identity. You can use this operation to do any of the following: Update the signing attributes for an identity that uses Bring Your Own DKIM (BYODKIM). Change from using no DKIM authentication to using Easy DKIM. Change from using no DKIM authentication to using BYODKIM. Change from using Easy DKIM to using BYODKIM. Change from using BYODKIM to using Easy DKIM."},{"ref":"AWS.SESv2.html#put_email_identity_feedback_attributes/4","title":"AWS.SESv2.put_email_identity_feedback_attributes/4","type":"function","doc":"Used to enable or disable feedback forwarding for an identity. This setting determines what happens when an identity is used to send an email that results in a bounce or complaint event. If the value is true, you receive email notifications when bounce or complaint events occur. These notifications are sent to the address that you specified in the Return-Path header of the original email. You&#39;re required to have a method of tracking bounces and complaints. If you haven&#39;t set up another mechanism for receiving bounce or complaint notifications (for example, by setting up an event destination), you receive an email notification when these events occur (even if this setting is disabled)."},{"ref":"AWS.SESv2.html#put_email_identity_mail_from_attributes/4","title":"AWS.SESv2.put_email_identity_mail_from_attributes/4","type":"function","doc":"Used to enable or disable the custom Mail-From domain configuration for an email identity."},{"ref":"AWS.SESv2.html#put_suppressed_destination/3","title":"AWS.SESv2.put_suppressed_destination/3","type":"function","doc":"Adds an email address to the suppression list for your account."},{"ref":"AWS.SESv2.html#send_bulk_email/3","title":"AWS.SESv2.send_bulk_email/3","type":"function","doc":"Composes an email message to multiple destinations."},{"ref":"AWS.SESv2.html#send_custom_verification_email/3","title":"AWS.SESv2.send_custom_verification_email/3","type":"function","doc":"Adds an email address to the list of identities for your Amazon SES account in the current AWS Region and attempts to verify it. As a result of executing this operation, a customized verification email is sent to the specified address. To use this operation, you must first create a custom verification email template. For more information about creating and using custom verification email templates, see Using Custom Verification Email Templates in the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SESv2.html#send_email/3","title":"AWS.SESv2.send_email/3","type":"function","doc":"Sends an email message. You can use the Amazon SES API v2 to send two types of messages: Simple  A standard email message. When you create this type of message, you specify the sender, the recipient, and the message body, and Amazon SES assembles the message for you. Raw  A raw, MIME-formatted email message. When you send this type of email, you have to specify all of the message headers, as well as the message body. You can use this message type to send messages that contain attachments. The message that you specify has to be a valid MIME message. Templated  A message that contains personalization tags. When you send this type of email, Amazon SES API v2 automatically replaces the tags with values that you specify."},{"ref":"AWS.SESv2.html#tag_resource/3","title":"AWS.SESv2.tag_resource/3","type":"function","doc":"Add one or more tags (keys and values) to a specified resource. A tagis a label that you optionally define and associate with a resource. Tags can help you categorize and manage resources in different ways, such as by purpose, owner, environment, or other criteria. A resource can have as many as 50 tags. Each tag consists of a requiredtag keyand an associatedtag value, both of which you define. A tag key is a general label that acts as a category for more specific tag values. A tag value acts as a descriptor within a tag key."},{"ref":"AWS.SESv2.html#test_render_email_template/4","title":"AWS.SESv2.test_render_email_template/4","type":"function","doc":"Creates a preview of the MIME content of an email when provided with a template and a set of replacement data. You can execute this operation no more than once per second."},{"ref":"AWS.SESv2.html#untag_resource/3","title":"AWS.SESv2.untag_resource/3","type":"function","doc":"Remove one or more tags (keys and values) from a specified resource."},{"ref":"AWS.SESv2.html#update_configuration_set_event_destination/5","title":"AWS.SESv2.update_configuration_set_event_destination/5","type":"function","doc":"Update the configuration of an event destination for a configuration set. Events include message sends, deliveries, opens, clicks, bounces, and complaints. Event destinations are places that you can send information about these events to. For example, you can send event data to Amazon SNS to receive notifications when you receive bounces or complaints, or you can use Amazon Kinesis Data Firehose to stream data to Amazon S3 for long-term storage."},{"ref":"AWS.SESv2.html#update_custom_verification_email_template/4","title":"AWS.SESv2.update_custom_verification_email_template/4","type":"function","doc":"Updates an existing custom verification email template. For more information about custom verification email templates, see Using Custom Verification Email Templates in the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SESv2.html#update_email_identity_policy/5","title":"AWS.SESv2.update_email_identity_policy/5","type":"function","doc":"Updates the specified sending authorization policy for the given identity (an email address or a domain). This API returns successfully even if a policy with the specified name does not exist. This API is for the identity owner only. If you have not verified the identity, this API will return an error. Sending authorization is a feature that enables an identity owner to authorize other senders to use its identities. For information about using sending authorization, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SESv2.html#update_email_template/4","title":"AWS.SESv2.update_email_template/4","type":"function","doc":"Updates an email template. Email templates enable you to send personalized email to one or more destinations in a single API operation. For more information, see the Amazon SES Developer Guide. You can execute this operation no more than once per second."},{"ref":"AWS.SFN.html","title":"AWS.SFN","type":"module","doc":"AWS Step Functions AWS Step Functions is a service that lets you coordinate the components of distributed applications and microservices using visual workflows. You can use Step Functions to build applications from individual components, each of which performs a discrete function, or task, allowing you to scale and change applications quickly. Step Functions provides a console that helps visualize the components of your application as a series of steps. Step Functions automatically triggers and tracks each step, and retries steps when there are errors, so your application executes predictably and in the right order every time. Step Functions logs the state of each step, so you can quickly diagnose and debug any issues. Step Functions manages operations and underlying infrastructure to ensure your application is available at any scale. You can run tasks on AWS, your own servers, or any system that has access to AWS. You can access and use Step Functions using the console, the AWS SDKs, or an HTTP API. For more information about Step Functions, see the AWS Step Functions Developer Guide ."},{"ref":"AWS.SFN.html#create_activity/3","title":"AWS.SFN.create_activity/3","type":"function","doc":"Creates an activity. An activity is a task that you write in any programming language and host on any machine that has access to AWS Step Functions. Activities must poll Step Functions using the GetActivityTask API action and respond using SendTask* API actions. This function lets Step Functions know the existence of your activity and returns an identifier for use in a state machine and when polling from the activity. This operation is eventually consistent. The results are best effort and may not reflect very recent updates and changes. CreateActivity is an idempotent API. Subsequent requests wont create a duplicate resource if it was already created. CreateActivity&#39;s idempotency check is based on the activity name. If a following request has different tags values, Step Functions will ignore these differences and treat it as an idempotent request of the previous. In this case, tags will not be updated, even if they are different."},{"ref":"AWS.SFN.html#create_state_machine/3","title":"AWS.SFN.create_state_machine/3","type":"function","doc":"Creates a state machine. A state machine consists of a collection of states that can do work (Task states), determine to which states to transition next (Choice states), stop an execution with an error (Fail states), and so on. State machines are specified using a JSON-based, structured language. For more information, see Amazon States Language in the AWS Step Functions User Guide. This operation is eventually consistent. The results are best effort and may not reflect very recent updates and changes. CreateStateMachine is an idempotent API. Subsequent requests wont create a duplicate resource if it was already created. CreateStateMachine&#39;s idempotency check is based on the state machine name, definition, type, LoggingConfiguration and TracingConfiguration. If a following request has a different roleArn or tags, Step Functions will ignore these differences and treat it as an idempotent request of the previous. In this case, roleArn and tags will not be updated, even if they are different."},{"ref":"AWS.SFN.html#delete_activity/3","title":"AWS.SFN.delete_activity/3","type":"function","doc":"Deletes an activity."},{"ref":"AWS.SFN.html#delete_state_machine/3","title":"AWS.SFN.delete_state_machine/3","type":"function","doc":"Deletes a state machine. This is an asynchronous operation: It sets the state machine&#39;s status to DELETING and begins the deletion process. For EXPRESSstate machines, the deletion will happen eventually (usually less than a minute). Running executions may emit logs after DeleteStateMachine API is called."},{"ref":"AWS.SFN.html#describe_activity/3","title":"AWS.SFN.describe_activity/3","type":"function","doc":"Describes an activity. This operation is eventually consistent. The results are best effort and may not reflect very recent updates and changes."},{"ref":"AWS.SFN.html#describe_execution/3","title":"AWS.SFN.describe_execution/3","type":"function","doc":"Describes an execution. This operation is eventually consistent. The results are best effort and may not reflect very recent updates and changes. This API action is not supported by EXPRESS state machines."},{"ref":"AWS.SFN.html#describe_state_machine/3","title":"AWS.SFN.describe_state_machine/3","type":"function","doc":"Describes a state machine. This operation is eventually consistent. The results are best effort and may not reflect very recent updates and changes."},{"ref":"AWS.SFN.html#describe_state_machine_for_execution/3","title":"AWS.SFN.describe_state_machine_for_execution/3","type":"function","doc":"Describes the state machine associated with a specific execution. This operation is eventually consistent. The results are best effort and may not reflect very recent updates and changes. This API action is not supported by EXPRESS state machines."},{"ref":"AWS.SFN.html#get_activity_task/3","title":"AWS.SFN.get_activity_task/3","type":"function","doc":"Used by workers to retrieve a task (with the specified activity ARN) which has been scheduled for execution by a running state machine. This initiates a long poll, where the service holds the HTTP connection open and responds as soon as a task becomes available (i.e. an execution of a task of this type is needed.) The maximum time the service holds on to the request before responding is 60 seconds. If no task is available within 60 seconds, the poll returns a taskToken with a null string. Workers should set their client side socket timeout to at least 65 seconds (5 seconds higher than the maximum time the service may hold the poll request). Polling with GetActivityTask can cause latency in some implementations. See Avoid Latency When Polling for Activity Tasks in the Step Functions Developer Guide."},{"ref":"AWS.SFN.html#get_execution_history/3","title":"AWS.SFN.get_execution_history/3","type":"function","doc":"Returns the history of the specified execution as a list of events. By default, the results are returned in ascending order of the timeStamp of the events. Use the reverseOrder parameter to get the latest events first. If nextToken is returned, there are more results available. The value of nextToken is a unique pagination token for each page. Make the call again using the returned token to retrieve the next page. Keep all other arguments unchanged. Each pagination token expires after 24 hours. Using an expired pagination token will return an HTTP 400 InvalidToken error. This API action is not supported by EXPRESS state machines."},{"ref":"AWS.SFN.html#list_activities/3","title":"AWS.SFN.list_activities/3","type":"function","doc":"Lists the existing activities. If nextToken is returned, there are more results available. The value of nextToken is a unique pagination token for each page. Make the call again using the returned token to retrieve the next page. Keep all other arguments unchanged. Each pagination token expires after 24 hours. Using an expired pagination token will return an HTTP 400 InvalidToken error. This operation is eventually consistent. The results are best effort and may not reflect very recent updates and changes."},{"ref":"AWS.SFN.html#list_executions/3","title":"AWS.SFN.list_executions/3","type":"function","doc":"Lists the executions of a state machine that meet the filtering criteria. Results are sorted by time, with the most recent execution first. If nextToken is returned, there are more results available. The value of nextToken is a unique pagination token for each page. Make the call again using the returned token to retrieve the next page. Keep all other arguments unchanged. Each pagination token expires after 24 hours. Using an expired pagination token will return an HTTP 400 InvalidToken error. This operation is eventually consistent. The results are best effort and may not reflect very recent updates and changes. This API action is not supported by EXPRESS state machines."},{"ref":"AWS.SFN.html#list_state_machines/3","title":"AWS.SFN.list_state_machines/3","type":"function","doc":"Lists the existing state machines. If nextToken is returned, there are more results available. The value of nextToken is a unique pagination token for each page. Make the call again using the returned token to retrieve the next page. Keep all other arguments unchanged. Each pagination token expires after 24 hours. Using an expired pagination token will return an HTTP 400 InvalidToken error. This operation is eventually consistent. The results are best effort and may not reflect very recent updates and changes."},{"ref":"AWS.SFN.html#list_tags_for_resource/3","title":"AWS.SFN.list_tags_for_resource/3","type":"function","doc":"List tags for a given resource. Tags may only contain Unicode letters, digits, white space, or these symbols: _ . : / = + - @."},{"ref":"AWS.SFN.html#send_task_failure/3","title":"AWS.SFN.send_task_failure/3","type":"function","doc":"Used by activity workers and task states using the callback pattern to report that the task identified by the taskToken failed."},{"ref":"AWS.SFN.html#send_task_heartbeat/3","title":"AWS.SFN.send_task_heartbeat/3","type":"function","doc":"Used by activity workers and task states using the callback pattern to report to Step Functions that the task represented by the specified taskToken is still making progress. This action resets the Heartbeat clock. The Heartbeat threshold is specified in the state machine&#39;s Amazon States Language definition (HeartbeatSeconds). This action does not in itself create an event in the execution history. However, if the task times out, the execution history contains an ActivityTimedOut entry for activities, or a TaskTimedOut entry for for tasks using the job run or callback pattern. The Timeout of a task, defined in the state machine&#39;s Amazon States Language definition, is its maximum allowed duration, regardless of the number of SendTaskHeartbeat requests received. Use HeartbeatSeconds to configure the timeout interval for heartbeats."},{"ref":"AWS.SFN.html#send_task_success/3","title":"AWS.SFN.send_task_success/3","type":"function","doc":"Used by activity workers and task states using the callback pattern to report that the task identified by the taskToken completed successfully."},{"ref":"AWS.SFN.html#start_execution/3","title":"AWS.SFN.start_execution/3","type":"function","doc":"Starts a state machine execution. StartExecution is idempotent. If StartExecution is called with the same name and input as a running execution, the call will succeed and return the same response as the original request. If the execution is closed or if the input is different, it will return a 400 ExecutionAlreadyExists error. Names can be reused after 90 days."},{"ref":"AWS.SFN.html#stop_execution/3","title":"AWS.SFN.stop_execution/3","type":"function","doc":"Stops an execution. This API action is not supported by EXPRESS state machines."},{"ref":"AWS.SFN.html#tag_resource/3","title":"AWS.SFN.tag_resource/3","type":"function","doc":"Add a tag to a Step Functions resource. An array of key-value pairs. For more information, see Using Cost Allocation Tags in the AWS Billing and Cost Management User Guide, and Controlling Access Using IAM Tags. Tags may only contain Unicode letters, digits, white space, or these symbols: _ . : / = + - @."},{"ref":"AWS.SFN.html#untag_resource/3","title":"AWS.SFN.untag_resource/3","type":"function","doc":"Remove a tag from a Step Functions resource"},{"ref":"AWS.SFN.html#update_state_machine/3","title":"AWS.SFN.update_state_machine/3","type":"function","doc":"Updates an existing state machine by modifying its definition, roleArn, or loggingConfiguration. Running executions will continue to use the previous definition and roleArn. You must include at least one of definition or roleArn or you will receive a MissingRequiredParameter error. All StartExecution calls within a few seconds will use the updated definition and roleArn. Executions started immediately after calling UpdateStateMachine may use the previous state machine definition and roleArn."},{"ref":"AWS.SMS.html","title":"AWS.SMS","type":"module","doc":"AWS Server Migration Service AWS Server Migration Service (AWS SMS) makes it easier and faster for you to migrate your on-premises workloads to AWS. To learn more about AWS SMS, see the following resources: AWS Server Migration Service product page AWS Server Migration Service User Guide"},{"ref":"AWS.SMS.html#create_app/3","title":"AWS.SMS.create_app/3","type":"function","doc":"Creates an application. An application consists of one or more server groups. Each server group contain one or more servers."},{"ref":"AWS.SMS.html#create_replication_job/3","title":"AWS.SMS.create_replication_job/3","type":"function","doc":"Creates a replication job. The replication job schedules periodic replication runs to replicate your server to AWS. Each replication run creates an Amazon Machine Image (AMI)."},{"ref":"AWS.SMS.html#delete_app/3","title":"AWS.SMS.delete_app/3","type":"function","doc":"Deletes the specified application. Optionally deletes the launched stack associated with the application and all AWS SMS replication jobs for servers in the application."},{"ref":"AWS.SMS.html#delete_app_launch_configuration/3","title":"AWS.SMS.delete_app_launch_configuration/3","type":"function","doc":"Deletes the launch configuration for the specified application."},{"ref":"AWS.SMS.html#delete_app_replication_configuration/3","title":"AWS.SMS.delete_app_replication_configuration/3","type":"function","doc":"Deletes the replication configuration for the specified application."},{"ref":"AWS.SMS.html#delete_app_validation_configuration/3","title":"AWS.SMS.delete_app_validation_configuration/3","type":"function","doc":"Deletes the validation configuration for the specified application."},{"ref":"AWS.SMS.html#delete_replication_job/3","title":"AWS.SMS.delete_replication_job/3","type":"function","doc":"Deletes the specified replication job. After you delete a replication job, there are no further replication runs. AWS deletes the contents of the Amazon S3 bucket used to store AWS SMS artifacts. The AMIs created by the replication runs are not deleted."},{"ref":"AWS.SMS.html#delete_server_catalog/3","title":"AWS.SMS.delete_server_catalog/3","type":"function","doc":"Deletes all servers from your server catalog."},{"ref":"AWS.SMS.html#disassociate_connector/3","title":"AWS.SMS.disassociate_connector/3","type":"function","doc":"Disassociates the specified connector from AWS SMS. After you disassociate a connector, it is no longer available to support replication jobs."},{"ref":"AWS.SMS.html#generate_change_set/3","title":"AWS.SMS.generate_change_set/3","type":"function","doc":"Generates a target change set for a currently launched stack and writes it to an Amazon S3 object in the customers Amazon S3 bucket."},{"ref":"AWS.SMS.html#generate_template/3","title":"AWS.SMS.generate_template/3","type":"function","doc":"Generates an AWS CloudFormation template based on the current launch configuration and writes it to an Amazon S3 object in the customers Amazon S3 bucket."},{"ref":"AWS.SMS.html#get_app/3","title":"AWS.SMS.get_app/3","type":"function","doc":"Retrieve information about the specified application."},{"ref":"AWS.SMS.html#get_app_launch_configuration/3","title":"AWS.SMS.get_app_launch_configuration/3","type":"function","doc":"Retrieves the application launch configuration associated with the specified application."},{"ref":"AWS.SMS.html#get_app_replication_configuration/3","title":"AWS.SMS.get_app_replication_configuration/3","type":"function","doc":"Retrieves the application replication configuration associated with the specified application."},{"ref":"AWS.SMS.html#get_app_validation_configuration/3","title":"AWS.SMS.get_app_validation_configuration/3","type":"function","doc":"Retrieves information about a configuration for validating an application."},{"ref":"AWS.SMS.html#get_app_validation_output/3","title":"AWS.SMS.get_app_validation_output/3","type":"function","doc":"Retrieves output from validating an application."},{"ref":"AWS.SMS.html#get_connectors/3","title":"AWS.SMS.get_connectors/3","type":"function","doc":"Describes the connectors registered with the AWS SMS."},{"ref":"AWS.SMS.html#get_replication_jobs/3","title":"AWS.SMS.get_replication_jobs/3","type":"function","doc":"Describes the specified replication job or all of your replication jobs."},{"ref":"AWS.SMS.html#get_replication_runs/3","title":"AWS.SMS.get_replication_runs/3","type":"function","doc":"Describes the replication runs for the specified replication job."},{"ref":"AWS.SMS.html#get_servers/3","title":"AWS.SMS.get_servers/3","type":"function","doc":"Describes the servers in your server catalog. Before you can describe your servers, you must import them using ImportServerCatalog."},{"ref":"AWS.SMS.html#import_app_catalog/3","title":"AWS.SMS.import_app_catalog/3","type":"function","doc":"Allows application import from AWS Migration Hub."},{"ref":"AWS.SMS.html#import_server_catalog/3","title":"AWS.SMS.import_server_catalog/3","type":"function","doc":"Gathers a complete list of on-premises servers. Connectors must be installed and monitoring all servers to import. This call returns immediately, but might take additional time to retrieve all the servers."},{"ref":"AWS.SMS.html#launch_app/3","title":"AWS.SMS.launch_app/3","type":"function","doc":"Launches the specified application as a stack in AWS CloudFormation."},{"ref":"AWS.SMS.html#list_apps/3","title":"AWS.SMS.list_apps/3","type":"function","doc":"Retrieves summaries for all applications."},{"ref":"AWS.SMS.html#notify_app_validation_output/3","title":"AWS.SMS.notify_app_validation_output/3","type":"function","doc":"Provides information to AWS SMS about whether application validation is successful."},{"ref":"AWS.SMS.html#put_app_launch_configuration/3","title":"AWS.SMS.put_app_launch_configuration/3","type":"function","doc":"Creates or updates the launch configuration for the specified application."},{"ref":"AWS.SMS.html#put_app_replication_configuration/3","title":"AWS.SMS.put_app_replication_configuration/3","type":"function","doc":"Creates or updates the replication configuration for the specified application."},{"ref":"AWS.SMS.html#put_app_validation_configuration/3","title":"AWS.SMS.put_app_validation_configuration/3","type":"function","doc":"Creates or updates a validation configuration for the specified application."},{"ref":"AWS.SMS.html#start_app_replication/3","title":"AWS.SMS.start_app_replication/3","type":"function","doc":"Starts replicating the specified application by creating replication jobs for each server in the application."},{"ref":"AWS.SMS.html#start_on_demand_app_replication/3","title":"AWS.SMS.start_on_demand_app_replication/3","type":"function","doc":"Starts an on-demand replication run for the specified application."},{"ref":"AWS.SMS.html#start_on_demand_replication_run/3","title":"AWS.SMS.start_on_demand_replication_run/3","type":"function","doc":"Starts an on-demand replication run for the specified replication job. This replication run starts immediately. This replication run is in addition to the ones already scheduled. There is a limit on the number of on-demand replications runs that you can request in a 24-hour period."},{"ref":"AWS.SMS.html#stop_app_replication/3","title":"AWS.SMS.stop_app_replication/3","type":"function","doc":"Stops replicating the specified application by deleting the replication job for each server in the application."},{"ref":"AWS.SMS.html#terminate_app/3","title":"AWS.SMS.terminate_app/3","type":"function","doc":"Terminates the stack for the specified application."},{"ref":"AWS.SMS.html#update_app/3","title":"AWS.SMS.update_app/3","type":"function","doc":"Updates the specified application."},{"ref":"AWS.SMS.html#update_replication_job/3","title":"AWS.SMS.update_replication_job/3","type":"function","doc":"Updates the specified settings for the specified replication job."},{"ref":"AWS.SNS.html","title":"AWS.SNS","type":"module","doc":"Amazon Simple Notification Service Amazon Simple Notification Service (Amazon SNS) is a web service that enables you to build distributed web-enabled applications. Applications can use Amazon SNS to easily push real-time notification messages to interested subscribers over multiple delivery protocols. For more information about this product see https://aws.amazon.com/sns. For detailed information about Amazon SNS features and their associated API calls, see the Amazon SNS Developer Guide. We also provide SDKs that enable you to access Amazon SNS from your preferred programming language. The SDKs contain functionality that automatically takes care of tasks such as: cryptographically signing your service requests, retrying requests, and handling error responses. For a list of available SDKs, go to Tools for Amazon Web Services."},{"ref":"AWS.SNS.html#add_permission/3","title":"AWS.SNS.add_permission/3","type":"function","doc":"Adds a statement to a topic&#39;s access control policy, granting access for the specified AWS accounts to the specified actions."},{"ref":"AWS.SNS.html#check_if_phone_number_is_opted_out/3","title":"AWS.SNS.check_if_phone_number_is_opted_out/3","type":"function","doc":"Accepts a phone number and indicates whether the phone holder has opted out of receiving SMS messages from your account. You cannot send SMS messages to a number that is opted out. To resume sending messages, you can opt in the number by using the OptInPhoneNumber action."},{"ref":"AWS.SNS.html#confirm_subscription/3","title":"AWS.SNS.confirm_subscription/3","type":"function","doc":"Verifies an endpoint owner&#39;s intent to receive messages by validating the token sent to the endpoint by an earlier Subscribe action. If the token is valid, the action creates a new subscription and returns its Amazon Resource Name (ARN). This call requires an AWS signature only when the AuthenticateOnUnsubscribe flag is set to &quot;true&quot;."},{"ref":"AWS.SNS.html#create_platform_application/3","title":"AWS.SNS.create_platform_application/3","type":"function","doc":"Creates a platform application object for one of the supported push notification services, such as APNS and GCM (Firebase Cloud Messaging), to which devices and mobile apps may register. You must specify PlatformPrincipal and PlatformCredential attributes when using the CreatePlatformApplication action. PlatformPrincipal and PlatformCredential are received from the notification service. For ADM, PlatformPrincipal is client id and PlatformCredential is client secret. For Baidu, PlatformPrincipal is API key and PlatformCredential is secret key. For APNS and APNS_SANDBOX, PlatformPrincipal is SSL certificate and PlatformCredential is private key. For GCM (Firebase Cloud Messaging), there is no PlatformPrincipal and the PlatformCredential is API key. For MPNS, PlatformPrincipal is TLS certificate and PlatformCredential is private key. For WNS, PlatformPrincipal is Package Security Identifier and PlatformCredential is secret key. You can use the returned PlatformApplicationArn as an attribute for the CreatePlatformEndpoint action."},{"ref":"AWS.SNS.html#create_platform_endpoint/3","title":"AWS.SNS.create_platform_endpoint/3","type":"function","doc":"Creates an endpoint for a device and mobile app on one of the supported push notification services, such as GCM (Firebase Cloud Messaging) and APNS. CreatePlatformEndpoint requires the PlatformApplicationArn that is returned from CreatePlatformApplication. You can use the returned EndpointArn to send a message to a mobile app or by the Subscribe action for subscription to a topic. The CreatePlatformEndpoint action is idempotent, so if the requester already owns an endpoint with the same device token and attributes, that endpoint&#39;s ARN is returned without creating a new endpoint. For more information, see Using Amazon SNS Mobile Push Notifications. When using CreatePlatformEndpoint with Baidu, two attributes must be provided: ChannelId and UserId. The token field must also contain the ChannelId. For more information, see Creating an Amazon SNS Endpoint for Baidu."},{"ref":"AWS.SNS.html#create_topic/3","title":"AWS.SNS.create_topic/3","type":"function","doc":"Creates a topic to which notifications can be published. Users can create at most 100,000 topics. For more information, see https://aws.amazon.com/sns. This action is idempotent, so if the requester already owns a topic with the specified name, that topic&#39;s ARN is returned without creating a new topic."},{"ref":"AWS.SNS.html#delete_endpoint/3","title":"AWS.SNS.delete_endpoint/3","type":"function","doc":"Deletes the endpoint for a device and mobile app from Amazon SNS. This action is idempotent. For more information, see Using Amazon SNS Mobile Push Notifications. When you delete an endpoint that is also subscribed to a topic, then you must also unsubscribe the endpoint from the topic."},{"ref":"AWS.SNS.html#delete_platform_application/3","title":"AWS.SNS.delete_platform_application/3","type":"function","doc":"Deletes a platform application object for one of the supported push notification services, such as APNS and GCM (Firebase Cloud Messaging). For more information, see Using Amazon SNS Mobile Push Notifications."},{"ref":"AWS.SNS.html#delete_topic/3","title":"AWS.SNS.delete_topic/3","type":"function","doc":"Deletes a topic and all its subscriptions. Deleting a topic might prevent some messages previously sent to the topic from being delivered to subscribers. This action is idempotent, so deleting a topic that does not exist does not result in an error."},{"ref":"AWS.SNS.html#get_endpoint_attributes/3","title":"AWS.SNS.get_endpoint_attributes/3","type":"function","doc":"Retrieves the endpoint attributes for a device on one of the supported push notification services, such as GCM (Firebase Cloud Messaging) and APNS. For more information, see Using Amazon SNS Mobile Push Notifications."},{"ref":"AWS.SNS.html#get_platform_application_attributes/3","title":"AWS.SNS.get_platform_application_attributes/3","type":"function","doc":"Retrieves the attributes of the platform application object for the supported push notification services, such as APNS and GCM (Firebase Cloud Messaging). For more information, see Using Amazon SNS Mobile Push Notifications."},{"ref":"AWS.SNS.html#get_s_m_s_attributes/3","title":"AWS.SNS.get_s_m_s_attributes/3","type":"function","doc":"Returns the settings for sending SMS messages from your account. These settings are set with the SetSMSAttributes action."},{"ref":"AWS.SNS.html#get_subscription_attributes/3","title":"AWS.SNS.get_subscription_attributes/3","type":"function","doc":"Returns all of the properties of a subscription."},{"ref":"AWS.SNS.html#get_topic_attributes/3","title":"AWS.SNS.get_topic_attributes/3","type":"function","doc":"Returns all of the properties of a topic. Topic properties returned might differ based on the authorization of the user."},{"ref":"AWS.SNS.html#list_endpoints_by_platform_application/3","title":"AWS.SNS.list_endpoints_by_platform_application/3","type":"function","doc":"Lists the endpoints and endpoint attributes for devices in a supported push notification service, such as GCM (Firebase Cloud Messaging) and APNS. The results for ListEndpointsByPlatformApplication are paginated and return a limited list of endpoints, up to 100. If additional records are available after the first page results, then a NextToken string will be returned. To receive the next page, you call ListEndpointsByPlatformApplication again using the NextToken string received from the previous call. When there are no more records to return, NextToken will be null. For more information, see Using Amazon SNS Mobile Push Notifications. This action is throttled at 30 transactions per second (TPS)."},{"ref":"AWS.SNS.html#list_phone_numbers_opted_out/3","title":"AWS.SNS.list_phone_numbers_opted_out/3","type":"function","doc":"Returns a list of phone numbers that are opted out, meaning you cannot send SMS messages to them. The results for ListPhoneNumbersOptedOut are paginated, and each page returns up to 100 phone numbers. If additional phone numbers are available after the first page of results, then a NextToken string will be returned. To receive the next page, you call ListPhoneNumbersOptedOut again using the NextToken string received from the previous call. When there are no more records to return, NextToken will be null."},{"ref":"AWS.SNS.html#list_platform_applications/3","title":"AWS.SNS.list_platform_applications/3","type":"function","doc":"Lists the platform application objects for the supported push notification services, such as APNS and GCM (Firebase Cloud Messaging). The results for ListPlatformApplications are paginated and return a limited list of applications, up to 100. If additional records are available after the first page results, then a NextToken string will be returned. To receive the next page, you call ListPlatformApplications using the NextToken string received from the previous call. When there are no more records to return, NextToken will be null. For more information, see Using Amazon SNS Mobile Push Notifications. This action is throttled at 15 transactions per second (TPS)."},{"ref":"AWS.SNS.html#list_subscriptions/3","title":"AWS.SNS.list_subscriptions/3","type":"function","doc":"Returns a list of the requester&#39;s subscriptions. Each call returns a limited list of subscriptions, up to 100. If there are more subscriptions, a NextToken is also returned. Use the NextToken parameter in a new ListSubscriptions call to get further results. This action is throttled at 30 transactions per second (TPS)."},{"ref":"AWS.SNS.html#list_subscriptions_by_topic/3","title":"AWS.SNS.list_subscriptions_by_topic/3","type":"function","doc":"Returns a list of the subscriptions to a specific topic. Each call returns a limited list of subscriptions, up to 100. If there are more subscriptions, a NextToken is also returned. Use the NextToken parameter in a new ListSubscriptionsByTopic call to get further results. This action is throttled at 30 transactions per second (TPS)."},{"ref":"AWS.SNS.html#list_tags_for_resource/3","title":"AWS.SNS.list_tags_for_resource/3","type":"function","doc":"List all tags added to the specified Amazon SNS topic. For an overview, see Amazon SNS Tags in the Amazon Simple Notification Service Developer Guide."},{"ref":"AWS.SNS.html#list_topics/3","title":"AWS.SNS.list_topics/3","type":"function","doc":"Returns a list of the requester&#39;s topics. Each call returns a limited list of topics, up to 100. If there are more topics, a NextToken is also returned. Use the NextToken parameter in a new ListTopics call to get further results. This action is throttled at 30 transactions per second (TPS)."},{"ref":"AWS.SNS.html#opt_in_phone_number/3","title":"AWS.SNS.opt_in_phone_number/3","type":"function","doc":"Use this request to opt in a phone number that is opted out, which enables you to resume sending SMS messages to the number. You can opt in a phone number only once every 30 days."},{"ref":"AWS.SNS.html#publish/3","title":"AWS.SNS.publish/3","type":"function","doc":"Sends a message to an Amazon SNS topic, a text message (SMS message) directly to a phone number, or a message to a mobile platform endpoint (when you specify the TargetArn). If you send a message to a topic, Amazon SNS delivers the message to each endpoint that is subscribed to the topic. The format of the message depends on the notification protocol for each subscribed endpoint. When a messageId is returned, the message has been saved and Amazon SNS will attempt to deliver it shortly. To use the Publish action for sending a message to a mobile endpoint, such as an app on a Kindle device or mobile phone, you must specify the EndpointArn for the TargetArn parameter. The EndpointArn is returned when making a call with the CreatePlatformEndpoint action. For more information about formatting messages, see Send Custom Platform-Specific Payloads in Messages to Mobile Devices. You can publish messages only to topics and endpoints in the same AWS Region."},{"ref":"AWS.SNS.html#remove_permission/3","title":"AWS.SNS.remove_permission/3","type":"function","doc":"Removes a statement from a topic&#39;s access control policy."},{"ref":"AWS.SNS.html#set_endpoint_attributes/3","title":"AWS.SNS.set_endpoint_attributes/3","type":"function","doc":"Sets the attributes for an endpoint for a device on one of the supported push notification services, such as GCM (Firebase Cloud Messaging) and APNS. For more information, see Using Amazon SNS Mobile Push Notifications."},{"ref":"AWS.SNS.html#set_platform_application_attributes/3","title":"AWS.SNS.set_platform_application_attributes/3","type":"function","doc":"Sets the attributes of the platform application object for the supported push notification services, such as APNS and GCM (Firebase Cloud Messaging). For more information, see Using Amazon SNS Mobile Push Notifications. For information on configuring attributes for message delivery status, see Using Amazon SNS Application Attributes for Message Delivery Status."},{"ref":"AWS.SNS.html#set_s_m_s_attributes/3","title":"AWS.SNS.set_s_m_s_attributes/3","type":"function","doc":"Use this request to set the default settings for sending SMS messages and receiving daily SMS usage reports. You can override some of these settings for a single message when you use the Publish action with the MessageAttributes.entry.N parameter. For more information, see Sending an SMS Message in the Amazon SNS Developer Guide."},{"ref":"AWS.SNS.html#set_subscription_attributes/3","title":"AWS.SNS.set_subscription_attributes/3","type":"function","doc":"Allows a subscription owner to set an attribute of the subscription to a new value."},{"ref":"AWS.SNS.html#set_topic_attributes/3","title":"AWS.SNS.set_topic_attributes/3","type":"function","doc":"Allows a topic owner to set an attribute of the topic to a new value."},{"ref":"AWS.SNS.html#subscribe/3","title":"AWS.SNS.subscribe/3","type":"function","doc":"Subscribes an endpoint to an Amazon SNS topic. If the endpoint type is HTTP/S or email, or if the endpoint and the topic are not in the same AWS account, the endpoint owner must the ConfirmSubscription action to confirm the subscription. You call the ConfirmSubscription action with the token from the subscription response. Confirmation tokens are valid for three days. This action is throttled at 100 transactions per second (TPS)."},{"ref":"AWS.SNS.html#tag_resource/3","title":"AWS.SNS.tag_resource/3","type":"function","doc":"Add tags to the specified Amazon SNS topic. For an overview, see Amazon SNS Tags in the Amazon SNS Developer Guide. When you use topic tags, keep the following guidelines in mind: Adding more than 50 tags to a topic isn&#39;t recommended. Tags don&#39;t have any semantic meaning. Amazon SNS interprets tags as character strings. Tags are case-sensitive. A new tag with a key identical to that of an existing tag overwrites the existing tag. Tagging actions are limited to 10 TPS per AWS account, per AWS region. If your application requires a higher throughput, file a technical support request."},{"ref":"AWS.SNS.html#unsubscribe/3","title":"AWS.SNS.unsubscribe/3","type":"function","doc":"Deletes a subscription. If the subscription requires authentication for deletion, only the owner of the subscription or the topic&#39;s owner can unsubscribe, and an AWS signature is required. If the Unsubscribe call does not require authentication and the requester is not the subscription owner, a final cancellation message is delivered to the endpoint, so that the endpoint owner can easily resubscribe to the topic if the Unsubscribe request was unintended. This action is throttled at 100 transactions per second (TPS)."},{"ref":"AWS.SNS.html#untag_resource/3","title":"AWS.SNS.untag_resource/3","type":"function","doc":"Remove tags from the specified Amazon SNS topic. For an overview, see Amazon SNS Tags in the Amazon SNS Developer Guide."},{"ref":"AWS.SQS.html","title":"AWS.SQS","type":"module","doc":"Welcome to the Amazon Simple Queue Service API Reference. Amazon Simple Queue Service (Amazon SQS) is a reliable, highly-scalable hosted queue for storing messages as they travel between applications or microservices. Amazon SQS moves data between distributed application components and helps you decouple these components. For information on the permissions you need to use this API, see Identity and access management in the Amazon Simple Queue Service Developer Guide. You can use AWS SDKs to access Amazon SQS using your favorite programming language. The SDKs perform tasks such as the following automatically: Cryptographically sign your service requests Retry requests Handle error responses Additional Information Amazon SQS Product Page Amazon Simple Queue Service Developer Guide Making API Requests Amazon SQS Message Attributes Amazon SQS Dead-Letter Queues Amazon SQS in the AWS CLI Command Reference Amazon Web Services General Reference Regions and Endpoints"},{"ref":"AWS.SQS.html#add_permission/3","title":"AWS.SQS.add_permission/3","type":"function","doc":"Adds a permission to a queue for a specific principal. This allows sharing access to the queue. When you create a queue, you have full control access rights for the queue. Only you, the owner of the queue, can grant or deny permissions to the queue. For more information about these permissions, see Allow Developers to Write Messages to a Shared Queue in the Amazon Simple Queue Service Developer Guide. AddPermission generates a policy for you. You can use SetQueueAttributes to upload your policy. For more information, see Using Custom Policies with the Amazon SQS Access Policy Language in the Amazon Simple Queue Service Developer Guide. An Amazon SQS policy can have a maximum of 7 actions. To remove the ability to change queue permissions, you must deny permission to the AddPermission, RemovePermission, and SetQueueAttributes actions in your IAM policy. Some actions take lists of parameters. These lists are specified using the param.n notation. Values of n are integers starting from 1. For example, a parameter list with two elements looks like this: &amp;AttributeName.1=first &amp;AttributeName.2=second Cross-account permissions don&#39;t apply to this action. For more information, see Grant Cross-Account Permissions to a Role and a User Name in the Amazon Simple Queue Service Developer Guide."},{"ref":"AWS.SQS.html#change_message_visibility/3","title":"AWS.SQS.change_message_visibility/3","type":"function","doc":"Changes the visibility timeout of a specified message in a queue to a new value. The default visibility timeout for a message is 30 seconds. The minimum is 0 seconds. The maximum is 12 hours. For more information, see Visibility Timeout in the Amazon Simple Queue Service Developer Guide. For example, you have a message with a visibility timeout of 5 minutes. After 3 minutes, you call ChangeMessageVisibility with a timeout of 10 minutes. You can continue to call ChangeMessageVisibility to extend the visibility timeout to the maximum allowed time. If you try to extend the visibility timeout beyond the maximum, your request is rejected. An Amazon SQS message has three basic states: Sent to a queue by a producer. Received from the queue by a consumer. Deleted from the queue. A message is considered to be stored after it is sent to a queue by a producer, but not yet received from the queue by a consumer (that is, between states 1 and 2). There is no limit to the number of stored messages. A message is considered to be in flight after it is received from a queue by a consumer, but not yet deleted from the queue (that is, between states 2 and 3). There is a limit to the number of inflight messages. Limits that apply to inflight messages are unrelated to the unlimited number of stored messages. For most standard queues (depending on queue traffic and message backlog), there can be a maximum of approximately 120,000 inflight messages (received from a queue by a consumer, but not yet deleted from the queue). If you reach this limit, Amazon SQS returns the OverLimit error message. To avoid reaching the limit, you should delete messages from the queue after they&#39;re processed. You can also increase the number of queues you use to process your messages. To request a limit increase, file a support request. For FIFO queues, there can be a maximum of 20,000 inflight messages (received from a queue by a consumer, but not yet deleted from the queue). If you reach this limit, Amazon SQS returns no error messages. If you attempt to set the VisibilityTimeout to a value greater than the maximum time left, Amazon SQS returns an error. Amazon SQS doesn&#39;t automatically recalculate and increase the timeout to the maximum remaining time. Unlike with a queue, when you change the visibility timeout for a specific message the timeout value is applied immediately but isn&#39;t saved in memory for that message. If you don&#39;t delete a message after it is received, the visibility timeout for the message reverts to the original timeout value (not to the value you set using the ChangeMessageVisibility action) the next time the message is received."},{"ref":"AWS.SQS.html#change_message_visibility_batch/3","title":"AWS.SQS.change_message_visibility_batch/3","type":"function","doc":"Changes the visibility timeout of multiple messages. This is a batch version of ChangeMessageVisibility. The result of the action on each message is reported individually in the response. You can send up to 10 ChangeMessageVisibility requests with each ChangeMessageVisibilityBatch action. Because the batch request can result in a combination of successful and unsuccessful actions, you should check for batch errors even when the call returns an HTTP status code of 200. Some actions take lists of parameters. These lists are specified using the param.n notation. Values of n are integers starting from 1. For example, a parameter list with two elements looks like this: &amp;AttributeName.1=first &amp;AttributeName.2=second"},{"ref":"AWS.SQS.html#create_queue/3","title":"AWS.SQS.create_queue/3","type":"function","doc":"Creates a new standard or FIFO queue. You can pass one or more attributes in the request. Keep the following in mind: If you don&#39;t specify the FifoQueue attribute, Amazon SQS creates a standard queue. You can&#39;t change the queue type after you create it and you can&#39;t convert an existing standard queue into a FIFO queue. You must either create a new FIFO queue for your application or delete your existing standard queue and recreate it as a FIFO queue. For more information, see Moving From a Standard Queue to a FIFO Queue in the Amazon Simple Queue Service Developer Guide. If you don&#39;t provide a value for an attribute, the queue is created with the default value for the attribute. If you delete a queue, you must wait at least 60 seconds before creating a queue with the same name. To successfully create a new queue, you must provide a queue name that adheres to the limits related to queues and is unique within the scope of your queues. After you create a queue, you must wait at least one second after the queue is created to be able to use the queue. To get the queue URL, use the GetQueueUrl action. GetQueueUrl requires only the QueueName parameter. be aware of existing queue names: If you provide the name of an existing queue along with the exact names and values of all the queue&#39;s attributes, CreateQueue returns the queue URL for the existing queue. If the queue name, attribute names, or attribute values don&#39;t match an existing queue, CreateQueue returns an error. Some actions take lists of parameters. These lists are specified using the param.n notation. Values of n are integers starting from 1. For example, a parameter list with two elements looks like this: &amp;AttributeName.1=first &amp;AttributeName.2=second Cross-account permissions don&#39;t apply to this action. For more information, see Grant Cross-Account Permissions to a Role and a User Name in the Amazon Simple Queue Service Developer Guide."},{"ref":"AWS.SQS.html#delete_message/3","title":"AWS.SQS.delete_message/3","type":"function","doc":"Deletes the specified message from the specified queue. To select the message to delete, use the ReceiptHandle of the message (not the MessageId which you receive when you send the message). Amazon SQS can delete a message from a queue even if a visibility timeout setting causes the message to be locked by another consumer. Amazon SQS automatically deletes messages left in a queue longer than the retention period configured for the queue. The ReceiptHandle is associated with a specific instance of receiving a message. If you receive a message more than once, the ReceiptHandle is different each time you receive a message. When you use the DeleteMessage action, you must provide the most recently received ReceiptHandle for the message (otherwise, the request succeeds, but the message might not be deleted). For standard queues, it is possible to receive a message even after you delete it. This might happen on rare occasions if one of the servers which stores a copy of the message is unavailable when you send the request to delete the message. The copy remains on the server and might be returned to you during a subsequent receive request. You should ensure that your application is idempotent, so that receiving a message more than once does not cause issues."},{"ref":"AWS.SQS.html#delete_message_batch/3","title":"AWS.SQS.delete_message_batch/3","type":"function","doc":"Deletes up to ten messages from the specified queue. This is a batch version of DeleteMessage. The result of the action on each message is reported individually in the response. Because the batch request can result in a combination of successful and unsuccessful actions, you should check for batch errors even when the call returns an HTTP status code of 200. Some actions take lists of parameters. These lists are specified using the param.n notation. Values of n are integers starting from 1. For example, a parameter list with two elements looks like this: &amp;AttributeName.1=first &amp;AttributeName.2=second"},{"ref":"AWS.SQS.html#delete_queue/3","title":"AWS.SQS.delete_queue/3","type":"function","doc":"Deletes the queue specified by the QueueUrl, regardless of the queue&#39;s contents. Be careful with the DeleteQueue action: When you delete a queue, any messages in the queue are no longer available. When you delete a queue, the deletion process takes up to 60 seconds. Requests you send involving that queue during the 60 seconds might succeed. For example, a SendMessage request might succeed, but after 60 seconds the queue and the message you sent no longer exist. When you delete a queue, you must wait at least 60 seconds before creating a queue with the same name. Cross-account permissions don&#39;t apply to this action. For more information, see Grant Cross-Account Permissions to a Role and a User Name in the Amazon Simple Queue Service Developer Guide."},{"ref":"AWS.SQS.html#get_queue_attributes/3","title":"AWS.SQS.get_queue_attributes/3","type":"function","doc":"Gets attributes for the specified queue. To determine whether a queue is FIFO, you can check whether QueueName ends with the .fifo suffix."},{"ref":"AWS.SQS.html#get_queue_url/3","title":"AWS.SQS.get_queue_url/3","type":"function","doc":"Returns the URL of an existing Amazon SQS queue. To access a queue that belongs to another AWS account, use the QueueOwnerAWSAccountId parameter to specify the account ID of the queue&#39;s owner. The queue&#39;s owner must grant you permission to access the queue. For more information about shared queue access, see AddPermission or see Allow Developers to Write Messages to a Shared Queue in the Amazon Simple Queue Service Developer Guide."},{"ref":"AWS.SQS.html#list_dead_letter_source_queues/3","title":"AWS.SQS.list_dead_letter_source_queues/3","type":"function","doc":"Returns a list of your queues that have the RedrivePolicy queue attribute configured with a dead-letter queue. The ListDeadLetterSourceQueues methods supports pagination. Set parameter MaxResults in the request to specify the maximum number of results to be returned in the response. If you do not set MaxResults, the response includes a maximum of 1,000 results. If you set MaxResults and there are additional results to display, the response includes a value for NextToken. Use NextToken as a parameter in your next request to ListDeadLetterSourceQueues to receive the next page of results. For more information about using dead-letter queues, see Using Amazon SQS Dead-Letter Queues in the Amazon Simple Queue Service Developer Guide."},{"ref":"AWS.SQS.html#list_queue_tags/3","title":"AWS.SQS.list_queue_tags/3","type":"function","doc":"List all cost allocation tags added to the specified Amazon SQS queue. For an overview, see Tagging Your Amazon SQS Queues in the Amazon Simple Queue Service Developer Guide. Cross-account permissions don&#39;t apply to this action. For more information, see Grant Cross-Account Permissions to a Role and a User Name in the Amazon Simple Queue Service Developer Guide."},{"ref":"AWS.SQS.html#list_queues/3","title":"AWS.SQS.list_queues/3","type":"function","doc":"Returns a list of your queues in the current region. The response includes a maximum of 1,000 results. If you specify a value for the optional QueueNamePrefix parameter, only queues with a name that begins with the specified value are returned. The listQueues methods supports pagination. Set parameter MaxResults in the request to specify the maximum number of results to be returned in the response. If you do not set MaxResults, the response includes a maximum of 1,000 results. If you set MaxResults and there are additional results to display, the response includes a value for NextToken. Use NextToken as a parameter in your next request to listQueues to receive the next page of results. Cross-account permissions don&#39;t apply to this action. For more information, see Grant Cross-Account Permissions to a Role and a User Name in the Amazon Simple Queue Service Developer Guide."},{"ref":"AWS.SQS.html#purge_queue/3","title":"AWS.SQS.purge_queue/3","type":"function","doc":"Deletes the messages in a queue specified by the QueueURL parameter. When you use the PurgeQueue action, you can&#39;t retrieve any messages deleted from a queue. The message deletion process takes up to 60 seconds. We recommend waiting for 60 seconds regardless of your queue&#39;s size. Messages sent to the queue before you call PurgeQueue might be received but are deleted within the next minute. Messages sent to the queue after you call PurgeQueue might be deleted while the queue is being purged."},{"ref":"AWS.SQS.html#receive_message/3","title":"AWS.SQS.receive_message/3","type":"function","doc":"Retrieves one or more messages (up to 10), from the specified queue. Using the WaitTimeSeconds parameter enables long-poll support. For more information, see Amazon SQS Long Polling in the Amazon Simple Queue Service Developer Guide. Short poll is the default behavior where a weighted random set of machines is sampled on a ReceiveMessage call. Thus, only the messages on the sampled machines are returned. If the number of messages in the queue is small (fewer than 1,000), you most likely get fewer messages than you requested per ReceiveMessage call. If the number of messages in the queue is extremely small, you might not receive any messages in a particular ReceiveMessage response. If this happens, repeat the request. For each message returned, the response includes the following: The message body. An MD5 digest of the message body. For information about MD5, see RFC1321. * The MessageId you received when you sent the message to the queue. The receipt handle. The message attributes. An MD5 digest of the message attributes. The receipt handle is the identifier you must provide when deleting the message. For more information, see Queue and Message Identifiers in the Amazon Simple Queue Service Developer Guide. You can provide the VisibilityTimeout parameter in your request. The parameter is applied to the messages that Amazon SQS returns in the response. If you don&#39;t include the parameter, the overall visibility timeout for the queue is used for the returned messages. For more information, see Visibility Timeout in the Amazon Simple Queue Service Developer Guide. A message that isn&#39;t deleted or a message whose visibility isn&#39;t extended before the visibility timeout expires counts as a failed receive. Depending on the configuration of the queue, the message might be sent to the dead-letter queue. In the future, new attributes might be added. If you write code that calls this action, we recommend that you structure your code so that it can handle new attributes gracefully."},{"ref":"AWS.SQS.html#remove_permission/3","title":"AWS.SQS.remove_permission/3","type":"function","doc":"Revokes any permissions in the queue policy that matches the specified Label parameter. Only the owner of a queue can remove permissions from it. Cross-account permissions don&#39;t apply to this action. For more information, see Grant Cross-Account Permissions to a Role and a User Name in the Amazon Simple Queue Service Developer Guide. To remove the ability to change queue permissions, you must deny permission to the AddPermission, RemovePermission, and SetQueueAttributes actions in your IAM policy."},{"ref":"AWS.SQS.html#send_message/3","title":"AWS.SQS.send_message/3","type":"function","doc":"Delivers a message to the specified queue. A message can include only XML, JSON, and unformatted text. The following Unicode characters are allowed: #x9 | #xA | #xD | #x20 to #xD7FF | #xE000 to #xFFFD | #x10000 to #x10FFFF Any characters not included in this list will be rejected. For more information, see the W3C specification for characters."},{"ref":"AWS.SQS.html#send_message_batch/3","title":"AWS.SQS.send_message_batch/3","type":"function","doc":"Delivers up to ten messages to the specified queue. This is a batch version of SendMessage. For a FIFO queue, multiple messages within a single batch are enqueued in the order they are sent. The result of sending each message is reported individually in the response. Because the batch request can result in a combination of successful and unsuccessful actions, you should check for batch errors even when the call returns an HTTP status code of 200. The maximum allowed individual message size and the maximum total payload size (the sum of the individual lengths of all of the batched messages) are both 256 KB (262,144 bytes). A message can include only XML, JSON, and unformatted text. The following Unicode characters are allowed: #x9 | #xA | #xD | #x20 to #xD7FF | #xE000 to #xFFFD | #x10000 to #x10FFFF Any characters not included in this list will be rejected. For more information, see the W3C specification for characters. If you don&#39;t specify the DelaySeconds parameter for an entry, Amazon SQS uses the default value for the queue. Some actions take lists of parameters. These lists are specified using the param.n notation. Values of n are integers starting from 1. For example, a parameter list with two elements looks like this: &amp;AttributeName.1=first &amp;AttributeName.2=second"},{"ref":"AWS.SQS.html#set_queue_attributes/3","title":"AWS.SQS.set_queue_attributes/3","type":"function","doc":"Sets the value of one or more queue attributes. When you change a queue&#39;s attributes, the change can take up to 60 seconds for most of the attributes to propagate throughout the Amazon SQS system. Changes made to the MessageRetentionPeriod attribute can take up to 15 minutes. In the future, new attributes might be added. If you write code that calls this action, we recommend that you structure your code so that it can handle new attributes gracefully. Cross-account permissions don&#39;t apply to this action. For more information, see Grant Cross-Account Permissions to a Role and a User Name in the Amazon Simple Queue Service Developer Guide. To remove the ability to change queue permissions, you must deny permission to the AddPermission, RemovePermission, and SetQueueAttributes actions in your IAM policy."},{"ref":"AWS.SQS.html#tag_queue/3","title":"AWS.SQS.tag_queue/3","type":"function","doc":"Add cost allocation tags to the specified Amazon SQS queue. For an overview, see Tagging Your Amazon SQS Queues in the Amazon Simple Queue Service Developer Guide. When you use queue tags, keep the following guidelines in mind: Adding more than 50 tags to a queue isn&#39;t recommended. Tags don&#39;t have any semantic meaning. Amazon SQS interprets tags as character strings. Tags are case-sensitive. A new tag with a key identical to that of an existing tag overwrites the existing tag. For a full list of tag restrictions, see Limits Related to Queues in the Amazon Simple Queue Service Developer Guide. Cross-account permissions don&#39;t apply to this action. For more information, see Grant Cross-Account Permissions to a Role and a User Name in the Amazon Simple Queue Service Developer Guide."},{"ref":"AWS.SQS.html#untag_queue/3","title":"AWS.SQS.untag_queue/3","type":"function","doc":"Remove cost allocation tags from the specified Amazon SQS queue. For an overview, see Tagging Your Amazon SQS Queues in the Amazon Simple Queue Service Developer Guide. Cross-account permissions don&#39;t apply to this action. For more information, see Grant Cross-Account Permissions to a Role and a User Name in the Amazon Simple Queue Service Developer Guide."},{"ref":"AWS.SSM.html","title":"AWS.SSM","type":"module","doc":"AWS Systems Manager AWS Systems Manager is a collection of capabilities that helps you automate management tasks such as collecting system inventory, applying operating system (OS) patches, automating the creation of Amazon Machine Images (AMIs), and configuring operating systems (OSs) and applications at scale. Systems Manager lets you remotely and securely manage the configuration of your managed instances. A managed instance is any Amazon Elastic Compute Cloud instance (EC2 instance), or any on-premises server or virtual machine (VM) in your hybrid environment that has been configured for Systems Manager. This reference is intended to be used with the AWS Systems Manager User Guide. To get started, verify prerequisites and configure managed instances. For more information, see Setting up AWS Systems Manager in the AWS Systems Manager User Guide. For information about other API actions you can perform on EC2 instances, see the Amazon EC2 API Reference. For information about how to use a Query API, see Making API requests."},{"ref":"AWS.SSM.html#add_tags_to_resource/3","title":"AWS.SSM.add_tags_to_resource/3","type":"function","doc":"Adds or overwrites one or more tags for the specified resource. Tags are metadata that you can assign to your documents, managed instances, maintenance windows, Parameter Store parameters, and patch baselines. Tags enable you to categorize your resources in different ways, for example, by purpose, owner, or environment. Each tag consists of a key and an optional value, both of which you define. For example, you could define a set of tags for your account&#39;s managed instances that helps you track each instance&#39;s owner and stack level. For example: Key=Owner and Value=DbAdmin, SysAdmin, or Dev. Or Key=Stack and Value=Production, Pre-Production, or Test. Each resource can have a maximum of 50 tags. We recommend that you devise a set of tag keys that meets your needs for each resource type. Using a consistent set of tag keys makes it easier for you to manage your resources. You can search and filter the resources based on the tags you add. Tags don&#39;t have any semantic meaning to and are interpreted strictly as a string of characters. For more information about using tags with EC2 instances, see Tagging your Amazon EC2 resources in the Amazon EC2 User Guide."},{"ref":"AWS.SSM.html#cancel_command/3","title":"AWS.SSM.cancel_command/3","type":"function","doc":"Attempts to cancel the command specified by the Command ID. There is no guarantee that the command will be terminated and the underlying process stopped."},{"ref":"AWS.SSM.html#cancel_maintenance_window_execution/3","title":"AWS.SSM.cancel_maintenance_window_execution/3","type":"function","doc":"Stops a maintenance window execution that is already in progress and cancels any tasks in the window that have not already starting running. (Tasks already in progress will continue to completion.)"},{"ref":"AWS.SSM.html#create_activation/3","title":"AWS.SSM.create_activation/3","type":"function","doc":"Generates an activation code and activation ID you can use to register your on-premises server or virtual machine (VM) with Systems Manager. Registering these machines with Systems Manager makes it possible to manage them using Systems Manager capabilities. You use the activation code and ID when installing SSM Agent on machines in your hybrid environment. For more information about requirements for managing on-premises instances and VMs using Systems Manager, see Setting up AWS Systems Manager for hybrid environments in the AWS Systems Manager User Guide. On-premises servers or VMs that are registered with Systems Manager and EC2 instances that you manage with Systems Manager are all called managed instances."},{"ref":"AWS.SSM.html#create_association/3","title":"AWS.SSM.create_association/3","type":"function","doc":"A State Manager association defines the state that you want to maintain on your instances. For example, an association can specify that anti-virus software must be installed and running on your instances, or that certain ports must be closed. For static targets, the association specifies a schedule for when the configuration is reapplied. For dynamic targets, such as an AWS Resource Group or an AWS Autoscaling Group, State Manager applies the configuration when new instances are added to the group. The association also specifies actions to take when applying the configuration. For example, an association for anti-virus software might run once a day. If the software is not installed, then State Manager installs it. If the software is installed, but the service is not running, then the association might instruct State Manager to start the service."},{"ref":"AWS.SSM.html#create_association_batch/3","title":"AWS.SSM.create_association_batch/3","type":"function","doc":"Associates the specified Systems Manager document with the specified instances or targets. When you associate a document with one or more instances using instance IDs or tags, SSM Agent running on the instance processes the document and configures the instance as specified. If you associate a document with an instance that already has an associated document, the system returns the AssociationAlreadyExists exception."},{"ref":"AWS.SSM.html#create_document/3","title":"AWS.SSM.create_document/3","type":"function","doc":"Creates a Systems Manager (SSM) document. An SSM document defines the actions that Systems Manager performs on your managed instances. For more information about SSM documents, including information about supported schemas, features, and syntax, see AWS Systems Manager Documents in the AWS Systems Manager User Guide."},{"ref":"AWS.SSM.html#create_maintenance_window/3","title":"AWS.SSM.create_maintenance_window/3","type":"function","doc":"Creates a new maintenance window. The value you specify for Duration determines the specific end time for the maintenance window based on the time it begins. No maintenance window tasks are permitted to start after the resulting endtime minus the number of hours you specify for Cutoff. For example, if the maintenance window starts at 3 PM, the duration is three hours, and the value you specify for Cutoff is one hour, no maintenance window tasks can start after 5 PM."},{"ref":"AWS.SSM.html#create_ops_item/3","title":"AWS.SSM.create_ops_item/3","type":"function","doc":"Creates a new OpsItem. You must have permission in AWS Identity and Access Management (IAM) to create a new OpsItem. For more information, see Getting started with OpsCenter in the AWS Systems Manager User Guide. Operations engineers and IT professionals use OpsCenter to view, investigate, and remediate operational issues impacting the performance and health of their AWS resources. For more information, see AWS Systems Manager OpsCenter in the AWS Systems Manager User Guide."},{"ref":"AWS.SSM.html#create_patch_baseline/3","title":"AWS.SSM.create_patch_baseline/3","type":"function","doc":"Creates a patch baseline. For information about valid key and value pairs in PatchFilters for each supported operating system type, see PatchFilter."},{"ref":"AWS.SSM.html#create_resource_data_sync/3","title":"AWS.SSM.create_resource_data_sync/3","type":"function","doc":"A resource data sync helps you view data from multiple sources in a single location. Systems Manager offers two types of resource data sync: SyncToDestination and SyncFromSource. You can configure Systems Manager Inventory to use the SyncToDestination type to synchronize Inventory data from multiple AWS Regions to a single S3 bucket. For more information, see Configuring Resource Data Sync for Inventory in the AWS Systems Manager User Guide. You can configure Systems Manager Explorer to use the SyncFromSource type to synchronize operational work items (OpsItems) and operational data (OpsData) from multiple AWS Regions to a single S3 bucket. This type can synchronize OpsItems and OpsData from multiple AWS accounts and Regions or EntireOrganization by using AWS Organizations. For more information, see Setting up Systems Manager Explorer to display data from multiple accounts and Regions in the AWS Systems Manager User Guide. A resource data sync is an asynchronous operation that returns immediately. After a successful initial sync is completed, the system continuously syncs data. To check the status of a sync, use the ListResourceDataSync. By default, data is not encrypted in Amazon S3. We strongly recommend that you enable encryption in Amazon S3 to ensure secure data storage. We also recommend that you secure access to the Amazon S3 bucket by creating a restrictive bucket policy."},{"ref":"AWS.SSM.html#delete_activation/3","title":"AWS.SSM.delete_activation/3","type":"function","doc":"Deletes an activation. You are not required to delete an activation. If you delete an activation, you can no longer use it to register additional managed instances. Deleting an activation does not de-register managed instances. You must manually de-register managed instances."},{"ref":"AWS.SSM.html#delete_association/3","title":"AWS.SSM.delete_association/3","type":"function","doc":"Disassociates the specified Systems Manager document from the specified instance. When you disassociate a document from an instance, it does not change the configuration of the instance. To change the configuration state of an instance after you disassociate a document, you must create a new document with the desired configuration and associate it with the instance."},{"ref":"AWS.SSM.html#delete_document/3","title":"AWS.SSM.delete_document/3","type":"function","doc":"Deletes the Systems Manager document and all instance associations to the document. Before you delete the document, we recommend that you use DeleteAssociation to disassociate all instances that are associated with the document."},{"ref":"AWS.SSM.html#delete_inventory/3","title":"AWS.SSM.delete_inventory/3","type":"function","doc":"Delete a custom inventory type or the data associated with a custom Inventory type. Deleting a custom inventory type is also referred to as deleting a custom inventory schema."},{"ref":"AWS.SSM.html#delete_maintenance_window/3","title":"AWS.SSM.delete_maintenance_window/3","type":"function","doc":"Deletes a maintenance window."},{"ref":"AWS.SSM.html#delete_parameter/3","title":"AWS.SSM.delete_parameter/3","type":"function","doc":"Delete a parameter from the system."},{"ref":"AWS.SSM.html#delete_parameters/3","title":"AWS.SSM.delete_parameters/3","type":"function","doc":"Delete a list of parameters."},{"ref":"AWS.SSM.html#delete_patch_baseline/3","title":"AWS.SSM.delete_patch_baseline/3","type":"function","doc":"Deletes a patch baseline."},{"ref":"AWS.SSM.html#delete_resource_data_sync/3","title":"AWS.SSM.delete_resource_data_sync/3","type":"function","doc":"Deletes a Resource Data Sync configuration. After the configuration is deleted, changes to data on managed instances are no longer synced to or from the target. Deleting a sync configuration does not delete data."},{"ref":"AWS.SSM.html#deregister_managed_instance/3","title":"AWS.SSM.deregister_managed_instance/3","type":"function","doc":"Removes the server or virtual machine from the list of registered servers. You can reregister the instance again at any time. If you don&#39;t plan to use Run Command on the server, we suggest uninstalling SSM Agent first."},{"ref":"AWS.SSM.html#deregister_patch_baseline_for_patch_group/3","title":"AWS.SSM.deregister_patch_baseline_for_patch_group/3","type":"function","doc":"Removes a patch group from a patch baseline."},{"ref":"AWS.SSM.html#deregister_target_from_maintenance_window/3","title":"AWS.SSM.deregister_target_from_maintenance_window/3","type":"function","doc":"Removes a target from a maintenance window."},{"ref":"AWS.SSM.html#deregister_task_from_maintenance_window/3","title":"AWS.SSM.deregister_task_from_maintenance_window/3","type":"function","doc":"Removes a task from a maintenance window."},{"ref":"AWS.SSM.html#describe_activations/3","title":"AWS.SSM.describe_activations/3","type":"function","doc":"Describes details about the activation, such as the date and time the activation was created, its expiration date, the IAM role assigned to the instances in the activation, and the number of instances registered by using this activation."},{"ref":"AWS.SSM.html#describe_association/3","title":"AWS.SSM.describe_association/3","type":"function","doc":"Describes the association for the specified target or instance. If you created the association by using the Targets parameter, then you must retrieve the association by using the association ID. If you created the association by specifying an instance ID and a Systems Manager document, then you retrieve the association by specifying the document name and the instance ID."},{"ref":"AWS.SSM.html#describe_association_execution_targets/3","title":"AWS.SSM.describe_association_execution_targets/3","type":"function","doc":"Use this API action to view information about a specific execution of a specific association."},{"ref":"AWS.SSM.html#describe_association_executions/3","title":"AWS.SSM.describe_association_executions/3","type":"function","doc":"Use this API action to view all executions for a specific association ID."},{"ref":"AWS.SSM.html#describe_automation_executions/3","title":"AWS.SSM.describe_automation_executions/3","type":"function","doc":"Provides details about all active and terminated Automation executions."},{"ref":"AWS.SSM.html#describe_automation_step_executions/3","title":"AWS.SSM.describe_automation_step_executions/3","type":"function","doc":"Information about all active and terminated step executions in an Automation workflow."},{"ref":"AWS.SSM.html#describe_available_patches/3","title":"AWS.SSM.describe_available_patches/3","type":"function","doc":"Lists all patches eligible to be included in a patch baseline."},{"ref":"AWS.SSM.html#describe_document/3","title":"AWS.SSM.describe_document/3","type":"function","doc":"Describes the specified Systems Manager document."},{"ref":"AWS.SSM.html#describe_document_permission/3","title":"AWS.SSM.describe_document_permission/3","type":"function","doc":"Describes the permissions for a Systems Manager document. If you created the document, you are the owner. If a document is shared, it can either be shared privately (by specifying a user&#39;s AWS account ID) or publicly (All)."},{"ref":"AWS.SSM.html#describe_effective_instance_associations/3","title":"AWS.SSM.describe_effective_instance_associations/3","type":"function","doc":"All associations for the instance(s)."},{"ref":"AWS.SSM.html#describe_effective_patches_for_patch_baseline/3","title":"AWS.SSM.describe_effective_patches_for_patch_baseline/3","type":"function","doc":"Retrieves the current effective patches (the patch and the approval state) for the specified patch baseline. Note that this API applies only to Windows patch baselines."},{"ref":"AWS.SSM.html#describe_instance_associations_status/3","title":"AWS.SSM.describe_instance_associations_status/3","type":"function","doc":"The status of the associations for the instance(s)."},{"ref":"AWS.SSM.html#describe_instance_information/3","title":"AWS.SSM.describe_instance_information/3","type":"function","doc":"Describes one or more of your instances, including information about the operating system platform, the version of SSM Agent installed on the instance, instance status, and so on. If you specify one or more instance IDs, it returns information for those instances. If you do not specify instance IDs, it returns information for all your instances. If you specify an instance ID that is not valid or an instance that you do not own, you receive an error. The IamRole field for this API action is the Amazon Identity and Access Management (IAM) role assigned to on-premises instances. This call does not return the IAM role for EC2 instances."},{"ref":"AWS.SSM.html#describe_instance_patch_states/3","title":"AWS.SSM.describe_instance_patch_states/3","type":"function","doc":"Retrieves the high-level patch state of one or more instances."},{"ref":"AWS.SSM.html#describe_instance_patch_states_for_patch_group/3","title":"AWS.SSM.describe_instance_patch_states_for_patch_group/3","type":"function","doc":"Retrieves the high-level patch state for the instances in the specified patch group."},{"ref":"AWS.SSM.html#describe_instance_patches/3","title":"AWS.SSM.describe_instance_patches/3","type":"function","doc":"Retrieves information about the patches on the specified instance and their state relative to the patch baseline being used for the instance."},{"ref":"AWS.SSM.html#describe_inventory_deletions/3","title":"AWS.SSM.describe_inventory_deletions/3","type":"function","doc":"Describes a specific delete inventory operation."},{"ref":"AWS.SSM.html#describe_maintenance_window_execution_task_invocations/3","title":"AWS.SSM.describe_maintenance_window_execution_task_invocations/3","type":"function","doc":"Retrieves the individual task executions (one per target) for a particular task run as part of a maintenance window execution."},{"ref":"AWS.SSM.html#describe_maintenance_window_execution_tasks/3","title":"AWS.SSM.describe_maintenance_window_execution_tasks/3","type":"function","doc":"For a given maintenance window execution, lists the tasks that were run."},{"ref":"AWS.SSM.html#describe_maintenance_window_executions/3","title":"AWS.SSM.describe_maintenance_window_executions/3","type":"function","doc":"Lists the executions of a maintenance window. This includes information about when the maintenance window was scheduled to be active, and information about tasks registered and run with the maintenance window."},{"ref":"AWS.SSM.html#describe_maintenance_window_schedule/3","title":"AWS.SSM.describe_maintenance_window_schedule/3","type":"function","doc":"Retrieves information about upcoming executions of a maintenance window."},{"ref":"AWS.SSM.html#describe_maintenance_window_targets/3","title":"AWS.SSM.describe_maintenance_window_targets/3","type":"function","doc":"Lists the targets registered with the maintenance window."},{"ref":"AWS.SSM.html#describe_maintenance_window_tasks/3","title":"AWS.SSM.describe_maintenance_window_tasks/3","type":"function","doc":"Lists the tasks in a maintenance window."},{"ref":"AWS.SSM.html#describe_maintenance_windows/3","title":"AWS.SSM.describe_maintenance_windows/3","type":"function","doc":"Retrieves the maintenance windows in an AWS account."},{"ref":"AWS.SSM.html#describe_maintenance_windows_for_target/3","title":"AWS.SSM.describe_maintenance_windows_for_target/3","type":"function","doc":"Retrieves information about the maintenance window targets or tasks that an instance is associated with."},{"ref":"AWS.SSM.html#describe_ops_items/3","title":"AWS.SSM.describe_ops_items/3","type":"function","doc":"Query a set of OpsItems. You must have permission in AWS Identity and Access Management (IAM) to query a list of OpsItems. For more information, see Getting started with OpsCenter in the AWS Systems Manager User Guide. Operations engineers and IT professionals use OpsCenter to view, investigate, and remediate operational issues impacting the performance and health of their AWS resources. For more information, see AWS Systems Manager OpsCenter in the AWS Systems Manager User Guide."},{"ref":"AWS.SSM.html#describe_parameters/3","title":"AWS.SSM.describe_parameters/3","type":"function","doc":"Get information about a parameter. Request results are returned on a best-effort basis. If you specify MaxResults in the request, the response includes information up to the limit specified. The number of items returned, however, can be between zero and the value of MaxResults. If the service reaches an internal limit while processing the results, it stops the operation and returns the matching values up to that point and a NextToken. You can specify the NextToken in a subsequent call to get the next set of results."},{"ref":"AWS.SSM.html#describe_patch_baselines/3","title":"AWS.SSM.describe_patch_baselines/3","type":"function","doc":"Lists the patch baselines in your AWS account."},{"ref":"AWS.SSM.html#describe_patch_group_state/3","title":"AWS.SSM.describe_patch_group_state/3","type":"function","doc":"Returns high-level aggregated patch compliance state for a patch group."},{"ref":"AWS.SSM.html#describe_patch_groups/3","title":"AWS.SSM.describe_patch_groups/3","type":"function","doc":"Lists all patch groups that have been registered with patch baselines."},{"ref":"AWS.SSM.html#describe_patch_properties/3","title":"AWS.SSM.describe_patch_properties/3","type":"function","doc":"Lists the properties of available patches organized by product, product family, classification, severity, and other properties of available patches. You can use the reported properties in the filters you specify in requests for actions such as CreatePatchBaseline, UpdatePatchBaseline, DescribeAvailablePatches, and DescribePatchBaselines. The following section lists the properties that can be used in filters for each major operating system type: Definitions AMAZON_LINUX Valid properties: PRODUCT, CLASSIFICATION, SEVERITY AMAZON_LINUX_2 Valid properties: PRODUCT, CLASSIFICATION, SEVERITY CENTOS Valid properties: PRODUCT, CLASSIFICATION, SEVERITY DEBIAN Valid properties: PRODUCT, PRIORITY ORACLE_LINUX Valid properties: PRODUCT, CLASSIFICATION, SEVERITY REDHAT_ENTERPRISE_LINUX Valid properties: PRODUCT, CLASSIFICATION, SEVERITY SUSE Valid properties: PRODUCT, CLASSIFICATION, SEVERITY UBUNTU Valid properties: PRODUCT, PRIORITY WINDOWS Valid properties: PRODUCT, PRODUCT_FAMILY, CLASSIFICATION, MSRC_SEVERITY"},{"ref":"AWS.SSM.html#describe_sessions/3","title":"AWS.SSM.describe_sessions/3","type":"function","doc":"Retrieves a list of all active sessions (both connected and disconnected) or terminated sessions from the past 30 days."},{"ref":"AWS.SSM.html#get_automation_execution/3","title":"AWS.SSM.get_automation_execution/3","type":"function","doc":"Get detailed information about a particular Automation execution."},{"ref":"AWS.SSM.html#get_calendar_state/3","title":"AWS.SSM.get_calendar_state/3","type":"function","doc":"Gets the state of the AWS Systems Manager Change Calendar at an optional, specified time. If you specify a time, GetCalendarState returns the state of the calendar at a specific time, and returns the next time that the Change Calendar state will transition. If you do not specify a time, GetCalendarState assumes the current time. Change Calendar entries have two possible states: OPEN or CLOSED. If you specify more than one calendar in a request, the command returns the status of OPEN only if all calendars in the request are open. If one or more calendars in the request are closed, the status returned is CLOSED. For more information about Systems Manager Change Calendar, see AWS Systems Manager Change Calendar in the AWS Systems Manager User Guide."},{"ref":"AWS.SSM.html#get_command_invocation/3","title":"AWS.SSM.get_command_invocation/3","type":"function","doc":"Returns detailed information about command execution for an invocation or plugin."},{"ref":"AWS.SSM.html#get_connection_status/3","title":"AWS.SSM.get_connection_status/3","type":"function","doc":"Retrieves the Session Manager connection status for an instance to determine whether it is running and ready to receive Session Manager connections."},{"ref":"AWS.SSM.html#get_default_patch_baseline/3","title":"AWS.SSM.get_default_patch_baseline/3","type":"function","doc":"Retrieves the default patch baseline. Note that Systems Manager supports creating multiple default patch baselines. For example, you can create a default patch baseline for each operating system. If you do not specify an operating system value, the default patch baseline for Windows is returned."},{"ref":"AWS.SSM.html#get_deployable_patch_snapshot_for_instance/3","title":"AWS.SSM.get_deployable_patch_snapshot_for_instance/3","type":"function","doc":"Retrieves the current snapshot for the patch baseline the instance uses. This API is primarily used by the AWS-RunPatchBaseline Systems Manager document."},{"ref":"AWS.SSM.html#get_document/3","title":"AWS.SSM.get_document/3","type":"function","doc":"Gets the contents of the specified Systems Manager document."},{"ref":"AWS.SSM.html#get_inventory/3","title":"AWS.SSM.get_inventory/3","type":"function","doc":"Query inventory information."},{"ref":"AWS.SSM.html#get_inventory_schema/3","title":"AWS.SSM.get_inventory_schema/3","type":"function","doc":"Return a list of inventory type names for the account, or return a list of attribute names for a specific Inventory item type."},{"ref":"AWS.SSM.html#get_maintenance_window/3","title":"AWS.SSM.get_maintenance_window/3","type":"function","doc":"Retrieves a maintenance window."},{"ref":"AWS.SSM.html#get_maintenance_window_execution/3","title":"AWS.SSM.get_maintenance_window_execution/3","type":"function","doc":"Retrieves details about a specific a maintenance window execution."},{"ref":"AWS.SSM.html#get_maintenance_window_execution_task/3","title":"AWS.SSM.get_maintenance_window_execution_task/3","type":"function","doc":"Retrieves the details about a specific task run as part of a maintenance window execution."},{"ref":"AWS.SSM.html#get_maintenance_window_execution_task_invocation/3","title":"AWS.SSM.get_maintenance_window_execution_task_invocation/3","type":"function","doc":"Retrieves information about a specific task running on a specific target."},{"ref":"AWS.SSM.html#get_maintenance_window_task/3","title":"AWS.SSM.get_maintenance_window_task/3","type":"function","doc":"Lists the tasks in a maintenance window."},{"ref":"AWS.SSM.html#get_ops_item/3","title":"AWS.SSM.get_ops_item/3","type":"function","doc":"Get information about an OpsItem by using the ID. You must have permission in AWS Identity and Access Management (IAM) to view information about an OpsItem. For more information, see Getting started with OpsCenter in the AWS Systems Manager User Guide. Operations engineers and IT professionals use OpsCenter to view, investigate, and remediate operational issues impacting the performance and health of their AWS resources. For more information, see AWS Systems Manager OpsCenter in the AWS Systems Manager User Guide."},{"ref":"AWS.SSM.html#get_ops_summary/3","title":"AWS.SSM.get_ops_summary/3","type":"function","doc":"View a summary of OpsItems based on specified filters and aggregators."},{"ref":"AWS.SSM.html#get_parameter/3","title":"AWS.SSM.get_parameter/3","type":"function","doc":"Get information about a parameter by using the parameter name. Don&#39;t confuse this API action with the GetParameters API action."},{"ref":"AWS.SSM.html#get_parameter_history/3","title":"AWS.SSM.get_parameter_history/3","type":"function","doc":"Query a list of all parameters used by the AWS account."},{"ref":"AWS.SSM.html#get_parameters/3","title":"AWS.SSM.get_parameters/3","type":"function","doc":"Get details of a parameter. Don&#39;t confuse this API action with the GetParameter API action."},{"ref":"AWS.SSM.html#get_parameters_by_path/3","title":"AWS.SSM.get_parameters_by_path/3","type":"function","doc":"Retrieve information about one or more parameters in a specific hierarchy. Request results are returned on a best-effort basis. If you specify MaxResults in the request, the response includes information up to the limit specified. The number of items returned, however, can be between zero and the value of MaxResults. If the service reaches an internal limit while processing the results, it stops the operation and returns the matching values up to that point and a NextToken. You can specify the NextToken in a subsequent call to get the next set of results."},{"ref":"AWS.SSM.html#get_patch_baseline/3","title":"AWS.SSM.get_patch_baseline/3","type":"function","doc":"Retrieves information about a patch baseline."},{"ref":"AWS.SSM.html#get_patch_baseline_for_patch_group/3","title":"AWS.SSM.get_patch_baseline_for_patch_group/3","type":"function","doc":"Retrieves the patch baseline that should be used for the specified patch group."},{"ref":"AWS.SSM.html#get_service_setting/3","title":"AWS.SSM.get_service_setting/3","type":"function","doc":"ServiceSetting is an account-level setting for an AWS service. This setting defines how a user interacts with or uses a service or a feature of a service. For example, if an AWS service charges money to the account based on feature or service usage, then the AWS service team might create a default setting of &quot;false&quot;. This means the user can&#39;t use this feature unless they change the setting to &quot;true&quot; and intentionally opt in for a paid feature. Services map a SettingId object to a setting value. AWS services teams define the default value for a SettingId. You can&#39;t create a new SettingId, but you can overwrite the default value if you have the ssm:UpdateServiceSetting permission for the setting. Use the UpdateServiceSetting API action to change the default setting. Or use the ResetServiceSetting to change the value back to the original value defined by the AWS service team. Query the current service setting for the account."},{"ref":"AWS.SSM.html#label_parameter_version/3","title":"AWS.SSM.label_parameter_version/3","type":"function","doc":"A parameter label is a user-defined alias to help you manage different versions of a parameter. When you modify a parameter, Systems Manager automatically saves a new version and increments the version number by one. A label can help you remember the purpose of a parameter when there are multiple versions. Parameter labels have the following requirements and restrictions. A version of a parameter can have a maximum of 10 labels. You can&#39;t attach the same label to different versions of the same parameter. For example, if version 1 has the label Production, then you can&#39;t attach Production to version 2. You can move a label from one version of a parameter to another. You can&#39;t create a label when you create a new parameter. You must attach a label to a specific version of a parameter. You can&#39;t delete a parameter label. If you no longer want to use a parameter label, then you must move it to a different version of a parameter. A label can have a maximum of 100 characters. Labels can contain letters (case sensitive), numbers, periods (.), hyphens (-), or underscores (_). Labels can&#39;t begin with a number, &quot;aws,&quot; or &quot;ssm&quot; (not case sensitive). If a label fails to meet these requirements, then the label is not associated with a parameter and the system displays it in the list of InvalidLabels."},{"ref":"AWS.SSM.html#list_association_versions/3","title":"AWS.SSM.list_association_versions/3","type":"function","doc":"Retrieves all versions of an association for a specific association ID."},{"ref":"AWS.SSM.html#list_associations/3","title":"AWS.SSM.list_associations/3","type":"function","doc":"Returns all State Manager associations in the current AWS account and Region. You can limit the results to a specific State Manager association document or instance by specifying a filter."},{"ref":"AWS.SSM.html#list_command_invocations/3","title":"AWS.SSM.list_command_invocations/3","type":"function","doc":"An invocation is copy of a command sent to a specific instance. A command can apply to one or more instances. A command invocation applies to one instance. For example, if a user runs SendCommand against three instances, then a command invocation is created for each requested instance ID. ListCommandInvocations provide status about command execution."},{"ref":"AWS.SSM.html#list_commands/3","title":"AWS.SSM.list_commands/3","type":"function","doc":"Lists the commands requested by users of the AWS account."},{"ref":"AWS.SSM.html#list_compliance_items/3","title":"AWS.SSM.list_compliance_items/3","type":"function","doc":"For a specified resource ID, this API action returns a list of compliance statuses for different resource types. Currently, you can only specify one resource ID per call. List results depend on the criteria specified in the filter."},{"ref":"AWS.SSM.html#list_compliance_summaries/3","title":"AWS.SSM.list_compliance_summaries/3","type":"function","doc":"Returns a summary count of compliant and non-compliant resources for a compliance type. For example, this call can return State Manager associations, patches, or custom compliance types according to the filter criteria that you specify."},{"ref":"AWS.SSM.html#list_document_versions/3","title":"AWS.SSM.list_document_versions/3","type":"function","doc":"List all versions for a document."},{"ref":"AWS.SSM.html#list_documents/3","title":"AWS.SSM.list_documents/3","type":"function","doc":"Returns all Systems Manager (SSM) documents in the current AWS account and Region. You can limit the results of this request by using a filter."},{"ref":"AWS.SSM.html#list_inventory_entries/3","title":"AWS.SSM.list_inventory_entries/3","type":"function","doc":"A list of inventory items returned by the request."},{"ref":"AWS.SSM.html#list_resource_compliance_summaries/3","title":"AWS.SSM.list_resource_compliance_summaries/3","type":"function","doc":"Returns a resource-level summary count. The summary includes information about compliant and non-compliant statuses and detailed compliance-item severity counts, according to the filter criteria you specify."},{"ref":"AWS.SSM.html#list_resource_data_sync/3","title":"AWS.SSM.list_resource_data_sync/3","type":"function","doc":"Lists your resource data sync configurations. Includes information about the last time a sync attempted to start, the last sync status, and the last time a sync successfully completed. The number of sync configurations might be too large to return using a single call to ListResourceDataSync. You can limit the number of sync configurations returned by using the MaxResults parameter. To determine whether there are more sync configurations to list, check the value of NextToken in the output. If there are more sync configurations to list, you can request them by specifying the NextToken returned in the call to the parameter of a subsequent call."},{"ref":"AWS.SSM.html#list_tags_for_resource/3","title":"AWS.SSM.list_tags_for_resource/3","type":"function","doc":"Returns a list of the tags assigned to the specified resource."},{"ref":"AWS.SSM.html#modify_document_permission/3","title":"AWS.SSM.modify_document_permission/3","type":"function","doc":"Shares a Systems Manager document publicly or privately. If you share a document privately, you must specify the AWS user account IDs for those people who can use the document. If you share a document publicly, you must specify All as the account ID."},{"ref":"AWS.SSM.html#put_compliance_items/3","title":"AWS.SSM.put_compliance_items/3","type":"function","doc":"Registers a compliance type and other compliance details on a designated resource. This action lets you register custom compliance details with a resource. This call overwrites existing compliance information on the resource, so you must provide a full list of compliance items each time that you send the request. ComplianceType can be one of the following: ExecutionId: The execution ID when the patch, association, or custom compliance item was applied. ExecutionType: Specify patch, association, or Custom:string. ExecutionTime. The time the patch, association, or custom compliance item was applied to the instance. Id: The patch, association, or custom compliance ID. Title: A title. Status: The status of the compliance item. For example, approved for patches, or Failed for associations. Severity: A patch severity. For example, critical. DocumentName: A SSM document name. For example, AWS-RunPatchBaseline. DocumentVersion: An SSM document version number. For example, 4. Classification: A patch classification. For example, security updates. PatchBaselineId: A patch baseline ID. PatchSeverity: A patch severity. For example, Critical. PatchState: A patch state. For example, InstancesWithFailedPatches. PatchGroup: The name of a patch group. InstalledTime: The time the association, patch, or custom compliance item was applied to the resource. Specify the time by using the following format: yyyy-MM-dd&#39;T&#39;HH:mm:ss&#39;Z&#39;"},{"ref":"AWS.SSM.html#put_inventory/3","title":"AWS.SSM.put_inventory/3","type":"function","doc":"Bulk update custom inventory items on one more instance. The request adds an inventory item, if it doesn&#39;t already exist, or updates an inventory item, if it does exist."},{"ref":"AWS.SSM.html#put_parameter/3","title":"AWS.SSM.put_parameter/3","type":"function","doc":"Add a parameter to the system."},{"ref":"AWS.SSM.html#register_default_patch_baseline/3","title":"AWS.SSM.register_default_patch_baseline/3","type":"function","doc":"Defines the default patch baseline for the relevant operating system. To reset the AWS predefined patch baseline as the default, specify the full patch baseline ARN as the baseline ID value. For example, for CentOS, specify arn:aws:ssm:us-east-2:733109147000:patchbaseline/pb-0574b43a65ea646ed instead of pb-0574b43a65ea646ed."},{"ref":"AWS.SSM.html#register_patch_baseline_for_patch_group/3","title":"AWS.SSM.register_patch_baseline_for_patch_group/3","type":"function","doc":"Registers a patch baseline for a patch group."},{"ref":"AWS.SSM.html#register_target_with_maintenance_window/3","title":"AWS.SSM.register_target_with_maintenance_window/3","type":"function","doc":"Registers a target with a maintenance window."},{"ref":"AWS.SSM.html#register_task_with_maintenance_window/3","title":"AWS.SSM.register_task_with_maintenance_window/3","type":"function","doc":"Adds a new task to a maintenance window."},{"ref":"AWS.SSM.html#remove_tags_from_resource/3","title":"AWS.SSM.remove_tags_from_resource/3","type":"function","doc":"Removes tag keys from the specified resource."},{"ref":"AWS.SSM.html#reset_service_setting/3","title":"AWS.SSM.reset_service_setting/3","type":"function","doc":"ServiceSetting is an account-level setting for an AWS service. This setting defines how a user interacts with or uses a service or a feature of a service. For example, if an AWS service charges money to the account based on feature or service usage, then the AWS service team might create a default setting of &quot;false&quot;. This means the user can&#39;t use this feature unless they change the setting to &quot;true&quot; and intentionally opt in for a paid feature. Services map a SettingId object to a setting value. AWS services teams define the default value for a SettingId. You can&#39;t create a new SettingId, but you can overwrite the default value if you have the ssm:UpdateServiceSetting permission for the setting. Use the GetServiceSetting API action to view the current value. Use the UpdateServiceSetting API action to change the default setting. Reset the service setting for the account to the default value as provisioned by the AWS service team."},{"ref":"AWS.SSM.html#resume_session/3","title":"AWS.SSM.resume_session/3","type":"function","doc":"Reconnects a session to an instance after it has been disconnected. Connections can be resumed for disconnected sessions, but not terminated sessions. This command is primarily for use by client machines to automatically reconnect during intermittent network issues. It is not intended for any other use."},{"ref":"AWS.SSM.html#send_automation_signal/3","title":"AWS.SSM.send_automation_signal/3","type":"function","doc":"Sends a signal to an Automation execution to change the current behavior or status of the execution."},{"ref":"AWS.SSM.html#send_command/3","title":"AWS.SSM.send_command/3","type":"function","doc":"Runs commands on one or more managed instances."},{"ref":"AWS.SSM.html#start_associations_once/3","title":"AWS.SSM.start_associations_once/3","type":"function","doc":"Use this API action to run an association immediately and only one time. This action can be helpful when troubleshooting associations."},{"ref":"AWS.SSM.html#start_automation_execution/3","title":"AWS.SSM.start_automation_execution/3","type":"function","doc":"Initiates execution of an Automation document."},{"ref":"AWS.SSM.html#start_session/3","title":"AWS.SSM.start_session/3","type":"function","doc":"Initiates a connection to a target (for example, an instance) for a Session Manager session. Returns a URL and token that can be used to open a WebSocket connection for sending input and receiving outputs. AWS CLI usage: start-session is an interactive command that requires the Session Manager plugin to be installed on the client machine making the call. For information, see Install the Session Manager plugin for the AWS CLI in the AWS Systems Manager User Guide. AWS Tools for PowerShell usage: Start-SSMSession is not currently supported by AWS Tools for PowerShell on Windows local machines."},{"ref":"AWS.SSM.html#stop_automation_execution/3","title":"AWS.SSM.stop_automation_execution/3","type":"function","doc":"Stop an Automation that is currently running."},{"ref":"AWS.SSM.html#terminate_session/3","title":"AWS.SSM.terminate_session/3","type":"function","doc":"Permanently ends a session and closes the data connection between the Session Manager client and SSM Agent on the instance. A terminated session cannot be resumed."},{"ref":"AWS.SSM.html#update_association/3","title":"AWS.SSM.update_association/3","type":"function","doc":"Updates an association. You can update the association name and version, the document version, schedule, parameters, and Amazon S3 output. In order to call this API action, your IAM user account, group, or role must be configured with permission to call the DescribeAssociation API action. If you don&#39;t have permission to call DescribeAssociation, then you receive the following error: An error occurred (AccessDeniedException) when calling the UpdateAssociation operation: User: &lt;user_arn&gt; is not authorized to perform: ssm:DescribeAssociation on resource: &lt;resource_arn&gt; When you update an association, the association immediately runs against the specified targets."},{"ref":"AWS.SSM.html#update_association_status/3","title":"AWS.SSM.update_association_status/3","type":"function","doc":"Updates the status of the Systems Manager document associated with the specified instance."},{"ref":"AWS.SSM.html#update_document/3","title":"AWS.SSM.update_document/3","type":"function","doc":"Updates one or more values for an SSM document."},{"ref":"AWS.SSM.html#update_document_default_version/3","title":"AWS.SSM.update_document_default_version/3","type":"function","doc":"Set the default version of a document."},{"ref":"AWS.SSM.html#update_maintenance_window/3","title":"AWS.SSM.update_maintenance_window/3","type":"function","doc":"Updates an existing maintenance window. Only specified parameters are modified. The value you specify for Duration determines the specific end time for the maintenance window based on the time it begins. No maintenance window tasks are permitted to start after the resulting endtime minus the number of hours you specify for Cutoff. For example, if the maintenance window starts at 3 PM, the duration is three hours, and the value you specify for Cutoff is one hour, no maintenance window tasks can start after 5 PM."},{"ref":"AWS.SSM.html#update_maintenance_window_target/3","title":"AWS.SSM.update_maintenance_window_target/3","type":"function","doc":"Modifies the target of an existing maintenance window. You can change the following: Name Description Owner IDs for an ID target Tags for a Tag target From any supported tag type to another. The three supported tag types are ID target, Tag target, and resource group. For more information, see Target. If a parameter is null, then the corresponding field is not modified."},{"ref":"AWS.SSM.html#update_maintenance_window_task/3","title":"AWS.SSM.update_maintenance_window_task/3","type":"function","doc":"Modifies a task assigned to a maintenance window. You can&#39;t change the task type, but you can change the following values: TaskARN. For example, you can change a RUN_COMMAND task from AWS-RunPowerShellScript to AWS-RunShellScript. ServiceRoleArn TaskInvocationParameters Priority MaxConcurrency MaxErrors If the value for a parameter in UpdateMaintenanceWindowTask is null, then the corresponding field is not modified. If you set Replace to true, then all fields required by the RegisterTaskWithMaintenanceWindow action are required for this request. Optional fields that aren&#39;t specified are set to null. When you update a maintenance window task that has options specified in TaskInvocationParameters, you must provide again all the TaskInvocationParameters values that you want to retain. The values you do not specify again are removed. For example, suppose that when you registered a Run Command task, you specified TaskInvocationParameters values for Comment, NotificationConfig, and OutputS3BucketName. If you update the maintenance window task and specify only a different OutputS3BucketName value, the values for Comment and NotificationConfig are removed."},{"ref":"AWS.SSM.html#update_managed_instance_role/3","title":"AWS.SSM.update_managed_instance_role/3","type":"function","doc":"Changes the Amazon Identity and Access Management (IAM) role that is assigned to the on-premises instance or virtual machines (VM). IAM roles are first assigned to these hybrid instances during the activation process. For more information, see CreateActivation."},{"ref":"AWS.SSM.html#update_ops_item/3","title":"AWS.SSM.update_ops_item/3","type":"function","doc":"Edit or change an OpsItem. You must have permission in AWS Identity and Access Management (IAM) to update an OpsItem. For more information, see Getting started with OpsCenter in the AWS Systems Manager User Guide. Operations engineers and IT professionals use OpsCenter to view, investigate, and remediate operational issues impacting the performance and health of their AWS resources. For more information, see AWS Systems Manager OpsCenter in the AWS Systems Manager User Guide."},{"ref":"AWS.SSM.html#update_patch_baseline/3","title":"AWS.SSM.update_patch_baseline/3","type":"function","doc":"Modifies an existing patch baseline. Fields not specified in the request are left unchanged. For information about valid key and value pairs in PatchFilters for each supported operating system type, see PatchFilter."},{"ref":"AWS.SSM.html#update_resource_data_sync/3","title":"AWS.SSM.update_resource_data_sync/3","type":"function","doc":"Update a resource data sync. After you create a resource data sync for a Region, you can&#39;t change the account options for that sync. For example, if you create a sync in the us-east-2 (Ohio) Region and you choose the Include only the current account option, you can&#39;t edit that sync later and choose the Include all accounts from my AWS Organizations configuration option. Instead, you must delete the first resource data sync, and create a new one. This API action only supports a resource data sync that was created with a SyncFromSource SyncType."},{"ref":"AWS.SSM.html#update_service_setting/3","title":"AWS.SSM.update_service_setting/3","type":"function","doc":"ServiceSetting is an account-level setting for an AWS service. This setting defines how a user interacts with or uses a service or a feature of a service. For example, if an AWS service charges money to the account based on feature or service usage, then the AWS service team might create a default setting of &quot;false&quot;. This means the user can&#39;t use this feature unless they change the setting to &quot;true&quot; and intentionally opt in for a paid feature. Services map a SettingId object to a setting value. AWS services teams define the default value for a SettingId. You can&#39;t create a new SettingId, but you can overwrite the default value if you have the ssm:UpdateServiceSetting permission for the setting. Use the GetServiceSetting API action to view the current value. Or, use the ResetServiceSetting to change the value back to the original value defined by the AWS service team. Update the service setting for the account."},{"ref":"AWS.SSO.html","title":"AWS.SSO","type":"module","doc":"AWS Single Sign-On Portal is a web service that makes it easy for you to assign user access to AWS SSO resources such as the user portal. Users can get AWS account applications and roles assigned to them and get federated into the application. For general information about AWS SSO, see What is AWS Single Sign-On? in the AWS SSO User Guide. This API reference guide describes the AWS SSO Portal operations that you can call programatically and includes detailed information on data types and errors. AWS provides SDKs that consist of libraries and sample code for various programming languages and platforms, such as Java, Ruby, .Net, iOS, or Android. The SDKs provide a convenient way to create programmatic access to AWS SSO and other AWS services. For more information about the AWS SDKs, including how to download and install them, see Tools for Amazon Web Services."},{"ref":"AWS.SSO.html#get_role_credentials/5","title":"AWS.SSO.get_role_credentials/5","type":"function","doc":"Returns the STS short-term credentials for a given role name that is assigned to the user."},{"ref":"AWS.SSO.html#list_account_roles/6","title":"AWS.SSO.list_account_roles/6","type":"function","doc":"Lists all roles that are assigned to the user for a given AWS account."},{"ref":"AWS.SSO.html#list_accounts/5","title":"AWS.SSO.list_accounts/5","type":"function","doc":"Lists all AWS accounts assigned to the user. These AWS accounts are assigned by the administrator of the account. For more information, see Assign User Access in the AWS SSO User Guide. This operation returns a paginated response."},{"ref":"AWS.SSO.html#logout/3","title":"AWS.SSO.logout/3","type":"function","doc":"Removes the client- and server-side session that is associated with the user."},{"ref":"AWS.SSOAdmin.html","title":"AWS.SSOAdmin","type":"module","doc":""},{"ref":"AWS.SSOAdmin.html#attach_managed_policy_to_permission_set/3","title":"AWS.SSOAdmin.attach_managed_policy_to_permission_set/3","type":"function","doc":"Attaches an IAM managed policy ARN to a permission set. If the permission set is already referenced by one or more account assignments, you will need to call ProvisionPermissionSet after this action to apply the corresponding IAM policy updates to all assigned accounts."},{"ref":"AWS.SSOAdmin.html#create_account_assignment/3","title":"AWS.SSOAdmin.create_account_assignment/3","type":"function","doc":"Assigns access to a principal for a specified AWS account using a specified permission set. The term principal here refers to a user or group that is defined in AWS SSO. As part of a successful CreateAccountAssignment call, the specified permission set will automatically be provisioned to the account in the form of an IAM policy attached to the SSO-created IAM role. If the permission set is subsequently updated, the corresponding IAM policies attached to roles in your accounts will not be updated automatically. In this case, you will need to call ProvisionPermissionSet to make these updates."},{"ref":"AWS.SSOAdmin.html#create_permission_set/3","title":"AWS.SSOAdmin.create_permission_set/3","type":"function","doc":"Creates a permission set within a specified SSO instance. To grant users and groups access to AWS account resources, use CreateAccountAssignment."},{"ref":"AWS.SSOAdmin.html#delete_account_assignment/3","title":"AWS.SSOAdmin.delete_account_assignment/3","type":"function","doc":"Deletes a principal&#39;s access from a specified AWS account using a specified permission set."},{"ref":"AWS.SSOAdmin.html#delete_inline_policy_from_permission_set/3","title":"AWS.SSOAdmin.delete_inline_policy_from_permission_set/3","type":"function","doc":"Deletes the inline policy from a specified permission set."},{"ref":"AWS.SSOAdmin.html#delete_permission_set/3","title":"AWS.SSOAdmin.delete_permission_set/3","type":"function","doc":"Deletes the specified permission set."},{"ref":"AWS.SSOAdmin.html#describe_account_assignment_creation_status/3","title":"AWS.SSOAdmin.describe_account_assignment_creation_status/3","type":"function","doc":"Describes the status of the assignment creation request."},{"ref":"AWS.SSOAdmin.html#describe_account_assignment_deletion_status/3","title":"AWS.SSOAdmin.describe_account_assignment_deletion_status/3","type":"function","doc":"Describes the status of the assignment deletion request."},{"ref":"AWS.SSOAdmin.html#describe_permission_set/3","title":"AWS.SSOAdmin.describe_permission_set/3","type":"function","doc":"Gets the details of the permission set."},{"ref":"AWS.SSOAdmin.html#describe_permission_set_provisioning_status/3","title":"AWS.SSOAdmin.describe_permission_set_provisioning_status/3","type":"function","doc":"Describes the status for the given permission set provisioning request."},{"ref":"AWS.SSOAdmin.html#detach_managed_policy_from_permission_set/3","title":"AWS.SSOAdmin.detach_managed_policy_from_permission_set/3","type":"function","doc":"Detaches the attached IAM managed policy ARN from the specified permission set."},{"ref":"AWS.SSOAdmin.html#get_inline_policy_for_permission_set/3","title":"AWS.SSOAdmin.get_inline_policy_for_permission_set/3","type":"function","doc":"Obtains the inline policy assigned to the permission set."},{"ref":"AWS.SSOAdmin.html#list_account_assignment_creation_status/3","title":"AWS.SSOAdmin.list_account_assignment_creation_status/3","type":"function","doc":"Lists the status of the AWS account assignment creation requests for a specified SSO instance."},{"ref":"AWS.SSOAdmin.html#list_account_assignment_deletion_status/3","title":"AWS.SSOAdmin.list_account_assignment_deletion_status/3","type":"function","doc":"Lists the status of the AWS account assignment deletion requests for a specified SSO instance."},{"ref":"AWS.SSOAdmin.html#list_account_assignments/3","title":"AWS.SSOAdmin.list_account_assignments/3","type":"function","doc":"Lists the assignee of the specified AWS account with the specified permission set."},{"ref":"AWS.SSOAdmin.html#list_accounts_for_provisioned_permission_set/3","title":"AWS.SSOAdmin.list_accounts_for_provisioned_permission_set/3","type":"function","doc":"Lists all the AWS accounts where the specified permission set is provisioned."},{"ref":"AWS.SSOAdmin.html#list_instances/3","title":"AWS.SSOAdmin.list_instances/3","type":"function","doc":"Lists the SSO instances that the caller has access to."},{"ref":"AWS.SSOAdmin.html#list_managed_policies_in_permission_set/3","title":"AWS.SSOAdmin.list_managed_policies_in_permission_set/3","type":"function","doc":"Lists the IAM managed policy that is attached to a specified permission set."},{"ref":"AWS.SSOAdmin.html#list_permission_set_provisioning_status/3","title":"AWS.SSOAdmin.list_permission_set_provisioning_status/3","type":"function","doc":"Lists the status of the permission set provisioning requests for a specified SSO instance."},{"ref":"AWS.SSOAdmin.html#list_permission_sets/3","title":"AWS.SSOAdmin.list_permission_sets/3","type":"function","doc":"Lists the PermissionSets in an SSO instance."},{"ref":"AWS.SSOAdmin.html#list_permission_sets_provisioned_to_account/3","title":"AWS.SSOAdmin.list_permission_sets_provisioned_to_account/3","type":"function","doc":"Lists all the permission sets that are provisioned to a specified AWS account."},{"ref":"AWS.SSOAdmin.html#list_tags_for_resource/3","title":"AWS.SSOAdmin.list_tags_for_resource/3","type":"function","doc":"Lists the tags that are attached to a specified resource."},{"ref":"AWS.SSOAdmin.html#provision_permission_set/3","title":"AWS.SSOAdmin.provision_permission_set/3","type":"function","doc":"The process by which a specified permission set is provisioned to the specified target."},{"ref":"AWS.SSOAdmin.html#put_inline_policy_to_permission_set/3","title":"AWS.SSOAdmin.put_inline_policy_to_permission_set/3","type":"function","doc":"Attaches an IAM inline policy to a permission set. If the permission set is already referenced by one or more account assignments, you will need to call ProvisionPermissionSet after this action to apply the corresponding IAM policy updates to all assigned accounts."},{"ref":"AWS.SSOAdmin.html#tag_resource/3","title":"AWS.SSOAdmin.tag_resource/3","type":"function","doc":"Associates a set of tags with a specified resource."},{"ref":"AWS.SSOAdmin.html#untag_resource/3","title":"AWS.SSOAdmin.untag_resource/3","type":"function","doc":"Disassociates a set of tags from a specified resource."},{"ref":"AWS.SSOAdmin.html#update_permission_set/3","title":"AWS.SSOAdmin.update_permission_set/3","type":"function","doc":"Updates an existing permission set."},{"ref":"AWS.SSOOIDC.html","title":"AWS.SSOOIDC","type":"module","doc":"AWS Single Sign-On (SSO) OpenID Connect (OIDC) is a web service that enables a client (such as AWS CLI or a native application) to register with AWS SSO. The service also enables the client to fetch the users access token upon successful authentication and authorization with AWS SSO. This service conforms with the OAuth 2.0 based implementation of the device authorization grant standard (https://tools.ietf.org/html/rfc8628). For general information about AWS SSO, see What is AWS Single Sign-On? in the AWS SSO User Guide. This API reference guide describes the AWS SSO OIDC operations that you can call programatically and includes detailed information on data types and errors. AWS provides SDKs that consist of libraries and sample code for various programming languages and platforms such as Java, Ruby, .Net, iOS, and Android. The SDKs provide a convenient way to create programmatic access to AWS SSO and other AWS services. For more information about the AWS SDKs, including how to download and install them, see Tools for Amazon Web Services."},{"ref":"AWS.SSOOIDC.html#create_token/3","title":"AWS.SSOOIDC.create_token/3","type":"function","doc":"Creates and returns an access token for the authorized client. The access token issued will be used to fetch short-term credentials for the assigned roles in the AWS account."},{"ref":"AWS.SSOOIDC.html#register_client/3","title":"AWS.SSOOIDC.register_client/3","type":"function","doc":"Registers a client with AWS SSO. This allows clients to initiate device authorization. The output should be persisted for reuse through many authentication requests."},{"ref":"AWS.SSOOIDC.html#start_device_authorization/3","title":"AWS.SSOOIDC.start_device_authorization/3","type":"function","doc":"Initiates device authorization by requesting a pair of verification codes from the authorization service."},{"ref":"AWS.STS.html","title":"AWS.STS","type":"module","doc":"AWS Security Token Service AWS Security Token Service (STS) enables you to request temporary, limited-privilege credentials for AWS Identity and Access Management (IAM) users or for users that you authenticate (federated users). This guide provides descriptions of the STS API. For more information about using this service, see Temporary Security Credentials."},{"ref":"AWS.STS.html#assume_role/3","title":"AWS.STS.assume_role/3","type":"function","doc":"Returns a set of temporary security credentials that you can use to access AWS resources that you might not normally have access to. These temporary credentials consist of an access key ID, a secret access key, and a security token. Typically, you use AssumeRole within your account or for cross-account access. For a comparison of AssumeRole with other API operations that produce temporary credentials, see Requesting Temporary Security Credentials and Comparing the AWS STS API operations in the IAM User Guide. You cannot use AWS account root user credentials to call AssumeRole. You must use credentials for an IAM user or an IAM role to call AssumeRole. For cross-account access, imagine that you own multiple accounts and need to access resources in each account. You could create long-term credentials in each account to access those resources. However, managing all those credentials and remembering which one can access which account can be time consuming. Instead, you can create one set of long-term credentials in one account. Then use temporary security credentials to access all the other accounts by assuming roles in those accounts. For more information about roles, see IAM Roles in the IAM User Guide. Session Duration By default, the temporary security credentials created by AssumeRole last for one hour. However, you can use the optional DurationSeconds parameter to specify the duration of your session. You can provide a value from 900 seconds (15 minutes) up to the maximum session duration setting for the role. This setting can have a value from 1 hour to 12 hours. To learn how to view the maximum value for your role, see View the Maximum Session Duration Setting for a Role in the IAM User Guide. The maximum session duration limit applies when you use the AssumeRole* API operations or the assume-role* CLI commands. However the limit does not apply when you use those operations to create a console URL. For more information, see Using IAM Roles in the IAM User Guide. Permissions The temporary security credentials created by AssumeRole can be used to make API calls to any AWS service with the following exception: You cannot call the AWS STS GetFederationToken or GetSessionToken API operations. (Optional) You can pass inline or managed session policies to this operation. You can pass a single JSON policy document to use as an inline session policy. You can also specify up to 10 managed policies to use as managed session policies. The plain text that you use for both inline and managed session policies can&#39;t exceed 2,048 characters. Passing policies to this operation returns new temporary credentials. The resulting session&#39;s permissions are the intersection of the role&#39;s identity-based policy and the session policies. You can use the role&#39;s temporary credentials in subsequent AWS API calls to access resources in the account that owns the role. You cannot use session policies to grant more permissions than those allowed by the identity-based policy of the role that is being assumed. For more information, see Session Policies in the IAM User Guide. To assume a role from a different account, your AWS account must be trusted by the role. The trust relationship is defined in the role&#39;s trust policy when the role is created. That trust policy states which accounts are allowed to delegate that access to users in the account. A user who wants to access a role in a different account must also have permissions that are delegated from the user account administrator. The administrator must attach a policy that allows the user to call AssumeRole for the ARN of the role in the other account. If the user is in the same account as the role, then you can do either of the following: Attach a policy to the user (identical to the previous user in a different account). Add the user as a principal directly in the role&#39;s trust policy. In this case, the trust policy acts as an IAM resource-based policy. Users in the same account as the role do not need explicit permission to assume the role. For more information about trust policies and resource-based policies, see IAM Policies in the IAM User Guide. Tags (Optional) You can pass tag key-value pairs to your session. These tags are called session tags. For more information about session tags, see Passing Session Tags in STS in the IAM User Guide. An administrator must grant you the permissions necessary to pass session tags. The administrator can also create granular permissions to allow you to pass only specific session tags. For more information, see Tutorial: Using Tags for Attribute-Based Access Control in the IAM User Guide. You can set the session tags as transitive. Transitive tags persist during role chaining. For more information, see Chaining Roles with Session Tags in the IAM User Guide. Using MFA with AssumeRole (Optional) You can include multi-factor authentication (MFA) information when you call AssumeRole. This is useful for cross-account scenarios to ensure that the user that assumes the role has been authenticated with an AWS MFA device. In that scenario, the trust policy of the role being assumed includes a condition that tests for MFA authentication. If the caller does not include valid MFA information, the request to assume the role is denied. The condition in a trust policy that tests for MFA authentication might look like the following example. &quot;Condition&quot;: {&quot;Bool&quot;: {&quot;aws:MultiFactorAuthPresent&quot;: true}} For more information, see Configuring MFA-Protected API Access in the IAM User Guide guide. To use MFA with AssumeRole, you pass values for the SerialNumber and TokenCode parameters. The SerialNumber value identifies the user&#39;s hardware or virtual MFA device. The TokenCode is the time-based one-time password (TOTP) that the MFA device produces."},{"ref":"AWS.STS.html#assume_role_with_s_a_m_l/3","title":"AWS.STS.assume_role_with_s_a_m_l/3","type":"function","doc":"Returns a set of temporary security credentials for users who have been authenticated via a SAML authentication response. This operation provides a mechanism for tying an enterprise identity store or directory to role-based AWS access without user-specific credentials or configuration. For a comparison of AssumeRoleWithSAML with the other API operations that produce temporary credentials, see Requesting Temporary Security Credentials and Comparing the AWS STS API operations in the IAM User Guide. The temporary security credentials returned by this operation consist of an access key ID, a secret access key, and a security token. Applications can use these temporary security credentials to sign calls to AWS services. Session Duration By default, the temporary security credentials created by AssumeRoleWithSAML last for one hour. However, you can use the optional DurationSeconds parameter to specify the duration of your session. Your role session lasts for the duration that you specify, or until the time specified in the SAML authentication response&#39;s SessionNotOnOrAfter value, whichever is shorter. You can provide a DurationSeconds value from 900 seconds (15 minutes) up to the maximum session duration setting for the role. This setting can have a value from 1 hour to 12 hours. To learn how to view the maximum value for your role, see View the Maximum Session Duration Setting for a Role in the IAM User Guide. The maximum session duration limit applies when you use the AssumeRole* API operations or the assume-role* CLI commands. However the limit does not apply when you use those operations to create a console URL. For more information, see Using IAM Roles in the IAM User Guide. Permissions The temporary security credentials created by AssumeRoleWithSAML can be used to make API calls to any AWS service with the following exception: you cannot call the STS GetFederationToken or GetSessionToken API operations. (Optional) You can pass inline or managed session policies to this operation. You can pass a single JSON policy document to use as an inline session policy. You can also specify up to 10 managed policies to use as managed session policies. The plain text that you use for both inline and managed session policies can&#39;t exceed 2,048 characters. Passing policies to this operation returns new temporary credentials. The resulting session&#39;s permissions are the intersection of the role&#39;s identity-based policy and the session policies. You can use the role&#39;s temporary credentials in subsequent AWS API calls to access resources in the account that owns the role. You cannot use session policies to grant more permissions than those allowed by the identity-based policy of the role that is being assumed. For more information, see Session Policies in the IAM User Guide. Calling AssumeRoleWithSAML does not require the use of AWS security credentials. The identity of the caller is validated by using keys in the metadata document that is uploaded for the SAML provider entity for your identity provider. Calling AssumeRoleWithSAML can result in an entry in your AWS CloudTrail logs. The entry includes the value in the NameID element of the SAML assertion. We recommend that you use a NameIDType that is not associated with any personally identifiable information (PII). For example, you could instead use the persistent identifier (urn:oasis:names:tc:SAML:2.0:nameid-format:persistent). Tags (Optional) You can configure your IdP to pass attributes into your SAML assertion as session tags. Each session tag consists of a key name and an associated value. For more information about session tags, see Passing Session Tags in STS in the IAM User Guide. You can pass up to 50 session tags. The plain text session tag keys cant exceed 128 characters and the values cant exceed 256 characters. For these and additional limits, see IAM and STS Character Limits in the IAM User Guide. An AWS conversion compresses the passed session policies and session tags into a packed binary format that has a separate limit. Your request can fail for this limit even if your plain text meets the other requirements. The PackedPolicySize response element indicates by percentage how close the policies and tags for your request are to the upper size limit. You can pass a session tag with the same key as a tag that is attached to the role. When you do, session tags override the role&#39;s tags with the same key. An administrator must grant you the permissions necessary to pass session tags. The administrator can also create granular permissions to allow you to pass only specific session tags. For more information, see Tutorial: Using Tags for Attribute-Based Access Control in the IAM User Guide. You can set the session tags as transitive. Transitive tags persist during role chaining. For more information, see Chaining Roles with Session Tags in the IAM User Guide. SAML Configuration Before your application can call AssumeRoleWithSAML, you must configure your SAML identity provider (IdP) to issue the claims required by AWS. Additionally, you must use AWS Identity and Access Management (IAM) to create a SAML provider entity in your AWS account that represents your identity provider. You must also create an IAM role that specifies this SAML provider in its trust policy. For more information, see the following resources: About SAML 2.0-based Federation in the IAM User Guide. Creating SAML Identity Providers in the IAM User Guide. Configuring a Relying Party and Claims in the IAM User Guide. Creating a Role for SAML 2.0 Federation in the IAM User Guide."},{"ref":"AWS.STS.html#assume_role_with_web_identity/3","title":"AWS.STS.assume_role_with_web_identity/3","type":"function","doc":"Returns a set of temporary security credentials for users who have been authenticated in a mobile or web application with a web identity provider. Example providers include Amazon Cognito, Login with Amazon, Facebook, Google, or any OpenID Connect-compatible identity provider. For mobile applications, we recommend that you use Amazon Cognito. You can use Amazon Cognito with the AWS SDK for iOS Developer Guide and the AWS SDK for Android Developer Guide to uniquely identify a user. You can also supply the user with a consistent identity throughout the lifetime of an application. To learn more about Amazon Cognito, see Amazon Cognito Overview in AWS SDK for Android Developer Guide and Amazon Cognito Overview in the AWS SDK for iOS Developer Guide. Calling AssumeRoleWithWebIdentity does not require the use of AWS security credentials. Therefore, you can distribute an application (for example, on mobile devices) that requests temporary security credentials without including long-term AWS credentials in the application. You also don&#39;t need to deploy server-based proxy services that use long-term AWS credentials. Instead, the identity of the caller is validated by using a token from the web identity provider. For a comparison of AssumeRoleWithWebIdentity with the other API operations that produce temporary credentials, see Requesting Temporary Security Credentials and Comparing the AWS STS API operations in the IAM User Guide. The temporary security credentials returned by this API consist of an access key ID, a secret access key, and a security token. Applications can use these temporary security credentials to sign calls to AWS service API operations. Session Duration By default, the temporary security credentials created by AssumeRoleWithWebIdentity last for one hour. However, you can use the optional DurationSeconds parameter to specify the duration of your session. You can provide a value from 900 seconds (15 minutes) up to the maximum session duration setting for the role. This setting can have a value from 1 hour to 12 hours. To learn how to view the maximum value for your role, see View the Maximum Session Duration Setting for a Role in the IAM User Guide. The maximum session duration limit applies when you use the AssumeRole* API operations or the assume-role* CLI commands. However the limit does not apply when you use those operations to create a console URL. For more information, see Using IAM Roles in the IAM User Guide. Permissions The temporary security credentials created by AssumeRoleWithWebIdentity can be used to make API calls to any AWS service with the following exception: you cannot call the STS GetFederationToken or GetSessionToken API operations. (Optional) You can pass inline or managed session policies to this operation. You can pass a single JSON policy document to use as an inline session policy. You can also specify up to 10 managed policies to use as managed session policies. The plain text that you use for both inline and managed session policies can&#39;t exceed 2,048 characters. Passing policies to this operation returns new temporary credentials. The resulting session&#39;s permissions are the intersection of the role&#39;s identity-based policy and the session policies. You can use the role&#39;s temporary credentials in subsequent AWS API calls to access resources in the account that owns the role. You cannot use session policies to grant more permissions than those allowed by the identity-based policy of the role that is being assumed. For more information, see Session Policies in the IAM User Guide. Tags (Optional) You can configure your IdP to pass attributes into your web identity token as session tags. Each session tag consists of a key name and an associated value. For more information about session tags, see Passing Session Tags in STS in the IAM User Guide. You can pass up to 50 session tags. The plain text session tag keys cant exceed 128 characters and the values cant exceed 256 characters. For these and additional limits, see IAM and STS Character Limits in the IAM User Guide. An AWS conversion compresses the passed session policies and session tags into a packed binary format that has a separate limit. Your request can fail for this limit even if your plain text meets the other requirements. The PackedPolicySize response element indicates by percentage how close the policies and tags for your request are to the upper size limit. You can pass a session tag with the same key as a tag that is attached to the role. When you do, the session tag overrides the role tag with the same key. An administrator must grant you the permissions necessary to pass session tags. The administrator can also create granular permissions to allow you to pass only specific session tags. For more information, see Tutorial: Using Tags for Attribute-Based Access Control in the IAM User Guide. You can set the session tags as transitive. Transitive tags persist during role chaining. For more information, see Chaining Roles with Session Tags in the IAM User Guide. Identities Before your application can call AssumeRoleWithWebIdentity, you must have an identity token from a supported identity provider and create a role that the application can assume. The role that your application assumes must trust the identity provider that is associated with the identity token. In other words, the identity provider must be specified in the role&#39;s trust policy. Calling AssumeRoleWithWebIdentity can result in an entry in your AWS CloudTrail logs. The entry includes the Subject of the provided Web Identity Token. We recommend that you avoid using any personally identifiable information (PII) in this field. For example, you could instead use a GUID or a pairwise identifier, as suggested in the OIDC specification. For more information about how to use web identity federation and the AssumeRoleWithWebIdentity API, see the following resources: Using Web Identity Federation API Operations for Mobile Apps and Federation Through a Web-based Identity Provider. Web Identity Federation Playground. Walk through the process of authenticating through Login with Amazon, Facebook, or Google, getting temporary security credentials, and then using those credentials to make a request to AWS. AWS SDK for iOS Developer Guide and AWS SDK for Android Developer Guide. These toolkits contain sample apps that show how to invoke the identity providers. The toolkits then show how to use the information from these providers to get and use temporary security credentials. Web Identity Federation with Mobile Applications. This article discusses web identity federation and shows an example of how to use web identity federation to get access to content in Amazon S3."},{"ref":"AWS.STS.html#decode_authorization_message/3","title":"AWS.STS.decode_authorization_message/3","type":"function","doc":"Decodes additional information about the authorization status of a request from an encoded message returned in response to an AWS request. For example, if a user is not authorized to perform an operation that he or she has requested, the request returns a Client.UnauthorizedOperation response (an HTTP 403 response). Some AWS operations additionally return an encoded message that can provide details about this authorization failure. Only certain AWS operations return an encoded authorization message. The documentation for an individual operation indicates whether that operation returns an encoded message in addition to returning an HTTP code. The message is encoded because the details of the authorization status can constitute privileged information that the user who requested the operation should not see. To decode an authorization status message, a user must be granted permissions via an IAM policy to request the DecodeAuthorizationMessage (sts:DecodeAuthorizationMessage) action. The decoded message includes the following type of information: Whether the request was denied due to an explicit deny or due to the absence of an explicit allow. For more information, see Determining Whether a Request is Allowed or Denied in the IAM User Guide. The principal who made the request. The requested action. The requested resource. The values of condition keys in the context of the user&#39;s request."},{"ref":"AWS.STS.html#get_access_key_info/3","title":"AWS.STS.get_access_key_info/3","type":"function","doc":"Returns the account identifier for the specified access key ID. Access keys consist of two parts: an access key ID (for example, AKIAIOSFODNN7EXAMPLE) and a secret access key (for example, wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY). For more information about access keys, see Managing Access Keys for IAM Users in the IAM User Guide. When you pass an access key ID to this operation, it returns the ID of the AWS account to which the keys belong. Access key IDs beginning with AKIA are long-term credentials for an IAM user or the AWS account root user. Access key IDs beginning with ASIA are temporary credentials that are created using STS operations. If the account in the response belongs to you, you can sign in as the root user and review your root user access keys. Then, you can pull a credentials report to learn which IAM user owns the keys. To learn who requested the temporary credentials for an ASIA access key, view the STS events in your CloudTrail logs in the IAM User Guide. This operation does not indicate the state of the access key. The key might be active, inactive, or deleted. Active keys might not have permissions to perform an operation. Providing a deleted access key might return an error that the key doesn&#39;t exist."},{"ref":"AWS.STS.html#get_caller_identity/3","title":"AWS.STS.get_caller_identity/3","type":"function","doc":"Returns details about the IAM user or role whose credentials are used to call the operation. No permissions are required to perform this operation. If an administrator adds a policy to your IAM user or role that explicitly denies access to the sts:GetCallerIdentity action, you can still perform this operation. Permissions are not required because the same information is returned when an IAM user or role is denied access. To view an example response, see I Am Not Authorized to Perform: iam:DeleteVirtualMFADevice in the IAM User Guide."},{"ref":"AWS.STS.html#get_federation_token/3","title":"AWS.STS.get_federation_token/3","type":"function","doc":"Returns a set of temporary security credentials (consisting of an access key ID, a secret access key, and a security token) for a federated user. A typical use is in a proxy application that gets temporary security credentials on behalf of distributed applications inside a corporate network. You must call the GetFederationToken operation using the long-term security credentials of an IAM user. As a result, this call is appropriate in contexts where those credentials can be safely stored, usually in a server-based application. For a comparison of GetFederationToken with the other API operations that produce temporary credentials, see Requesting Temporary Security Credentials and Comparing the AWS STS API operations in the IAM User Guide. You can create a mobile-based or browser-based app that can authenticate users using a web identity provider like Login with Amazon, Facebook, Google, or an OpenID Connect-compatible identity provider. In this case, we recommend that you use Amazon Cognito or AssumeRoleWithWebIdentity. For more information, see Federation Through a Web-based Identity Provider in the IAM User Guide. You can also call GetFederationToken using the security credentials of an AWS account root user, but we do not recommend it. Instead, we recommend that you create an IAM user for the purpose of the proxy application. Then attach a policy to the IAM user that limits federated users to only the actions and resources that they need to access. For more information, see IAM Best Practices in the IAM User Guide. Session duration The temporary credentials are valid for the specified duration, from 900 seconds (15 minutes) up to a maximum of 129,600 seconds (36 hours). The default session duration is 43,200 seconds (12 hours). Temporary credentials that are obtained by using AWS account root user credentials have a maximum duration of 3,600 seconds (1 hour). Permissions You can use the temporary credentials created by GetFederationToken in any AWS service except the following: You cannot call any IAM operations using the AWS CLI or the AWS API. You cannot call any STS operations except GetCallerIdentity. You must pass an inline or managed session policy to this operation. You can pass a single JSON policy document to use as an inline session policy. You can also specify up to 10 managed policies to use as managed session policies. The plain text that you use for both inline and managed session policies can&#39;t exceed 2,048 characters. Though the session policy parameters are optional, if you do not pass a policy, then the resulting federated user session has no permissions. When you pass session policies, the session permissions are the intersection of the IAM user policies and the session policies that you pass. This gives you a way to further restrict the permissions for a federated user. You cannot use session policies to grant more permissions than those that are defined in the permissions policy of the IAM user. For more information, see Session Policies in the IAM User Guide. For information about using GetFederationToken to create temporary security credentials, see GetFederationTokenFederation Through a Custom Identity Broker. You can use the credentials to access a resource that has a resource-based policy. If that policy specifically references the federated user session in the Principal element of the policy, the session has the permissions allowed by the policy. These permissions are granted in addition to the permissions granted by the session policies. Tags (Optional) You can pass tag key-value pairs to your session. These are called session tags. For more information about session tags, see Passing Session Tags in STS in the IAM User Guide. An administrator must grant you the permissions necessary to pass session tags. The administrator can also create granular permissions to allow you to pass only specific session tags. For more information, see Tutorial: Using Tags for Attribute-Based Access Control in the IAM User Guide. Tag keyvalue pairs are not case sensitive, but case is preserved. This means that you cannot have separate Department and department tag keys. Assume that the user that you are federating has the Department=Marketing tag and you pass the department=engineering session tag. Department and department are not saved as separate tags, and the session tag passed in the request takes precedence over the user tag."},{"ref":"AWS.STS.html#get_session_token/3","title":"AWS.STS.get_session_token/3","type":"function","doc":"Returns a set of temporary credentials for an AWS account or IAM user. The credentials consist of an access key ID, a secret access key, and a security token. Typically, you use GetSessionToken if you want to use MFA to protect programmatic calls to specific AWS API operations like Amazon EC2 StopInstances. MFA-enabled IAM users would need to call GetSessionToken and submit an MFA code that is associated with their MFA device. Using the temporary security credentials that are returned from the call, IAM users can then make programmatic calls to API operations that require MFA authentication. If you do not supply a correct MFA code, then the API returns an access denied error. For a comparison of GetSessionToken with the other API operations that produce temporary credentials, see Requesting Temporary Security Credentials and Comparing the AWS STS API operations in the IAM User Guide. Session Duration The GetSessionToken operation must be called by using the long-term AWS security credentials of the AWS account root user or an IAM user. Credentials that are created by IAM users are valid for the duration that you specify. This duration can range from 900 seconds (15 minutes) up to a maximum of 129,600 seconds (36 hours), with a default of 43,200 seconds (12 hours). Credentials based on account credentials can range from 900 seconds (15 minutes) up to 3,600 seconds (1 hour), with a default of 1 hour. Permissions The temporary security credentials created by GetSessionToken can be used to make API calls to any AWS service with the following exceptions: You cannot call any IAM API operations unless MFA authentication information is included in the request. You cannot call any STS API except AssumeRole or GetCallerIdentity. We recommend that you do not call GetSessionToken with AWS account root user credentials. Instead, follow our best practices by creating one or more IAM users, giving them the necessary permissions, and using IAM users for everyday interaction with AWS. The credentials that are returned by GetSessionToken are based on permissions associated with the user whose credentials were used to call the operation. If GetSessionToken is called using AWS account root user credentials, the temporary credentials have root user permissions. Similarly, if GetSessionToken is called using the credentials of an IAM user, the temporary credentials have the same permissions as the IAM user. For more information about using GetSessionToken to create temporary credentials, go to Temporary Credentials for Users in Untrusted Environments in the IAM User Guide."},{"ref":"AWS.SWF.html","title":"AWS.SWF","type":"module","doc":"Amazon Simple Workflow Service The Amazon Simple Workflow Service (Amazon SWF) makes it easy to build applications that use Amazon&#39;s cloud to coordinate work across distributed components. In Amazon SWF, a task represents a logical unit of work that is performed by a component of your workflow. Coordinating tasks in a workflow involves managing intertask dependencies, scheduling, and concurrency in accordance with the logical flow of the application. Amazon SWF gives you full control over implementing tasks and coordinating them without worrying about underlying complexities such as tracking their progress and maintaining their state. This documentation serves as reference only. For a broader overview of the Amazon SWF programming model, see the Amazon SWF Developer Guide ."},{"ref":"AWS.SWF.html#count_closed_workflow_executions/3","title":"AWS.SWF.count_closed_workflow_executions/3","type":"function","doc":"Returns the number of closed workflow executions within the given domain that meet the specified filtering criteria. This operation is eventually consistent. The results are best effort and may not exactly reflect recent updates and changes. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. Constrain the following parameters by using a Condition element with the appropriate keys. tagFilter.tag: String constraint. The key is swf:tagFilter.tag. typeFilter.name: String constraint. The key is swf:typeFilter.name. typeFilter.version: String constraint. The key is swf:typeFilter.version. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#count_open_workflow_executions/3","title":"AWS.SWF.count_open_workflow_executions/3","type":"function","doc":"Returns the number of open workflow executions within the given domain that meet the specified filtering criteria. This operation is eventually consistent. The results are best effort and may not exactly reflect recent updates and changes. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. Constrain the following parameters by using a Condition element with the appropriate keys. tagFilter.tag: String constraint. The key is swf:tagFilter.tag. typeFilter.name: String constraint. The key is swf:typeFilter.name. typeFilter.version: String constraint. The key is swf:typeFilter.version. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#count_pending_activity_tasks/3","title":"AWS.SWF.count_pending_activity_tasks/3","type":"function","doc":"Returns the estimated number of activity tasks in the specified task list. The count returned is an approximation and isn&#39;t guaranteed to be exact. If you specify a task list that no activity task was ever scheduled in then 0 is returned. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. Constrain the taskList.name parameter by using a Condition element with the swf:taskList.name key to allow the action to access only certain task lists. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#count_pending_decision_tasks/3","title":"AWS.SWF.count_pending_decision_tasks/3","type":"function","doc":"Returns the estimated number of decision tasks in the specified task list. The count returned is an approximation and isn&#39;t guaranteed to be exact. If you specify a task list that no decision task was ever scheduled in then 0 is returned. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. Constrain the taskList.name parameter by using a Condition element with the swf:taskList.name key to allow the action to access only certain task lists. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#deprecate_activity_type/3","title":"AWS.SWF.deprecate_activity_type/3","type":"function","doc":"Deprecates the specified activity type. After an activity type has been deprecated, you cannot create new tasks of that activity type. Tasks of this type that were scheduled before the type was deprecated continue to run. This operation is eventually consistent. The results are best effort and may not exactly reflect recent updates and changes. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. Constrain the following parameters by using a Condition element with the appropriate keys. activityType.name: String constraint. The key is swf:activityType.name. activityType.version: String constraint. The key is swf:activityType.version. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#deprecate_domain/3","title":"AWS.SWF.deprecate_domain/3","type":"function","doc":"Deprecates the specified domain. After a domain has been deprecated it cannot be used to create new workflow executions or register new types. However, you can still use visibility actions on this domain. Deprecating a domain also deprecates all activity and workflow types registered in the domain. Executions that were started before the domain was deprecated continues to run. This operation is eventually consistent. The results are best effort and may not exactly reflect recent updates and changes. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. You cannot use an IAM policy to constrain this action&#39;s parameters. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#deprecate_workflow_type/3","title":"AWS.SWF.deprecate_workflow_type/3","type":"function","doc":"Deprecates the specified workflow type. After a workflow type has been deprecated, you cannot create new executions of that type. Executions that were started before the type was deprecated continues to run. A deprecated workflow type may still be used when calling visibility actions. This operation is eventually consistent. The results are best effort and may not exactly reflect recent updates and changes. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. Constrain the following parameters by using a Condition element with the appropriate keys. workflowType.name: String constraint. The key is swf:workflowType.name. workflowType.version: String constraint. The key is swf:workflowType.version. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#describe_activity_type/3","title":"AWS.SWF.describe_activity_type/3","type":"function","doc":"Returns information about the specified activity type. This includes configuration settings provided when the type was registered and other general information about the type. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. Constrain the following parameters by using a Condition element with the appropriate keys. activityType.name: String constraint. The key is swf:activityType.name. activityType.version: String constraint. The key is swf:activityType.version. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#describe_domain/3","title":"AWS.SWF.describe_domain/3","type":"function","doc":"Returns information about the specified domain, including description and status. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. You cannot use an IAM policy to constrain this action&#39;s parameters. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#describe_workflow_execution/3","title":"AWS.SWF.describe_workflow_execution/3","type":"function","doc":"Returns information about the specified workflow execution including its type and some statistics. This operation is eventually consistent. The results are best effort and may not exactly reflect recent updates and changes. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. You cannot use an IAM policy to constrain this action&#39;s parameters. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#describe_workflow_type/3","title":"AWS.SWF.describe_workflow_type/3","type":"function","doc":"Returns information about the specified workflow type. This includes configuration settings specified when the type was registered and other information such as creation date, current status, etc. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. Constrain the following parameters by using a Condition element with the appropriate keys. workflowType.name: String constraint. The key is swf:workflowType.name. workflowType.version: String constraint. The key is swf:workflowType.version. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#get_workflow_execution_history/3","title":"AWS.SWF.get_workflow_execution_history/3","type":"function","doc":"Returns the history of the specified workflow execution. The results may be split into multiple pages. To retrieve subsequent pages, make the call again using the nextPageToken returned by the initial call. This operation is eventually consistent. The results are best effort and may not exactly reflect recent updates and changes. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. You cannot use an IAM policy to constrain this action&#39;s parameters. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#list_activity_types/3","title":"AWS.SWF.list_activity_types/3","type":"function","doc":"Returns information about all activities registered in the specified domain that match the specified name and registration status. The result includes information like creation date, current status of the activity, etc. The results may be split into multiple pages. To retrieve subsequent pages, make the call again using the nextPageToken returned by the initial call. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. You cannot use an IAM policy to constrain this action&#39;s parameters. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#list_closed_workflow_executions/3","title":"AWS.SWF.list_closed_workflow_executions/3","type":"function","doc":"Returns a list of closed workflow executions in the specified domain that meet the filtering criteria. The results may be split into multiple pages. To retrieve subsequent pages, make the call again using the nextPageToken returned by the initial call. This operation is eventually consistent. The results are best effort and may not exactly reflect recent updates and changes. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. Constrain the following parameters by using a Condition element with the appropriate keys. tagFilter.tag: String constraint. The key is swf:tagFilter.tag. typeFilter.name: String constraint. The key is swf:typeFilter.name. typeFilter.version: String constraint. The key is swf:typeFilter.version. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#list_domains/3","title":"AWS.SWF.list_domains/3","type":"function","doc":"Returns the list of domains registered in the account. The results may be split into multiple pages. To retrieve subsequent pages, make the call again using the nextPageToken returned by the initial call. This operation is eventually consistent. The results are best effort and may not exactly reflect recent updates and changes. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. The element must be set to arn:aws:swf::AccountID:domain/*, where AccountID is the account ID, with no dashes. Use an Action element to allow or deny permission to call this action. You cannot use an IAM policy to constrain this action&#39;s parameters. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#list_open_workflow_executions/3","title":"AWS.SWF.list_open_workflow_executions/3","type":"function","doc":"Returns a list of open workflow executions in the specified domain that meet the filtering criteria. The results may be split into multiple pages. To retrieve subsequent pages, make the call again using the nextPageToken returned by the initial call. This operation is eventually consistent. The results are best effort and may not exactly reflect recent updates and changes. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. Constrain the following parameters by using a Condition element with the appropriate keys. tagFilter.tag: String constraint. The key is swf:tagFilter.tag. typeFilter.name: String constraint. The key is swf:typeFilter.name. typeFilter.version: String constraint. The key is swf:typeFilter.version. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#list_tags_for_resource/3","title":"AWS.SWF.list_tags_for_resource/3","type":"function","doc":"List tags for a given domain."},{"ref":"AWS.SWF.html#list_workflow_types/3","title":"AWS.SWF.list_workflow_types/3","type":"function","doc":"Returns information about workflow types in the specified domain. The results may be split into multiple pages that can be retrieved by making the call repeatedly. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. You cannot use an IAM policy to constrain this action&#39;s parameters. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#poll_for_activity_task/3","title":"AWS.SWF.poll_for_activity_task/3","type":"function","doc":"Used by workers to get an ActivityTask from the specified activity taskList. This initiates a long poll, where the service holds the HTTP connection open and responds as soon as a task becomes available. The maximum time the service holds on to the request before responding is 60 seconds. If no task is available within 60 seconds, the poll returns an empty result. An empty result, in this context, means that an ActivityTask is returned, but that the value of taskToken is an empty string. If a task is returned, the worker should use its type to identify and process it correctly. Workers should set their client side socket timeout to at least 70 seconds (10 seconds higher than the maximum time service may hold the poll request). Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. Constrain the taskList.name parameter by using a Condition element with the swf:taskList.name key to allow the action to access only certain task lists. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#poll_for_decision_task/3","title":"AWS.SWF.poll_for_decision_task/3","type":"function","doc":"Used by deciders to get a DecisionTask from the specified decision taskList. A decision task may be returned for any open workflow execution that is using the specified task list. The task includes a paginated view of the history of the workflow execution. The decider should use the workflow type and the history to determine how to properly handle the task. This action initiates a long poll, where the service holds the HTTP connection open and responds as soon a task becomes available. If no decision task is available in the specified task list before the timeout of 60 seconds expires, an empty result is returned. An empty result, in this context, means that a DecisionTask is returned, but that the value of taskToken is an empty string. Deciders should set their client side socket timeout to at least 70 seconds (10 seconds higher than the timeout). Because the number of workflow history events for a single workflow execution might be very large, the result returned might be split up across a number of pages. To retrieve subsequent pages, make additional calls to PollForDecisionTask using the nextPageToken returned by the initial call. Note that you do not call GetWorkflowExecutionHistory with this nextPageToken. Instead, call PollForDecisionTask again. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. Constrain the taskList.name parameter by using a Condition element with the swf:taskList.name key to allow the action to access only certain task lists. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#record_activity_task_heartbeat/3","title":"AWS.SWF.record_activity_task_heartbeat/3","type":"function","doc":"Used by activity workers to report to the service that the ActivityTask represented by the specified taskToken is still making progress. The worker can also specify details of the progress, for example percent complete, using the details parameter. This action can also be used by the worker as a mechanism to check if cancellation is being requested for the activity task. If a cancellation is being attempted for the specified task, then the boolean cancelRequested flag returned by the service is set to true. This action resets the taskHeartbeatTimeout clock. The taskHeartbeatTimeout is specified in RegisterActivityType. This action doesn&#39;t in itself create an event in the workflow execution history. However, if the task times out, the workflow execution history contains a ActivityTaskTimedOut event that contains the information from the last heartbeat generated by the activity worker. The taskStartToCloseTimeout of an activity type is the maximum duration of an activity task, regardless of the number of RecordActivityTaskHeartbeat requests received. The taskStartToCloseTimeout is also specified in RegisterActivityType. This operation is only useful for long-lived activities to report liveliness of the task and to determine if a cancellation is being attempted. If the cancelRequested flag returns true, a cancellation is being attempted. If the worker can cancel the activity, it should respond with RespondActivityTaskCanceled. Otherwise, it should ignore the cancellation request. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. You cannot use an IAM policy to constrain this action&#39;s parameters. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#register_activity_type/3","title":"AWS.SWF.register_activity_type/3","type":"function","doc":"Registers a new activity type along with its configuration settings in the specified domain. A TypeAlreadyExists fault is returned if the type already exists in the domain. You cannot change any configuration settings of the type after its registration, and it must be registered as a new version. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. Constrain the following parameters by using a Condition element with the appropriate keys. defaultTaskList.name: String constraint. The key is swf:defaultTaskList.name. name: String constraint. The key is swf:name. version: String constraint. The key is swf:version. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#register_domain/3","title":"AWS.SWF.register_domain/3","type":"function","doc":"Registers a new domain. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: You cannot use an IAM policy to control domain access for this action. The name of the domain being registered is available as the resource of this action. Use an Action element to allow or deny permission to call this action. You cannot use an IAM policy to constrain this action&#39;s parameters. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#register_workflow_type/3","title":"AWS.SWF.register_workflow_type/3","type":"function","doc":"Registers a new workflow type and its configuration settings in the specified domain. The retention period for the workflow history is set by the RegisterDomain action. If the type already exists, then a TypeAlreadyExists fault is returned. You cannot change the configuration settings of a workflow type once it is registered and it must be registered as a new version. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. Constrain the following parameters by using a Condition element with the appropriate keys. defaultTaskList.name: String constraint. The key is swf:defaultTaskList.name. name: String constraint. The key is swf:name. version: String constraint. The key is swf:version. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#request_cancel_workflow_execution/3","title":"AWS.SWF.request_cancel_workflow_execution/3","type":"function","doc":"Records a WorkflowExecutionCancelRequested event in the currently running workflow execution identified by the given domain, workflowId, and runId. This logically requests the cancellation of the workflow execution as a whole. It is up to the decider to take appropriate actions when it receives an execution history with this event. If the runId isn&#39;t specified, the WorkflowExecutionCancelRequested event is recorded in the history of the current open workflow execution with the specified workflowId in the domain. Because this action allows the workflow to properly clean up and gracefully close, it should be used instead of TerminateWorkflowExecution when possible. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. You cannot use an IAM policy to constrain this action&#39;s parameters. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#respond_activity_task_canceled/3","title":"AWS.SWF.respond_activity_task_canceled/3","type":"function","doc":"Used by workers to tell the service that the ActivityTask identified by the taskToken was successfully canceled. Additional details can be provided using the details argument. These details (if provided) appear in the ActivityTaskCanceled event added to the workflow history. Only use this operation if the canceled flag of a RecordActivityTaskHeartbeat request returns true and if the activity can be safely undone or abandoned. A task is considered open from the time that it is scheduled until it is closed. Therefore a task is reported as open while a worker is processing it. A task is closed after it has been specified in a call to RespondActivityTaskCompleted, RespondActivityTaskCanceled, RespondActivityTaskFailed, or the task has timed out. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. You cannot use an IAM policy to constrain this action&#39;s parameters. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#respond_activity_task_completed/3","title":"AWS.SWF.respond_activity_task_completed/3","type":"function","doc":"Used by workers to tell the service that the ActivityTask identified by the taskToken completed successfully with a result (if provided). The result appears in the ActivityTaskCompleted event in the workflow history. If the requested task doesn&#39;t complete successfully, use RespondActivityTaskFailed instead. If the worker finds that the task is canceled through the canceled flag returned by RecordActivityTaskHeartbeat, it should cancel the task, clean up and then call RespondActivityTaskCanceled. A task is considered open from the time that it is scheduled until it is closed. Therefore a task is reported as open while a worker is processing it. A task is closed after it has been specified in a call to RespondActivityTaskCompleted, RespondActivityTaskCanceled, RespondActivityTaskFailed, or the task has timed out. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. You cannot use an IAM policy to constrain this action&#39;s parameters. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#respond_activity_task_failed/3","title":"AWS.SWF.respond_activity_task_failed/3","type":"function","doc":"Used by workers to tell the service that the ActivityTask identified by the taskToken has failed with reason (if specified). The reason and details appear in the ActivityTaskFailed event added to the workflow history. A task is considered open from the time that it is scheduled until it is closed. Therefore a task is reported as open while a worker is processing it. A task is closed after it has been specified in a call to RespondActivityTaskCompleted, RespondActivityTaskCanceled, RespondActivityTaskFailed, or the task has timed out. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. You cannot use an IAM policy to constrain this action&#39;s parameters. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#respond_decision_task_completed/3","title":"AWS.SWF.respond_decision_task_completed/3","type":"function","doc":"Used by deciders to tell the service that the DecisionTask identified by the taskToken has successfully completed. The decisions argument specifies the list of decisions made while processing the task. A DecisionTaskCompleted event is added to the workflow history. The executionContext specified is attached to the event in the workflow execution history. Access Control If an IAM policy grants permission to use RespondDecisionTaskCompleted, it can express permissions for the list of decisions in the decisions parameter. Each of the decisions has one or more parameters, much like a regular API call. To allow for policies to be as readable as possible, you can express permissions on decisions as if they were actual API calls, including applying conditions to some parameters. For more information, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#signal_workflow_execution/3","title":"AWS.SWF.signal_workflow_execution/3","type":"function","doc":"Records a WorkflowExecutionSignaled event in the workflow execution history and creates a decision task for the workflow execution identified by the given domain, workflowId and runId. The event is recorded with the specified user defined signalName and input (if provided). If a runId isn&#39;t specified, then the WorkflowExecutionSignaled event is recorded in the history of the current open workflow with the matching workflowId in the domain. If the specified workflow execution isn&#39;t open, this method fails with UnknownResource. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. You cannot use an IAM policy to constrain this action&#39;s parameters. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#start_workflow_execution/3","title":"AWS.SWF.start_workflow_execution/3","type":"function","doc":"Starts an execution of the workflow type in the specified domain using the provided workflowId and input data. This action returns the newly started workflow execution. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. Constrain the following parameters by using a Condition element with the appropriate keys. tagList.member.0: The key is swf:tagList.member.0. tagList.member.1: The key is swf:tagList.member.1. tagList.member.2: The key is swf:tagList.member.2. tagList.member.3: The key is swf:tagList.member.3. tagList.member.4: The key is swf:tagList.member.4. taskList: String constraint. The key is swf:taskList.name. workflowType.name: String constraint. The key is swf:workflowType.name. workflowType.version: String constraint. The key is swf:workflowType.version. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#tag_resource/3","title":"AWS.SWF.tag_resource/3","type":"function","doc":"Add a tag to a Amazon SWF domain. Amazon SWF supports a maximum of 50 tags per resource."},{"ref":"AWS.SWF.html#terminate_workflow_execution/3","title":"AWS.SWF.terminate_workflow_execution/3","type":"function","doc":"Records a WorkflowExecutionTerminated event and forces closure of the workflow execution identified by the given domain, runId, and workflowId. The child policy, registered with the workflow type or specified when starting this execution, is applied to any open child workflow executions of this workflow execution. If the identified workflow execution was in progress, it is terminated immediately. If a runId isn&#39;t specified, then the WorkflowExecutionTerminated event is recorded in the history of the current open workflow with the matching workflowId in the domain. You should consider using RequestCancelWorkflowExecution action instead because it allows the workflow to gracefully close while TerminateWorkflowExecution doesn&#39;t. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. You cannot use an IAM policy to constrain this action&#39;s parameters. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#undeprecate_activity_type/3","title":"AWS.SWF.undeprecate_activity_type/3","type":"function","doc":"Undeprecates a previously deprecated activity type. After an activity type has been undeprecated, you can create new tasks of that activity type. This operation is eventually consistent. The results are best effort and may not exactly reflect recent updates and changes. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. Constrain the following parameters by using a Condition element with the appropriate keys. activityType.name: String constraint. The key is swf:activityType.name. activityType.version: String constraint. The key is swf:activityType.version. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#undeprecate_domain/3","title":"AWS.SWF.undeprecate_domain/3","type":"function","doc":"Undeprecates a previously deprecated domain. After a domain has been undeprecated it can be used to create new workflow executions or register new types. This operation is eventually consistent. The results are best effort and may not exactly reflect recent updates and changes. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. You cannot use an IAM policy to constrain this action&#39;s parameters. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#undeprecate_workflow_type/3","title":"AWS.SWF.undeprecate_workflow_type/3","type":"function","doc":"Undeprecates a previously deprecated workflow type. After a workflow type has been undeprecated, you can create new executions of that type. This operation is eventually consistent. The results are best effort and may not exactly reflect recent updates and changes. Access Control You can use IAM policies to control this action&#39;s access to Amazon SWF resources as follows: Use a Resource element with the domain name to limit the action to only specified domains. Use an Action element to allow or deny permission to call this action. Constrain the following parameters by using a Condition element with the appropriate keys. workflowType.name: String constraint. The key is swf:workflowType.name. workflowType.version: String constraint. The key is swf:workflowType.version. If the caller doesn&#39;t have sufficient permissions to invoke the action, or the parameter values fall outside the specified constraints, the action fails. The associated event attribute&#39;s cause parameter is set to OPERATION_NOT_PERMITTED. For details and example IAM policies, see Using IAM to Manage Access to Amazon SWF Workflows in the Amazon SWF Developer Guide."},{"ref":"AWS.SWF.html#untag_resource/3","title":"AWS.SWF.untag_resource/3","type":"function","doc":"Remove a tag from a Amazon SWF domain."},{"ref":"AWS.SageMaker.html","title":"AWS.SageMaker","type":"module","doc":"Provides APIs for creating and managing Amazon SageMaker resources. Other Resources: Amazon SageMaker Developer Guide Amazon Augmented AI Runtime API Reference"},{"ref":"AWS.SageMaker.html#add_tags/3","title":"AWS.SageMaker.add_tags/3","type":"function","doc":"Adds or overwrites one or more tags for the specified Amazon SageMaker resource. You can add tags to notebook instances, training jobs, hyperparameter tuning jobs, batch transform jobs, models, labeling jobs, work teams, endpoint configurations, and endpoints. Each tag consists of a key and an optional value. Tag keys must be unique per resource. For more information about tags, see For more information, see AWS Tagging Strategies. Tags that you add to a hyperparameter tuning job by calling this API are also added to any training jobs that the hyperparameter tuning job launches after you call this API, but not to training jobs that the hyperparameter tuning job launched before you called this API. To make sure that the tags associated with a hyperparameter tuning job are also added to all training jobs that the hyperparameter tuning job launches, add the tags when you first create the tuning job by specifying them in the Tags parameter of CreateHyperParameterTuningJob"},{"ref":"AWS.SageMaker.html#associate_trial_component/3","title":"AWS.SageMaker.associate_trial_component/3","type":"function","doc":"Associates a trial component with a trial. A trial component can be associated with multiple trials. To disassociate a trial component from a trial, call the DisassociateTrialComponent API."},{"ref":"AWS.SageMaker.html#create_algorithm/3","title":"AWS.SageMaker.create_algorithm/3","type":"function","doc":"Create a machine learning algorithm that you can use in Amazon SageMaker and list in the AWS Marketplace."},{"ref":"AWS.SageMaker.html#create_app/3","title":"AWS.SageMaker.create_app/3","type":"function","doc":"Creates a running App for the specified UserProfile. Supported Apps are JupyterServer and KernelGateway. This operation is automatically invoked by Amazon SageMaker Studio upon access to the associated Domain, and when new kernel configurations are selected by the user. A user may have multiple Apps active simultaneously."},{"ref":"AWS.SageMaker.html#create_auto_m_l_job/3","title":"AWS.SageMaker.create_auto_m_l_job/3","type":"function","doc":"Creates an Autopilot job. Find the best performing model after you run an Autopilot job by calling . Deploy that model by following the steps described in Step 6.1: Deploy the Model to Amazon SageMaker Hosting Services. For information about how to use Autopilot, see Automate Model Development with Amazon SageMaker Autopilot."},{"ref":"AWS.SageMaker.html#create_code_repository/3","title":"AWS.SageMaker.create_code_repository/3","type":"function","doc":"Creates a Git repository as a resource in your Amazon SageMaker account. You can associate the repository with notebook instances so that you can use Git source control for the notebooks you create. The Git repository is a resource in your Amazon SageMaker account, so it can be associated with more than one notebook instance, and it persists independently from the lifecycle of any notebook instances it is associated with. The repository can be hosted either in AWS CodeCommit or in any other Git repository."},{"ref":"AWS.SageMaker.html#create_compilation_job/3","title":"AWS.SageMaker.create_compilation_job/3","type":"function","doc":"Starts a model compilation job. After the model has been compiled, Amazon SageMaker saves the resulting model artifacts to an Amazon Simple Storage Service (Amazon S3) bucket that you specify. If you choose to host your model using Amazon SageMaker hosting services, you can use the resulting model artifacts as part of the model. You can also use the artifacts with AWS IoT Greengrass. In that case, deploy them as an ML resource. In the request body, you provide the following: A name for the compilation job Information about the input model artifacts The output location for the compiled model and the device (target) that the model runs on The Amazon Resource Name (ARN) of the IAM role that Amazon SageMaker assumes to perform the model compilation job. You can also provide a Tag to track the model compilation job&#39;s resource use and costs. The response body contains the CompilationJobArn for the compiled job. To stop a model compilation job, use StopCompilationJob. To get information about a particular model compilation job, use DescribeCompilationJob. To get information about multiple model compilation jobs, use ListCompilationJobs."},{"ref":"AWS.SageMaker.html#create_domain/3","title":"AWS.SageMaker.create_domain/3","type":"function","doc":"Creates a Domain used by Amazon SageMaker Studio. A domain consists of an associated Amazon Elastic File System (EFS) volume, a list of authorized users, and a variety of security, application, policy, and Amazon Virtual Private Cloud (VPC) configurations. An AWS account is limited to one domain per region. Users within a domain can share notebook files and other artifacts with each other. When a domain is created, an EFS volume is created for use by all of the users within the domain. Each user receives a private home directory within the EFS volume for notebooks, Git repositories, and data files. VPC configuration All SageMaker Studio traffic between the domain and the EFS volume is through the specified VPC and subnets. For other Studio traffic, you can specify the AppNetworkAccessType parameter. AppNetworkAccessType corresponds to the network access type that you choose when you onboard to Studio. The following options are available: PublicInternetOnly - Non-EFS traffic goes through a VPC managed by Amazon SageMaker, which allows internet access. This is the default value. VpcOnly - All Studio traffic is through the specified VPC and subnets. Internet access is disabled by default. To allow internet access, you must specify a NAT gateway. When internet access is disabled, you won&#39;t be able to train or host models unless your VPC has an interface endpoint (PrivateLink) or a NAT gateway and your security groups allow outbound connections. VpcOnly network access type When you choose VpcOnly, you must specify the following: Security group inbound and outbound rules to allow NFS traffic over TCP on port 2049 between the domain and the EFS volume Security group inbound and outbound rules to allow traffic between the JupyterServer app and the KernelGateway apps Interface endpoints to access the SageMaker API and SageMaker runtime For more information, see: Security groups for your VPC VPC with public and private subnets (NAT) Connect to SageMaker through a VPC interface endpoint"},{"ref":"AWS.SageMaker.html#create_endpoint/3","title":"AWS.SageMaker.create_endpoint/3","type":"function","doc":"Creates an endpoint using the endpoint configuration specified in the request. Amazon SageMaker uses the endpoint to provision resources and deploy models. You create the endpoint configuration with the CreateEndpointConfig API. Use this API to deploy models using Amazon SageMaker hosting services. For an example that calls this method when deploying a model to Amazon SageMaker hosting services, see Deploy the Model to Amazon SageMaker Hosting Services (AWS SDK for Python (Boto 3)). You must not delete an EndpointConfig that is in use by an endpoint that is live or while the UpdateEndpoint or CreateEndpoint operations are being performed on the endpoint. To update an endpoint, you must create a new EndpointConfig. The endpoint name must be unique within an AWS Region in your AWS account. When it receives the request, Amazon SageMaker creates the endpoint, launches the resources (ML compute instances), and deploys the model(s) on them. When you call CreateEndpoint, a load call is made to DynamoDB to verify that your endpoint configuration exists. When you read data from a DynamoDB table supporting Eventually Consistent Reads , the response might not reflect the results of a recently completed write operation. The response might include some stale data. If the dependent entities are not yet in DynamoDB, this causes a validation error. If you repeat your read request after a short time, the response should return the latest data. So retry logic is recommended to handle these possible issues. We also recommend that customers call DescribeEndpointConfig before calling CreateEndpoint to minimize the potential impact of a DynamoDB eventually consistent read. When Amazon SageMaker receives the request, it sets the endpoint status to Creating. After it creates the endpoint, it sets the status to InService. Amazon SageMaker can then process incoming requests for inferences. To check the status of an endpoint, use the DescribeEndpoint API. If any of the models hosted at this endpoint get model data from an Amazon S3 location, Amazon SageMaker uses AWS Security Token Service to download model artifacts from the S3 path you provided. AWS STS is activated in your IAM user account by default. If you previously deactivated AWS STS for a region, you need to reactivate AWS STS for that region. For more information, see Activating and Deactivating AWS STS in an AWS Region in the AWS Identity and Access Management User Guide."},{"ref":"AWS.SageMaker.html#create_endpoint_config/3","title":"AWS.SageMaker.create_endpoint_config/3","type":"function","doc":"Creates an endpoint configuration that Amazon SageMaker hosting services uses to deploy models. In the configuration, you identify one or more models, created using the CreateModel API, to deploy and the resources that you want Amazon SageMaker to provision. Then you call the CreateEndpoint API. Use this API if you want to use Amazon SageMaker hosting services to deploy models into production. In the request, you define a ProductionVariant, for each model that you want to deploy. Each ProductionVariant parameter also describes the resources that you want Amazon SageMaker to provision. This includes the number and type of ML compute instances to deploy. If you are hosting multiple models, you also assign a VariantWeight to specify how much traffic you want to allocate to each model. For example, suppose that you want to host two models, A and B, and you assign traffic weight 2 for model A and 1 for model B. Amazon SageMaker distributes two-thirds of the traffic to Model A, and one-third to model B. For an example that calls this method when deploying a model to Amazon SageMaker hosting services, see Deploy the Model to Amazon SageMaker Hosting Services (AWS SDK for Python (Boto 3)). When you call CreateEndpoint, a load call is made to DynamoDB to verify that your endpoint configuration exists. When you read data from a DynamoDB table supporting Eventually Consistent Reads , the response might not reflect the results of a recently completed write operation. The response might include some stale data. If the dependent entities are not yet in DynamoDB, this causes a validation error. If you repeat your read request after a short time, the response should return the latest data. So retry logic is recommended to handle these possible issues. We also recommend that customers call DescribeEndpointConfig before calling CreateEndpoint to minimize the potential impact of a DynamoDB eventually consistent read."},{"ref":"AWS.SageMaker.html#create_experiment/3","title":"AWS.SageMaker.create_experiment/3","type":"function","doc":"Creates an SageMaker experiment. An experiment is a collection of trials that are observed, compared and evaluated as a group. A trial is a set of steps, called trial components, that produce a machine learning model. The goal of an experiment is to determine the components that produce the best model. Multiple trials are performed, each one isolating and measuring the impact of a change to one or more inputs, while keeping the remaining inputs constant. When you use Amazon SageMaker Studio or the Amazon SageMaker Python SDK, all experiments, trials, and trial components are automatically tracked, logged, and indexed. When you use the AWS SDK for Python (Boto), you must use the logging APIs provided by the SDK. You can add tags to experiments, trials, trial components and then use the Search API to search for the tags. To add a description to an experiment, specify the optional Description parameter. To add a description later, or to change the description, call the UpdateExperiment API. To get a list of all your experiments, call the ListExperiments API. To view an experiment&#39;s properties, call the DescribeExperiment API. To get a list of all the trials associated with an experiment, call the ListTrials API. To create a trial call the CreateTrial API."},{"ref":"AWS.SageMaker.html#create_flow_definition/3","title":"AWS.SageMaker.create_flow_definition/3","type":"function","doc":"Creates a flow definition."},{"ref":"AWS.SageMaker.html#create_human_task_ui/3","title":"AWS.SageMaker.create_human_task_ui/3","type":"function","doc":"Defines the settings you will use for the human review workflow user interface. Reviewers will see a three-panel interface with an instruction area, the item to review, and an input area."},{"ref":"AWS.SageMaker.html#create_hyper_parameter_tuning_job/3","title":"AWS.SageMaker.create_hyper_parameter_tuning_job/3","type":"function","doc":"Starts a hyperparameter tuning job. A hyperparameter tuning job finds the best version of a model by running many training jobs on your dataset using the algorithm you choose and values for hyperparameters within ranges that you specify. It then chooses the hyperparameter values that result in a model that performs the best, as measured by an objective metric that you choose."},{"ref":"AWS.SageMaker.html#create_labeling_job/3","title":"AWS.SageMaker.create_labeling_job/3","type":"function","doc":"Creates a job that uses workers to label the data objects in your input dataset. You can use the labeled data to train machine learning models. You can select your workforce from one of three providers: A private workforce that you create. It can include employees, contractors, and outside experts. Use a private workforce when want the data to stay within your organization or when a specific set of skills is required. One or more vendors that you select from the AWS Marketplace. Vendors provide expertise in specific areas. The Amazon Mechanical Turk workforce. This is the largest workforce, but it should only be used for public data or data that has been stripped of any personally identifiable information. You can also use automated data labeling to reduce the number of data objects that need to be labeled by a human. Automated data labeling uses active learning to determine if a data object can be labeled by machine or if it needs to be sent to a human worker. For more information, see Using Automated Data Labeling. The data objects to be labeled are contained in an Amazon S3 bucket. You create a manifest file that describes the location of each object. For more information, see Using Input and Output Data. The output can be used as the manifest file for another labeling job or as training data for your machine learning models."},{"ref":"AWS.SageMaker.html#create_model/3","title":"AWS.SageMaker.create_model/3","type":"function","doc":"Creates a model in Amazon SageMaker. In the request, you name the model and describe a primary container. For the primary container, you specify the Docker image that contains inference code, artifacts (from prior training), and a custom environment map that the inference code uses when you deploy the model for predictions. Use this API to create a model if you want to use Amazon SageMaker hosting services or run a batch transform job. To host your model, you create an endpoint configuration with the CreateEndpointConfig API, and then create an endpoint with the CreateEndpoint API. Amazon SageMaker then deploys all of the containers that you defined for the model in the hosting environment. For an example that calls this method when deploying a model to Amazon SageMaker hosting services, see Deploy the Model to Amazon SageMaker Hosting Services (AWS SDK for Python (Boto 3)). To run a batch transform using your model, you start a job with the CreateTransformJob API. Amazon SageMaker uses your model and your dataset to get inferences which are then saved to a specified S3 location. In the CreateModel request, you must define a container with the PrimaryContainer parameter. In the request, you also provide an IAM role that Amazon SageMaker can assume to access model artifacts and docker image for deployment on ML compute hosting instances or for batch transform jobs. In addition, you also use the IAM role to manage permissions the inference code needs. For example, if the inference code access any other AWS resources, you grant necessary permissions via this role."},{"ref":"AWS.SageMaker.html#create_model_package/3","title":"AWS.SageMaker.create_model_package/3","type":"function","doc":"Creates a model package that you can use to create Amazon SageMaker models or list on AWS Marketplace. Buyers can subscribe to model packages listed on AWS Marketplace to create models in Amazon SageMaker. To create a model package by specifying a Docker container that contains your inference code and the Amazon S3 location of your model artifacts, provide values for InferenceSpecification. To create a model from an algorithm resource that you created or subscribed to in AWS Marketplace, provide a value for SourceAlgorithmSpecification."},{"ref":"AWS.SageMaker.html#create_monitoring_schedule/3","title":"AWS.SageMaker.create_monitoring_schedule/3","type":"function","doc":"Creates a schedule that regularly starts Amazon SageMaker Processing Jobs to monitor the data captured for an Amazon SageMaker Endoint."},{"ref":"AWS.SageMaker.html#create_notebook_instance/3","title":"AWS.SageMaker.create_notebook_instance/3","type":"function","doc":"Creates an Amazon SageMaker notebook instance. A notebook instance is a machine learning (ML) compute instance running on a Jupyter notebook. In a CreateNotebookInstance request, specify the type of ML compute instance that you want to run. Amazon SageMaker launches the instance, installs common libraries that you can use to explore datasets for model training, and attaches an ML storage volume to the notebook instance. Amazon SageMaker also provides a set of example notebooks. Each notebook demonstrates how to use Amazon SageMaker with a specific algorithm or with a machine learning framework. After receiving the request, Amazon SageMaker does the following: Creates a network interface in the Amazon SageMaker VPC. (Option) If you specified SubnetId, Amazon SageMaker creates a network interface in your own VPC, which is inferred from the subnet ID that you provide in the input. When creating this network interface, Amazon SageMaker attaches the security group that you specified in the request to the network interface that it creates in your VPC. Launches an EC2 instance of the type specified in the request in the Amazon SageMaker VPC. If you specified SubnetId of your VPC, Amazon SageMaker specifies both network interfaces when launching this instance. This enables inbound traffic from your own VPC to the notebook instance, assuming that the security groups allow it. After creating the notebook instance, Amazon SageMaker returns its Amazon Resource Name (ARN). You can&#39;t change the name of a notebook instance after you create it. After Amazon SageMaker creates the notebook instance, you can connect to the Jupyter server and work in Jupyter notebooks. For example, you can write code to explore a dataset that you can use for model training, train a model, host models by creating Amazon SageMaker endpoints, and validate hosted models. For more information, see How It Works."},{"ref":"AWS.SageMaker.html#create_notebook_instance_lifecycle_config/3","title":"AWS.SageMaker.create_notebook_instance_lifecycle_config/3","type":"function","doc":"Creates a lifecycle configuration that you can associate with a notebook instance. A lifecycle configuration is a collection of shell scripts that run when you create or start a notebook instance. Each lifecycle configuration script has a limit of 16384 characters. The value of the $PATH environment variable that is available to both scripts is /sbin:bin:/usr/sbin:/usr/bin. View CloudWatch Logs for notebook instance lifecycle configurations in log group /aws/sagemaker/NotebookInstances in log stream [notebook-instance-name]/[LifecycleConfigHook]. Lifecycle configuration scripts cannot run for longer than 5 minutes. If a script runs for longer than 5 minutes, it fails and the notebook instance is not created or started. For information about notebook instance lifestyle configurations, see Step 2.1: (Optional) Customize a Notebook Instance."},{"ref":"AWS.SageMaker.html#create_presigned_domain_url/3","title":"AWS.SageMaker.create_presigned_domain_url/3","type":"function","doc":"Creates a URL for a specified UserProfile in a Domain. When accessed in a web browser, the user will be automatically signed in to Amazon SageMaker Studio, and granted access to all of the Apps and files associated with the Domain&#39;s Amazon Elastic File System (EFS) volume. This operation can only be called when the authentication mode equals IAM. The URL that you get from a call to CreatePresignedDomainUrl is valid only for 5 minutes. If you try to use the URL after the 5-minute limit expires, you are directed to the AWS console sign-in page."},{"ref":"AWS.SageMaker.html#create_presigned_notebook_instance_url/3","title":"AWS.SageMaker.create_presigned_notebook_instance_url/3","type":"function","doc":"Returns a URL that you can use to connect to the Jupyter server from a notebook instance. In the Amazon SageMaker console, when you choose Open next to a notebook instance, Amazon SageMaker opens a new tab showing the Jupyter server home page from the notebook instance. The console uses this API to get the URL and show the page. The IAM role or user used to call this API defines the permissions to access the notebook instance. Once the presigned URL is created, no additional permission is required to access this URL. IAM authorization policies for this API are also enforced for every HTTP request and WebSocket frame that attempts to connect to the notebook instance. You can restrict access to this API and to the URL that it returns to a list of IP addresses that you specify. Use the NotIpAddress condition operator and the aws:SourceIP condition context key to specify the list of IP addresses that you want to have access to the notebook instance. For more information, see Limit Access to a Notebook Instance by IP Address. The URL that you get from a call to CreatePresignedNotebookInstanceUrl is valid only for 5 minutes. If you try to use the URL after the 5-minute limit expires, you are directed to the AWS console sign-in page."},{"ref":"AWS.SageMaker.html#create_processing_job/3","title":"AWS.SageMaker.create_processing_job/3","type":"function","doc":"Creates a processing job."},{"ref":"AWS.SageMaker.html#create_training_job/3","title":"AWS.SageMaker.create_training_job/3","type":"function","doc":"Starts a model training job. After training completes, Amazon SageMaker saves the resulting model artifacts to an Amazon S3 location that you specify. If you choose to host your model using Amazon SageMaker hosting services, you can use the resulting model artifacts as part of the model. You can also use the artifacts in a machine learning service other than Amazon SageMaker, provided that you know how to use them for inferences. In the request body, you provide the following: AlgorithmSpecification - Identifies the training algorithm to use. HyperParameters - Specify these algorithm-specific parameters to enable the estimation of model parameters during training. Hyperparameters can be tuned to optimize this learning process. For a list of hyperparameters for each training algorithm provided by Amazon SageMaker, see Algorithms. * InputDataConfig - Describes the training dataset and the Amazon S3, EFS, or FSx location where it is stored. OutputDataConfig - Identifies the Amazon S3 bucket where you want Amazon SageMaker to save the results of model training. ResourceConfig - Identifies the resources, ML compute instances, and ML storage volumes to deploy for model training. In distributed training, you specify more than one instance. EnableManagedSpotTraining - Optimize the cost of training machine learning models by up to 80% by using Amazon EC2 Spot instances. For more information, see Managed Spot Training. RoleARN - The Amazon Resource Number (ARN) that Amazon SageMaker assumes to perform tasks on your behalf during model training. You must grant this role the necessary permissions so that Amazon SageMaker can successfully complete model training. StoppingCondition - To help cap training costs, use MaxRuntimeInSeconds to set a time limit for training. Use MaxWaitTimeInSeconds to specify how long you are willing to wait for a managed spot training job to complete. For more information about Amazon SageMaker, see How It Works."},{"ref":"AWS.SageMaker.html#create_transform_job/3","title":"AWS.SageMaker.create_transform_job/3","type":"function","doc":"Starts a transform job. A transform job uses a trained model to get inferences on a dataset and saves these results to an Amazon S3 location that you specify. To perform batch transformations, you create a transform job and use the data that you have readily available. In the request body, you provide the following: TransformJobName - Identifies the transform job. The name must be unique within an AWS Region in an AWS account. ModelName - Identifies the model to use. ModelName must be the name of an existing Amazon SageMaker model in the same AWS Region and AWS account. For information on creating a model, see CreateModel. TransformInput - Describes the dataset to be transformed and the Amazon S3 location where it is stored. TransformOutput - Identifies the Amazon S3 location where you want Amazon SageMaker to save the results from the transform job. TransformResources - Identifies the ML compute instances for the transform job. For more information about how batch transformation works, see Batch Transform."},{"ref":"AWS.SageMaker.html#create_trial/3","title":"AWS.SageMaker.create_trial/3","type":"function","doc":"Creates an Amazon SageMaker trial. A trial is a set of steps called trial components that produce a machine learning model. A trial is part of a single Amazon SageMaker experiment. When you use Amazon SageMaker Studio or the Amazon SageMaker Python SDK, all experiments, trials, and trial components are automatically tracked, logged, and indexed. When you use the AWS SDK for Python (Boto), you must use the logging APIs provided by the SDK. You can add tags to a trial and then use the Search API to search for the tags. To get a list of all your trials, call the ListTrials API. To view a trial&#39;s properties, call the DescribeTrial API. To create a trial component, call the CreateTrialComponent API."},{"ref":"AWS.SageMaker.html#create_trial_component/3","title":"AWS.SageMaker.create_trial_component/3","type":"function","doc":"Creates a trial component, which is a stage of a machine learning trial. A trial is composed of one or more trial components. A trial component can be used in multiple trials. Trial components include pre-processing jobs, training jobs, and batch transform jobs. When you use Amazon SageMaker Studio or the Amazon SageMaker Python SDK, all experiments, trials, and trial components are automatically tracked, logged, and indexed. When you use the AWS SDK for Python (Boto), you must use the logging APIs provided by the SDK. You can add tags to a trial component and then use the Search API to search for the tags. CreateTrialComponent can only be invoked from within an Amazon SageMaker managed environment. This includes Amazon SageMaker training jobs, processing jobs, transform jobs, and Amazon SageMaker notebooks. A call to CreateTrialComponent from outside one of these environments results in an error."},{"ref":"AWS.SageMaker.html#create_user_profile/3","title":"AWS.SageMaker.create_user_profile/3","type":"function","doc":"Creates a user profile. A user profile represents a single user within a domain, and is the main way to reference a &quot;person&quot; for the purposes of sharing, reporting, and other user-oriented features. This entity is created when a user onboards to Amazon SageMaker Studio. If an administrator invites a person by email or imports them from SSO, a user profile is automatically created. A user profile is the primary holder of settings for an individual user and has a reference to the user&#39;s private Amazon Elastic File System (EFS) home directory."},{"ref":"AWS.SageMaker.html#create_workforce/3","title":"AWS.SageMaker.create_workforce/3","type":"function","doc":"Use this operation to create a workforce. This operation will return an error if a workforce already exists in the AWS Region that you specify. You can only create one workforce in each AWS Region per AWS account. If you want to create a new workforce in an AWS Region where a workforce already exists, use the API operation to delete the existing workforce and then use CreateWorkforce to create a new workforce. To create a private workforce using Amazon Cognito, you must specify a Cognito user pool in CognitoConfig. You can also create an Amazon Cognito workforce using the Amazon SageMaker console. For more information, see Create a Private Workforce (Amazon Cognito). To create a private workforce using your own OIDC Identity Provider (IdP), specify your IdP configuration in OidcConfig. Your OIDC IdP must support groups because groups are used by Ground Truth and Amazon A2I to create work teams. For more information, see Create a Private Workforce (OIDC IdP)."},{"ref":"AWS.SageMaker.html#create_workteam/3","title":"AWS.SageMaker.create_workteam/3","type":"function","doc":"Creates a new work team for labeling your data. A work team is defined by one or more Amazon Cognito user pools. You must first create the user pools before you can create a work team. You cannot create more than 25 work teams in an account and region."},{"ref":"AWS.SageMaker.html#delete_algorithm/3","title":"AWS.SageMaker.delete_algorithm/3","type":"function","doc":"Removes the specified algorithm from your account."},{"ref":"AWS.SageMaker.html#delete_app/3","title":"AWS.SageMaker.delete_app/3","type":"function","doc":"Used to stop and delete an app."},{"ref":"AWS.SageMaker.html#delete_code_repository/3","title":"AWS.SageMaker.delete_code_repository/3","type":"function","doc":"Deletes the specified Git repository from your account."},{"ref":"AWS.SageMaker.html#delete_domain/3","title":"AWS.SageMaker.delete_domain/3","type":"function","doc":"Used to delete a domain. If you onboarded with IAM mode, you will need to delete your domain to onboard again using SSO. Use with caution. All of the members of the domain will lose access to their EFS volume, including data, notebooks, and other artifacts."},{"ref":"AWS.SageMaker.html#delete_endpoint/3","title":"AWS.SageMaker.delete_endpoint/3","type":"function","doc":"Deletes an endpoint. Amazon SageMaker frees up all of the resources that were deployed when the endpoint was created. Amazon SageMaker retires any custom KMS key grants associated with the endpoint, meaning you don&#39;t need to use the RevokeGrant API call."},{"ref":"AWS.SageMaker.html#delete_endpoint_config/3","title":"AWS.SageMaker.delete_endpoint_config/3","type":"function","doc":"Deletes an endpoint configuration. The DeleteEndpointConfig API deletes only the specified configuration. It does not delete endpoints created using the configuration. You must not delete an EndpointConfig in use by an endpoint that is live or while the UpdateEndpoint or CreateEndpoint operations are being performed on the endpoint. If you delete the EndpointConfig of an endpoint that is active or being created or updated you may lose visibility into the instance type the endpoint is using. The endpoint must be deleted in order to stop incurring charges."},{"ref":"AWS.SageMaker.html#delete_experiment/3","title":"AWS.SageMaker.delete_experiment/3","type":"function","doc":"Deletes an Amazon SageMaker experiment. All trials associated with the experiment must be deleted first. Use the ListTrials API to get a list of the trials associated with the experiment."},{"ref":"AWS.SageMaker.html#delete_flow_definition/3","title":"AWS.SageMaker.delete_flow_definition/3","type":"function","doc":"Deletes the specified flow definition."},{"ref":"AWS.SageMaker.html#delete_human_task_ui/3","title":"AWS.SageMaker.delete_human_task_ui/3","type":"function","doc":"Use this operation to delete a human task user interface (worker task template). To see a list of human task user interfaces (work task templates) in your account, use . When you delete a worker task template, it no longer appears when you call ListHumanTaskUis."},{"ref":"AWS.SageMaker.html#delete_model/3","title":"AWS.SageMaker.delete_model/3","type":"function","doc":"Deletes a model. The DeleteModel API deletes only the model entry that was created in Amazon SageMaker when you called the CreateModel API. It does not delete model artifacts, inference code, or the IAM role that you specified when creating the model."},{"ref":"AWS.SageMaker.html#delete_model_package/3","title":"AWS.SageMaker.delete_model_package/3","type":"function","doc":"Deletes a model package. A model package is used to create Amazon SageMaker models or list on AWS Marketplace. Buyers can subscribe to model packages listed on AWS Marketplace to create models in Amazon SageMaker."},{"ref":"AWS.SageMaker.html#delete_monitoring_schedule/3","title":"AWS.SageMaker.delete_monitoring_schedule/3","type":"function","doc":"Deletes a monitoring schedule. Also stops the schedule had not already been stopped. This does not delete the job execution history of the monitoring schedule."},{"ref":"AWS.SageMaker.html#delete_notebook_instance/3","title":"AWS.SageMaker.delete_notebook_instance/3","type":"function","doc":"Deletes an Amazon SageMaker notebook instance. Before you can delete a notebook instance, you must call the StopNotebookInstance API. When you delete a notebook instance, you lose all of your data. Amazon SageMaker removes the ML compute instance, and deletes the ML storage volume and the network interface associated with the notebook instance."},{"ref":"AWS.SageMaker.html#delete_notebook_instance_lifecycle_config/3","title":"AWS.SageMaker.delete_notebook_instance_lifecycle_config/3","type":"function","doc":"Deletes a notebook instance lifecycle configuration."},{"ref":"AWS.SageMaker.html#delete_tags/3","title":"AWS.SageMaker.delete_tags/3","type":"function","doc":"Deletes the specified tags from an Amazon SageMaker resource. To list a resource&#39;s tags, use the ListTags API. When you call this API to delete tags from a hyperparameter tuning job, the deleted tags are not removed from training jobs that the hyperparameter tuning job launched before you called this API."},{"ref":"AWS.SageMaker.html#delete_trial/3","title":"AWS.SageMaker.delete_trial/3","type":"function","doc":"Deletes the specified trial. All trial components that make up the trial must be deleted first. Use the DescribeTrialComponent API to get the list of trial components."},{"ref":"AWS.SageMaker.html#delete_trial_component/3","title":"AWS.SageMaker.delete_trial_component/3","type":"function","doc":"Deletes the specified trial component. A trial component must be disassociated from all trials before the trial component can be deleted. To disassociate a trial component from a trial, call the DisassociateTrialComponent API."},{"ref":"AWS.SageMaker.html#delete_user_profile/3","title":"AWS.SageMaker.delete_user_profile/3","type":"function","doc":"Deletes a user profile. When a user profile is deleted, the user loses access to their EFS volume, including data, notebooks, and other artifacts."},{"ref":"AWS.SageMaker.html#delete_workforce/3","title":"AWS.SageMaker.delete_workforce/3","type":"function","doc":"Use this operation to delete a workforce. If you want to create a new workforce in an AWS Region where a workforce already exists, use this operation to delete the existing workforce and then use to create a new workforce. If a private workforce contains one or more work teams, you must use the operation to delete all work teams before you delete the workforce. If you try to delete a workforce that contains one or more work teams, you will recieve a ResourceInUse error."},{"ref":"AWS.SageMaker.html#delete_workteam/3","title":"AWS.SageMaker.delete_workteam/3","type":"function","doc":"Deletes an existing work team. This operation can&#39;t be undone."},{"ref":"AWS.SageMaker.html#describe_algorithm/3","title":"AWS.SageMaker.describe_algorithm/3","type":"function","doc":"Returns a description of the specified algorithm that is in your account."},{"ref":"AWS.SageMaker.html#describe_app/3","title":"AWS.SageMaker.describe_app/3","type":"function","doc":"Describes the app."},{"ref":"AWS.SageMaker.html#describe_auto_m_l_job/3","title":"AWS.SageMaker.describe_auto_m_l_job/3","type":"function","doc":"Returns information about an Amazon SageMaker job."},{"ref":"AWS.SageMaker.html#describe_code_repository/3","title":"AWS.SageMaker.describe_code_repository/3","type":"function","doc":"Gets details about the specified Git repository."},{"ref":"AWS.SageMaker.html#describe_compilation_job/3","title":"AWS.SageMaker.describe_compilation_job/3","type":"function","doc":"Returns information about a model compilation job. To create a model compilation job, use CreateCompilationJob. To get information about multiple model compilation jobs, use ListCompilationJobs."},{"ref":"AWS.SageMaker.html#describe_domain/3","title":"AWS.SageMaker.describe_domain/3","type":"function","doc":"The description of the domain."},{"ref":"AWS.SageMaker.html#describe_endpoint/3","title":"AWS.SageMaker.describe_endpoint/3","type":"function","doc":"Returns the description of an endpoint."},{"ref":"AWS.SageMaker.html#describe_endpoint_config/3","title":"AWS.SageMaker.describe_endpoint_config/3","type":"function","doc":"Returns the description of an endpoint configuration created using the CreateEndpointConfig API."},{"ref":"AWS.SageMaker.html#describe_experiment/3","title":"AWS.SageMaker.describe_experiment/3","type":"function","doc":"Provides a list of an experiment&#39;s properties."},{"ref":"AWS.SageMaker.html#describe_flow_definition/3","title":"AWS.SageMaker.describe_flow_definition/3","type":"function","doc":"Returns information about the specified flow definition."},{"ref":"AWS.SageMaker.html#describe_human_task_ui/3","title":"AWS.SageMaker.describe_human_task_ui/3","type":"function","doc":"Returns information about the requested human task user interface (worker task template)."},{"ref":"AWS.SageMaker.html#describe_hyper_parameter_tuning_job/3","title":"AWS.SageMaker.describe_hyper_parameter_tuning_job/3","type":"function","doc":"Gets a description of a hyperparameter tuning job."},{"ref":"AWS.SageMaker.html#describe_labeling_job/3","title":"AWS.SageMaker.describe_labeling_job/3","type":"function","doc":"Gets information about a labeling job."},{"ref":"AWS.SageMaker.html#describe_model/3","title":"AWS.SageMaker.describe_model/3","type":"function","doc":"Describes a model that you created using the CreateModel API."},{"ref":"AWS.SageMaker.html#describe_model_package/3","title":"AWS.SageMaker.describe_model_package/3","type":"function","doc":"Returns a description of the specified model package, which is used to create Amazon SageMaker models or list them on AWS Marketplace. To create models in Amazon SageMaker, buyers can subscribe to model packages listed on AWS Marketplace."},{"ref":"AWS.SageMaker.html#describe_monitoring_schedule/3","title":"AWS.SageMaker.describe_monitoring_schedule/3","type":"function","doc":"Describes the schedule for a monitoring job."},{"ref":"AWS.SageMaker.html#describe_notebook_instance/3","title":"AWS.SageMaker.describe_notebook_instance/3","type":"function","doc":"Returns information about a notebook instance."},{"ref":"AWS.SageMaker.html#describe_notebook_instance_lifecycle_config/3","title":"AWS.SageMaker.describe_notebook_instance_lifecycle_config/3","type":"function","doc":"Returns a description of a notebook instance lifecycle configuration. For information about notebook instance lifestyle configurations, see Step 2.1: (Optional) Customize a Notebook Instance."},{"ref":"AWS.SageMaker.html#describe_processing_job/3","title":"AWS.SageMaker.describe_processing_job/3","type":"function","doc":"Returns a description of a processing job."},{"ref":"AWS.SageMaker.html#describe_subscribed_workteam/3","title":"AWS.SageMaker.describe_subscribed_workteam/3","type":"function","doc":"Gets information about a work team provided by a vendor. It returns details about the subscription with a vendor in the AWS Marketplace."},{"ref":"AWS.SageMaker.html#describe_training_job/3","title":"AWS.SageMaker.describe_training_job/3","type":"function","doc":"Returns information about a training job."},{"ref":"AWS.SageMaker.html#describe_transform_job/3","title":"AWS.SageMaker.describe_transform_job/3","type":"function","doc":"Returns information about a transform job."},{"ref":"AWS.SageMaker.html#describe_trial/3","title":"AWS.SageMaker.describe_trial/3","type":"function","doc":"Provides a list of a trial&#39;s properties."},{"ref":"AWS.SageMaker.html#describe_trial_component/3","title":"AWS.SageMaker.describe_trial_component/3","type":"function","doc":"Provides a list of a trials component&#39;s properties."},{"ref":"AWS.SageMaker.html#describe_user_profile/3","title":"AWS.SageMaker.describe_user_profile/3","type":"function","doc":"Describes a user profile. For more information, see CreateUserProfile."},{"ref":"AWS.SageMaker.html#describe_workforce/3","title":"AWS.SageMaker.describe_workforce/3","type":"function","doc":"Lists private workforce information, including workforce name, Amazon Resource Name (ARN), and, if applicable, allowed IP address ranges (CIDRs). Allowable IP address ranges are the IP addresses that workers can use to access tasks. This operation applies only to private workforces."},{"ref":"AWS.SageMaker.html#describe_workteam/3","title":"AWS.SageMaker.describe_workteam/3","type":"function","doc":"Gets information about a specific work team. You can see information such as the create date, the last updated date, membership information, and the work team&#39;s Amazon Resource Name (ARN)."},{"ref":"AWS.SageMaker.html#disassociate_trial_component/3","title":"AWS.SageMaker.disassociate_trial_component/3","type":"function","doc":"Disassociates a trial component from a trial. This doesn&#39;t effect other trials the component is associated with. Before you can delete a component, you must disassociate the component from all trials it is associated with. To associate a trial component with a trial, call the AssociateTrialComponent API. To get a list of the trials a component is associated with, use the Search API. Specify ExperimentTrialComponent for the Resource parameter. The list appears in the response under Results.TrialComponent.Parents."},{"ref":"AWS.SageMaker.html#get_search_suggestions/3","title":"AWS.SageMaker.get_search_suggestions/3","type":"function","doc":"An auto-complete API for the search functionality in the Amazon SageMaker console. It returns suggestions of possible matches for the property name to use in Search queries. Provides suggestions for HyperParameters, Tags, and Metrics."},{"ref":"AWS.SageMaker.html#list_algorithms/3","title":"AWS.SageMaker.list_algorithms/3","type":"function","doc":"Lists the machine learning algorithms that have been created."},{"ref":"AWS.SageMaker.html#list_apps/3","title":"AWS.SageMaker.list_apps/3","type":"function","doc":"Lists apps."},{"ref":"AWS.SageMaker.html#list_auto_m_l_jobs/3","title":"AWS.SageMaker.list_auto_m_l_jobs/3","type":"function","doc":"Request a list of jobs."},{"ref":"AWS.SageMaker.html#list_candidates_for_auto_m_l_job/3","title":"AWS.SageMaker.list_candidates_for_auto_m_l_job/3","type":"function","doc":"List the Candidates created for the job."},{"ref":"AWS.SageMaker.html#list_code_repositories/3","title":"AWS.SageMaker.list_code_repositories/3","type":"function","doc":"Gets a list of the Git repositories in your account."},{"ref":"AWS.SageMaker.html#list_compilation_jobs/3","title":"AWS.SageMaker.list_compilation_jobs/3","type":"function","doc":"Lists model compilation jobs that satisfy various filters. To create a model compilation job, use CreateCompilationJob. To get information about a particular model compilation job you have created, use DescribeCompilationJob."},{"ref":"AWS.SageMaker.html#list_domains/3","title":"AWS.SageMaker.list_domains/3","type":"function","doc":"Lists the domains."},{"ref":"AWS.SageMaker.html#list_endpoint_configs/3","title":"AWS.SageMaker.list_endpoint_configs/3","type":"function","doc":"Lists endpoint configurations."},{"ref":"AWS.SageMaker.html#list_endpoints/3","title":"AWS.SageMaker.list_endpoints/3","type":"function","doc":"Lists endpoints."},{"ref":"AWS.SageMaker.html#list_experiments/3","title":"AWS.SageMaker.list_experiments/3","type":"function","doc":"Lists all the experiments in your account. The list can be filtered to show only experiments that were created in a specific time range. The list can be sorted by experiment name or creation time."},{"ref":"AWS.SageMaker.html#list_flow_definitions/3","title":"AWS.SageMaker.list_flow_definitions/3","type":"function","doc":"Returns information about the flow definitions in your account."},{"ref":"AWS.SageMaker.html#list_human_task_uis/3","title":"AWS.SageMaker.list_human_task_uis/3","type":"function","doc":"Returns information about the human task user interfaces in your account."},{"ref":"AWS.SageMaker.html#list_hyper_parameter_tuning_jobs/3","title":"AWS.SageMaker.list_hyper_parameter_tuning_jobs/3","type":"function","doc":"Gets a list of HyperParameterTuningJobSummary objects that describe the hyperparameter tuning jobs launched in your account."},{"ref":"AWS.SageMaker.html#list_labeling_jobs/3","title":"AWS.SageMaker.list_labeling_jobs/3","type":"function","doc":"Gets a list of labeling jobs."},{"ref":"AWS.SageMaker.html#list_labeling_jobs_for_workteam/3","title":"AWS.SageMaker.list_labeling_jobs_for_workteam/3","type":"function","doc":"Gets a list of labeling jobs assigned to a specified work team."},{"ref":"AWS.SageMaker.html#list_model_packages/3","title":"AWS.SageMaker.list_model_packages/3","type":"function","doc":"Lists the model packages that have been created."},{"ref":"AWS.SageMaker.html#list_models/3","title":"AWS.SageMaker.list_models/3","type":"function","doc":"Lists models created with the CreateModel API."},{"ref":"AWS.SageMaker.html#list_monitoring_executions/3","title":"AWS.SageMaker.list_monitoring_executions/3","type":"function","doc":"Returns list of all monitoring job executions."},{"ref":"AWS.SageMaker.html#list_monitoring_schedules/3","title":"AWS.SageMaker.list_monitoring_schedules/3","type":"function","doc":"Returns list of all monitoring schedules."},{"ref":"AWS.SageMaker.html#list_notebook_instance_lifecycle_configs/3","title":"AWS.SageMaker.list_notebook_instance_lifecycle_configs/3","type":"function","doc":"Lists notebook instance lifestyle configurations created with the CreateNotebookInstanceLifecycleConfig API."},{"ref":"AWS.SageMaker.html#list_notebook_instances/3","title":"AWS.SageMaker.list_notebook_instances/3","type":"function","doc":"Returns a list of the Amazon SageMaker notebook instances in the requester&#39;s account in an AWS Region."},{"ref":"AWS.SageMaker.html#list_processing_jobs/3","title":"AWS.SageMaker.list_processing_jobs/3","type":"function","doc":"Lists processing jobs that satisfy various filters."},{"ref":"AWS.SageMaker.html#list_subscribed_workteams/3","title":"AWS.SageMaker.list_subscribed_workteams/3","type":"function","doc":"Gets a list of the work teams that you are subscribed to in the AWS Marketplace. The list may be empty if no work team satisfies the filter specified in the NameContains parameter."},{"ref":"AWS.SageMaker.html#list_tags/3","title":"AWS.SageMaker.list_tags/3","type":"function","doc":"Returns the tags for the specified Amazon SageMaker resource."},{"ref":"AWS.SageMaker.html#list_training_jobs/3","title":"AWS.SageMaker.list_training_jobs/3","type":"function","doc":"Lists training jobs."},{"ref":"AWS.SageMaker.html#list_training_jobs_for_hyper_parameter_tuning_job/3","title":"AWS.SageMaker.list_training_jobs_for_hyper_parameter_tuning_job/3","type":"function","doc":"Gets a list of TrainingJobSummary objects that describe the training jobs that a hyperparameter tuning job launched."},{"ref":"AWS.SageMaker.html#list_transform_jobs/3","title":"AWS.SageMaker.list_transform_jobs/3","type":"function","doc":"Lists transform jobs."},{"ref":"AWS.SageMaker.html#list_trial_components/3","title":"AWS.SageMaker.list_trial_components/3","type":"function","doc":"Lists the trial components in your account. You can sort the list by trial component name or creation time. You can filter the list to show only components that were created in a specific time range. You can also filter on one of the following: ExperimentName SourceArn TrialName"},{"ref":"AWS.SageMaker.html#list_trials/3","title":"AWS.SageMaker.list_trials/3","type":"function","doc":"Lists the trials in your account. Specify an experiment name to limit the list to the trials that are part of that experiment. Specify a trial component name to limit the list to the trials that associated with that trial component. The list can be filtered to show only trials that were created in a specific time range. The list can be sorted by trial name or creation time."},{"ref":"AWS.SageMaker.html#list_user_profiles/3","title":"AWS.SageMaker.list_user_profiles/3","type":"function","doc":"Lists user profiles."},{"ref":"AWS.SageMaker.html#list_workforces/3","title":"AWS.SageMaker.list_workforces/3","type":"function","doc":"Use this operation to list all private and vendor workforces in an AWS Region. Note that you can only have one private workforce per AWS Region."},{"ref":"AWS.SageMaker.html#list_workteams/3","title":"AWS.SageMaker.list_workteams/3","type":"function","doc":"Gets a list of private work teams that you have defined in a region. The list may be empty if no work team satisfies the filter specified in the NameContains parameter."},{"ref":"AWS.SageMaker.html#render_ui_template/3","title":"AWS.SageMaker.render_ui_template/3","type":"function","doc":"Renders the UI template so that you can preview the worker&#39;s experience."},{"ref":"AWS.SageMaker.html#search/3","title":"AWS.SageMaker.search/3","type":"function","doc":"Finds Amazon SageMaker resources that match a search query. Matching resources are returned as a list of SearchRecord objects in the response. You can sort the search results by any resource property in a ascending or descending order. You can query against the following value types: numeric, text, Boolean, and timestamp."},{"ref":"AWS.SageMaker.html#start_monitoring_schedule/3","title":"AWS.SageMaker.start_monitoring_schedule/3","type":"function","doc":"Starts a previously stopped monitoring schedule. New monitoring schedules are immediately started after creation."},{"ref":"AWS.SageMaker.html#start_notebook_instance/3","title":"AWS.SageMaker.start_notebook_instance/3","type":"function","doc":"Launches an ML compute instance with the latest version of the libraries and attaches your ML storage volume. After configuring the notebook instance, Amazon SageMaker sets the notebook instance status to InService. A notebook instance&#39;s status must be InService before you can connect to your Jupyter notebook."},{"ref":"AWS.SageMaker.html#stop_auto_m_l_job/3","title":"AWS.SageMaker.stop_auto_m_l_job/3","type":"function","doc":"A method for forcing the termination of a running job."},{"ref":"AWS.SageMaker.html#stop_compilation_job/3","title":"AWS.SageMaker.stop_compilation_job/3","type":"function","doc":"Stops a model compilation job. To stop a job, Amazon SageMaker sends the algorithm the SIGTERM signal. This gracefully shuts the job down. If the job hasn&#39;t stopped, it sends the SIGKILL signal. When it receives a StopCompilationJob request, Amazon SageMaker changes the CompilationJobSummary$CompilationJobStatus of the job to Stopping. After Amazon SageMaker stops the job, it sets the CompilationJobSummary$CompilationJobStatus to Stopped."},{"ref":"AWS.SageMaker.html#stop_hyper_parameter_tuning_job/3","title":"AWS.SageMaker.stop_hyper_parameter_tuning_job/3","type":"function","doc":"Stops a running hyperparameter tuning job and all running training jobs that the tuning job launched. All model artifacts output from the training jobs are stored in Amazon Simple Storage Service (Amazon S3). All data that the training jobs write to Amazon CloudWatch Logs are still available in CloudWatch. After the tuning job moves to the Stopped state, it releases all reserved resources for the tuning job."},{"ref":"AWS.SageMaker.html#stop_labeling_job/3","title":"AWS.SageMaker.stop_labeling_job/3","type":"function","doc":"Stops a running labeling job. A job that is stopped cannot be restarted. Any results obtained before the job is stopped are placed in the Amazon S3 output bucket."},{"ref":"AWS.SageMaker.html#stop_monitoring_schedule/3","title":"AWS.SageMaker.stop_monitoring_schedule/3","type":"function","doc":"Stops a previously started monitoring schedule."},{"ref":"AWS.SageMaker.html#stop_notebook_instance/3","title":"AWS.SageMaker.stop_notebook_instance/3","type":"function","doc":"Terminates the ML compute instance. Before terminating the instance, Amazon SageMaker disconnects the ML storage volume from it. Amazon SageMaker preserves the ML storage volume. Amazon SageMaker stops charging you for the ML compute instance when you call StopNotebookInstance. To access data on the ML storage volume for a notebook instance that has been terminated, call the StartNotebookInstance API. StartNotebookInstance launches another ML compute instance, configures it, and attaches the preserved ML storage volume so you can continue your work."},{"ref":"AWS.SageMaker.html#stop_processing_job/3","title":"AWS.SageMaker.stop_processing_job/3","type":"function","doc":"Stops a processing job."},{"ref":"AWS.SageMaker.html#stop_training_job/3","title":"AWS.SageMaker.stop_training_job/3","type":"function","doc":"Stops a training job. To stop a job, Amazon SageMaker sends the algorithm the SIGTERM signal, which delays job termination for 120 seconds. Algorithms might use this 120-second window to save the model artifacts, so the results of the training is not lost. When it receives a StopTrainingJob request, Amazon SageMaker changes the status of the job to Stopping. After Amazon SageMaker stops the job, it sets the status to Stopped."},{"ref":"AWS.SageMaker.html#stop_transform_job/3","title":"AWS.SageMaker.stop_transform_job/3","type":"function","doc":"Stops a transform job. When Amazon SageMaker receives a StopTransformJob request, the status of the job changes to Stopping. After Amazon SageMaker stops the job, the status is set to Stopped. When you stop a transform job before it is completed, Amazon SageMaker doesn&#39;t store the job&#39;s output in Amazon S3."},{"ref":"AWS.SageMaker.html#update_code_repository/3","title":"AWS.SageMaker.update_code_repository/3","type":"function","doc":"Updates the specified Git repository with the specified values."},{"ref":"AWS.SageMaker.html#update_domain/3","title":"AWS.SageMaker.update_domain/3","type":"function","doc":"Updates the default settings for new user profiles in the domain."},{"ref":"AWS.SageMaker.html#update_endpoint/3","title":"AWS.SageMaker.update_endpoint/3","type":"function","doc":"Deploys the new EndpointConfig specified in the request, switches to using newly created endpoint, and then deletes resources provisioned for the endpoint using the previous EndpointConfig (there is no availability loss). When Amazon SageMaker receives the request, it sets the endpoint status to Updating. After updating the endpoint, it sets the status to InService. To check the status of an endpoint, use the DescribeEndpoint API. You must not delete an EndpointConfig in use by an endpoint that is live or while the UpdateEndpoint or CreateEndpoint operations are being performed on the endpoint. To update an endpoint, you must create a new EndpointConfig. If you delete the EndpointConfig of an endpoint that is active or being created or updated you may lose visibility into the instance type the endpoint is using. The endpoint must be deleted in order to stop incurring charges."},{"ref":"AWS.SageMaker.html#update_endpoint_weights_and_capacities/3","title":"AWS.SageMaker.update_endpoint_weights_and_capacities/3","type":"function","doc":"Updates variant weight of one or more variants associated with an existing endpoint, or capacity of one variant associated with an existing endpoint. When it receives the request, Amazon SageMaker sets the endpoint status to Updating. After updating the endpoint, it sets the status to InService. To check the status of an endpoint, use the DescribeEndpoint API."},{"ref":"AWS.SageMaker.html#update_experiment/3","title":"AWS.SageMaker.update_experiment/3","type":"function","doc":"Adds, updates, or removes the description of an experiment. Updates the display name of an experiment."},{"ref":"AWS.SageMaker.html#update_monitoring_schedule/3","title":"AWS.SageMaker.update_monitoring_schedule/3","type":"function","doc":"Updates a previously created schedule."},{"ref":"AWS.SageMaker.html#update_notebook_instance/3","title":"AWS.SageMaker.update_notebook_instance/3","type":"function","doc":"Updates a notebook instance. NotebookInstance updates include upgrading or downgrading the ML compute instance used for your notebook instance to accommodate changes in your workload requirements."},{"ref":"AWS.SageMaker.html#update_notebook_instance_lifecycle_config/3","title":"AWS.SageMaker.update_notebook_instance_lifecycle_config/3","type":"function","doc":"Updates a notebook instance lifecycle configuration created with the CreateNotebookInstanceLifecycleConfig API."},{"ref":"AWS.SageMaker.html#update_trial/3","title":"AWS.SageMaker.update_trial/3","type":"function","doc":"Updates the display name of a trial."},{"ref":"AWS.SageMaker.html#update_trial_component/3","title":"AWS.SageMaker.update_trial_component/3","type":"function","doc":"Updates one or more properties of a trial component."},{"ref":"AWS.SageMaker.html#update_user_profile/3","title":"AWS.SageMaker.update_user_profile/3","type":"function","doc":"Updates a user profile."},{"ref":"AWS.SageMaker.html#update_workforce/3","title":"AWS.SageMaker.update_workforce/3","type":"function","doc":"Use this operation to update your workforce. You can use this operation to require that workers use specific IP addresses to work on tasks and to update your OpenID Connect (OIDC) Identity Provider (IdP) workforce configuration. Use SourceIpConfig to restrict worker access to tasks to a specific range of IP addresses. You specify allowed IP addresses by creating a list of up to ten CIDRs. By default, a workforce isn&#39;t restricted to specific IP addresses. If you specify a range of IP addresses, workers who attempt to access tasks using any IP address outside the specified range are denied and get a Not Found error message on the worker portal. Use OidcConfig to update the configuration of a workforce created using your own OIDC IdP. You can only update your OIDC IdP configuration when there are no work teams associated with your workforce. You can delete work teams using the operation. After restricting access to a range of IP addresses or updating your OIDC IdP configuration with this operation, you can view details about your update workforce using the operation. This operation only applies to private workforces."},{"ref":"AWS.SageMaker.html#update_workteam/3","title":"AWS.SageMaker.update_workteam/3","type":"function","doc":"Updates an existing work team with new member definitions or description."},{"ref":"AWS.SageMakerA2IRuntime.html","title":"AWS.SageMakerA2IRuntime","type":"module","doc":"Amazon Augmented AI is in preview release and is subject to change. We do not recommend using this product in production environments. Amazon Augmented AI (Amazon A2I) adds the benefit of human judgment to any machine learning application. When an AI application can&#39;t evaluate data with a high degree of confidence, human reviewers can take over. This human review is called a human review workflow. To create and start a human review workflow, you need three resources: a worker task template, a flow definition, and a human loop. For information about these resources and prerequisites for using Amazon A2I, see Get Started with Amazon Augmented AI in the Amazon SageMaker Developer Guide. This API reference includes information about API actions and data types that you can use to interact with Amazon A2I programmatically. Use this guide to: Start a human loop with the StartHumanLoop operation when using Amazon A2I with a custom task type. To learn more about the difference between custom and built-in task types, see Use Task Types . To learn how to start a human loop using this API, see Create and Start a Human Loop for a Custom Task Type in the Amazon SageMaker Developer Guide. Manage your human loops. You can list all human loops that you have created, describe individual human loops, and stop and delete human loops. To learn more, see Monitor and Manage Your Human Loop in the Amazon SageMaker Developer Guide. Amazon A2I integrates APIs from various AWS services to create and start human review workflows for those services. To learn how Amazon A2I uses these APIs, see Use APIs in Amazon A2I in the Amazon SageMaker Developer Guide."},{"ref":"AWS.SageMakerA2IRuntime.html#delete_human_loop/4","title":"AWS.SageMakerA2IRuntime.delete_human_loop/4","type":"function","doc":"Deletes the specified human loop for a flow definition."},{"ref":"AWS.SageMakerA2IRuntime.html#describe_human_loop/3","title":"AWS.SageMakerA2IRuntime.describe_human_loop/3","type":"function","doc":"Returns information about the specified human loop."},{"ref":"AWS.SageMakerA2IRuntime.html#list_human_loops/8","title":"AWS.SageMakerA2IRuntime.list_human_loops/8","type":"function","doc":"Returns information about human loops, given the specified parameters. If a human loop was deleted, it will not be included."},{"ref":"AWS.SageMakerA2IRuntime.html#start_human_loop/3","title":"AWS.SageMakerA2IRuntime.start_human_loop/3","type":"function","doc":"Starts a human loop, provided that at least one activation condition is met."},{"ref":"AWS.SageMakerA2IRuntime.html#stop_human_loop/3","title":"AWS.SageMakerA2IRuntime.stop_human_loop/3","type":"function","doc":"Stops the specified human loop."},{"ref":"AWS.SageMakerRuntime.html","title":"AWS.SageMakerRuntime","type":"module","doc":"The Amazon SageMaker runtime API."},{"ref":"AWS.SageMakerRuntime.html#invoke_endpoint/4","title":"AWS.SageMakerRuntime.invoke_endpoint/4","type":"function","doc":"After you deploy a model into production using Amazon SageMaker hosting services, your client applications use this API to get inferences from the model hosted at the specified endpoint. For an overview of Amazon SageMaker, see How It Works. Amazon SageMaker strips all POST headers except those supported by the API. Amazon SageMaker might add additional headers. You should not rely on the behavior of headers outside those enumerated in the request syntax. Calls to InvokeEndpoint are authenticated by using AWS Signature Version 4. For information, see Authenticating Requests (AWS Signature Version 4) in the Amazon S3 API Reference. A customer&#39;s model containers must respond to requests within 60 seconds. The model itself can have a maximum processing time of 60 seconds before responding to the /invocations. If your model is going to take 50-60 seconds of processing time, the SDK socket timeout should be set to be 70 seconds. Endpoints are scoped to an individual account, and are not public. The URL does not contain the account ID, but Amazon SageMaker determines the account ID from the authentication token that is supplied by the caller."},{"ref":"AWS.Savingsplans.html","title":"AWS.Savingsplans","type":"module","doc":"Savings Plans are a pricing model that offer significant savings on AWS usage (for example, on Amazon EC2 instances). You commit to a consistent amount of usage, in USD per hour, for a term of 1 or 3 years, and receive a lower price for that usage. For more information, see the AWS Savings Plans User Guide."},{"ref":"AWS.Savingsplans.html#create_savings_plan/3","title":"AWS.Savingsplans.create_savings_plan/3","type":"function","doc":"Creates a Savings Plan."},{"ref":"AWS.Savingsplans.html#delete_queued_savings_plan/3","title":"AWS.Savingsplans.delete_queued_savings_plan/3","type":"function","doc":"Deletes the queued purchase for the specified Savings Plan."},{"ref":"AWS.Savingsplans.html#describe_savings_plan_rates/3","title":"AWS.Savingsplans.describe_savings_plan_rates/3","type":"function","doc":"Describes the specified Savings Plans rates."},{"ref":"AWS.Savingsplans.html#describe_savings_plans/3","title":"AWS.Savingsplans.describe_savings_plans/3","type":"function","doc":"Describes the specified Savings Plans."},{"ref":"AWS.Savingsplans.html#describe_savings_plans_offering_rates/3","title":"AWS.Savingsplans.describe_savings_plans_offering_rates/3","type":"function","doc":"Describes the specified Savings Plans offering rates."},{"ref":"AWS.Savingsplans.html#describe_savings_plans_offerings/3","title":"AWS.Savingsplans.describe_savings_plans_offerings/3","type":"function","doc":"Describes the specified Savings Plans offerings."},{"ref":"AWS.Savingsplans.html#list_tags_for_resource/3","title":"AWS.Savingsplans.list_tags_for_resource/3","type":"function","doc":"Lists the tags for the specified resource."},{"ref":"AWS.Savingsplans.html#tag_resource/3","title":"AWS.Savingsplans.tag_resource/3","type":"function","doc":"Adds the specified tags to the specified resource."},{"ref":"AWS.Savingsplans.html#untag_resource/3","title":"AWS.Savingsplans.untag_resource/3","type":"function","doc":"Removes the specified tags from the specified resource."},{"ref":"AWS.Schemas.html","title":"AWS.Schemas","type":"module","doc":"Amazon EventBridge Schema Registry"},{"ref":"AWS.Schemas.html#create_discoverer/3","title":"AWS.Schemas.create_discoverer/3","type":"function","doc":"Creates a discoverer."},{"ref":"AWS.Schemas.html#create_registry/4","title":"AWS.Schemas.create_registry/4","type":"function","doc":"Creates a registry."},{"ref":"AWS.Schemas.html#create_schema/5","title":"AWS.Schemas.create_schema/5","type":"function","doc":"Creates a schema definition. Inactive schemas will be deleted after two years."},{"ref":"AWS.Schemas.html#delete_discoverer/4","title":"AWS.Schemas.delete_discoverer/4","type":"function","doc":"Deletes a discoverer."},{"ref":"AWS.Schemas.html#delete_registry/4","title":"AWS.Schemas.delete_registry/4","type":"function","doc":"Deletes a Registry."},{"ref":"AWS.Schemas.html#delete_resource_policy/3","title":"AWS.Schemas.delete_resource_policy/3","type":"function","doc":"Delete the resource-based policy attached to the specified registry."},{"ref":"AWS.Schemas.html#delete_schema/5","title":"AWS.Schemas.delete_schema/5","type":"function","doc":"Delete a schema definition."},{"ref":"AWS.Schemas.html#delete_schema_version/6","title":"AWS.Schemas.delete_schema_version/6","type":"function","doc":"Delete the schema version definition"},{"ref":"AWS.Schemas.html#describe_code_binding/6","title":"AWS.Schemas.describe_code_binding/6","type":"function","doc":"Describe the code binding URI."},{"ref":"AWS.Schemas.html#describe_discoverer/3","title":"AWS.Schemas.describe_discoverer/3","type":"function","doc":"Describes the discoverer."},{"ref":"AWS.Schemas.html#describe_registry/3","title":"AWS.Schemas.describe_registry/3","type":"function","doc":"Describes the registry."},{"ref":"AWS.Schemas.html#describe_schema/5","title":"AWS.Schemas.describe_schema/5","type":"function","doc":"Retrieve the schema definition."},{"ref":"AWS.Schemas.html#export_schema/6","title":"AWS.Schemas.export_schema/6","type":"function","doc":"Exports a schema to a different specification."},{"ref":"AWS.Schemas.html#get_code_binding_source/6","title":"AWS.Schemas.get_code_binding_source/6","type":"function","doc":"Get the code binding source URI."},{"ref":"AWS.Schemas.html#get_discovered_schema/3","title":"AWS.Schemas.get_discovered_schema/3","type":"function","doc":"Get the discovered schema that was generated based on sampled events."},{"ref":"AWS.Schemas.html#get_resource_policy/3","title":"AWS.Schemas.get_resource_policy/3","type":"function","doc":"Retrieves the resource-based policy attached to a given registry."},{"ref":"AWS.Schemas.html#list_discoverers/6","title":"AWS.Schemas.list_discoverers/6","type":"function","doc":"List the discoverers."},{"ref":"AWS.Schemas.html#list_registries/6","title":"AWS.Schemas.list_registries/6","type":"function","doc":"List the registries."},{"ref":"AWS.Schemas.html#list_schema_versions/6","title":"AWS.Schemas.list_schema_versions/6","type":"function","doc":"Provides a list of the schema versions and related information."},{"ref":"AWS.Schemas.html#list_schemas/6","title":"AWS.Schemas.list_schemas/6","type":"function","doc":"List the schemas."},{"ref":"AWS.Schemas.html#list_tags_for_resource/3","title":"AWS.Schemas.list_tags_for_resource/3","type":"function","doc":"Get tags for resource."},{"ref":"AWS.Schemas.html#put_code_binding/6","title":"AWS.Schemas.put_code_binding/6","type":"function","doc":"Put code binding URI"},{"ref":"AWS.Schemas.html#put_resource_policy/3","title":"AWS.Schemas.put_resource_policy/3","type":"function","doc":"The name of the policy."},{"ref":"AWS.Schemas.html#search_schemas/6","title":"AWS.Schemas.search_schemas/6","type":"function","doc":"Search the schemas"},{"ref":"AWS.Schemas.html#start_discoverer/4","title":"AWS.Schemas.start_discoverer/4","type":"function","doc":"Starts the discoverer"},{"ref":"AWS.Schemas.html#stop_discoverer/4","title":"AWS.Schemas.stop_discoverer/4","type":"function","doc":"Stops the discoverer"},{"ref":"AWS.Schemas.html#tag_resource/4","title":"AWS.Schemas.tag_resource/4","type":"function","doc":"Add tags to a resource."},{"ref":"AWS.Schemas.html#untag_resource/4","title":"AWS.Schemas.untag_resource/4","type":"function","doc":"Removes tags from a resource."},{"ref":"AWS.Schemas.html#update_discoverer/4","title":"AWS.Schemas.update_discoverer/4","type":"function","doc":"Updates the discoverer"},{"ref":"AWS.Schemas.html#update_registry/4","title":"AWS.Schemas.update_registry/4","type":"function","doc":"Updates a registry."},{"ref":"AWS.Schemas.html#update_schema/5","title":"AWS.Schemas.update_schema/5","type":"function","doc":"Updates the schema definition Inactive schemas will be deleted after two years."},{"ref":"AWS.Sdb.html","title":"AWS.Sdb","type":"module","doc":"Amazon SimpleDB is a web service providing the core database functions of data indexing and querying in the cloud. By offloading the time and effort associated with building and operating a web-scale database, SimpleDB provides developers the freedom to focus on application development. A traditional, clustered relational database requires a sizable upfront capital outlay, is complex to design, and often requires extensive and repetitive database administration. Amazon SimpleDB is dramatically simpler, requiring no schema, automatically indexing your data and providing a simple API for storage and access. This approach eliminates the administrative burden of data modeling, index maintenance, and performance tuning. Developers gain access to this functionality within Amazon&#39;s proven computing environment, are able to scale instantly, and pay only for what they use. Visit http://aws.amazon.com/simpledb/ for more information."},{"ref":"AWS.Sdb.html#batch_delete_attributes/3","title":"AWS.Sdb.batch_delete_attributes/3","type":"function","doc":"Performs multiple DeleteAttributes operations in a single call, which reduces round trips and latencies. This enables Amazon SimpleDB to optimize requests, which generally yields better throughput. If you specify BatchDeleteAttributes without attributes or values, all the attributes for the item are deleted. BatchDeleteAttributes is an idempotent operation; running it multiple times on the same item or attribute doesn&#39;t result in an error. The BatchDeleteAttributes operation succeeds or fails in its entirety. There are no partial deletes. You can execute multiple BatchDeleteAttributes operations and other operations in parallel. However, large numbers of concurrent BatchDeleteAttributes calls can result in Service Unavailable (503) responses. This operation is vulnerable to exceeding the maximum URL size when making a REST request using the HTTP GET method. This operation does not support conditions using Expected.X.Name, Expected.X.Value, or Expected.X.Exists. The following limitations are enforced for this operation: 1 MB request size 25 item limit per BatchDeleteAttributes operation"},{"ref":"AWS.Sdb.html#batch_put_attributes/3","title":"AWS.Sdb.batch_put_attributes/3","type":"function","doc":"The BatchPutAttributes operation creates or replaces attributes within one or more items. By using this operation, the client can perform multiple PutAttribute operation with a single call. This helps yield savings in round trips and latencies, enabling Amazon SimpleDB to optimize requests and generally produce better throughput. The client may specify the item name with the Item.X.ItemName parameter. The client may specify new attributes using a combination of the Item.X.Attribute.Y.Name and Item.X.Attribute.Y.Value parameters. The client may specify the first attribute for the first item using the parameters Item.0.Attribute.0.Name and Item.0.Attribute.0.Value, and for the second attribute for the first item by the parameters Item.0.Attribute.1.Name and Item.0.Attribute.1.Value, and so on. Attributes are uniquely identified within an item by their name/value combination. For example, a single item can have the attributes { &quot;first_name&quot;, &quot;first_value&quot; } and { &quot;first_name&quot;, &quot;second_value&quot; }. However, it cannot have two attribute instances where both the Item.X.Attribute.Y.Name and Item.X.Attribute.Y.Value are the same. Optionally, the requester can supply the Replace parameter for each individual value. Setting this value to true will cause the new attribute values to replace the existing attribute values. For example, if an item I has the attributes { &#39;a&#39;, &#39;1&#39; }, { &#39;b&#39;, &#39;2&#39;} and { &#39;b&#39;, &#39;3&#39; } and the requester does a BatchPutAttributes of {&#39;I&#39;, &#39;b&#39;, &#39;4&#39; } with the Replace parameter set to true, the final attributes of the item will be { &#39;a&#39;, &#39;1&#39; } and { &#39;b&#39;, &#39;4&#39; }, replacing the previous values of the &#39;b&#39; attribute with the new value. You cannot specify an empty string as an item or as an attribute name. The BatchPutAttributes operation succeeds or fails in its entirety. There are no partial puts. This operation is vulnerable to exceeding the maximum URL size when making a REST request using the HTTP GET method. This operation does not support conditions using Expected.X.Name, Expected.X.Value, or Expected.X.Exists. You can execute multiple BatchPutAttributes operations and other operations in parallel. However, large numbers of concurrent BatchPutAttributes calls can result in Service Unavailable (503) responses. The following limitations are enforced for this operation: 256 attribute name-value pairs per item 1 MB request size 1 billion attributes per domain 10 GB of total user data storage per domain 25 item limit per BatchPutAttributes operation"},{"ref":"AWS.Sdb.html#create_domain/3","title":"AWS.Sdb.create_domain/3","type":"function","doc":"The CreateDomain operation creates a new domain. The domain name should be unique among the domains associated with the Access Key ID provided in the request. The CreateDomain operation may take 10 or more seconds to complete. CreateDomain is an idempotent operation; running it multiple times using the same domain name will not result in an error response. The client can create up to 100 domains per account. If the client requires additional domains, go to http://aws.amazon.com/contact-us/simpledb-limit-request/."},{"ref":"AWS.Sdb.html#delete_attributes/3","title":"AWS.Sdb.delete_attributes/3","type":"function","doc":"Deletes one or more attributes associated with an item. If all attributes of the item are deleted, the item is deleted. If DeleteAttributes is called without being passed any attributes or values specified, all the attributes for the item are deleted. DeleteAttributes is an idempotent operation; running it multiple times on the same item or attribute does not result in an error response. Because Amazon SimpleDB makes multiple copies of item data and uses an eventual consistency update model, performing a GetAttributes or Select operation (read) immediately after a DeleteAttributes or PutAttributes operation (write) might not return updated item data."},{"ref":"AWS.Sdb.html#delete_domain/3","title":"AWS.Sdb.delete_domain/3","type":"function","doc":"The DeleteDomain operation deletes a domain. Any items (and their attributes) in the domain are deleted as well. The DeleteDomain operation might take 10 or more seconds to complete. Running DeleteDomain on a domain that does not exist or running the function multiple times using the same domain name will not result in an error response."},{"ref":"AWS.Sdb.html#domain_metadata/3","title":"AWS.Sdb.domain_metadata/3","type":"function","doc":"Returns information about the domain, including when the domain was created, the number of items and attributes in the domain, and the size of the attribute names and values."},{"ref":"AWS.Sdb.html#get_attributes/3","title":"AWS.Sdb.get_attributes/3","type":"function","doc":"Returns all of the attributes associated with the specified item. Optionally, the attributes returned can be limited to one or more attributes by specifying an attribute name parameter. If the item does not exist on the replica that was accessed for this operation, an empty set is returned. The system does not return an error as it cannot guarantee the item does not exist on other replicas. If GetAttributes is called without being passed any attribute names, all the attributes for the item are returned."},{"ref":"AWS.Sdb.html#list_domains/3","title":"AWS.Sdb.list_domains/3","type":"function","doc":"The ListDomains operation lists all domains associated with the Access Key ID. It returns domain names up to the limit set by MaxNumberOfDomains. A NextToken is returned if there are more than MaxNumberOfDomains domains. Calling ListDomains successive times with the NextToken provided by the operation returns up to MaxNumberOfDomains more domain names with each successive operation call."},{"ref":"AWS.Sdb.html#put_attributes/3","title":"AWS.Sdb.put_attributes/3","type":"function","doc":"The PutAttributes operation creates or replaces attributes in an item. The client may specify new attributes using a combination of the Attribute.X.Name and Attribute.X.Value parameters. The client specifies the first attribute by the parameters Attribute.0.Name and Attribute.0.Value, the second attribute by the parameters Attribute.1.Name and Attribute.1.Value, and so on. Attributes are uniquely identified in an item by their name/value combination. For example, a single item can have the attributes { &quot;first_name&quot;, &quot;first_value&quot; } and { &quot;first_name&quot;, second_value&quot; }. However, it cannot have two attribute instances where both the Attribute.X.Name and Attribute.X.Value are the same. Optionally, the requestor can supply the Replace parameter for each individual attribute. Setting this value to true causes the new attribute value to replace the existing attribute value(s). For example, if an item has the attributes { &#39;a&#39;, &#39;1&#39; }, { &#39;b&#39;, &#39;2&#39;} and { &#39;b&#39;, &#39;3&#39; } and the requestor calls PutAttributes using the attributes { &#39;b&#39;, &#39;4&#39; } with the Replace parameter set to true, the final attributes of the item are changed to { &#39;a&#39;, &#39;1&#39; } and { &#39;b&#39;, &#39;4&#39; }, which replaces the previous values of the &#39;b&#39; attribute with the new value. Using PutAttributes to replace attribute values that do not exist will not result in an error response. You cannot specify an empty string as an attribute name. Because Amazon SimpleDB makes multiple copies of client data and uses an eventual consistency update model, an immediate GetAttributes or Select operation (read) immediately after a PutAttributes or DeleteAttributes operation (write) might not return the updated data. The following limitations are enforced for this operation: 256 total attribute name-value pairs per item One billion attributes per domain 10 GB of total user data storage per domain"},{"ref":"AWS.Sdb.html#select/3","title":"AWS.Sdb.select/3","type":"function","doc":"The Select operation returns a set of attributes for ItemNames that match the select expression. Select is similar to the standard SQL SELECT statement. The total size of the response cannot exceed 1 MB in total size. Amazon SimpleDB automatically adjusts the number of items returned per page to enforce this limit. For example, if the client asks to retrieve 2500 items, but each individual item is 10 kB in size, the system returns 100 items and an appropriate NextToken so the client can access the next page of results. For information on how to construct select expressions, see Using Select to Create Amazon SimpleDB Queries in the Developer Guide."},{"ref":"AWS.SecretsManager.html","title":"AWS.SecretsManager","type":"module","doc":"AWS Secrets Manager API Reference AWS Secrets Manager provides a service to enable you to store, manage, and retrieve, secrets. This guide provides descriptions of the Secrets Manager API. For more information about using this service, see the AWS Secrets Manager User Guide. API Version This version of the Secrets Manager API Reference documents the Secrets Manager API version 2017-10-17. As an alternative to using the API, you can use one of the AWS SDKs, which consist of libraries and sample code for various programming languages and platforms such as Java, Ruby, .NET, iOS, and Android. The SDKs provide a convenient way to create programmatic access to AWS Secrets Manager. For example, the SDKs provide cryptographically signing requests, managing errors, and retrying requests automatically. For more information about the AWS SDKs, including downloading and installing them, see Tools for Amazon Web Services. We recommend you use the AWS SDKs to make programmatic API calls to Secrets Manager. However, you also can use the Secrets Manager HTTP Query API to make direct calls to the Secrets Manager web service. To learn more about the Secrets Manager HTTP Query API, see Making Query Requests in the AWS Secrets Manager User Guide. Secrets Manager API supports GET and POST requests for all actions, and doesn&#39;t require you to use GET for some actions and POST for others. However, GET requests are subject to the limitation size of a URL. Therefore, for operations that require larger sizes, use a POST request. Support and Feedback for AWS Secrets Manager We welcome your feedback. Send your comments to awssecretsmanager-feedback@amazon.com, or post your feedback and questions in the AWS Secrets Manager Discussion Forum. For more information about the AWS Discussion Forums, see Forums Help. How examples are presented The JSON that AWS Secrets Manager expects as your request parameters and the service returns as a response to HTTP query requests contain single, long strings without line breaks or white space formatting. The JSON shown in the examples displays the code formatted with both line breaks and white space to improve readability. When example input parameters can also cause long strings extending beyond the screen, you can insert line breaks to enhance readability. You should always submit the input as a single JSON text string. Logging API Requests AWS Secrets Manager supports AWS CloudTrail, a service that records AWS API calls for your AWS account and delivers log files to an Amazon S3 bucket. By using information that&#39;s collected by AWS CloudTrail, you can determine the requests successfully made to Secrets Manager, who made the request, when it was made, and so on. For more about AWS Secrets Manager and support for AWS CloudTrail, see Logging AWS Secrets Manager Events with AWS CloudTrail in the AWS Secrets Manager User Guide. To learn more about CloudTrail, including enabling it and find your log files, see the AWS CloudTrail User Guide."},{"ref":"AWS.SecretsManager.html#cancel_rotate_secret/3","title":"AWS.SecretsManager.cancel_rotate_secret/3","type":"function","doc":"Disables automatic scheduled rotation and cancels the rotation of a secret if currently in progress. To re-enable scheduled rotation, call RotateSecret with AutomaticallyRotateAfterDays set to a value greater than 0. This immediately rotates your secret and then enables the automatic schedule. If you cancel a rotation while in progress, it can leave the VersionStage labels in an unexpected state. Depending on the step of the rotation in progress, you might need to remove the staging label AWSPENDING from the partially created version, specified by the VersionId response value. You should also evaluate the partially rotated new version to see if it should be deleted, which you can do by removing all staging labels from the new version VersionStage field. To successfully start a rotation, the staging label AWSPENDING must be in one of the following states: Not attached to any version at all Attached to the same version as the staging label AWSCURRENT If the staging label AWSPENDING attached to a different version than the version with AWSCURRENT then the attempt to rotate fails. Minimum permissions To run this command, you must have the following permissions: secretsmanager:CancelRotateSecret Related operations To configure rotation for a secret or to manually trigger a rotation, use RotateSecret. To get the rotation configuration details for a secret, use DescribeSecret. To list all of the currently available secrets, use ListSecrets. To list all of the versions currently associated with a secret, use ListSecretVersionIds."},{"ref":"AWS.SecretsManager.html#create_secret/3","title":"AWS.SecretsManager.create_secret/3","type":"function","doc":"Creates a new secret. A secret in Secrets Manager consists of both the protected secret data and the important information needed to manage the secret. Secrets Manager stores the encrypted secret data in one of a collection of &quot;versions&quot; associated with the secret. Each version contains a copy of the encrypted secret data. Each version is associated with one or more &quot;staging labels&quot; that identify where the version is in the rotation cycle. The SecretVersionsToStages field of the secret contains the mapping of staging labels to the active versions of the secret. Versions without a staging label are considered deprecated and not included in the list. You provide the secret data to be encrypted by putting text in either the SecretString parameter or binary data in the SecretBinary parameter, but not both. If you include SecretString or SecretBinary then Secrets Manager also creates an initial secret version and automatically attaches the staging label AWSCURRENT to the new version. If you call an operation to encrypt or decrypt the SecretString or SecretBinary for a secret in the same account as the calling user and that secret doesn&#39;t specify a AWS KMS encryption key, Secrets Manager uses the account&#39;s default AWS managed customer master key (CMK) with the alias aws/secretsmanager. If this key doesn&#39;t already exist in your account then Secrets Manager creates it for you automatically. All users and roles in the same AWS account automatically have access to use the default CMK. Note that if an Secrets Manager API call results in AWS creating the account&#39;s AWS-managed CMK, it can result in a one-time significant delay in returning the result. If the secret resides in a different AWS account from the credentials calling an API that requires encryption or decryption of the secret value then you must create and use a custom AWS KMS CMK because you can&#39;t access the default CMK for the account using credentials from a different AWS account. Store the ARN of the CMK in the secret when you create the secret or when you update it by including it in the KMSKeyId. If you call an API that must encrypt or decrypt SecretString or SecretBinary using credentials from a different account then the AWS KMS key policy must grant cross-account access to that other account&#39;s user or role for both the kms:GenerateDataKey and kms:Decrypt operations. Minimum permissions To run this command, you must have the following permissions: secretsmanager:CreateSecret kms:GenerateDataKey - needed only if you use a customer-managed AWS KMS key to encrypt the secret. You do not need this permission to use the account default AWS managed CMK for Secrets Manager. kms:Decrypt - needed only if you use a customer-managed AWS KMS key to encrypt the secret. You do not need this permission to use the account default AWS managed CMK for Secrets Manager. secretsmanager:TagResource - needed only if you include the Tags parameter. Related operations To delete a secret, use DeleteSecret. To modify an existing secret, use UpdateSecret. To create a new version of a secret, use PutSecretValue. To retrieve the encrypted secure string and secure binary values, use GetSecretValue. To retrieve all other details for a secret, use DescribeSecret. This does not include the encrypted secure string and secure binary values. To retrieve the list of secret versions associated with the current secret, use DescribeSecret and examine the SecretVersionsToStages response value."},{"ref":"AWS.SecretsManager.html#delete_resource_policy/3","title":"AWS.SecretsManager.delete_resource_policy/3","type":"function","doc":"Deletes the resource-based permission policy attached to the secret. Minimum permissions To run this command, you must have the following permissions: secretsmanager:DeleteResourcePolicy Related operations To attach a resource policy to a secret, use PutResourcePolicy. To retrieve the current resource-based policy that&#39;s attached to a secret, use GetResourcePolicy. To list all of the currently available secrets, use ListSecrets."},{"ref":"AWS.SecretsManager.html#delete_secret/3","title":"AWS.SecretsManager.delete_secret/3","type":"function","doc":"Deletes an entire secret and all of its versions. You can optionally include a recovery window during which you can restore the secret. If you don&#39;t specify a recovery window value, the operation defaults to 30 days. Secrets Manager attaches a DeletionDate stamp to the secret that specifies the end of the recovery window. At the end of the recovery window, Secrets Manager deletes the secret permanently. At any time before recovery window ends, you can use RestoreSecret to remove the DeletionDate and cancel the deletion of the secret. You cannot access the encrypted secret information in any secret that is scheduled for deletion. If you need to access that information, you must cancel the deletion with RestoreSecret and then retrieve the information. There is no explicit operation to delete a version of a secret. Instead, remove all staging labels from the VersionStage field of a version. That marks the version as deprecated and allows Secrets Manager to delete it as needed. Versions that do not have any staging labels do not show up in ListSecretVersionIds unless you specify IncludeDeprecated. The permanent secret deletion at the end of the waiting period is performed as a background task with low priority. There is no guarantee of a specific time after the recovery window for the actual delete operation to occur. Minimum permissions To run this command, you must have the following permissions: secretsmanager:DeleteSecret Related operations To create a secret, use CreateSecret. To cancel deletion of a version of a secret before the recovery window has expired, use RestoreSecret."},{"ref":"AWS.SecretsManager.html#describe_secret/3","title":"AWS.SecretsManager.describe_secret/3","type":"function","doc":"Retrieves the details of a secret. It does not include the encrypted fields. Secrets Manager only returns fields populated with a value in the response. Minimum permissions To run this command, you must have the following permissions: secretsmanager:DescribeSecret Related operations To create a secret, use CreateSecret. To modify a secret, use UpdateSecret. To retrieve the encrypted secret information in a version of the secret, use GetSecretValue. To list all of the secrets in the AWS account, use ListSecrets."},{"ref":"AWS.SecretsManager.html#get_random_password/3","title":"AWS.SecretsManager.get_random_password/3","type":"function","doc":"Generates a random password of the specified complexity. This operation is intended for use in the Lambda rotation function. Per best practice, we recommend that you specify the maximum length and include every character type that the system you are generating a password for can support. Minimum permissions To run this command, you must have the following permissions: secretsmanager:GetRandomPassword"},{"ref":"AWS.SecretsManager.html#get_resource_policy/3","title":"AWS.SecretsManager.get_resource_policy/3","type":"function","doc":"Retrieves the JSON text of the resource-based policy document attached to the specified secret. The JSON request string input and response output displays formatted code with white space and line breaks for better readability. Submit your input as a single line JSON string. Minimum permissions To run this command, you must have the following permissions: secretsmanager:GetResourcePolicy Related operations To attach a resource policy to a secret, use PutResourcePolicy. To delete the resource-based policy attached to a secret, use DeleteResourcePolicy. To list all of the currently available secrets, use ListSecrets."},{"ref":"AWS.SecretsManager.html#get_secret_value/3","title":"AWS.SecretsManager.get_secret_value/3","type":"function","doc":"Retrieves the contents of the encrypted fields SecretString or SecretBinary from the specified version of a secret, whichever contains content. Minimum permissions To run this command, you must have the following permissions: secretsmanager:GetSecretValue kms:Decrypt - required only if you use a customer-managed AWS KMS key to encrypt the secret. You do not need this permission to use the account&#39;s default AWS managed CMK for Secrets Manager. Related operations To create a new version of the secret with different encrypted information, use PutSecretValue. To retrieve the non-encrypted details for the secret, use DescribeSecret."},{"ref":"AWS.SecretsManager.html#list_secret_version_ids/3","title":"AWS.SecretsManager.list_secret_version_ids/3","type":"function","doc":"Lists all of the versions attached to the specified secret. The output does not include the SecretString or SecretBinary fields. By default, the list includes only versions that have at least one staging label in VersionStage attached. Always check the NextToken response parameter when calling any of the List* operations. These operations can occasionally return an empty or shorter than expected list of results even when there more results become available. When this happens, the NextToken response parameter contains a value to pass to the next call to the same API to request the next part of the list. Minimum permissions To run this command, you must have the following permissions: secretsmanager:ListSecretVersionIds Related operations To list the secrets in an account, use ListSecrets."},{"ref":"AWS.SecretsManager.html#list_secrets/3","title":"AWS.SecretsManager.list_secrets/3","type":"function","doc":"Lists all of the secrets that are stored by Secrets Manager in the AWS account. To list the versions currently stored for a specific secret, use ListSecretVersionIds. The encrypted fields SecretString and SecretBinary are not included in the output. To get that information, call the GetSecretValue operation. Always check the NextToken response parameter when calling any of the List* operations. These operations can occasionally return an empty or shorter than expected list of results even when there more results become available. When this happens, the NextToken response parameter contains a value to pass to the next call to the same API to request the next part of the list. Minimum permissions To run this command, you must have the following permissions: secretsmanager:ListSecrets Related operations To list the versions attached to a secret, use ListSecretVersionIds."},{"ref":"AWS.SecretsManager.html#put_resource_policy/3","title":"AWS.SecretsManager.put_resource_policy/3","type":"function","doc":"Attaches the contents of the specified resource-based permission policy to a secret. A resource-based policy is optional. Alternatively, you can use IAM identity-based policies that specify the secret&#39;s Amazon Resource Name (ARN) in the policy statement&#39;s Resources element. You can also use a combination of both identity-based and resource-based policies. The affected users and roles receive the permissions that are permitted by all of the relevant policies. For more information, see Using Resource-Based Policies for AWS Secrets Manager. For the complete description of the AWS policy syntax and grammar, see IAM JSON Policy Reference in the IAM User Guide. Minimum permissions To run this command, you must have the following permissions: secretsmanager:PutResourcePolicy Related operations To retrieve the resource policy attached to a secret, use GetResourcePolicy. To delete the resource-based policy that&#39;s attached to a secret, use DeleteResourcePolicy. To list all of the currently available secrets, use ListSecrets."},{"ref":"AWS.SecretsManager.html#put_secret_value/3","title":"AWS.SecretsManager.put_secret_value/3","type":"function","doc":"Stores a new encrypted secret value in the specified secret. To do this, the operation creates a new version and attaches it to the secret. The version can contain a new SecretString value or a new SecretBinary value. You can also specify the staging labels that are initially attached to the new version. The Secrets Manager console uses only the SecretString field. To add binary data to a secret with the SecretBinary field you must use the AWS CLI or one of the AWS SDKs. If this operation creates the first version for the secret then Secrets Manager automatically attaches the staging label AWSCURRENT to the new version. If another version of this secret already exists, then this operation does not automatically move any staging labels other than those that you explicitly specify in the VersionStages parameter. If this operation moves the staging label AWSCURRENT from another version to this version (because you included it in the StagingLabels parameter) then Secrets Manager also automatically moves the staging label AWSPREVIOUS to the version that AWSCURRENT was removed from. This operation is idempotent. If a version with a VersionId with the same value as the ClientRequestToken parameter already exists and you specify the same secret data, the operation succeeds but does nothing. However, if the secret data is different, then the operation fails because you cannot modify an existing version; you can only create new ones. If you call an operation to encrypt or decrypt the SecretString or SecretBinary for a secret in the same account as the calling user and that secret doesn&#39;t specify a AWS KMS encryption key, Secrets Manager uses the account&#39;s default AWS managed customer master key (CMK) with the alias aws/secretsmanager. If this key doesn&#39;t already exist in your account then Secrets Manager creates it for you automatically. All users and roles in the same AWS account automatically have access to use the default CMK. Note that if an Secrets Manager API call results in AWS creating the account&#39;s AWS-managed CMK, it can result in a one-time significant delay in returning the result. If the secret resides in a different AWS account from the credentials calling an API that requires encryption or decryption of the secret value then you must create and use a custom AWS KMS CMK because you can&#39;t access the default CMK for the account using credentials from a different AWS account. Store the ARN of the CMK in the secret when you create the secret or when you update it by including it in the KMSKeyId. If you call an API that must encrypt or decrypt SecretString or SecretBinary using credentials from a different account then the AWS KMS key policy must grant cross-account access to that other account&#39;s user or role for both the kms:GenerateDataKey and kms:Decrypt operations. Minimum permissions To run this command, you must have the following permissions: secretsmanager:PutSecretValue kms:GenerateDataKey - needed only if you use a customer-managed AWS KMS key to encrypt the secret. You do not need this permission to use the account&#39;s default AWS managed CMK for Secrets Manager. Related operations To retrieve the encrypted value you store in the version of a secret, use GetSecretValue. To create a secret, use CreateSecret. To get the details for a secret, use DescribeSecret. To list the versions attached to a secret, use ListSecretVersionIds."},{"ref":"AWS.SecretsManager.html#restore_secret/3","title":"AWS.SecretsManager.restore_secret/3","type":"function","doc":"Cancels the scheduled deletion of a secret by removing the DeletedDate time stamp. This makes the secret accessible to query once again. Minimum permissions To run this command, you must have the following permissions: secretsmanager:RestoreSecret Related operations To delete a secret, use DeleteSecret."},{"ref":"AWS.SecretsManager.html#rotate_secret/3","title":"AWS.SecretsManager.rotate_secret/3","type":"function","doc":"Configures and starts the asynchronous process of rotating this secret. If you include the configuration parameters, the operation sets those values for the secret and then immediately starts a rotation. If you do not include the configuration parameters, the operation starts a rotation with the values already stored in the secret. After the rotation completes, the protected service and its clients all use the new version of the secret. This required configuration information includes the ARN of an AWS Lambda function and the time between scheduled rotations. The Lambda rotation function creates a new version of the secret and creates or updates the credentials on the protected service to match. After testing the new credentials, the function marks the new secret with the staging label AWSCURRENT so that your clients all immediately begin to use the new version. For more information about rotating secrets and how to configure a Lambda function to rotate the secrets for your protected service, see Rotating Secrets in AWS Secrets Manager in the AWS Secrets Manager User Guide. Secrets Manager schedules the next rotation when the previous one completes. Secrets Manager schedules the date by adding the rotation interval (number of days) to the actual date of the last rotation. The service chooses the hour within that 24-hour date window randomly. The minute is also chosen somewhat randomly, but weighted towards the top of the hour and influenced by a variety of factors that help distribute load. The rotation function must end with the versions of the secret in one of two states: The AWSPENDING and AWSCURRENT staging labels are attached to the same version of the secret, or The AWSPENDING staging label is not attached to any version of the secret. If the AWSPENDING staging label is present but not attached to the same version as AWSCURRENT then any later invocation of RotateSecret assumes that a previous rotation request is still in progress and returns an error. Minimum permissions To run this command, you must have the following permissions: secretsmanager:RotateSecret lambda:InvokeFunction (on the function specified in the secret&#39;s metadata) Related operations To list the secrets in your account, use ListSecrets. To get the details for a version of a secret, use DescribeSecret. To create a new version of a secret, use CreateSecret. To attach staging labels to or remove staging labels from a version of a secret, use UpdateSecretVersionStage."},{"ref":"AWS.SecretsManager.html#tag_resource/3","title":"AWS.SecretsManager.tag_resource/3","type":"function","doc":"Attaches one or more tags, each consisting of a key name and a value, to the specified secret. Tags are part of the secret&#39;s overall metadata, and are not associated with any specific version of the secret. This operation only appends tags to the existing list of tags. To remove tags, you must use UntagResource. The following basic restrictions apply to tags: Maximum number of tags per secret50 Maximum key length127 Unicode characters in UTF-8 Maximum value length255 Unicode characters in UTF-8 Tag keys and values are case sensitive. Do not use the aws: prefix in your tag names or values because AWS reserves it for AWS use. You can&#39;t edit or delete tag names or values with this prefix. Tags with this prefix do not count against your tags per secret limit. If you use your tagging schema across multiple services and resources, remember other services might have restrictions on allowed characters. Generally allowed characters: letters, spaces, and numbers representable in UTF-8, plus the following special characters: + - = . _ : / @. If you use tags as part of your security strategy, then adding or removing a tag can change permissions. If successfully completing this operation would result in you losing your permissions for this secret, then the operation is blocked and returns an Access Denied error. Minimum permissions To run this command, you must have the following permissions: secretsmanager:TagResource Related operations To remove one or more tags from the collection attached to a secret, use UntagResource. To view the list of tags attached to a secret, use DescribeSecret."},{"ref":"AWS.SecretsManager.html#untag_resource/3","title":"AWS.SecretsManager.untag_resource/3","type":"function","doc":"Removes one or more tags from the specified secret. This operation is idempotent. If a requested tag is not attached to the secret, no error is returned and the secret metadata is unchanged. If you use tags as part of your security strategy, then removing a tag can change permissions. If successfully completing this operation would result in you losing your permissions for this secret, then the operation is blocked and returns an Access Denied error. Minimum permissions To run this command, you must have the following permissions: secretsmanager:UntagResource Related operations To add one or more tags to the collection attached to a secret, use TagResource. To view the list of tags attached to a secret, use DescribeSecret."},{"ref":"AWS.SecretsManager.html#update_secret/3","title":"AWS.SecretsManager.update_secret/3","type":"function","doc":"Modifies many of the details of the specified secret. If you include a ClientRequestToken and either SecretString or SecretBinary then it also creates a new version attached to the secret. To modify the rotation configuration of a secret, use RotateSecret instead. The Secrets Manager console uses only the SecretString parameter and therefore limits you to encrypting and storing only a text string. To encrypt and store binary data as part of the version of a secret, you must use either the AWS CLI or one of the AWS SDKs. If a version with a VersionId with the same value as the ClientRequestToken parameter already exists, the operation results in an error. You cannot modify an existing version, you can only create a new version. If you include SecretString or SecretBinary to create a new secret version, Secrets Manager automatically attaches the staging label AWSCURRENT to the new version. If you call an operation to encrypt or decrypt the SecretString or SecretBinary for a secret in the same account as the calling user and that secret doesn&#39;t specify a AWS KMS encryption key, Secrets Manager uses the account&#39;s default AWS managed customer master key (CMK) with the alias aws/secretsmanager. If this key doesn&#39;t already exist in your account then Secrets Manager creates it for you automatically. All users and roles in the same AWS account automatically have access to use the default CMK. Note that if an Secrets Manager API call results in AWS creating the account&#39;s AWS-managed CMK, it can result in a one-time significant delay in returning the result. If the secret resides in a different AWS account from the credentials calling an API that requires encryption or decryption of the secret value then you must create and use a custom AWS KMS CMK because you can&#39;t access the default CMK for the account using credentials from a different AWS account. Store the ARN of the CMK in the secret when you create the secret or when you update it by including it in the KMSKeyId. If you call an API that must encrypt or decrypt SecretString or SecretBinary using credentials from a different account then the AWS KMS key policy must grant cross-account access to that other account&#39;s user or role for both the kms:GenerateDataKey and kms:Decrypt operations. Minimum permissions To run this command, you must have the following permissions: secretsmanager:UpdateSecret kms:GenerateDataKey - needed only if you use a custom AWS KMS key to encrypt the secret. You do not need this permission to use the account&#39;s AWS managed CMK for Secrets Manager. kms:Decrypt - needed only if you use a custom AWS KMS key to encrypt the secret. You do not need this permission to use the account&#39;s AWS managed CMK for Secrets Manager. Related operations To create a new secret, use CreateSecret. To add only a new version to an existing secret, use PutSecretValue. To get the details for a secret, use DescribeSecret. To list the versions contained in a secret, use ListSecretVersionIds."},{"ref":"AWS.SecretsManager.html#update_secret_version_stage/3","title":"AWS.SecretsManager.update_secret_version_stage/3","type":"function","doc":"Modifies the staging labels attached to a version of a secret. Staging labels are used to track a version as it progresses through the secret rotation process. You can attach a staging label to only one version of a secret at a time. If a staging label to be added is already attached to another version, then it is moved--removed from the other version first and then attached to this one. For more information about staging labels, see Staging Labels in the AWS Secrets Manager User Guide. The staging labels that you specify in the VersionStage parameter are added to the existing list of staging labels--they don&#39;t replace it. You can move the AWSCURRENT staging label to this version by including it in this call. Whenever you move AWSCURRENT, Secrets Manager automatically moves the label AWSPREVIOUS to the version that AWSCURRENT was removed from. If this action results in the last label being removed from a version, then the version is considered to be &#39;deprecated&#39; and can be deleted by Secrets Manager. Minimum permissions To run this command, you must have the following permissions: secretsmanager:UpdateSecretVersionStage Related operations To get the list of staging labels that are currently associated with a version of a secret, use DescribeSecret and examine the SecretVersionsToStages response value."},{"ref":"AWS.SecretsManager.html#validate_resource_policy/3","title":"AWS.SecretsManager.validate_resource_policy/3","type":"function","doc":"Validates the JSON text of the resource-based policy document attached to the specified secret. The JSON request string input and response output displays formatted code with white space and line breaks for better readability. Submit your input as a single line JSON string. A resource-based policy is optional."},{"ref":"AWS.SecurityHub.html","title":"AWS.SecurityHub","type":"module","doc":"Security Hub provides you with a comprehensive view of the security state of your AWS environment and resources. It also provides you with the readiness status of your environment based on controls from supported security standards. Security Hub collects security data from AWS accounts, services, and integrated third-party products and helps you analyze security trends in your environment to identify the highest priority security issues. For more information about Security Hub, see the AWS Security Hub User Guide . When you use operations in the Security Hub API, the requests are executed only in the AWS Region that is currently active or in the specific AWS Region that you specify in your request. Any configuration or settings change that results from the operation is applied only to that Region. To make the same change in other Regions, execute the same command for each Region to apply the change to. For example, if your Region is set to us-west-2, when you use CreateMembers to add a member account to Security Hub, the association of the member account with the master account is created only in the us-west-2 Region. Security Hub must be enabled for the member account in the same Region that the invitation was sent from. The following throttling limits apply to using Security Hub API operations. BatchEnableStandards - RateLimit of 1 request per second, BurstLimit of 1 request per second. GetFindings - RateLimit of 3 requests per second. BurstLimit of 6 requests per second. UpdateFindings - RateLimit of 1 request per second. BurstLimit of 5 requests per second. UpdateStandardsControl - RateLimit of 1 request per second, BurstLimit of 5 requests per second. All other operations - RateLimit of 10 requests per second. BurstLimit of 30 requests per second."},{"ref":"AWS.SecurityHub.html#accept_invitation/3","title":"AWS.SecurityHub.accept_invitation/3","type":"function","doc":"Accepts the invitation to be a member account and be monitored by the Security Hub master account that the invitation was sent from. When the member account accepts the invitation, permission is granted to the master account to view findings generated in the member account."},{"ref":"AWS.SecurityHub.html#batch_disable_standards/3","title":"AWS.SecurityHub.batch_disable_standards/3","type":"function","doc":"Disables the standards specified by the provided StandardsSubscriptionArns. For more information, see Security Standards section of the AWS Security Hub User Guide."},{"ref":"AWS.SecurityHub.html#batch_enable_standards/3","title":"AWS.SecurityHub.batch_enable_standards/3","type":"function","doc":"Enables the standards specified by the provided StandardsArn. To obtain the ARN for a standard, use the DescribeStandards operation. For more information, see the Security Standards section of the AWS Security Hub User Guide."},{"ref":"AWS.SecurityHub.html#batch_import_findings/3","title":"AWS.SecurityHub.batch_import_findings/3","type":"function","doc":"Imports security findings generated from an integrated third-party product into Security Hub. This action is requested by the integrated product to import its findings into Security Hub. The maximum allowed size for a finding is 240 Kb. An error is returned for any finding larger than 240 Kb. After a finding is created, BatchImportFindings cannot be used to update the following finding fields and objects, which Security Hub customers use to manage their investigation workflow. Confidence Criticality Note RelatedFindings Severity Types UserDefinedFields VerificationState Workflow"},{"ref":"AWS.SecurityHub.html#batch_update_findings/3","title":"AWS.SecurityHub.batch_update_findings/3","type":"function","doc":"Used by Security Hub customers to update information about their investigation into a finding. Requested by master accounts or member accounts. Master accounts can update findings for their account and their member accounts. Member accounts can update findings for their account. Updates from BatchUpdateFindings do not affect the value of UpdatedAt for a finding. Master and member accounts can use BatchUpdateFindings to update the following finding fields and objects. Confidence Criticality Note RelatedFindings Severity Types UserDefinedFields VerificationState Workflow You can configure IAM policies to restrict access to fields and field values. For example, you might not want member accounts to be able to suppress findings or change the finding severity. See Configuring access to BatchUpdateFindings in the AWS Security Hub User Guide."},{"ref":"AWS.SecurityHub.html#create_action_target/3","title":"AWS.SecurityHub.create_action_target/3","type":"function","doc":"Creates a custom action target in Security Hub. You can use custom actions on findings and insights in Security Hub to trigger target actions in Amazon CloudWatch Events."},{"ref":"AWS.SecurityHub.html#create_insight/3","title":"AWS.SecurityHub.create_insight/3","type":"function","doc":"Creates a custom insight in Security Hub. An insight is a consolidation of findings that relate to a security issue that requires attention or remediation. To group the related findings in the insight, use the GroupByAttribute."},{"ref":"AWS.SecurityHub.html#create_members/3","title":"AWS.SecurityHub.create_members/3","type":"function","doc":"Creates a member association in Security Hub between the specified accounts and the account used to make the request, which is the master account. To successfully create a member, you must use this action from an account that already has Security Hub enabled. To enable Security Hub, you can use the EnableSecurityHub operation. After you use CreateMembers to create member account associations in Security Hub, you must use the InviteMembers operation to invite the accounts to enable Security Hub and become member accounts in Security Hub. If the account owner accepts the invitation, the account becomes a member account in Security Hub. A permissions policy is added that permits the master account to view the findings generated in the member account. When Security Hub is enabled in the invited account, findings start to be sent to both the member and master accounts. To remove the association between the master and member accounts, use the DisassociateFromMasterAccount or DisassociateMembers operation."},{"ref":"AWS.SecurityHub.html#decline_invitations/3","title":"AWS.SecurityHub.decline_invitations/3","type":"function","doc":"Declines invitations to become a member account."},{"ref":"AWS.SecurityHub.html#delete_action_target/4","title":"AWS.SecurityHub.delete_action_target/4","type":"function","doc":"Deletes a custom action target from Security Hub. Deleting a custom action target does not affect any findings or insights that were already sent to Amazon CloudWatch Events using the custom action."},{"ref":"AWS.SecurityHub.html#delete_insight/4","title":"AWS.SecurityHub.delete_insight/4","type":"function","doc":"Deletes the insight specified by the InsightArn."},{"ref":"AWS.SecurityHub.html#delete_invitations/3","title":"AWS.SecurityHub.delete_invitations/3","type":"function","doc":"Deletes invitations received by the AWS account to become a member account."},{"ref":"AWS.SecurityHub.html#delete_members/3","title":"AWS.SecurityHub.delete_members/3","type":"function","doc":"Deletes the specified member accounts from Security Hub."},{"ref":"AWS.SecurityHub.html#describe_action_targets/3","title":"AWS.SecurityHub.describe_action_targets/3","type":"function","doc":"Returns a list of the custom action targets in Security Hub in your account."},{"ref":"AWS.SecurityHub.html#describe_hub/3","title":"AWS.SecurityHub.describe_hub/3","type":"function","doc":"Returns details about the Hub resource in your account, including the HubArn and the time when you enabled Security Hub."},{"ref":"AWS.SecurityHub.html#describe_products/4","title":"AWS.SecurityHub.describe_products/4","type":"function","doc":"Returns information about the available products that you can subscribe to and integrate with Security Hub in order to consolidate findings."},{"ref":"AWS.SecurityHub.html#describe_standards/4","title":"AWS.SecurityHub.describe_standards/4","type":"function","doc":"Returns a list of the available standards in Security Hub. For each standard, the results include the standard ARN, the name, and a description."},{"ref":"AWS.SecurityHub.html#describe_standards_controls/5","title":"AWS.SecurityHub.describe_standards_controls/5","type":"function","doc":"Returns a list of security standards controls. For each control, the results include information about whether it is currently enabled, the severity, and a link to remediation information."},{"ref":"AWS.SecurityHub.html#disable_import_findings_for_product/4","title":"AWS.SecurityHub.disable_import_findings_for_product/4","type":"function","doc":"Disables the integration of the specified product with Security Hub. After the integration is disabled, findings from that product are no longer sent to Security Hub."},{"ref":"AWS.SecurityHub.html#disable_security_hub/3","title":"AWS.SecurityHub.disable_security_hub/3","type":"function","doc":"Disables Security Hub in your account only in the current Region. To disable Security Hub in all Regions, you must submit one request per Region where you have enabled Security Hub. When you disable Security Hub for a master account, it doesn&#39;t disable Security Hub for any associated member accounts. When you disable Security Hub, your existing findings and insights and any Security Hub configuration settings are deleted after 90 days and cannot be recovered. Any standards that were enabled are disabled, and your master and member account associations are removed. If you want to save your existing findings, you must export them before you disable Security Hub."},{"ref":"AWS.SecurityHub.html#disassociate_from_master_account/3","title":"AWS.SecurityHub.disassociate_from_master_account/3","type":"function","doc":"Disassociates the current Security Hub member account from the associated master account."},{"ref":"AWS.SecurityHub.html#disassociate_members/3","title":"AWS.SecurityHub.disassociate_members/3","type":"function","doc":"Disassociates the specified member accounts from the associated master account."},{"ref":"AWS.SecurityHub.html#enable_import_findings_for_product/3","title":"AWS.SecurityHub.enable_import_findings_for_product/3","type":"function","doc":"Enables the integration of a partner product with Security Hub. Integrated products send findings to Security Hub. When you enable a product integration, a permissions policy that grants permission for the product to send findings to Security Hub is applied."},{"ref":"AWS.SecurityHub.html#enable_security_hub/3","title":"AWS.SecurityHub.enable_security_hub/3","type":"function","doc":"Enables Security Hub for your account in the current Region or the Region you specify in the request. When you enable Security Hub, you grant to Security Hub the permissions necessary to gather findings from other services that are integrated with Security Hub. When you use the EnableSecurityHub operation to enable Security Hub, you also automatically enable the following standards. CIS AWS Foundations AWS Foundational Security Best Practices You do not enable the Payment Card Industry Data Security Standard (PCI DSS) standard. To not enable the automatically enabled standards, set EnableDefaultStandards to false. After you enable Security Hub, to enable a standard, use the BatchEnableStandards operation. To disable a standard, use the BatchDisableStandards operation. To learn more, see Setting Up AWS Security Hub in the AWS Security Hub User Guide."},{"ref":"AWS.SecurityHub.html#get_enabled_standards/3","title":"AWS.SecurityHub.get_enabled_standards/3","type":"function","doc":"Returns a list of the standards that are currently enabled."},{"ref":"AWS.SecurityHub.html#get_findings/3","title":"AWS.SecurityHub.get_findings/3","type":"function","doc":"Returns a list of findings that match the specified criteria."},{"ref":"AWS.SecurityHub.html#get_insight_results/3","title":"AWS.SecurityHub.get_insight_results/3","type":"function","doc":"Lists the results of the Security Hub insight specified by the insight ARN."},{"ref":"AWS.SecurityHub.html#get_insights/3","title":"AWS.SecurityHub.get_insights/3","type":"function","doc":"Lists and describes insights for the specified insight ARNs."},{"ref":"AWS.SecurityHub.html#get_invitations_count/2","title":"AWS.SecurityHub.get_invitations_count/2","type":"function","doc":"Returns the count of all Security Hub membership invitations that were sent to the current member account, not including the currently accepted invitation."},{"ref":"AWS.SecurityHub.html#get_master_account/2","title":"AWS.SecurityHub.get_master_account/2","type":"function","doc":"Provides the details for the Security Hub master account for the current member account."},{"ref":"AWS.SecurityHub.html#get_members/3","title":"AWS.SecurityHub.get_members/3","type":"function","doc":"Returns the details for the Security Hub member accounts for the specified account IDs."},{"ref":"AWS.SecurityHub.html#invite_members/3","title":"AWS.SecurityHub.invite_members/3","type":"function","doc":"Invites other AWS accounts to become member accounts for the Security Hub master account that the invitation is sent from. Before you can use this action to invite a member, you must first use the CreateMembers action to create the member account in Security Hub. When the account owner accepts the invitation to become a member account and enables Security Hub, the master account can view the findings generated from the member account."},{"ref":"AWS.SecurityHub.html#list_enabled_products_for_import/4","title":"AWS.SecurityHub.list_enabled_products_for_import/4","type":"function","doc":"Lists all findings-generating solutions (products) that you are subscribed to receive findings from in Security Hub."},{"ref":"AWS.SecurityHub.html#list_invitations/4","title":"AWS.SecurityHub.list_invitations/4","type":"function","doc":"Lists all Security Hub membership invitations that were sent to the current AWS account."},{"ref":"AWS.SecurityHub.html#list_members/5","title":"AWS.SecurityHub.list_members/5","type":"function","doc":"Lists details about all member accounts for the current Security Hub master account."},{"ref":"AWS.SecurityHub.html#list_tags_for_resource/3","title":"AWS.SecurityHub.list_tags_for_resource/3","type":"function","doc":"Returns a list of tags associated with a resource."},{"ref":"AWS.SecurityHub.html#tag_resource/4","title":"AWS.SecurityHub.tag_resource/4","type":"function","doc":"Adds one or more tags to a resource."},{"ref":"AWS.SecurityHub.html#untag_resource/4","title":"AWS.SecurityHub.untag_resource/4","type":"function","doc":"Removes one or more tags from a resource."},{"ref":"AWS.SecurityHub.html#update_action_target/4","title":"AWS.SecurityHub.update_action_target/4","type":"function","doc":"Updates the name and description of a custom action target in Security Hub."},{"ref":"AWS.SecurityHub.html#update_findings/3","title":"AWS.SecurityHub.update_findings/3","type":"function","doc":"UpdateFindings is deprecated. Instead of UpdateFindings, use BatchUpdateFindings. Updates the Note and RecordState of the Security Hub-aggregated findings that the filter attributes specify. Any member account that can view the finding also sees the update to the finding."},{"ref":"AWS.SecurityHub.html#update_insight/4","title":"AWS.SecurityHub.update_insight/4","type":"function","doc":"Updates the Security Hub insight identified by the specified insight ARN."},{"ref":"AWS.SecurityHub.html#update_security_hub_configuration/3","title":"AWS.SecurityHub.update_security_hub_configuration/3","type":"function","doc":"Updates configuration options for Security Hub."},{"ref":"AWS.SecurityHub.html#update_standards_control/4","title":"AWS.SecurityHub.update_standards_control/4","type":"function","doc":"Used to control whether an individual security standard control is enabled or disabled."},{"ref":"AWS.ServerlessApplicationRepository.html","title":"AWS.ServerlessApplicationRepository","type":"module","doc":"The AWS Serverless Application Repository makes it easy for developers and enterprises to quickly find and deploy serverless applications in the AWS Cloud. For more information about serverless applications, see Serverless Computing and Applications on the AWS website. The AWS Serverless Application Repository is deeply integrated with the AWS Lambda console, so that developers of all levels can get started with serverless computing without needing to learn anything new. You can use category keywords to browse for applications such as web and mobile backends, data processing applications, or chatbots. You can also search for applications by name, publisher, or event source. To use an application, you simply choose it, configure any required fields, and deploy it with a few clicks. You can also easily publish applications, sharing them publicly with the community at large, or privately within your team or across your organization. To publish a serverless application (or app), you can use the AWS Management Console, AWS Command Line Interface (AWS CLI), or AWS SDKs to upload the code. Along with the code, you upload a simple manifest file, also known as the AWS Serverless Application Model (AWS SAM) template. For more information about AWS SAM, see AWS Serverless Application Model (AWS SAM) on the AWS Labs GitHub repository. The AWS Serverless Application Repository Developer Guide contains more information about the two developer experiences available: * Consuming Applications  Browse for applications and view information about them, including source code and readme files. Also install, configure, and deploy applications of your choosing. Publishing Applications  Configure and upload applications to make them available to other developers, and publish new versions of applications."},{"ref":"AWS.ServerlessApplicationRepository.html#create_application/3","title":"AWS.ServerlessApplicationRepository.create_application/3","type":"function","doc":"Creates an application, optionally including an AWS SAM file to create the first application version in the same call."},{"ref":"AWS.ServerlessApplicationRepository.html#create_application_version/5","title":"AWS.ServerlessApplicationRepository.create_application_version/5","type":"function","doc":"Creates an application version."},{"ref":"AWS.ServerlessApplicationRepository.html#create_cloud_formation_change_set/4","title":"AWS.ServerlessApplicationRepository.create_cloud_formation_change_set/4","type":"function","doc":"Creates an AWS CloudFormation change set for the given application."},{"ref":"AWS.ServerlessApplicationRepository.html#create_cloud_formation_template/4","title":"AWS.ServerlessApplicationRepository.create_cloud_formation_template/4","type":"function","doc":"Creates an AWS CloudFormation template."},{"ref":"AWS.ServerlessApplicationRepository.html#delete_application/4","title":"AWS.ServerlessApplicationRepository.delete_application/4","type":"function","doc":"Deletes the specified application."},{"ref":"AWS.ServerlessApplicationRepository.html#get_application/4","title":"AWS.ServerlessApplicationRepository.get_application/4","type":"function","doc":"Gets the specified application."},{"ref":"AWS.ServerlessApplicationRepository.html#get_application_policy/3","title":"AWS.ServerlessApplicationRepository.get_application_policy/3","type":"function","doc":"Retrieves the policy for the application."},{"ref":"AWS.ServerlessApplicationRepository.html#get_cloud_formation_template/4","title":"AWS.ServerlessApplicationRepository.get_cloud_formation_template/4","type":"function","doc":"Gets the specified AWS CloudFormation template."},{"ref":"AWS.ServerlessApplicationRepository.html#list_application_dependencies/6","title":"AWS.ServerlessApplicationRepository.list_application_dependencies/6","type":"function","doc":"Retrieves the list of applications nested in the containing application."},{"ref":"AWS.ServerlessApplicationRepository.html#list_application_versions/5","title":"AWS.ServerlessApplicationRepository.list_application_versions/5","type":"function","doc":"Lists versions for the specified application."},{"ref":"AWS.ServerlessApplicationRepository.html#list_applications/4","title":"AWS.ServerlessApplicationRepository.list_applications/4","type":"function","doc":"Lists applications owned by the requester."},{"ref":"AWS.ServerlessApplicationRepository.html#put_application_policy/4","title":"AWS.ServerlessApplicationRepository.put_application_policy/4","type":"function","doc":"Sets the permission policy for an application. For the list of actions supported for this operation, see Application Permissions ."},{"ref":"AWS.ServerlessApplicationRepository.html#unshare_application/4","title":"AWS.ServerlessApplicationRepository.unshare_application/4","type":"function","doc":"Unshares an application from an AWS Organization. This operation can be called only from the organization&#39;s master account."},{"ref":"AWS.ServerlessApplicationRepository.html#update_application/4","title":"AWS.ServerlessApplicationRepository.update_application/4","type":"function","doc":"Updates the specified application."},{"ref":"AWS.ServiceCatalog.html","title":"AWS.ServiceCatalog","type":"module","doc":"AWS Service Catalog AWS Service Catalog enables organizations to create and manage catalogs of IT services that are approved for use on AWS. To get the most out of this documentation, you should be familiar with the terminology discussed in AWS Service Catalog Concepts."},{"ref":"AWS.ServiceCatalog.html#accept_portfolio_share/3","title":"AWS.ServiceCatalog.accept_portfolio_share/3","type":"function","doc":"Accepts an offer to share the specified portfolio."},{"ref":"AWS.ServiceCatalog.html#associate_budget_with_resource/3","title":"AWS.ServiceCatalog.associate_budget_with_resource/3","type":"function","doc":"Associates the specified budget with the specified resource."},{"ref":"AWS.ServiceCatalog.html#associate_principal_with_portfolio/3","title":"AWS.ServiceCatalog.associate_principal_with_portfolio/3","type":"function","doc":"Associates the specified principal ARN with the specified portfolio."},{"ref":"AWS.ServiceCatalog.html#associate_product_with_portfolio/3","title":"AWS.ServiceCatalog.associate_product_with_portfolio/3","type":"function","doc":"Associates the specified product with the specified portfolio. A delegated admin is authorized to invoke this command."},{"ref":"AWS.ServiceCatalog.html#associate_service_action_with_provisioning_artifact/3","title":"AWS.ServiceCatalog.associate_service_action_with_provisioning_artifact/3","type":"function","doc":"Associates a self-service action with a provisioning artifact."},{"ref":"AWS.ServiceCatalog.html#associate_tag_option_with_resource/3","title":"AWS.ServiceCatalog.associate_tag_option_with_resource/3","type":"function","doc":"Associate the specified TagOption with the specified portfolio or product."},{"ref":"AWS.ServiceCatalog.html#batch_associate_service_action_with_provisioning_artifact/3","title":"AWS.ServiceCatalog.batch_associate_service_action_with_provisioning_artifact/3","type":"function","doc":"Associates multiple self-service actions with provisioning artifacts."},{"ref":"AWS.ServiceCatalog.html#batch_disassociate_service_action_from_provisioning_artifact/3","title":"AWS.ServiceCatalog.batch_disassociate_service_action_from_provisioning_artifact/3","type":"function","doc":"Disassociates a batch of self-service actions from the specified provisioning artifact."},{"ref":"AWS.ServiceCatalog.html#copy_product/3","title":"AWS.ServiceCatalog.copy_product/3","type":"function","doc":"Copies the specified source product to the specified target product or a new product. You can copy a product to the same account or another account. You can copy a product to the same region or another region. This operation is performed asynchronously. To track the progress of the operation, use DescribeCopyProductStatus."},{"ref":"AWS.ServiceCatalog.html#create_constraint/3","title":"AWS.ServiceCatalog.create_constraint/3","type":"function","doc":"Creates a constraint. A delegated admin is authorized to invoke this command."},{"ref":"AWS.ServiceCatalog.html#create_portfolio/3","title":"AWS.ServiceCatalog.create_portfolio/3","type":"function","doc":"Creates a portfolio. A delegated admin is authorized to invoke this command."},{"ref":"AWS.ServiceCatalog.html#create_portfolio_share/3","title":"AWS.ServiceCatalog.create_portfolio_share/3","type":"function","doc":"Shares the specified portfolio with the specified account or organization node. Shares to an organization node can only be created by the management account of an organization or by a delegated administrator. You can share portfolios to an organization, an organizational unit, or a specific account. Note that if a delegated admin is de-registered, they can no longer create portfolio shares. AWSOrganizationsAccess must be enabled in order to create a portfolio share to an organization node. You can&#39;t share a shared resource. This includes portfolios that contain a shared product."},{"ref":"AWS.ServiceCatalog.html#create_product/3","title":"AWS.ServiceCatalog.create_product/3","type":"function","doc":"Creates a product. A delegated admin is authorized to invoke this command."},{"ref":"AWS.ServiceCatalog.html#create_provisioned_product_plan/3","title":"AWS.ServiceCatalog.create_provisioned_product_plan/3","type":"function","doc":"Creates a plan. A plan includes the list of resources to be created (when provisioning a new product) or modified (when updating a provisioned product) when the plan is executed. You can create one plan per provisioned product. To create a plan for an existing provisioned product, the product status must be AVAILBLE or TAINTED. To view the resource changes in the change set, use DescribeProvisionedProductPlan. To create or modify the provisioned product, use ExecuteProvisionedProductPlan."},{"ref":"AWS.ServiceCatalog.html#create_provisioning_artifact/3","title":"AWS.ServiceCatalog.create_provisioning_artifact/3","type":"function","doc":"Creates a provisioning artifact (also known as a version) for the specified product. You cannot create a provisioning artifact for a product that was shared with you."},{"ref":"AWS.ServiceCatalog.html#create_service_action/3","title":"AWS.ServiceCatalog.create_service_action/3","type":"function","doc":"Creates a self-service action."},{"ref":"AWS.ServiceCatalog.html#create_tag_option/3","title":"AWS.ServiceCatalog.create_tag_option/3","type":"function","doc":"Creates a TagOption."},{"ref":"AWS.ServiceCatalog.html#delete_constraint/3","title":"AWS.ServiceCatalog.delete_constraint/3","type":"function","doc":"Deletes the specified constraint. A delegated admin is authorized to invoke this command."},{"ref":"AWS.ServiceCatalog.html#delete_portfolio/3","title":"AWS.ServiceCatalog.delete_portfolio/3","type":"function","doc":"Deletes the specified portfolio. You cannot delete a portfolio if it was shared with you or if it has associated products, users, constraints, or shared accounts. A delegated admin is authorized to invoke this command."},{"ref":"AWS.ServiceCatalog.html#delete_portfolio_share/3","title":"AWS.ServiceCatalog.delete_portfolio_share/3","type":"function","doc":"Stops sharing the specified portfolio with the specified account or organization node. Shares to an organization node can only be deleted by the management account of an organization or by a delegated administrator. Note that if a delegated admin is de-registered, portfolio shares created from that account are removed."},{"ref":"AWS.ServiceCatalog.html#delete_product/3","title":"AWS.ServiceCatalog.delete_product/3","type":"function","doc":"Deletes the specified product. You cannot delete a product if it was shared with you or is associated with a portfolio. A delegated admin is authorized to invoke this command."},{"ref":"AWS.ServiceCatalog.html#delete_provisioned_product_plan/3","title":"AWS.ServiceCatalog.delete_provisioned_product_plan/3","type":"function","doc":"Deletes the specified plan."},{"ref":"AWS.ServiceCatalog.html#delete_provisioning_artifact/3","title":"AWS.ServiceCatalog.delete_provisioning_artifact/3","type":"function","doc":"Deletes the specified provisioning artifact (also known as a version) for the specified product. You cannot delete a provisioning artifact associated with a product that was shared with you. You cannot delete the last provisioning artifact for a product, because a product must have at least one provisioning artifact."},{"ref":"AWS.ServiceCatalog.html#delete_service_action/3","title":"AWS.ServiceCatalog.delete_service_action/3","type":"function","doc":"Deletes a self-service action."},{"ref":"AWS.ServiceCatalog.html#delete_tag_option/3","title":"AWS.ServiceCatalog.delete_tag_option/3","type":"function","doc":"Deletes the specified TagOption. You cannot delete a TagOption if it is associated with a product or portfolio."},{"ref":"AWS.ServiceCatalog.html#describe_constraint/3","title":"AWS.ServiceCatalog.describe_constraint/3","type":"function","doc":"Gets information about the specified constraint."},{"ref":"AWS.ServiceCatalog.html#describe_copy_product_status/3","title":"AWS.ServiceCatalog.describe_copy_product_status/3","type":"function","doc":"Gets the status of the specified copy product operation."},{"ref":"AWS.ServiceCatalog.html#describe_portfolio/3","title":"AWS.ServiceCatalog.describe_portfolio/3","type":"function","doc":"Gets information about the specified portfolio. A delegated admin is authorized to invoke this command."},{"ref":"AWS.ServiceCatalog.html#describe_portfolio_share_status/3","title":"AWS.ServiceCatalog.describe_portfolio_share_status/3","type":"function","doc":"Gets the status of the specified portfolio share operation. This API can only be called by the management account in the organization or by a delegated admin."},{"ref":"AWS.ServiceCatalog.html#describe_product/3","title":"AWS.ServiceCatalog.describe_product/3","type":"function","doc":"Gets information about the specified product."},{"ref":"AWS.ServiceCatalog.html#describe_product_as_admin/3","title":"AWS.ServiceCatalog.describe_product_as_admin/3","type":"function","doc":"Gets information about the specified product. This operation is run with administrator access."},{"ref":"AWS.ServiceCatalog.html#describe_product_view/3","title":"AWS.ServiceCatalog.describe_product_view/3","type":"function","doc":"Gets information about the specified product."},{"ref":"AWS.ServiceCatalog.html#describe_provisioned_product/3","title":"AWS.ServiceCatalog.describe_provisioned_product/3","type":"function","doc":"Gets information about the specified provisioned product."},{"ref":"AWS.ServiceCatalog.html#describe_provisioned_product_plan/3","title":"AWS.ServiceCatalog.describe_provisioned_product_plan/3","type":"function","doc":"Gets information about the resource changes for the specified plan."},{"ref":"AWS.ServiceCatalog.html#describe_provisioning_artifact/3","title":"AWS.ServiceCatalog.describe_provisioning_artifact/3","type":"function","doc":"Gets information about the specified provisioning artifact (also known as a version) for the specified product."},{"ref":"AWS.ServiceCatalog.html#describe_provisioning_parameters/3","title":"AWS.ServiceCatalog.describe_provisioning_parameters/3","type":"function","doc":"Gets information about the configuration required to provision the specified product using the specified provisioning artifact. If the output contains a TagOption key with an empty list of values, there is a TagOption conflict for that key. The end user cannot take action to fix the conflict, and launch is not blocked. In subsequent calls to ProvisionProduct, do not include conflicted TagOption keys as tags, or this causes the error &quot;Parameter validation failed: Missing required parameter in Tags[N]:Value&quot;. Tag the provisioned product with the value sc-tagoption-conflict-portfolioId-productId."},{"ref":"AWS.ServiceCatalog.html#describe_record/3","title":"AWS.ServiceCatalog.describe_record/3","type":"function","doc":"Gets information about the specified request operation. Use this operation after calling a request operation (for example, ProvisionProduct, TerminateProvisionedProduct, or UpdateProvisionedProduct). If a provisioned product was transferred to a new owner using UpdateProvisionedProductProperties, the new owner will be able to describe all past records for that product. The previous owner will no longer be able to describe the records, but will be able to use ListRecordHistory to see the product&#39;s history from when he was the owner."},{"ref":"AWS.ServiceCatalog.html#describe_service_action/3","title":"AWS.ServiceCatalog.describe_service_action/3","type":"function","doc":"Describes a self-service action."},{"ref":"AWS.ServiceCatalog.html#describe_service_action_execution_parameters/3","title":"AWS.ServiceCatalog.describe_service_action_execution_parameters/3","type":"function","doc":"Finds the default parameters for a specific self-service action on a specific provisioned product and returns a map of the results to the user."},{"ref":"AWS.ServiceCatalog.html#describe_tag_option/3","title":"AWS.ServiceCatalog.describe_tag_option/3","type":"function","doc":"Gets information about the specified TagOption."},{"ref":"AWS.ServiceCatalog.html#disable_a_w_s_organizations_access/3","title":"AWS.ServiceCatalog.disable_a_w_s_organizations_access/3","type":"function","doc":"Disable portfolio sharing through AWS Organizations feature. This feature will not delete your current shares but it will prevent you from creating new shares throughout your organization. Current shares will not be in sync with your organization structure if it changes after calling this API. This API can only be called by the management account in the organization. This API can&#39;t be invoked if there are active delegated administrators in the organization. Note that a delegated administrator is not authorized to invoke DisableAWSOrganizationsAccess."},{"ref":"AWS.ServiceCatalog.html#disassociate_budget_from_resource/3","title":"AWS.ServiceCatalog.disassociate_budget_from_resource/3","type":"function","doc":"Disassociates the specified budget from the specified resource."},{"ref":"AWS.ServiceCatalog.html#disassociate_principal_from_portfolio/3","title":"AWS.ServiceCatalog.disassociate_principal_from_portfolio/3","type":"function","doc":"Disassociates a previously associated principal ARN from a specified portfolio."},{"ref":"AWS.ServiceCatalog.html#disassociate_product_from_portfolio/3","title":"AWS.ServiceCatalog.disassociate_product_from_portfolio/3","type":"function","doc":"Disassociates the specified product from the specified portfolio. A delegated admin is authorized to invoke this command."},{"ref":"AWS.ServiceCatalog.html#disassociate_service_action_from_provisioning_artifact/3","title":"AWS.ServiceCatalog.disassociate_service_action_from_provisioning_artifact/3","type":"function","doc":"Disassociates the specified self-service action association from the specified provisioning artifact."},{"ref":"AWS.ServiceCatalog.html#disassociate_tag_option_from_resource/3","title":"AWS.ServiceCatalog.disassociate_tag_option_from_resource/3","type":"function","doc":"Disassociates the specified TagOption from the specified resource."},{"ref":"AWS.ServiceCatalog.html#enable_a_w_s_organizations_access/3","title":"AWS.ServiceCatalog.enable_a_w_s_organizations_access/3","type":"function","doc":"Enable portfolio sharing feature through AWS Organizations. This API will allow Service Catalog to receive updates on your organization in order to sync your shares with the current structure. This API can only be called by the management account in the organization. By calling this API Service Catalog will make a call to organizations:EnableAWSServiceAccess on your behalf so that your shares can be in sync with any changes in your AWS Organizations structure. Note that a delegated administrator is not authorized to invoke EnableAWSOrganizationsAccess."},{"ref":"AWS.ServiceCatalog.html#execute_provisioned_product_plan/3","title":"AWS.ServiceCatalog.execute_provisioned_product_plan/3","type":"function","doc":"Provisions or modifies a product based on the resource changes for the specified plan."},{"ref":"AWS.ServiceCatalog.html#execute_provisioned_product_service_action/3","title":"AWS.ServiceCatalog.execute_provisioned_product_service_action/3","type":"function","doc":"Executes a self-service action against a provisioned product."},{"ref":"AWS.ServiceCatalog.html#get_a_w_s_organizations_access_status/3","title":"AWS.ServiceCatalog.get_a_w_s_organizations_access_status/3","type":"function","doc":"Get the Access Status for AWS Organization portfolio share feature. This API can only be called by the management account in the organization or by a delegated admin."},{"ref":"AWS.ServiceCatalog.html#get_provisioned_product_outputs/3","title":"AWS.ServiceCatalog.get_provisioned_product_outputs/3","type":"function","doc":"This API takes either a ProvisonedProductId or a ProvisionedProductName, along with a list of one or more output keys, and responds with the key/value pairs of those outputs."},{"ref":"AWS.ServiceCatalog.html#list_accepted_portfolio_shares/3","title":"AWS.ServiceCatalog.list_accepted_portfolio_shares/3","type":"function","doc":"Lists all portfolios for which sharing was accepted by this account."},{"ref":"AWS.ServiceCatalog.html#list_budgets_for_resource/3","title":"AWS.ServiceCatalog.list_budgets_for_resource/3","type":"function","doc":"Lists all the budgets associated to the specified resource."},{"ref":"AWS.ServiceCatalog.html#list_constraints_for_portfolio/3","title":"AWS.ServiceCatalog.list_constraints_for_portfolio/3","type":"function","doc":"Lists the constraints for the specified portfolio and product."},{"ref":"AWS.ServiceCatalog.html#list_launch_paths/3","title":"AWS.ServiceCatalog.list_launch_paths/3","type":"function","doc":"Lists the paths to the specified product. A path is how the user has access to a specified product, and is necessary when provisioning a product. A path also determines the constraints put on the product."},{"ref":"AWS.ServiceCatalog.html#list_organization_portfolio_access/3","title":"AWS.ServiceCatalog.list_organization_portfolio_access/3","type":"function","doc":"Lists the organization nodes that have access to the specified portfolio. This API can only be called by the management account in the organization or by a delegated admin. If a delegated admin is de-registered, they can no longer perform this operation."},{"ref":"AWS.ServiceCatalog.html#list_portfolio_access/3","title":"AWS.ServiceCatalog.list_portfolio_access/3","type":"function","doc":"Lists the account IDs that have access to the specified portfolio. A delegated admin can list the accounts that have access to the shared portfolio. Note that if a delegated admin is de-registered, they can no longer perform this operation."},{"ref":"AWS.ServiceCatalog.html#list_portfolios/3","title":"AWS.ServiceCatalog.list_portfolios/3","type":"function","doc":"Lists all portfolios in the catalog."},{"ref":"AWS.ServiceCatalog.html#list_portfolios_for_product/3","title":"AWS.ServiceCatalog.list_portfolios_for_product/3","type":"function","doc":"Lists all portfolios that the specified product is associated with."},{"ref":"AWS.ServiceCatalog.html#list_principals_for_portfolio/3","title":"AWS.ServiceCatalog.list_principals_for_portfolio/3","type":"function","doc":"Lists all principal ARNs associated with the specified portfolio."},{"ref":"AWS.ServiceCatalog.html#list_provisioned_product_plans/3","title":"AWS.ServiceCatalog.list_provisioned_product_plans/3","type":"function","doc":"Lists the plans for the specified provisioned product or all plans to which the user has access."},{"ref":"AWS.ServiceCatalog.html#list_provisioning_artifacts/3","title":"AWS.ServiceCatalog.list_provisioning_artifacts/3","type":"function","doc":"Lists all provisioning artifacts (also known as versions) for the specified product."},{"ref":"AWS.ServiceCatalog.html#list_provisioning_artifacts_for_service_action/3","title":"AWS.ServiceCatalog.list_provisioning_artifacts_for_service_action/3","type":"function","doc":"Lists all provisioning artifacts (also known as versions) for the specified self-service action."},{"ref":"AWS.ServiceCatalog.html#list_record_history/3","title":"AWS.ServiceCatalog.list_record_history/3","type":"function","doc":"Lists the specified requests or all performed requests."},{"ref":"AWS.ServiceCatalog.html#list_resources_for_tag_option/3","title":"AWS.ServiceCatalog.list_resources_for_tag_option/3","type":"function","doc":"Lists the resources associated with the specified TagOption."},{"ref":"AWS.ServiceCatalog.html#list_service_actions/3","title":"AWS.ServiceCatalog.list_service_actions/3","type":"function","doc":"Lists all self-service actions."},{"ref":"AWS.ServiceCatalog.html#list_service_actions_for_provisioning_artifact/3","title":"AWS.ServiceCatalog.list_service_actions_for_provisioning_artifact/3","type":"function","doc":"Returns a paginated list of self-service actions associated with the specified Product ID and Provisioning Artifact ID."},{"ref":"AWS.ServiceCatalog.html#list_stack_instances_for_provisioned_product/3","title":"AWS.ServiceCatalog.list_stack_instances_for_provisioned_product/3","type":"function","doc":"Returns summary information about stack instances that are associated with the specified CFN_STACKSET type provisioned product. You can filter for stack instances that are associated with a specific AWS account name or region."},{"ref":"AWS.ServiceCatalog.html#list_tag_options/3","title":"AWS.ServiceCatalog.list_tag_options/3","type":"function","doc":"Lists the specified TagOptions or all TagOptions."},{"ref":"AWS.ServiceCatalog.html#provision_product/3","title":"AWS.ServiceCatalog.provision_product/3","type":"function","doc":"Provisions the specified product. A provisioned product is a resourced instance of a product. For example, provisioning a product based on a CloudFormation template launches a CloudFormation stack and its underlying resources. You can check the status of this request using DescribeRecord. If the request contains a tag key with an empty list of values, there is a tag conflict for that key. Do not include conflicted keys as tags, or this causes the error &quot;Parameter validation failed: Missing required parameter in Tags[N]:Value&quot;."},{"ref":"AWS.ServiceCatalog.html#reject_portfolio_share/3","title":"AWS.ServiceCatalog.reject_portfolio_share/3","type":"function","doc":"Rejects an offer to share the specified portfolio."},{"ref":"AWS.ServiceCatalog.html#scan_provisioned_products/3","title":"AWS.ServiceCatalog.scan_provisioned_products/3","type":"function","doc":"Lists the provisioned products that are available (not terminated). To use additional filtering, see SearchProvisionedProducts."},{"ref":"AWS.ServiceCatalog.html#search_products/3","title":"AWS.ServiceCatalog.search_products/3","type":"function","doc":"Gets information about the products to which the caller has access."},{"ref":"AWS.ServiceCatalog.html#search_products_as_admin/3","title":"AWS.ServiceCatalog.search_products_as_admin/3","type":"function","doc":"Gets information about the products for the specified portfolio or all products."},{"ref":"AWS.ServiceCatalog.html#search_provisioned_products/3","title":"AWS.ServiceCatalog.search_provisioned_products/3","type":"function","doc":"Gets information about the provisioned products that meet the specified criteria."},{"ref":"AWS.ServiceCatalog.html#terminate_provisioned_product/3","title":"AWS.ServiceCatalog.terminate_provisioned_product/3","type":"function","doc":"Terminates the specified provisioned product. This operation does not delete any records associated with the provisioned product. You can check the status of this request using DescribeRecord."},{"ref":"AWS.ServiceCatalog.html#update_constraint/3","title":"AWS.ServiceCatalog.update_constraint/3","type":"function","doc":"Updates the specified constraint."},{"ref":"AWS.ServiceCatalog.html#update_portfolio/3","title":"AWS.ServiceCatalog.update_portfolio/3","type":"function","doc":"Updates the specified portfolio. You cannot update a product that was shared with you."},{"ref":"AWS.ServiceCatalog.html#update_product/3","title":"AWS.ServiceCatalog.update_product/3","type":"function","doc":"Updates the specified product."},{"ref":"AWS.ServiceCatalog.html#update_provisioned_product/3","title":"AWS.ServiceCatalog.update_provisioned_product/3","type":"function","doc":"Requests updates to the configuration of the specified provisioned product. If there are tags associated with the object, they cannot be updated or added. Depending on the specific updates requested, this operation can update with no interruption, with some interruption, or replace the provisioned product entirely. You can check the status of this request using DescribeRecord."},{"ref":"AWS.ServiceCatalog.html#update_provisioned_product_properties/3","title":"AWS.ServiceCatalog.update_provisioned_product_properties/3","type":"function","doc":"Requests updates to the properties of the specified provisioned product."},{"ref":"AWS.ServiceCatalog.html#update_provisioning_artifact/3","title":"AWS.ServiceCatalog.update_provisioning_artifact/3","type":"function","doc":"Updates the specified provisioning artifact (also known as a version) for the specified product. You cannot update a provisioning artifact for a product that was shared with you."},{"ref":"AWS.ServiceCatalog.html#update_service_action/3","title":"AWS.ServiceCatalog.update_service_action/3","type":"function","doc":"Updates a self-service action."},{"ref":"AWS.ServiceCatalog.html#update_tag_option/3","title":"AWS.ServiceCatalog.update_tag_option/3","type":"function","doc":"Updates the specified TagOption."},{"ref":"AWS.ServiceDiscovery.html","title":"AWS.ServiceDiscovery","type":"module","doc":"AWS Cloud Map lets you configure public DNS, private DNS, or HTTP namespaces that your microservice applications run in. When an instance of the service becomes available, you can call the AWS Cloud Map API to register the instance with AWS Cloud Map. For public or private DNS namespaces, AWS Cloud Map automatically creates DNS records and an optional health check. Clients that submit public or private DNS queries, or HTTP requests, for the service receive an answer that contains up to eight healthy records."},{"ref":"AWS.ServiceDiscovery.html#create_http_namespace/3","title":"AWS.ServiceDiscovery.create_http_namespace/3","type":"function","doc":"Creates an HTTP namespace. Service instances that you register using an HTTP namespace can be discovered using a DiscoverInstances request but can&#39;t be discovered using DNS. For the current quota on the number of namespaces that you can create using the same AWS account, see AWS Cloud Map quotas in the AWS Cloud Map Developer Guide."},{"ref":"AWS.ServiceDiscovery.html#create_private_dns_namespace/3","title":"AWS.ServiceDiscovery.create_private_dns_namespace/3","type":"function","doc":"Creates a private namespace based on DNS, which will be visible only inside a specified Amazon VPC. The namespace defines your service naming scheme. For example, if you name your namespace example.com and name your service backend, the resulting DNS name for the service will be backend.example.com. For the current quota on the number of namespaces that you can create using the same AWS account, see AWS Cloud Map Limits in the AWS Cloud Map Developer Guide."},{"ref":"AWS.ServiceDiscovery.html#create_public_dns_namespace/3","title":"AWS.ServiceDiscovery.create_public_dns_namespace/3","type":"function","doc":"Creates a public namespace based on DNS, which will be visible on the internet. The namespace defines your service naming scheme. For example, if you name your namespace example.com and name your service backend, the resulting DNS name for the service will be backend.example.com. For the current quota on the number of namespaces that you can create using the same AWS account, see AWS Cloud Map Limits in the AWS Cloud Map Developer Guide."},{"ref":"AWS.ServiceDiscovery.html#create_service/3","title":"AWS.ServiceDiscovery.create_service/3","type":"function","doc":"Creates a service, which defines the configuration for the following entities: For public and private DNS namespaces, one of the following combinations of DNS records in Amazon Route53: A AAAA A and AAAA SRV CNAME Optionally, a health check After you create the service, you can submit a RegisterInstance request, and AWS Cloud Map uses the values in the configuration to create the specified entities. For the current quota on the number of instances that you can register using the same namespace and using the same service, see AWS Cloud Map Limits in the AWS Cloud Map Developer Guide."},{"ref":"AWS.ServiceDiscovery.html#delete_namespace/3","title":"AWS.ServiceDiscovery.delete_namespace/3","type":"function","doc":"Deletes a namespace from the current account. If the namespace still contains one or more services, the request fails."},{"ref":"AWS.ServiceDiscovery.html#delete_service/3","title":"AWS.ServiceDiscovery.delete_service/3","type":"function","doc":"Deletes a specified service. If the service still contains one or more registered instances, the request fails."},{"ref":"AWS.ServiceDiscovery.html#deregister_instance/3","title":"AWS.ServiceDiscovery.deregister_instance/3","type":"function","doc":"Deletes the Amazon Route53 DNS records and health check, if any, that AWS Cloud Map created for the specified instance."},{"ref":"AWS.ServiceDiscovery.html#discover_instances/3","title":"AWS.ServiceDiscovery.discover_instances/3","type":"function","doc":"Discovers registered instances for a specified namespace and service. You can use DiscoverInstances to discover instances for any type of namespace. For public and private DNS namespaces, you can also use DNS queries to discover instances."},{"ref":"AWS.ServiceDiscovery.html#get_instance/3","title":"AWS.ServiceDiscovery.get_instance/3","type":"function","doc":"Gets information about a specified instance."},{"ref":"AWS.ServiceDiscovery.html#get_instances_health_status/3","title":"AWS.ServiceDiscovery.get_instances_health_status/3","type":"function","doc":"Gets the current health status (Healthy, Unhealthy, or Unknown) of one or more instances that are associated with a specified service. There is a brief delay between when you register an instance and when the health status for the instance is available."},{"ref":"AWS.ServiceDiscovery.html#get_namespace/3","title":"AWS.ServiceDiscovery.get_namespace/3","type":"function","doc":"Gets information about a namespace."},{"ref":"AWS.ServiceDiscovery.html#get_operation/3","title":"AWS.ServiceDiscovery.get_operation/3","type":"function","doc":"Gets information about any operation that returns an operation ID in the response, such as a CreateService request. To get a list of operations that match specified criteria, see ListOperations."},{"ref":"AWS.ServiceDiscovery.html#get_service/3","title":"AWS.ServiceDiscovery.get_service/3","type":"function","doc":"Gets the settings for a specified service."},{"ref":"AWS.ServiceDiscovery.html#list_instances/3","title":"AWS.ServiceDiscovery.list_instances/3","type":"function","doc":"Lists summary information about the instances that you registered by using a specified service."},{"ref":"AWS.ServiceDiscovery.html#list_namespaces/3","title":"AWS.ServiceDiscovery.list_namespaces/3","type":"function","doc":"Lists summary information about the namespaces that were created by the current AWS account."},{"ref":"AWS.ServiceDiscovery.html#list_operations/3","title":"AWS.ServiceDiscovery.list_operations/3","type":"function","doc":"Lists operations that match the criteria that you specify."},{"ref":"AWS.ServiceDiscovery.html#list_services/3","title":"AWS.ServiceDiscovery.list_services/3","type":"function","doc":"Lists summary information for all the services that are associated with one or more specified namespaces."},{"ref":"AWS.ServiceDiscovery.html#list_tags_for_resource/3","title":"AWS.ServiceDiscovery.list_tags_for_resource/3","type":"function","doc":"Lists tags for the specified resource."},{"ref":"AWS.ServiceDiscovery.html#register_instance/3","title":"AWS.ServiceDiscovery.register_instance/3","type":"function","doc":"Creates or updates one or more records and, optionally, creates a health check based on the settings in a specified service. When you submit a RegisterInstance request, the following occurs: For each DNS record that you define in the service that is specified by ServiceId, a record is created or updated in the hosted zone that is associated with the corresponding namespace. If the service includes HealthCheckConfig, a health check is created based on the settings in the health check configuration. The health check, if any, is associated with each of the new or updated records. One RegisterInstance request must complete before you can submit another request and specify the same service ID and instance ID. For more information, see CreateService. When AWS Cloud Map receives a DNS query for the specified DNS name, it returns the applicable value: If the health check is healthy: returns all the records If the health check is unhealthy: returns the applicable value for the last healthy instance If you didn&#39;t specify a health check configuration: returns all the records For the current quota on the number of instances that you can register using the same namespace and using the same service, see AWS Cloud Map Limits in the AWS Cloud Map Developer Guide."},{"ref":"AWS.ServiceDiscovery.html#tag_resource/3","title":"AWS.ServiceDiscovery.tag_resource/3","type":"function","doc":"Adds one or more tags to the specified resource."},{"ref":"AWS.ServiceDiscovery.html#untag_resource/3","title":"AWS.ServiceDiscovery.untag_resource/3","type":"function","doc":"Removes one or more tags from the specified resource."},{"ref":"AWS.ServiceDiscovery.html#update_instance_custom_health_status/3","title":"AWS.ServiceDiscovery.update_instance_custom_health_status/3","type":"function","doc":"Submits a request to change the health status of a custom health check to healthy or unhealthy. You can use UpdateInstanceCustomHealthStatus to change the status only for custom health checks, which you define using HealthCheckCustomConfig when you create a service. You can&#39;t use it to change the status for Route53 health checks, which you define using HealthCheckConfig. For more information, see HealthCheckCustomConfig."},{"ref":"AWS.ServiceDiscovery.html#update_service/3","title":"AWS.ServiceDiscovery.update_service/3","type":"function","doc":"Submits a request to perform the following operations: Update the TTL setting for existing DnsRecords configurations Add, update, or delete HealthCheckConfig for a specified service You can&#39;t add, update, or delete a HealthCheckCustomConfig configuration. For public and private DNS namespaces, note the following: If you omit any existing DnsRecords or HealthCheckConfig configurations from an UpdateService request, the configurations are deleted from the service. If you omit an existing HealthCheckCustomConfig configuration from an UpdateService request, the configuration is not deleted from the service. When you update settings for a service, AWS Cloud Map also updates the corresponding settings in all the records and health checks that were created by using the specified service."},{"ref":"AWS.ServiceQuotas.html","title":"AWS.ServiceQuotas","type":"module","doc":"Service Quotas is a web service that you can use to manage many of your AWS service quotas. Quotas, also referred to as limits, are the maximum values for a resource, item, or operation. This guide provide descriptions of the Service Quotas actions that you can call from an API. For the Service Quotas user guide, which explains how to use Service Quotas from the console, see What is Service Quotas. AWS provides SDKs that consist of libraries and sample code for programming languages and platforms (Java, Ruby, .NET, iOS, Android, etc...,). The SDKs provide a convenient way to create programmatic access to Service Quotas and AWS. For information about the AWS SDKs, including how to download and install them, see the Tools for Amazon Web Services page."},{"ref":"AWS.ServiceQuotas.html#associate_service_quota_template/3","title":"AWS.ServiceQuotas.associate_service_quota_template/3","type":"function","doc":"Associates the Service Quotas template with your organization so that when new accounts are created in your organization, the template submits increase requests for the specified service quotas. Use the Service Quotas template to request an increase for any adjustable quota value. After you define the Service Quotas template, use this operation to associate, or enable, the template."},{"ref":"AWS.ServiceQuotas.html#delete_service_quota_increase_request_from_template/3","title":"AWS.ServiceQuotas.delete_service_quota_increase_request_from_template/3","type":"function","doc":"Removes a service quota increase request from the Service Quotas template."},{"ref":"AWS.ServiceQuotas.html#disassociate_service_quota_template/3","title":"AWS.ServiceQuotas.disassociate_service_quota_template/3","type":"function","doc":"Disables the Service Quotas template. Once the template is disabled, it does not request quota increases for new accounts in your organization. Disabling the quota template does not apply the quota increase requests from the template. Related operations To enable the quota template, call AssociateServiceQuotaTemplate. To delete a specific service quota from the template, use DeleteServiceQuotaIncreaseRequestFromTemplate."},{"ref":"AWS.ServiceQuotas.html#get_a_w_s_default_service_quota/3","title":"AWS.ServiceQuotas.get_a_w_s_default_service_quota/3","type":"function","doc":"Retrieves the default service quotas values. The Value returned for each quota is the AWS default value, even if the quotas have been increased.."},{"ref":"AWS.ServiceQuotas.html#get_association_for_service_quota_template/3","title":"AWS.ServiceQuotas.get_association_for_service_quota_template/3","type":"function","doc":"Retrieves the ServiceQuotaTemplateAssociationStatus value from the service. Use this action to determine if the Service Quota template is associated, or enabled."},{"ref":"AWS.ServiceQuotas.html#get_requested_service_quota_change/3","title":"AWS.ServiceQuotas.get_requested_service_quota_change/3","type":"function","doc":"Retrieves the details for a particular increase request."},{"ref":"AWS.ServiceQuotas.html#get_service_quota/3","title":"AWS.ServiceQuotas.get_service_quota/3","type":"function","doc":"Returns the details for the specified service quota. This operation provides a different Value than the GetAWSDefaultServiceQuota operation. This operation returns the applied value for each quota. GetAWSDefaultServiceQuota returns the default AWS value for each quota."},{"ref":"AWS.ServiceQuotas.html#get_service_quota_increase_request_from_template/3","title":"AWS.ServiceQuotas.get_service_quota_increase_request_from_template/3","type":"function","doc":"Returns the details of the service quota increase request in your template."},{"ref":"AWS.ServiceQuotas.html#list_a_w_s_default_service_quotas/3","title":"AWS.ServiceQuotas.list_a_w_s_default_service_quotas/3","type":"function","doc":"Lists all default service quotas for the specified AWS service or all AWS services. ListAWSDefaultServiceQuotas is similar to ListServiceQuotas except for the Value object. The Value object returned by ListAWSDefaultServiceQuotas is the default value assigned by AWS. This request returns a list of all service quotas for the specified service. The listing of each you&#39;ll see the default values are the values that AWS provides for the quotas. Always check the NextToken response parameter when calling any of the List* operations. These operations can return an unexpected list of results, even when there are more results available. When this happens, the NextToken response parameter contains a value to pass the next call to the same API to request the next part of the list."},{"ref":"AWS.ServiceQuotas.html#list_requested_service_quota_change_history/3","title":"AWS.ServiceQuotas.list_requested_service_quota_change_history/3","type":"function","doc":"Requests a list of the changes to quotas for a service."},{"ref":"AWS.ServiceQuotas.html#list_requested_service_quota_change_history_by_quota/3","title":"AWS.ServiceQuotas.list_requested_service_quota_change_history_by_quota/3","type":"function","doc":"Requests a list of the changes to specific service quotas. This command provides additional granularity over the ListRequestedServiceQuotaChangeHistory command. Once a quota change request has reached CASE_CLOSED, APPROVED, or DENIED, the history has been kept for 90 days."},{"ref":"AWS.ServiceQuotas.html#list_service_quota_increase_requests_in_template/3","title":"AWS.ServiceQuotas.list_service_quota_increase_requests_in_template/3","type":"function","doc":"Returns a list of the quota increase requests in the template."},{"ref":"AWS.ServiceQuotas.html#list_service_quotas/3","title":"AWS.ServiceQuotas.list_service_quotas/3","type":"function","doc":"Lists all service quotas for the specified AWS service. This request returns a list of the service quotas for the specified service. you&#39;ll see the default values are the values that AWS provides for the quotas. Always check the NextToken response parameter when calling any of the List* operations. These operations can return an unexpected list of results, even when there are more results available. When this happens, the NextToken response parameter contains a value to pass the next call to the same API to request the next part of the list."},{"ref":"AWS.ServiceQuotas.html#list_services/3","title":"AWS.ServiceQuotas.list_services/3","type":"function","doc":"Lists the AWS services available in Service Quotas. Not all AWS services are available in Service Quotas. To list the see the list of the service quotas for a specific service, use ListServiceQuotas."},{"ref":"AWS.ServiceQuotas.html#put_service_quota_increase_request_into_template/3","title":"AWS.ServiceQuotas.put_service_quota_increase_request_into_template/3","type":"function","doc":"Defines and adds a quota to the service quota template. To add a quota to the template, you must provide the ServiceCode, QuotaCode, AwsRegion, and DesiredValue. Once you add a quota to the template, use ListServiceQuotaIncreaseRequestsInTemplate to see the list of quotas in the template."},{"ref":"AWS.ServiceQuotas.html#request_service_quota_increase/3","title":"AWS.ServiceQuotas.request_service_quota_increase/3","type":"function","doc":"Retrieves the details of a service quota increase request. The response to this command provides the details in the RequestedServiceQuotaChange object."},{"ref":"AWS.Shield.html","title":"AWS.Shield","type":"module","doc":"AWS Shield Advanced This is the AWS Shield Advanced API Reference. This guide is for developers who need detailed information about the AWS Shield Advanced API actions, data types, and errors. For detailed information about AWS WAF and AWS Shield Advanced features and an overview of how to use the AWS WAF and AWS Shield Advanced APIs, see the AWS WAF and AWS Shield Developer Guide."},{"ref":"AWS.Shield.html#associate_d_r_t_log_bucket/3","title":"AWS.Shield.associate_d_r_t_log_bucket/3","type":"function","doc":"Authorizes the DDoS Response Team (DRT) to access the specified Amazon S3 bucket containing your AWS WAF logs. You can associate up to 10 Amazon S3 buckets with your subscription. To use the services of the DRT and make an AssociateDRTLogBucket request, you must be subscribed to the Business Support plan or the Enterprise Support plan."},{"ref":"AWS.Shield.html#associate_d_r_t_role/3","title":"AWS.Shield.associate_d_r_t_role/3","type":"function","doc":"Authorizes the DDoS Response Team (DRT), using the specified role, to access your AWS account to assist with DDoS attack mitigation during potential attacks. This enables the DRT to inspect your AWS WAF configuration and create or update AWS WAF rules and web ACLs. You can associate only one RoleArn with your subscription. If you submit an AssociateDRTRole request for an account that already has an associated role, the new RoleArn will replace the existing RoleArn. Prior to making the AssociateDRTRole request, you must attach the AWSShieldDRTAccessPolicy managed policy to the role you will specify in the request. For more information see Attaching and Detaching IAM Policies. The role must also trust the service principal drt.shield.amazonaws.com. For more information, see IAM JSON Policy Elements: Principal. The DRT will have access only to your AWS WAF and Shield resources. By submitting this request, you authorize the DRT to inspect your AWS WAF and Shield configuration and create and update AWS WAF rules and web ACLs on your behalf. The DRT takes these actions only if explicitly authorized by you. You must have the iam:PassRole permission to make an AssociateDRTRole request. For more information, see Granting a User Permissions to Pass a Role to an AWS Service. To use the services of the DRT and make an AssociateDRTRole request, you must be subscribed to the Business Support plan or the Enterprise Support plan."},{"ref":"AWS.Shield.html#associate_health_check/3","title":"AWS.Shield.associate_health_check/3","type":"function","doc":"Adds health-based detection to the Shield Advanced protection for a resource. Shield Advanced health-based detection uses the health of your AWS resource to improve responsiveness and accuracy in attack detection and mitigation. You define the health check in Route 53 and then associate it with your Shield Advanced protection. For more information, see Shield Advanced Health-Based Detection in the AWS WAF and AWS Shield Developer Guide."},{"ref":"AWS.Shield.html#associate_proactive_engagement_details/3","title":"AWS.Shield.associate_proactive_engagement_details/3","type":"function","doc":"Initializes proactive engagement and sets the list of contacts for the DDoS Response Team (DRT) to use. You must provide at least one phone number in the emergency contact list. After you have initialized proactive engagement using this call, to disable or enable proactive engagement, use the calls DisableProactiveEngagement and EnableProactiveEngagement. This call defines the list of email addresses and phone numbers that the DDoS Response Team (DRT) can use to contact you for escalations to the DRT and to initiate proactive customer support. The contacts that you provide in the request replace any contacts that were already defined. If you already have contacts defined and want to use them, retrieve the list using DescribeEmergencyContactSettings and then provide it to this call."},{"ref":"AWS.Shield.html#create_protection/3","title":"AWS.Shield.create_protection/3","type":"function","doc":"Enables AWS Shield Advanced for a specific AWS resource. The resource can be an Amazon CloudFront distribution, Elastic Load Balancing load balancer, AWS Global Accelerator accelerator, Elastic IP Address, or an Amazon Route 53 hosted zone. You can add protection to only a single resource with each CreateProtection request. If you want to add protection to multiple resources at once, use the AWS WAF console. For more information see Getting Started with AWS Shield Advanced and Add AWS Shield Advanced Protection to more AWS Resources."},{"ref":"AWS.Shield.html#create_subscription/3","title":"AWS.Shield.create_subscription/3","type":"function","doc":"Activates AWS Shield Advanced for an account. When you initally create a subscription, your subscription is set to be automatically renewed at the end of the existing subscription period. You can change this by submitting an UpdateSubscription request."},{"ref":"AWS.Shield.html#delete_protection/3","title":"AWS.Shield.delete_protection/3","type":"function","doc":"Deletes an AWS Shield Advanced Protection."},{"ref":"AWS.Shield.html#delete_subscription/3","title":"AWS.Shield.delete_subscription/3","type":"function","doc":"Removes AWS Shield Advanced from an account. AWS Shield Advanced requires a 1-year subscription commitment. You cannot delete a subscription prior to the completion of that commitment."},{"ref":"AWS.Shield.html#describe_attack/3","title":"AWS.Shield.describe_attack/3","type":"function","doc":"Describes the details of a DDoS attack."},{"ref":"AWS.Shield.html#describe_d_r_t_access/3","title":"AWS.Shield.describe_d_r_t_access/3","type":"function","doc":"Returns the current role and list of Amazon S3 log buckets used by the DDoS Response Team (DRT) to access your AWS account while assisting with attack mitigation."},{"ref":"AWS.Shield.html#describe_emergency_contact_settings/3","title":"AWS.Shield.describe_emergency_contact_settings/3","type":"function","doc":"A list of email addresses and phone numbers that the DDoS Response Team (DRT) can use to contact you if you have proactive engagement enabled, for escalations to the DRT and to initiate proactive customer support."},{"ref":"AWS.Shield.html#describe_protection/3","title":"AWS.Shield.describe_protection/3","type":"function","doc":"Lists the details of a Protection object."},{"ref":"AWS.Shield.html#describe_subscription/3","title":"AWS.Shield.describe_subscription/3","type":"function","doc":"Provides details about the AWS Shield Advanced subscription for an account."},{"ref":"AWS.Shield.html#disable_proactive_engagement/3","title":"AWS.Shield.disable_proactive_engagement/3","type":"function","doc":"Removes authorization from the DDoS Response Team (DRT) to notify contacts about escalations to the DRT and to initiate proactive customer support."},{"ref":"AWS.Shield.html#disassociate_d_r_t_log_bucket/3","title":"AWS.Shield.disassociate_d_r_t_log_bucket/3","type":"function","doc":"Removes the DDoS Response Team&#39;s (DRT) access to the specified Amazon S3 bucket containing your AWS WAF logs. To make a DisassociateDRTLogBucket request, you must be subscribed to the Business Support plan or the Enterprise Support plan. However, if you are not subscribed to one of these support plans, but had been previously and had granted the DRT access to your account, you can submit a DisassociateDRTLogBucket request to remove this access."},{"ref":"AWS.Shield.html#disassociate_d_r_t_role/3","title":"AWS.Shield.disassociate_d_r_t_role/3","type":"function","doc":"Removes the DDoS Response Team&#39;s (DRT) access to your AWS account. To make a DisassociateDRTRole request, you must be subscribed to the Business Support plan or the Enterprise Support plan. However, if you are not subscribed to one of these support plans, but had been previously and had granted the DRT access to your account, you can submit a DisassociateDRTRole request to remove this access."},{"ref":"AWS.Shield.html#disassociate_health_check/3","title":"AWS.Shield.disassociate_health_check/3","type":"function","doc":"Removes health-based detection from the Shield Advanced protection for a resource. Shield Advanced health-based detection uses the health of your AWS resource to improve responsiveness and accuracy in attack detection and mitigation. You define the health check in Route 53 and then associate or disassociate it with your Shield Advanced protection. For more information, see Shield Advanced Health-Based Detection in the AWS WAF and AWS Shield Developer Guide."},{"ref":"AWS.Shield.html#enable_proactive_engagement/3","title":"AWS.Shield.enable_proactive_engagement/3","type":"function","doc":"Authorizes the DDoS Response Team (DRT) to use email and phone to notify contacts about escalations to the DRT and to initiate proactive customer support."},{"ref":"AWS.Shield.html#get_subscription_state/3","title":"AWS.Shield.get_subscription_state/3","type":"function","doc":"Returns the SubscriptionState, either Active or Inactive."},{"ref":"AWS.Shield.html#list_attacks/3","title":"AWS.Shield.list_attacks/3","type":"function","doc":"Returns all ongoing DDoS attacks or all DDoS attacks during a specified time period."},{"ref":"AWS.Shield.html#list_protections/3","title":"AWS.Shield.list_protections/3","type":"function","doc":"Lists all Protection objects for the account."},{"ref":"AWS.Shield.html#update_emergency_contact_settings/3","title":"AWS.Shield.update_emergency_contact_settings/3","type":"function","doc":"Updates the details of the list of email addresses and phone numbers that the DDoS Response Team (DRT) can use to contact you if you have proactive engagement enabled, for escalations to the DRT and to initiate proactive customer support."},{"ref":"AWS.Shield.html#update_subscription/3","title":"AWS.Shield.update_subscription/3","type":"function","doc":"Updates the details of an existing subscription. Only enter values for parameters you want to change. Empty parameters are not updated."},{"ref":"AWS.Signer.html","title":"AWS.Signer","type":"module","doc":"With code signing for IoT, you can sign code that you create for any IoT device that is supported by Amazon Web Services (AWS). Code signing is available through Amazon FreeRTOS and AWS IoT Device Management, and integrated with AWS Certificate Manager (ACM). In order to sign code, you import a third-party code signing certificate with ACM that is used to sign updates in Amazon FreeRTOS and AWS IoT Device Management. For general information about using code signing, see the Code Signing for IoT Developer Guide."},{"ref":"AWS.Signer.html#cancel_signing_profile/4","title":"AWS.Signer.cancel_signing_profile/4","type":"function","doc":"Changes the state of an ACTIVE signing profile to CANCELED. A canceled profile is still viewable with the ListSigningProfiles operation, but it cannot perform new signing jobs, and is deleted two years after cancelation."},{"ref":"AWS.Signer.html#describe_signing_job/3","title":"AWS.Signer.describe_signing_job/3","type":"function","doc":"Returns information about a specific code signing job. You specify the job by using the jobId value that is returned by the StartSigningJob operation."},{"ref":"AWS.Signer.html#get_signing_platform/3","title":"AWS.Signer.get_signing_platform/3","type":"function","doc":"Returns information on a specific signing platform."},{"ref":"AWS.Signer.html#get_signing_profile/3","title":"AWS.Signer.get_signing_profile/3","type":"function","doc":"Returns information on a specific signing profile."},{"ref":"AWS.Signer.html#list_signing_jobs/7","title":"AWS.Signer.list_signing_jobs/7","type":"function","doc":"Lists all your signing jobs. You can use the maxResults parameter to limit the number of signing jobs that are returned in the response. If additional jobs remain to be listed, code signing returns a nextToken value. Use this value in subsequent calls to ListSigningJobs to fetch the remaining values. You can continue calling ListSigningJobs with your maxResults parameter and with new values that code signing returns in the nextToken parameter until all of your signing jobs have been returned."},{"ref":"AWS.Signer.html#list_signing_platforms/7","title":"AWS.Signer.list_signing_platforms/7","type":"function","doc":"Lists all signing platforms available in code signing that match the request parameters. If additional jobs remain to be listed, code signing returns a nextToken value. Use this value in subsequent calls to ListSigningJobs to fetch the remaining values. You can continue calling ListSigningJobs with your maxResults parameter and with new values that code signing returns in the nextToken parameter until all of your signing jobs have been returned."},{"ref":"AWS.Signer.html#list_signing_profiles/5","title":"AWS.Signer.list_signing_profiles/5","type":"function","doc":"Lists all available signing profiles in your AWS account. Returns only profiles with an ACTIVE status unless the includeCanceled request field is set to true. If additional jobs remain to be listed, code signing returns a nextToken value. Use this value in subsequent calls to ListSigningJobs to fetch the remaining values. You can continue calling ListSigningJobs with your maxResults parameter and with new values that code signing returns in the nextToken parameter until all of your signing jobs have been returned."},{"ref":"AWS.Signer.html#list_tags_for_resource/3","title":"AWS.Signer.list_tags_for_resource/3","type":"function","doc":"Returns a list of the tags associated with a signing profile resource."},{"ref":"AWS.Signer.html#put_signing_profile/4","title":"AWS.Signer.put_signing_profile/4","type":"function","doc":"Creates a signing profile. A signing profile is a code signing template that can be used to carry out a pre-defined signing job. For more information, see http://docs.aws.amazon.com/signer/latest/developerguide/gs-profile.html"},{"ref":"AWS.Signer.html#start_signing_job/3","title":"AWS.Signer.start_signing_job/3","type":"function","doc":"Initiates a signing job to be performed on the code provided. Signing jobs are viewable by the ListSigningJobs operation for two years after they are performed. Note the following requirements: You must create an Amazon S3 source bucket. For more information, see Create a Bucket in the Amazon S3 Getting Started Guide. Your S3 source bucket must be version enabled. You must create an S3 destination bucket. Code signing uses your S3 destination bucket to write your signed code. You specify the name of the source and destination buckets when calling the StartSigningJob operation. You must also specify a request token that identifies your request to code signing. You can call the DescribeSigningJob and the ListSigningJobs actions after you call StartSigningJob. For a Java example that shows how to use this action, see http://docs.aws.amazon.com/acm/latest/userguide/"},{"ref":"AWS.Signer.html#tag_resource/4","title":"AWS.Signer.tag_resource/4","type":"function","doc":"Adds one or more tags to a signing profile. Tags are labels that you can use to identify and organize your AWS resources. Each tag consists of a key and an optional value. To specify the signing profile, use its Amazon Resource Name (ARN). To specify the tag, use a key-value pair."},{"ref":"AWS.Signer.html#untag_resource/4","title":"AWS.Signer.untag_resource/4","type":"function","doc":"Removes one or more tags from a signing profile. To remove the tags, specify a list of tag keys."},{"ref":"AWS.Snowball.html","title":"AWS.Snowball","type":"module","doc":"AWS Snow Family is a petabyte-scale data transport solution that uses secure devices to transfer large amounts of data between your on-premises data centers and Amazon Simple Storage Service (Amazon S3). The Snow commands described here provide access to the same functionality that is available in the AWS Snow Family Management Console, which enables you to create and manage jobs for a Snow device. To transfer data locally with a Snow device, you&#39;ll need to use the Snowball Edge client or the Amazon S3 API Interface for Snowball or AWS OpsHub for Snow Family. For more information, see the User Guide."},{"ref":"AWS.Snowball.html#cancel_cluster/3","title":"AWS.Snowball.cancel_cluster/3","type":"function","doc":"Cancels a cluster job. You can only cancel a cluster job while it&#39;s in the AwaitingQuorum status. You&#39;ll have at least an hour after creating a cluster job to cancel it."},{"ref":"AWS.Snowball.html#cancel_job/3","title":"AWS.Snowball.cancel_job/3","type":"function","doc":"Cancels the specified job. You can only cancel a job before its JobState value changes to PreparingAppliance. Requesting the ListJobs or DescribeJob action returns a job&#39;s JobState as part of the response element data returned."},{"ref":"AWS.Snowball.html#create_address/3","title":"AWS.Snowball.create_address/3","type":"function","doc":"Creates an address for a Snow device to be shipped to. In most regions, addresses are validated at the time of creation. The address you provide must be located within the serviceable area of your region. If the address is invalid or unsupported, then an exception is thrown."},{"ref":"AWS.Snowball.html#create_cluster/3","title":"AWS.Snowball.create_cluster/3","type":"function","doc":"Creates an empty cluster. Each cluster supports five nodes. You use the CreateJob action separately to create the jobs for each of these nodes. The cluster does not ship until these five node jobs have been created."},{"ref":"AWS.Snowball.html#create_job/3","title":"AWS.Snowball.create_job/3","type":"function","doc":"Creates a job to import or export data between Amazon S3 and your on-premises data center. Your AWS account must have the right trust policies and permissions in place to create a job for a Snow device. If you&#39;re creating a job for a node in a cluster, you only need to provide the clusterId value; the other job attributes are inherited from the cluster."},{"ref":"AWS.Snowball.html#create_return_shipping_label/3","title":"AWS.Snowball.create_return_shipping_label/3","type":"function","doc":"Creates a shipping label that will be used to return the Snow device to AWS."},{"ref":"AWS.Snowball.html#describe_address/3","title":"AWS.Snowball.describe_address/3","type":"function","doc":"Takes an AddressId and returns specific details about that address in the form of an Address object."},{"ref":"AWS.Snowball.html#describe_addresses/3","title":"AWS.Snowball.describe_addresses/3","type":"function","doc":"Returns a specified number of ADDRESS objects. Calling this API in one of the US regions will return addresses from the list of all addresses associated with this account in all US regions."},{"ref":"AWS.Snowball.html#describe_cluster/3","title":"AWS.Snowball.describe_cluster/3","type":"function","doc":"Returns information about a specific cluster including shipping information, cluster status, and other important metadata."},{"ref":"AWS.Snowball.html#describe_job/3","title":"AWS.Snowball.describe_job/3","type":"function","doc":"Returns information about a specific job including shipping information, job status, and other important metadata."},{"ref":"AWS.Snowball.html#describe_return_shipping_label/3","title":"AWS.Snowball.describe_return_shipping_label/3","type":"function","doc":"Information on the shipping label of a Snow device that is being returned to AWS."},{"ref":"AWS.Snowball.html#get_job_manifest/3","title":"AWS.Snowball.get_job_manifest/3","type":"function","doc":"Returns a link to an Amazon S3 presigned URL for the manifest file associated with the specified JobId value. You can access the manifest file for up to 60 minutes after this request has been made. To access the manifest file after 60 minutes have passed, you&#39;ll have to make another call to the GetJobManifest action. The manifest is an encrypted file that you can download after your job enters the WithCustomer status. The manifest is decrypted by using the UnlockCode code value, when you pass both values to the Snow device through the Snowball client when the client is started for the first time. As a best practice, we recommend that you don&#39;t save a copy of an UnlockCode value in the same location as the manifest file for that job. Saving these separately helps prevent unauthorized parties from gaining access to the Snow device associated with that job. The credentials of a given job, including its manifest file and unlock code, expire 90 days after the job is created."},{"ref":"AWS.Snowball.html#get_job_unlock_code/3","title":"AWS.Snowball.get_job_unlock_code/3","type":"function","doc":"Returns the UnlockCode code value for the specified job. A particular UnlockCode value can be accessed for up to 90 days after the associated job has been created. The UnlockCode value is a 29-character code with 25 alphanumeric characters and 4 hyphens. This code is used to decrypt the manifest file when it is passed along with the manifest to the Snow device through the Snowball client when the client is started for the first time. As a best practice, we recommend that you don&#39;t save a copy of the UnlockCode in the same location as the manifest file for that job. Saving these separately helps prevent unauthorized parties from gaining access to the Snow device associated with that job."},{"ref":"AWS.Snowball.html#get_snowball_usage/3","title":"AWS.Snowball.get_snowball_usage/3","type":"function","doc":"Returns information about the Snow Family service limit for your account, and also the number of Snow devices your account has in use. The default service limit for the number of Snow devices that you can have at one time is 1. If you want to increase your service limit, contact AWS Support."},{"ref":"AWS.Snowball.html#get_software_updates/3","title":"AWS.Snowball.get_software_updates/3","type":"function","doc":"Returns an Amazon S3 presigned URL for an update file associated with a specified JobId."},{"ref":"AWS.Snowball.html#list_cluster_jobs/3","title":"AWS.Snowball.list_cluster_jobs/3","type":"function","doc":"Returns an array of JobListEntry objects of the specified length. Each JobListEntry object is for a job in the specified cluster and contains a job&#39;s state, a job&#39;s ID, and other information."},{"ref":"AWS.Snowball.html#list_clusters/3","title":"AWS.Snowball.list_clusters/3","type":"function","doc":"Returns an array of ClusterListEntry objects of the specified length. Each ClusterListEntry object contains a cluster&#39;s state, a cluster&#39;s ID, and other important status information."},{"ref":"AWS.Snowball.html#list_compatible_images/3","title":"AWS.Snowball.list_compatible_images/3","type":"function","doc":"This action returns a list of the different Amazon EC2 Amazon Machine Images (AMIs) that are owned by your AWS account that would be supported for use on a Snow device. Currently, supported AMIs are based on the CentOS 7 (x86_64) - with Updates HVM, Ubuntu Server 14.04 LTS (HVM), and Ubuntu 16.04 LTS - Xenial (HVM) images, available on the AWS Marketplace."},{"ref":"AWS.Snowball.html#list_jobs/3","title":"AWS.Snowball.list_jobs/3","type":"function","doc":"Returns an array of JobListEntry objects of the specified length. Each JobListEntry object contains a job&#39;s state, a job&#39;s ID, and a value that indicates whether the job is a job part, in the case of export jobs. Calling this API action in one of the US regions will return jobs from the list of all jobs associated with this account in all US regions."},{"ref":"AWS.Snowball.html#update_cluster/3","title":"AWS.Snowball.update_cluster/3","type":"function","doc":"While a cluster&#39;s ClusterState value is in the AwaitingQuorum state, you can update some of the information associated with a cluster. Once the cluster changes to a different job state, usually 60 minutes after the cluster being created, this action is no longer available."},{"ref":"AWS.Snowball.html#update_job/3","title":"AWS.Snowball.update_job/3","type":"function","doc":"While a job&#39;s JobState value is New, you can update some of the information associated with a job. Once the job changes to a different job state, usually within 60 minutes of the job being created, this action is no longer available."},{"ref":"AWS.Snowball.html#update_job_shipment_state/3","title":"AWS.Snowball.update_job_shipment_state/3","type":"function","doc":"Updates the state when a the shipment states changes to a different state."},{"ref":"AWS.StorageGateway.html","title":"AWS.StorageGateway","type":"module","doc":"AWS Storage Gateway Service AWS Storage Gateway is the service that connects an on-premises software appliance with cloud-based storage to provide seamless and secure integration between an organization&#39;s on-premises IT environment and the AWS storage infrastructure. The service enables you to securely upload data to the AWS Cloud for cost effective backup and rapid disaster recovery. Use the following links to get started using the AWS Storage Gateway Service API Reference: AWS Storage Gateway required request headers: Describes the required headers that you must send with every POST request to AWS Storage Gateway. Signing requests: AWS Storage Gateway requires that you authenticate every request you send; this topic describes how sign such a request. Error responses: Provides reference information about AWS Storage Gateway errors. Operations in AWS Storage Gateway: Contains detailed descriptions of all AWS Storage Gateway operations, their request parameters, response elements, possible errors, and examples of requests and responses. AWS Storage Gateway endpoints and quotas: Provides a list of each AWS Region and the endpoints available for use with AWS Storage Gateway. AWS Storage Gateway resource IDs are in uppercase. When you use these resource IDs with the Amazon EC2 API, EC2 expects resource IDs in lowercase. You must change your resource ID to lowercase to use it with the EC2 API. For example, in Storage Gateway the ID for a volume might be vol-AA22BB012345DAF670. When you use this ID with the EC2 API, you must change it to vol-aa22bb012345daf670. Otherwise, the EC2 API might not behave as expected. IDs for Storage Gateway volumes and Amazon EBS snapshots created from gateway volumes are changing to a longer format. Starting in December 2016, all new volumes and snapshots will be created with a 17-character string. Starting in April 2016, you will be able to use these longer IDs so you can test your systems with the new format. For more information, see Longer EC2 and EBS resource IDs. For example, a volume Amazon Resource Name (ARN) with the longer volume ID format looks like the following: arn:aws:storagegateway:us-west-2:111122223333:gateway/sgw-12A3456B/volume/vol-1122AABBCCDDEEFFG. A snapshot ID with the longer ID format looks like the following: snap-78e226633445566ee. For more information, see Announcement: Heads-up  Longer AWS Storage Gateway volume and snapshot IDs coming in 2016."},{"ref":"AWS.StorageGateway.html#activate_gateway/3","title":"AWS.StorageGateway.activate_gateway/3","type":"function","doc":"Activates the gateway you previously deployed on your host. In the activation process, you specify information such as the AWS Region that you want to use for storing snapshots or tapes, the time zone for scheduled snapshots the gateway snapshot schedule window, an activation key, and a name for your gateway. The activation process also associates your gateway with your account. For more information, see UpdateGatewayInformation. You must turn on the gateway VM before you can activate your gateway."},{"ref":"AWS.StorageGateway.html#add_cache/3","title":"AWS.StorageGateway.add_cache/3","type":"function","doc":"Configures one or more gateway local disks as cache for a gateway. This operation is only supported in the cached volume, tape, and file gateway type (see How AWS Storage Gateway works (architecture). In the request, you specify the gateway Amazon Resource Name (ARN) to which you want to add cache, and one or more disk IDs that you want to configure as cache."},{"ref":"AWS.StorageGateway.html#add_tags_to_resource/3","title":"AWS.StorageGateway.add_tags_to_resource/3","type":"function","doc":"Adds one or more tags to the specified resource. You use tags to add metadata to resources, which you can use to categorize these resources. For example, you can categorize resources by purpose, owner, environment, or team. Each tag consists of a key and a value, which you define. You can add tags to the following AWS Storage Gateway resources: Storage gateways of all types Storage volumes Virtual tapes NFS and SMB file shares You can create a maximum of 50 tags for each resource. Virtual tapes and storage volumes that are recovered to a new gateway maintain their tags."},{"ref":"AWS.StorageGateway.html#add_upload_buffer/3","title":"AWS.StorageGateway.add_upload_buffer/3","type":"function","doc":"Configures one or more gateway local disks as upload buffer for a specified gateway. This operation is supported for the stored volume, cached volume and tape gateway types. In the request, you specify the gateway Amazon Resource Name (ARN) to which you want to add upload buffer, and one or more disk IDs that you want to configure as upload buffer."},{"ref":"AWS.StorageGateway.html#add_working_storage/3","title":"AWS.StorageGateway.add_working_storage/3","type":"function","doc":"Configures one or more gateway local disks as working storage for a gateway. This operation is only supported in the stored volume gateway type. This operation is deprecated in cached volume API version 20120630. Use AddUploadBuffer instead. Working storage is also referred to as upload buffer. You can also use the AddUploadBuffer operation to add upload buffer to a stored volume gateway. In the request, you specify the gateway Amazon Resource Name (ARN) to which you want to add working storage, and one or more disk IDs that you want to configure as working storage."},{"ref":"AWS.StorageGateway.html#assign_tape_pool/3","title":"AWS.StorageGateway.assign_tape_pool/3","type":"function","doc":"Assigns a tape to a tape pool for archiving. The tape assigned to a pool is archived in the S3 storage class that is associated with the pool. When you use your backup application to eject the tape, the tape is archived directly into the S3 storage class (S3 Glacier or S3 Glacier Deep Archive) that corresponds to the pool. Valid Values: GLACIER | DEEP_ARCHIVE"},{"ref":"AWS.StorageGateway.html#attach_volume/3","title":"AWS.StorageGateway.attach_volume/3","type":"function","doc":"Connects a volume to an iSCSI connection and then attaches the volume to the specified gateway. Detaching and attaching a volume enables you to recover your data from one gateway to a different gateway without creating a snapshot. It also makes it easier to move your volumes from an on-premises gateway to a gateway hosted on an Amazon EC2 instance."},{"ref":"AWS.StorageGateway.html#cancel_archival/3","title":"AWS.StorageGateway.cancel_archival/3","type":"function","doc":"Cancels archiving of a virtual tape to the virtual tape shelf (VTS) after the archiving process is initiated. This operation is only supported in the tape gateway type."},{"ref":"AWS.StorageGateway.html#cancel_retrieval/3","title":"AWS.StorageGateway.cancel_retrieval/3","type":"function","doc":"Cancels retrieval of a virtual tape from the virtual tape shelf (VTS) to a gateway after the retrieval process is initiated. The virtual tape is returned to the VTS. This operation is only supported in the tape gateway type."},{"ref":"AWS.StorageGateway.html#create_cached_iscsi_volume/3","title":"AWS.StorageGateway.create_cached_iscsi_volume/3","type":"function","doc":"Creates a cached volume on a specified cached volume gateway. This operation is only supported in the cached volume gateway type. Cache storage must be allocated to the gateway before you can create a cached volume. Use the AddCache operation to add cache storage to a gateway. In the request, you must specify the gateway, size of the volume in bytes, the iSCSI target name, an IP address on which to expose the target, and a unique client token. In response, the gateway creates the volume and returns information about it. This information includes the volume Amazon Resource Name (ARN), its size, and the iSCSI target ARN that initiators can use to connect to the volume target. Optionally, you can provide the ARN for an existing volume as the SourceVolumeARN for this cached volume, which creates an exact copy of the existing volumes latest recovery point. The VolumeSizeInBytes value must be equal to or larger than the size of the copied volume, in bytes."},{"ref":"AWS.StorageGateway.html#create_nfs_file_share/3","title":"AWS.StorageGateway.create_nfs_file_share/3","type":"function","doc":"Creates a Network File System (NFS) file share on an existing file gateway. In Storage Gateway, a file share is a file system mount point backed by Amazon S3 cloud storage. Storage Gateway exposes file shares using an NFS interface. This operation is only supported for file gateways. File gateway requires AWS Security Token Service (AWS STS) to be activated to enable you to create a file share. Make sure AWS STS is activated in the AWS Region you are creating your file gateway in. If AWS STS is not activated in the AWS Region, activate it. For information about how to activate AWS STS, see Activating and deactivating AWS STS in an AWS Region in the AWS Identity and Access Management User Guide. File gateway does not support creating hard or symbolic links on a file share."},{"ref":"AWS.StorageGateway.html#create_s_m_b_file_share/3","title":"AWS.StorageGateway.create_s_m_b_file_share/3","type":"function","doc":"Creates a Server Message Block (SMB) file share on an existing file gateway. In Storage Gateway, a file share is a file system mount point backed by Amazon S3 cloud storage. Storage Gateway exposes file shares using an SMB interface. This operation is only supported for file gateways. File gateways require AWS Security Token Service (AWS STS) to be activated to enable you to create a file share. Make sure that AWS STS is activated in the AWS Region you are creating your file gateway in. If AWS STS is not activated in this AWS Region, activate it. For information about how to activate AWS STS, see Activating and deactivating AWS STS in an AWS Region in the AWS Identity and Access Management User Guide. File gateways don&#39;t support creating hard or symbolic links on a file share."},{"ref":"AWS.StorageGateway.html#create_snapshot/3","title":"AWS.StorageGateway.create_snapshot/3","type":"function","doc":"Initiates a snapshot of a volume. AWS Storage Gateway provides the ability to back up point-in-time snapshots of your data to Amazon Simple Storage (Amazon S3) for durable off-site recovery, as well as import the data to an Amazon Elastic Block Store (EBS) volume in Amazon Elastic Compute Cloud (EC2). You can take snapshots of your gateway volume on a scheduled or ad hoc basis. This API enables you to take an ad hoc snapshot. For more information, see Editing a snapshot schedule. In the CreateSnapshot request, you identify the volume by providing its Amazon Resource Name (ARN). You must also provide description for the snapshot. When AWS Storage Gateway takes the snapshot of specified volume, the snapshot and description appears in the AWS Storage Gateway console. In response, AWS Storage Gateway returns you a snapshot ID. You can use this snapshot ID to check the snapshot progress or later use it when you want to create a volume from a snapshot. This operation is only supported in stored and cached volume gateway type. To list or delete a snapshot, you must use the Amazon EC2 API. For more information, see DescribeSnapshots or DeleteSnapshot in the Amazon Elastic Compute Cloud API Reference. Volume and snapshot IDs are changing to a longer length ID format. For more information, see the important note on the Welcome page."},{"ref":"AWS.StorageGateway.html#create_snapshot_from_volume_recovery_point/3","title":"AWS.StorageGateway.create_snapshot_from_volume_recovery_point/3","type":"function","doc":"Initiates a snapshot of a gateway from a volume recovery point. This operation is only supported in the cached volume gateway type. A volume recovery point is a point in time at which all data of the volume is consistent and from which you can create a snapshot. To get a list of volume recovery point for cached volume gateway, use ListVolumeRecoveryPoints. In the CreateSnapshotFromVolumeRecoveryPoint request, you identify the volume by providing its Amazon Resource Name (ARN). You must also provide a description for the snapshot. When the gateway takes a snapshot of the specified volume, the snapshot and its description appear in the AWS Storage Gateway console. In response, the gateway returns you a snapshot ID. You can use this snapshot ID to check the snapshot progress or later use it when you want to create a volume from a snapshot. To list or delete a snapshot, you must use the Amazon EC2 API. For more information, see DescribeSnapshots or DeleteSnapshot in the Amazon Elastic Compute Cloud API Reference."},{"ref":"AWS.StorageGateway.html#create_stored_iscsi_volume/3","title":"AWS.StorageGateway.create_stored_iscsi_volume/3","type":"function","doc":"Creates a volume on a specified gateway. This operation is only supported in the stored volume gateway type. The size of the volume to create is inferred from the disk size. You can choose to preserve existing data on the disk, create volume from an existing snapshot, or create an empty volume. If you choose to create an empty gateway volume, then any existing data on the disk is erased. In the request, you must specify the gateway and the disk information on which you are creating the volume. In response, the gateway creates the volume and returns volume information such as the volume Amazon Resource Name (ARN), its size, and the iSCSI target ARN that initiators can use to connect to the volume target."},{"ref":"AWS.StorageGateway.html#create_tape_pool/3","title":"AWS.StorageGateway.create_tape_pool/3","type":"function","doc":"Creates a new custom tape pool. You can use custom tape pool to enable tape retention lock on tapes that are archived in the custom pool."},{"ref":"AWS.StorageGateway.html#create_tape_with_barcode/3","title":"AWS.StorageGateway.create_tape_with_barcode/3","type":"function","doc":"Creates a virtual tape by using your own barcode. You write data to the virtual tape and then archive the tape. A barcode is unique and cannot be reused if it has already been used on a tape. This applies to barcodes used on deleted tapes. This operation is only supported in the tape gateway type. Cache storage must be allocated to the gateway before you can create a virtual tape. Use the AddCache operation to add cache storage to a gateway."},{"ref":"AWS.StorageGateway.html#create_tapes/3","title":"AWS.StorageGateway.create_tapes/3","type":"function","doc":"Creates one or more virtual tapes. You write data to the virtual tapes and then archive the tapes. This operation is only supported in the tape gateway type. Cache storage must be allocated to the gateway before you can create virtual tapes. Use the AddCache operation to add cache storage to a gateway."},{"ref":"AWS.StorageGateway.html#delete_automatic_tape_creation_policy/3","title":"AWS.StorageGateway.delete_automatic_tape_creation_policy/3","type":"function","doc":"Deletes the automatic tape creation policy of a gateway. If you delete this policy, new virtual tapes must be created manually. Use the Amazon Resource Name (ARN) of the gateway in your request to remove the policy."},{"ref":"AWS.StorageGateway.html#delete_bandwidth_rate_limit/3","title":"AWS.StorageGateway.delete_bandwidth_rate_limit/3","type":"function","doc":"Deletes the bandwidth rate limits of a gateway. You can delete either the upload and download bandwidth rate limit, or you can delete both. If you delete only one of the limits, the other limit remains unchanged. To specify which gateway to work with, use the Amazon Resource Name (ARN) of the gateway in your request. This operation is supported for the stored volume, cached volume and tape gateway types."},{"ref":"AWS.StorageGateway.html#delete_chap_credentials/3","title":"AWS.StorageGateway.delete_chap_credentials/3","type":"function","doc":"Deletes Challenge-Handshake Authentication Protocol (CHAP) credentials for a specified iSCSI target and initiator pair. This operation is supported in volume and tape gateway types."},{"ref":"AWS.StorageGateway.html#delete_file_share/3","title":"AWS.StorageGateway.delete_file_share/3","type":"function","doc":"Deletes a file share from a file gateway. This operation is only supported for file gateways."},{"ref":"AWS.StorageGateway.html#delete_gateway/3","title":"AWS.StorageGateway.delete_gateway/3","type":"function","doc":"Deletes a gateway. To specify which gateway to delete, use the Amazon Resource Name (ARN) of the gateway in your request. The operation deletes the gateway; however, it does not delete the gateway virtual machine (VM) from your host computer. After you delete a gateway, you cannot reactivate it. Completed snapshots of the gateway volumes are not deleted upon deleting the gateway, however, pending snapshots will not complete. After you delete a gateway, your next step is to remove it from your environment. You no longer pay software charges after the gateway is deleted; however, your existing Amazon EBS snapshots persist and you will continue to be billed for these snapshots.You can choose to remove all remaining Amazon EBS snapshots by canceling your Amazon EC2 subscription. If you prefer not to cancel your Amazon EC2 subscription, you can delete your snapshots using the Amazon EC2 console. For more information, see the AWS Storage Gateway detail page."},{"ref":"AWS.StorageGateway.html#delete_snapshot_schedule/3","title":"AWS.StorageGateway.delete_snapshot_schedule/3","type":"function","doc":"Deletes a snapshot of a volume. You can take snapshots of your gateway volumes on a scheduled or ad hoc basis. This API action enables you to delete a snapshot schedule for a volume. For more information, see Backing up your volumes. In the DeleteSnapshotSchedule request, you identify the volume by providing its Amazon Resource Name (ARN). This operation is only supported in stored and cached volume gateway types. To list or delete a snapshot, you must use the Amazon EC2 API. For more information, go to DescribeSnapshots in the Amazon Elastic Compute Cloud API Reference."},{"ref":"AWS.StorageGateway.html#delete_tape/3","title":"AWS.StorageGateway.delete_tape/3","type":"function","doc":"Deletes the specified virtual tape. This operation is only supported in the tape gateway type."},{"ref":"AWS.StorageGateway.html#delete_tape_archive/3","title":"AWS.StorageGateway.delete_tape_archive/3","type":"function","doc":"Deletes the specified virtual tape from the virtual tape shelf (VTS). This operation is only supported in the tape gateway type."},{"ref":"AWS.StorageGateway.html#delete_tape_pool/3","title":"AWS.StorageGateway.delete_tape_pool/3","type":"function","doc":"Delete a custom tape pool. A custom tape pool can only be deleted if there are no tapes in the pool and if there are no automatic tape creation policies that reference the custom tape pool."},{"ref":"AWS.StorageGateway.html#delete_volume/3","title":"AWS.StorageGateway.delete_volume/3","type":"function","doc":"Deletes the specified storage volume that you previously created using the CreateCachediSCSIVolume or CreateStorediSCSIVolume API. This operation is only supported in the cached volume and stored volume types. For stored volume gateways, the local disk that was configured as the storage volume is not deleted. You can reuse the local disk to create another storage volume. Before you delete a volume, make sure there are no iSCSI connections to the volume you are deleting. You should also make sure there is no snapshot in progress. You can use the Amazon Elastic Compute Cloud (Amazon EC2) API to query snapshots on the volume you are deleting and check the snapshot status. For more information, go to DescribeSnapshots in the Amazon Elastic Compute Cloud API Reference. In the request, you must provide the Amazon Resource Name (ARN) of the storage volume you want to delete."},{"ref":"AWS.StorageGateway.html#describe_availability_monitor_test/3","title":"AWS.StorageGateway.describe_availability_monitor_test/3","type":"function","doc":"Returns information about the most recent High Availability monitoring test that was performed on the host in a cluster. If a test isn&#39;t performed, the status and start time in the response would be null."},{"ref":"AWS.StorageGateway.html#describe_bandwidth_rate_limit/3","title":"AWS.StorageGateway.describe_bandwidth_rate_limit/3","type":"function","doc":"Returns the bandwidth rate limits of a gateway. By default, these limits are not set, which means no bandwidth rate limiting is in effect. This operation is supported for the stored volume, cached volume, and tape gateway types. This operation only returns a value for a bandwidth rate limit only if the limit is set. If no limits are set for the gateway, then this operation returns only the gateway ARN in the response body. To specify which gateway to describe, use the Amazon Resource Name (ARN) of the gateway in your request."},{"ref":"AWS.StorageGateway.html#describe_cache/3","title":"AWS.StorageGateway.describe_cache/3","type":"function","doc":"Returns information about the cache of a gateway. This operation is only supported in the cached volume, tape, and file gateway types. The response includes disk IDs that are configured as cache, and it includes the amount of cache allocated and used."},{"ref":"AWS.StorageGateway.html#describe_cached_iscsi_volumes/3","title":"AWS.StorageGateway.describe_cached_iscsi_volumes/3","type":"function","doc":"Returns a description of the gateway volumes specified in the request. This operation is only supported in the cached volume gateway types. The list of gateway volumes in the request must be from one gateway. In the response, AWS Storage Gateway returns volume information sorted by volume Amazon Resource Name (ARN)."},{"ref":"AWS.StorageGateway.html#describe_chap_credentials/3","title":"AWS.StorageGateway.describe_chap_credentials/3","type":"function","doc":"Returns an array of Challenge-Handshake Authentication Protocol (CHAP) credentials information for a specified iSCSI target, one for each target-initiator pair. This operation is supported in the volume and tape gateway types."},{"ref":"AWS.StorageGateway.html#describe_gateway_information/3","title":"AWS.StorageGateway.describe_gateway_information/3","type":"function","doc":"Returns metadata about a gateway such as its name, network interfaces, configured time zone, and the state (whether the gateway is running or not). To specify which gateway to describe, use the Amazon Resource Name (ARN) of the gateway in your request."},{"ref":"AWS.StorageGateway.html#describe_maintenance_start_time/3","title":"AWS.StorageGateway.describe_maintenance_start_time/3","type":"function","doc":"Returns your gateway&#39;s weekly maintenance start time including the day and time of the week. Note that values are in terms of the gateway&#39;s time zone."},{"ref":"AWS.StorageGateway.html#describe_nfs_file_shares/3","title":"AWS.StorageGateway.describe_nfs_file_shares/3","type":"function","doc":"Gets a description for one or more Network File System (NFS) file shares from a file gateway. This operation is only supported for file gateways."},{"ref":"AWS.StorageGateway.html#describe_s_m_b_file_shares/3","title":"AWS.StorageGateway.describe_s_m_b_file_shares/3","type":"function","doc":"Gets a description for one or more Server Message Block (SMB) file shares from a file gateway. This operation is only supported for file gateways."},{"ref":"AWS.StorageGateway.html#describe_s_m_b_settings/3","title":"AWS.StorageGateway.describe_s_m_b_settings/3","type":"function","doc":"Gets a description of a Server Message Block (SMB) file share settings from a file gateway. This operation is only supported for file gateways."},{"ref":"AWS.StorageGateway.html#describe_snapshot_schedule/3","title":"AWS.StorageGateway.describe_snapshot_schedule/3","type":"function","doc":"Describes the snapshot schedule for the specified gateway volume. The snapshot schedule information includes intervals at which snapshots are automatically initiated on the volume. This operation is only supported in the cached volume and stored volume types."},{"ref":"AWS.StorageGateway.html#describe_stored_iscsi_volumes/3","title":"AWS.StorageGateway.describe_stored_iscsi_volumes/3","type":"function","doc":"Returns the description of the gateway volumes specified in the request. The list of gateway volumes in the request must be from one gateway. In the response, AWS Storage Gateway returns volume information sorted by volume ARNs. This operation is only supported in stored volume gateway type."},{"ref":"AWS.StorageGateway.html#describe_tape_archives/3","title":"AWS.StorageGateway.describe_tape_archives/3","type":"function","doc":"Returns a description of specified virtual tapes in the virtual tape shelf (VTS). This operation is only supported in the tape gateway type. If a specific TapeARN is not specified, AWS Storage Gateway returns a description of all virtual tapes found in the VTS associated with your account."},{"ref":"AWS.StorageGateway.html#describe_tape_recovery_points/3","title":"AWS.StorageGateway.describe_tape_recovery_points/3","type":"function","doc":"Returns a list of virtual tape recovery points that are available for the specified tape gateway. A recovery point is a point-in-time view of a virtual tape at which all the data on the virtual tape is consistent. If your gateway crashes, virtual tapes that have recovery points can be recovered to a new gateway. This operation is only supported in the tape gateway type."},{"ref":"AWS.StorageGateway.html#describe_tapes/3","title":"AWS.StorageGateway.describe_tapes/3","type":"function","doc":"Returns a description of the specified Amazon Resource Name (ARN) of virtual tapes. If a TapeARN is not specified, returns a description of all virtual tapes associated with the specified gateway. This operation is only supported in the tape gateway type."},{"ref":"AWS.StorageGateway.html#describe_upload_buffer/3","title":"AWS.StorageGateway.describe_upload_buffer/3","type":"function","doc":"Returns information about the upload buffer of a gateway. This operation is supported for the stored volume, cached volume, and tape gateway types. The response includes disk IDs that are configured as upload buffer space, and it includes the amount of upload buffer space allocated and used."},{"ref":"AWS.StorageGateway.html#describe_vtl_devices/3","title":"AWS.StorageGateway.describe_vtl_devices/3","type":"function","doc":"Returns a description of virtual tape library (VTL) devices for the specified tape gateway. In the response, AWS Storage Gateway returns VTL device information. This operation is only supported in the tape gateway type."},{"ref":"AWS.StorageGateway.html#describe_working_storage/3","title":"AWS.StorageGateway.describe_working_storage/3","type":"function","doc":"Returns information about the working storage of a gateway. This operation is only supported in the stored volumes gateway type. This operation is deprecated in cached volumes API version (20120630). Use DescribeUploadBuffer instead. Working storage is also referred to as upload buffer. You can also use the DescribeUploadBuffer operation to add upload buffer to a stored volume gateway. The response includes disk IDs that are configured as working storage, and it includes the amount of working storage allocated and used."},{"ref":"AWS.StorageGateway.html#detach_volume/3","title":"AWS.StorageGateway.detach_volume/3","type":"function","doc":"Disconnects a volume from an iSCSI connection and then detaches the volume from the specified gateway. Detaching and attaching a volume enables you to recover your data from one gateway to a different gateway without creating a snapshot. It also makes it easier to move your volumes from an on-premises gateway to a gateway hosted on an Amazon EC2 instance. This operation is only supported in the volume gateway type."},{"ref":"AWS.StorageGateway.html#disable_gateway/3","title":"AWS.StorageGateway.disable_gateway/3","type":"function","doc":"Disables a tape gateway when the gateway is no longer functioning. For example, if your gateway VM is damaged, you can disable the gateway so you can recover virtual tapes. Use this operation for a tape gateway that is not reachable or not functioning. This operation is only supported in the tape gateway type. After a gateway is disabled, it cannot be enabled."},{"ref":"AWS.StorageGateway.html#join_domain/3","title":"AWS.StorageGateway.join_domain/3","type":"function","doc":"Adds a file gateway to an Active Directory domain. This operation is only supported for file gateways that support the SMB file protocol."},{"ref":"AWS.StorageGateway.html#list_automatic_tape_creation_policies/3","title":"AWS.StorageGateway.list_automatic_tape_creation_policies/3","type":"function","doc":"Lists the automatic tape creation policies for a gateway. If there are no automatic tape creation policies for the gateway, it returns an empty list. This operation is only supported for tape gateways."},{"ref":"AWS.StorageGateway.html#list_file_shares/3","title":"AWS.StorageGateway.list_file_shares/3","type":"function","doc":"Gets a list of the file shares for a specific file gateway, or the list of file shares that belong to the calling user account. This operation is only supported for file gateways."},{"ref":"AWS.StorageGateway.html#list_gateways/3","title":"AWS.StorageGateway.list_gateways/3","type":"function","doc":"Lists gateways owned by an AWS account in an AWS Region specified in the request. The returned list is ordered by gateway Amazon Resource Name (ARN). By default, the operation returns a maximum of 100 gateways. This operation supports pagination that allows you to optionally reduce the number of gateways returned in a response. If you have more gateways than are returned in a response (that is, the response returns only a truncated list of your gateways), the response contains a marker that you can specify in your next request to fetch the next page of gateways."},{"ref":"AWS.StorageGateway.html#list_local_disks/3","title":"AWS.StorageGateway.list_local_disks/3","type":"function","doc":"Returns a list of the gateway&#39;s local disks. To specify which gateway to describe, you use the Amazon Resource Name (ARN) of the gateway in the body of the request. The request returns a list of all disks, specifying which are configured as working storage, cache storage, or stored volume or not configured at all. The response includes a DiskStatus field. This field can have a value of present (the disk is available to use), missing (the disk is no longer connected to the gateway), or mismatch (the disk node is occupied by a disk that has incorrect metadata or the disk content is corrupted)."},{"ref":"AWS.StorageGateway.html#list_tags_for_resource/3","title":"AWS.StorageGateway.list_tags_for_resource/3","type":"function","doc":"Lists the tags that have been added to the specified resource. This operation is supported in storage gateways of all types."},{"ref":"AWS.StorageGateway.html#list_tape_pools/3","title":"AWS.StorageGateway.list_tape_pools/3","type":"function","doc":"Lists custom tape pools. You specify custom tape pools to list by specifying one or more custom tape pool Amazon Resource Names (ARNs). If you don&#39;t specify a custom tape pool ARN, the operation lists all custom tape pools. This operation supports pagination. You can optionally specify the Limit parameter in the body to limit the number of tape pools in the response. If the number of tape pools returned in the response is truncated, the response includes a Marker element that you can use in your subsequent request to retrieve the next set of tape pools."},{"ref":"AWS.StorageGateway.html#list_tapes/3","title":"AWS.StorageGateway.list_tapes/3","type":"function","doc":"Lists virtual tapes in your virtual tape library (VTL) and your virtual tape shelf (VTS). You specify the tapes to list by specifying one or more tape Amazon Resource Names (ARNs). If you don&#39;t specify a tape ARN, the operation lists all virtual tapes in both your VTL and VTS. This operation supports pagination. By default, the operation returns a maximum of up to 100 tapes. You can optionally specify the Limit parameter in the body to limit the number of tapes in the response. If the number of tapes returned in the response is truncated, the response includes a Marker element that you can use in your subsequent request to retrieve the next set of tapes. This operation is only supported in the tape gateway type."},{"ref":"AWS.StorageGateway.html#list_volume_initiators/3","title":"AWS.StorageGateway.list_volume_initiators/3","type":"function","doc":"Lists iSCSI initiators that are connected to a volume. You can use this operation to determine whether a volume is being used or not. This operation is only supported in the cached volume and stored volume gateway types."},{"ref":"AWS.StorageGateway.html#list_volume_recovery_points/3","title":"AWS.StorageGateway.list_volume_recovery_points/3","type":"function","doc":"Lists the recovery points for a specified gateway. This operation is only supported in the cached volume gateway type. Each cache volume has one recovery point. A volume recovery point is a point in time at which all data of the volume is consistent and from which you can create a snapshot or clone a new cached volume from a source volume. To create a snapshot from a volume recovery point use the CreateSnapshotFromVolumeRecoveryPoint operation."},{"ref":"AWS.StorageGateway.html#list_volumes/3","title":"AWS.StorageGateway.list_volumes/3","type":"function","doc":"Lists the iSCSI stored volumes of a gateway. Results are sorted by volume ARN. The response includes only the volume ARNs. If you want additional volume information, use the DescribeStorediSCSIVolumes or the DescribeCachediSCSIVolumes API. The operation supports pagination. By default, the operation returns a maximum of up to 100 volumes. You can optionally specify the Limit field in the body to limit the number of volumes in the response. If the number of volumes returned in the response is truncated, the response includes a Marker field. You can use this Marker value in your subsequent request to retrieve the next set of volumes. This operation is only supported in the cached volume and stored volume gateway types."},{"ref":"AWS.StorageGateway.html#notify_when_uploaded/3","title":"AWS.StorageGateway.notify_when_uploaded/3","type":"function","doc":"Sends you notification through CloudWatch Events when all files written to your file share have been uploaded to Amazon S3. AWS Storage Gateway can send a notification through Amazon CloudWatch Events when all files written to your file share up to that point in time have been uploaded to Amazon S3. These files include files written to the file share up to the time that you make a request for notification. When the upload is done, Storage Gateway sends you notification through an Amazon CloudWatch Event. You can configure CloudWatch Events to send the notification through event targets such as Amazon SNS or AWS Lambda function. This operation is only supported for file gateways. For more information, see Getting file upload notification in the AWS Storage Gateway User Guide."},{"ref":"AWS.StorageGateway.html#refresh_cache/3","title":"AWS.StorageGateway.refresh_cache/3","type":"function","doc":"Refreshes the cache for the specified file share. This operation finds objects in the Amazon S3 bucket that were added, removed, or replaced since the gateway last listed the bucket&#39;s contents and cached the results. This operation is only supported in the file gateway type. You can subscribe to be notified through an Amazon CloudWatch event when your RefreshCache operation completes. For more information, see Getting notified about file operations in the AWS Storage Gateway User Guide. When this API is called, it only initiates the refresh operation. When the API call completes and returns a success code, it doesn&#39;t necessarily mean that the file refresh has completed. You should use the refresh-complete notification to determine that the operation has completed before you check for new files on the gateway file share. You can subscribe to be notified through an CloudWatch event when your RefreshCache operation completes. Throttle limit: This API is asynchronous so the gateway will accept no more than two refreshes at any time. We recommend using the refresh-complete CloudWatch event notification before issuing additional requests. For more information, see Getting notified about file operations in the AWS Storage Gateway User Guide. If you invoke the RefreshCache API when two requests are already being processed, any new request will cause an InvalidGatewayRequestException error because too many requests were sent to the server. For more information, see Getting notified about file operations in the AWS Storage Gateway User Guide."},{"ref":"AWS.StorageGateway.html#remove_tags_from_resource/3","title":"AWS.StorageGateway.remove_tags_from_resource/3","type":"function","doc":"Removes one or more tags from the specified resource. This operation is supported in storage gateways of all types."},{"ref":"AWS.StorageGateway.html#reset_cache/3","title":"AWS.StorageGateway.reset_cache/3","type":"function","doc":"Resets all cache disks that have encountered an error and makes the disks available for reconfiguration as cache storage. If your cache disk encounters an error, the gateway prevents read and write operations on virtual tapes in the gateway. For example, an error can occur when a disk is corrupted or removed from the gateway. When a cache is reset, the gateway loses its cache storage. At this point, you can reconfigure the disks as cache disks. This operation is only supported in the cached volume and tape types. If the cache disk you are resetting contains data that has not been uploaded to Amazon S3 yet, that data can be lost. After you reset cache disks, there will be no configured cache disks left in the gateway, so you must configure at least one new cache disk for your gateway to function properly."},{"ref":"AWS.StorageGateway.html#retrieve_tape_archive/3","title":"AWS.StorageGateway.retrieve_tape_archive/3","type":"function","doc":"Retrieves an archived virtual tape from the virtual tape shelf (VTS) to a tape gateway. Virtual tapes archived in the VTS are not associated with any gateway. However after a tape is retrieved, it is associated with a gateway, even though it is also listed in the VTS, that is, archive. This operation is only supported in the tape gateway type. Once a tape is successfully retrieved to a gateway, it cannot be retrieved again to another gateway. You must archive the tape again before you can retrieve it to another gateway. This operation is only supported in the tape gateway type."},{"ref":"AWS.StorageGateway.html#retrieve_tape_recovery_point/3","title":"AWS.StorageGateway.retrieve_tape_recovery_point/3","type":"function","doc":"Retrieves the recovery point for the specified virtual tape. This operation is only supported in the tape gateway type. A recovery point is a point in time view of a virtual tape at which all the data on the tape is consistent. If your gateway crashes, virtual tapes that have recovery points can be recovered to a new gateway. The virtual tape can be retrieved to only one gateway. The retrieved tape is read-only. The virtual tape can be retrieved to only a tape gateway. There is no charge for retrieving recovery points."},{"ref":"AWS.StorageGateway.html#set_local_console_password/3","title":"AWS.StorageGateway.set_local_console_password/3","type":"function","doc":"Sets the password for your VM local console. When you log in to the local console for the first time, you log in to the VM with the default credentials. We recommend that you set a new password. You don&#39;t need to know the default password to set a new password."},{"ref":"AWS.StorageGateway.html#set_s_m_b_guest_password/3","title":"AWS.StorageGateway.set_s_m_b_guest_password/3","type":"function","doc":"Sets the password for the guest user smbguest. The smbguest user is the user when the authentication method for the file share is set to GuestAccess."},{"ref":"AWS.StorageGateway.html#shutdown_gateway/3","title":"AWS.StorageGateway.shutdown_gateway/3","type":"function","doc":"Shuts down a gateway. To specify which gateway to shut down, use the Amazon Resource Name (ARN) of the gateway in the body of your request. The operation shuts down the gateway service component running in the gateway&#39;s virtual machine (VM) and not the host VM. If you want to shut down the VM, it is recommended that you first shut down the gateway component in the VM to avoid unpredictable conditions. After the gateway is shutdown, you cannot call any other API except StartGateway, DescribeGatewayInformation, and ListGateways. For more information, see ActivateGateway. Your applications cannot read from or write to the gateway&#39;s storage volumes, and there are no snapshots taken. When you make a shutdown request, you will get a 200 OK success response immediately. However, it might take some time for the gateway to shut down. You can call the DescribeGatewayInformation API to check the status. For more information, see ActivateGateway. If do not intend to use the gateway again, you must delete the gateway (using DeleteGateway) to no longer pay software charges associated with the gateway."},{"ref":"AWS.StorageGateway.html#start_availability_monitor_test/3","title":"AWS.StorageGateway.start_availability_monitor_test/3","type":"function","doc":"Start a test that verifies that the specified gateway is configured for High Availability monitoring in your host environment. This request only initiates the test and that a successful response only indicates that the test was started. It doesn&#39;t indicate that the test passed. For the status of the test, invoke the DescribeAvailabilityMonitorTest API. Starting this test will cause your gateway to go offline for a brief period."},{"ref":"AWS.StorageGateway.html#start_gateway/3","title":"AWS.StorageGateway.start_gateway/3","type":"function","doc":"Starts a gateway that you previously shut down (see ShutdownGateway). After the gateway starts, you can then make other API calls, your applications can read from or write to the gateway&#39;s storage volumes and you will be able to take snapshot backups. When you make a request, you will get a 200 OK success response immediately. However, it might take some time for the gateway to be ready. You should call DescribeGatewayInformation and check the status before making any additional API calls. For more information, see ActivateGateway. To specify which gateway to start, use the Amazon Resource Name (ARN) of the gateway in your request."},{"ref":"AWS.StorageGateway.html#update_automatic_tape_creation_policy/3","title":"AWS.StorageGateway.update_automatic_tape_creation_policy/3","type":"function","doc":"Updates the automatic tape creation policy of a gateway. Use this to update the policy with a new set of automatic tape creation rules. This is only supported for tape gateways. By default, there is no automatic tape creation policy. A gateway can have only one automatic tape creation policy."},{"ref":"AWS.StorageGateway.html#update_bandwidth_rate_limit/3","title":"AWS.StorageGateway.update_bandwidth_rate_limit/3","type":"function","doc":"Updates the bandwidth rate limits of a gateway. You can update both the upload and download bandwidth rate limit or specify only one of the two. If you don&#39;t set a bandwidth rate limit, the existing rate limit remains. This operation is supported for the stored volume, cached volume, and tape gateway types. By default, a gateway&#39;s bandwidth rate limits are not set. If you don&#39;t set any limit, the gateway does not have any limitations on its bandwidth usage and could potentially use the maximum available bandwidth. To specify which gateway to update, use the Amazon Resource Name (ARN) of the gateway in your request."},{"ref":"AWS.StorageGateway.html#update_chap_credentials/3","title":"AWS.StorageGateway.update_chap_credentials/3","type":"function","doc":"Updates the Challenge-Handshake Authentication Protocol (CHAP) credentials for a specified iSCSI target. By default, a gateway does not have CHAP enabled; however, for added security, you might use it. This operation is supported in the volume and tape gateway types. When you update CHAP credentials, all existing connections on the target are closed and initiators must reconnect with the new credentials."},{"ref":"AWS.StorageGateway.html#update_gateway_information/3","title":"AWS.StorageGateway.update_gateway_information/3","type":"function","doc":"Updates a gateway&#39;s metadata, which includes the gateway&#39;s name and time zone. To specify which gateway to update, use the Amazon Resource Name (ARN) of the gateway in your request. For gateways activated after September 2, 2015, the gateway&#39;s ARN contains the gateway ID rather than the gateway name. However, changing the name of the gateway has no effect on the gateway&#39;s ARN."},{"ref":"AWS.StorageGateway.html#update_gateway_software_now/3","title":"AWS.StorageGateway.update_gateway_software_now/3","type":"function","doc":"Updates the gateway virtual machine (VM) software. The request immediately triggers the software update. When you make this request, you get a 200 OK success response immediately. However, it might take some time for the update to complete. You can call DescribeGatewayInformation to verify the gateway is in the STATE_RUNNING state. A software update forces a system restart of your gateway. You can minimize the chance of any disruption to your applications by increasing your iSCSI Initiators&#39; timeouts. For more information about increasing iSCSI Initiator timeouts for Windows and Linux, see Customizing your Windows iSCSI settings and Customizing your Linux iSCSI settings, respectively."},{"ref":"AWS.StorageGateway.html#update_maintenance_start_time/3","title":"AWS.StorageGateway.update_maintenance_start_time/3","type":"function","doc":"Updates a gateway&#39;s weekly maintenance start time information, including day and time of the week. The maintenance time is the time in your gateway&#39;s time zone."},{"ref":"AWS.StorageGateway.html#update_nfs_file_share/3","title":"AWS.StorageGateway.update_nfs_file_share/3","type":"function","doc":"Updates a Network File System (NFS) file share. This operation is only supported in the file gateway type. To leave a file share field unchanged, set the corresponding input field to null. Updates the following file share setting: Default storage class for your S3 bucket Metadata defaults for your S3 bucket Allowed NFS clients for your file share Squash settings Write status of your file share To leave a file share field unchanged, set the corresponding input field to null. This operation is only supported in file gateways."},{"ref":"AWS.StorageGateway.html#update_s_m_b_file_share/3","title":"AWS.StorageGateway.update_s_m_b_file_share/3","type":"function","doc":"Updates a Server Message Block (SMB) file share. To leave a file share field unchanged, set the corresponding input field to null. This operation is only supported for file gateways. File gateways require AWS Security Token Service (AWS STS) to be activated to enable you to create a file share. Make sure that AWS STS is activated in the AWS Region you are creating your file gateway in. If AWS STS is not activated in this AWS Region, activate it. For information about how to activate AWS STS, see Activating and deactivating AWS STS in an AWS Region in the AWS Identity and Access Management User Guide. File gateways don&#39;t support creating hard or symbolic links on a file share."},{"ref":"AWS.StorageGateway.html#update_s_m_b_security_strategy/3","title":"AWS.StorageGateway.update_s_m_b_security_strategy/3","type":"function","doc":"Updates the SMB security strategy on a file gateway. This action is only supported in file gateways. This API is called Security level in the User Guide. A higher security level can affect performance of the gateway."},{"ref":"AWS.StorageGateway.html#update_snapshot_schedule/3","title":"AWS.StorageGateway.update_snapshot_schedule/3","type":"function","doc":"Updates a snapshot schedule configured for a gateway volume. This operation is only supported in the cached volume and stored volume gateway types. The default snapshot schedule for volume is once every 24 hours, starting at the creation time of the volume. You can use this API to change the snapshot schedule configured for the volume. In the request you must identify the gateway volume whose snapshot schedule you want to update, and the schedule information, including when you want the snapshot to begin on a day and the frequency (in hours) of snapshots."},{"ref":"AWS.StorageGateway.html#update_vtl_device_type/3","title":"AWS.StorageGateway.update_vtl_device_type/3","type":"function","doc":"Updates the type of medium changer in a tape gateway. When you activate a tape gateway, you select a medium changer type for the tape gateway. This operation enables you to select a different type of medium changer after a tape gateway is activated. This operation is only supported in the tape gateway type."},{"ref":"AWS.Streams.DynamoDB.html","title":"AWS.Streams.DynamoDB","type":"module","doc":"Amazon DynamoDB Amazon DynamoDB Streams provides API actions for accessing streams and processing stream records. To learn more about application development with Streams, see Capturing Table Activity with DynamoDB Streams in the Amazon DynamoDB Developer Guide."},{"ref":"AWS.Streams.DynamoDB.html#describe_stream/3","title":"AWS.Streams.DynamoDB.describe_stream/3","type":"function","doc":"Returns information about a stream, including the current status of the stream, its Amazon Resource Name (ARN), the composition of its shards, and its corresponding DynamoDB table. You can call `DescribeStream` at a maximum rate of 10 times per second. Each shard in the stream has a `SequenceNumberRange` associatedwith it. If the SequenceNumberRange has a StartingSequenceNumber but no EndingSequenceNumber, then the shard is still open (able to receive more stream records). If both StartingSequenceNumber and EndingSequenceNumber are present, then that shard is closed and can no longer receive more data."},{"ref":"AWS.Streams.DynamoDB.html#get_records/3","title":"AWS.Streams.DynamoDB.get_records/3","type":"function","doc":"Retrieves the stream records from a given shard. Specify a shard iterator using the ShardIterator parameter. The shard iterator specifies the position in the shard from which you want to start reading stream records sequentially. If there are no stream records available in the portion of the shard that the iterator points to, GetRecords returns an empty list. Note that it might take multiple calls to get to a portion of the shard that contains stream records. `GetRecords` can retrieve a maximum of 1 MB of data or 1000 stream records, whichever comes first."},{"ref":"AWS.Streams.DynamoDB.html#get_shard_iterator/3","title":"AWS.Streams.DynamoDB.get_shard_iterator/3","type":"function","doc":"Returns a shard iterator. A shard iterator provides information about how to retrieve the stream records from within a shard. Use the shard iterator in a subsequent GetRecords request to read the stream records from the shard. A shard iterator expires 15 minutes after it is returned to the requester."},{"ref":"AWS.Streams.DynamoDB.html#list_streams/3","title":"AWS.Streams.DynamoDB.list_streams/3","type":"function","doc":"Returns an array of stream ARNs associated with the current account and endpoint. If the TableName parameter is present, then ListStreams will return only the streams ARNs for that table. You can call `ListStreams` at a maximum rate of 5 times per second."},{"ref":"AWS.Support.html","title":"AWS.Support","type":"module","doc":"AWS Support The AWS Support API reference is intended for programmers who need detailed information about the AWS Support operations and data types. This service enables you to manage your AWS Support cases programmatically. It uses HTTP methods that return results in JSON format. You must have a Business or Enterprise support plan to use the AWS Support API. If you call the AWS Support API from an account that does not have a Business or Enterprise support plan, the SubscriptionRequiredException error message appears. For information about changing your support plan, see AWS Support. The AWS Support service also exposes a set of AWS Trusted Advisor features. You can retrieve a list of checks and their descriptions, get check results, specify checks to refresh, and get the refresh status of checks. The following list describes the AWS Support case management operations: Service names, issue categories, and available severity levels. The DescribeServices and DescribeSeverityLevels operations return AWS service names, service codes, service categories, and problem severity levels. You use these values when you call the CreateCase operation. Case creation, case details, and case resolution. The CreateCase, DescribeCases, DescribeAttachment, and ResolveCase operations create AWS Support cases, retrieve information about cases, and resolve cases. Case communication. The DescribeCommunications, AddCommunicationToCase, and AddAttachmentsToSet operations retrieve and add communications and attachments to AWS Support cases. The following list describes the operations available from the AWS Support service for Trusted Advisor: DescribeTrustedAdvisorChecks returns the list of checks that run against your AWS resources. Using the checkId for a specific check returned by DescribeTrustedAdvisorChecks, you can call DescribeTrustedAdvisorCheckResult to obtain the results for the check that you specified. DescribeTrustedAdvisorCheckSummaries returns summarized results for one or more Trusted Advisor checks. RefreshTrustedAdvisorCheck requests that Trusted Advisor rerun a specified check. DescribeTrustedAdvisorCheckRefreshStatuses reports the refresh status of one or more checks. For authentication of requests, AWS Support uses Signature Version 4 Signing Process. See About the AWS Support API in the AWS Support User Guide for information about how to use this service to create and manage your support cases, and how to call Trusted Advisor for results of checks on your resources."},{"ref":"AWS.Support.html#add_attachments_to_set/3","title":"AWS.Support.add_attachments_to_set/3","type":"function","doc":"Adds one or more attachments to an attachment set. An attachment set is a temporary container for attachments that you add to a case or case communication. The set is available for 1 hour after it&#39;s created. The expiryTime returned in the response is when the set expires. You must have a Business or Enterprise support plan to use the AWS Support API. If you call the AWS Support API from an account that does not have a Business or Enterprise support plan, the SubscriptionRequiredException error message appears. For information about changing your support plan, see AWS Support."},{"ref":"AWS.Support.html#add_communication_to_case/3","title":"AWS.Support.add_communication_to_case/3","type":"function","doc":"Adds additional customer communication to an AWS Support case. Use the caseId parameter to identify the case to which to add communication. You can list a set of email addresses to copy on the communication by using the ccEmailAddresses parameter. The communicationBody value contains the text of the communication. You must have a Business or Enterprise support plan to use the AWS Support API. If you call the AWS Support API from an account that does not have a Business or Enterprise support plan, the SubscriptionRequiredException error message appears. For information about changing your support plan, see AWS Support."},{"ref":"AWS.Support.html#create_case/3","title":"AWS.Support.create_case/3","type":"function","doc":"Creates a case in the AWS Support Center. This operation is similar to how you create a case in the AWS Support Center Create Case page. The AWS Support API doesn&#39;t support requesting service limit increases. You can submit a service limit increase in the following ways: Submit a request from the AWS Support Center Create Case page. Use the Service Quotas RequestServiceQuotaIncrease operation. A successful CreateCase request returns an AWS Support case number. You can use the DescribeCases operation and specify the case number to get existing AWS Support cases. After you create a case, use the AddCommunicationToCase operation to add additional communication or attachments to an existing case. The caseId is separate from the displayId that appears in the AWS Support Center. Use the DescribeCases operation to get the displayId. You must have a Business or Enterprise support plan to use the AWS Support API. If you call the AWS Support API from an account that does not have a Business or Enterprise support plan, the SubscriptionRequiredException error message appears. For information about changing your support plan, see AWS Support."},{"ref":"AWS.Support.html#describe_attachment/3","title":"AWS.Support.describe_attachment/3","type":"function","doc":"Returns the attachment that has the specified ID. Attachments can include screenshots, error logs, or other files that describe your issue. Attachment IDs are generated by the case management system when you add an attachment to a case or case communication. Attachment IDs are returned in the AttachmentDetails objects that are returned by the DescribeCommunications operation. You must have a Business or Enterprise support plan to use the AWS Support API. If you call the AWS Support API from an account that does not have a Business or Enterprise support plan, the SubscriptionRequiredException error message appears. For information about changing your support plan, see AWS Support."},{"ref":"AWS.Support.html#describe_cases/3","title":"AWS.Support.describe_cases/3","type":"function","doc":"Returns a list of cases that you specify by passing one or more case IDs. You can use the afterTime and beforeTime parameters to filter the cases by date. You can set values for the includeResolvedCases and includeCommunications parameters to specify how much information to return. The response returns the following in JSON format: One or more CaseDetails data types. One or more nextToken values, which specify where to paginate the returned records represented by the CaseDetails objects. Case data is available for 12 months after creation. If a case was created more than 12 months ago, a request might return an error. You must have a Business or Enterprise support plan to use the AWS Support API. If you call the AWS Support API from an account that does not have a Business or Enterprise support plan, the SubscriptionRequiredException error message appears. For information about changing your support plan, see AWS Support."},{"ref":"AWS.Support.html#describe_communications/3","title":"AWS.Support.describe_communications/3","type":"function","doc":"Returns communications and attachments for one or more support cases. Use the afterTime and beforeTime parameters to filter by date. You can use the caseId parameter to restrict the results to a specific case. Case data is available for 12 months after creation. If a case was created more than 12 months ago, a request for data might cause an error. You can use the maxResults and nextToken parameters to control the pagination of the results. Set maxResults to the number of cases that you want to display on each page, and use nextToken to specify the resumption of pagination. You must have a Business or Enterprise support plan to use the AWS Support API. If you call the AWS Support API from an account that does not have a Business or Enterprise support plan, the SubscriptionRequiredException error message appears. For information about changing your support plan, see AWS Support."},{"ref":"AWS.Support.html#describe_services/3","title":"AWS.Support.describe_services/3","type":"function","doc":"Returns the current list of AWS services and a list of service categories for each service. You then use service names and categories in your CreateCase requests. Each AWS service has its own set of categories. The service codes and category codes correspond to the values that appear in the Service and Category lists on the AWS Support Center Create Case page. The values in those fields don&#39;t necessarily match the service codes and categories returned by the DescribeServices operation. Always use the service codes and categories that the DescribeServices operation returns, so that you have the most recent set of service and category codes. You must have a Business or Enterprise support plan to use the AWS Support API. If you call the AWS Support API from an account that does not have a Business or Enterprise support plan, the SubscriptionRequiredException error message appears. For information about changing your support plan, see AWS Support."},{"ref":"AWS.Support.html#describe_severity_levels/3","title":"AWS.Support.describe_severity_levels/3","type":"function","doc":"Returns the list of severity levels that you can assign to an AWS Support case. The severity level for a case is also a field in the CaseDetails data type that you include for a CreateCase request. You must have a Business or Enterprise support plan to use the AWS Support API. If you call the AWS Support API from an account that does not have a Business or Enterprise support plan, the SubscriptionRequiredException error message appears. For information about changing your support plan, see AWS Support."},{"ref":"AWS.Support.html#describe_trusted_advisor_check_refresh_statuses/3","title":"AWS.Support.describe_trusted_advisor_check_refresh_statuses/3","type":"function","doc":"Returns the refresh status of the AWS Trusted Advisor checks that have the specified check IDs. You can get the check IDs by calling the DescribeTrustedAdvisorChecks operation. Some checks are refreshed automatically, and you can&#39;t return their refresh statuses by using the DescribeTrustedAdvisorCheckRefreshStatuses operation. If you call this operation for these checks, you might see an InvalidParameterValue error. You must have a Business or Enterprise support plan to use the AWS Support API. If you call the AWS Support API from an account that does not have a Business or Enterprise support plan, the SubscriptionRequiredException error message appears. For information about changing your support plan, see AWS Support."},{"ref":"AWS.Support.html#describe_trusted_advisor_check_result/3","title":"AWS.Support.describe_trusted_advisor_check_result/3","type":"function","doc":"Returns the results of the AWS Trusted Advisor check that has the specified check ID. You can get the check IDs by calling the DescribeTrustedAdvisorChecks operation. The response contains a TrustedAdvisorCheckResult object, which contains these three objects: TrustedAdvisorCategorySpecificSummary TrustedAdvisorResourceDetail TrustedAdvisorResourcesSummary In addition, the response contains these fields: status - The alert status of the check: &quot;ok&quot; (green), &quot;warning&quot; (yellow), &quot;error&quot; (red), or &quot;not_available&quot;. timestamp - The time of the last refresh of the check. checkId - The unique identifier for the check. You must have a Business or Enterprise support plan to use the AWS Support API. If you call the AWS Support API from an account that does not have a Business or Enterprise support plan, the SubscriptionRequiredException error message appears. For information about changing your support plan, see AWS Support."},{"ref":"AWS.Support.html#describe_trusted_advisor_check_summaries/3","title":"AWS.Support.describe_trusted_advisor_check_summaries/3","type":"function","doc":"Returns the results for the AWS Trusted Advisor check summaries for the check IDs that you specified. You can get the check IDs by calling the DescribeTrustedAdvisorChecks operation. The response contains an array of TrustedAdvisorCheckSummary objects. You must have a Business or Enterprise support plan to use the AWS Support API. If you call the AWS Support API from an account that does not have a Business or Enterprise support plan, the SubscriptionRequiredException error message appears. For information about changing your support plan, see AWS Support."},{"ref":"AWS.Support.html#describe_trusted_advisor_checks/3","title":"AWS.Support.describe_trusted_advisor_checks/3","type":"function","doc":"Returns information about all available AWS Trusted Advisor checks, including the name, ID, category, description, and metadata. You must specify a language code. The AWS Support API currently supports English (&quot;en&quot;) and Japanese (&quot;ja&quot;). The response contains a TrustedAdvisorCheckDescription object for each check. You must set the AWS Region to us-east-1. You must have a Business or Enterprise support plan to use the AWS Support API. If you call the AWS Support API from an account that does not have a Business or Enterprise support plan, the SubscriptionRequiredException error message appears. For information about changing your support plan, see AWS Support."},{"ref":"AWS.Support.html#refresh_trusted_advisor_check/3","title":"AWS.Support.refresh_trusted_advisor_check/3","type":"function","doc":"Refreshes the AWS Trusted Advisor check that you specify using the check ID. You can get the check IDs by calling the DescribeTrustedAdvisorChecks operation. Some checks are refreshed automatically. If you call the RefreshTrustedAdvisorCheck operation to refresh them, you might see the InvalidParameterValue error. The response contains a TrustedAdvisorCheckRefreshStatus object. You must have a Business or Enterprise support plan to use the AWS Support API. If you call the AWS Support API from an account that does not have a Business or Enterprise support plan, the SubscriptionRequiredException error message appears. For information about changing your support plan, see AWS Support."},{"ref":"AWS.Support.html#resolve_case/3","title":"AWS.Support.resolve_case/3","type":"function","doc":"Resolves a support case. This operation takes a caseId and returns the initial and final state of the case. You must have a Business or Enterprise support plan to use the AWS Support API. If you call the AWS Support API from an account that does not have a Business or Enterprise support plan, the SubscriptionRequiredException error message appears. For information about changing your support plan, see AWS Support."},{"ref":"AWS.Synthetics.html","title":"AWS.Synthetics","type":"module","doc":"Amazon CloudWatch Synthetics You can use Amazon CloudWatch Synthetics to continually monitor your services. You can create and manage canaries, which are modular, lightweight scripts that monitor your endpoints and APIs from the outside-in. You can set up your canaries to run 24 hours a day, once per minute. The canaries help you check the availability and latency of your web services and troubleshoot anomalies by investigating load time data, screenshots of the UI, logs, and metrics. The canaries seamlessly integrate with CloudWatch ServiceLens to help you trace the causes of impacted nodes in your applications. For more information, see Using ServiceLens to Monitor the Health of Your Applications in the Amazon CloudWatch User Guide. Before you create and manage canaries, be aware of the security considerations. For more information, see Security Considerations for Synthetics Canaries."},{"ref":"AWS.Synthetics.html#create_canary/3","title":"AWS.Synthetics.create_canary/3","type":"function","doc":"Creates a canary. Canaries are scripts that monitor your endpoints and APIs from the outside-in. Canaries help you check the availability and latency of your web services and troubleshoot anomalies by investigating load time data, screenshots of the UI, logs, and metrics. You can set up a canary to run continuously or just once. Do not use CreateCanary to modify an existing canary. Use UpdateCanary instead. To create canaries, you must have the CloudWatchSyntheticsFullAccess policy. If you are creating a new IAM role for the canary, you also need the the iam:CreateRole, iam:CreatePolicy and iam:AttachRolePolicy permissions. For more information, see Necessary Roles and Permissions. Do not include secrets or proprietary information in your canary names. The canary name makes up part of the Amazon Resource Name (ARN) for the canary, and the ARN is included in outbound calls over the internet. For more information, see Security Considerations for Synthetics Canaries."},{"ref":"AWS.Synthetics.html#delete_canary/4","title":"AWS.Synthetics.delete_canary/4","type":"function","doc":"Permanently deletes the specified canary. When you delete a canary, resources used and created by the canary are not automatically deleted. After you delete a canary that you do not intend to use again, you should also delete the following: The Lambda functions and layers used by this canary. These have the prefix cwsyn-*MyCanaryName*. The CloudWatch alarms created for this canary. These alarms have a name of Synthetics-SharpDrop-Alarm-*MyCanaryName*. Amazon S3 objects and buckets, such as the canary&#39;s artifact location. IAM roles created for the canary. If they were created in the console, these roles have the name role/service-role/CloudWatchSyntheticsRole-*MyCanaryName*. CloudWatch Logs log groups created for the canary. These logs groups have the name /aws/lambda/cwsyn-*MyCanaryName*. Before you delete a canary, you might want to use GetCanary to display the information about this canary. Make note of the information returned by this operation so that you can delete these resources after you delete the canary."},{"ref":"AWS.Synthetics.html#describe_canaries/3","title":"AWS.Synthetics.describe_canaries/3","type":"function","doc":"This operation returns a list of the canaries in your account, along with full details about each canary. This operation does not have resource-level authorization, so if a user is able to use DescribeCanaries, the user can see all of the canaries in the account. A deny policy can only be used to restrict access to all canaries. It cannot be used on specific resources."},{"ref":"AWS.Synthetics.html#describe_canaries_last_run/3","title":"AWS.Synthetics.describe_canaries_last_run/3","type":"function","doc":"Use this operation to see information from the most recent run of each canary that you have created."},{"ref":"AWS.Synthetics.html#describe_runtime_versions/3","title":"AWS.Synthetics.describe_runtime_versions/3","type":"function","doc":"Returns a list of Synthetics canary runtime versions. For more information, see Canary Runtime Versions."},{"ref":"AWS.Synthetics.html#get_canary/3","title":"AWS.Synthetics.get_canary/3","type":"function","doc":"Retrieves complete information about one canary. You must specify the name of the canary that you want. To get a list of canaries and their names, use DescribeCanaries."},{"ref":"AWS.Synthetics.html#get_canary_runs/4","title":"AWS.Synthetics.get_canary_runs/4","type":"function","doc":"Retrieves a list of runs for a specified canary."},{"ref":"AWS.Synthetics.html#list_tags_for_resource/3","title":"AWS.Synthetics.list_tags_for_resource/3","type":"function","doc":"Displays the tags associated with a canary."},{"ref":"AWS.Synthetics.html#start_canary/4","title":"AWS.Synthetics.start_canary/4","type":"function","doc":"Use this operation to run a canary that has already been created. The frequency of the canary runs is determined by the value of the canary&#39;s Schedule. To see a canary&#39;s schedule, use GetCanary."},{"ref":"AWS.Synthetics.html#stop_canary/4","title":"AWS.Synthetics.stop_canary/4","type":"function","doc":"Stops the canary to prevent all future runs. If the canary is currently running, Synthetics stops waiting for the current run of the specified canary to complete. The run that is in progress completes on its own, publishes metrics, and uploads artifacts, but it is not recorded in Synthetics as a completed run. You can use StartCanary to start it running again with the canarys current schedule at any point in the future."},{"ref":"AWS.Synthetics.html#tag_resource/4","title":"AWS.Synthetics.tag_resource/4","type":"function","doc":"Assigns one or more tags (key-value pairs) to the specified canary. Tags can help you organize and categorize your resources. You can also use them to scope user permissions, by granting a user permission to access or change only resources with certain tag values. Tags don&#39;t have any semantic meaning to AWS and are interpreted strictly as strings of characters. You can use the TagResource action with a canary that already has tags. If you specify a new tag key for the alarm, this tag is appended to the list of tags associated with the alarm. If you specify a tag key that is already associated with the alarm, the new tag value that you specify replaces the previous value for that tag. You can associate as many as 50 tags with a canary."},{"ref":"AWS.Synthetics.html#untag_resource/4","title":"AWS.Synthetics.untag_resource/4","type":"function","doc":"Removes one or more tags from the specified canary."},{"ref":"AWS.Synthetics.html#update_canary/4","title":"AWS.Synthetics.update_canary/4","type":"function","doc":"Use this operation to change the settings of a canary that has already been created. You can&#39;t use this operation to update the tags of an existing canary. To change the tags of an existing canary, use TagResource."},{"ref":"AWS.Textract.html","title":"AWS.Textract","type":"module","doc":"Amazon Textract detects and analyzes text in documents and converts it into machine-readable text. This is the API reference documentation for Amazon Textract."},{"ref":"AWS.Textract.html#analyze_document/3","title":"AWS.Textract.analyze_document/3","type":"function","doc":"Analyzes an input document for relationships between detected items. The types of information returned are as follows: Form data (key-value pairs). The related information is returned in two Block objects, each of type KEY_VALUE_SET: a KEY Block object and a VALUE Block object. For example, Name: Ana Silva Carolina contains a key and value. Name: is the key. Ana Silva Carolina is the value. Table and table cell data. A TABLE Block object contains information about a detected table. A CELL Block object is returned for each cell in a table. Lines and words of text. A LINE Block object contains one or more WORD Block objects. All lines and words that are detected in the document are returned (including text that doesn&#39;t have a relationship with the value of FeatureTypes). Selection elements such as check boxes and option buttons (radio buttons) can be detected in form data and in tables. A SELECTION_ELEMENT Block object contains information about a selection element, including the selection status. You can choose which type of analysis to perform by specifying the FeatureTypes list. The output is returned in a list of Block objects. AnalyzeDocument is a synchronous operation. To analyze documents asynchronously, use StartDocumentAnalysis. For more information, see Document Text Analysis."},{"ref":"AWS.Textract.html#detect_document_text/3","title":"AWS.Textract.detect_document_text/3","type":"function","doc":"Detects text in the input document. Amazon Textract can detect lines of text and the words that make up a line of text. The input document must be an image in JPEG or PNG format. DetectDocumentText returns the detected text in an array of Block objects. Each document page has as an associated Block of type PAGE. Each PAGE Block object is the parent of LINE Block objects that represent the lines of detected text on a page. A LINE Block object is a parent for each word that makes up the line. Words are represented by Block objects of type WORD. DetectDocumentText is a synchronous operation. To analyze documents asynchronously, use StartDocumentTextDetection. For more information, see Document Text Detection."},{"ref":"AWS.Textract.html#get_document_analysis/3","title":"AWS.Textract.get_document_analysis/3","type":"function","doc":"Gets the results for an Amazon Textract asynchronous operation that analyzes text in a document. You start asynchronous text analysis by calling StartDocumentAnalysis, which returns a job identifier (JobId). When the text analysis operation finishes, Amazon Textract publishes a completion status to the Amazon Simple Notification Service (Amazon SNS) topic that&#39;s registered in the initial call to StartDocumentAnalysis. To get the results of the text-detection operation, first check that the status value published to the Amazon SNS topic is SUCCEEDED. If so, call GetDocumentAnalysis, and pass the job identifier (JobId) from the initial call to StartDocumentAnalysis. GetDocumentAnalysis returns an array of Block objects. The following types of information are returned: Form data (key-value pairs). The related information is returned in two Block objects, each of type KEY_VALUE_SET: a KEY Block object and a VALUE Block object. For example, Name: Ana Silva Carolina contains a key and value. Name: is the key. Ana Silva Carolina is the value. Table and table cell data. A TABLE Block object contains information about a detected table. A CELL Block object is returned for each cell in a table. Lines and words of text. A LINE Block object contains one or more WORD Block objects. All lines and words that are detected in the document are returned (including text that doesn&#39;t have a relationship with the value of the StartDocumentAnalysis FeatureTypes input parameter). Selection elements such as check boxes and option buttons (radio buttons) can be detected in form data and in tables. A SELECTION_ELEMENT Block object contains information about a selection element, including the selection status. Use the MaxResults parameter to limit the number of blocks that are returned. If there are more results than specified in MaxResults, the value of NextToken in the operation response contains a pagination token for getting the next set of results. To get the next page of results, call GetDocumentAnalysis, and populate the NextToken request parameter with the token value that&#39;s returned from the previous call to GetDocumentAnalysis. For more information, see Document Text Analysis."},{"ref":"AWS.Textract.html#get_document_text_detection/3","title":"AWS.Textract.get_document_text_detection/3","type":"function","doc":"Gets the results for an Amazon Textract asynchronous operation that detects text in a document. Amazon Textract can detect lines of text and the words that make up a line of text. You start asynchronous text detection by calling StartDocumentTextDetection, which returns a job identifier (JobId). When the text detection operation finishes, Amazon Textract publishes a completion status to the Amazon Simple Notification Service (Amazon SNS) topic that&#39;s registered in the initial call to StartDocumentTextDetection. To get the results of the text-detection operation, first check that the status value published to the Amazon SNS topic is SUCCEEDED. If so, call GetDocumentTextDetection, and pass the job identifier (JobId) from the initial call to StartDocumentTextDetection. GetDocumentTextDetection returns an array of Block objects. Each document page has as an associated Block of type PAGE. Each PAGE Block object is the parent of LINE Block objects that represent the lines of detected text on a page. A LINE Block object is a parent for each word that makes up the line. Words are represented by Block objects of type WORD. Use the MaxResults parameter to limit the number of blocks that are returned. If there are more results than specified in MaxResults, the value of NextToken in the operation response contains a pagination token for getting the next set of results. To get the next page of results, call GetDocumentTextDetection, and populate the NextToken request parameter with the token value that&#39;s returned from the previous call to GetDocumentTextDetection. For more information, see Document Text Detection."},{"ref":"AWS.Textract.html#start_document_analysis/3","title":"AWS.Textract.start_document_analysis/3","type":"function","doc":"Starts the asynchronous analysis of an input document for relationships between detected items such as key-value pairs, tables, and selection elements. StartDocumentAnalysis can analyze text in documents that are in JPEG, PNG, and PDF format. The documents are stored in an Amazon S3 bucket. Use DocumentLocation to specify the bucket name and file name of the document. StartDocumentAnalysis returns a job identifier (JobId) that you use to get the results of the operation. When text analysis is finished, Amazon Textract publishes a completion status to the Amazon Simple Notification Service (Amazon SNS) topic that you specify in NotificationChannel. To get the results of the text analysis operation, first check that the status value published to the Amazon SNS topic is SUCCEEDED. If so, call GetDocumentAnalysis, and pass the job identifier (JobId) from the initial call to StartDocumentAnalysis. For more information, see Document Text Analysis."},{"ref":"AWS.Textract.html#start_document_text_detection/3","title":"AWS.Textract.start_document_text_detection/3","type":"function","doc":"Starts the asynchronous detection of text in a document. Amazon Textract can detect lines of text and the words that make up a line of text. StartDocumentTextDetection can analyze text in documents that are in JPEG, PNG, and PDF format. The documents are stored in an Amazon S3 bucket. Use DocumentLocation to specify the bucket name and file name of the document. StartTextDetection returns a job identifier (JobId) that you use to get the results of the operation. When text detection is finished, Amazon Textract publishes a completion status to the Amazon Simple Notification Service (Amazon SNS) topic that you specify in NotificationChannel. To get the results of the text detection operation, first check that the status value published to the Amazon SNS topic is SUCCEEDED. If so, call GetDocumentTextDetection, and pass the job identifier (JobId) from the initial call to StartDocumentTextDetection. For more information, see Document Text Detection."},{"ref":"AWS.TimestreamQuery.html","title":"AWS.TimestreamQuery","type":"module","doc":""},{"ref":"AWS.TimestreamQuery.html#cancel_query/3","title":"AWS.TimestreamQuery.cancel_query/3","type":"function","doc":"Cancels a query that has been issued. Cancellation is guaranteed only if the query has not completed execution before the cancellation request was issued. Because cancellation is an idempotent operation, subsequent cancellation requests will return a CancellationMessage, indicating that the query has already been canceled."},{"ref":"AWS.TimestreamQuery.html#describe_endpoints/3","title":"AWS.TimestreamQuery.describe_endpoints/3","type":"function","doc":"DescribeEndpoints returns a list of available endpoints to make Timestream API calls against. This API is available through both Write and Query. Because Timestreams SDKs are designed to transparently work with the services architecture, including the management and mapping of the service endpoints, it is not recommended that you use this API unless: Your application uses a programming language that does not yet have SDK support You require better control over the client-side implementation For detailed information on how to use DescribeEndpoints, see The Endpoint Discovery Pattern and REST APIs."},{"ref":"AWS.TimestreamQuery.html#query/3","title":"AWS.TimestreamQuery.query/3","type":"function","doc":"Query is a synchronous operation that enables you to execute a query. Query will timeout after 60 seconds. You must update the default timeout in the SDK to support a timeout of 60 seconds. The result set will be truncated to 1MB. Service quotas apply. For more information, see Quotas in the Timestream Developer Guide."},{"ref":"AWS.TimestreamWrite.html","title":"AWS.TimestreamWrite","type":"module","doc":"Amazon Timestream is a fast, scalable, fully managed time series database service that makes it easy to store and analyze trillions of time series data points per day. With Timestream, you can easily store and analyze IoT sensor data to derive insights from your IoT applications. You can analyze industrial telemetry to streamline equipment management and maintenance. You can also store and analyze log data and metrics to improve the performance and availability of your applications. Timestream is built from the ground up to effectively ingest, process, and store time series data. It organizes data to optimize query processing. It automatically scales based on the volume of data ingested and on the query volume to ensure you receive optimal performance while inserting and querying data. As your data grows over time, Timestreams adaptive query processing engine spans across storage tiers to provide fast analysis while reducing costs."},{"ref":"AWS.TimestreamWrite.html#create_database/3","title":"AWS.TimestreamWrite.create_database/3","type":"function","doc":"Creates a new Timestream database. If the KMS key is not specified, the database will be encrypted with a Timestream managed KMS key located in your account. Refer to AWS managed KMS keys for more info. Service quotas apply. For more information, see Access Management in the Timestream Developer Guide."},{"ref":"AWS.TimestreamWrite.html#create_table/3","title":"AWS.TimestreamWrite.create_table/3","type":"function","doc":"The CreateTable operation adds a new table to an existing database in your account. In an AWS account, table names must be at least unique within each Region if they are in the same database. You may have identical table names in the same Region if the tables are in seperate databases. While creating the table, you must specify the table name, database name, and the retention properties. Service quotas apply. For more information, see Access Management in the Timestream Developer Guide."},{"ref":"AWS.TimestreamWrite.html#delete_database/3","title":"AWS.TimestreamWrite.delete_database/3","type":"function","doc":"Deletes a given Timestream database. This is an irreversible operation. After a database is deleted, the time series data from its tables cannot be recovered. All tables in the database must be deleted first, or a ValidationException error will be thrown."},{"ref":"AWS.TimestreamWrite.html#delete_table/3","title":"AWS.TimestreamWrite.delete_table/3","type":"function","doc":"Deletes a given Timestream table. This is an irreversible operation. After a Timestream database table is deleted, the time series data stored in the table cannot be recovered."},{"ref":"AWS.TimestreamWrite.html#describe_database/3","title":"AWS.TimestreamWrite.describe_database/3","type":"function","doc":"Returns information about the database, including the database name, time that the database was created, and the total number of tables found within the database. Service quotas apply. For more information, see Access Management in the Timestream Developer Guide."},{"ref":"AWS.TimestreamWrite.html#describe_endpoints/3","title":"AWS.TimestreamWrite.describe_endpoints/3","type":"function","doc":"DescribeEndpoints returns a list of available endpoints to make Timestream API calls against. This API is available through both Write and Query. Because Timestreams SDKs are designed to transparently work with the services architecture, including the management and mapping of the service endpoints, it is not recommended that you use this API unless: Your application uses a programming language that does not yet have SDK support You require better control over the client-side implementation For detailed information on how to use DescribeEndpoints, see The Endpoint Discovery Pattern and REST APIs."},{"ref":"AWS.TimestreamWrite.html#describe_table/3","title":"AWS.TimestreamWrite.describe_table/3","type":"function","doc":"Returns information about the table, including the table name, database name, retention duration of the memory store and the magnetic store. Service quotas apply. For more information, see Access Management in the Timestream Developer Guide."},{"ref":"AWS.TimestreamWrite.html#list_databases/3","title":"AWS.TimestreamWrite.list_databases/3","type":"function","doc":"Returns a list of your Timestream databases. Service quotas apply. For more information, see Access Management in the Timestream Developer Guide."},{"ref":"AWS.TimestreamWrite.html#list_tables/3","title":"AWS.TimestreamWrite.list_tables/3","type":"function","doc":"A list of tables, along with the name, status and retention properties of each table."},{"ref":"AWS.TimestreamWrite.html#list_tags_for_resource/3","title":"AWS.TimestreamWrite.list_tags_for_resource/3","type":"function","doc":"List all tags on a Timestream resource."},{"ref":"AWS.TimestreamWrite.html#tag_resource/3","title":"AWS.TimestreamWrite.tag_resource/3","type":"function","doc":"Associate a set of tags with a Timestream resource. You can then activate these user-defined tags so that they appear on the Billing and Cost Management console for cost allocation tracking."},{"ref":"AWS.TimestreamWrite.html#untag_resource/3","title":"AWS.TimestreamWrite.untag_resource/3","type":"function","doc":"Removes the association of tags from a Timestream resource."},{"ref":"AWS.TimestreamWrite.html#update_database/3","title":"AWS.TimestreamWrite.update_database/3","type":"function","doc":"Modifies the KMS key for an existing database. While updating the database, you must specify the database name and the identifier of the new KMS key to be used (KmsKeyId). If there are any concurrent UpdateDatabase requests, first writer wins."},{"ref":"AWS.TimestreamWrite.html#update_table/3","title":"AWS.TimestreamWrite.update_table/3","type":"function","doc":"Modifies the retention duration of the memory store and magnetic store for your Timestream table. Note that the change in retention duration takes effect immediately. For example, if the retention period of the memory store was initially set to 2 hours and then changed to 24 hours, the memory store will be capable of holding 24 hours of data, but will be populated with 24 hours of data 22 hours after this change was made. Timestream does not retrieve data from the magnetic store to populate the memory store. Service quotas apply. For more information, see Access Management in the Timestream Developer Guide."},{"ref":"AWS.TimestreamWrite.html#write_records/3","title":"AWS.TimestreamWrite.write_records/3","type":"function","doc":"The WriteRecords operation enables you to write your time series data into Timestream. You can specify a single data point or a batch of data points to be inserted into the system. Timestream offers you with a flexible schema that auto detects the column names and data types for your Timestream tables based on the dimension names and data types of the data points you specify when invoking writes into the database. Timestream support eventual consistency read semantics. This means that when you query data immediately after writing a batch of data into Timestream, the query results might not reflect the results of a recently completed write operation. The results may also include some stale data. If you repeat the query request after a short time, the results should return the latest data. Service quotas apply. For more information, see Access Management in the Timestream Developer Guide."},{"ref":"AWS.Transcribe.html","title":"AWS.Transcribe","type":"module","doc":"Operations and objects for transcribing speech to text."},{"ref":"AWS.Transcribe.html#create_language_model/3","title":"AWS.Transcribe.create_language_model/3","type":"function","doc":"Creates a new custom language model. Use Amazon S3 prefixes to provide the location of your input files. The time it takes to create your model depends on the size of your training data."},{"ref":"AWS.Transcribe.html#create_medical_vocabulary/3","title":"AWS.Transcribe.create_medical_vocabulary/3","type":"function","doc":"Creates a new custom vocabulary that you can use to change how Amazon Transcribe Medical transcribes your audio file."},{"ref":"AWS.Transcribe.html#create_vocabulary/3","title":"AWS.Transcribe.create_vocabulary/3","type":"function","doc":"Creates a new custom vocabulary that you can use to change the way Amazon Transcribe handles transcription of an audio file."},{"ref":"AWS.Transcribe.html#create_vocabulary_filter/3","title":"AWS.Transcribe.create_vocabulary_filter/3","type":"function","doc":"Creates a new vocabulary filter that you can use to filter words, such as profane words, from the output of a transcription job."},{"ref":"AWS.Transcribe.html#delete_language_model/3","title":"AWS.Transcribe.delete_language_model/3","type":"function","doc":"Deletes a custom language model using its name."},{"ref":"AWS.Transcribe.html#delete_medical_transcription_job/3","title":"AWS.Transcribe.delete_medical_transcription_job/3","type":"function","doc":"Deletes a transcription job generated by Amazon Transcribe Medical and any related information."},{"ref":"AWS.Transcribe.html#delete_medical_vocabulary/3","title":"AWS.Transcribe.delete_medical_vocabulary/3","type":"function","doc":"Deletes a vocabulary from Amazon Transcribe Medical."},{"ref":"AWS.Transcribe.html#delete_transcription_job/3","title":"AWS.Transcribe.delete_transcription_job/3","type":"function","doc":"Deletes a previously submitted transcription job along with any other generated results such as the transcription, models, and so on."},{"ref":"AWS.Transcribe.html#delete_vocabulary/3","title":"AWS.Transcribe.delete_vocabulary/3","type":"function","doc":"Deletes a vocabulary from Amazon Transcribe."},{"ref":"AWS.Transcribe.html#delete_vocabulary_filter/3","title":"AWS.Transcribe.delete_vocabulary_filter/3","type":"function","doc":"Removes a vocabulary filter."},{"ref":"AWS.Transcribe.html#describe_language_model/3","title":"AWS.Transcribe.describe_language_model/3","type":"function","doc":"Gets information about a single custom language model. Use this information to see details about the language model in your AWS account. You can also see whether the base language model used to create your custom language model has been updated. If Amazon Transcribe has updated the base model, you can create a new custom language model using the updated base model. If the language model wasn&#39;t created, you can use this operation to understand why Amazon Transcribe couldn&#39;t create it."},{"ref":"AWS.Transcribe.html#get_medical_transcription_job/3","title":"AWS.Transcribe.get_medical_transcription_job/3","type":"function","doc":"Returns information about a transcription job from Amazon Transcribe Medical. To see the status of the job, check the TranscriptionJobStatus field. If the status is COMPLETED, the job is finished. You find the results of the completed job in the TranscriptFileUri field."},{"ref":"AWS.Transcribe.html#get_medical_vocabulary/3","title":"AWS.Transcribe.get_medical_vocabulary/3","type":"function","doc":"Retrieves information about a medical vocabulary."},{"ref":"AWS.Transcribe.html#get_transcription_job/3","title":"AWS.Transcribe.get_transcription_job/3","type":"function","doc":"Returns information about a transcription job. To see the status of the job, check the TranscriptionJobStatus field. If the status is COMPLETED, the job is finished and you can find the results at the location specified in the TranscriptFileUri field. If you enable content redaction, the redacted transcript appears in RedactedTranscriptFileUri."},{"ref":"AWS.Transcribe.html#get_vocabulary/3","title":"AWS.Transcribe.get_vocabulary/3","type":"function","doc":"Gets information about a vocabulary."},{"ref":"AWS.Transcribe.html#get_vocabulary_filter/3","title":"AWS.Transcribe.get_vocabulary_filter/3","type":"function","doc":"Returns information about a vocabulary filter."},{"ref":"AWS.Transcribe.html#list_language_models/3","title":"AWS.Transcribe.list_language_models/3","type":"function","doc":"Provides more information about the custom language models you&#39;ve created. You can use the information in this list to find a specific custom language model. You can then use the operation to get more information about it."},{"ref":"AWS.Transcribe.html#list_medical_transcription_jobs/3","title":"AWS.Transcribe.list_medical_transcription_jobs/3","type":"function","doc":"Lists medical transcription jobs with a specified status or substring that matches their names."},{"ref":"AWS.Transcribe.html#list_medical_vocabularies/3","title":"AWS.Transcribe.list_medical_vocabularies/3","type":"function","doc":"Returns a list of vocabularies that match the specified criteria. If you don&#39;t enter a value in any of the request parameters, returns the entire list of vocabularies."},{"ref":"AWS.Transcribe.html#list_transcription_jobs/3","title":"AWS.Transcribe.list_transcription_jobs/3","type":"function","doc":"Lists transcription jobs with the specified status."},{"ref":"AWS.Transcribe.html#list_vocabularies/3","title":"AWS.Transcribe.list_vocabularies/3","type":"function","doc":"Returns a list of vocabularies that match the specified criteria. If no criteria are specified, returns the entire list of vocabularies."},{"ref":"AWS.Transcribe.html#list_vocabulary_filters/3","title":"AWS.Transcribe.list_vocabulary_filters/3","type":"function","doc":"Gets information about vocabulary filters."},{"ref":"AWS.Transcribe.html#start_medical_transcription_job/3","title":"AWS.Transcribe.start_medical_transcription_job/3","type":"function","doc":"Starts a batch job to transcribe medical speech to text."},{"ref":"AWS.Transcribe.html#start_transcription_job/3","title":"AWS.Transcribe.start_transcription_job/3","type":"function","doc":"Starts an asynchronous job to transcribe speech to text."},{"ref":"AWS.Transcribe.html#update_medical_vocabulary/3","title":"AWS.Transcribe.update_medical_vocabulary/3","type":"function","doc":"Updates a vocabulary with new values that you provide in a different text file from the one you used to create the vocabulary. The UpdateMedicalVocabulary operation overwrites all of the existing information with the values that you provide in the request."},{"ref":"AWS.Transcribe.html#update_vocabulary/3","title":"AWS.Transcribe.update_vocabulary/3","type":"function","doc":"Updates an existing vocabulary with new values. The UpdateVocabulary operation overwrites all of the existing information with the values that you provide in the request."},{"ref":"AWS.Transcribe.html#update_vocabulary_filter/3","title":"AWS.Transcribe.update_vocabulary_filter/3","type":"function","doc":"Updates a vocabulary filter with a new list of filtered words."},{"ref":"AWS.TranscribeStreaming.html","title":"AWS.TranscribeStreaming","type":"module","doc":"Operations and objects for transcribing streaming speech to text."},{"ref":"AWS.TranscribeStreaming.html#start_stream_transcription/3","title":"AWS.TranscribeStreaming.start_stream_transcription/3","type":"function","doc":"Starts a bidirectional HTTP2 stream where audio is streamed to Amazon Transcribe and the transcription results are streamed to your application. The following are encoded as HTTP2 headers: x-amzn-transcribe-language-code x-amzn-transcribe-media-encoding x-amzn-transcribe-sample-rate x-amzn-transcribe-session-id"},{"ref":"AWS.Transfer.html","title":"AWS.Transfer","type":"module","doc":"AWS Transfer Family is a fully managed service that enables the transfer of files over the File Transfer Protocol (FTP), File Transfer Protocol over SSL (FTPS), or Secure Shell (SSH) File Transfer Protocol (SFTP) directly into and out of Amazon Simple Storage Service (Amazon S3). AWS helps you seamlessly migrate your file transfer workflows to AWS Transfer Family by integrating with existing authentication systems, and providing DNS routing with Amazon Route 53 so nothing changes for your customers and partners, or their applications. With your data in Amazon S3, you can use it with AWS services for processing, analytics, machine learning, and archiving. Getting started with AWS Transfer Family is easy since there is no infrastructure to buy and set up."},{"ref":"AWS.Transfer.html#create_server/3","title":"AWS.Transfer.create_server/3","type":"function","doc":"Instantiates an autoscaling virtual server based on the selected file transfer protocol in AWS. When you make updates to your file transfer protocol-enabled server or when you work with users, use the service-generated ServerId property that is assigned to the newly created server."},{"ref":"AWS.Transfer.html#create_user/3","title":"AWS.Transfer.create_user/3","type":"function","doc":"Creates a user and associates them with an existing file transfer protocol-enabled server. You can only create and associate users with servers that have the IdentityProviderType set to SERVICE_MANAGED. Using parameters for CreateUser, you can specify the user name, set the home directory, store the user&#39;s public key, and assign the user&#39;s AWS Identity and Access Management (IAM) role. You can also optionally add a scope-down policy, and assign metadata with tags that can be used to group and search for users."},{"ref":"AWS.Transfer.html#delete_server/3","title":"AWS.Transfer.delete_server/3","type":"function","doc":"Deletes the file transfer protocol-enabled server that you specify. No response returns from this operation."},{"ref":"AWS.Transfer.html#delete_ssh_public_key/3","title":"AWS.Transfer.delete_ssh_public_key/3","type":"function","doc":"Deletes a user&#39;s Secure Shell (SSH) public key. No response is returned from this operation."},{"ref":"AWS.Transfer.html#delete_user/3","title":"AWS.Transfer.delete_user/3","type":"function","doc":"Deletes the user belonging to a file transfer protocol-enabled server you specify. No response returns from this operation. When you delete a user from a server, the user&#39;s information is lost."},{"ref":"AWS.Transfer.html#describe_security_policy/3","title":"AWS.Transfer.describe_security_policy/3","type":"function","doc":"Describes the security policy that is attached to your file transfer protocol-enabled server. The response contains a description of the security policy&#39;s properties. For more information about security policies, see Working with security policies."},{"ref":"AWS.Transfer.html#describe_server/3","title":"AWS.Transfer.describe_server/3","type":"function","doc":"Describes a file transfer protocol-enabled server that you specify by passing the ServerId parameter. The response contains a description of a server&#39;s properties. When you set EndpointType to VPC, the response will contain the EndpointDetails."},{"ref":"AWS.Transfer.html#describe_user/3","title":"AWS.Transfer.describe_user/3","type":"function","doc":"Describes the user assigned to the specific file transfer protocol-enabled server, as identified by its ServerId property. The response from this call returns the properties of the user associated with the ServerId value that was specified."},{"ref":"AWS.Transfer.html#import_ssh_public_key/3","title":"AWS.Transfer.import_ssh_public_key/3","type":"function","doc":"Adds a Secure Shell (SSH) public key to a user account identified by a UserName value assigned to the specific file transfer protocol-enabled server, identified by ServerId. The response returns the UserName value, the ServerId value, and the name of the SshPublicKeyId."},{"ref":"AWS.Transfer.html#list_security_policies/3","title":"AWS.Transfer.list_security_policies/3","type":"function","doc":"Lists the security policies that are attached to your file transfer protocol-enabled servers."},{"ref":"AWS.Transfer.html#list_servers/3","title":"AWS.Transfer.list_servers/3","type":"function","doc":"Lists the file transfer protocol-enabled servers that are associated with your AWS account."},{"ref":"AWS.Transfer.html#list_tags_for_resource/3","title":"AWS.Transfer.list_tags_for_resource/3","type":"function","doc":"Lists all of the tags associated with the Amazon Resource Number (ARN) you specify. The resource can be a user, server, or role."},{"ref":"AWS.Transfer.html#list_users/3","title":"AWS.Transfer.list_users/3","type":"function","doc":"Lists the users for a file transfer protocol-enabled server that you specify by passing the ServerId parameter."},{"ref":"AWS.Transfer.html#start_server/3","title":"AWS.Transfer.start_server/3","type":"function","doc":"Changes the state of a file transfer protocol-enabled server from OFFLINE to ONLINE. It has no impact on a server that is already ONLINE. An ONLINE server can accept and process file transfer jobs. The state of STARTING indicates that the server is in an intermediate state, either not fully able to respond, or not fully online. The values of START_FAILED can indicate an error condition. No response is returned from this call."},{"ref":"AWS.Transfer.html#stop_server/3","title":"AWS.Transfer.stop_server/3","type":"function","doc":"Changes the state of a file transfer protocol-enabled server from ONLINE to OFFLINE. An OFFLINE server cannot accept and process file transfer jobs. Information tied to your server, such as server and user properties, are not affected by stopping your server. Stopping the server will not reduce or impact your file transfer protocol endpoint billing. The state of STOPPING indicates that the server is in an intermediate state, either not fully able to respond, or not fully offline. The values of STOP_FAILED can indicate an error condition. No response is returned from this call."},{"ref":"AWS.Transfer.html#tag_resource/3","title":"AWS.Transfer.tag_resource/3","type":"function","doc":"Attaches a key-value pair to a resource, as identified by its Amazon Resource Name (ARN). Resources are users, servers, roles, and other entities. There is no response returned from this call."},{"ref":"AWS.Transfer.html#test_identity_provider/3","title":"AWS.Transfer.test_identity_provider/3","type":"function","doc":"If the IdentityProviderType of a file transfer protocol-enabled server is API_Gateway, tests whether your API Gateway is set up successfully. We highly recommend that you call this operation to test your authentication method as soon as you create your server. By doing so, you can troubleshoot issues with the API Gateway integration to ensure that your users can successfully use the service."},{"ref":"AWS.Transfer.html#untag_resource/3","title":"AWS.Transfer.untag_resource/3","type":"function","doc":"Detaches a key-value pair from a resource, as identified by its Amazon Resource Name (ARN). Resources are users, servers, roles, and other entities. No response is returned from this call."},{"ref":"AWS.Transfer.html#update_server/3","title":"AWS.Transfer.update_server/3","type":"function","doc":"Updates the file transfer protocol-enabled server&#39;s properties after that server has been created. The UpdateServer call returns the ServerId of the server you updated."},{"ref":"AWS.Transfer.html#update_user/3","title":"AWS.Transfer.update_user/3","type":"function","doc":"Assigns new properties to a user. Parameters you pass modify any or all of the following: the home directory, role, and policy for the UserName and ServerId you specify. The response returns the ServerId and the UserName for the updated user."},{"ref":"AWS.Translate.html","title":"AWS.Translate","type":"module","doc":"Provides translation between one source language and another of the same set of languages."},{"ref":"AWS.Translate.html#delete_terminology/3","title":"AWS.Translate.delete_terminology/3","type":"function","doc":"A synchronous action that deletes a custom terminology."},{"ref":"AWS.Translate.html#describe_text_translation_job/3","title":"AWS.Translate.describe_text_translation_job/3","type":"function","doc":"Gets the properties associated with an asycnhronous batch translation job including name, ID, status, source and target languages, input/output S3 buckets, and so on."},{"ref":"AWS.Translate.html#get_terminology/3","title":"AWS.Translate.get_terminology/3","type":"function","doc":"Retrieves a custom terminology."},{"ref":"AWS.Translate.html#import_terminology/3","title":"AWS.Translate.import_terminology/3","type":"function","doc":"Creates or updates a custom terminology, depending on whether or not one already exists for the given terminology name. Importing a terminology with the same name as an existing one will merge the terminologies based on the chosen merge strategy. Currently, the only supported merge strategy is OVERWRITE, and so the imported terminology will overwrite an existing terminology of the same name. If you import a terminology that overwrites an existing one, the new terminology take up to 10 minutes to fully propagate and be available for use in a translation due to cache policies with the DataPlane service that performs the translations."},{"ref":"AWS.Translate.html#list_terminologies/3","title":"AWS.Translate.list_terminologies/3","type":"function","doc":"Provides a list of custom terminologies associated with your account."},{"ref":"AWS.Translate.html#list_text_translation_jobs/3","title":"AWS.Translate.list_text_translation_jobs/3","type":"function","doc":"Gets a list of the batch translation jobs that you have submitted."},{"ref":"AWS.Translate.html#start_text_translation_job/3","title":"AWS.Translate.start_text_translation_job/3","type":"function","doc":"Starts an asynchronous batch translation job. Batch translation jobs can be used to translate large volumes of text across multiple documents at once. For more information, see async. Batch translation jobs can be described with the DescribeTextTranslationJob operation, listed with the ListTextTranslationJobs operation, and stopped with the StopTextTranslationJob operation. Amazon Translate does not support batch translation of multiple source languages at once."},{"ref":"AWS.Translate.html#stop_text_translation_job/3","title":"AWS.Translate.stop_text_translation_job/3","type":"function","doc":"Stops an asynchronous batch translation job that is in progress. If the job&#39;s state is IN_PROGRESS, the job will be marked for termination and put into the STOP_REQUESTED state. If the job completes before it can be stopped, it is put into the COMPLETED state. Otherwise, the job is put into the STOPPED state. Asynchronous batch translation jobs are started with the StartTextTranslationJob operation. You can use the DescribeTextTranslationJob or ListTextTranslationJobs operations to get a batch translation job&#39;s JobId."},{"ref":"AWS.Translate.html#translate_text/3","title":"AWS.Translate.translate_text/3","type":"function","doc":"Translates input text from the source language to the target language. For a list of available languages and language codes, see what-is-languages."},{"ref":"AWS.WAF.html","title":"AWS.WAF","type":"module","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. This is the AWS WAF Classic API Reference for using AWS WAF Classic with Amazon CloudFront. The AWS WAF Classic actions and data types listed in the reference are available for protecting Amazon CloudFront distributions. You can use these actions and data types via the endpoint waf.amazonaws.com. This guide is for developers who need detailed information about the AWS WAF Classic API actions, data types, and errors. For detailed information about AWS WAF Classic features and an overview of how to use the AWS WAF Classic API, see the AWS WAF Classic in the developer guide."},{"ref":"AWS.WAF.html#create_byte_match_set/3","title":"AWS.WAF.create_byte_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates a ByteMatchSet. You then use UpdateByteMatchSet to identify the part of a web request that you want AWS WAF to inspect, such as the values of the User-Agent header or the query string. For example, you can create a ByteMatchSet that matches any requests with User-Agent headers that contain the string BadBot. You can then configure AWS WAF to reject those requests. To create and configure a ByteMatchSet, perform the following steps: Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a CreateByteMatchSet request. Submit a CreateByteMatchSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateByteMatchSet request. Submit an UpdateByteMatchSet request to specify the part of the request that you want AWS WAF to inspect (for example, the header or the URI) and the value that you want AWS WAF to watch for. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#create_geo_match_set/3","title":"AWS.WAF.create_geo_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates an GeoMatchSet, which you use to specify which web requests you want to allow or block based on the country that the requests originate from. For example, if you&#39;re receiving a lot of requests from one or more countries and you want to block the requests, you can create an GeoMatchSet that contains those countries and then configure AWS WAF to block the requests. To create and configure a GeoMatchSet, perform the following steps: Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a CreateGeoMatchSet request. Submit a CreateGeoMatchSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateGeoMatchSet request. Submit an UpdateGeoMatchSetSet request to specify the countries that you want AWS WAF to watch for. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#create_i_p_set/3","title":"AWS.WAF.create_i_p_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates an IPSet, which you use to specify which web requests that you want to allow or block based on the IP addresses that the requests originate from. For example, if you&#39;re receiving a lot of requests from one or more individual IP addresses or one or more ranges of IP addresses and you want to block the requests, you can create an IPSet that contains those IP addresses and then configure AWS WAF to block the requests. To create and configure an IPSet, perform the following steps: Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a CreateIPSet request. Submit a CreateIPSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateIPSet request. Submit an UpdateIPSet request to specify the IP addresses that you want AWS WAF to watch for. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#create_rate_based_rule/3","title":"AWS.WAF.create_rate_based_rule/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates a RateBasedRule. The RateBasedRule contains a RateLimit, which specifies the maximum number of requests that AWS WAF allows from a specified IP address in a five-minute period. The RateBasedRule also contains the IPSet objects, ByteMatchSet objects, and other predicates that identify the requests that you want to count or block if these requests exceed the RateLimit. If you add more than one predicate to a RateBasedRule, a request not only must exceed the RateLimit, but it also must match all the conditions to be counted or blocked. For example, suppose you add the following to a RateBasedRule: An IPSet that matches the IP address 192.0.2.44/32 A ByteMatchSet that matches BadBot in the User-Agent header Further, you specify a RateLimit of 1,000. You then add the RateBasedRule to a WebACL and specify that you want to block requests that meet the conditions in the rule. For a request to be blocked, it must come from the IP address 192.0.2.44 and the User-Agent header in the request must contain the value BadBot. Further, requests that match these two conditions must be received at a rate of more than 1,000 requests every five minutes. If both conditions are met and the rate is exceeded, AWS WAF blocks the requests. If the rate drops below 1,000 for a five-minute period, AWS WAF no longer blocks the requests. As a second example, suppose you want to limit requests to a particular page on your site. To do this, you could add the following to a RateBasedRule: A ByteMatchSet with FieldToMatch of URI A PositionalConstraint of STARTS_WITH A TargetString of login Further, you specify a RateLimit of 1,000. By adding this RateBasedRule to a WebACL, you could limit requests to your login page without affecting the rest of your site. To create and configure a RateBasedRule, perform the following steps: Create and update the predicates that you want to include in the rule. For more information, see CreateByteMatchSet, CreateIPSet, and CreateSqlInjectionMatchSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a CreateRule request. Submit a CreateRateBasedRule request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateRule request. Submit an UpdateRateBasedRule request to specify the predicates that you want to include in the rule. Create and update a WebACL that contains the RateBasedRule. For more information, see CreateWebACL. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#create_regex_match_set/3","title":"AWS.WAF.create_regex_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates a RegexMatchSet. You then use UpdateRegexMatchSet to identify the part of a web request that you want AWS WAF to inspect, such as the values of the User-Agent header or the query string. For example, you can create a RegexMatchSet that contains a RegexMatchTuple that looks for any requests with User-Agent headers that match a RegexPatternSet with pattern B[a@]dB[o0]t. You can then configure AWS WAF to reject those requests. To create and configure a RegexMatchSet, perform the following steps: Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a CreateRegexMatchSet request. Submit a CreateRegexMatchSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateRegexMatchSet request. Submit an UpdateRegexMatchSet request to specify the part of the request that you want AWS WAF to inspect (for example, the header or the URI) and the value, using a RegexPatternSet, that you want AWS WAF to watch for. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#create_regex_pattern_set/3","title":"AWS.WAF.create_regex_pattern_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates a RegexPatternSet. You then use UpdateRegexPatternSet to specify the regular expression (regex) pattern that you want AWS WAF to search for, such as B[a@]dB[o0]t. You can then configure AWS WAF to reject those requests. To create and configure a RegexPatternSet, perform the following steps: Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a CreateRegexPatternSet request. Submit a CreateRegexPatternSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateRegexPatternSet request. Submit an UpdateRegexPatternSet request to specify the string that you want AWS WAF to watch for. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#create_rule/3","title":"AWS.WAF.create_rule/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates a Rule, which contains the IPSet objects, ByteMatchSet objects, and other predicates that identify the requests that you want to block. If you add more than one predicate to a Rule, a request must match all of the specifications to be allowed or blocked. For example, suppose that you add the following to a Rule: An IPSet that matches the IP address 192.0.2.44/32 A ByteMatchSet that matches BadBot in the User-Agent header You then add the Rule to a WebACL and specify that you want to blocks requests that satisfy the Rule. For a request to be blocked, it must come from the IP address 192.0.2.44 and the User-Agent header in the request must contain the value BadBot. To create and configure a Rule, perform the following steps: Create and update the predicates that you want to include in the Rule. For more information, see CreateByteMatchSet, CreateIPSet, and CreateSqlInjectionMatchSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a CreateRule request. Submit a CreateRule request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateRule request. Submit an UpdateRule request to specify the predicates that you want to include in the Rule. Create and update a WebACL that contains the Rule. For more information, see CreateWebACL. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#create_rule_group/3","title":"AWS.WAF.create_rule_group/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates a RuleGroup. A rule group is a collection of predefined rules that you add to a web ACL. You use UpdateRuleGroup to add rules to the rule group. Rule groups are subject to the following limits: Three rule groups per account. You can request an increase to this limit by contacting customer support. One rule group per web ACL. Ten rules per rule group. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#create_size_constraint_set/3","title":"AWS.WAF.create_size_constraint_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates a SizeConstraintSet. You then use UpdateSizeConstraintSet to identify the part of a web request that you want AWS WAF to check for length, such as the length of the User-Agent header or the length of the query string. For example, you can create a SizeConstraintSet that matches any requests that have a query string that is longer than 100 bytes. You can then configure AWS WAF to reject those requests. To create and configure a SizeConstraintSet, perform the following steps: Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a CreateSizeConstraintSet request. Submit a CreateSizeConstraintSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateSizeConstraintSet request. Submit an UpdateSizeConstraintSet request to specify the part of the request that you want AWS WAF to inspect (for example, the header or the URI) and the value that you want AWS WAF to watch for. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#create_sql_injection_match_set/3","title":"AWS.WAF.create_sql_injection_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates a SqlInjectionMatchSet, which you use to allow, block, or count requests that contain snippets of SQL code in a specified part of web requests. AWS WAF searches for character sequences that are likely to be malicious strings. To create and configure a SqlInjectionMatchSet, perform the following steps: Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a CreateSqlInjectionMatchSet request. Submit a CreateSqlInjectionMatchSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateSqlInjectionMatchSet request. Submit an UpdateSqlInjectionMatchSet request to specify the parts of web requests in which you want to allow, block, or count malicious SQL code. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#create_web_a_c_l/3","title":"AWS.WAF.create_web_a_c_l/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates a WebACL, which contains the Rules that identify the CloudFront web requests that you want to allow, block, or count. AWS WAF evaluates Rules in order based on the value of Priority for each Rule. You also specify a default action, either ALLOW or BLOCK. If a web request doesn&#39;t match any of the Rules in a WebACL, AWS WAF responds to the request with the default action. To create and configure a WebACL, perform the following steps: Create and update the ByteMatchSet objects and other predicates that you want to include in Rules. For more information, see CreateByteMatchSet, UpdateByteMatchSet, CreateIPSet, UpdateIPSet, CreateSqlInjectionMatchSet, and UpdateSqlInjectionMatchSet. Create and update the Rules that you want to include in the WebACL. For more information, see CreateRule and UpdateRule. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a CreateWebACL request. Submit a CreateWebACL request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateWebACL request. Submit an UpdateWebACL request to specify the Rules that you want to include in the WebACL, to specify the default action, and to associate the WebACL with a CloudFront distribution. For more information about how to use the AWS WAF API, see the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#create_web_a_c_l_migration_stack/3","title":"AWS.WAF.create_web_a_c_l_migration_stack/3","type":"function","doc":"Creates an AWS CloudFormation WAFV2 template for the specified web ACL in the specified Amazon S3 bucket. Then, in CloudFormation, you create a stack from the template, to create the web ACL and its resources in AWS WAFV2. Use this to migrate your AWS WAF Classic web ACL to the latest version of AWS WAF. This is part of a larger migration procedure for web ACLs from AWS WAF Classic to the latest version of AWS WAF. For the full procedure, including caveats and manual steps to complete the migration and switch over to the new web ACL, see Migrating your AWS WAF Classic resources to AWS WAF in the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#create_xss_match_set/3","title":"AWS.WAF.create_xss_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates an XssMatchSet, which you use to allow, block, or count requests that contain cross-site scripting attacks in the specified part of web requests. AWS WAF searches for character sequences that are likely to be malicious strings. To create and configure an XssMatchSet, perform the following steps: Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a CreateXssMatchSet request. Submit a CreateXssMatchSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateXssMatchSet request. Submit an UpdateXssMatchSet request to specify the parts of web requests in which you want to allow, block, or count cross-site scripting attacks. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#delete_byte_match_set/3","title":"AWS.WAF.delete_byte_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes a ByteMatchSet. You can&#39;t delete a ByteMatchSet if it&#39;s still used in any Rules or if it still includes any ByteMatchTuple objects (any filters). If you just want to remove a ByteMatchSet from a Rule, use UpdateRule. To permanently delete a ByteMatchSet, perform the following steps: Update the ByteMatchSet to remove filters, if any. For more information, see UpdateByteMatchSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a DeleteByteMatchSet request. Submit a DeleteByteMatchSet request."},{"ref":"AWS.WAF.html#delete_geo_match_set/3","title":"AWS.WAF.delete_geo_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes a GeoMatchSet. You can&#39;t delete a GeoMatchSet if it&#39;s still used in any Rules or if it still includes any countries. If you just want to remove a GeoMatchSet from a Rule, use UpdateRule. To permanently delete a GeoMatchSet from AWS WAF, perform the following steps: Update the GeoMatchSet to remove any countries. For more information, see UpdateGeoMatchSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a DeleteGeoMatchSet request. Submit a DeleteGeoMatchSet request."},{"ref":"AWS.WAF.html#delete_i_p_set/3","title":"AWS.WAF.delete_i_p_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes an IPSet. You can&#39;t delete an IPSet if it&#39;s still used in any Rules or if it still includes any IP addresses. If you just want to remove an IPSet from a Rule, use UpdateRule. To permanently delete an IPSet from AWS WAF, perform the following steps: Update the IPSet to remove IP address ranges, if any. For more information, see UpdateIPSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a DeleteIPSet request. Submit a DeleteIPSet request."},{"ref":"AWS.WAF.html#delete_logging_configuration/3","title":"AWS.WAF.delete_logging_configuration/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes the LoggingConfiguration from the specified web ACL."},{"ref":"AWS.WAF.html#delete_permission_policy/3","title":"AWS.WAF.delete_permission_policy/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes an IAM policy from the specified RuleGroup. The user making the request must be the owner of the RuleGroup."},{"ref":"AWS.WAF.html#delete_rate_based_rule/3","title":"AWS.WAF.delete_rate_based_rule/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes a RateBasedRule. You can&#39;t delete a rule if it&#39;s still used in any WebACL objects or if it still includes any predicates, such as ByteMatchSet objects. If you just want to remove a rule from a WebACL, use UpdateWebACL. To permanently delete a RateBasedRule from AWS WAF, perform the following steps: Update the RateBasedRule to remove predicates, if any. For more information, see UpdateRateBasedRule. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a DeleteRateBasedRule request. Submit a DeleteRateBasedRule request."},{"ref":"AWS.WAF.html#delete_regex_match_set/3","title":"AWS.WAF.delete_regex_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes a RegexMatchSet. You can&#39;t delete a RegexMatchSet if it&#39;s still used in any Rules or if it still includes any RegexMatchTuples objects (any filters). If you just want to remove a RegexMatchSet from a Rule, use UpdateRule. To permanently delete a RegexMatchSet, perform the following steps: Update the RegexMatchSet to remove filters, if any. For more information, see UpdateRegexMatchSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a DeleteRegexMatchSet request. Submit a DeleteRegexMatchSet request."},{"ref":"AWS.WAF.html#delete_regex_pattern_set/3","title":"AWS.WAF.delete_regex_pattern_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes a RegexPatternSet. You can&#39;t delete a RegexPatternSet if it&#39;s still used in any RegexMatchSet or if the RegexPatternSet is not empty."},{"ref":"AWS.WAF.html#delete_rule/3","title":"AWS.WAF.delete_rule/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes a Rule. You can&#39;t delete a Rule if it&#39;s still used in any WebACL objects or if it still includes any predicates, such as ByteMatchSet objects. If you just want to remove a Rule from a WebACL, use UpdateWebACL. To permanently delete a Rule from AWS WAF, perform the following steps: Update the Rule to remove predicates, if any. For more information, see UpdateRule. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a DeleteRule request. Submit a DeleteRule request."},{"ref":"AWS.WAF.html#delete_rule_group/3","title":"AWS.WAF.delete_rule_group/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes a RuleGroup. You can&#39;t delete a RuleGroup if it&#39;s still used in any WebACL objects or if it still includes any rules. If you just want to remove a RuleGroup from a WebACL, use UpdateWebACL. To permanently delete a RuleGroup from AWS WAF, perform the following steps: Update the RuleGroup to remove rules, if any. For more information, see UpdateRuleGroup. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a DeleteRuleGroup request. Submit a DeleteRuleGroup request."},{"ref":"AWS.WAF.html#delete_size_constraint_set/3","title":"AWS.WAF.delete_size_constraint_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes a SizeConstraintSet. You can&#39;t delete a SizeConstraintSet if it&#39;s still used in any Rules or if it still includes any SizeConstraint objects (any filters). If you just want to remove a SizeConstraintSet from a Rule, use UpdateRule. To permanently delete a SizeConstraintSet, perform the following steps: Update the SizeConstraintSet to remove filters, if any. For more information, see UpdateSizeConstraintSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a DeleteSizeConstraintSet request. Submit a DeleteSizeConstraintSet request."},{"ref":"AWS.WAF.html#delete_sql_injection_match_set/3","title":"AWS.WAF.delete_sql_injection_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes a SqlInjectionMatchSet. You can&#39;t delete a SqlInjectionMatchSet if it&#39;s still used in any Rules or if it still contains any SqlInjectionMatchTuple objects. If you just want to remove a SqlInjectionMatchSet from a Rule, use UpdateRule. To permanently delete a SqlInjectionMatchSet from AWS WAF, perform the following steps: Update the SqlInjectionMatchSet to remove filters, if any. For more information, see UpdateSqlInjectionMatchSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a DeleteSqlInjectionMatchSet request. Submit a DeleteSqlInjectionMatchSet request."},{"ref":"AWS.WAF.html#delete_web_a_c_l/3","title":"AWS.WAF.delete_web_a_c_l/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes a WebACL. You can&#39;t delete a WebACL if it still contains any Rules. To delete a WebACL, perform the following steps: Update the WebACL to remove Rules, if any. For more information, see UpdateWebACL. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a DeleteWebACL request. Submit a DeleteWebACL request."},{"ref":"AWS.WAF.html#delete_xss_match_set/3","title":"AWS.WAF.delete_xss_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes an XssMatchSet. You can&#39;t delete an XssMatchSet if it&#39;s still used in any Rules or if it still contains any XssMatchTuple objects. If you just want to remove an XssMatchSet from a Rule, use UpdateRule. To permanently delete an XssMatchSet from AWS WAF, perform the following steps: Update the XssMatchSet to remove filters, if any. For more information, see UpdateXssMatchSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a DeleteXssMatchSet request. Submit a DeleteXssMatchSet request."},{"ref":"AWS.WAF.html#get_byte_match_set/3","title":"AWS.WAF.get_byte_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the ByteMatchSet specified by ByteMatchSetId."},{"ref":"AWS.WAF.html#get_change_token/3","title":"AWS.WAF.get_change_token/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. When you want to create, update, or delete AWS WAF objects, get a change token and include the change token in the create, update, or delete request. Change tokens ensure that your application doesn&#39;t submit conflicting requests to AWS WAF. Each create, update, or delete request must use a unique change token. If your application submits a GetChangeToken request and then submits a second GetChangeToken request before submitting a create, update, or delete request, the second GetChangeToken request returns the same value as the first GetChangeToken request. When you use a change token in a create, update, or delete request, the status of the change token changes to PENDING, which indicates that AWS WAF is propagating the change to all AWS WAF servers. Use GetChangeTokenStatus to determine the status of your change token."},{"ref":"AWS.WAF.html#get_change_token_status/3","title":"AWS.WAF.get_change_token_status/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the status of a ChangeToken that you got by calling GetChangeToken. ChangeTokenStatus is one of the following values: PROVISIONED: You requested the change token by calling GetChangeToken, but you haven&#39;t used it yet in a call to create, update, or delete an AWS WAF object. PENDING: AWS WAF is propagating the create, update, or delete request to all AWS WAF servers. INSYNC: Propagation is complete."},{"ref":"AWS.WAF.html#get_geo_match_set/3","title":"AWS.WAF.get_geo_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the GeoMatchSet that is specified by GeoMatchSetId."},{"ref":"AWS.WAF.html#get_i_p_set/3","title":"AWS.WAF.get_i_p_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the IPSet that is specified by IPSetId."},{"ref":"AWS.WAF.html#get_logging_configuration/3","title":"AWS.WAF.get_logging_configuration/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the LoggingConfiguration for the specified web ACL."},{"ref":"AWS.WAF.html#get_permission_policy/3","title":"AWS.WAF.get_permission_policy/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the IAM policy attached to the RuleGroup."},{"ref":"AWS.WAF.html#get_rate_based_rule/3","title":"AWS.WAF.get_rate_based_rule/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the RateBasedRule that is specified by the RuleId that you included in the GetRateBasedRule request."},{"ref":"AWS.WAF.html#get_rate_based_rule_managed_keys/3","title":"AWS.WAF.get_rate_based_rule_managed_keys/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of IP addresses currently being blocked by the RateBasedRule that is specified by the RuleId. The maximum number of managed keys that will be blocked is 10,000. If more than 10,000 addresses exceed the rate limit, the 10,000 addresses with the highest rates will be blocked."},{"ref":"AWS.WAF.html#get_regex_match_set/3","title":"AWS.WAF.get_regex_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the RegexMatchSet specified by RegexMatchSetId."},{"ref":"AWS.WAF.html#get_regex_pattern_set/3","title":"AWS.WAF.get_regex_pattern_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the RegexPatternSet specified by RegexPatternSetId."},{"ref":"AWS.WAF.html#get_rule/3","title":"AWS.WAF.get_rule/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the Rule that is specified by the RuleId that you included in the GetRule request."},{"ref":"AWS.WAF.html#get_rule_group/3","title":"AWS.WAF.get_rule_group/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the RuleGroup that is specified by the RuleGroupId that you included in the GetRuleGroup request. To view the rules in a rule group, use ListActivatedRulesInRuleGroup."},{"ref":"AWS.WAF.html#get_sampled_requests/3","title":"AWS.WAF.get_sampled_requests/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Gets detailed information about a specified number of requests--a sample--that AWS WAF randomly selects from among the first 5,000 requests that your AWS resource received during a time range that you choose. You can specify a sample size of up to 500 requests, and you can specify any time range in the previous three hours. GetSampledRequests returns a time range, which is usually the time range that you specified. However, if your resource (such as a CloudFront distribution) received 5,000 requests before the specified time range elapsed, GetSampledRequests returns an updated time range. This new time range indicates the actual period during which AWS WAF selected the requests in the sample."},{"ref":"AWS.WAF.html#get_size_constraint_set/3","title":"AWS.WAF.get_size_constraint_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the SizeConstraintSet specified by SizeConstraintSetId."},{"ref":"AWS.WAF.html#get_sql_injection_match_set/3","title":"AWS.WAF.get_sql_injection_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the SqlInjectionMatchSet that is specified by SqlInjectionMatchSetId."},{"ref":"AWS.WAF.html#get_web_a_c_l/3","title":"AWS.WAF.get_web_a_c_l/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the WebACL that is specified by WebACLId."},{"ref":"AWS.WAF.html#get_xss_match_set/3","title":"AWS.WAF.get_xss_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the XssMatchSet that is specified by XssMatchSetId."},{"ref":"AWS.WAF.html#list_activated_rules_in_rule_group/3","title":"AWS.WAF.list_activated_rules_in_rule_group/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of ActivatedRule objects."},{"ref":"AWS.WAF.html#list_byte_match_sets/3","title":"AWS.WAF.list_byte_match_sets/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of ByteMatchSetSummary objects."},{"ref":"AWS.WAF.html#list_geo_match_sets/3","title":"AWS.WAF.list_geo_match_sets/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of GeoMatchSetSummary objects in the response."},{"ref":"AWS.WAF.html#list_i_p_sets/3","title":"AWS.WAF.list_i_p_sets/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of IPSetSummary objects in the response."},{"ref":"AWS.WAF.html#list_logging_configurations/3","title":"AWS.WAF.list_logging_configurations/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of LoggingConfiguration objects."},{"ref":"AWS.WAF.html#list_rate_based_rules/3","title":"AWS.WAF.list_rate_based_rules/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of RuleSummary objects."},{"ref":"AWS.WAF.html#list_regex_match_sets/3","title":"AWS.WAF.list_regex_match_sets/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of RegexMatchSetSummary objects."},{"ref":"AWS.WAF.html#list_regex_pattern_sets/3","title":"AWS.WAF.list_regex_pattern_sets/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of RegexPatternSetSummary objects."},{"ref":"AWS.WAF.html#list_rule_groups/3","title":"AWS.WAF.list_rule_groups/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of RuleGroup objects."},{"ref":"AWS.WAF.html#list_rules/3","title":"AWS.WAF.list_rules/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of RuleSummary objects."},{"ref":"AWS.WAF.html#list_size_constraint_sets/3","title":"AWS.WAF.list_size_constraint_sets/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of SizeConstraintSetSummary objects."},{"ref":"AWS.WAF.html#list_sql_injection_match_sets/3","title":"AWS.WAF.list_sql_injection_match_sets/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of SqlInjectionMatchSet objects."},{"ref":"AWS.WAF.html#list_subscribed_rule_groups/3","title":"AWS.WAF.list_subscribed_rule_groups/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of RuleGroup objects that you are subscribed to."},{"ref":"AWS.WAF.html#list_tags_for_resource/3","title":"AWS.WAF.list_tags_for_resource/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Retrieves the tags associated with the specified AWS resource. Tags are key:value pairs that you can use to categorize and manage your resources, for purposes like billing. For example, you might set the tag key to &quot;customer&quot; and the value to the customer name or ID. You can specify one or more tags to add to each AWS resource, up to 50 tags for a resource. Tagging is only available through the API, SDKs, and CLI. You can&#39;t manage or view tags through the AWS WAF Classic console. You can tag the AWS resources that you manage through AWS WAF Classic: web ACLs, rule groups, and rules."},{"ref":"AWS.WAF.html#list_web_a_c_ls/3","title":"AWS.WAF.list_web_a_c_ls/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of WebACLSummary objects in the response."},{"ref":"AWS.WAF.html#list_xss_match_sets/3","title":"AWS.WAF.list_xss_match_sets/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of XssMatchSet objects."},{"ref":"AWS.WAF.html#put_logging_configuration/3","title":"AWS.WAF.put_logging_configuration/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Associates a LoggingConfiguration with a specified web ACL. You can access information about all traffic that AWS WAF inspects using the following steps: Create an Amazon Kinesis Data Firehose. Create the data firehose with a PUT source and in the region that you are operating. However, if you are capturing logs for Amazon CloudFront, always create the firehose in US East (N. Virginia). Do not create the data firehose using a Kinesis stream as your source. Associate that firehose to your web ACL using a PutLoggingConfiguration request. When you successfully enable logging using a PutLoggingConfiguration request, AWS WAF will create a service linked role with the necessary permissions to write logs to the Amazon Kinesis Data Firehose. For more information, see Logging Web ACL Traffic Information in the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#put_permission_policy/3","title":"AWS.WAF.put_permission_policy/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Attaches an IAM policy to the specified resource. The only supported use for this action is to share a RuleGroup across accounts. The PutPermissionPolicy is subject to the following restrictions: You can attach only one policy with each PutPermissionPolicy request. The policy must include an Effect, Action and Principal. Effect must specify Allow. The Action in the policy must be waf:UpdateWebACL, waf-regional:UpdateWebACL, waf:GetRuleGroup and waf-regional:GetRuleGroup . Any extra or wildcard actions in the policy will be rejected. The policy cannot include a Resource parameter. The ARN in the request must be a valid WAF RuleGroup ARN and the RuleGroup must exist in the same region. The user making the request must be the owner of the RuleGroup. Your policy must be composed using IAM Policy version 2012-10-17. For more information, see IAM Policies. An example of a valid policy parameter is shown in the Examples section below."},{"ref":"AWS.WAF.html#tag_resource/3","title":"AWS.WAF.tag_resource/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Associates tags with the specified AWS resource. Tags are key:value pairs that you can use to categorize and manage your resources, for purposes like billing. For example, you might set the tag key to &quot;customer&quot; and the value to the customer name or ID. You can specify one or more tags to add to each AWS resource, up to 50 tags for a resource. Tagging is only available through the API, SDKs, and CLI. You can&#39;t manage or view tags through the AWS WAF Classic console. You can use this action to tag the AWS resources that you manage through AWS WAF Classic: web ACLs, rule groups, and rules."},{"ref":"AWS.WAF.html#untag_resource/3","title":"AWS.WAF.untag_resource/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use."},{"ref":"AWS.WAF.html#update_byte_match_set/3","title":"AWS.WAF.update_byte_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes ByteMatchTuple objects (filters) in a ByteMatchSet. For each ByteMatchTuple object, you specify the following values: Whether to insert or delete the object from the array. If you want to change a ByteMatchSetUpdate object, you delete the existing object and add a new one. The part of a web request that you want AWS WAF to inspect, such as a query string or the value of the User-Agent header. The bytes (typically a string that corresponds with ASCII characters) that you want AWS WAF to look for. For more information, including how you specify the values for the AWS WAF API and the AWS CLI or SDKs, see TargetString in the ByteMatchTuple data type. Where to look, such as at the beginning or the end of a query string. Whether to perform any conversions on the request, such as converting it to lowercase, before inspecting it for the specified string. For example, you can add a ByteMatchSetUpdate object that matches web requests in which User-Agent headers contain the string BadBot. You can then configure AWS WAF to block those requests. To create and configure a ByteMatchSet, perform the following steps: Create a ByteMatchSet. For more information, see CreateByteMatchSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateByteMatchSet request. Submit an UpdateByteMatchSet request to specify the part of the request that you want AWS WAF to inspect (for example, the header or the URI) and the value that you want AWS WAF to watch for. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#update_geo_match_set/3","title":"AWS.WAF.update_geo_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes GeoMatchConstraint objects in an GeoMatchSet. For each GeoMatchConstraint object, you specify the following values: Whether to insert or delete the object from the array. If you want to change an GeoMatchConstraint object, you delete the existing object and add a new one. The Type. The only valid value for Type is Country. The Value, which is a two character code for the country to add to the GeoMatchConstraint object. Valid codes are listed in GeoMatchConstraint$Value. To create and configure an GeoMatchSet, perform the following steps: Submit a CreateGeoMatchSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateGeoMatchSet request. Submit an UpdateGeoMatchSet request to specify the country that you want AWS WAF to watch for. When you update an GeoMatchSet, you specify the country that you want to add and/or the country that you want to delete. If you want to change a country, you delete the existing country and add the new one. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#update_i_p_set/3","title":"AWS.WAF.update_i_p_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes IPSetDescriptor objects in an IPSet. For each IPSetDescriptor object, you specify the following values: Whether to insert or delete the object from the array. If you want to change an IPSetDescriptor object, you delete the existing object and add a new one. The IP address version, IPv4 or IPv6. The IP address in CIDR notation, for example, 192.0.2.0/24 (for the range of IP addresses from 192.0.2.0 to 192.0.2.255) or 192.0.2.44/32 (for the individual IP address 192.0.2.44). AWS WAF supports IPv4 address ranges: /8 and any range between /16 through /32. AWS WAF supports IPv6 address ranges: /24, /32, /48, /56, /64, and /128. For more information about CIDR notation, see the Wikipedia entry Classless Inter-Domain Routing. IPv6 addresses can be represented using any of the following formats: 1111:0000:0000:0000:0000:0000:0000:0111/128 1111:0:0:0:0:0:0:0111/128 1111::0111/128 1111::111/128 You use an IPSet to specify which web requests you want to allow or block based on the IP addresses that the requests originated from. For example, if you&#39;re receiving a lot of requests from one or a small number of IP addresses and you want to block the requests, you can create an IPSet that specifies those IP addresses, and then configure AWS WAF to block the requests. To create and configure an IPSet, perform the following steps: Submit a CreateIPSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateIPSet request. Submit an UpdateIPSet request to specify the IP addresses that you want AWS WAF to watch for. When you update an IPSet, you specify the IP addresses that you want to add and/or the IP addresses that you want to delete. If you want to change an IP address, you delete the existing IP address and add the new one. You can insert a maximum of 1000 addresses in a single request. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#update_rate_based_rule/3","title":"AWS.WAF.update_rate_based_rule/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes Predicate objects in a rule and updates the RateLimit in the rule. Each Predicate object identifies a predicate, such as a ByteMatchSet or an IPSet, that specifies the web requests that you want to block or count. The RateLimit specifies the number of requests every five minutes that triggers the rule. If you add more than one predicate to a RateBasedRule, a request must match all the predicates and exceed the RateLimit to be counted or blocked. For example, suppose you add the following to a RateBasedRule: An IPSet that matches the IP address 192.0.2.44/32 A ByteMatchSet that matches BadBot in the User-Agent header Further, you specify a RateLimit of 1,000. You then add the RateBasedRule to a WebACL and specify that you want to block requests that satisfy the rule. For a request to be blocked, it must come from the IP address 192.0.2.44 and the User-Agent header in the request must contain the value BadBot. Further, requests that match these two conditions much be received at a rate of more than 1,000 every five minutes. If the rate drops below this limit, AWS WAF no longer blocks the requests. As a second example, suppose you want to limit requests to a particular page on your site. To do this, you could add the following to a RateBasedRule: A ByteMatchSet with FieldToMatch of URI A PositionalConstraint of STARTS_WITH A TargetString of login Further, you specify a RateLimit of 1,000. By adding this RateBasedRule to a WebACL, you could limit requests to your login page without affecting the rest of your site."},{"ref":"AWS.WAF.html#update_regex_match_set/3","title":"AWS.WAF.update_regex_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes RegexMatchTuple objects (filters) in a RegexMatchSet. For each RegexMatchSetUpdate object, you specify the following values: Whether to insert or delete the object from the array. If you want to change a RegexMatchSetUpdate object, you delete the existing object and add a new one. The part of a web request that you want AWS WAF to inspectupdate, such as a query string or the value of the User-Agent header. The identifier of the pattern (a regular expression) that you want AWS WAF to look for. For more information, see RegexPatternSet. Whether to perform any conversions on the request, such as converting it to lowercase, before inspecting it for the specified string. For example, you can create a RegexPatternSet that matches any requests with User-Agent headers that contain the string B[a@]dB[o0]t. You can then configure AWS WAF to reject those requests. To create and configure a RegexMatchSet, perform the following steps: Create a RegexMatchSet. For more information, see CreateRegexMatchSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateRegexMatchSet request. Submit an UpdateRegexMatchSet request to specify the part of the request that you want AWS WAF to inspect (for example, the header or the URI) and the identifier of the RegexPatternSet that contain the regular expression patters you want AWS WAF to watch for. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#update_regex_pattern_set/3","title":"AWS.WAF.update_regex_pattern_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes RegexPatternString objects in a RegexPatternSet. For each RegexPatternString object, you specify the following values: Whether to insert or delete the RegexPatternString. The regular expression pattern that you want to insert or delete. For more information, see RegexPatternSet. For example, you can create a RegexPatternString such as B[a@]dB[o0]t. AWS WAF will match this RegexPatternString to: BadBot BadB0t B@dBot B@dB0t To create and configure a RegexPatternSet, perform the following steps: Create a RegexPatternSet. For more information, see CreateRegexPatternSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateRegexPatternSet request. Submit an UpdateRegexPatternSet request to specify the regular expression pattern that you want AWS WAF to watch for. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#update_rule/3","title":"AWS.WAF.update_rule/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes Predicate objects in a Rule. Each Predicate object identifies a predicate, such as a ByteMatchSet or an IPSet, that specifies the web requests that you want to allow, block, or count. If you add more than one predicate to a Rule, a request must match all of the specifications to be allowed, blocked, or counted. For example, suppose that you add the following to a Rule: A ByteMatchSet that matches the value BadBot in the User-Agent header An IPSet that matches the IP address 192.0.2.44 You then add the Rule to a WebACL and specify that you want to block requests that satisfy the Rule. For a request to be blocked, the User-Agent header in the request must contain the value BadBot and the request must originate from the IP address 192.0.2.44. To create and configure a Rule, perform the following steps: Create and update the predicates that you want to include in the Rule. Create the Rule. See CreateRule. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateRule request. Submit an UpdateRule request to add predicates to the Rule. Create and update a WebACL that contains the Rule. See CreateWebACL. If you want to replace one ByteMatchSet or IPSet with another, you delete the existing one and add the new one. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#update_rule_group/3","title":"AWS.WAF.update_rule_group/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes ActivatedRule objects in a RuleGroup. You can only insert REGULAR rules into a rule group. You can have a maximum of ten rules per rule group. To create and configure a RuleGroup, perform the following steps: Create and update the Rules that you want to include in the RuleGroup. See CreateRule. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateRuleGroup request. Submit an UpdateRuleGroup request to add Rules to the RuleGroup. Create and update a WebACL that contains the RuleGroup. See CreateWebACL. If you want to replace one Rule with another, you delete the existing one and add the new one. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#update_size_constraint_set/3","title":"AWS.WAF.update_size_constraint_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes SizeConstraint objects (filters) in a SizeConstraintSet. For each SizeConstraint object, you specify the following values: Whether to insert or delete the object from the array. If you want to change a SizeConstraintSetUpdate object, you delete the existing object and add a new one. The part of a web request that you want AWS WAF to evaluate, such as the length of a query string or the length of the User-Agent header. Whether to perform any transformations on the request, such as converting it to lowercase, before checking its length. Note that transformations of the request body are not supported because the AWS resource forwards only the first 8192 bytes of your request to AWS WAF. You can only specify a single type of TextTransformation. A ComparisonOperator used for evaluating the selected part of the request against the specified Size, such as equals, greater than, less than, and so on. The length, in bytes, that you want AWS WAF to watch for in selected part of the request. The length is computed after applying the transformation. For example, you can add a SizeConstraintSetUpdate object that matches web requests in which the length of the User-Agent header is greater than 100 bytes. You can then configure AWS WAF to block those requests. To create and configure a SizeConstraintSet, perform the following steps: Create a SizeConstraintSet. For more information, see CreateSizeConstraintSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateSizeConstraintSet request. Submit an UpdateSizeConstraintSet request to specify the part of the request that you want AWS WAF to inspect (for example, the header or the URI) and the value that you want AWS WAF to watch for. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#update_sql_injection_match_set/3","title":"AWS.WAF.update_sql_injection_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes SqlInjectionMatchTuple objects (filters) in a SqlInjectionMatchSet. For each SqlInjectionMatchTuple object, you specify the following values: Action: Whether to insert the object into or delete the object from the array. To change a SqlInjectionMatchTuple, you delete the existing object and add a new one. FieldToMatch: The part of web requests that you want AWS WAF to inspect and, if you want AWS WAF to inspect a header or custom query parameter, the name of the header or parameter. TextTransformation: Which text transformation, if any, to perform on the web request before inspecting the request for snippets of malicious SQL code. You can only specify a single type of TextTransformation. You use SqlInjectionMatchSet objects to specify which CloudFront requests that you want to allow, block, or count. For example, if you&#39;re receiving requests that contain snippets of SQL code in the query string and you want to block the requests, you can create a SqlInjectionMatchSet with the applicable settings, and then configure AWS WAF to block the requests. To create and configure a SqlInjectionMatchSet, perform the following steps: Submit a CreateSqlInjectionMatchSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateIPSet request. Submit an UpdateSqlInjectionMatchSet request to specify the parts of web requests that you want AWS WAF to inspect for snippets of SQL code. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#update_web_a_c_l/3","title":"AWS.WAF.update_web_a_c_l/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes ActivatedRule objects in a WebACL. Each Rule identifies web requests that you want to allow, block, or count. When you update a WebACL, you specify the following values: A default action for the WebACL, either ALLOW or BLOCK. AWS WAF performs the default action if a request doesn&#39;t match the criteria in any of the Rules in a WebACL. The Rules that you want to add or delete. If you want to replace one Rule with another, you delete the existing Rule and add the new one. For each Rule, whether you want AWS WAF to allow requests, block requests, or count requests that match the conditions in the Rule. The order in which you want AWS WAF to evaluate the Rules in a WebACL. If you add more than one Rule to a WebACL, AWS WAF evaluates each request against the Rules in order based on the value of Priority. (The Rule that has the lowest value for Priority is evaluated first.) When a web request matches all the predicates (such as ByteMatchSets and IPSets) in a Rule, AWS WAF immediately takes the corresponding action, allow or block, and doesn&#39;t evaluate the request against the remaining Rules in the WebACL, if any. To create and configure a WebACL, perform the following steps: Create and update the predicates that you want to include in Rules. For more information, see CreateByteMatchSet, UpdateByteMatchSet, CreateIPSet, UpdateIPSet, CreateSqlInjectionMatchSet, and UpdateSqlInjectionMatchSet. Create and update the Rules that you want to include in the WebACL. For more information, see CreateRule and UpdateRule. Create a WebACL. See CreateWebACL. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateWebACL request. Submit an UpdateWebACL request to specify the Rules that you want to include in the WebACL, to specify the default action, and to associate the WebACL with a CloudFront distribution. The ActivatedRule can be a rule group. If you specify a rule group as your ActivatedRule , you can exclude specific rules from that rule group. If you already have a rule group associated with a web ACL and want to submit an UpdateWebACL request to exclude certain rules from that rule group, you must first remove the rule group from the web ACL, the re-insert it again, specifying the excluded rules. For details, see ActivatedRule$ExcludedRules . Be aware that if you try to add a RATE_BASED rule to a web ACL without setting the rule type when first creating the rule, the UpdateWebACL request will fail because the request tries to add a REGULAR rule (the default rule type) with the specified ID, which does not exist. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAF.html#update_xss_match_set/3","title":"AWS.WAF.update_xss_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes XssMatchTuple objects (filters) in an XssMatchSet. For each XssMatchTuple object, you specify the following values: Action: Whether to insert the object into or delete the object from the array. To change an XssMatchTuple, you delete the existing object and add a new one. FieldToMatch: The part of web requests that you want AWS WAF to inspect and, if you want AWS WAF to inspect a header or custom query parameter, the name of the header or parameter. TextTransformation: Which text transformation, if any, to perform on the web request before inspecting the request for cross-site scripting attacks. You can only specify a single type of TextTransformation. You use XssMatchSet objects to specify which CloudFront requests that you want to allow, block, or count. For example, if you&#39;re receiving requests that contain cross-site scripting attacks in the request body and you want to block the requests, you can create an XssMatchSet with the applicable settings, and then configure AWS WAF to block the requests. To create and configure an XssMatchSet, perform the following steps: Submit a CreateXssMatchSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateIPSet request. Submit an UpdateXssMatchSet request to specify the parts of web requests that you want AWS WAF to inspect for cross-site scripting attacks. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html","title":"AWS.WAFRegional","type":"module","doc":"This is AWS WAF Classic Regional documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. This is the AWS WAF Regional Classic API Reference for using AWS WAF Classic with the AWS resources, Elastic Load Balancing (ELB) Application Load Balancers and API Gateway APIs. The AWS WAF Classic actions and data types listed in the reference are available for protecting Elastic Load Balancing (ELB) Application Load Balancers and API Gateway APIs. You can use these actions and data types by means of the endpoints listed in AWS Regions and Endpoints. This guide is for developers who need detailed information about the AWS WAF Classic API actions, data types, and errors. For detailed information about AWS WAF Classic features and an overview of how to use the AWS WAF Classic API, see the AWS WAF Classic in the developer guide."},{"ref":"AWS.WAFRegional.html#associate_web_a_c_l/3","title":"AWS.WAFRegional.associate_web_a_c_l/3","type":"function","doc":"This is AWS WAF Classic Regional documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Associates a web ACL with a resource, either an application load balancer or Amazon API Gateway stage."},{"ref":"AWS.WAFRegional.html#create_byte_match_set/3","title":"AWS.WAFRegional.create_byte_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates a ByteMatchSet. You then use UpdateByteMatchSet to identify the part of a web request that you want AWS WAF to inspect, such as the values of the User-Agent header or the query string. For example, you can create a ByteMatchSet that matches any requests with User-Agent headers that contain the string BadBot. You can then configure AWS WAF to reject those requests. To create and configure a ByteMatchSet, perform the following steps: Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a CreateByteMatchSet request. Submit a CreateByteMatchSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateByteMatchSet request. Submit an UpdateByteMatchSet request to specify the part of the request that you want AWS WAF to inspect (for example, the header or the URI) and the value that you want AWS WAF to watch for. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#create_geo_match_set/3","title":"AWS.WAFRegional.create_geo_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates an GeoMatchSet, which you use to specify which web requests you want to allow or block based on the country that the requests originate from. For example, if you&#39;re receiving a lot of requests from one or more countries and you want to block the requests, you can create an GeoMatchSet that contains those countries and then configure AWS WAF to block the requests. To create and configure a GeoMatchSet, perform the following steps: Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a CreateGeoMatchSet request. Submit a CreateGeoMatchSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateGeoMatchSet request. Submit an UpdateGeoMatchSetSet request to specify the countries that you want AWS WAF to watch for. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#create_i_p_set/3","title":"AWS.WAFRegional.create_i_p_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates an IPSet, which you use to specify which web requests that you want to allow or block based on the IP addresses that the requests originate from. For example, if you&#39;re receiving a lot of requests from one or more individual IP addresses or one or more ranges of IP addresses and you want to block the requests, you can create an IPSet that contains those IP addresses and then configure AWS WAF to block the requests. To create and configure an IPSet, perform the following steps: Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a CreateIPSet request. Submit a CreateIPSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateIPSet request. Submit an UpdateIPSet request to specify the IP addresses that you want AWS WAF to watch for. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#create_rate_based_rule/3","title":"AWS.WAFRegional.create_rate_based_rule/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates a RateBasedRule. The RateBasedRule contains a RateLimit, which specifies the maximum number of requests that AWS WAF allows from a specified IP address in a five-minute period. The RateBasedRule also contains the IPSet objects, ByteMatchSet objects, and other predicates that identify the requests that you want to count or block if these requests exceed the RateLimit. If you add more than one predicate to a RateBasedRule, a request not only must exceed the RateLimit, but it also must match all the conditions to be counted or blocked. For example, suppose you add the following to a RateBasedRule: An IPSet that matches the IP address 192.0.2.44/32 A ByteMatchSet that matches BadBot in the User-Agent header Further, you specify a RateLimit of 1,000. You then add the RateBasedRule to a WebACL and specify that you want to block requests that meet the conditions in the rule. For a request to be blocked, it must come from the IP address 192.0.2.44 and the User-Agent header in the request must contain the value BadBot. Further, requests that match these two conditions must be received at a rate of more than 1,000 requests every five minutes. If both conditions are met and the rate is exceeded, AWS WAF blocks the requests. If the rate drops below 1,000 for a five-minute period, AWS WAF no longer blocks the requests. As a second example, suppose you want to limit requests to a particular page on your site. To do this, you could add the following to a RateBasedRule: A ByteMatchSet with FieldToMatch of URI A PositionalConstraint of STARTS_WITH A TargetString of login Further, you specify a RateLimit of 1,000. By adding this RateBasedRule to a WebACL, you could limit requests to your login page without affecting the rest of your site. To create and configure a RateBasedRule, perform the following steps: Create and update the predicates that you want to include in the rule. For more information, see CreateByteMatchSet, CreateIPSet, and CreateSqlInjectionMatchSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a CreateRule request. Submit a CreateRateBasedRule request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateRule request. Submit an UpdateRateBasedRule request to specify the predicates that you want to include in the rule. Create and update a WebACL that contains the RateBasedRule. For more information, see CreateWebACL. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#create_regex_match_set/3","title":"AWS.WAFRegional.create_regex_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates a RegexMatchSet. You then use UpdateRegexMatchSet to identify the part of a web request that you want AWS WAF to inspect, such as the values of the User-Agent header or the query string. For example, you can create a RegexMatchSet that contains a RegexMatchTuple that looks for any requests with User-Agent headers that match a RegexPatternSet with pattern B[a@]dB[o0]t. You can then configure AWS WAF to reject those requests. To create and configure a RegexMatchSet, perform the following steps: Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a CreateRegexMatchSet request. Submit a CreateRegexMatchSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateRegexMatchSet request. Submit an UpdateRegexMatchSet request to specify the part of the request that you want AWS WAF to inspect (for example, the header or the URI) and the value, using a RegexPatternSet, that you want AWS WAF to watch for. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#create_regex_pattern_set/3","title":"AWS.WAFRegional.create_regex_pattern_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates a RegexPatternSet. You then use UpdateRegexPatternSet to specify the regular expression (regex) pattern that you want AWS WAF to search for, such as B[a@]dB[o0]t. You can then configure AWS WAF to reject those requests. To create and configure a RegexPatternSet, perform the following steps: Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a CreateRegexPatternSet request. Submit a CreateRegexPatternSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateRegexPatternSet request. Submit an UpdateRegexPatternSet request to specify the string that you want AWS WAF to watch for. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#create_rule/3","title":"AWS.WAFRegional.create_rule/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates a Rule, which contains the IPSet objects, ByteMatchSet objects, and other predicates that identify the requests that you want to block. If you add more than one predicate to a Rule, a request must match all of the specifications to be allowed or blocked. For example, suppose that you add the following to a Rule: An IPSet that matches the IP address 192.0.2.44/32 A ByteMatchSet that matches BadBot in the User-Agent header You then add the Rule to a WebACL and specify that you want to blocks requests that satisfy the Rule. For a request to be blocked, it must come from the IP address 192.0.2.44 and the User-Agent header in the request must contain the value BadBot. To create and configure a Rule, perform the following steps: Create and update the predicates that you want to include in the Rule. For more information, see CreateByteMatchSet, CreateIPSet, and CreateSqlInjectionMatchSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a CreateRule request. Submit a CreateRule request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateRule request. Submit an UpdateRule request to specify the predicates that you want to include in the Rule. Create and update a WebACL that contains the Rule. For more information, see CreateWebACL. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#create_rule_group/3","title":"AWS.WAFRegional.create_rule_group/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates a RuleGroup. A rule group is a collection of predefined rules that you add to a web ACL. You use UpdateRuleGroup to add rules to the rule group. Rule groups are subject to the following limits: Three rule groups per account. You can request an increase to this limit by contacting customer support. One rule group per web ACL. Ten rules per rule group. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#create_size_constraint_set/3","title":"AWS.WAFRegional.create_size_constraint_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates a SizeConstraintSet. You then use UpdateSizeConstraintSet to identify the part of a web request that you want AWS WAF to check for length, such as the length of the User-Agent header or the length of the query string. For example, you can create a SizeConstraintSet that matches any requests that have a query string that is longer than 100 bytes. You can then configure AWS WAF to reject those requests. To create and configure a SizeConstraintSet, perform the following steps: Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a CreateSizeConstraintSet request. Submit a CreateSizeConstraintSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateSizeConstraintSet request. Submit an UpdateSizeConstraintSet request to specify the part of the request that you want AWS WAF to inspect (for example, the header or the URI) and the value that you want AWS WAF to watch for. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#create_sql_injection_match_set/3","title":"AWS.WAFRegional.create_sql_injection_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates a SqlInjectionMatchSet, which you use to allow, block, or count requests that contain snippets of SQL code in a specified part of web requests. AWS WAF searches for character sequences that are likely to be malicious strings. To create and configure a SqlInjectionMatchSet, perform the following steps: Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a CreateSqlInjectionMatchSet request. Submit a CreateSqlInjectionMatchSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateSqlInjectionMatchSet request. Submit an UpdateSqlInjectionMatchSet request to specify the parts of web requests in which you want to allow, block, or count malicious SQL code. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#create_web_a_c_l/3","title":"AWS.WAFRegional.create_web_a_c_l/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates a WebACL, which contains the Rules that identify the CloudFront web requests that you want to allow, block, or count. AWS WAF evaluates Rules in order based on the value of Priority for each Rule. You also specify a default action, either ALLOW or BLOCK. If a web request doesn&#39;t match any of the Rules in a WebACL, AWS WAF responds to the request with the default action. To create and configure a WebACL, perform the following steps: Create and update the ByteMatchSet objects and other predicates that you want to include in Rules. For more information, see CreateByteMatchSet, UpdateByteMatchSet, CreateIPSet, UpdateIPSet, CreateSqlInjectionMatchSet, and UpdateSqlInjectionMatchSet. Create and update the Rules that you want to include in the WebACL. For more information, see CreateRule and UpdateRule. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a CreateWebACL request. Submit a CreateWebACL request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateWebACL request. Submit an UpdateWebACL request to specify the Rules that you want to include in the WebACL, to specify the default action, and to associate the WebACL with a CloudFront distribution. For more information about how to use the AWS WAF API, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#create_web_a_c_l_migration_stack/3","title":"AWS.WAFRegional.create_web_a_c_l_migration_stack/3","type":"function","doc":"Creates an AWS CloudFormation WAFV2 template for the specified web ACL in the specified Amazon S3 bucket. Then, in CloudFormation, you create a stack from the template, to create the web ACL and its resources in AWS WAFV2. Use this to migrate your AWS WAF Classic web ACL to the latest version of AWS WAF. This is part of a larger migration procedure for web ACLs from AWS WAF Classic to the latest version of AWS WAF. For the full procedure, including caveats and manual steps to complete the migration and switch over to the new web ACL, see Migrating your AWS WAF Classic resources to AWS WAF in the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#create_xss_match_set/3","title":"AWS.WAFRegional.create_xss_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Creates an XssMatchSet, which you use to allow, block, or count requests that contain cross-site scripting attacks in the specified part of web requests. AWS WAF searches for character sequences that are likely to be malicious strings. To create and configure an XssMatchSet, perform the following steps: Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a CreateXssMatchSet request. Submit a CreateXssMatchSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateXssMatchSet request. Submit an UpdateXssMatchSet request to specify the parts of web requests in which you want to allow, block, or count cross-site scripting attacks. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#delete_byte_match_set/3","title":"AWS.WAFRegional.delete_byte_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes a ByteMatchSet. You can&#39;t delete a ByteMatchSet if it&#39;s still used in any Rules or if it still includes any ByteMatchTuple objects (any filters). If you just want to remove a ByteMatchSet from a Rule, use UpdateRule. To permanently delete a ByteMatchSet, perform the following steps: Update the ByteMatchSet to remove filters, if any. For more information, see UpdateByteMatchSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a DeleteByteMatchSet request. Submit a DeleteByteMatchSet request."},{"ref":"AWS.WAFRegional.html#delete_geo_match_set/3","title":"AWS.WAFRegional.delete_geo_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes a GeoMatchSet. You can&#39;t delete a GeoMatchSet if it&#39;s still used in any Rules or if it still includes any countries. If you just want to remove a GeoMatchSet from a Rule, use UpdateRule. To permanently delete a GeoMatchSet from AWS WAF, perform the following steps: Update the GeoMatchSet to remove any countries. For more information, see UpdateGeoMatchSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a DeleteGeoMatchSet request. Submit a DeleteGeoMatchSet request."},{"ref":"AWS.WAFRegional.html#delete_i_p_set/3","title":"AWS.WAFRegional.delete_i_p_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes an IPSet. You can&#39;t delete an IPSet if it&#39;s still used in any Rules or if it still includes any IP addresses. If you just want to remove an IPSet from a Rule, use UpdateRule. To permanently delete an IPSet from AWS WAF, perform the following steps: Update the IPSet to remove IP address ranges, if any. For more information, see UpdateIPSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a DeleteIPSet request. Submit a DeleteIPSet request."},{"ref":"AWS.WAFRegional.html#delete_logging_configuration/3","title":"AWS.WAFRegional.delete_logging_configuration/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes the LoggingConfiguration from the specified web ACL."},{"ref":"AWS.WAFRegional.html#delete_permission_policy/3","title":"AWS.WAFRegional.delete_permission_policy/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes an IAM policy from the specified RuleGroup. The user making the request must be the owner of the RuleGroup."},{"ref":"AWS.WAFRegional.html#delete_rate_based_rule/3","title":"AWS.WAFRegional.delete_rate_based_rule/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes a RateBasedRule. You can&#39;t delete a rule if it&#39;s still used in any WebACL objects or if it still includes any predicates, such as ByteMatchSet objects. If you just want to remove a rule from a WebACL, use UpdateWebACL. To permanently delete a RateBasedRule from AWS WAF, perform the following steps: Update the RateBasedRule to remove predicates, if any. For more information, see UpdateRateBasedRule. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a DeleteRateBasedRule request. Submit a DeleteRateBasedRule request."},{"ref":"AWS.WAFRegional.html#delete_regex_match_set/3","title":"AWS.WAFRegional.delete_regex_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes a RegexMatchSet. You can&#39;t delete a RegexMatchSet if it&#39;s still used in any Rules or if it still includes any RegexMatchTuples objects (any filters). If you just want to remove a RegexMatchSet from a Rule, use UpdateRule. To permanently delete a RegexMatchSet, perform the following steps: Update the RegexMatchSet to remove filters, if any. For more information, see UpdateRegexMatchSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a DeleteRegexMatchSet request. Submit a DeleteRegexMatchSet request."},{"ref":"AWS.WAFRegional.html#delete_regex_pattern_set/3","title":"AWS.WAFRegional.delete_regex_pattern_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes a RegexPatternSet. You can&#39;t delete a RegexPatternSet if it&#39;s still used in any RegexMatchSet or if the RegexPatternSet is not empty."},{"ref":"AWS.WAFRegional.html#delete_rule/3","title":"AWS.WAFRegional.delete_rule/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes a Rule. You can&#39;t delete a Rule if it&#39;s still used in any WebACL objects or if it still includes any predicates, such as ByteMatchSet objects. If you just want to remove a Rule from a WebACL, use UpdateWebACL. To permanently delete a Rule from AWS WAF, perform the following steps: Update the Rule to remove predicates, if any. For more information, see UpdateRule. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a DeleteRule request. Submit a DeleteRule request."},{"ref":"AWS.WAFRegional.html#delete_rule_group/3","title":"AWS.WAFRegional.delete_rule_group/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes a RuleGroup. You can&#39;t delete a RuleGroup if it&#39;s still used in any WebACL objects or if it still includes any rules. If you just want to remove a RuleGroup from a WebACL, use UpdateWebACL. To permanently delete a RuleGroup from AWS WAF, perform the following steps: Update the RuleGroup to remove rules, if any. For more information, see UpdateRuleGroup. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a DeleteRuleGroup request. Submit a DeleteRuleGroup request."},{"ref":"AWS.WAFRegional.html#delete_size_constraint_set/3","title":"AWS.WAFRegional.delete_size_constraint_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes a SizeConstraintSet. You can&#39;t delete a SizeConstraintSet if it&#39;s still used in any Rules or if it still includes any SizeConstraint objects (any filters). If you just want to remove a SizeConstraintSet from a Rule, use UpdateRule. To permanently delete a SizeConstraintSet, perform the following steps: Update the SizeConstraintSet to remove filters, if any. For more information, see UpdateSizeConstraintSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a DeleteSizeConstraintSet request. Submit a DeleteSizeConstraintSet request."},{"ref":"AWS.WAFRegional.html#delete_sql_injection_match_set/3","title":"AWS.WAFRegional.delete_sql_injection_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes a SqlInjectionMatchSet. You can&#39;t delete a SqlInjectionMatchSet if it&#39;s still used in any Rules or if it still contains any SqlInjectionMatchTuple objects. If you just want to remove a SqlInjectionMatchSet from a Rule, use UpdateRule. To permanently delete a SqlInjectionMatchSet from AWS WAF, perform the following steps: Update the SqlInjectionMatchSet to remove filters, if any. For more information, see UpdateSqlInjectionMatchSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a DeleteSqlInjectionMatchSet request. Submit a DeleteSqlInjectionMatchSet request."},{"ref":"AWS.WAFRegional.html#delete_web_a_c_l/3","title":"AWS.WAFRegional.delete_web_a_c_l/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes a WebACL. You can&#39;t delete a WebACL if it still contains any Rules. To delete a WebACL, perform the following steps: Update the WebACL to remove Rules, if any. For more information, see UpdateWebACL. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a DeleteWebACL request. Submit a DeleteWebACL request."},{"ref":"AWS.WAFRegional.html#delete_xss_match_set/3","title":"AWS.WAFRegional.delete_xss_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Permanently deletes an XssMatchSet. You can&#39;t delete an XssMatchSet if it&#39;s still used in any Rules or if it still contains any XssMatchTuple objects. If you just want to remove an XssMatchSet from a Rule, use UpdateRule. To permanently delete an XssMatchSet from AWS WAF, perform the following steps: Update the XssMatchSet to remove filters, if any. For more information, see UpdateXssMatchSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of a DeleteXssMatchSet request. Submit a DeleteXssMatchSet request."},{"ref":"AWS.WAFRegional.html#disassociate_web_a_c_l/3","title":"AWS.WAFRegional.disassociate_web_a_c_l/3","type":"function","doc":"This is AWS WAF Classic Regional documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Removes a web ACL from the specified resource, either an application load balancer or Amazon API Gateway stage."},{"ref":"AWS.WAFRegional.html#get_byte_match_set/3","title":"AWS.WAFRegional.get_byte_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the ByteMatchSet specified by ByteMatchSetId."},{"ref":"AWS.WAFRegional.html#get_change_token/3","title":"AWS.WAFRegional.get_change_token/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. When you want to create, update, or delete AWS WAF objects, get a change token and include the change token in the create, update, or delete request. Change tokens ensure that your application doesn&#39;t submit conflicting requests to AWS WAF. Each create, update, or delete request must use a unique change token. If your application submits a GetChangeToken request and then submits a second GetChangeToken request before submitting a create, update, or delete request, the second GetChangeToken request returns the same value as the first GetChangeToken request. When you use a change token in a create, update, or delete request, the status of the change token changes to PENDING, which indicates that AWS WAF is propagating the change to all AWS WAF servers. Use GetChangeTokenStatus to determine the status of your change token."},{"ref":"AWS.WAFRegional.html#get_change_token_status/3","title":"AWS.WAFRegional.get_change_token_status/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the status of a ChangeToken that you got by calling GetChangeToken. ChangeTokenStatus is one of the following values: PROVISIONED: You requested the change token by calling GetChangeToken, but you haven&#39;t used it yet in a call to create, update, or delete an AWS WAF object. PENDING: AWS WAF is propagating the create, update, or delete request to all AWS WAF servers. INSYNC: Propagation is complete."},{"ref":"AWS.WAFRegional.html#get_geo_match_set/3","title":"AWS.WAFRegional.get_geo_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the GeoMatchSet that is specified by GeoMatchSetId."},{"ref":"AWS.WAFRegional.html#get_i_p_set/3","title":"AWS.WAFRegional.get_i_p_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the IPSet that is specified by IPSetId."},{"ref":"AWS.WAFRegional.html#get_logging_configuration/3","title":"AWS.WAFRegional.get_logging_configuration/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the LoggingConfiguration for the specified web ACL."},{"ref":"AWS.WAFRegional.html#get_permission_policy/3","title":"AWS.WAFRegional.get_permission_policy/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the IAM policy attached to the RuleGroup."},{"ref":"AWS.WAFRegional.html#get_rate_based_rule/3","title":"AWS.WAFRegional.get_rate_based_rule/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the RateBasedRule that is specified by the RuleId that you included in the GetRateBasedRule request."},{"ref":"AWS.WAFRegional.html#get_rate_based_rule_managed_keys/3","title":"AWS.WAFRegional.get_rate_based_rule_managed_keys/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of IP addresses currently being blocked by the RateBasedRule that is specified by the RuleId. The maximum number of managed keys that will be blocked is 10,000. If more than 10,000 addresses exceed the rate limit, the 10,000 addresses with the highest rates will be blocked."},{"ref":"AWS.WAFRegional.html#get_regex_match_set/3","title":"AWS.WAFRegional.get_regex_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the RegexMatchSet specified by RegexMatchSetId."},{"ref":"AWS.WAFRegional.html#get_regex_pattern_set/3","title":"AWS.WAFRegional.get_regex_pattern_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the RegexPatternSet specified by RegexPatternSetId."},{"ref":"AWS.WAFRegional.html#get_rule/3","title":"AWS.WAFRegional.get_rule/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the Rule that is specified by the RuleId that you included in the GetRule request."},{"ref":"AWS.WAFRegional.html#get_rule_group/3","title":"AWS.WAFRegional.get_rule_group/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the RuleGroup that is specified by the RuleGroupId that you included in the GetRuleGroup request. To view the rules in a rule group, use ListActivatedRulesInRuleGroup."},{"ref":"AWS.WAFRegional.html#get_sampled_requests/3","title":"AWS.WAFRegional.get_sampled_requests/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Gets detailed information about a specified number of requests--a sample--that AWS WAF randomly selects from among the first 5,000 requests that your AWS resource received during a time range that you choose. You can specify a sample size of up to 500 requests, and you can specify any time range in the previous three hours. GetSampledRequests returns a time range, which is usually the time range that you specified. However, if your resource (such as a CloudFront distribution) received 5,000 requests before the specified time range elapsed, GetSampledRequests returns an updated time range. This new time range indicates the actual period during which AWS WAF selected the requests in the sample."},{"ref":"AWS.WAFRegional.html#get_size_constraint_set/3","title":"AWS.WAFRegional.get_size_constraint_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the SizeConstraintSet specified by SizeConstraintSetId."},{"ref":"AWS.WAFRegional.html#get_sql_injection_match_set/3","title":"AWS.WAFRegional.get_sql_injection_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the SqlInjectionMatchSet that is specified by SqlInjectionMatchSetId."},{"ref":"AWS.WAFRegional.html#get_web_a_c_l/3","title":"AWS.WAFRegional.get_web_a_c_l/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the WebACL that is specified by WebACLId."},{"ref":"AWS.WAFRegional.html#get_web_a_c_l_for_resource/3","title":"AWS.WAFRegional.get_web_a_c_l_for_resource/3","type":"function","doc":"This is AWS WAF Classic Regional documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the web ACL for the specified resource, either an application load balancer or Amazon API Gateway stage."},{"ref":"AWS.WAFRegional.html#get_xss_match_set/3","title":"AWS.WAFRegional.get_xss_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns the XssMatchSet that is specified by XssMatchSetId."},{"ref":"AWS.WAFRegional.html#list_activated_rules_in_rule_group/3","title":"AWS.WAFRegional.list_activated_rules_in_rule_group/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of ActivatedRule objects."},{"ref":"AWS.WAFRegional.html#list_byte_match_sets/3","title":"AWS.WAFRegional.list_byte_match_sets/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of ByteMatchSetSummary objects."},{"ref":"AWS.WAFRegional.html#list_geo_match_sets/3","title":"AWS.WAFRegional.list_geo_match_sets/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of GeoMatchSetSummary objects in the response."},{"ref":"AWS.WAFRegional.html#list_i_p_sets/3","title":"AWS.WAFRegional.list_i_p_sets/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of IPSetSummary objects in the response."},{"ref":"AWS.WAFRegional.html#list_logging_configurations/3","title":"AWS.WAFRegional.list_logging_configurations/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of LoggingConfiguration objects."},{"ref":"AWS.WAFRegional.html#list_rate_based_rules/3","title":"AWS.WAFRegional.list_rate_based_rules/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of RuleSummary objects."},{"ref":"AWS.WAFRegional.html#list_regex_match_sets/3","title":"AWS.WAFRegional.list_regex_match_sets/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of RegexMatchSetSummary objects."},{"ref":"AWS.WAFRegional.html#list_regex_pattern_sets/3","title":"AWS.WAFRegional.list_regex_pattern_sets/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of RegexPatternSetSummary objects."},{"ref":"AWS.WAFRegional.html#list_resources_for_web_a_c_l/3","title":"AWS.WAFRegional.list_resources_for_web_a_c_l/3","type":"function","doc":"This is AWS WAF Classic Regional documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of resources associated with the specified web ACL."},{"ref":"AWS.WAFRegional.html#list_rule_groups/3","title":"AWS.WAFRegional.list_rule_groups/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of RuleGroup objects."},{"ref":"AWS.WAFRegional.html#list_rules/3","title":"AWS.WAFRegional.list_rules/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of RuleSummary objects."},{"ref":"AWS.WAFRegional.html#list_size_constraint_sets/3","title":"AWS.WAFRegional.list_size_constraint_sets/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of SizeConstraintSetSummary objects."},{"ref":"AWS.WAFRegional.html#list_sql_injection_match_sets/3","title":"AWS.WAFRegional.list_sql_injection_match_sets/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of SqlInjectionMatchSet objects."},{"ref":"AWS.WAFRegional.html#list_subscribed_rule_groups/3","title":"AWS.WAFRegional.list_subscribed_rule_groups/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of RuleGroup objects that you are subscribed to."},{"ref":"AWS.WAFRegional.html#list_tags_for_resource/3","title":"AWS.WAFRegional.list_tags_for_resource/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Retrieves the tags associated with the specified AWS resource. Tags are key:value pairs that you can use to categorize and manage your resources, for purposes like billing. For example, you might set the tag key to &quot;customer&quot; and the value to the customer name or ID. You can specify one or more tags to add to each AWS resource, up to 50 tags for a resource. Tagging is only available through the API, SDKs, and CLI. You can&#39;t manage or view tags through the AWS WAF Classic console. You can tag the AWS resources that you manage through AWS WAF Classic: web ACLs, rule groups, and rules."},{"ref":"AWS.WAFRegional.html#list_web_a_c_ls/3","title":"AWS.WAFRegional.list_web_a_c_ls/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of WebACLSummary objects in the response."},{"ref":"AWS.WAFRegional.html#list_xss_match_sets/3","title":"AWS.WAFRegional.list_xss_match_sets/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Returns an array of XssMatchSet objects."},{"ref":"AWS.WAFRegional.html#put_logging_configuration/3","title":"AWS.WAFRegional.put_logging_configuration/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Associates a LoggingConfiguration with a specified web ACL. You can access information about all traffic that AWS WAF inspects using the following steps: Create an Amazon Kinesis Data Firehose. Create the data firehose with a PUT source and in the region that you are operating. However, if you are capturing logs for Amazon CloudFront, always create the firehose in US East (N. Virginia). Do not create the data firehose using a Kinesis stream as your source. Associate that firehose to your web ACL using a PutLoggingConfiguration request. When you successfully enable logging using a PutLoggingConfiguration request, AWS WAF will create a service linked role with the necessary permissions to write logs to the Amazon Kinesis Data Firehose. For more information, see Logging Web ACL Traffic Information in the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#put_permission_policy/3","title":"AWS.WAFRegional.put_permission_policy/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Attaches an IAM policy to the specified resource. The only supported use for this action is to share a RuleGroup across accounts. The PutPermissionPolicy is subject to the following restrictions: You can attach only one policy with each PutPermissionPolicy request. The policy must include an Effect, Action and Principal. Effect must specify Allow. The Action in the policy must be waf:UpdateWebACL, waf-regional:UpdateWebACL, waf:GetRuleGroup and waf-regional:GetRuleGroup . Any extra or wildcard actions in the policy will be rejected. The policy cannot include a Resource parameter. The ARN in the request must be a valid WAF RuleGroup ARN and the RuleGroup must exist in the same region. The user making the request must be the owner of the RuleGroup. Your policy must be composed using IAM Policy version 2012-10-17. For more information, see IAM Policies. An example of a valid policy parameter is shown in the Examples section below."},{"ref":"AWS.WAFRegional.html#tag_resource/3","title":"AWS.WAFRegional.tag_resource/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Associates tags with the specified AWS resource. Tags are key:value pairs that you can use to categorize and manage your resources, for purposes like billing. For example, you might set the tag key to &quot;customer&quot; and the value to the customer name or ID. You can specify one or more tags to add to each AWS resource, up to 50 tags for a resource. Tagging is only available through the API, SDKs, and CLI. You can&#39;t manage or view tags through the AWS WAF Classic console. You can use this action to tag the AWS resources that you manage through AWS WAF Classic: web ACLs, rule groups, and rules."},{"ref":"AWS.WAFRegional.html#untag_resource/3","title":"AWS.WAFRegional.untag_resource/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use."},{"ref":"AWS.WAFRegional.html#update_byte_match_set/3","title":"AWS.WAFRegional.update_byte_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes ByteMatchTuple objects (filters) in a ByteMatchSet. For each ByteMatchTuple object, you specify the following values: Whether to insert or delete the object from the array. If you want to change a ByteMatchSetUpdate object, you delete the existing object and add a new one. The part of a web request that you want AWS WAF to inspect, such as a query string or the value of the User-Agent header. The bytes (typically a string that corresponds with ASCII characters) that you want AWS WAF to look for. For more information, including how you specify the values for the AWS WAF API and the AWS CLI or SDKs, see TargetString in the ByteMatchTuple data type. Where to look, such as at the beginning or the end of a query string. Whether to perform any conversions on the request, such as converting it to lowercase, before inspecting it for the specified string. For example, you can add a ByteMatchSetUpdate object that matches web requests in which User-Agent headers contain the string BadBot. You can then configure AWS WAF to block those requests. To create and configure a ByteMatchSet, perform the following steps: Create a ByteMatchSet. For more information, see CreateByteMatchSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateByteMatchSet request. Submit an UpdateByteMatchSet request to specify the part of the request that you want AWS WAF to inspect (for example, the header or the URI) and the value that you want AWS WAF to watch for. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#update_geo_match_set/3","title":"AWS.WAFRegional.update_geo_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes GeoMatchConstraint objects in an GeoMatchSet. For each GeoMatchConstraint object, you specify the following values: Whether to insert or delete the object from the array. If you want to change an GeoMatchConstraint object, you delete the existing object and add a new one. The Type. The only valid value for Type is Country. The Value, which is a two character code for the country to add to the GeoMatchConstraint object. Valid codes are listed in GeoMatchConstraint$Value. To create and configure an GeoMatchSet, perform the following steps: Submit a CreateGeoMatchSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateGeoMatchSet request. Submit an UpdateGeoMatchSet request to specify the country that you want AWS WAF to watch for. When you update an GeoMatchSet, you specify the country that you want to add and/or the country that you want to delete. If you want to change a country, you delete the existing country and add the new one. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#update_i_p_set/3","title":"AWS.WAFRegional.update_i_p_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes IPSetDescriptor objects in an IPSet. For each IPSetDescriptor object, you specify the following values: Whether to insert or delete the object from the array. If you want to change an IPSetDescriptor object, you delete the existing object and add a new one. The IP address version, IPv4 or IPv6. The IP address in CIDR notation, for example, 192.0.2.0/24 (for the range of IP addresses from 192.0.2.0 to 192.0.2.255) or 192.0.2.44/32 (for the individual IP address 192.0.2.44). AWS WAF supports IPv4 address ranges: /8 and any range between /16 through /32. AWS WAF supports IPv6 address ranges: /24, /32, /48, /56, /64, and /128. For more information about CIDR notation, see the Wikipedia entry Classless Inter-Domain Routing. IPv6 addresses can be represented using any of the following formats: 1111:0000:0000:0000:0000:0000:0000:0111/128 1111:0:0:0:0:0:0:0111/128 1111::0111/128 1111::111/128 You use an IPSet to specify which web requests you want to allow or block based on the IP addresses that the requests originated from. For example, if you&#39;re receiving a lot of requests from one or a small number of IP addresses and you want to block the requests, you can create an IPSet that specifies those IP addresses, and then configure AWS WAF to block the requests. To create and configure an IPSet, perform the following steps: Submit a CreateIPSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateIPSet request. Submit an UpdateIPSet request to specify the IP addresses that you want AWS WAF to watch for. When you update an IPSet, you specify the IP addresses that you want to add and/or the IP addresses that you want to delete. If you want to change an IP address, you delete the existing IP address and add the new one. You can insert a maximum of 1000 addresses in a single request. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#update_rate_based_rule/3","title":"AWS.WAFRegional.update_rate_based_rule/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes Predicate objects in a rule and updates the RateLimit in the rule. Each Predicate object identifies a predicate, such as a ByteMatchSet or an IPSet, that specifies the web requests that you want to block or count. The RateLimit specifies the number of requests every five minutes that triggers the rule. If you add more than one predicate to a RateBasedRule, a request must match all the predicates and exceed the RateLimit to be counted or blocked. For example, suppose you add the following to a RateBasedRule: An IPSet that matches the IP address 192.0.2.44/32 A ByteMatchSet that matches BadBot in the User-Agent header Further, you specify a RateLimit of 1,000. You then add the RateBasedRule to a WebACL and specify that you want to block requests that satisfy the rule. For a request to be blocked, it must come from the IP address 192.0.2.44 and the User-Agent header in the request must contain the value BadBot. Further, requests that match these two conditions much be received at a rate of more than 1,000 every five minutes. If the rate drops below this limit, AWS WAF no longer blocks the requests. As a second example, suppose you want to limit requests to a particular page on your site. To do this, you could add the following to a RateBasedRule: A ByteMatchSet with FieldToMatch of URI A PositionalConstraint of STARTS_WITH A TargetString of login Further, you specify a RateLimit of 1,000. By adding this RateBasedRule to a WebACL, you could limit requests to your login page without affecting the rest of your site."},{"ref":"AWS.WAFRegional.html#update_regex_match_set/3","title":"AWS.WAFRegional.update_regex_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes RegexMatchTuple objects (filters) in a RegexMatchSet. For each RegexMatchSetUpdate object, you specify the following values: Whether to insert or delete the object from the array. If you want to change a RegexMatchSetUpdate object, you delete the existing object and add a new one. The part of a web request that you want AWS WAF to inspectupdate, such as a query string or the value of the User-Agent header. The identifier of the pattern (a regular expression) that you want AWS WAF to look for. For more information, see RegexPatternSet. Whether to perform any conversions on the request, such as converting it to lowercase, before inspecting it for the specified string. For example, you can create a RegexPatternSet that matches any requests with User-Agent headers that contain the string B[a@]dB[o0]t. You can then configure AWS WAF to reject those requests. To create and configure a RegexMatchSet, perform the following steps: Create a RegexMatchSet. For more information, see CreateRegexMatchSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateRegexMatchSet request. Submit an UpdateRegexMatchSet request to specify the part of the request that you want AWS WAF to inspect (for example, the header or the URI) and the identifier of the RegexPatternSet that contain the regular expression patters you want AWS WAF to watch for. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#update_regex_pattern_set/3","title":"AWS.WAFRegional.update_regex_pattern_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes RegexPatternString objects in a RegexPatternSet. For each RegexPatternString object, you specify the following values: Whether to insert or delete the RegexPatternString. The regular expression pattern that you want to insert or delete. For more information, see RegexPatternSet. For example, you can create a RegexPatternString such as B[a@]dB[o0]t. AWS WAF will match this RegexPatternString to: BadBot BadB0t B@dBot B@dB0t To create and configure a RegexPatternSet, perform the following steps: Create a RegexPatternSet. For more information, see CreateRegexPatternSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateRegexPatternSet request. Submit an UpdateRegexPatternSet request to specify the regular expression pattern that you want AWS WAF to watch for. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#update_rule/3","title":"AWS.WAFRegional.update_rule/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes Predicate objects in a Rule. Each Predicate object identifies a predicate, such as a ByteMatchSet or an IPSet, that specifies the web requests that you want to allow, block, or count. If you add more than one predicate to a Rule, a request must match all of the specifications to be allowed, blocked, or counted. For example, suppose that you add the following to a Rule: A ByteMatchSet that matches the value BadBot in the User-Agent header An IPSet that matches the IP address 192.0.2.44 You then add the Rule to a WebACL and specify that you want to block requests that satisfy the Rule. For a request to be blocked, the User-Agent header in the request must contain the value BadBot and the request must originate from the IP address 192.0.2.44. To create and configure a Rule, perform the following steps: Create and update the predicates that you want to include in the Rule. Create the Rule. See CreateRule. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateRule request. Submit an UpdateRule request to add predicates to the Rule. Create and update a WebACL that contains the Rule. See CreateWebACL. If you want to replace one ByteMatchSet or IPSet with another, you delete the existing one and add the new one. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#update_rule_group/3","title":"AWS.WAFRegional.update_rule_group/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes ActivatedRule objects in a RuleGroup. You can only insert REGULAR rules into a rule group. You can have a maximum of ten rules per rule group. To create and configure a RuleGroup, perform the following steps: Create and update the Rules that you want to include in the RuleGroup. See CreateRule. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateRuleGroup request. Submit an UpdateRuleGroup request to add Rules to the RuleGroup. Create and update a WebACL that contains the RuleGroup. See CreateWebACL. If you want to replace one Rule with another, you delete the existing one and add the new one. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#update_size_constraint_set/3","title":"AWS.WAFRegional.update_size_constraint_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes SizeConstraint objects (filters) in a SizeConstraintSet. For each SizeConstraint object, you specify the following values: Whether to insert or delete the object from the array. If you want to change a SizeConstraintSetUpdate object, you delete the existing object and add a new one. The part of a web request that you want AWS WAF to evaluate, such as the length of a query string or the length of the User-Agent header. Whether to perform any transformations on the request, such as converting it to lowercase, before checking its length. Note that transformations of the request body are not supported because the AWS resource forwards only the first 8192 bytes of your request to AWS WAF. You can only specify a single type of TextTransformation. A ComparisonOperator used for evaluating the selected part of the request against the specified Size, such as equals, greater than, less than, and so on. The length, in bytes, that you want AWS WAF to watch for in selected part of the request. The length is computed after applying the transformation. For example, you can add a SizeConstraintSetUpdate object that matches web requests in which the length of the User-Agent header is greater than 100 bytes. You can then configure AWS WAF to block those requests. To create and configure a SizeConstraintSet, perform the following steps: Create a SizeConstraintSet. For more information, see CreateSizeConstraintSet. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateSizeConstraintSet request. Submit an UpdateSizeConstraintSet request to specify the part of the request that you want AWS WAF to inspect (for example, the header or the URI) and the value that you want AWS WAF to watch for. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#update_sql_injection_match_set/3","title":"AWS.WAFRegional.update_sql_injection_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes SqlInjectionMatchTuple objects (filters) in a SqlInjectionMatchSet. For each SqlInjectionMatchTuple object, you specify the following values: Action: Whether to insert the object into or delete the object from the array. To change a SqlInjectionMatchTuple, you delete the existing object and add a new one. FieldToMatch: The part of web requests that you want AWS WAF to inspect and, if you want AWS WAF to inspect a header or custom query parameter, the name of the header or parameter. TextTransformation: Which text transformation, if any, to perform on the web request before inspecting the request for snippets of malicious SQL code. You can only specify a single type of TextTransformation. You use SqlInjectionMatchSet objects to specify which CloudFront requests that you want to allow, block, or count. For example, if you&#39;re receiving requests that contain snippets of SQL code in the query string and you want to block the requests, you can create a SqlInjectionMatchSet with the applicable settings, and then configure AWS WAF to block the requests. To create and configure a SqlInjectionMatchSet, perform the following steps: Submit a CreateSqlInjectionMatchSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateIPSet request. Submit an UpdateSqlInjectionMatchSet request to specify the parts of web requests that you want AWS WAF to inspect for snippets of SQL code. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#update_web_a_c_l/3","title":"AWS.WAFRegional.update_web_a_c_l/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes ActivatedRule objects in a WebACL. Each Rule identifies web requests that you want to allow, block, or count. When you update a WebACL, you specify the following values: A default action for the WebACL, either ALLOW or BLOCK. AWS WAF performs the default action if a request doesn&#39;t match the criteria in any of the Rules in a WebACL. The Rules that you want to add or delete. If you want to replace one Rule with another, you delete the existing Rule and add the new one. For each Rule, whether you want AWS WAF to allow requests, block requests, or count requests that match the conditions in the Rule. The order in which you want AWS WAF to evaluate the Rules in a WebACL. If you add more than one Rule to a WebACL, AWS WAF evaluates each request against the Rules in order based on the value of Priority. (The Rule that has the lowest value for Priority is evaluated first.) When a web request matches all the predicates (such as ByteMatchSets and IPSets) in a Rule, AWS WAF immediately takes the corresponding action, allow or block, and doesn&#39;t evaluate the request against the remaining Rules in the WebACL, if any. To create and configure a WebACL, perform the following steps: Create and update the predicates that you want to include in Rules. For more information, see CreateByteMatchSet, UpdateByteMatchSet, CreateIPSet, UpdateIPSet, CreateSqlInjectionMatchSet, and UpdateSqlInjectionMatchSet. Create and update the Rules that you want to include in the WebACL. For more information, see CreateRule and UpdateRule. Create a WebACL. See CreateWebACL. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateWebACL request. Submit an UpdateWebACL request to specify the Rules that you want to include in the WebACL, to specify the default action, and to associate the WebACL with a CloudFront distribution. The ActivatedRule can be a rule group. If you specify a rule group as your ActivatedRule , you can exclude specific rules from that rule group. If you already have a rule group associated with a web ACL and want to submit an UpdateWebACL request to exclude certain rules from that rule group, you must first remove the rule group from the web ACL, the re-insert it again, specifying the excluded rules. For details, see ActivatedRule$ExcludedRules . Be aware that if you try to add a RATE_BASED rule to a web ACL without setting the rule type when first creating the rule, the UpdateWebACL request will fail because the request tries to add a REGULAR rule (the default rule type) with the specified ID, which does not exist. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFRegional.html#update_xss_match_set/3","title":"AWS.WAFRegional.update_xss_match_set/3","type":"function","doc":"This is AWS WAF Classic documentation. For more information, see AWS WAF Classic in the developer guide. For the latest version of AWS WAF, use the AWS WAFV2 API and see the AWS WAF Developer Guide. With the latest version, AWS WAF has a single set of endpoints for regional and global use. Inserts or deletes XssMatchTuple objects (filters) in an XssMatchSet. For each XssMatchTuple object, you specify the following values: Action: Whether to insert the object into or delete the object from the array. To change an XssMatchTuple, you delete the existing object and add a new one. FieldToMatch: The part of web requests that you want AWS WAF to inspect and, if you want AWS WAF to inspect a header or custom query parameter, the name of the header or parameter. TextTransformation: Which text transformation, if any, to perform on the web request before inspecting the request for cross-site scripting attacks. You can only specify a single type of TextTransformation. You use XssMatchSet objects to specify which CloudFront requests that you want to allow, block, or count. For example, if you&#39;re receiving requests that contain cross-site scripting attacks in the request body and you want to block the requests, you can create an XssMatchSet with the applicable settings, and then configure AWS WAF to block the requests. To create and configure an XssMatchSet, perform the following steps: Submit a CreateXssMatchSet request. Use GetChangeToken to get the change token that you provide in the ChangeToken parameter of an UpdateIPSet request. Submit an UpdateXssMatchSet request to specify the parts of web requests that you want AWS WAF to inspect for cross-site scripting attacks. For more information about how to use the AWS WAF API to allow or block HTTP requests, see the AWS WAF Developer Guide."},{"ref":"AWS.WAFV2.html","title":"AWS.WAFV2","type":"module","doc":"This is the latest version of the AWS WAF API, released in November, 2019. The names of the entities that you use to access this API, like endpoints and namespaces, all have the versioning information added, like &quot;V2&quot; or &quot;v2&quot;, to distinguish from the prior version. We recommend migrating your resources to this version, because it has a number of significant improvements. If you used AWS WAF prior to this release, you can&#39;t use this AWS WAFV2 API to access any AWS WAF resources that you created before. You can access your old rules, web ACLs, and other AWS WAF resources only through the AWS WAF Classic APIs. The AWS WAF Classic APIs have retained the prior names, endpoints, and namespaces. For information, including how to migrate your AWS WAF resources to this version, see the AWS WAF Developer Guide. AWS WAF is a web application firewall that lets you monitor the HTTP and HTTPS requests that are forwarded to Amazon CloudFront, an Amazon API Gateway REST API, an Application Load Balancer, or an AWS AppSync GraphQL API. AWS WAF also lets you control access to your content. Based on conditions that you specify, such as the IP addresses that requests originate from or the values of query strings, the API Gateway REST API, CloudFront distribution, the Application Load Balancer, or the AWS AppSync GraphQL API responds to requests either with the requested content or with an HTTP 403 status code (Forbidden). You also can configure CloudFront to return a custom error page when a request is blocked. This API guide is for developers who need detailed information about AWS WAF API actions, data types, and errors. For detailed information about AWS WAF features and an overview of how to use AWS WAF, see the AWS WAF Developer Guide. You can make calls using the endpoints listed in AWS Service Endpoints for AWS WAF. For regional applications, you can use any of the endpoints in the list. A regional application can be an Application Load Balancer (ALB), an API Gateway REST API, or an AppSync GraphQL API. For AWS CloudFront applications, you must use the API endpoint listed for US East (N. Virginia): us-east-1. Alternatively, you can use one of the AWS SDKs to access an API that&#39;s tailored to the programming language or platform that you&#39;re using. For more information, see AWS SDKs. We currently provide two versions of the AWS WAF API: this API and the prior versions, the classic AWS WAF APIs. This new API provides the same functionality as the older versions, with the following major improvements: You use one API for both global and regional applications. Where you need to distinguish the scope, you specify a Scope parameter and set it to CLOUDFRONT or REGIONAL. You can define a Web ACL or rule group with a single call, and update it with a single call. You define all rule specifications in JSON format, and pass them to your rule group or Web ACL calls. The limits AWS WAF places on the use of rules more closely reflects the cost of running each type of rule. Rule groups include capacity settings, so you know the maximum cost of a rule group when you use it."},{"ref":"AWS.WAFV2.html#associate_web_a_c_l/3","title":"AWS.WAFV2.associate_web_a_c_l/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Associates a Web ACL with a regional application resource, to protect the resource. A regional application can be an Application Load Balancer (ALB), an API Gateway REST API, or an AppSync GraphQL API. For AWS CloudFront, don&#39;t use this call. Instead, use your CloudFront distribution configuration. To associate a Web ACL, in the CloudFront call UpdateDistribution, set the web ACL ID to the Amazon Resource Name (ARN) of the Web ACL. For information, see UpdateDistribution."},{"ref":"AWS.WAFV2.html#check_capacity/3","title":"AWS.WAFV2.check_capacity/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Returns the web ACL capacity unit (WCU) requirements for a specified scope and set of rules. You can use this to check the capacity requirements for the rules you want to use in a RuleGroup or WebACL. AWS WAF uses WCUs to calculate and control the operating resources that are used to run your rules, rule groups, and web ACLs. AWS WAF calculates capacity differently for each rule type, to reflect the relative cost of each rule. Simple rules that cost little to run use fewer WCUs than more complex rules that use more processing power. Rule group capacity is fixed at creation, which helps users plan their web ACL WCU usage when they use a rule group. The WCU limit for web ACLs is 1,500."},{"ref":"AWS.WAFV2.html#create_i_p_set/3","title":"AWS.WAFV2.create_i_p_set/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Creates an IPSet, which you use to identify web requests that originate from specific IP addresses or ranges of IP addresses. For example, if you&#39;re receiving a lot of requests from a ranges of IP addresses, you can configure AWS WAF to block them using an IPSet that lists those IP addresses."},{"ref":"AWS.WAFV2.html#create_regex_pattern_set/3","title":"AWS.WAFV2.create_regex_pattern_set/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Creates a RegexPatternSet, which you reference in a RegexPatternSetReferenceStatement, to have AWS WAF inspect a web request component for the specified patterns."},{"ref":"AWS.WAFV2.html#create_rule_group/3","title":"AWS.WAFV2.create_rule_group/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Creates a RuleGroup per the specifications provided. A rule group defines a collection of rules to inspect and control web requests that you can use in a WebACL. When you create a rule group, you define an immutable capacity limit. If you update a rule group, you must stay within the capacity. This allows others to reuse the rule group with confidence in its capacity requirements."},{"ref":"AWS.WAFV2.html#create_web_a_c_l/3","title":"AWS.WAFV2.create_web_a_c_l/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Creates a WebACL per the specifications provided. A Web ACL defines a collection of rules to use to inspect and control web requests. Each rule has an action defined (allow, block, or count) for requests that match the statement of the rule. In the Web ACL, you assign a default action to take (allow, block) for any request that does not match any of the rules. The rules in a Web ACL can be a combination of the types Rule, RuleGroup, and managed rule group. You can associate a Web ACL with one or more AWS resources to protect. The resources can be Amazon CloudFront, an Amazon API Gateway REST API, an Application Load Balancer, or an AWS AppSync GraphQL API."},{"ref":"AWS.WAFV2.html#delete_firewall_manager_rule_groups/3","title":"AWS.WAFV2.delete_firewall_manager_rule_groups/3","type":"function","doc":"Deletes all rule groups that are managed by AWS Firewall Manager for the specified web ACL. You can only use this if ManagedByFirewallManager is false in the specified WebACL."},{"ref":"AWS.WAFV2.html#delete_i_p_set/3","title":"AWS.WAFV2.delete_i_p_set/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Deletes the specified IPSet."},{"ref":"AWS.WAFV2.html#delete_logging_configuration/3","title":"AWS.WAFV2.delete_logging_configuration/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Deletes the LoggingConfiguration from the specified web ACL."},{"ref":"AWS.WAFV2.html#delete_permission_policy/3","title":"AWS.WAFV2.delete_permission_policy/3","type":"function","doc":"Permanently deletes an IAM policy from the specified rule group. You must be the owner of the rule group to perform this operation."},{"ref":"AWS.WAFV2.html#delete_regex_pattern_set/3","title":"AWS.WAFV2.delete_regex_pattern_set/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Deletes the specified RegexPatternSet."},{"ref":"AWS.WAFV2.html#delete_rule_group/3","title":"AWS.WAFV2.delete_rule_group/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Deletes the specified RuleGroup."},{"ref":"AWS.WAFV2.html#delete_web_a_c_l/3","title":"AWS.WAFV2.delete_web_a_c_l/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Deletes the specified WebACL. You can only use this if ManagedByFirewallManager is false in the specified WebACL."},{"ref":"AWS.WAFV2.html#describe_managed_rule_group/3","title":"AWS.WAFV2.describe_managed_rule_group/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Provides high-level information for a managed rule group, including descriptions of the rules."},{"ref":"AWS.WAFV2.html#disassociate_web_a_c_l/3","title":"AWS.WAFV2.disassociate_web_a_c_l/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Disassociates a Web ACL from a regional application resource. A regional application can be an Application Load Balancer (ALB), an API Gateway REST API, or an AppSync GraphQL API. For AWS CloudFront, don&#39;t use this call. Instead, use your CloudFront distribution configuration. To disassociate a Web ACL, provide an empty web ACL ID in the CloudFront call UpdateDistribution. For information, see UpdateDistribution."},{"ref":"AWS.WAFV2.html#get_i_p_set/3","title":"AWS.WAFV2.get_i_p_set/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Retrieves the specified IPSet."},{"ref":"AWS.WAFV2.html#get_logging_configuration/3","title":"AWS.WAFV2.get_logging_configuration/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Returns the LoggingConfiguration for the specified web ACL."},{"ref":"AWS.WAFV2.html#get_permission_policy/3","title":"AWS.WAFV2.get_permission_policy/3","type":"function","doc":"Returns the IAM policy that is attached to the specified rule group. You must be the owner of the rule group to perform this operation."},{"ref":"AWS.WAFV2.html#get_rate_based_statement_managed_keys/3","title":"AWS.WAFV2.get_rate_based_statement_managed_keys/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Retrieves the keys that are currently blocked by a rate-based rule. The maximum number of managed keys that can be blocked for a single rate-based rule is 10,000. If more than 10,000 addresses exceed the rate limit, those with the highest rates are blocked."},{"ref":"AWS.WAFV2.html#get_regex_pattern_set/3","title":"AWS.WAFV2.get_regex_pattern_set/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Retrieves the specified RegexPatternSet."},{"ref":"AWS.WAFV2.html#get_rule_group/3","title":"AWS.WAFV2.get_rule_group/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Retrieves the specified RuleGroup."},{"ref":"AWS.WAFV2.html#get_sampled_requests/3","title":"AWS.WAFV2.get_sampled_requests/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Gets detailed information about a specified number of requests--a sample--that AWS WAF randomly selects from among the first 5,000 requests that your AWS resource received during a time range that you choose. You can specify a sample size of up to 500 requests, and you can specify any time range in the previous three hours. GetSampledRequests returns a time range, which is usually the time range that you specified. However, if your resource (such as a CloudFront distribution) received 5,000 requests before the specified time range elapsed, GetSampledRequests returns an updated time range. This new time range indicates the actual period during which AWS WAF selected the requests in the sample."},{"ref":"AWS.WAFV2.html#get_web_a_c_l/3","title":"AWS.WAFV2.get_web_a_c_l/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Retrieves the specified WebACL."},{"ref":"AWS.WAFV2.html#get_web_a_c_l_for_resource/3","title":"AWS.WAFV2.get_web_a_c_l_for_resource/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Retrieves the WebACL for the specified resource."},{"ref":"AWS.WAFV2.html#list_available_managed_rule_groups/3","title":"AWS.WAFV2.list_available_managed_rule_groups/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Retrieves an array of managed rule groups that are available for you to use. This list includes all AWS Managed Rules rule groups and the AWS Marketplace managed rule groups that you&#39;re subscribed to."},{"ref":"AWS.WAFV2.html#list_i_p_sets/3","title":"AWS.WAFV2.list_i_p_sets/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Retrieves an array of IPSetSummary objects for the IP sets that you manage."},{"ref":"AWS.WAFV2.html#list_logging_configurations/3","title":"AWS.WAFV2.list_logging_configurations/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Retrieves an array of your LoggingConfiguration objects."},{"ref":"AWS.WAFV2.html#list_regex_pattern_sets/3","title":"AWS.WAFV2.list_regex_pattern_sets/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Retrieves an array of RegexPatternSetSummary objects for the regex pattern sets that you manage."},{"ref":"AWS.WAFV2.html#list_resources_for_web_a_c_l/3","title":"AWS.WAFV2.list_resources_for_web_a_c_l/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Retrieves an array of the Amazon Resource Names (ARNs) for the regional resources that are associated with the specified web ACL. If you want the list of AWS CloudFront resources, use the AWS CloudFront call ListDistributionsByWebACLId."},{"ref":"AWS.WAFV2.html#list_rule_groups/3","title":"AWS.WAFV2.list_rule_groups/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Retrieves an array of RuleGroupSummary objects for the rule groups that you manage."},{"ref":"AWS.WAFV2.html#list_tags_for_resource/3","title":"AWS.WAFV2.list_tags_for_resource/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Retrieves the TagInfoForResource for the specified resource. Tags are key:value pairs that you can use to categorize and manage your resources, for purposes like billing. For example, you might set the tag key to &quot;customer&quot; and the value to the customer name or ID. You can specify one or more tags to add to each AWS resource, up to 50 tags for a resource. You can tag the AWS resources that you manage through AWS WAF: web ACLs, rule groups, IP sets, and regex pattern sets. You can&#39;t manage or view tags through the AWS WAF console."},{"ref":"AWS.WAFV2.html#list_web_a_c_ls/3","title":"AWS.WAFV2.list_web_a_c_ls/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Retrieves an array of WebACLSummary objects for the web ACLs that you manage."},{"ref":"AWS.WAFV2.html#put_logging_configuration/3","title":"AWS.WAFV2.put_logging_configuration/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Enables the specified LoggingConfiguration, to start logging from a web ACL, according to the configuration provided. You can access information about all traffic that AWS WAF inspects using the following steps: Create an Amazon Kinesis Data Firehose. Create the data firehose with a PUT source and in the Region that you are operating. If you are capturing logs for Amazon CloudFront, always create the firehose in US East (N. Virginia). Give the data firehose a name that starts with the prefix aws-waf-logs-. For example, aws-waf-logs-us-east-2-analytics. Do not create the data firehose using a Kinesis stream as your source. Associate that firehose to your web ACL using a PutLoggingConfiguration request. When you successfully enable logging using a PutLoggingConfiguration request, AWS WAF will create a service linked role with the necessary permissions to write logs to the Amazon Kinesis Data Firehose. For more information, see Logging Web ACL Traffic Information in the AWS WAF Developer Guide."},{"ref":"AWS.WAFV2.html#put_permission_policy/3","title":"AWS.WAFV2.put_permission_policy/3","type":"function","doc":"Attaches an IAM policy to the specified resource. Use this to share a rule group across accounts. You must be the owner of the rule group to perform this operation. This action is subject to the following restrictions: You can attach only one policy with each PutPermissionPolicy request. The ARN in the request must be a valid WAF RuleGroup ARN and the rule group must exist in the same region. The user making the request must be the owner of the rule group."},{"ref":"AWS.WAFV2.html#tag_resource/3","title":"AWS.WAFV2.tag_resource/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Associates tags with the specified AWS resource. Tags are key:value pairs that you can use to categorize and manage your resources, for purposes like billing. For example, you might set the tag key to &quot;customer&quot; and the value to the customer name or ID. You can specify one or more tags to add to each AWS resource, up to 50 tags for a resource. You can tag the AWS resources that you manage through AWS WAF: web ACLs, rule groups, IP sets, and regex pattern sets. You can&#39;t manage or view tags through the AWS WAF console."},{"ref":"AWS.WAFV2.html#untag_resource/3","title":"AWS.WAFV2.untag_resource/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Disassociates tags from an AWS resource. Tags are key:value pairs that you can associate with AWS resources. For example, the tag key might be &quot;customer&quot; and the tag value might be &quot;companyA.&quot; You can specify one or more tags to add to each container. You can add up to 50 tags to each AWS resource."},{"ref":"AWS.WAFV2.html#update_i_p_set/3","title":"AWS.WAFV2.update_i_p_set/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Updates the specified IPSet."},{"ref":"AWS.WAFV2.html#update_regex_pattern_set/3","title":"AWS.WAFV2.update_regex_pattern_set/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Updates the specified RegexPatternSet."},{"ref":"AWS.WAFV2.html#update_rule_group/3","title":"AWS.WAFV2.update_rule_group/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Updates the specified RuleGroup. A rule group defines a collection of rules to inspect and control web requests that you can use in a WebACL. When you create a rule group, you define an immutable capacity limit. If you update a rule group, you must stay within the capacity. This allows others to reuse the rule group with confidence in its capacity requirements."},{"ref":"AWS.WAFV2.html#update_web_a_c_l/3","title":"AWS.WAFV2.update_web_a_c_l/3","type":"function","doc":"This is the latest version of AWS WAF, named AWS WAFV2, released in November, 2019. For information, including how to migrate your AWS WAF resources from the prior release, see the AWS WAF Developer Guide. Updates the specified WebACL. A Web ACL defines a collection of rules to use to inspect and control web requests. Each rule has an action defined (allow, block, or count) for requests that match the statement of the rule. In the Web ACL, you assign a default action to take (allow, block) for any request that does not match any of the rules. The rules in a Web ACL can be a combination of the types Rule, RuleGroup, and managed rule group. You can associate a Web ACL with one or more AWS resources to protect. The resources can be Amazon CloudFront, an Amazon API Gateway REST API, an Application Load Balancer, or an AWS AppSync GraphQL API."},{"ref":"AWS.WorkDocs.html","title":"AWS.WorkDocs","type":"module","doc":"The WorkDocs API is designed for the following use cases: File Migration: File migration applications are supported for users who want to migrate their files from an on-premises or off-premises file system or service. Users can insert files into a user directory structure, as well as allow for basic metadata changes, such as modifications to the permissions of files. Security: Support security applications are supported for users who have additional security needs, such as antivirus or data loss prevention. The API actions, along with AWS CloudTrail, allow these applications to detect when changes occur in Amazon WorkDocs. Then, the application can take the necessary actions and replace the target file. If the target file violates the policy, the application can also choose to email the user. eDiscovery/Analytics: General administrative applications are supported, such as eDiscovery and analytics. These applications can choose to mimic or record the actions in an Amazon WorkDocs site, along with AWS CloudTrail, to replicate data for eDiscovery, backup, or analytical applications. All Amazon WorkDocs API actions are Amazon authenticated and certificate-signed. They not only require the use of the AWS SDK, but also allow for the exclusive use of IAM users and roles to help facilitate access, trust, and permission policies. By creating a role and allowing an IAM user to access the Amazon WorkDocs site, the IAM user gains full administrative visibility into the entire Amazon WorkDocs site (or as set in the IAM policy). This includes, but is not limited to, the ability to modify file permissions and upload any file to any user. This allows developers to perform the three use cases above, as well as give users the ability to grant access on a selective basis using the IAM model."},{"ref":"AWS.WorkDocs.html#abort_document_version_upload/5","title":"AWS.WorkDocs.abort_document_version_upload/5","type":"function","doc":"Aborts the upload of the specified document version that was previously initiated by InitiateDocumentVersionUpload. The client should make this call only when it no longer intends to upload the document version, or fails to do so."},{"ref":"AWS.WorkDocs.html#activate_user/4","title":"AWS.WorkDocs.activate_user/4","type":"function","doc":"Activates the specified user. Only active users can access Amazon WorkDocs."},{"ref":"AWS.WorkDocs.html#add_resource_permissions/4","title":"AWS.WorkDocs.add_resource_permissions/4","type":"function","doc":"Creates a set of permissions for the specified folder or document. The resource permissions are overwritten if the principals already have different permissions."},{"ref":"AWS.WorkDocs.html#create_comment/5","title":"AWS.WorkDocs.create_comment/5","type":"function","doc":"Adds a new comment to the specified document version."},{"ref":"AWS.WorkDocs.html#create_custom_metadata/4","title":"AWS.WorkDocs.create_custom_metadata/4","type":"function","doc":"Adds one or more custom properties to the specified resource (a folder, document, or version)."},{"ref":"AWS.WorkDocs.html#create_folder/3","title":"AWS.WorkDocs.create_folder/3","type":"function","doc":"Creates a folder with the specified name and parent folder."},{"ref":"AWS.WorkDocs.html#create_labels/4","title":"AWS.WorkDocs.create_labels/4","type":"function","doc":"Adds the specified list of labels to the given resource (a document or folder)"},{"ref":"AWS.WorkDocs.html#create_notification_subscription/4","title":"AWS.WorkDocs.create_notification_subscription/4","type":"function","doc":"Configure Amazon WorkDocs to use Amazon SNS notifications. The endpoint receives a confirmation message, and must confirm the subscription. For more information, see Subscribe to Notifications in the Amazon WorkDocs Developer Guide."},{"ref":"AWS.WorkDocs.html#create_user/3","title":"AWS.WorkDocs.create_user/3","type":"function","doc":"Creates a user in a Simple AD or Microsoft AD directory. The status of a newly created user is &quot;ACTIVE&quot;. New users can access Amazon WorkDocs."},{"ref":"AWS.WorkDocs.html#deactivate_user/4","title":"AWS.WorkDocs.deactivate_user/4","type":"function","doc":"Deactivates the specified user, which revokes the user&#39;s access to Amazon WorkDocs."},{"ref":"AWS.WorkDocs.html#delete_comment/6","title":"AWS.WorkDocs.delete_comment/6","type":"function","doc":"Deletes the specified comment from the document version."},{"ref":"AWS.WorkDocs.html#delete_custom_metadata/4","title":"AWS.WorkDocs.delete_custom_metadata/4","type":"function","doc":"Deletes custom metadata from the specified resource."},{"ref":"AWS.WorkDocs.html#delete_document/4","title":"AWS.WorkDocs.delete_document/4","type":"function","doc":"Permanently deletes the specified document and its associated metadata."},{"ref":"AWS.WorkDocs.html#delete_folder/4","title":"AWS.WorkDocs.delete_folder/4","type":"function","doc":"Permanently deletes the specified folder and its contents."},{"ref":"AWS.WorkDocs.html#delete_folder_contents/4","title":"AWS.WorkDocs.delete_folder_contents/4","type":"function","doc":"Deletes the contents of the specified folder."},{"ref":"AWS.WorkDocs.html#delete_labels/4","title":"AWS.WorkDocs.delete_labels/4","type":"function","doc":"Deletes the specified list of labels from a resource."},{"ref":"AWS.WorkDocs.html#delete_notification_subscription/5","title":"AWS.WorkDocs.delete_notification_subscription/5","type":"function","doc":"Deletes the specified subscription from the specified organization."},{"ref":"AWS.WorkDocs.html#delete_user/4","title":"AWS.WorkDocs.delete_user/4","type":"function","doc":"Deletes the specified user from a Simple AD or Microsoft AD directory."},{"ref":"AWS.WorkDocs.html#describe_activities/12","title":"AWS.WorkDocs.describe_activities/12","type":"function","doc":"Describes the user activities in a specified time period."},{"ref":"AWS.WorkDocs.html#describe_comments/7","title":"AWS.WorkDocs.describe_comments/7","type":"function","doc":"List all the comments for the specified document version."},{"ref":"AWS.WorkDocs.html#describe_document_versions/8","title":"AWS.WorkDocs.describe_document_versions/8","type":"function","doc":"Retrieves the document versions for the specified document. By default, only active versions are returned."},{"ref":"AWS.WorkDocs.html#describe_folder_contents/10","title":"AWS.WorkDocs.describe_folder_contents/10","type":"function","doc":"Describes the contents of the specified folder, including its documents and subfolders. By default, Amazon WorkDocs returns the first 100 active document and folder metadata items. If there are more results, the response includes a marker that you can use to request the next set of results. You can also request initialized documents."},{"ref":"AWS.WorkDocs.html#describe_groups/7","title":"AWS.WorkDocs.describe_groups/7","type":"function","doc":"Describes the groups specified by the query. Groups are defined by the underlying Active Directory."},{"ref":"AWS.WorkDocs.html#describe_notification_subscriptions/5","title":"AWS.WorkDocs.describe_notification_subscriptions/5","type":"function","doc":"Lists the specified notification subscriptions."},{"ref":"AWS.WorkDocs.html#describe_resource_permissions/7","title":"AWS.WorkDocs.describe_resource_permissions/7","type":"function","doc":"Describes the permissions of a specified resource."},{"ref":"AWS.WorkDocs.html#describe_root_folders/5","title":"AWS.WorkDocs.describe_root_folders/5","type":"function","doc":"Describes the current user&#39;s special folders; the RootFolder and the RecycleBin. RootFolder is the root of user&#39;s files and folders and RecycleBin is the root of recycled items. This is not a valid action for SigV4 (administrative API) clients. This action requires an authentication token. To get an authentication token, register an application with Amazon WorkDocs. For more information, see Authentication and Access Control for User Applications in the Amazon WorkDocs Developer Guide."},{"ref":"AWS.WorkDocs.html#describe_users/12","title":"AWS.WorkDocs.describe_users/12","type":"function","doc":"Describes the specified users. You can describe all users or filter the results (for example, by status or organization). By default, Amazon WorkDocs returns the first 24 active or pending users. If there are more results, the response includes a marker that you can use to request the next set of results."},{"ref":"AWS.WorkDocs.html#get_current_user/3","title":"AWS.WorkDocs.get_current_user/3","type":"function","doc":"Retrieves details of the current user for whom the authentication token was generated. This is not a valid action for SigV4 (administrative API) clients. This action requires an authentication token. To get an authentication token, register an application with Amazon WorkDocs. For more information, see Authentication and Access Control for User Applications in the Amazon WorkDocs Developer Guide."},{"ref":"AWS.WorkDocs.html#get_document/5","title":"AWS.WorkDocs.get_document/5","type":"function","doc":"Retrieves details of a document."},{"ref":"AWS.WorkDocs.html#get_document_path/7","title":"AWS.WorkDocs.get_document_path/7","type":"function","doc":"Retrieves the path information (the hierarchy from the root folder) for the requested document. By default, Amazon WorkDocs returns a maximum of 100 levels upwards from the requested document and only includes the IDs of the parent folders in the path. You can limit the maximum number of levels. You can also request the names of the parent folders."},{"ref":"AWS.WorkDocs.html#get_document_version/7","title":"AWS.WorkDocs.get_document_version/7","type":"function","doc":"Retrieves version metadata for the specified document."},{"ref":"AWS.WorkDocs.html#get_folder/5","title":"AWS.WorkDocs.get_folder/5","type":"function","doc":"Retrieves the metadata of the specified folder."},{"ref":"AWS.WorkDocs.html#get_folder_path/7","title":"AWS.WorkDocs.get_folder_path/7","type":"function","doc":"Retrieves the path information (the hierarchy from the root folder) for the specified folder. By default, Amazon WorkDocs returns a maximum of 100 levels upwards from the requested folder and only includes the IDs of the parent folders in the path. You can limit the maximum number of levels. You can also request the parent folder names."},{"ref":"AWS.WorkDocs.html#get_resources/7","title":"AWS.WorkDocs.get_resources/7","type":"function","doc":"Retrieves a collection of resources, including folders and documents. The only CollectionType supported is SHARED_WITH_ME."},{"ref":"AWS.WorkDocs.html#initiate_document_version_upload/3","title":"AWS.WorkDocs.initiate_document_version_upload/3","type":"function","doc":"Creates a new document object and version object. The client specifies the parent folder ID and name of the document to upload. The ID is optionally specified when creating a new version of an existing document. This is the first step to upload a document. Next, upload the document to the URL returned from the call, and then call UpdateDocumentVersion. To cancel the document upload, call AbortDocumentVersionUpload."},{"ref":"AWS.WorkDocs.html#remove_all_resource_permissions/4","title":"AWS.WorkDocs.remove_all_resource_permissions/4","type":"function","doc":"Removes all the permissions from the specified resource."},{"ref":"AWS.WorkDocs.html#remove_resource_permission/5","title":"AWS.WorkDocs.remove_resource_permission/5","type":"function","doc":"Removes the permission for the specified principal from the specified resource."},{"ref":"AWS.WorkDocs.html#update_document/4","title":"AWS.WorkDocs.update_document/4","type":"function","doc":"Updates the specified attributes of a document. The user must have access to both the document and its parent folder, if applicable."},{"ref":"AWS.WorkDocs.html#update_document_version/5","title":"AWS.WorkDocs.update_document_version/5","type":"function","doc":"Changes the status of the document version to ACTIVE. Amazon WorkDocs also sets its document container to ACTIVE. This is the last step in a document upload, after the client uploads the document to an S3-presigned URL returned by InitiateDocumentVersionUpload."},{"ref":"AWS.WorkDocs.html#update_folder/4","title":"AWS.WorkDocs.update_folder/4","type":"function","doc":"Updates the specified attributes of the specified folder. The user must have access to both the folder and its parent folder, if applicable."},{"ref":"AWS.WorkDocs.html#update_user/4","title":"AWS.WorkDocs.update_user/4","type":"function","doc":"Updates the specified attributes of the specified user, and grants or revokes administrative privileges to the Amazon WorkDocs site."},{"ref":"AWS.WorkLink.html","title":"AWS.WorkLink","type":"module","doc":"Amazon WorkLink is a cloud-based service that provides secure access to internal websites and web apps from iOS and Android phones. In a single step, your users, such as employees, can access internal websites as efficiently as they access any other public website. They enter a URL in their web browser, or choose a link to an internal website in an email. Amazon WorkLink authenticates the user&#39;s access and securely renders authorized internal web content in a secure rendering service in the AWS cloud. Amazon WorkLink doesn&#39;t download or store any internal web content on mobile devices."},{"ref":"AWS.WorkLink.html#associate_domain/3","title":"AWS.WorkLink.associate_domain/3","type":"function","doc":"Specifies a domain to be associated to Amazon WorkLink."},{"ref":"AWS.WorkLink.html#associate_website_authorization_provider/3","title":"AWS.WorkLink.associate_website_authorization_provider/3","type":"function","doc":"Associates a website authorization provider with a specified fleet. This is used to authorize users against associated websites in the company network."},{"ref":"AWS.WorkLink.html#associate_website_certificate_authority/3","title":"AWS.WorkLink.associate_website_certificate_authority/3","type":"function","doc":"Imports the root certificate of a certificate authority (CA) used to obtain TLS certificates used by associated websites within the company network."},{"ref":"AWS.WorkLink.html#create_fleet/3","title":"AWS.WorkLink.create_fleet/3","type":"function","doc":"Creates a fleet. A fleet consists of resources and the configuration that delivers associated websites to authorized users who download and set up the Amazon WorkLink app."},{"ref":"AWS.WorkLink.html#delete_fleet/3","title":"AWS.WorkLink.delete_fleet/3","type":"function","doc":"Deletes a fleet. Prevents users from accessing previously associated websites."},{"ref":"AWS.WorkLink.html#describe_audit_stream_configuration/3","title":"AWS.WorkLink.describe_audit_stream_configuration/3","type":"function","doc":"Describes the configuration for delivering audit streams to the customer account."},{"ref":"AWS.WorkLink.html#describe_company_network_configuration/3","title":"AWS.WorkLink.describe_company_network_configuration/3","type":"function","doc":"Describes the networking configuration to access the internal websites associated with the specified fleet."},{"ref":"AWS.WorkLink.html#describe_device/3","title":"AWS.WorkLink.describe_device/3","type":"function","doc":"Provides information about a user&#39;s device."},{"ref":"AWS.WorkLink.html#describe_device_policy_configuration/3","title":"AWS.WorkLink.describe_device_policy_configuration/3","type":"function","doc":"Describes the device policy configuration for the specified fleet."},{"ref":"AWS.WorkLink.html#describe_domain/3","title":"AWS.WorkLink.describe_domain/3","type":"function","doc":"Provides information about the domain."},{"ref":"AWS.WorkLink.html#describe_fleet_metadata/3","title":"AWS.WorkLink.describe_fleet_metadata/3","type":"function","doc":"Provides basic information for the specified fleet, excluding identity provider, networking, and device configuration details."},{"ref":"AWS.WorkLink.html#describe_identity_provider_configuration/3","title":"AWS.WorkLink.describe_identity_provider_configuration/3","type":"function","doc":"Describes the identity provider configuration of the specified fleet."},{"ref":"AWS.WorkLink.html#describe_website_certificate_authority/3","title":"AWS.WorkLink.describe_website_certificate_authority/3","type":"function","doc":"Provides information about the certificate authority."},{"ref":"AWS.WorkLink.html#disassociate_domain/3","title":"AWS.WorkLink.disassociate_domain/3","type":"function","doc":"Disassociates a domain from Amazon WorkLink. End users lose the ability to access the domain with Amazon WorkLink."},{"ref":"AWS.WorkLink.html#disassociate_website_authorization_provider/3","title":"AWS.WorkLink.disassociate_website_authorization_provider/3","type":"function","doc":"Disassociates a website authorization provider from a specified fleet. After the disassociation, users can&#39;t load any associated websites that require this authorization provider."},{"ref":"AWS.WorkLink.html#disassociate_website_certificate_authority/3","title":"AWS.WorkLink.disassociate_website_certificate_authority/3","type":"function","doc":"Removes a certificate authority (CA)."},{"ref":"AWS.WorkLink.html#list_devices/3","title":"AWS.WorkLink.list_devices/3","type":"function","doc":"Retrieves a list of devices registered with the specified fleet."},{"ref":"AWS.WorkLink.html#list_domains/3","title":"AWS.WorkLink.list_domains/3","type":"function","doc":"Retrieves a list of domains associated to a specified fleet."},{"ref":"AWS.WorkLink.html#list_fleets/3","title":"AWS.WorkLink.list_fleets/3","type":"function","doc":"Retrieves a list of fleets for the current account and Region."},{"ref":"AWS.WorkLink.html#list_tags_for_resource/3","title":"AWS.WorkLink.list_tags_for_resource/3","type":"function","doc":"Retrieves a list of tags for the specified resource."},{"ref":"AWS.WorkLink.html#list_website_authorization_providers/3","title":"AWS.WorkLink.list_website_authorization_providers/3","type":"function","doc":"Retrieves a list of website authorization providers associated with a specified fleet."},{"ref":"AWS.WorkLink.html#list_website_certificate_authorities/3","title":"AWS.WorkLink.list_website_certificate_authorities/3","type":"function","doc":"Retrieves a list of certificate authorities added for the current account and Region."},{"ref":"AWS.WorkLink.html#restore_domain_access/3","title":"AWS.WorkLink.restore_domain_access/3","type":"function","doc":"Moves a domain to ACTIVE status if it was in the INACTIVE status."},{"ref":"AWS.WorkLink.html#revoke_domain_access/3","title":"AWS.WorkLink.revoke_domain_access/3","type":"function","doc":"Moves a domain to INACTIVE status if it was in the ACTIVE status."},{"ref":"AWS.WorkLink.html#sign_out_user/3","title":"AWS.WorkLink.sign_out_user/3","type":"function","doc":"Signs the user out from all of their devices. The user can sign in again if they have valid credentials."},{"ref":"AWS.WorkLink.html#tag_resource/4","title":"AWS.WorkLink.tag_resource/4","type":"function","doc":"Adds or overwrites one or more tags for the specified resource, such as a fleet. Each tag consists of a key and an optional value. If a resource already has a tag with the same key, this operation updates its value."},{"ref":"AWS.WorkLink.html#untag_resource/4","title":"AWS.WorkLink.untag_resource/4","type":"function","doc":"Removes one or more tags from the specified resource."},{"ref":"AWS.WorkLink.html#update_audit_stream_configuration/3","title":"AWS.WorkLink.update_audit_stream_configuration/3","type":"function","doc":"Updates the audit stream configuration for the fleet."},{"ref":"AWS.WorkLink.html#update_company_network_configuration/3","title":"AWS.WorkLink.update_company_network_configuration/3","type":"function","doc":"Updates the company network configuration for the fleet."},{"ref":"AWS.WorkLink.html#update_device_policy_configuration/3","title":"AWS.WorkLink.update_device_policy_configuration/3","type":"function","doc":"Updates the device policy configuration for the fleet."},{"ref":"AWS.WorkLink.html#update_domain_metadata/3","title":"AWS.WorkLink.update_domain_metadata/3","type":"function","doc":"Updates domain metadata, such as DisplayName."},{"ref":"AWS.WorkLink.html#update_fleet_metadata/3","title":"AWS.WorkLink.update_fleet_metadata/3","type":"function","doc":"Updates fleet metadata, such as DisplayName."},{"ref":"AWS.WorkLink.html#update_identity_provider_configuration/3","title":"AWS.WorkLink.update_identity_provider_configuration/3","type":"function","doc":"Updates the identity provider configuration for the fleet."},{"ref":"AWS.WorkMail.html","title":"AWS.WorkMail","type":"module","doc":"Amazon WorkMail is a secure, managed business email and calendaring service with support for existing desktop and mobile email clients. You can access your email, contacts, and calendars using Microsoft Outlook, your browser, or other native iOS and Android email applications. You can integrate WorkMail with your existing corporate directory and control both the keys that encrypt your data and the location in which your data is stored. The WorkMail API is designed for the following scenarios: Listing and describing organizations Managing users Managing groups Managing resources All WorkMail API operations are Amazon-authenticated and certificate-signed. They not only require the use of the AWS SDK, but also allow for the exclusive use of AWS Identity and Access Management users and roles to help facilitate access, trust, and permission policies. By creating a role and allowing an IAM user to access the WorkMail site, the IAM user gains full administrative visibility into the entire WorkMail organization (or as set in the IAM policy). This includes, but is not limited to, the ability to create, update, and delete users, groups, and resources. This allows developers to perform the scenarios listed above, as well as give users the ability to grant access on a selective basis using the IAM model."},{"ref":"AWS.WorkMail.html#associate_delegate_to_resource/3","title":"AWS.WorkMail.associate_delegate_to_resource/3","type":"function","doc":"Adds a member (user or group) to the resource&#39;s set of delegates."},{"ref":"AWS.WorkMail.html#associate_member_to_group/3","title":"AWS.WorkMail.associate_member_to_group/3","type":"function","doc":"Adds a member (user or group) to the group&#39;s set."},{"ref":"AWS.WorkMail.html#cancel_mailbox_export_job/3","title":"AWS.WorkMail.cancel_mailbox_export_job/3","type":"function","doc":"Cancels a mailbox export job. If the mailbox export job is near completion, it might not be possible to cancel it."},{"ref":"AWS.WorkMail.html#create_alias/3","title":"AWS.WorkMail.create_alias/3","type":"function","doc":"Adds an alias to the set of a given member (user or group) of Amazon WorkMail."},{"ref":"AWS.WorkMail.html#create_group/3","title":"AWS.WorkMail.create_group/3","type":"function","doc":"Creates a group that can be used in Amazon WorkMail by calling the RegisterToWorkMail operation."},{"ref":"AWS.WorkMail.html#create_resource/3","title":"AWS.WorkMail.create_resource/3","type":"function","doc":"Creates a new Amazon WorkMail resource."},{"ref":"AWS.WorkMail.html#create_user/3","title":"AWS.WorkMail.create_user/3","type":"function","doc":"Creates a user who can be used in Amazon WorkMail by calling the RegisterToWorkMail operation."},{"ref":"AWS.WorkMail.html#delete_access_control_rule/3","title":"AWS.WorkMail.delete_access_control_rule/3","type":"function","doc":"Deletes an access control rule for the specified WorkMail organization."},{"ref":"AWS.WorkMail.html#delete_alias/3","title":"AWS.WorkMail.delete_alias/3","type":"function","doc":"Remove one or more specified aliases from a set of aliases for a given user."},{"ref":"AWS.WorkMail.html#delete_group/3","title":"AWS.WorkMail.delete_group/3","type":"function","doc":"Deletes a group from Amazon WorkMail."},{"ref":"AWS.WorkMail.html#delete_mailbox_permissions/3","title":"AWS.WorkMail.delete_mailbox_permissions/3","type":"function","doc":"Deletes permissions granted to a member (user or group)."},{"ref":"AWS.WorkMail.html#delete_resource/3","title":"AWS.WorkMail.delete_resource/3","type":"function","doc":"Deletes the specified resource."},{"ref":"AWS.WorkMail.html#delete_retention_policy/3","title":"AWS.WorkMail.delete_retention_policy/3","type":"function","doc":"Deletes the specified retention policy from the specified organization."},{"ref":"AWS.WorkMail.html#delete_user/3","title":"AWS.WorkMail.delete_user/3","type":"function","doc":"Deletes a user from Amazon WorkMail and all subsequent systems. Before you can delete a user, the user state must be DISABLED. Use the DescribeUser action to confirm the user state. Deleting a user is permanent and cannot be undone. WorkMail archives user mailboxes for 30 days before they are permanently removed."},{"ref":"AWS.WorkMail.html#deregister_from_work_mail/3","title":"AWS.WorkMail.deregister_from_work_mail/3","type":"function","doc":"Mark a user, group, or resource as no longer used in Amazon WorkMail. This action disassociates the mailbox and schedules it for clean-up. WorkMail keeps mailboxes for 30 days before they are permanently removed. The functionality in the console is Disable."},{"ref":"AWS.WorkMail.html#describe_group/3","title":"AWS.WorkMail.describe_group/3","type":"function","doc":"Returns the data available for the group."},{"ref":"AWS.WorkMail.html#describe_mailbox_export_job/3","title":"AWS.WorkMail.describe_mailbox_export_job/3","type":"function","doc":"Describes the current status of a mailbox export job."},{"ref":"AWS.WorkMail.html#describe_organization/3","title":"AWS.WorkMail.describe_organization/3","type":"function","doc":"Provides more information regarding a given organization based on its identifier."},{"ref":"AWS.WorkMail.html#describe_resource/3","title":"AWS.WorkMail.describe_resource/3","type":"function","doc":"Returns the data available for the resource."},{"ref":"AWS.WorkMail.html#describe_user/3","title":"AWS.WorkMail.describe_user/3","type":"function","doc":"Provides information regarding the user."},{"ref":"AWS.WorkMail.html#disassociate_delegate_from_resource/3","title":"AWS.WorkMail.disassociate_delegate_from_resource/3","type":"function","doc":"Removes a member from the resource&#39;s set of delegates."},{"ref":"AWS.WorkMail.html#disassociate_member_from_group/3","title":"AWS.WorkMail.disassociate_member_from_group/3","type":"function","doc":"Removes a member from a group."},{"ref":"AWS.WorkMail.html#get_access_control_effect/3","title":"AWS.WorkMail.get_access_control_effect/3","type":"function","doc":"Gets the effects of an organization&#39;s access control rules as they apply to a specified IPv4 address, access protocol action, or user ID."},{"ref":"AWS.WorkMail.html#get_default_retention_policy/3","title":"AWS.WorkMail.get_default_retention_policy/3","type":"function","doc":"Gets the default retention policy details for the specified organization."},{"ref":"AWS.WorkMail.html#get_mailbox_details/3","title":"AWS.WorkMail.get_mailbox_details/3","type":"function","doc":"Requests a user&#39;s mailbox details for a specified organization and user."},{"ref":"AWS.WorkMail.html#list_access_control_rules/3","title":"AWS.WorkMail.list_access_control_rules/3","type":"function","doc":"Lists the access control rules for the specified organization."},{"ref":"AWS.WorkMail.html#list_aliases/3","title":"AWS.WorkMail.list_aliases/3","type":"function","doc":"Creates a paginated call to list the aliases associated with a given entity."},{"ref":"AWS.WorkMail.html#list_group_members/3","title":"AWS.WorkMail.list_group_members/3","type":"function","doc":"Returns an overview of the members of a group. Users and groups can be members of a group."},{"ref":"AWS.WorkMail.html#list_groups/3","title":"AWS.WorkMail.list_groups/3","type":"function","doc":"Returns summaries of the organization&#39;s groups."},{"ref":"AWS.WorkMail.html#list_mailbox_export_jobs/3","title":"AWS.WorkMail.list_mailbox_export_jobs/3","type":"function","doc":"Lists the mailbox export jobs started for the specified organization within the last seven days."},{"ref":"AWS.WorkMail.html#list_mailbox_permissions/3","title":"AWS.WorkMail.list_mailbox_permissions/3","type":"function","doc":"Lists the mailbox permissions associated with a user, group, or resource mailbox."},{"ref":"AWS.WorkMail.html#list_organizations/3","title":"AWS.WorkMail.list_organizations/3","type":"function","doc":"Returns summaries of the customer&#39;s organizations."},{"ref":"AWS.WorkMail.html#list_resource_delegates/3","title":"AWS.WorkMail.list_resource_delegates/3","type":"function","doc":"Lists the delegates associated with a resource. Users and groups can be resource delegates and answer requests on behalf of the resource."},{"ref":"AWS.WorkMail.html#list_resources/3","title":"AWS.WorkMail.list_resources/3","type":"function","doc":"Returns summaries of the organization&#39;s resources."},{"ref":"AWS.WorkMail.html#list_tags_for_resource/3","title":"AWS.WorkMail.list_tags_for_resource/3","type":"function","doc":"Lists the tags applied to an Amazon WorkMail organization resource."},{"ref":"AWS.WorkMail.html#list_users/3","title":"AWS.WorkMail.list_users/3","type":"function","doc":"Returns summaries of the organization&#39;s users."},{"ref":"AWS.WorkMail.html#put_access_control_rule/3","title":"AWS.WorkMail.put_access_control_rule/3","type":"function","doc":"Adds a new access control rule for the specified organization. The rule allows or denies access to the organization for the specified IPv4 addresses, access protocol actions, and user IDs. Adding a new rule with the same name as an existing rule replaces the older rule."},{"ref":"AWS.WorkMail.html#put_mailbox_permissions/3","title":"AWS.WorkMail.put_mailbox_permissions/3","type":"function","doc":"Sets permissions for a user, group, or resource. This replaces any pre-existing permissions."},{"ref":"AWS.WorkMail.html#put_retention_policy/3","title":"AWS.WorkMail.put_retention_policy/3","type":"function","doc":"Puts a retention policy to the specified organization."},{"ref":"AWS.WorkMail.html#register_to_work_mail/3","title":"AWS.WorkMail.register_to_work_mail/3","type":"function","doc":"Registers an existing and disabled user, group, or resource for Amazon WorkMail use by associating a mailbox and calendaring capabilities. It performs no change if the user, group, or resource is enabled and fails if the user, group, or resource is deleted. This operation results in the accumulation of costs. For more information, see Pricing. The equivalent console functionality for this operation is Enable. Users can either be created by calling the CreateUser API operation or they can be synchronized from your directory. For more information, see DeregisterFromWorkMail."},{"ref":"AWS.WorkMail.html#reset_password/3","title":"AWS.WorkMail.reset_password/3","type":"function","doc":"Allows the administrator to reset the password for a user."},{"ref":"AWS.WorkMail.html#start_mailbox_export_job/3","title":"AWS.WorkMail.start_mailbox_export_job/3","type":"function","doc":"Starts a mailbox export job to export MIME-format email messages and calendar items from the specified mailbox to the specified Amazon Simple Storage Service (Amazon S3) bucket. For more information, see Exporting mailbox content in the Amazon WorkMail Administrator Guide."},{"ref":"AWS.WorkMail.html#tag_resource/3","title":"AWS.WorkMail.tag_resource/3","type":"function","doc":"Applies the specified tags to the specified Amazon WorkMail organization resource."},{"ref":"AWS.WorkMail.html#untag_resource/3","title":"AWS.WorkMail.untag_resource/3","type":"function","doc":"Untags the specified tags from the specified Amazon WorkMail organization resource."},{"ref":"AWS.WorkMail.html#update_mailbox_quota/3","title":"AWS.WorkMail.update_mailbox_quota/3","type":"function","doc":"Updates a user&#39;s current mailbox quota for a specified organization and user."},{"ref":"AWS.WorkMail.html#update_primary_email_address/3","title":"AWS.WorkMail.update_primary_email_address/3","type":"function","doc":"Updates the primary email for a user, group, or resource. The current email is moved into the list of aliases (or swapped between an existing alias and the current primary email), and the email provided in the input is promoted as the primary."},{"ref":"AWS.WorkMail.html#update_resource/3","title":"AWS.WorkMail.update_resource/3","type":"function","doc":"Updates data for the resource. To have the latest information, it must be preceded by a DescribeResource call. The dataset in the request should be the one expected when performing another DescribeResource call."},{"ref":"AWS.WorkMailMessageFlow.html","title":"AWS.WorkMailMessageFlow","type":"module","doc":"The WorkMail Message Flow API provides access to email messages as they are being sent and received by a WorkMail organization."},{"ref":"AWS.WorkMailMessageFlow.html#get_raw_message_content/3","title":"AWS.WorkMailMessageFlow.get_raw_message_content/3","type":"function","doc":"Retrieves the raw content of an in-transit email message, in MIME format."},{"ref":"AWS.WorkSpaces.html","title":"AWS.WorkSpaces","type":"module","doc":"Amazon WorkSpaces Service Amazon WorkSpaces enables you to provision virtual, cloud-based Microsoft Windows and Amazon Linux desktops for your users."},{"ref":"AWS.WorkSpaces.html#associate_connection_alias/3","title":"AWS.WorkSpaces.associate_connection_alias/3","type":"function","doc":"Associates the specified connection alias with the specified directory to enable cross-Region redirection. For more information, see Cross-Region Redirection for Amazon WorkSpaces. Before performing this operation, call DescribeConnectionAliases to make sure that the current state of the connection alias is CREATED."},{"ref":"AWS.WorkSpaces.html#associate_ip_groups/3","title":"AWS.WorkSpaces.associate_ip_groups/3","type":"function","doc":"Associates the specified IP access control group with the specified directory."},{"ref":"AWS.WorkSpaces.html#authorize_ip_rules/3","title":"AWS.WorkSpaces.authorize_ip_rules/3","type":"function","doc":"Adds one or more rules to the specified IP access control group. This action gives users permission to access their WorkSpaces from the CIDR address ranges specified in the rules."},{"ref":"AWS.WorkSpaces.html#copy_workspace_image/3","title":"AWS.WorkSpaces.copy_workspace_image/3","type":"function","doc":"Copies the specified image from the specified Region to the current Region."},{"ref":"AWS.WorkSpaces.html#create_connection_alias/3","title":"AWS.WorkSpaces.create_connection_alias/3","type":"function","doc":"Creates the specified connection alias for use with cross-Region redirection. For more information, see Cross-Region Redirection for Amazon WorkSpaces."},{"ref":"AWS.WorkSpaces.html#create_ip_group/3","title":"AWS.WorkSpaces.create_ip_group/3","type":"function","doc":"Creates an IP access control group. An IP access control group provides you with the ability to control the IP addresses from which users are allowed to access their WorkSpaces. To specify the CIDR address ranges, add rules to your IP access control group and then associate the group with your directory. You can add rules when you create the group or at any time using AuthorizeIpRules. There is a default IP access control group associated with your directory. If you don&#39;t associate an IP access control group with your directory, the default group is used. The default group includes a default rule that allows users to access their WorkSpaces from anywhere. You cannot modify the default IP access control group for your directory."},{"ref":"AWS.WorkSpaces.html#create_tags/3","title":"AWS.WorkSpaces.create_tags/3","type":"function","doc":"Creates the specified tags for the specified WorkSpaces resource."},{"ref":"AWS.WorkSpaces.html#create_workspaces/3","title":"AWS.WorkSpaces.create_workspaces/3","type":"function","doc":"Creates one or more WorkSpaces. This operation is asynchronous and returns before the WorkSpaces are created."},{"ref":"AWS.WorkSpaces.html#delete_connection_alias/3","title":"AWS.WorkSpaces.delete_connection_alias/3","type":"function","doc":"Deletes the specified connection alias. For more information, see Cross-Region Redirection for Amazon WorkSpaces. If you will no longer be using a fully qualified domain name (FQDN) as the registration code for your WorkSpaces users, you must take certain precautions to prevent potential security issues. For more information, see Security Considerations if You Stop Using Cross-Region Redirection. To delete a connection alias that has been shared, the shared account must first disassociate the connection alias from any directories it has been associated with. Then you must unshare the connection alias from the account it has been shared with. You can delete a connection alias only after it is no longer shared with any accounts or associated with any directories."},{"ref":"AWS.WorkSpaces.html#delete_ip_group/3","title":"AWS.WorkSpaces.delete_ip_group/3","type":"function","doc":"Deletes the specified IP access control group. You cannot delete an IP access control group that is associated with a directory."},{"ref":"AWS.WorkSpaces.html#delete_tags/3","title":"AWS.WorkSpaces.delete_tags/3","type":"function","doc":"Deletes the specified tags from the specified WorkSpaces resource."},{"ref":"AWS.WorkSpaces.html#delete_workspace_image/3","title":"AWS.WorkSpaces.delete_workspace_image/3","type":"function","doc":"Deletes the specified image from your account. To delete an image, you must first delete any bundles that are associated with the image and unshare the image if it is shared with other accounts."},{"ref":"AWS.WorkSpaces.html#deregister_workspace_directory/3","title":"AWS.WorkSpaces.deregister_workspace_directory/3","type":"function","doc":"Deregisters the specified directory. This operation is asynchronous and returns before the WorkSpace directory is deregistered. If any WorkSpaces are registered to this directory, you must remove them before you can deregister the directory."},{"ref":"AWS.WorkSpaces.html#describe_account/3","title":"AWS.WorkSpaces.describe_account/3","type":"function","doc":"Retrieves a list that describes the configuration of Bring Your Own License (BYOL) for the specified account."},{"ref":"AWS.WorkSpaces.html#describe_account_modifications/3","title":"AWS.WorkSpaces.describe_account_modifications/3","type":"function","doc":"Retrieves a list that describes modifications to the configuration of Bring Your Own License (BYOL) for the specified account."},{"ref":"AWS.WorkSpaces.html#describe_client_properties/3","title":"AWS.WorkSpaces.describe_client_properties/3","type":"function","doc":"Retrieves a list that describes one or more specified Amazon WorkSpaces clients."},{"ref":"AWS.WorkSpaces.html#describe_connection_alias_permissions/3","title":"AWS.WorkSpaces.describe_connection_alias_permissions/3","type":"function","doc":"Describes the permissions that the owner of a connection alias has granted to another AWS account for the specified connection alias. For more information, see Cross-Region Redirection for Amazon WorkSpaces."},{"ref":"AWS.WorkSpaces.html#describe_connection_aliases/3","title":"AWS.WorkSpaces.describe_connection_aliases/3","type":"function","doc":"Retrieves a list that describes the connection aliases used for cross-Region redirection. For more information, see Cross-Region Redirection for Amazon WorkSpaces."},{"ref":"AWS.WorkSpaces.html#describe_ip_groups/3","title":"AWS.WorkSpaces.describe_ip_groups/3","type":"function","doc":"Describes one or more of your IP access control groups."},{"ref":"AWS.WorkSpaces.html#describe_tags/3","title":"AWS.WorkSpaces.describe_tags/3","type":"function","doc":"Describes the specified tags for the specified WorkSpaces resource."},{"ref":"AWS.WorkSpaces.html#describe_workspace_bundles/3","title":"AWS.WorkSpaces.describe_workspace_bundles/3","type":"function","doc":"Retrieves a list that describes the available WorkSpace bundles. You can filter the results using either bundle ID or owner, but not both."},{"ref":"AWS.WorkSpaces.html#describe_workspace_directories/3","title":"AWS.WorkSpaces.describe_workspace_directories/3","type":"function","doc":"Describes the available directories that are registered with Amazon WorkSpaces."},{"ref":"AWS.WorkSpaces.html#describe_workspace_image_permissions/3","title":"AWS.WorkSpaces.describe_workspace_image_permissions/3","type":"function","doc":"Describes the permissions that the owner of an image has granted to other AWS accounts for an image."},{"ref":"AWS.WorkSpaces.html#describe_workspace_images/3","title":"AWS.WorkSpaces.describe_workspace_images/3","type":"function","doc":"Retrieves a list that describes one or more specified images, if the image identifiers are provided. Otherwise, all images in the account are described."},{"ref":"AWS.WorkSpaces.html#describe_workspace_snapshots/3","title":"AWS.WorkSpaces.describe_workspace_snapshots/3","type":"function","doc":"Describes the snapshots for the specified WorkSpace."},{"ref":"AWS.WorkSpaces.html#describe_workspaces/3","title":"AWS.WorkSpaces.describe_workspaces/3","type":"function","doc":"Describes the specified WorkSpaces. You can filter the results by using the bundle identifier, directory identifier, or owner, but you can specify only one filter at a time."},{"ref":"AWS.WorkSpaces.html#describe_workspaces_connection_status/3","title":"AWS.WorkSpaces.describe_workspaces_connection_status/3","type":"function","doc":"Describes the connection status of the specified WorkSpaces."},{"ref":"AWS.WorkSpaces.html#disassociate_connection_alias/3","title":"AWS.WorkSpaces.disassociate_connection_alias/3","type":"function","doc":"Disassociates a connection alias from a directory. Disassociating a connection alias disables cross-Region redirection between two directories in different AWS Regions. For more information, see Cross-Region Redirection for Amazon WorkSpaces. Before performing this operation, call DescribeConnectionAliases to make sure that the current state of the connection alias is CREATED."},{"ref":"AWS.WorkSpaces.html#disassociate_ip_groups/3","title":"AWS.WorkSpaces.disassociate_ip_groups/3","type":"function","doc":"Disassociates the specified IP access control group from the specified directory."},{"ref":"AWS.WorkSpaces.html#import_workspace_image/3","title":"AWS.WorkSpaces.import_workspace_image/3","type":"function","doc":"Imports the specified Windows 10 Bring Your Own License (BYOL) image into Amazon WorkSpaces. The image must be an already licensed Amazon EC2 image that is in your AWS account, and you must own the image. For more information about creating BYOL images, see Bring Your Own Windows Desktop Licenses."},{"ref":"AWS.WorkSpaces.html#list_available_management_cidr_ranges/3","title":"AWS.WorkSpaces.list_available_management_cidr_ranges/3","type":"function","doc":"Retrieves a list of IP address ranges, specified as IPv4 CIDR blocks, that you can use for the network management interface when you enable Bring Your Own License (BYOL). The management network interface is connected to a secure Amazon WorkSpaces management network. It is used for interactive streaming of the WorkSpace desktop to Amazon WorkSpaces clients, and to allow Amazon WorkSpaces to manage the WorkSpace."},{"ref":"AWS.WorkSpaces.html#migrate_workspace/3","title":"AWS.WorkSpaces.migrate_workspace/3","type":"function","doc":"Migrates a WorkSpace from one operating system or bundle type to another, while retaining the data on the user volume. The migration process recreates the WorkSpace by using a new root volume from the target bundle image and the user volume from the last available snapshot of the original WorkSpace. During migration, the original D:Users%USERNAME% user profile folder is renamed to D:Users%USERNAME%MMddyyTHHmmss%.NotMigrated. A new D:Users%USERNAME% folder is generated by the new OS. Certain files in the old user profile are moved to the new user profile. For available migration scenarios, details about what happens during migration, and best practices, see Migrate a WorkSpace."},{"ref":"AWS.WorkSpaces.html#modify_account/3","title":"AWS.WorkSpaces.modify_account/3","type":"function","doc":"Modifies the configuration of Bring Your Own License (BYOL) for the specified account."},{"ref":"AWS.WorkSpaces.html#modify_client_properties/3","title":"AWS.WorkSpaces.modify_client_properties/3","type":"function","doc":"Modifies the properties of the specified Amazon WorkSpaces clients."},{"ref":"AWS.WorkSpaces.html#modify_selfservice_permissions/3","title":"AWS.WorkSpaces.modify_selfservice_permissions/3","type":"function","doc":"Modifies the self-service WorkSpace management capabilities for your users. For more information, see Enable Self-Service WorkSpace Management Capabilities for Your Users."},{"ref":"AWS.WorkSpaces.html#modify_workspace_access_properties/3","title":"AWS.WorkSpaces.modify_workspace_access_properties/3","type":"function","doc":"Specifies which devices and operating systems users can use to access their WorkSpaces. For more information, see Control Device Access."},{"ref":"AWS.WorkSpaces.html#modify_workspace_creation_properties/3","title":"AWS.WorkSpaces.modify_workspace_creation_properties/3","type":"function","doc":"Modify the default properties used to create WorkSpaces."},{"ref":"AWS.WorkSpaces.html#modify_workspace_properties/3","title":"AWS.WorkSpaces.modify_workspace_properties/3","type":"function","doc":"Modifies the specified WorkSpace properties. For important information about how to modify the size of the root and user volumes, see Modify a WorkSpace."},{"ref":"AWS.WorkSpaces.html#modify_workspace_state/3","title":"AWS.WorkSpaces.modify_workspace_state/3","type":"function","doc":"Sets the state of the specified WorkSpace. To maintain a WorkSpace without being interrupted, set the WorkSpace state to ADMIN_MAINTENANCE. WorkSpaces in this state do not respond to requests to reboot, stop, start, rebuild, or restore. An AutoStop WorkSpace in this state is not stopped. Users cannot log into a WorkSpace in the ADMIN_MAINTENANCE state."},{"ref":"AWS.WorkSpaces.html#reboot_workspaces/3","title":"AWS.WorkSpaces.reboot_workspaces/3","type":"function","doc":"Reboots the specified WorkSpaces. You cannot reboot a WorkSpace unless its state is AVAILABLE or UNHEALTHY. This operation is asynchronous and returns before the WorkSpaces have rebooted."},{"ref":"AWS.WorkSpaces.html#rebuild_workspaces/3","title":"AWS.WorkSpaces.rebuild_workspaces/3","type":"function","doc":"Rebuilds the specified WorkSpace. You cannot rebuild a WorkSpace unless its state is AVAILABLE, ERROR, UNHEALTHY, STOPPED, or REBOOTING. Rebuilding a WorkSpace is a potentially destructive action that can result in the loss of data. For more information, see Rebuild a WorkSpace. This operation is asynchronous and returns before the WorkSpaces have been completely rebuilt."},{"ref":"AWS.WorkSpaces.html#register_workspace_directory/3","title":"AWS.WorkSpaces.register_workspace_directory/3","type":"function","doc":"Registers the specified directory. This operation is asynchronous and returns before the WorkSpace directory is registered. If this is the first time you are registering a directory, you will need to create the workspaces_DefaultRole role before you can register a directory. For more information, see Creating the workspaces_DefaultRole Role."},{"ref":"AWS.WorkSpaces.html#restore_workspace/3","title":"AWS.WorkSpaces.restore_workspace/3","type":"function","doc":"Restores the specified WorkSpace to its last known healthy state. You cannot restore a WorkSpace unless its state is AVAILABLE, ERROR, UNHEALTHY, or STOPPED. Restoring a WorkSpace is a potentially destructive action that can result in the loss of data. For more information, see Restore a WorkSpace. This operation is asynchronous and returns before the WorkSpace is completely restored."},{"ref":"AWS.WorkSpaces.html#revoke_ip_rules/3","title":"AWS.WorkSpaces.revoke_ip_rules/3","type":"function","doc":"Removes one or more rules from the specified IP access control group."},{"ref":"AWS.WorkSpaces.html#start_workspaces/3","title":"AWS.WorkSpaces.start_workspaces/3","type":"function","doc":"Starts the specified WorkSpaces. You cannot start a WorkSpace unless it has a running mode of AutoStop and a state of STOPPED."},{"ref":"AWS.WorkSpaces.html#stop_workspaces/3","title":"AWS.WorkSpaces.stop_workspaces/3","type":"function","doc":"Stops the specified WorkSpaces. You cannot stop a WorkSpace unless it has a running mode of AutoStop and a state of AVAILABLE, IMPAIRED, UNHEALTHY, or ERROR."},{"ref":"AWS.WorkSpaces.html#terminate_workspaces/3","title":"AWS.WorkSpaces.terminate_workspaces/3","type":"function","doc":"Terminates the specified WorkSpaces. Terminating a WorkSpace is a permanent action and cannot be undone. The user&#39;s data is destroyed. If you need to archive any user data, contact Amazon Web Services before terminating the WorkSpace. You can terminate a WorkSpace that is in any state except SUSPENDED. This operation is asynchronous and returns before the WorkSpaces have been completely terminated."},{"ref":"AWS.WorkSpaces.html#update_connection_alias_permission/3","title":"AWS.WorkSpaces.update_connection_alias_permission/3","type":"function","doc":"Shares or unshares a connection alias with one account by specifying whether that account has permission to associate the connection alias with a directory. If the association permission is granted, the connection alias is shared with that account. If the association permission is revoked, the connection alias is unshared with the account. For more information, see Cross-Region Redirection for Amazon WorkSpaces. Before performing this operation, call DescribeConnectionAliases to make sure that the current state of the connection alias is CREATED. To delete a connection alias that has been shared, the shared account must first disassociate the connection alias from any directories it has been associated with. Then you must unshare the connection alias from the account it has been shared with. You can delete a connection alias only after it is no longer shared with any accounts or associated with any directories."},{"ref":"AWS.WorkSpaces.html#update_rules_of_ip_group/3","title":"AWS.WorkSpaces.update_rules_of_ip_group/3","type":"function","doc":"Replaces the current rules of the specified IP access control group with the specified rules."},{"ref":"AWS.WorkSpaces.html#update_workspace_image_permission/3","title":"AWS.WorkSpaces.update_workspace_image_permission/3","type":"function","doc":"Shares or unshares an image with one account by specifying whether that account has permission to copy the image. If the copy image permission is granted, the image is shared with that account. If the copy image permission is revoked, the image is unshared with the account. To delete an image that has been shared, you must unshare the image before you delete it. Sharing Bring Your Own License (BYOL) images across AWS accounts isn&#39;t supported at this time in the AWS GovCloud (US-West) Region. To share BYOL images across accounts in the AWS GovCloud (US-West) Region, contact AWS Support."},{"ref":"AWS.XRay.html","title":"AWS.XRay","type":"module","doc":"AWS X-Ray provides APIs for managing debug traces and retrieving service maps and other data created by processing those traces."},{"ref":"AWS.XRay.html#batch_get_traces/3","title":"AWS.XRay.batch_get_traces/3","type":"function","doc":"Retrieves a list of traces specified by ID. Each trace is a collection of segment documents that originates from a single request. Use GetTraceSummaries to get a list of trace IDs."},{"ref":"AWS.XRay.html#create_group/3","title":"AWS.XRay.create_group/3","type":"function","doc":"Creates a group resource with a name and a filter expression."},{"ref":"AWS.XRay.html#create_sampling_rule/3","title":"AWS.XRay.create_sampling_rule/3","type":"function","doc":"Creates a rule to control sampling behavior for instrumented applications. Services retrieve rules with GetSamplingRules, and evaluate each rule in ascending order of priority for each request. If a rule matches, the service records a trace, borrowing it from the reservoir size. After 10 seconds, the service reports back to X-Ray with GetSamplingTargets to get updated versions of each in-use rule. The updated rule contains a trace quota that the service can use instead of borrowing from the reservoir."},{"ref":"AWS.XRay.html#delete_group/3","title":"AWS.XRay.delete_group/3","type":"function","doc":"Deletes a group resource."},{"ref":"AWS.XRay.html#delete_sampling_rule/3","title":"AWS.XRay.delete_sampling_rule/3","type":"function","doc":"Deletes a sampling rule."},{"ref":"AWS.XRay.html#get_encryption_config/3","title":"AWS.XRay.get_encryption_config/3","type":"function","doc":"Retrieves the current encryption configuration for X-Ray data."},{"ref":"AWS.XRay.html#get_group/3","title":"AWS.XRay.get_group/3","type":"function","doc":"Retrieves group resource details."},{"ref":"AWS.XRay.html#get_groups/3","title":"AWS.XRay.get_groups/3","type":"function","doc":"Retrieves all active group details."},{"ref":"AWS.XRay.html#get_sampling_rules/3","title":"AWS.XRay.get_sampling_rules/3","type":"function","doc":"Retrieves all sampling rules."},{"ref":"AWS.XRay.html#get_sampling_statistic_summaries/3","title":"AWS.XRay.get_sampling_statistic_summaries/3","type":"function","doc":"Retrieves information about recent sampling results for all sampling rules."},{"ref":"AWS.XRay.html#get_sampling_targets/3","title":"AWS.XRay.get_sampling_targets/3","type":"function","doc":"Requests a sampling quota for rules that the service is using to sample requests."},{"ref":"AWS.XRay.html#get_service_graph/3","title":"AWS.XRay.get_service_graph/3","type":"function","doc":"Retrieves a document that describes services that process incoming requests, and downstream services that they call as a result. Root services process incoming requests and make calls to downstream services. Root services are applications that use the AWS X-Ray SDK. Downstream services can be other applications, AWS resources, HTTP web APIs, or SQL databases."},{"ref":"AWS.XRay.html#get_time_series_service_statistics/3","title":"AWS.XRay.get_time_series_service_statistics/3","type":"function","doc":"Get an aggregation of service statistics defined by a specific time range."},{"ref":"AWS.XRay.html#get_trace_graph/3","title":"AWS.XRay.get_trace_graph/3","type":"function","doc":"Retrieves a service graph for one or more specific trace IDs."},{"ref":"AWS.XRay.html#get_trace_summaries/3","title":"AWS.XRay.get_trace_summaries/3","type":"function","doc":"Retrieves IDs and annotations for traces available for a specified time frame using an optional filter. To get the full traces, pass the trace IDs to BatchGetTraces. A filter expression can target traced requests that hit specific service nodes or edges, have errors, or come from a known user. For example, the following filter expression targets traces that pass through api.example.com: service(&quot;api.example.com&quot;) This filter expression finds traces that have an annotation named account with the value 12345: annotation.account = &quot;12345&quot; For a full list of indexed fields and keywords that you can use in filter expressions, see Using Filter Expressions in the AWS X-Ray Developer Guide."},{"ref":"AWS.XRay.html#list_tags_for_resource/3","title":"AWS.XRay.list_tags_for_resource/3","type":"function","doc":"Returns a list of tags that are applied to the specified AWS X-Ray group or sampling rule."},{"ref":"AWS.XRay.html#put_encryption_config/3","title":"AWS.XRay.put_encryption_config/3","type":"function","doc":"Updates the encryption configuration for X-Ray data."},{"ref":"AWS.XRay.html#put_telemetry_records/3","title":"AWS.XRay.put_telemetry_records/3","type":"function","doc":"Used by the AWS X-Ray daemon to upload telemetry."},{"ref":"AWS.XRay.html#put_trace_segments/3","title":"AWS.XRay.put_trace_segments/3","type":"function","doc":"Uploads segment documents to AWS X-Ray. The X-Ray SDK generates segment documents and sends them to the X-Ray daemon, which uploads them in batches. A segment document can be a completed segment, an in-progress segment, or an array of subsegments. Segments must include the following fields. For the full segment document schema, see AWS X-Ray Segment Documents in the AWS X-Ray Developer Guide. Required Segment Document Fields name - The name of the service that handled the request. id - A 64-bit identifier for the segment, unique among segments in the same trace, in 16 hexadecimal digits. trace_id - A unique identifier that connects all segments and subsegments originating from a single client request. start_time - Time the segment or subsegment was created, in floating point seconds in epoch time, accurate to milliseconds. For example, 1480615200.010 or 1.480615200010E9. end_time - Time the segment or subsegment was closed. For example, 1480615200.090 or 1.480615200090E9. Specify either an end_time or in_progress. in_progress - Set to true instead of specifying an end_time to record that a segment has been started, but is not complete. Send an in progress segment when your application receives a request that will take a long time to serve, to trace the fact that the request was received. When the response is sent, send the complete segment to overwrite the in-progress segment. A trace_id consists of three numbers separated by hyphens. For example, 1-58406520-a006649127e371903a2de979. This includes: Trace ID Format The version number, i.e. 1. The time of the original request, in Unix epoch time, in 8 hexadecimal digits. For example, 10:00AM December 2nd, 2016 PST in epoch time is 1480615200 seconds, or 58406520 in hexadecimal. A 96-bit identifier for the trace, globally unique, in 24 hexadecimal digits."},{"ref":"AWS.XRay.html#tag_resource/3","title":"AWS.XRay.tag_resource/3","type":"function","doc":"Applies tags to an existing AWS X-Ray group or sampling rule."},{"ref":"AWS.XRay.html#untag_resource/3","title":"AWS.XRay.untag_resource/3","type":"function","doc":"Removes tags from an AWS X-Ray group or sampling rule. You cannot edit or delete system tags (those with an aws: prefix)."},{"ref":"AWS.XRay.html#update_group/3","title":"AWS.XRay.update_group/3","type":"function","doc":"Updates a group resource."},{"ref":"AWS.XRay.html#update_sampling_rule/3","title":"AWS.XRay.update_sampling_rule/3","type":"function","doc":"Modifies a sampling rule&#39;s configuration."}]